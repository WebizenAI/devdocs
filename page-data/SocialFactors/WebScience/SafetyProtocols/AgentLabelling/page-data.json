{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/SocialFactors/WebScience/SafetyProtocols/AgentLabelling/",
    "result": {"data":{"mdx":{"id":"7fc8def3-f169-5a56-aade-7ceca792d56f","tableOfContents":{"items":[{"url":"#agent-labelling","title":"Agent Labelling"}]},"fields":{"title":"Agent Labelling","slug":"/SocialFactors/WebScience/SafetyProtocols/AgentLabelling/","url":"https://devdocs.webizen.org/SocialFactors/WebScience/SafetyProtocols/AgentLabelling/","editUrl":"https://github.com/webizenai/devdocs/tree/main/SocialFactors/WebScience/SafetyProtocols/AgentLabelling.md","lastUpdatedAt":"2023-01-14T07:33:42.000Z","lastUpdated":"1/14/2023","gitCreatedAt":"2023-01-12T01:59:34.000Z","shouldShowTitle":false},"frontmatter":{"title":"","description":null,"imageAlt":null,"tags":[],"date":null,"dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"agent-labelling\"\n  }, \"Agent Labelling\"), mdx(\"p\", null, \"It is important that there is a clear means to distinguish between the content, information or processes and decisions that are made by Software Agents (AI) Vs. those made by legal entities; and in-turn also, the ability to dertermine which specific human beings were involved in many or causing any sort of causality related action to occur.\"), mdx(\"p\", null, \"Asking ChatGPT;\"), mdx(\"p\", null, \"My Question:\\nWhat are the sorts of dangers, threats and social attack vectors that may occur if human beings are falsely led to believe they are consuming the work of other human beings or legal entities; when in-fact they're consuming information generated via an artificial intelligence software program?\"), mdx(\"p\", null, \"ChatGPT Answer:\\n\", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"There are several dangers and threats that may occur if individuals are falsely led to believe that they are consuming information generated by other human beings or legal entities when it is actually generated by an artificial intelligence (AI) program. Some of these include:\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Misinformation and disinformation: AI-generated content can be used to spread false or misleading information, which can have negative effects on individuals and society at large.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Manipulation and influence: AI-generated content can be used to manipulate individuals and groups by appealing to their emotions, biases, and prejudices.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Privacy and security concerns: AI-generated content can be used to target individuals with personalized phishing, scams, and other malicious attacks.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Dehumanization and mistrust: People being exposed to AI generated content that is falsely presented as being generated by human could lead to mistrust in human-generated content, leading towards a dehumanization of human expression as well as a mistrust in human-generated content, AI-generated content can be used to perpetuate stereotypes and reinforce societal biases.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Interfere with legal process: AI-generated content can be used to impersonate people or entities for fraudulent activities or illegal activities and could interfere with legal proceedings.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Overall, it is important for individuals to be able to distinguish between AI-generated content and human-generated content in order to make informed decisions and to protect themselves from potential dangers.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Another potential danger of falsely believing that information is generated by human beings when it is actually generated by AI is that it may lead to a lack of critical thinking and evaluation of the information being consumed. If people believe that the information they are consuming is coming from a trusted source, they may be less likely to fact-check or critically evaluate it. This can lead to the spread of misinformation and disinformation, as well as a decrease in people's ability to make well-informed decisions.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Additionally, there may be ethical concerns associated with the use of AI-generated content, particularly when it is used to impersonate human beings or legal entities. The ability to generate content that is indistinguishable from human-generated content raises questions about consent and accountability, as well as potential harms that may be caused by the use of this technology.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Finally, the widespread use of AI-generated content has the potential to disrupt various industries and change the way people think about and interact with information. It could change how professional authors, journalists, and creative professionals work, which could have both positive and negative impacts on the economy and society.\")), mdx(\"p\", null, \"My Question:\\nWhat are some of the threats related to circumstances where government departments and/or employees may use Artificial Intelligence to act in a manner that has human rights implications in relation to the effect of those actions if it is not clearly labelled to have been done via an AI Agent?\"), mdx(\"p\", null, \"ChatGPT Answer: \"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"If government departments or employees use Artificial Intelligence (AI) in a way that has human rights implications and it is not clearly labeled as having been done by an AI agent, there could be several threats. Some of these include:\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"em\", {\n    parentName: \"li\"\n  }, \"Discrimination and bias: If an AI system is not transparent in its decision-making processes, it may perpetuate discrimination and bias against certain individuals or groups, potentially violating their human rights.\"))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"-   Lack of accountability: If an AI system is used to make decisions or take actions that have human rights implications, it can be difficult to hold individuals or organizations accountable if the system is not clearly labeled as an AI agent and its decision-making process is opaque.\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"em\", {\n    parentName: \"li\"\n  }, \"Due process concerns: If an AI system is used to make decisions that affect an individual's rights or freedoms, it may not always provide the same level of due process protections as a human decision-maker. This could lead to violations of human rights and the rule of law.\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"em\", {\n    parentName: \"li\"\n  }, \"Privacy and security: If an AI system is used to process personal data without proper regulation or oversight, it could lead to privacy violations, security breaches, and other harms.\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"em\", {\n    parentName: \"li\"\n  }, \"Lack of transparency: If the actions of an AI agent is not clearly labeled, it can make it difficult for people to understand how decisions are being made, which could lead to mistrust and lack of transparency.\"))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"-   Interference with human autonomy: If an AI agent make decisions that have significant impact on human life, people may lose their autonomy on the decision making process and their right to self-determination.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Overall, it is crucial that government departments and employees are transparent in their use of AI, clearly label any decisions or actions that are made by an AI agent, and ensure that the AI systems they use are fair, accountable, and respect human rights.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Another potential threat is that the AI may have unintended consequences on human rights, if it not properly implemented, tested, and monitored. Even if the AI system is not inherently biased, the data it is trained on may be biased, leading to unjust outcomes.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Additionally, if the use of AI is not transparent and the decision-making processes of the AI system are not explainable, it may be difficult for people to understand how the decisions are being made and to challenge them if they believe that their human rights are being violated.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Moreover, if AI agents are used in law enforcement or security, without proper oversight or regulation, there could be a risk that the AI systems may be used to infringe on individuals\\u2019 rights, such as freedom of speech and freedom of assembly, or to target certain groups based on their ethnicity, religion, or political beliefs.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"It is important that the use of AI by government departments and employees is subject to proper regulation and oversight, so that human rights are protected and that the actions of the AI systems can be transparently tracked and audited.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Finally, It is crucial that the AI system are continuously monitored and evaluated for their impacts on human rights and adjustments or replacements are made if necessary\"), \".\"), mdx(\"p\", null, \"My Question:\\nwhat are some of the potential risks in circumstances relating to foreign governments? \"), mdx(\"p\", null, \"ChatGPT Answer:\"), mdx(\"p\", null, \"There are several potential risks in circumstances related to foreign governments using AI:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Cyber espionage: Foreign governments may use AI to conduct cyber espionage or cyberattacks against other countries, potentially stealing sensitive information or disrupting critical infrastructure.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Misinformation and disinformation: Foreign governments may use AI-generated content to spread false or misleading information, with the intention of manipulating public opinion or undermining the credibility of other governments.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Interference in domestic politics: Foreign governments may use AI to interfere in the domestic politics of other countries, with the goal of swaying elections or influencing policy decisions.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Economic espionage: Foreign governments may use AI to gain an unfair advantage in international trade, by collecting business intelligence and targeting specific industries or companies.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Military advantage: Foreign governments may use AI to enhance their military capabilities, potentially threatening the stability of regions and global security\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Human Rights abuse: AI technology has been used by some governments to track and control their citizens, violating their privacy and freedom. This technology can also be used to identify and monitor individuals based on their ethnicity, religion, or political beliefs, leading to further human rights violations.\")), mdx(\"p\", null, \"Overall, the use of AI by foreign governments has the potential to destabilize international relations and threaten the security and sovereignty of other countries. It is important for governments to be aware of these risks and to take steps to protect against them, through international cooperation, regulation, and diplomacy.\"), mdx(\"p\", null, \"Another potential risk is that foreign governments may use AI in a way that violates international law or human rights. For example, they may use AI-enabled surveillance to target political opponents, or use autonomous weapons to target civilians in warfare. These actions can have significant negative consequences on human rights and global security.\"), mdx(\"p\", null, \"Moreover, the increasing use of AI in economic and technological fields may lead to a power imbalance between countries that have access to advanced AI technology and those that do not, leading to further economic and societal inequality.\"), mdx(\"p\", null, \"Furthermore, if AI is not controlled and regulated properly, foreign governments may use it to violate international norms, such as economic sanctions or arms control agreements.\"), mdx(\"p\", null, \"Lastly, foreign governments may also use AI to target individuals, companies or countries with cyber-attacks and disinformation campaigns for political, economic, or military gain.\"), mdx(\"p\", null, \"To mitigate these risks, it is crucial for countries to work together through international organizations and agreements to establish norms and regulations for the responsible development and use of AI, as well as to cooperate on matters of cyber security, disinformation, and human rights.\"), mdx(\"p\", null, \"My Question:\"), mdx(\"p\", null, \"What are some of the ways AI content and/or software actions could be clearly labelled and associated with the legal entity involved and responsible for that AI content and/or software action, including both any legal personality (ie: government department, institution, corporation or business, ) as well as the specific natural legal entities / individuals (human beings) who were instrumentally involved in enabling or rendering the applied use of AI for the particular artifact or event?\"), mdx(\"p\", null, \"ChatGPT Answer;\"), mdx(\"p\", null, \"There are several ways that AI content and/or software actions can be clearly labeled and associated with the legal entity responsible for them, including both the legal personality (e.g. government department, institution, corporation or business) and the specific natural legal entities/individuals who were involved in enabling or using the AI for the particular artifact or event. Some of these methods include:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Digital Signatures: Using digital signatures to verify the authenticity of AI content or software actions, and to link them to the legal entity or individual responsible for them.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Attribution Statements: Including an attribution statement in the AI content or software that identifies the legal entity or individual responsible for it.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Watermarking: Watermarking AI content or software with unique identifiers that can be used to trace it back to the legal entity or individual responsible for it.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Logging: Keeping detailed logs of who had access to and used the AI system, and what actions they took.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Transparency Reports: Publishing transparency reports that provide information on the legal entities and individuals involved in the development and use of AI, as well as the system's decision-making processes and any human rights considerations.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Certifications: Certifying the AI system by a third-party, that verifies that the system meets certain standards, such as fairness and transparency\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Source codes or system architecture: Making the source codes or system architecture of AI systems available for public inspection, in order for third parties to verify how the systems make decisions.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Human oversight: Ensuring that AI systems are designed with human oversight and decision-making capabilities to make adjustments or corrections if necessary, and keeping records of those adjustments or corrections.\")), mdx(\"p\", null, \"Overall, it is important to ensure that the AI system are clearly labeled and that the legal entity or individual responsible for the system is easily identifiable and can be held accountable for its actions. This can be achieved through a combination of technical and organizational measures, such as the ones listed above, which should be chosen according to the specific context and the potential impacts of the system.\"), mdx(\"p\", null, \"Another way of clearly labelling AI content and/or software actions and associating them with the legal entity responsible for them, is by using blockchain technology, it can enable the creation of an immutable and transparent record of the origin and usage of the AI content or software. This can enable users to verify the authenticity of the content and trace it back to the legal entity or individual that created it, providing a tamper-proof record of the development and usage of the AI system.\"), mdx(\"p\", null, \"Another approach to clearly identify the responsible entity is by using standard data labels, like the \\\"metadata\\\" of digital files, AI artifacts should also have standard labels that clearly identify the legal entity or individual responsible for them, such as the developer, creator, owner, or operator.\"), mdx(\"p\", null, \"Additionally, governments could also play a role in promoting transparency and accountability of AI systems by implementing regulations and guidelines on the labeling of AI content and software actions, and enforcing penalties for non-compliance.\"), mdx(\"p\", null, \"Finally, it is important to note that it is not just a technical problem but also a societal one, and that it requires a multi-stakeholder approach, which includes industry, civil society, and government, to develop a solution and to ensure that it is effectively implemented.\"), mdx(\"p\", null, \"Another way of clearly labeling AI content and/or software actions is by using certification systems. These systems involve an independent third party, such as a regulatory agency or industry group, evaluating the AI system and verifying that it meets certain standards, such as transparency, fairness, and accountability. These certifications can be used to clearly label the AI system and to provide assurance to users that the system has been independently reviewed and found to be trustworthy.\"), mdx(\"p\", null, \"Another way of clearly labelling AI content and/or software actions is by using explainable AI (XAI) techniques, these techniques allow the AI system to explain its decision-making process to users in a way that is easy for humans to understand. This can help users to trust the system and to understand how it makes decisions, and also make it easier for legal entities or individuals to be held accountable for the actions of the system.\"), mdx(\"p\", null, \"Finally, it is important to educate the public about the importance of clearly labeling AI content and/or software actions and associating them with the legal entity responsible for them. This can help to increase awareness of the risks associated with AI and to promote responsible use of the technology.\"), mdx(\"p\", null, \"In summary, there are many methods for clearly labelling AI content and/or software actions and associating them with the legal entity responsible for them, such as digital signatures, attribution statements, watermarking, logging, transparency reports, certifications, blockchain, standard data labels, explainable AI (XAI) and education. These methods can be used in combination to provide a comprehensive approach to transparency and accountability of AI systems.\"), mdx(\"p\", null, \"My Question:\\nHow might an ontology using RDF and common vocabularies be defined to provide a means to deploy these sorts of solutions? Can you give me an example of an RDF OWL ontology?\"), mdx(\"p\", null, \"An ontology using RDF and common vocabularies can provide a structured way to describe and represent information related to the legal entity responsible for AI content and/or software actions, as well as the actions themselves. RDF (Resource Description Framework) is a standard for modeling information on the web, and it provides a way to express the relationships between resources (e.g. documents, people, and concepts) using a graph-based structure.\"), mdx(\"p\", null, \"A simple example of an RDF OWL (Web Ontology Language) ontology for describing AI content and software actions could include classes such as \\\"AI system\\\", \\\"Legal entity\\\", \\\"Individual\\\", \\\"Action\\\", and \\\"Responsibility\\\". Each class would have a set of properties that describe their characteristics and relationships, such as \\\"name\\\", \\\"developer\\\", \\\"owner\\\", \\\"operator\\\", \\\"decision-making process\\\" and \\\"Standards met\\\", respectively.\"), mdx(\"p\", null, \"For example, the class \\\"AI system\\\" could have properties such as \\\"name\\\", \\\"developer\\\", \\\"owner\\\", \\\"operator\\\" and \\\"decision-making process\\\". The class \\\"Legal entity\\\" would have properties such as \\\"name\\\", \\\"type\\\" (e.g. government department, institution, corporation or business), \\\"location\\\", and \\\"jurisdiction\\\". The class \\\"Individual\\\" would have properties such as \\\"name\\\" and \\\"role\\\" (e.g. developer, owner, operator). The class \\\"Action\\\" would have properties such as \\\"name\\\", \\\"date\\\", \\\"type\\\" (e.g. decision, action) and \\\"outcome\\\". The class \\\"Responsibility\\\" would have properties such as \\\"level\\\" (e.g. primary, secondary, etc) and \\\"entity\\\" (e.g. legal entity, individual)\"), mdx(\"p\", null, \"These classes and properties can be interconnected to describe complex relationships between AI systems, legal entities, individuals, and actions, and can be used to trace the origin and usage of AI content and software actions, and to establish accountability and transparency. The use of common vocabularies, such as schema.org and others, would help to standardize the representation of the information and make it more easily understandable and usable by different systems and applications.\"), mdx(\"p\", null, \"It's worth noting that this is just a simple example and that a more comprehensive ontology would be more complex and take into account the specific context and use case. And that, the use of RDF and OWL enables the use of formal reasoning to infer new information from the ontology, which is particularly useful for the transparency and accountability of AI systems.\"), mdx(\"p\", null, \"Additionally, using RDF and OWL to represent an ontology can enable the use of formal reasoning to infer new information from the ontology, this is particularly useful for transparency and accountability of AI systems. For example, by creating inferences rules in the ontology, you can automatically infer information about the legal entities, individuals and actions responsible for an AI system, based on the properties of the AI system.\"), mdx(\"p\", null, \"Moreover, using RDF and OWL in this context can also enable the integration of the ontology with other systems, such as databases, document management systems and even other AI systems. This is particularly useful for creating transparency and accountability solutions, where information about AI systems, legal entities and individuals need to be shared and combined across different systems.\"), mdx(\"p\", null, \"Another advantage of using RDF and OWL is that they can leverage the Linked Data ecosystem, which allows for easy data sharing and integration across different organizations and domains. This allows for more collaboration between different stakeholders, like industry, civil society and government, to help ensure the transparency and accountability of AI systems.\"), mdx(\"p\", null, \"Finally, it is important to note that creating an ontology is just a first step, the ontology itself should be continuously updated, maintained, and evaluated to make sure it is still useful and useful, to address the complexity and dynamic nature of the field of AI.\"), mdx(\"p\", null, \"My Question:\"), mdx(\"p\", null, \"can you write an example in notation3 syntax.\"), mdx(\"p\", null, \"ChatGPT Answer:\"), mdx(\"p\", null, \"Sure, here is an example of an RDF ontology written in Notation3 (N3) syntax to describe an AI system and its responsible legal entities and individuals:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"@prefix ai: <http://example.com/ontology/ai#> .\\n@prefix foaf: <http://xmlns.com/foaf/0.1/> .\\n@prefix org: <http://www.w3.org/ns/org#> .\\n\\nai:MyAI a ai:AI;\\n    ai:name \\\"My AI System\\\";\\n    ai:developer [ a foaf:Person; foaf:name \\\"John Doe\\\" ];\\n    ai:owner [ a org:Organization; org:name \\\"Acme Inc.\\\" ];\\n    ai:operator [ a foaf:Person; foaf:name \\\"Jane Smith\\\" ];\\n    ai:decision-makingProcess \\\"Explainable AI using Decision Trees\\\" .\\n\\n\")), mdx(\"p\", null, \"In this example, the ontology defines a class \\\"AI\\\" (ai:AI) and an instance of that class \\\"MyAI\\\" (ai:MyAI), it also specifies that \\\"MyAI\\\" has a name \\\"My AI System\\\", a developer \\\"John Doe\\\" (foaf:Person), an owner \\\"Acme Inc.\\\" (org:Organization), an operator \\\"Jane Smith\\\" (foaf:Person) and a decision-making process \\\"Explainable AI using Decision Trees\\\"\"), mdx(\"p\", null, \"This ontology uses prefixes to simplify the URIs (ai:, foaf:, org:) used in the statements. The prefixes indicate that the URIs in the ontology are from the given namespace, so \\\"ai:AI\\\" refers to the URI \\\"\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://example.com/ontology/ai#AI\"\n  }, \"http://example.com/ontology/ai#AI\"), \"\\\".\"), mdx(\"p\", null, \"Note that this is a simplified example, in real-world scenarios, the ontology would likely have more classes and properties and also, would relate to other ontologies to provide more context and meaning, such as time, location, standards met, etc.\"), mdx(\"p\", null, \"Additionally, the ontology can include more classes and properties such as \\\"Action\\\", \\\"Responsibility\\\", \\\"Jurisdiction\\\", \\\"Location\\\", \\\"Date\\\", \\\"Standards\\\", \\\"Certification\\\" and \\\"TransparencyReports\\\" that describe the actions taken by the AI system, the level of responsibility of the legal entities and individuals, the jurisdiction, location, date of action, standards met, certifications achieved and transparency reports respectively.\"), mdx(\"p\", null, \"Here's an example of how these classes and properties can be added to the ontology:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"@prefix ai: <http://example.com/ontology/ai#> .\\n@prefix foaf: <http://xmlns.com/foaf/0.1/> .\\n@prefix org: <http://www.w3.org/ns/org#> .\\n@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\\n\\nai:MyAI a ai:AI;\\n    ai:name \\\"My AI System\\\";\\n    ai:developer [ a foaf:Person; foaf:name \\\"John Doe\\\" ];\\n    ai:owner [ a org:Organization; org:name \\\"Acme Inc.\\\" ];\\n    ai:operator [ a foaf:Person; foaf:name \\\"Jane Smith\\\" ];\\n    ai:decision-makingProcess \\\"Explainable AI using Decision Trees\\\" ;\\n    ai:performedAction [ a ai:Action; ai:name \\\"Decision Making\\\";\\n    ai:outcome \\\"Approve the loan\\\";\\n    ai:date \\\"2022-01-12T10:30:00Z\\\"^^xsd:dateTime];\\n    ai:responsibility [ a ai:Responsibility;\\n    ai:level \\\"Primary\\\";\\n    ai:entity [a org:Organization; org:name \\\"Acme Inc.\\\" ]];\\n    ai:jurisdiction \\\"US\\\";\\n    ai:location \\\"New York\\\";\\n    ai:standardsMet \\\"ISO/IEC 27001:2013\\\";\\n    ai:certifications \\\"ISO/IEC 27001:2013 certified\\\";\\n    ai:transparencyReports <http://example.com/reports/myaisystem> .\\n\\n\")), mdx(\"p\", null, \"This enhanced example illustrates how more information can be added to the ontology, such as the actions taken by the AI system, the outcome, the date of the action, the level of responsibility of the legal entities and individuals, the jurisdiction, location, the standards met, certifications achieved, and transparency reports.\"), mdx(\"p\", null, \"It is worth noting that the example provided is not intended to be a complete or perfect ontology but is meant to give an idea of how RDF and OWL can be used to represent an ontology that would help with transparency and accountability of AI systems.\"), mdx(\"p\", null, \"My Question:\"), mdx(\"p\", null, \"can you provide a more comprehensive example in json-ld?\"), mdx(\"p\", null, \"ChatGPT Answer:\"), mdx(\"p\", null, \"Sure, here is a more comprehensive example of an RDF ontology written in JSON-LD (JavaScript Object Notation for Linked Data) syntax to describe an AI system and its responsible legal entities and individuals:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-json\"\n  }, \"\\n{\\n\\n\\xA0 \\xA0 \\\"@context\\\": {\\n\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"rdf\\\": \\\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"rdfs\\\": \\\"http://www.w3.org/2000/01/rdf-schema#\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"xsd\\\": \\\"http://www.w3.org/2001/XMLSchema#\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"foaf\\\": \\\"http://xmlns.com/foaf/0.1/\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"org\\\": \\\"http://www.w3.org/ns/org#\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"ai\\\": \\\"http://example.com/ontology/ai#\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"name\\\": \\\"ai:name\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"developer\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"ai:developer\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"@id\\\"\\n\\xA0 \\xA0 \\xA0 \\xA0 },\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"owner\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"ai:owner\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"@id\\\"\\n\\xA0 \\xA0 \\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"operator\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"ai:operator\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"@id\\\"\\n\\xA0 \\xA0 \\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"decision-makingProcess\\\": \\\"ai:decision-makingProcess\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"performedAction\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"ai:performedAction\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"@id\\\"\\n\\xA0 \\xA0 \\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"outcome\\\": \\\"ai:outcome\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"date\\\": \\\"ai:date\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"responsibility\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"ai:responsibility\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"@id\\\"\\n\\xA0 \\xA0 \\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"level\\\": \\\"ai:level\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"entity\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"ai:entity\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"@id\\\"\\n\\xA0 \\xA0 \\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"jurisdiction\\\": \\\"ai:jurisdiction\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"location\\\": \\\"ai:location\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"standardsMet\\\": \\\"ai:standardsMet\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"certifications\\\": \\\"ai:certifications\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"transparencyReports\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"ai:transparencyReports\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"@id\\\"\\n\\xA0 \\xA0 \\xA0 \\xA0 }\\n\\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\\"@id\\\": \\\"ai:MyAI\\\",\\n\\xA0 \\xA0 \\\"@type\\\": \\\"ai:AI\\\",\\n\\xA0 \\xA0 \\\"name\\\": \\\"My AI System\\\",\\n\\xA0 \\xA0 \\\"developer\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"foaf:JohnDoe\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"foaf:Person\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"name\\\": \\\"John Doe\\\"\\n\\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\\"owner\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"org:AcmeInc\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"org:Organization\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"name\\\": \\\"Acme Inc.\\\"\\n\\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\\"operator\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"foaf:JaneSmith\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"foaf:Person\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"name\\\": \\\"Jane Smith\\\"\\n\\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\\"decision-makingProcess\\\": \\\"Explainable AI using Decision Trees\\\",\\n\\xA0 \\xA0 \\\"performedAction\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"ai:Action1\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"ai:Action\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"name\\\": \\\"Decision Making\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"outcome\\\": \\\"Approve the loan\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"date\\\": \\\"2022-01-12T10:30:00Z\\\"\\n\\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\\"responsibility\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"ai:responsibility1\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"ai:Responsibility\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"level\\\": \\\"Primary\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"entity\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"org:AcmeInc\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"org:Organization\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"name\\\": \\\"Acme Inc.\\\"\\n\\xA0 \\xA0 \\xA0 \\xA0 }\\n\\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\\"jurisdiction\\\": \\\"US\\\",\\n\\xA0 \\xA0 \\\"location\\\": \\\"New York\\\",\\n\\xA0 \\xA0 \\\"standardsMet\\\": \\\"ISO/IEC 27001:2013\\\",\\n\\xA0 \\xA0 \\\"certifications\\\": \\\"ISO/IEC 27001:2013 certified\\\",\\n\\xA0 \\xA0 \\\"transparencyReports\\\": \\\"http://example.com/reports/myaisystem\\\"\\n}\\n\")), mdx(\"p\", null, \"In this example, the ontology defines several classes, such as \\\"AI\\\" (ai:AI), \\\"Action\\\" (ai:Action), \\\"Responsibility\\\" (ai:Responsibility), \\\"Person\\\" (foaf:Person), and \\\"Organization\\\" (org:Organization), it also specifies that \\\"MyAI\\\" has a name, developer, owner, operator, decision-making process, performed actions, outcome, date, level of responsibility, and jurisdiction, location, standards met, certifications and transparency reports. \"), mdx(\"p\", null, \"The context provided, maps the prefixes used in the ontology to the corresponding URIs, as well as provides data types and relationships between the different classes and properties. This is used to make the JSON-LD data more easily readable for both machines and humans. As before, it's important to note that this is just an example and that the ontology can be much more detailed, depending on the complexity and dynamic nature of the field of AI.\"), mdx(\"h3\", {\n    \"id\": \"considerations\"\n  }, \"CONSIDERATIONS\"), mdx(\"p\", null, \"Whilst the specific approach certainly requires a great deal more work and consideration, the merit of the underlying notion appears to be considered important even by ChatGPT.  \"), mdx(\"p\", null, \"I hope this explains enough of this underlying consideration as is sought to be sufficiently illustrated, as to be added to the ToDo list for informatics policies relating to the development of webizen systems.\"));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"\n# Agent Labelling\n\nIt is important that there is a clear means to distinguish between the content, information or processes and decisions that are made by Software Agents (AI) Vs. those made by legal entities; and in-turn also, the ability to dertermine which specific human beings were involved in many or causing any sort of causality related action to occur.\n\nAsking ChatGPT;\n\nMy Question:\nWhat are the sorts of dangers, threats and social attack vectors that may occur if human beings are falsely led to believe they are consuming the work of other human beings or legal entities; when in-fact they're consuming information generated via an artificial intelligence software program?\n\nChatGPT Answer:\n*There are several dangers and threats that may occur if individuals are falsely led to believe that they are consuming information generated by other human beings or legal entities when it is actually generated by an artificial intelligence (AI) program. Some of these include:*\n\n-   Misinformation and disinformation: AI-generated content can be used to spread false or misleading information, which can have negative effects on individuals and society at large.\n    \n-   Manipulation and influence: AI-generated content can be used to manipulate individuals and groups by appealing to their emotions, biases, and prejudices.\n    \n-   Privacy and security concerns: AI-generated content can be used to target individuals with personalized phishing, scams, and other malicious attacks.\n    \n-   Dehumanization and mistrust: People being exposed to AI generated content that is falsely presented as being generated by human could lead to mistrust in human-generated content, leading towards a dehumanization of human expression as well as a mistrust in human-generated content, AI-generated content can be used to perpetuate stereotypes and reinforce societal biases.\n    \n-   Interfere with legal process: AI-generated content can be used to impersonate people or entities for fraudulent activities or illegal activities and could interfere with legal proceedings.\n    \n\n*Overall, it is important for individuals to be able to distinguish between AI-generated content and human-generated content in order to make informed decisions and to protect themselves from potential dangers.*\n\n*Another potential danger of falsely believing that information is generated by human beings when it is actually generated by AI is that it may lead to a lack of critical thinking and evaluation of the information being consumed. If people believe that the information they are consuming is coming from a trusted source, they may be less likely to fact-check or critically evaluate it. This can lead to the spread of misinformation and disinformation, as well as a decrease in people's ability to make well-informed decisions.*\n\n*Additionally, there may be ethical concerns associated with the use of AI-generated content, particularly when it is used to impersonate human beings or legal entities. The ability to generate content that is indistinguishable from human-generated content raises questions about consent and accountability, as well as potential harms that may be caused by the use of this technology.*\n\n*Finally, the widespread use of AI-generated content has the potential to disrupt various industries and change the way people think about and interact with information. It could change how professional authors, journalists, and creative professionals work, which could have both positive and negative impacts on the economy and society.*\n\nMy Question: \nWhat are some of the threats related to circumstances where government departments and/or employees may use Artificial Intelligence to act in a manner that has human rights implications in relation to the effect of those actions if it is not clearly labelled to have been done via an AI Agent?\n\n\nChatGPT Answer: \n\n*If government departments or employees use Artificial Intelligence (AI) in a way that has human rights implications and it is not clearly labeled as having been done by an AI agent, there could be several threats. Some of these include:*\n\n-   *Discrimination and bias: If an AI system is not transparent in its decision-making processes, it may perpetuate discrimination and bias against certain individuals or groups, potentially violating their human rights.*\n    \n*-   Lack of accountability: If an AI system is used to make decisions or take actions that have human rights implications, it can be difficult to hold individuals or organizations accountable if the system is not clearly labeled as an AI agent and its decision-making process is opaque.*\n    \n-   *Due process concerns: If an AI system is used to make decisions that affect an individual's rights or freedoms, it may not always provide the same level of due process protections as a human decision-maker. This could lead to violations of human rights and the rule of law.*\n    \n-   *Privacy and security: If an AI system is used to process personal data without proper regulation or oversight, it could lead to privacy violations, security breaches, and other harms.*\n    \n-   *Lack of transparency: If the actions of an AI agent is not clearly labeled, it can make it difficult for people to understand how decisions are being made, which could lead to mistrust and lack of transparency.*\n    \n*-   Interference with human autonomy: If an AI agent make decisions that have significant impact on human life, people may lose their autonomy on the decision making process and their right to self-determination.*\n    \n\n*Overall, it is crucial that government departments and employees are transparent in their use of AI, clearly label any decisions or actions that are made by an AI agent, and ensure that the AI systems they use are fair, accountable, and respect human rights.*\n\n*Another potential threat is that the AI may have unintended consequences on human rights, if it not properly implemented, tested, and monitored. Even if the AI system is not inherently biased, the data it is trained on may be biased, leading to unjust outcomes.*\n\n*Additionally, if the use of AI is not transparent and the decision-making processes of the AI system are not explainable, it may be difficult for people to understand how the decisions are being made and to challenge them if they believe that their human rights are being violated.*\n\n*Moreover, if AI agents are used in law enforcement or security, without proper oversight or regulation, there could be a risk that the AI systems may be used to infringe on individuals’ rights, such as freedom of speech and freedom of assembly, or to target certain groups based on their ethnicity, religion, or political beliefs.*\n\n*It is important that the use of AI by government departments and employees is subject to proper regulation and oversight, so that human rights are protected and that the actions of the AI systems can be transparently tracked and audited.*\n\n*Finally, It is crucial that the AI system are continuously monitored and evaluated for their impacts on human rights and adjustments or replacements are made if necessary*.\n\nMy Question:\nwhat are some of the potential risks in circumstances relating to foreign governments? \n\nChatGPT Answer:\n\nThere are several potential risks in circumstances related to foreign governments using AI:\n\n-   Cyber espionage: Foreign governments may use AI to conduct cyber espionage or cyberattacks against other countries, potentially stealing sensitive information or disrupting critical infrastructure.\n    \n-   Misinformation and disinformation: Foreign governments may use AI-generated content to spread false or misleading information, with the intention of manipulating public opinion or undermining the credibility of other governments.\n    \n-   Interference in domestic politics: Foreign governments may use AI to interfere in the domestic politics of other countries, with the goal of swaying elections or influencing policy decisions.\n    \n-   Economic espionage: Foreign governments may use AI to gain an unfair advantage in international trade, by collecting business intelligence and targeting specific industries or companies.\n    \n-   Military advantage: Foreign governments may use AI to enhance their military capabilities, potentially threatening the stability of regions and global security\n    \n-   Human Rights abuse: AI technology has been used by some governments to track and control their citizens, violating their privacy and freedom. This technology can also be used to identify and monitor individuals based on their ethnicity, religion, or political beliefs, leading to further human rights violations.\n    \n\nOverall, the use of AI by foreign governments has the potential to destabilize international relations and threaten the security and sovereignty of other countries. It is important for governments to be aware of these risks and to take steps to protect against them, through international cooperation, regulation, and diplomacy.\n\nAnother potential risk is that foreign governments may use AI in a way that violates international law or human rights. For example, they may use AI-enabled surveillance to target political opponents, or use autonomous weapons to target civilians in warfare. These actions can have significant negative consequences on human rights and global security.\n\nMoreover, the increasing use of AI in economic and technological fields may lead to a power imbalance between countries that have access to advanced AI technology and those that do not, leading to further economic and societal inequality.\n\nFurthermore, if AI is not controlled and regulated properly, foreign governments may use it to violate international norms, such as economic sanctions or arms control agreements.\n\nLastly, foreign governments may also use AI to target individuals, companies or countries with cyber-attacks and disinformation campaigns for political, economic, or military gain.\n\nTo mitigate these risks, it is crucial for countries to work together through international organizations and agreements to establish norms and regulations for the responsible development and use of AI, as well as to cooperate on matters of cyber security, disinformation, and human rights.\n\n\nMy Question:\n\nWhat are some of the ways AI content and/or software actions could be clearly labelled and associated with the legal entity involved and responsible for that AI content and/or software action, including both any legal personality (ie: government department, institution, corporation or business, ) as well as the specific natural legal entities / individuals (human beings) who were instrumentally involved in enabling or rendering the applied use of AI for the particular artifact or event?\n\nChatGPT Answer;\n\nThere are several ways that AI content and/or software actions can be clearly labeled and associated with the legal entity responsible for them, including both the legal personality (e.g. government department, institution, corporation or business) and the specific natural legal entities/individuals who were involved in enabling or using the AI for the particular artifact or event. Some of these methods include:\n\n-   Digital Signatures: Using digital signatures to verify the authenticity of AI content or software actions, and to link them to the legal entity or individual responsible for them.\n    \n-   Attribution Statements: Including an attribution statement in the AI content or software that identifies the legal entity or individual responsible for it.\n    \n-   Watermarking: Watermarking AI content or software with unique identifiers that can be used to trace it back to the legal entity or individual responsible for it.\n    \n-   Logging: Keeping detailed logs of who had access to and used the AI system, and what actions they took.\n    \n-   Transparency Reports: Publishing transparency reports that provide information on the legal entities and individuals involved in the development and use of AI, as well as the system's decision-making processes and any human rights considerations.\n    \n-   Certifications: Certifying the AI system by a third-party, that verifies that the system meets certain standards, such as fairness and transparency\n    \n-   Source codes or system architecture: Making the source codes or system architecture of AI systems available for public inspection, in order for third parties to verify how the systems make decisions.\n    \n-   Human oversight: Ensuring that AI systems are designed with human oversight and decision-making capabilities to make adjustments or corrections if necessary, and keeping records of those adjustments or corrections.\n    \n\nOverall, it is important to ensure that the AI system are clearly labeled and that the legal entity or individual responsible for the system is easily identifiable and can be held accountable for its actions. This can be achieved through a combination of technical and organizational measures, such as the ones listed above, which should be chosen according to the specific context and the potential impacts of the system.\n\nAnother way of clearly labelling AI content and/or software actions and associating them with the legal entity responsible for them, is by using blockchain technology, it can enable the creation of an immutable and transparent record of the origin and usage of the AI content or software. This can enable users to verify the authenticity of the content and trace it back to the legal entity or individual that created it, providing a tamper-proof record of the development and usage of the AI system.\n\nAnother approach to clearly identify the responsible entity is by using standard data labels, like the \"metadata\" of digital files, AI artifacts should also have standard labels that clearly identify the legal entity or individual responsible for them, such as the developer, creator, owner, or operator.\n\nAdditionally, governments could also play a role in promoting transparency and accountability of AI systems by implementing regulations and guidelines on the labeling of AI content and software actions, and enforcing penalties for non-compliance.\n\nFinally, it is important to note that it is not just a technical problem but also a societal one, and that it requires a multi-stakeholder approach, which includes industry, civil society, and government, to develop a solution and to ensure that it is effectively implemented.\n\nAnother way of clearly labeling AI content and/or software actions is by using certification systems. These systems involve an independent third party, such as a regulatory agency or industry group, evaluating the AI system and verifying that it meets certain standards, such as transparency, fairness, and accountability. These certifications can be used to clearly label the AI system and to provide assurance to users that the system has been independently reviewed and found to be trustworthy.\n\nAnother way of clearly labelling AI content and/or software actions is by using explainable AI (XAI) techniques, these techniques allow the AI system to explain its decision-making process to users in a way that is easy for humans to understand. This can help users to trust the system and to understand how it makes decisions, and also make it easier for legal entities or individuals to be held accountable for the actions of the system.\n\nFinally, it is important to educate the public about the importance of clearly labeling AI content and/or software actions and associating them with the legal entity responsible for them. This can help to increase awareness of the risks associated with AI and to promote responsible use of the technology.\n\nIn summary, there are many methods for clearly labelling AI content and/or software actions and associating them with the legal entity responsible for them, such as digital signatures, attribution statements, watermarking, logging, transparency reports, certifications, blockchain, standard data labels, explainable AI (XAI) and education. These methods can be used in combination to provide a comprehensive approach to transparency and accountability of AI systems.\n\nMy Question:\nHow might an ontology using RDF and common vocabularies be defined to provide a means to deploy these sorts of solutions? Can you give me an example of an RDF OWL ontology?\n\nAn ontology using RDF and common vocabularies can provide a structured way to describe and represent information related to the legal entity responsible for AI content and/or software actions, as well as the actions themselves. RDF (Resource Description Framework) is a standard for modeling information on the web, and it provides a way to express the relationships between resources (e.g. documents, people, and concepts) using a graph-based structure.\n\nA simple example of an RDF OWL (Web Ontology Language) ontology for describing AI content and software actions could include classes such as \"AI system\", \"Legal entity\", \"Individual\", \"Action\", and \"Responsibility\". Each class would have a set of properties that describe their characteristics and relationships, such as \"name\", \"developer\", \"owner\", \"operator\", \"decision-making process\" and \"Standards met\", respectively.\n\nFor example, the class \"AI system\" could have properties such as \"name\", \"developer\", \"owner\", \"operator\" and \"decision-making process\". The class \"Legal entity\" would have properties such as \"name\", \"type\" (e.g. government department, institution, corporation or business), \"location\", and \"jurisdiction\". The class \"Individual\" would have properties such as \"name\" and \"role\" (e.g. developer, owner, operator). The class \"Action\" would have properties such as \"name\", \"date\", \"type\" (e.g. decision, action) and \"outcome\". The class \"Responsibility\" would have properties such as \"level\" (e.g. primary, secondary, etc) and \"entity\" (e.g. legal entity, individual)\n\nThese classes and properties can be interconnected to describe complex relationships between AI systems, legal entities, individuals, and actions, and can be used to trace the origin and usage of AI content and software actions, and to establish accountability and transparency. The use of common vocabularies, such as schema.org and others, would help to standardize the representation of the information and make it more easily understandable and usable by different systems and applications.\n\nIt's worth noting that this is just a simple example and that a more comprehensive ontology would be more complex and take into account the specific context and use case. And that, the use of RDF and OWL enables the use of formal reasoning to infer new information from the ontology, which is particularly useful for the transparency and accountability of AI systems.\n\nAdditionally, using RDF and OWL to represent an ontology can enable the use of formal reasoning to infer new information from the ontology, this is particularly useful for transparency and accountability of AI systems. For example, by creating inferences rules in the ontology, you can automatically infer information about the legal entities, individuals and actions responsible for an AI system, based on the properties of the AI system.\n\nMoreover, using RDF and OWL in this context can also enable the integration of the ontology with other systems, such as databases, document management systems and even other AI systems. This is particularly useful for creating transparency and accountability solutions, where information about AI systems, legal entities and individuals need to be shared and combined across different systems.\n\nAnother advantage of using RDF and OWL is that they can leverage the Linked Data ecosystem, which allows for easy data sharing and integration across different organizations and domains. This allows for more collaboration between different stakeholders, like industry, civil society and government, to help ensure the transparency and accountability of AI systems.\n\nFinally, it is important to note that creating an ontology is just a first step, the ontology itself should be continuously updated, maintained, and evaluated to make sure it is still useful and useful, to address the complexity and dynamic nature of the field of AI.\n\nMy Question:\n\ncan you write an example in notation3 syntax.\n\nChatGPT Answer:\n\nSure, here is an example of an RDF ontology written in Notation3 (N3) syntax to describe an AI system and its responsible legal entities and individuals:\n\n``` \n@prefix ai: <http://example.com/ontology/ai#> .\n@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n@prefix org: <http://www.w3.org/ns/org#> .\n\nai:MyAI a ai:AI;\n    ai:name \"My AI System\";\n    ai:developer [ a foaf:Person; foaf:name \"John Doe\" ];\n    ai:owner [ a org:Organization; org:name \"Acme Inc.\" ];\n    ai:operator [ a foaf:Person; foaf:name \"Jane Smith\" ];\n    ai:decision-makingProcess \"Explainable AI using Decision Trees\" .\n\n```\n\nIn this example, the ontology defines a class \"AI\" (ai:AI) and an instance of that class \"MyAI\" (ai:MyAI), it also specifies that \"MyAI\" has a name \"My AI System\", a developer \"John Doe\" (foaf:Person), an owner \"Acme Inc.\" (org:Organization), an operator \"Jane Smith\" (foaf:Person) and a decision-making process \"Explainable AI using Decision Trees\"\n\nThis ontology uses prefixes to simplify the URIs (ai:, foaf:, org:) used in the statements. The prefixes indicate that the URIs in the ontology are from the given namespace, so \"ai:AI\" refers to the URI \"[http://example.com/ontology/ai#AI](http://example.com/ontology/ai#AI)\".\n\nNote that this is a simplified example, in real-world scenarios, the ontology would likely have more classes and properties and also, would relate to other ontologies to provide more context and meaning, such as time, location, standards met, etc.\n\nAdditionally, the ontology can include more classes and properties such as \"Action\", \"Responsibility\", \"Jurisdiction\", \"Location\", \"Date\", \"Standards\", \"Certification\" and \"TransparencyReports\" that describe the actions taken by the AI system, the level of responsibility of the legal entities and individuals, the jurisdiction, location, date of action, standards met, certifications achieved and transparency reports respectively.\n\nHere's an example of how these classes and properties can be added to the ontology:\n\n```\n@prefix ai: <http://example.com/ontology/ai#> .\n@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n@prefix org: <http://www.w3.org/ns/org#> .\n@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n\nai:MyAI a ai:AI;\n    ai:name \"My AI System\";\n    ai:developer [ a foaf:Person; foaf:name \"John Doe\" ];\n    ai:owner [ a org:Organization; org:name \"Acme Inc.\" ];\n    ai:operator [ a foaf:Person; foaf:name \"Jane Smith\" ];\n    ai:decision-makingProcess \"Explainable AI using Decision Trees\" ;\n    ai:performedAction [ a ai:Action; ai:name \"Decision Making\";\n    ai:outcome \"Approve the loan\";\n    ai:date \"2022-01-12T10:30:00Z\"^^xsd:dateTime];\n    ai:responsibility [ a ai:Responsibility;\n    ai:level \"Primary\";\n    ai:entity [a org:Organization; org:name \"Acme Inc.\" ]];\n    ai:jurisdiction \"US\";\n    ai:location \"New York\";\n    ai:standardsMet \"ISO/IEC 27001:2013\";\n    ai:certifications \"ISO/IEC 27001:2013 certified\";\n    ai:transparencyReports <http://example.com/reports/myaisystem> .\n\n```\n\n\nThis enhanced example illustrates how more information can be added to the ontology, such as the actions taken by the AI system, the outcome, the date of the action, the level of responsibility of the legal entities and individuals, the jurisdiction, location, the standards met, certifications achieved, and transparency reports.\n\nIt is worth noting that the example provided is not intended to be a complete or perfect ontology but is meant to give an idea of how RDF and OWL can be used to represent an ontology that would help with transparency and accountability of AI systems.\n\n\nMy Question:\n\ncan you provide a more comprehensive example in json-ld?\n\nChatGPT Answer:\n\nSure, here is a more comprehensive example of an RDF ontology written in JSON-LD (JavaScript Object Notation for Linked Data) syntax to describe an AI system and its responsible legal entities and individuals:\n\n```json\n\n{\n\n    \"@context\": {\n\n        \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n        \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\",\n        \"xsd\": \"http://www.w3.org/2001/XMLSchema#\",\n        \"foaf\": \"http://xmlns.com/foaf/0.1/\",\n        \"org\": \"http://www.w3.org/ns/org#\",\n        \"ai\": \"http://example.com/ontology/ai#\",\n        \"name\": \"ai:name\",\n        \"developer\": {\n            \"@id\": \"ai:developer\",\n            \"@type\": \"@id\"\n        },\n        \"owner\": {\n            \"@id\": \"ai:owner\",\n            \"@type\": \"@id\"\n        },\n\n        \"operator\": {\n            \"@id\": \"ai:operator\",\n            \"@type\": \"@id\"\n        },\n\n        \"decision-makingProcess\": \"ai:decision-makingProcess\",\n        \"performedAction\": {\n            \"@id\": \"ai:performedAction\",\n            \"@type\": \"@id\"\n        },\n\n        \"outcome\": \"ai:outcome\",\n        \"date\": \"ai:date\",\n        \"responsibility\": {\n            \"@id\": \"ai:responsibility\",\n            \"@type\": \"@id\"\n        },\n\n        \"level\": \"ai:level\",\n        \"entity\": {\n            \"@id\": \"ai:entity\",\n            \"@type\": \"@id\"\n        },\n\n        \"jurisdiction\": \"ai:jurisdiction\",\n        \"location\": \"ai:location\",\n        \"standardsMet\": \"ai:standardsMet\",\n        \"certifications\": \"ai:certifications\",\n        \"transparencyReports\": {\n            \"@id\": \"ai:transparencyReports\",\n            \"@type\": \"@id\"\n        }\n    },\n\n    \"@id\": \"ai:MyAI\",\n    \"@type\": \"ai:AI\",\n    \"name\": \"My AI System\",\n    \"developer\": {\n        \"@id\": \"foaf:JohnDoe\",\n        \"@type\": \"foaf:Person\",\n        \"name\": \"John Doe\"\n    },\n\n    \"owner\": {\n        \"@id\": \"org:AcmeInc\",\n        \"@type\": \"org:Organization\",\n        \"name\": \"Acme Inc.\"\n    },\n\n    \"operator\": {\n        \"@id\": \"foaf:JaneSmith\",\n        \"@type\": \"foaf:Person\",\n        \"name\": \"Jane Smith\"\n    },\n\n    \"decision-makingProcess\": \"Explainable AI using Decision Trees\",\n    \"performedAction\": {\n        \"@id\": \"ai:Action1\",\n        \"@type\": \"ai:Action\",\n        \"name\": \"Decision Making\",\n        \"outcome\": \"Approve the loan\",\n        \"date\": \"2022-01-12T10:30:00Z\"\n    },\n\n    \"responsibility\": {\n        \"@id\": \"ai:responsibility1\",\n        \"@type\": \"ai:Responsibility\",\n        \"level\": \"Primary\",\n        \"entity\": {\n            \"@id\": \"org:AcmeInc\",\n            \"@type\": \"org:Organization\",\n            \"name\": \"Acme Inc.\"\n        }\n    },\n\n    \"jurisdiction\": \"US\",\n    \"location\": \"New York\",\n    \"standardsMet\": \"ISO/IEC 27001:2013\",\n    \"certifications\": \"ISO/IEC 27001:2013 certified\",\n    \"transparencyReports\": \"http://example.com/reports/myaisystem\"\n}\n```\n\nIn this example, the ontology defines several classes, such as \"AI\" (ai:AI), \"Action\" (ai:Action), \"Responsibility\" (ai:Responsibility), \"Person\" (foaf:Person), and \"Organization\" (org:Organization), it also specifies that \"MyAI\" has a name, developer, owner, operator, decision-making process, performed actions, outcome, date, level of responsibility, and jurisdiction, location, standards met, certifications and transparency reports. \n\nThe context provided, maps the prefixes used in the ontology to the corresponding URIs, as well as provides data types and relationships between the different classes and properties. This is used to make the JSON-LD data more easily readable for both machines and humans. As before, it's important to note that this is just an example and that the ontology can be much more detailed, depending on the complexity and dynamic nature of the field of AI.\n\n### CONSIDERATIONS\n\nWhilst the specific approach certainly requires a great deal more work and consideration, the merit of the underlying notion appears to be considered important even by ChatGPT.  \n\nI hope this explains enough of this underlying consideration as is sought to be sufficiently illustrated, as to be added to the ToDo list for informatics policies relating to the development of webizen systems.\n\n","excerpt":"Agent Labelling It is important that there is a clear means to distinguish between the content, information or processes and decisions that…","outboundReferences":[],"inboundReferences":[]},"tagsOutbound":{"nodes":[]}},"pageContext":{"tags":[],"slug":"/SocialFactors/WebScience/SafetyProtocols/AgentLabelling/","sidebarItems":[{"title":"Categories","items":[{"title":"Documentation Method","url":"/DocumentationMethod/","items":[]},{"title":"Old-Work-Archives","url":"/old-work-archives/","items":[{"title":"2005 Lots of Ideas - some Big & some Small","url":"/old-work-archives/2005 Lots of ideas - some big & some small/","items":[]},{"title":"2018-Webizen-Net-Au","url":"/old-work-archives/2018-webizen-net-au/","items":[{"title":"_Link_library_links","url":"","items":[{"title":"Link Library","url":"/old-work-archives/2018-webizen-net-au/_link_library_links/2018-09-23-wp-linked-data/","items":[]}]},{"title":"about","url":"/old-work-archives/2018-webizen-net-au/about/","items":[{"title":"About The Author","url":"/old-work-archives/2018-webizen-net-au/about/about-the-author/","items":[]},{"title":"Applied Theory: Applications for a Human Centric Web","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/","items":[{"title":"Digital Receipts","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/digital-receipts/","items":[]},{"title":"Fake News: Considerations → Principles → The Institution of Socio & Economic Values","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations/","items":[]},{"title":"Healthy Living Economy","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/healthy-living-economy/","items":[]},{"title":"HyperMedia Solutions Adapting HbbTV V2","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/","items":[{"title":"HYPERMEDIA PACKAGES","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/hypermedia-packages/","items":[]},{"title":"USER STORIES: INTERACTIVE VIEWING EXPERIENCE","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/user-stories-interactive-viewing-experience/","items":[]}]},{"title":"Measurements App","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/measurements-app/","items":[]},{"title":"Re:Animation","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/reanimation/","items":[]},{"title":"Solutions to FakeNews: Linked-Data, Ontologies and Verifiable Claims","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/ld-solutions-to-fakenews/","items":[]}]},{"title":"Executive Summary","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/","items":[{"title":"Assisting those who Enforce the Law","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/assisting-those-who-enforce-the-law/","items":[]},{"title":"Consumer Protections","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/consumer-protections/","items":[]},{"title":"Knowledge Banking: Legal Structures","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-banking-legal-structures/","items":[]},{"title":"Knowledge Economics &#8211; Services","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-economics-services/","items":[]},{"title":"Preserving The Freedom to Think","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/preserving-the-freedom-to-think/","items":[]}]},{"title":"History","url":"","items":[{"title":"History: Global Governance and ICT.","url":"/old-work-archives/2018-webizen-net-au/about/history/history-global-governance-ict-1/","items":[]}]},{"title":"Knowledge Banking: A Technical Architecture Summary","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/","items":[{"title":"An introduction to Credentials.","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/","items":[{"title":"credentials and custodianship","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/credentials-and-custodianship/","items":[]},{"title":"DIDs and MultiSig","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/dids-and-multisig/","items":[]}]},{"title":"Personal Augmentation of AI","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/personal-augmentation-of-ai/","items":[]},{"title":"Semantic Inferencing","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/semantic-inferencing/","items":[]},{"title":"Web of Things (IoT+LD)","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/web-of-things-iotld/","items":[]}]},{"title":"References","url":"/old-work-archives/2018-webizen-net-au/about/references/","items":[{"title":"Making the distinction between ‘privacy’ and ‘dignity’.","url":"/old-work-archives/2018-webizen-net-au/about/references/privacy-vs-dignity/","items":[]},{"title":"Roles & Entity Analysis","url":"/old-work-archives/2018-webizen-net-au/about/references/roles-entity-analysis/","items":[]},{"title":"Social Informatics Design Considerations","url":"/old-work-archives/2018-webizen-net-au/about/references/social-informatics-design-concept-and-principles/","items":[]},{"title":"Socio-economic relations | A conceptual model","url":"/old-work-archives/2018-webizen-net-au/about/references/socioeconomic-relations-p1/","items":[]},{"title":"The need for decentralised Open (Linked) Data","url":"/old-work-archives/2018-webizen-net-au/about/references/the-need-for-decentralised-open-linked-data/","items":[]}]},{"title":"The design of new medium","url":"/old-work-archives/2018-webizen-net-au/about/the-design-of-new-medium/","items":[]},{"title":"The need to modernise socioeconomic infrastructure","url":"/old-work-archives/2018-webizen-net-au/about/the-modernisation-of-socioeconomics/","items":[]},{"title":"The Vision","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/","items":[{"title":"Domesticating Pervasive Surveillance","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/a-technical-vision/","items":[]}]}]},{"title":"Posts","url":"","items":[{"title":"About W3C","url":"/old-work-archives/2018-webizen-net-au/posts/About W3C/","items":[]},{"title":"Advanced Functions & Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/posts/Advanced Functions & Facebook Pages/","items":[]},{"title":"Advanced Search & Discovery Tips","url":"/old-work-archives/2018-webizen-net-au/posts/Advanced Search & Discovery Tips/","items":[]},{"title":"An Introduction to Virtual Machines","url":"/old-work-archives/2018-webizen-net-au/posts/An introduction to Virtual Machines/","items":[]},{"title":"Basic Media Analysis & Part 1 (Audio)","url":"/old-work-archives/2018-webizen-net-au/posts/Basic Media Analysis & Part 1 (Audio)/","items":[]},{"title":"Basic Media Analysis & Part 2 (Visual)","url":"/old-work-archives/2018-webizen-net-au/posts/Basic Media Analysis & Part 2 (visual)/","items":[]},{"title":"Basic Media Analysis & Part 3 (Text & Metadata)","url":"/old-work-archives/2018-webizen-net-au/posts/Basic Media Analysis & Part 3 (Text & Metadata)/","items":[]},{"title":"Building an Economy Based upon Knowledge Equity","url":"/old-work-archives/2018-webizen-net-au/posts/Building an Economy based upon Knowledge Equity/","items":[]},{"title":"Choice of Law","url":"/old-work-archives/2018-webizen-net-au/posts/Choice of Law/","items":[]},{"title":"Contemplation of the ITU Dubai Meeting and the Future of the Internet","url":"/old-work-archives/2018-webizen-net-au/posts/Contemplation of the ITU Dubai Meeting and the Future of the Internet/","items":[]},{"title":"Creating a Presence & Online","url":"/old-work-archives/2018-webizen-net-au/posts/Creating a Presence & Online/","items":[]},{"title":"Credentials and Payments by Manu Sporny","url":"/old-work-archives/2018-webizen-net-au/posts/Credentials and Payments by Manu Sporny/","items":[]},{"title":"Data Recovery - Laptop & Computers","url":"/old-work-archives/2018-webizen-net-au/posts/Data Recovery - Laptop & Computers/","items":[]},{"title":"Data Recovery & Collection Mobile Devices","url":"/old-work-archives/2018-webizen-net-au/posts/Data Recovery & Collection Mobile Devices/","items":[]},{"title":"Decentralized Web Conference 2016","url":"/old-work-archives/2018-webizen-net-au/posts/Decentralized Web Conference 2016/","items":[]},{"title":"Decentralized Web Summit 2018","url":"/old-work-archives/2018-webizen-net-au/posts/Decentralized Web Summit 2018/","items":[]},{"title":"Does Anonymity Exist","url":"/old-work-archives/2018-webizen-net-au/posts/Does Anonymity exist/","items":[]},{"title":"Downloading My Data From Social Networks","url":"/old-work-archives/2018-webizen-net-au/posts/Downloading My Data from Social Networks/","items":[]},{"title":"Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/posts/Facebook Pages/","items":[]},{"title":"Google Tracking Data (Geolocation)","url":"/old-work-archives/2018-webizen-net-au/posts/Google Tracking Data (geolocation)/","items":[]},{"title":"Human Consciousness","url":"/old-work-archives/2018-webizen-net-au/posts/Human Consciousness/","items":[]},{"title":"Image Recgonition Video Playlist","url":"/old-work-archives/2018-webizen-net-au/posts/Image Recgonition Video Playlist/","items":[]},{"title":"Inferencing (Introduction)","url":"/old-work-archives/2018-webizen-net-au/posts/Inferencing (introduction)/","items":[]},{"title":"Introduction to AI","url":"/old-work-archives/2018-webizen-net-au/posts/Introduction to AI/","items":[]},{"title":"Introduction to Maltego","url":"/old-work-archives/2018-webizen-net-au/posts/Introduction to Maltego/","items":[]},{"title":"Introduction to Ontologies","url":"/old-work-archives/2018-webizen-net-au/posts/Introduction to Ontologies/","items":[]},{"title":"Introduction to Semantic Web","url":"/old-work-archives/2018-webizen-net-au/posts/Introduction to Semantic Web/","items":[]},{"title":"Knowledge-Capital","url":"/old-work-archives/2018-webizen-net-au/posts/knowledge-capital/","items":[]},{"title":"Logos-Style-Guides-and-Artwork","url":"/old-work-archives/2018-webizen-net-au/posts/logos-style-guides-and-artwork/","items":[]},{"title":"MindMapping & Setting-up a Business & Identity","url":"/old-work-archives/2018-webizen-net-au/posts/MindMapping & Setting-up a business & Identity/","items":[]},{"title":"Openlink Virtuoso","url":"/old-work-archives/2018-webizen-net-au/posts/Openlink Virtuoso/","items":[]},{"title":"OpenRefine","url":"/old-work-archives/2018-webizen-net-au/posts/OpenRefine/","items":[]},{"title":"Projects-Customers-and-Invoicing-Web-Services-for-Startups","url":"/old-work-archives/2018-webizen-net-au/posts/projects-customers-and-invoicing-web-services-for-startups/","items":[]},{"title":"RWW & some Solid History","url":"/old-work-archives/2018-webizen-net-au/posts/RWW & some Solid history/","items":[]},{"title":"Semantic Web (An Intro)","url":"/old-work-archives/2018-webizen-net-au/posts/Semantic Web (An Intro)/","items":[]},{"title":"Setting-up Twitter","url":"/old-work-archives/2018-webizen-net-au/posts/Setting-up Twitter/","items":[]},{"title":"Social Encryption An Introduction","url":"/old-work-archives/2018-webizen-net-au/posts/Social Encryption An Introduction/","items":[]},{"title":"Stock Content","url":"/old-work-archives/2018-webizen-net-au/posts/Stock Content/","items":[]},{"title":"The WayBack Machine","url":"/old-work-archives/2018-webizen-net-au/posts/The WayBack Machine/","items":[]},{"title":"Tim Berners Lee & Turing Lecture","url":"/old-work-archives/2018-webizen-net-au/posts/Tim Berners Lee & Turing Lecture/","items":[]},{"title":"Tools-of-Trade","url":"/old-work-archives/2018-webizen-net-au/posts/tools-of-trade/","items":[]},{"title":"Trust Factory 2017","url":"/old-work-archives/2018-webizen-net-au/posts/Trust Factory 2017/","items":[]},{"title":"Verifiable Claims (An Introduction)","url":"/old-work-archives/2018-webizen-net-au/posts/Verifiable Claims (An Introduction)/","items":[]},{"title":"Web of Things & an Introduction","url":"/old-work-archives/2018-webizen-net-au/posts/Web of Things & an Introduction/","items":[]},{"title":"Web-Persistence","url":"/old-work-archives/2018-webizen-net-au/posts/Web-Persistence/","items":[]},{"title":"Web-Services & Marketing Tools","url":"/old-work-archives/2018-webizen-net-au/posts/Web-Services & Marketing Tools/","items":[]},{"title":"Website Templates","url":"/old-work-archives/2018-webizen-net-au/posts/Website Templates/","items":[]},{"title":"What is <span class=\"textannotation disambiguated wl-thing\" id=\"urn:local-text-annotation-16v2koc9fcuj5lwn7helj9zpo9t4iqv4\" itemid=\"http://data.wordlift.io/wl0293/entity/linked_data\">Linked Data</span>?","url":"/old-work-archives/2018-webizen-net-au/posts/Introduction to Linked Data/","items":[]},{"title":"What Is Linked Data","url":"/old-work-archives/2018-webizen-net-au/posts/What is Linked Data/","items":[]},{"title":"What Is Open Source Intelligence","url":"/old-work-archives/2018-webizen-net-au/posts/What is Open Source Intelligence/","items":[]}]},{"title":"Resource Library","url":"/old-work-archives/2018-webizen-net-au/resource-library/","items":[]}]},{"title":"WebCivics BizPlan 2018","url":"/old-work-archives/WebCivics BizPlan 2018/","items":[]},{"title":"WebCivics Medium Posts","url":"/old-work-archives/WebCivics Medium Posts/","items":[{"title":"2019","url":"","items":[{"title":"An Open Letter - What Is Your Digital Identity Mandate for Humanity","url":"/old-work-archives/WebCivics Medium Posts/2019/An Open Letter - What is your Digital Identity Mandate for Humanity/","items":[]},{"title":"Building a NewStart for the Australian Creative Sector.","url":"/old-work-archives/WebCivics Medium Posts/2019/Building a NewStart for the Australian Creative Sector./","items":[]},{"title":"Building a Safe Environment for Kids to Thrive with Their ‘Digital Twin’","url":"/old-work-archives/WebCivics Medium Posts/2019/Building a safe environment for Kids to thrive with their ‘Digital Twin’/","items":[]},{"title":"Causal Relationships Between Social Informatics Design and Quantum Mechanical Phenomenon.","url":"/old-work-archives/WebCivics Medium Posts/2019/Causal Relationships between Social informatics design and Quantum Mechanical Phenomenon./","items":[]},{"title":"Comms & Security Privacy vs. Dignity","url":"/old-work-archives/WebCivics Medium Posts/2019/Comms & Security Privacy vs. Dignity/","items":[]},{"title":"Cyber Security Infrastructure, AI & Semantics","url":"/old-work-archives/WebCivics Medium Posts/2019/Cyber Security Infrastructure, AI & Semantics/","items":[]},{"title":"Dependents The Emergence of Cyber Nation. Estates of ‘Virtual IDentity’","url":"/old-work-archives/WebCivics Medium Posts/2019/Dependents The Emergence of Cyber Nation. Estates of ‘Virtual IDentity’/","items":[]},{"title":"Engineering Einstein","url":"/old-work-archives/WebCivics Medium Posts/2019/Engineering Einstein/","items":[]},{"title":"Health Informatics History, Challenges & Opportunities","url":"/old-work-archives/WebCivics Medium Posts/2019/Health Informatics History, Challenges & Opportunities/","items":[]},{"title":"History Community, Civics & GLAM. Means to Bootstrap Digital Economy Growth & Knowledge Banking Tools.","url":"/old-work-archives/WebCivics Medium Posts/2019/History Community, Civics & GLAM. Means to Bootstrap Digital Economy Growth & Knowledge Banking Tools./","items":[]},{"title":"History of Banking, Knowledge Economy and Moral Poverty","url":"/old-work-archives/WebCivics Medium Posts/2019/History of Banking, Knowledge Economy and Moral Poverty/","items":[]},{"title":"HyperMedia Exhibition & Events Spaces","url":"/old-work-archives/WebCivics Medium Posts/2019/HyperMedia Exhibition & Events Spaces/","items":[]},{"title":"Inforgs & The Collective Infosphere","url":"/old-work-archives/WebCivics Medium Posts/2019/Inforgs & The Collective Infosphere/","items":[]},{"title":"Knowledge Age - A Conceptual Evolution of the Cyber-Physical From Our Present Information Age","url":"/old-work-archives/WebCivics Medium Posts/2019/Knowledge Age - A conceptual evolution of the Cyber-Physical from our Present Information Age/","items":[]},{"title":"Knowledge Banking Infrastructure","url":"/old-work-archives/WebCivics Medium Posts/2019/Knowledge Banking Infrastructure/","items":[]},{"title":"Knowledge Banking Infrastructure - Cyber Socio-Economic Foundations for Our Shared World","url":"/old-work-archives/WebCivics Medium Posts/2019/Knowledge Banking Infrastructure - Cyber Socio-Economic Foundations for our shared world/","items":[]},{"title":"Knowledge Clouds","url":"/old-work-archives/WebCivics Medium Posts/2019/Knowledge Clouds/","items":[]},{"title":"Media Analytics & Hyper-Media Services","url":"/old-work-archives/WebCivics Medium Posts/2019/Media Analytics & Hyper-Media Services/","items":[]},{"title":"Micropayments Standards - An Economic Imperative for the Knowledge Age","url":"/old-work-archives/WebCivics Medium Posts/2019/Micropayments Standards - An Economic Imperative for the Knowledge Age/","items":[]},{"title":"Open Data v3.0 Permissive Commons","url":"/old-work-archives/WebCivics Medium Posts/2019/Open Data v3.0 Permissive Commons/","items":[]},{"title":"Skills & Social Activities","url":"/old-work-archives/WebCivics Medium Posts/2019/Skills & Social Activities/","items":[]},{"title":"Small to Medium Business, WebPayments & Knowledge Banking","url":"/old-work-archives/WebCivics Medium Posts/2019/Small to Medium Business, WebPayments & Knowledge Banking/","items":[]},{"title":"Tech for Permissive Commons","url":"/old-work-archives/WebCivics Medium Posts/2019/Tech for Permissive Commons/","items":[]},{"title":"The Case for a ‘Human Centric’ Global Cyber Infrastructure Project","url":"/old-work-archives/WebCivics Medium Posts/2019/The Case for a ‘Human Centric’ Global Cyber Infrastructure Project/","items":[]},{"title":"The Semantic Inforg & The “Human Centric Web” — Reality Check, Tech.","url":"/old-work-archives/WebCivics Medium Posts/2019/The Semantic Inforg & The “Human Centric Web” — Reality Check, Tech./","items":[]},{"title":"Tooling for Democracies","url":"/old-work-archives/WebCivics Medium Posts/2019/Tooling for Democracies/","items":[]},{"title":"Universitas Doctrina Et Sapientiae","url":"/old-work-archives/WebCivics Medium Posts/2019/Universitas Doctrina et Sapientiae/","items":[]},{"title":"Why a Trust Factory (“Think Tank”)","url":"/old-work-archives/WebCivics Medium Posts/2019/Why a Trust Factory (“think tank”)/","items":[]},{"title":"WoT Smart Cities Engineering Digital Twin Things & Ecosystems.","url":"/old-work-archives/WebCivics Medium Posts/2019/WoT Smart Cities Engineering Digital Twin Things & Ecosystems./","items":[]}]},{"title":"During-Covid","url":"","items":[{"title":"A Future For Australians","url":"/old-work-archives/WebCivics Medium Posts/during-covid/A Future For Australians/","items":[]},{"title":"A Future to Support Informed Decisions S.T.E.A.M & Stars","url":"/old-work-archives/WebCivics Medium Posts/during-covid/A Future to Support Informed Decisions S.T.E.A.M & Stars/","items":[]},{"title":"A Major Manifestation Problem","url":"/old-work-archives/WebCivics Medium Posts/during-covid/A Major Manifestation Problem/","items":[]},{"title":"Choices About the Future of Knowledge Governance & Alternatives Solutions to What Appears to Be How VaccinePassports Are Now Being Made","url":"/old-work-archives/WebCivics Medium Posts/during-covid/Choices about the future of Knowledge Governance & alternatives Solutions to what appears to be how VaccinePassports are now being made/","items":[]},{"title":"Digital Covid19 “Vaccine Passport”","url":"/old-work-archives/WebCivics Medium Posts/during-covid/Digital Covid19 “Vaccine Passport”/","items":[]},{"title":"Do We Need a Space Time Navigator","url":"/old-work-archives/WebCivics Medium Posts/during-covid/Do We Need a Space Time Navigator/","items":[]},{"title":"Is an International Cyber Migration Even Possible","url":"/old-work-archives/WebCivics Medium Posts/during-covid/Is an International Cyber Migration Even Possible/","items":[]}]}]},{"title":"Webizen Group 2015","url":"/old-work-archives/Webizen Group 2015/","items":[]}]},{"title":"Social Factors","url":"/SocialFactors/","items":[{"title":"Background","url":"/SocialFactors/Background/","items":[]},{"title":"Commercial Models","url":"/SocialFactors/CommercialModels/","items":[{"title":"Best Efforts","url":"/SocialFactors/CommercialModels/BestEfforts/","items":[]},{"title":"Currencies","url":"/SocialFactors/CommercialModels/Currencies/","items":[{"title":"Financial Payment Types","url":"/SocialFactors/CommercialModels/Currencies/FinancialPaymentTypes/","items":[]},{"title":"Gifts and Donations","url":"/SocialFactors/CommercialModels/Currencies/GiftsAndDonations/","items":[]},{"title":"Micro Payments","url":"/SocialFactors/CommercialModels/Currencies/Micropayments/","items":[]},{"title":"Non-Financial Currencies","url":"/SocialFactors/CommercialModels/Currencies/Non-FinancialCurrencies/","items":[]}]},{"title":"Economic Systems","url":"/SocialFactors/CommercialModels/EconomicSystems/","items":[]},{"title":"Environmental, Social and Governance (ESG)","url":"/SocialFactors/CommercialModels/ESG/","items":[{"title":"Biosphere Calcs","url":"/SocialFactors/CommercialModels/ESG/BiosphereCalcs/","items":[]},{"title":"Energy Calcs","url":"/SocialFactors/CommercialModels/ESG/EnergyCalcs/","items":[]},{"title":"Sociosphere Calcs","url":"/SocialFactors/CommercialModels/ESG/SocioshereCalcs/","items":[]}]},{"title":"Fit For Purpose","url":"/SocialFactors/CommercialModels/FitForPurpose/","items":[]},{"title":"Hardware Strategy","url":"/SocialFactors/CommercialModels/HardwareStrategy/","items":[]},{"title":"Historical Information","url":"/SocialFactors/CommercialModels/Historical Information/","items":[{"title":"Domains","url":"/SocialFactors/CommercialModels/Historical Information/Domains/","items":[]},{"title":"Value Accounting Initiatives","url":"/SocialFactors/CommercialModels/Historical Information/ValueAccountingInitiatives/","items":[]},{"title":"Web Civics","url":"/SocialFactors/CommercialModels/Historical Information/WebCivics/","items":[]}]},{"title":"The Work Project","url":"/SocialFactors/CommercialModels/WorkProject/","items":[{"title":"Contribution Classifications","url":"/SocialFactors/CommercialModels/WorkProject/ContributionClassifications/","items":[]},{"title":"Equipment and Supplies","url":"/SocialFactors/CommercialModels/WorkProject/EquipmentAndSupplies/","items":[]},{"title":"Intellectual Property","url":"/SocialFactors/CommercialModels/WorkProject/IntellectualProperty/","items":[]},{"title":"Knowledge Work","url":"/SocialFactors/CommercialModels/WorkProject/KnowledgeWork/","items":[]},{"title":"Labour Work","url":"/SocialFactors/CommercialModels/WorkProject/LabourWork/","items":[]},{"title":"Licensing Frameworks","url":"/SocialFactors/CommercialModels/WorkProject/LicensingFrameworks/","items":[]},{"title":"Project Financing","url":"/SocialFactors/CommercialModels/WorkProject/ProjectFinancing/","items":[]},{"title":"Resources","url":"/SocialFactors/CommercialModels/WorkProject/Resources/","items":[]},{"title":"Work Valuation Methods","url":"/SocialFactors/CommercialModels/WorkProject/WorkValuationMethods/","items":[]}]},{"title":"Trust Factory","url":"/SocialFactors/CommercialModels/TrustFactory/","items":[]},{"title":"Webizen","url":"/SocialFactors/CommercialModels/Webizen/","items":[]},{"title":"Webizen Alliance","url":"/SocialFactors/CommercialModels/WebizenAlliance/","items":[{"title":"Community of Practice","url":"/SocialFactors/CommercialModels/WebizenAlliance/CommunityOfPractice/","items":[]},{"title":"Early Stage Income Strategies","url":"/SocialFactors/CommercialModels/WebizenAlliance/EarlyStageIncomeStrategies/","items":[]},{"title":"The Webizen Charter","url":"/SocialFactors/CommercialModels/WebizenAlliance/TheWebizenCharter/","items":[]}]},{"title":"Webizen Pro VAR Solutions","url":"/SocialFactors/CommercialModels/WebizenProVARSolutions/","items":[]},{"title":"WebizenPro Usecases","url":"/SocialFactors/CommercialModels/WebizenProUsecases/","items":[{"title":"Webizen Pro Ecosystem Usecases","url":"/SocialFactors/CommercialModels/WebizenProUsecases/WebizenProEcosystemUsecases/","items":[]},{"title":"Webizen Pro Edge UseCases","url":"/SocialFactors/CommercialModels/WebizenProUsecases/WebizenProEdgeUseCases/","items":[]},{"title":"Webizen Pro Use-Cases","url":"/SocialFactors/CommercialModels/WebizenProUsecases/WebizenProUse-Cases/","items":[]}]}]},{"title":"Commercial-Technical Requirements","url":"/SocialFactors/SocioEconomicTechReqs/","items":[{"title":"Account Creation","url":"/SocialFactors/SocioEconomicTechReqs/AccountCreation/","items":[]},{"title":"Guardianship Relations","url":"/SocialFactors/SocioEconomicTechReqs/GuardianshipRelations/","items":[]},{"title":"Guardianship Semantics","url":"/SocialFactors/SocioEconomicTechReqs/GuardianshipSemantics/","items":[]},{"title":"Support for Human Agency","url":"/SocialFactors/SocioEconomicTechReqs/SupportForHumanAgency/","items":[]}]},{"title":"Peace Infrastructure Project","url":"/SocialFactors/PeaceInfrastructureProject/","items":[{"title":"About the Peace Infrastructure Project","url":"/SocialFactors/PeaceInfrastructureProject/AboutThePeaceInfrastructureProject/","items":[]}]},{"title":"Social Attack Vectors","url":"/SocialFactors/SocialAttackVectors/","items":[{"title":"CommercialExploitation","url":"/SocialFactors/SocialAttackVectors/CommercialExploitation/","items":[]},{"title":"Criminal Activity","url":"/SocialFactors/SocialAttackVectors/CriminalActivity/","items":[{"title":"Corporate Crime","url":"/SocialFactors/SocialAttackVectors/CriminalActivity/CorporateCrime/","items":[]},{"title":"Digital Slavery","url":"/SocialFactors/SocialAttackVectors/CriminalActivity/DigitalSlavery/","items":[]},{"title":"Environmental Crime","url":"/SocialFactors/SocialAttackVectors/CriminalActivity/EnvironmentalCrime/","items":[]},{"title":"Financial Crimes","url":"/SocialFactors/SocialAttackVectors/CriminalActivity/FinancialCrimes/","items":[]},{"title":"Fraud","url":"/SocialFactors/SocialAttackVectors/CriminalActivity/Fraud/","items":[]},{"title":"Proxy Attacks","url":"/SocialFactors/SocialAttackVectors/CriminalActivity/ProxyAttacks/","items":[]}]},{"title":"Cyber Attack Vectors","url":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/","items":[{"title":"Attacks Online","url":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/AttacksOnline/","items":[]},{"title":"Cyber Crime","url":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/CyberCrime/","items":[]},{"title":"NobodyAI","url":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/NobodyAI/","items":[]},{"title":"Tech Debt","url":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/TechDebt/","items":[]}]},{"title":"Dehumanisation","url":"/SocialFactors/SocialAttackVectors/Dehumanisation/","items":[]},{"title":"Dishonesty","url":"/SocialFactors/SocialAttackVectors/Dishonesty/","items":[]},{"title":"Fake News","url":"/SocialFactors/SocialAttackVectors/FakeNews/","items":[]},{"title":"Public Sector Wrong Doings","url":"/SocialFactors/SocialAttackVectors/PublicSectorWrongDoings/","items":[]},{"title":"TemporalAttacks","url":"/SocialFactors/SocialAttackVectors/TemporalAttacks/","items":[]},{"title":"Torts","url":"/SocialFactors/SocialAttackVectors/Torts/","items":[{"title":"Economic Torts","url":"/SocialFactors/SocialAttackVectors/Torts/EconomicTorts/","items":[]},{"title":"Intentional Torts","url":"/SocialFactors/SocialAttackVectors/Torts/IntentionalTorts/","items":[]},{"title":"Negligence","url":"/SocialFactors/SocialAttackVectors/Torts/Negligence/","items":[]},{"title":"Nuisance","url":"/SocialFactors/SocialAttackVectors/Torts/Nuisance/","items":[]}]}]},{"title":"Web Science","url":"/SocialFactors/WebScience/","items":[{"title":"Artificial Minds","url":"/SocialFactors/WebScience/ArtificialMinds/","items":[{"title":"A ChatGPT Experiment: Holborn","url":"/SocialFactors/WebScience/ArtificialMinds/AChatGPTExperimentHolborn/","items":[]},{"title":"Cognative AI","url":"/SocialFactors/WebScience/ArtificialMinds/CognativeAI/","items":[]},{"title":"The Artificial Minds List","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/","items":[{"title":"Baymax","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Baymax/","items":[]},{"title":"Bishop - Aliens","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Bishop - Aliens/","items":[]},{"title":"Borg - Star Trek","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Borg - Star Trek/","items":[]},{"title":"ChatGPT","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/ChatGPT/","items":[]},{"title":"Edwin Jarvis","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Edwin Jarvis/","items":[]},{"title":"IBM Watson","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/IBM Watson/","items":[]},{"title":"Max - Flight of the Navigator","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Max - Flight of the Navigator/","items":[]},{"title":"Rosie - The Jetsons","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Rosie - The Jetsons/","items":[]},{"title":"Sarah - Eureka","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Sarah - Eureka/","items":[]},{"title":"SkyNet","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/SkyNet/","items":[]},{"title":"The Doctor - Star Trek Voyager","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/The Doctor - Star Trek Voyager/","items":[]}]}]},{"title":"Centricity","url":"/SocialFactors/WebScience/Centricity/","items":[]},{"title":"Human-Centric AI Ethics","url":"/SocialFactors/WebScience/HumanCentricAIEthics/","items":[]},{"title":"Learning Modals","url":"/SocialFactors/WebScience/LearningModals/","items":[]},{"title":"Permissive Commons","url":"/SocialFactors/WebScience/PermissiveCommons/","items":[{"title":"Biosphere Ontologies","url":"/SocialFactors/WebScience/PermissiveCommons/BiosphereOntologies/","items":[]},{"title":"SocioSphere Ontologies","url":"/SocialFactors/WebScience/PermissiveCommons/SocioSphereOntologies/","items":[]},{"title":"Sustainable Development Goals (ESG)","url":"/SocialFactors/WebScience/PermissiveCommons/SDGs/","items":[]}]},{"title":"Safety Protocols","url":"/SocialFactors/WebScience/SafetyProtocols/","items":[{"title":"Agent Labelling","url":"/SocialFactors/WebScience/SafetyProtocols/AgentLabelling/","items":[]},{"title":"Data Portability","url":"/SocialFactors/WebScience/SafetyProtocols/DataPortability/","items":[]},{"title":"Ending Digital Slavery","url":"/SocialFactors/WebScience/SafetyProtocols/EndingDigitalSlavery/","items":[]},{"title":"Fair Work Protocols","url":"/SocialFactors/WebScience/SafetyProtocols/FairWorkProtocols/","items":[]},{"title":"Freedom of Thought","url":"/SocialFactors/WebScience/SafetyProtocols/FreedomOfThought/","items":[]},{"title":"Human Centric AI","url":"/SocialFactors/WebScience/SafetyProtocols/HumanCentricAI/","items":[]},{"title":"HumanCentric Digital Identity","url":"/SocialFactors/WebScience/SafetyProtocols/HumanCentricDigitalIdentity/","items":[]},{"title":"Knowledge Qualification Methods","url":"/SocialFactors/WebScience/SafetyProtocols/KnowledgeQualificationMethods/","items":[]},{"title":"No Lock-ins","url":"/SocialFactors/WebScience/SafetyProtocols/NoLock-ins/","items":[]},{"title":"Protecting Children","url":"/SocialFactors/WebScience/SafetyProtocols/ProtectingChildren/","items":[]},{"title":"Relationships (Social)","url":"/SocialFactors/WebScience/SafetyProtocols/Relationships(Social)/","items":[]},{"title":"Values Credentials","url":"/SocialFactors/WebScience/SafetyProtocols/Values Credentials/","items":[]}]},{"title":"Science of Consciousness","url":"/SocialFactors/WebScience/ScienceOfConsciousness/","items":[]},{"title":"The Values Project","url":"/SocialFactors/WebScience/TheValuesProject/","items":[]},{"title":"Understanding Ontologies","url":"/SocialFactors/WebScience/UnderstandingOntologies/","items":[]}]},{"title":"Webizen 3.0 Setup User Experience","url":"/SocialFactors/Webizen3.0SetupUserExperience/","items":[]},{"title":"Webizen: For Humans","url":"/SocialFactors/WebizenForHumans/","items":[]}]},{"title":"Webizen Docs Introduction","url":"/","items":[]},{"title":"Webizen Tech Stack","url":"/WebizenTechStack/","items":[{"title":"Authentication Fabric","url":"/WebizenTechStack/AuthenticationFabric/","items":[{"title":"Verifiable Credentials","url":"/WebizenTechStack/AuthenticationFabric/VerifiableCredentials/","items":[]},{"title":"WebAuthn","url":"/WebizenTechStack/AuthenticationFabric/WebAuthn/","items":[]},{"title":"WebID","url":"/WebizenTechStack/AuthenticationFabric/WebID/","items":[]}]},{"title":"Core Services","url":"/WebizenTechStack/CoreServices/","items":[{"title":"Decentralised Ontologies","url":"/WebizenTechStack/CoreServices/DecentralisedOntologies/","items":[]},{"title":"Non-HTTP(s) Protocols","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/","items":[{"title":"Chia","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/Chia/","items":[]},{"title":"DAT","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/DAT/","items":[]},{"title":"GIT","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/GIT/","items":[]},{"title":"GUNECO","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/GUNECO/","items":[]},{"title":"Hedera","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/Hedera/","items":[]},{"title":"IOTA","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/IOTA/","items":[]},{"title":"IPFS","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/IPFS/","items":[]},{"title":"Lightning Network","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/LightningNetwork/","items":[]},{"title":"NYM","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/NYM/","items":[]},{"title":"Obyte","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/obyte/","items":[]},{"title":"WebCash","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/WebCash/","items":[]},{"title":"WebRTC","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/WebRTC/","items":[]},{"title":"WebSockets","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/WebSockets/","items":[]},{"title":"WebTorrent","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/WebTorrent/","items":[]},{"title":"WireGuard","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/WireGuard/","items":[]},{"title":"XRP Ledger","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/XRPLedger/","items":[]}]},{"title":"Verifiable Claims & Credentials","url":"/WebizenTechStack/CoreServices/VerifiableClaims&Credentials/","items":[]}]},{"title":"Core Technologies","url":"/WebizenTechStack/CoreTechnologies/","items":[{"title":"GoLang Libraries","url":"/WebizenTechStack/CoreTechnologies/GoLangLibraries/","items":[]},{"title":"Open Badges","url":"/WebizenTechStack/CoreTechnologies/OpenBadges/","items":[]},{"title":"Permissive Commons Tech","url":"/WebizenTechStack/CoreTechnologies/PermissiveCommonsTech/","items":[{"title":"Ontology Modelling","url":"/WebizenTechStack/CoreTechnologies/PermissiveCommonsTech/OntologyModelling/","items":[]}]},{"title":"Semantic Web","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/","items":[{"title":"Ontologies","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/","items":[{"title":"FOAF","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/FOAF/","items":[]},{"title":"Human Rights Ontologies","url":"","items":[{"title":"UDHR","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/Human Rights Ontologies/UDHR/","items":[]}]},{"title":"MD-RDF Ontologies","url":"","items":[{"title":"DataTypesOntology (DTO) Core","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/MD-RDF Ontologies/DataTypes Ontology/","items":[]},{"title":"Friend of a Friend (FOAF) Core","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/MD-RDF Ontologies/FOAF/","items":[]}]},{"title":"OWL","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/OWL/","items":[]},{"title":"RDFS","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/RDFS/","items":[]},{"title":"Sitemap","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/Sitemap/","items":[]},{"title":"SKOS","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/SKOS/","items":[]},{"title":"SOIC","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/SOIC/","items":[]}]},{"title":"Semantic Web Authentication Tech","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWeb-AUTH/","items":[{"title":"WebID-OIDC","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWeb-AUTH/WebID-OIDC/","items":[]},{"title":"WebID-RSA","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWeb-AUTH/WebID-RSA/","items":[]},{"title":"WebID-TLS","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWeb-AUTH/WebID-TLS/","items":[]}]},{"title":"Sparql Family","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SparqlFamily/","items":[]},{"title":"W3C Specifications","url":"","items":[{"title":"Linked Data Fragments","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/Linked Data Fragments/","items":[]},{"title":"Linked Data Notifications","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/Linked Data Notifications/","items":[]},{"title":"Linked Data Platform","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/Linked Data Platform/","items":[]},{"title":"Linked Media Fragments","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/Linked Media Fragments/","items":[]},{"title":"RDF","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/RDF/","items":[]},{"title":"Web Access Control (WAC)","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/Web Access Control (WAC)/","items":[]},{"title":"Web Of Things","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/Web Of Things/","items":[]},{"title":"WebID Specifications","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/WebID Specifications/","items":[]}]}]},{"title":"Temporal Semantics","url":"/WebizenTechStack/CoreTechnologies/TemporalSemantics/","items":[]}]},{"title":"Engineering Considerations","url":"/WebizenTechStack/EngineeringConsiderations/","items":[{"title":"Containerisation","url":"/WebizenTechStack/EngineeringConsiderations/Containerisation/","items":[]},{"title":"Cryptography","url":"/WebizenTechStack/EngineeringConsiderations/Cryptography/","items":[]},{"title":"Database Requirements","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/","items":[{"title":"DatabaseAlternatives","url":"","items":[{"title":"Akutan","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseAlternatives/akutan/","items":[]},{"title":"Apache Kafka","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseAlternatives/ApacheKafka/","items":[]},{"title":"Bad Wolf","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseAlternatives/BadWolf/","items":[]},{"title":"CayleyGraph","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseAlternatives/CayleyGraph/","items":[]}]},{"title":"DatabaseMethods","url":"","items":[{"title":"BQL","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseMethods/BQL/","items":[]},{"title":"GraphQL","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseMethods/GraphQL/","items":[]},{"title":"Sparql","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseMethods/Sparql/","items":[]}]}]},{"title":"Prolog","url":"/WebizenTechStack/EngineeringConsiderations/Prolog/","items":[]},{"title":"TopLevelOntologyNLPResearch","url":"/WebizenTechStack/EngineeringConsiderations/TopLevelOntologyNLPResearch/","items":[]}]},{"title":"Internet","url":"/WebizenTechStack/Internet/","items":[{"title":"DNS Considerations","url":"/WebizenTechStack/Internet/DNSConsiderations/","items":[]},{"title":"List of Protocols ISO model","url":"/WebizenTechStack/Internet/ListOfProtocolsISOmodel/","items":[]}]},{"title":"Webizen 3.0","url":"/WebizenTechStack/Webizen3.0/","items":[{"title":"Client Software Requirements","url":"/WebizenTechStack/Webizen3.0/ClientSoftwareRequirements/","items":[]},{"title":"Host Software Requirements","url":"/WebizenTechStack/Webizen3.0/HostServiceRequirements/","items":[{"title":"Domain Hosting","url":"/WebizenTechStack/Webizen3.0/HostServiceRequirements/DomainHosting/","items":[]},{"title":"Media Processing","url":"/WebizenTechStack/Webizen3.0/HostServiceRequirements/MediaProcessing/","items":[{"title":"Ffmpeg","url":"/WebizenTechStack/Webizen3.0/HostServiceRequirements/MediaProcessing/ffmpeg/","items":[]},{"title":"Opencv","url":"/WebizenTechStack/Webizen3.0/HostServiceRequirements/MediaProcessing/opencv/","items":[]}]},{"title":"Networking Considerations","url":"/WebizenTechStack/Webizen3.0/HostServiceRequirements/NetworkingConsiderations/","items":[]}]},{"title":"HyperMedia Containers","url":"/WebizenTechStack/Webizen3.0/HyperMediaContainers/","items":[{"title":"Knowledge Documents","url":"/WebizenTechStack/Webizen3.0/HyperMediaContainers/KnowledgeDocuments/","items":[]},{"title":"webizen.n3","url":"/WebizenTechStack/Webizen3.0/HyperMediaContainers/webizen.n3/","items":[]}]},{"title":"Webizen 2.5 Dev in GoLang","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/","items":[{"title":"Chat GPT Supported Notes","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/ChatGPTSupported/","items":[{"title":"Dynamic Ontology","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/ChatGPTSupported/ChatGPTDynamicOntology/","items":[]},{"title":"Go WebID-OIDC & ChatGPT","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/ChatGPTSupported/GoLangWebIDOIDC/","items":[]}]},{"title":"DevNotesWebizen2.5","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/DevNotesWebizen2.5/","items":[]},{"title":"FunctionalObjectives","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/FunctionalObjectives/","items":[{"title":"FUNCTIONS","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/FunctionalObjectives/FUNCTIONS/","items":[]},{"title":"HelperAppObjectives","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/FunctionalObjectives/HelperAppObjectives/","items":[]},{"title":"PCT-NOTES","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/FunctionalObjectives/PCT-NOTES/","items":[]},{"title":"Webizen - Root Concepts","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/FunctionalObjectives/RootConcepts/","items":[]}]},{"title":"POC of Core Concepts","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/POCOfCoreConcepts/","items":[]},{"title":"POC: Ontology App Development","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/POCOntologyAppDev/","items":[]},{"title":"Sacrifices-Hard Problems","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/Sacrifices-hardproblems/","items":[]}]}]},{"title":"Webizen 3.5","url":"/WebizenTechStack/Webizen3.5/","items":[{"title":"AI Capabilities","url":"/WebizenTechStack/Webizen3.5/AICapabilities/","items":[{"title":"AI Capabilities Objectives","url":"/WebizenTechStack/Webizen3.5/AICapabilities/AICapabilitiesObjectives/","items":[]},{"title":"Audio & Video Analysis","url":"/WebizenTechStack/Webizen3.5/AICapabilities/Audio & Video Analysis/","items":[]},{"title":"Image Analysis","url":"/WebizenTechStack/Webizen3.5/AICapabilities/Image Analysis/","items":[]},{"title":"Text Analysis","url":"/WebizenTechStack/Webizen3.5/AICapabilities/Text Analysis/","items":[]}]},{"title":"Web Of Things (IoT)","url":"/WebizenTechStack/Webizen3.5/WebOfThings(IoT)/","items":[]},{"title":"Webizen AI OS Platform","url":"/WebizenTechStack/Webizen3.5/WebizenAiOS-Platform/","items":[]},{"title":"Webizen Pro Series","url":"/WebizenTechStack/Webizen3.5/WebizenProSeries/","items":[{"title":"Webizen Pro","url":"/WebizenTechStack/Webizen3.5/WebizenProSeries/WebizenPro/","items":[]},{"title":"Webizen Pro - Edge","url":"/WebizenTechStack/Webizen3.5/WebizenProSeries/WebizenPro-Edge/","items":[]},{"title":"WebizenProHardware","url":"/WebizenTechStack/Webizen3.5/WebizenProSeries/WebizenProHardware/","items":[]},{"title":"WebizenProSoftware","url":"/WebizenTechStack/Webizen3.5/WebizenProSeries/WebizenProSoftware/","items":[]}]},{"title":"Webizen Vision","url":"/WebizenTechStack/Webizen3.5/WebizenVision/","items":[]}]},{"title":"Webizen 4.0","url":"/WebizenTechStack/Webizen4.0/","items":[{"title":"MyWebizen","url":"/WebizenTechStack/Webizen4.0/MyWebizen/","items":[]}]},{"title":"Webizen Apps","url":"/WebizenTechStack/WebizenApps/","items":[{"title":"Historical RWW Apps","url":"/WebizenTechStack/WebizenApps/Historical RWW Apps/","items":[]},{"title":"Webizen 3.5 Apps","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/","items":[{"title":"Media Production","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/MediaProduction/","items":[]},{"title":"Mobile Apps","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/MobileApps/","items":[{"title":"Android","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/MobileApps/Android/","items":[]},{"title":"iOS","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/MobileApps/iOS/","items":[]},{"title":"The Webizen (mobile) Agent","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/MobileApps/TheWebizen(mobile)Agent/","items":[]}]},{"title":"Search","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/Search/","items":[]},{"title":"Webizen Host Apps","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/HostApps/","items":[{"title":"Email Services","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/HostApps/EmailServices/","items":[]},{"title":"Webizen Server - WebApps","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/HostApps/WebizenServer-WebApps/","items":[]},{"title":"Website Hosting","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/HostApps/WebsiteHost/","items":[]}]},{"title":"Webizen Manager","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/WebizenManager/","items":[]}]},{"title":"Webizen Interfaces","url":"/WebizenTechStack/WebizenApps/WebizenInterfaces/","items":[{"title":"TheWebizen","url":"/WebizenTechStack/WebizenApps/WebizenInterfaces/TheWebizen/","items":[]}]},{"title":"Webizen3.0Apps","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/","items":[{"title":"Design Goals","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/DesignGoals/","items":[]},{"title":"MobileBasics","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/MobileBasics/","items":[]},{"title":"WADE No-Code - Low-Code","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/NoCodeAppDev/","items":[]},{"title":"Webizen App Spec","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/WebizenAppSpec/","items":[{"title":"DOAP Form Example","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/WebizenAppSpec/DOAP form Example/","items":[]},{"title":"WebSpec","url":"","items":[{"title":"HTML SPECS","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/WebizenAppSpec/WebSpec/HTML SPECS/","items":[]},{"title":"Query Interfaces","url":"","items":[{"title":"GraphQL Query Specs","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/WebizenAppSpec/WebSpec/Query Interfaces/GraphQL Query Specs/","items":[]}]},{"title":"WebPlatformTools","url":"","items":[{"title":"WebAuthn","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/WebizenAppSpec/WebSpec/WebPlatformTools/WebAuthn/","items":[]},{"title":"WebDav","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/WebizenAppSpec/WebSpec/WebPlatformTools/WebDav/","items":[]}]}]}]},{"title":"Webizen Core Apps","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/","items":[{"title":"Agent Directory","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/AgentDirectory/","items":[]},{"title":"Cookie Monster","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/CookieMonster/","items":[]},{"title":"Credentials & Contracts Manager","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Credentials & Contracts Manager/","items":[]},{"title":"HyperMedia Library","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/HyperMediaLibrary/","items":[]},{"title":"Knowledge Clouds","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/KnowledgeClouds/","items":[]},{"title":"Library","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Library/","items":[]},{"title":"TemporalApps","url":"","items":[{"title":"Calendar","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/TemporalApps/Calendar/","items":[]},{"title":"Timeline Interface","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/TemporalApps/Timeline Interface/","items":[]}]},{"title":"The Work Platform","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/TheWorkPlatform/","items":[]},{"title":"Webizen Social","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/WebizenSocial/","items":[]}]},{"title":"Webizen-Connect","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/Webizen-Connect/","items":[{"title":"Data Applications","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/Webizen-Connect/Data Applications/","items":[]},{"title":"Social Media APIs","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/Webizen-Connect/Social Media APIs/","items":[]}]}]}]}]},{"title":"Work in Progress","url":"/WorkInProgress/","items":[]}]}],"tagsGroups":[],"latestPosts":[{"fields":{"slug":"/WorkInProgress/","title":"Work in Progress","lastUpdatedAt":"2023-01-18T05:35:20.000Z","lastUpdated":"1/18/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/SocialFactors/SocialAttackVectors/","title":"Social Attack Vectors","lastUpdatedAt":"2023-01-18T05:35:20.000Z","lastUpdated":"1/18/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/WebizenTechStack/Internet/","title":"Internet","lastUpdatedAt":"2023-01-18T05:35:20.000Z","lastUpdated":"1/18/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/SocialFactors/SocialAttackVectors/CommercialExploitation/","title":"CommercialExploitation","lastUpdatedAt":"2023-01-18T05:35:20.000Z","lastUpdated":"1/18/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/","title":"Cyber Attack Vectors","lastUpdatedAt":"2023-01-18T05:35:20.000Z","lastUpdated":"1/18/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/SocialFactors/SocialAttackVectors/Torts/","title":"Torts","lastUpdatedAt":"2023-01-18T05:35:20.000Z","lastUpdated":"1/18/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/SocialFactors/SocioEconomicTechReqs/AccountCreation/","title":"Account Creation","lastUpdatedAt":"2023-01-18T05:35:20.000Z","lastUpdated":"1/18/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/SocialFactors/SocioEconomicTechReqs/GuardianshipRelations/","title":"Guardianship Relations","lastUpdatedAt":"2023-01-18T05:35:20.000Z","lastUpdated":"1/18/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/WebizenTechStack/EngineeringConsiderations/TopLevelOntologyNLPResearch/","title":"TopLevelOntologyNLPResearch","lastUpdatedAt":"2023-01-18T05:35:20.000Z","lastUpdated":"1/18/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/WebizenTechStack/Internet/DNSConsiderations/","title":"DNS Considerations","lastUpdatedAt":"2023-01-18T05:35:20.000Z","lastUpdated":"1/18/2023"},"frontmatter":{"draft":false,"tags":[]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}