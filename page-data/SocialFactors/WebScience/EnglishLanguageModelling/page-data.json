{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/SocialFactors/WebScience/EnglishLanguageModelling/",
    "result": {"data":{"mdx":{"id":"e5220580-9795-535f-9c7d-dff2f9f24032","tableOfContents":{"items":[{"url":"#english-language-modelling","title":"English Language Modelling","items":[{"url":"#requirement","title":"Requirement"},{"url":"#forming-a-hypothesis","title":"Forming a Hypothesis"},{"url":"#technology-considerations","title":"Technology Considerations"}]}]},"fields":{"title":"English Language Modelling","slug":"/SocialFactors/WebScience/EnglishLanguageModelling/","url":"https://devdocs.webizen.org/SocialFactors/WebScience/EnglishLanguageModelling/","editUrl":"https://github.com/webizenai/devdocs/tree/main/SocialFactors/WebScience/EnglishLanguageModelling.md","lastUpdatedAt":"2023-01-18T16:25:14.000Z","lastUpdated":"1/18/2023","gitCreatedAt":"2023-01-18T10:51:50.000Z","shouldShowTitle":false},"frontmatter":{"title":"","description":null,"imageAlt":null,"tags":[],"date":null,"dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"english-language-modelling\"\n  }, \"English Language Modelling\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"This Document is a work in progress!\"))), mdx(\"p\", null, \"\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/WebScience/UnderstandingOntologies/\",\n    \"title\": \"UnderstandingOntologies\"\n  }, \"UnderstandingOntologies\"), \"\"), mdx(\"p\", null, \"I'm exploring an idea about forming some sort of semantic database method that would use language (english) to structure the ontological predicates. Part of the objective is to end up with a software model that can operate on a laptop (or mobile phone) privately.  \"), mdx(\"p\", null, \"The underlying consideration is that the ability to 'think' and write something that may or may not be communicated to anyone else (or any other agent) should not be subject to interference or survellience.  Any implication any use of the english language either written or as is able to be intepreted via sensors (ie: microphones) for natural language processing, should be private - until such a time as the derivatives of that work are shared with someone else (a 3rd party agent); and even then, permissions and rules should be asserted to the rightful use of any-such derivatives of a persons thought-processes.  \"), mdx(\"p\", null, \"Yet, then when getting 'stuck into' the design challenge, the implication became a process of engaging in the study of language in a way, that i hadn't done in a similar way earlier. \"), mdx(\"p\", null, \"This document is work in progress - it will seek to uplift the considerations made in other documents relating to my research of how to form the best possible approach in this area / for this problem; and thereby illustrate my thought-processes in relation to the practical undertaking of trying to figure out what the best possible (based upon what is known now) solutions architecture for addressing this problem; both in the more immediate term, and consequentially thereafter - overtime (growth, evolution, 'upgradability', etc.).  I also want to expressly note; the underlying sentiments being considered in relation to english - as do in-turn relate to my identity, who and how i communicate and 'think' is sought to be supportively considered for others whose life relates to languages other than english.  \"), mdx(\"p\", null, \"Terein also - i am particularly interested in seeking to support indigenous languages, and in other areas - hearldy and similarly pictorially defined languages are also an area of interest..\"), mdx(\"p\", null, \"Language, has an enormous role and influence on our minds and experiences as an observer and as an active natural agent.  Without language, without a comprehension of (a) language; we might see the 'data' but we won't understand 'what it says' (information) or the meaning (knowledge) - which in-turn relates to the formation of 'wisdom', in-effect; that is an instrumental part of consciousness, and therefore - of significant importance to HumanCentricAI and HumanCentric Identity modelling requirements and related processes.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"NOTING AGAIN - I DO NOT CONSIDER MYSELF AN EXPERT IN THIS SPECIFIC AREA!!\")), \" \"), mdx(\"p\", null, \"Now therefore,\"), mdx(\"h2\", {\n    \"id\": \"requirement\"\n  }, \"Requirement\"), mdx(\"p\", null, \"The considerations overall relate to the concept of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Upper_ontology\"\n  }, \"Upper Ontology\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"In\\xA0\", mdx(\"a\", {\n    parentName: \"em\",\n    \"href\": \"https://en.wikipedia.org/wiki/Information_science\",\n    \"title\": \"Information science\"\n  }, \"information science\"), \", an\\xA0\", mdx(\"strong\", {\n    parentName: \"em\"\n  }, \"upper ontology\"), \"\\xA0(also known as a\\xA0\", mdx(\"strong\", {\n    parentName: \"em\"\n  }, \"top-level ontology\"), \",\\xA0\", mdx(\"strong\", {\n    parentName: \"em\"\n  }, \"upper model\"), \", or\\xA0\", mdx(\"strong\", {\n    parentName: \"em\"\n  }, \"foundation ontology\"), \") is an\\xA0\", mdx(\"a\", {\n    parentName: \"em\",\n    \"href\": \"https://en.wikipedia.org/wiki/Ontology_(information_science)\",\n    \"title\": \"Ontology (information science)\"\n  }, \"ontology\"), \"\\xA0(in the sense used in information science) which consists of very general terms (such as \\\"object\\\", \\\"property\\\", \\\"relation\\\") that are common across all domains. An important function of an upper ontology is to support broad\\xA0\", mdx(\"a\", {\n    parentName: \"em\",\n    \"href\": \"https://en.wikipedia.org/wiki/Semantic_interoperability\",\n    \"title\": \"Semantic interoperability\"\n  }, \"semantic interoperability\"), \"\\xA0among a large number of domain-specific ontologies by providing a common starting point for the formulation of definitions. Terms in the domain ontology are ranked under the terms in the upper ontology, e.g., the upper ontology classes are superclasses or supersets of all the classes in the domain ontologies.\"), \"\\nSource: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Upper_ontology\"\n  }, \"WikiPedia\")), mdx(\"h3\", {\n    \"id\": \"permissive-commons-technology--webizen-ecosystems\"\n  }, \"Permissive Commons Technology & Webizen Ecosystems\"), mdx(\"p\", null, \"Both the Permissive Commons Technology and Webizen systems use ontologies as the primary means for defining 'functionality' and the structure of how to access resources. \"), mdx(\"p\", null, \"Ontologies are used throughout the systems for many different purposes, including but not limited to - providing the means to structure electronic assets in a manner that is thereby able to be used in a decentralised way (with permissions, defined using ontologies) across the ecosystem.  The historical tools used for ontologies are broadly known to be part of the broader 'semantic web' ecosystem; which declares a HTTP Namespace in connection to an ontology document, which other documents and systems are thereby defined to employ. \"), mdx(\"p\", null, \"PCT and thereby also Webizen systems are designed to provide support for the storage and use of ontologies that are sourced from protocols other than HTTP(s); even though, the primary communications protocols are build upon the use of web-protocols (http, ws, webrtc, etc.); the underlying 'informatics tools' (ie: ontologies and 'hypermedia containers') make use of non-http-protocols, as a means to provide functionality that is not easily facilitated via WWW.  The format of PCT is intended to REQUIRE a HTTP URI as well as information about the location of those ontology assets on other PCT supported protocols. Different protocols support different qualities and will be employed for different purposes; these definitions are intended to be defined - using PCT ontology.  Webizen Agents are intended to function using Ontology.  The extensibility of AI capabilities, is intended to be harmonised into the webizen ecosystem using ontology.  \"), mdx(\"p\", null, \"The Webizen ecosystem requires support via a VPN like tunnelling technique; in-order to support 'fully qualified domain names' for users, whose devices are connected on dynamic IP addresses behind firewalls.  This in-turn introduces an opportunity to review how DNS might be employed within the network, as to provide support for an ecosystems solution that is made to work in a complimentary manner (ie: doesn't clash) with external / public ICANN DNS.\"), mdx(\"p\", null, \"In-order to build the software that operates the underlying 'read-write' server/client, a database structure needs to be defined; and thereafter, built upon, using ontologies. \"), mdx(\"p\", null, \"The below diagram provides a basic summary.\"), mdx(\"p\", null, \"\", mdx(\"figure\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"561px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/70aca/webizen_diagram_1-2.jpg\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"61.42857142857143%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIDBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe3GwlQ//8QAGRAAAgMBAAAAAAAAAAAAAAAAAREAECFB/9oACAEBAAEFAmz3YqGD/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFxAAAwEAAAAAAAAAAAAAAAAAAAExIP/aAAgBAQAGPwKjmf/EABoQAAMAAwEAAAAAAAAAAAAAAAABESExQVH/2gAIAQEAAT8hmCSb2Lk6cynkvKTXCPBoSC3PT//aAAwDAQACAAMAAAAQY8//xAAVEQEBAAAAAAAAAAAAAAAAAAAQIf/aAAgBAwEBPxCn/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGhABAAMBAQEAAAAAAAAAAAAAAQARITFBgf/aAAgBAQABPxAeVACtuvnyEXFQcLHvkEXhLXqVAeA+QXOWdPJqLRVq1n//2Q==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"webizen diagram 1 2\",\n    \"title\": \"webizen_diagram_1-2.jpg\",\n    \"src\": \"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/611f2/webizen_diagram_1-2.jpg\",\n    \"srcSet\": [\"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/e2e20/webizen_diagram_1-2.jpg 140w\", \"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/1631d/webizen_diagram_1-2.jpg 281w\", \"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/611f2/webizen_diagram_1-2.jpg 561w\", \"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/652d0/webizen_diagram_1-2.jpg 842w\", \"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/70aca/webizen_diagram_1-2.jpg 966w\"],\n    \"sizes\": \"(max-width: 561px) 100vw, 561px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"webizen_diagram_1-2.jpg\"), \"\\n  \"), \"\"), mdx(\"p\", null, \"Therein - the 'personal vault' - is entirely private, whereas the 'PCT DB' stores and communiates information that is shared with at least one other 'person' (entity or 3rd party agent). The Webizen (ai) agent; is required to operate in a manner that is controlled and defined by the owner of that agent; which thereafter includes a requirement to support the agreements that have been made electronically with others, using cryptographic instruments (credentials, essentially) that are defined - via ontologies. \"), mdx(\"p\", null, \"Whilst there are existing semantic web ontologies; the process of defining a different ecosystem presents an opportunity to redefine how the ontology ecosystem is designed to work 'natively'; therein, whilst mapping to other ontologies is part of how these systems are designed to work;  the question becomes, how might one best form a new solution, in 2023.\"), mdx(\"p\", null, \"A few requirements to support analysis of the context. \"), mdx(\"h3\", {\n    \"id\": \"run-locally\"\n  }, \"Run Locally\"), mdx(\"p\", null, \"The requirement is to end-up with a solution that can be run with a relatively minor amount of hardware resources on a stanard laptop / desktop machine.  This means, that whilst it should be far more sophistocated that traditional 'dictionary' software; it shouldn't require a connection to an online - 'global language model' or 3rd party online service, in-order to function.  As such, there's a variety of considerations about the level of sophistocation that is reasonably feasible; which in-turn, also relates to the approach taken to achieve an outcome.\"), mdx(\"h3\", {\n    \"id\": \"personal-vs-commons\"\n  }, \"Personal Vs. Commons\"), mdx(\"p\", null, \"The solution should support both; the ability for persons to structure their own private semantic 'datastore' in a manner that reflects how they naturally structure the use of vocabulary with mind, whilst noting that this is subject to change and evolution; as well as, being able to participatorily support shared structures - that may be different or a form of translation from what and how it is that they would personally employ language, etc. \"), mdx(\"p\", null, \"These considerations are distinct from the misuse of language (ie: false understandings or beliefs that words might mean one thing - when in-fact the term might mean something else entirely or be intepreted to have the opposite meaning, to what the natural agent intended).\"), mdx(\"h3\", {\n    \"id\": \"related-notes\"\n  }, \"Related Notes\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Etymology\"), \"\\n\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Etymology\"), \"\\xA0(\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Help:IPA/English\",\n    \"title\": \"Help:IPA/English\"\n  }, \"/\\u02CC\\u025Bt\\u026A\\u02C8m\\u0252l\\u0259d\\u0292i/\"), \"\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Help:Pronunciation_respelling_key\",\n    \"title\": \"Help:Pronunciation respelling key\"\n  }, mdx(\"em\", {\n    parentName: \"a\"\n  }, \"ET-im-OL-\\u0259-jee\")), \")\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Etymology#cite_note-OED-1\"\n  }, \"[1]\"), \"\\xA0is the study of the\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/History\",\n    \"title\": \"History\"\n  }, \"history\"), \"\\xA0of the\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Phonological_change\",\n    \"title\": \"Phonological change\"\n  }, \"form\"), \"\\xA0of\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Word\",\n    \"title\": \"Word\"\n  }, \"words\"), mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Etymology#cite_note-2\"\n  }, \"[2]\"), \"\\xA0and, by extension, the origin and evolution of their semantic meaning across time.\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Etymology#cite_note-3\"\n  }, \"[3]\"), \"\\xA0It is a subfield of\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Historical_linguistics\"\n  }, \"historical linguistics\"), \", and draws upon comparative\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Semantics\",\n    \"title\": \"Semantics\"\n  }, \"semantics\"), \",\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Morphology_(linguistics)\",\n    \"title\": \"Morphology (linguistics)\"\n  }, \"morphology\"), \",\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Semiotics\",\n    \"title\": \"Semiotics\"\n  }, \"semiotics\"), \", and\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Phonetics\",\n    \"title\": \"Phonetics\"\n  }, \"phonetics\"), \".\"), mdx(\"p\", null, \"Source: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Etymology\"\n  }, \"WikiPedia\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semiotics\"), \"\\n\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semiotics\"), \"\\xA0(also called\\xA0\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"semiotic studies\"), \") is the systematic study of sign processes (\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Semiosis\",\n    \"title\": \"Semiosis\"\n  }, \"semiosis\"), \") and meaning making. Semiosis is any activity, conduct, or process that involves\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Sign_(semiotics)\",\n    \"title\": \"Sign (semiotics)\"\n  }, \"signs\"), \", where a sign is defined as anything that communicates something, usually called a\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Meaning_(semiotics)\",\n    \"title\": \"Meaning (semiotics)\"\n  }, \"meaning\"), \", to the sign's interpreter. The meaning can be intentional such as a word uttered with a specific meaning, or unintentional, such as a symptom being a sign of a particular medical condition. Signs can also communicate feelings (which are usually not considered meanings) and may communicate internally (through thought itself) or through any of the senses:\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Visual_system\",\n    \"title\": \"Visual system\"\n  }, \"visual\"), \",\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Hearing\",\n    \"title\": \"Hearing\"\n  }, \"auditory\"), \",\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Somatosensory_system\",\n    \"title\": \"Somatosensory system\"\n  }, \"tactile\"), \",\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Olfaction\",\n    \"title\": \"Olfaction\"\n  }, \"olfactory\"), \", or\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Taste\",\n    \"title\": \"Taste\"\n  }, \"gustatory\"), \"\\xA0(taste). Contemporary semiotics is a branch of science that studies meaning-making and various types of knowledge\"), mdx(\"p\", null, \"Source: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Semiotics\"\n  }, \"WikiPedia\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Epistemology\"), \"\\n\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Epistemology\"), \"\\xA0(\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Help:IPA/English\",\n    \"title\": \"Help:IPA/English\"\n  }, \"/\\u026A\\u02CCp\\u026Ast\\u0259\\u02C8m\\u0252l\\u0259d\\u0292i/\"), \"\\xA0(\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/File:En-uk-epistemology.ogg\",\n    \"title\": \"About this sound\"\n  }, mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Loudspeaker.svg/11px-Loudspeaker.svg.png\",\n    \"alt\": null\n  })), mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://upload.wikimedia.org/wikipedia/commons/6/63/En-uk-epistemology.ogg\",\n    \"title\": \"En-uk-epistemology.ogg\"\n  }, \"listen\"), \"); from\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Ancient_Greek_language\",\n    \"title\": \"Ancient Greek language\"\n  }, \"Ancient Greek\"), \"\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wiktionary.org/wiki/%E1%BC%90%CF%80%CE%B9%CF%83%CF%84%CE%AE%CE%BC%CE%B7#Ancient_Greek\",\n    \"title\": \"wikt:ἐπιστήμη\"\n  }, \"\\u1F10\\u03C0\\u03B9\\u03C3\\u03C4\\u03AE\\u03BC\\u03B7\"), \"\\xA0\", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"(_epist\\u1E17m\\u0113\"), \")\", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"\\xA0'knowledge', and\\xA0\"), mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/-logy\",\n    \"title\": \"-logy\"\n  }, \"-logy\"), \"_), or the\\xA0\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"theory of knowledge\"), \", is the\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Outline_of_philosophy\",\n    \"title\": \"Outline of philosophy\"\n  }, \"branch of philosophy\"), \"\\xA0concerned with\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Knowledge\",\n    \"title\": \"Knowledge\"\n  }, \"knowledge\"), \". Epistemology is considered a major subfield of philosophy, along with other major subfields such as\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Ethics\",\n    \"title\": \"Ethics\"\n  }, \"ethics\"), \",\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Logic\",\n    \"title\": \"Logic\"\n  }, \"logic\"), \", and\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Metaphysics\",\n    \"title\": \"Metaphysics\"\n  }, \"metaphysics\"), \".\\nSource: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Epistemology\"\n  }, \"WikiPedia\")), mdx(\"h2\", {\n    \"id\": \"forming-a-hypothesis\"\n  }, \"Forming a Hypothesis\"), mdx(\"p\", null, \"The underlying hypothesis is that there may be a way to define a top-level ontology using natural language (english); and that, if this method is able to be achieved and done so well, then the intent - is to render various very positive implications for the creation of ontologies that make use of that underlying 'core' service / data-structure framework. \"), mdx(\"p\", null, \"Some of the implications may include;\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Significant AI Inferencing Benefits\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Ability to use the foundational library readily in a way that may both improve the quality of inferencing services whilst also reduce overall energy consuption. \"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The development of tooling that will be an important part of the permissions frameworks (as is thereafter supported by cryptography)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"An opportunity to enhance the capacity to produce via ontology - a 'universal api', that may speed-up the process of software production and related tooling.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"It appears that the implication may also be - significant improvements for 'privacy' support.\")), mdx(\"h3\", {\n    \"id\": \"considerations\"\n  }, \"Considerations\"), mdx(\"h3\", {\n    \"id\": \"natural-language-processing\"\n  }, \"Natural Language Processing\"), mdx(\"p\", null, \"As a consequence of the public release of ChatGPT - large-scale 'natural language' models are perhaps the most significant area of discussion generally - in relation to the use of AI, at the moment.  Consequentially also, it seems to me as though there's also some level of confusion about the nature of natural language processing generally and what it is that i'm working to achieve.  The implicit implication is that these large language models are far too big and hardware intensive to run on any one machine.  Also, they're not simply a model that is about 'english' as a language, rather, services like ChatGPT have a comprehensive knowledge (database) that it has harvested from the internet, that embody the contributions of many billions of persons over time. Perhaps, a better term for it might be that it is a 'knowledge platform' rather than more simply being a 'natural language model'.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"At the opposite end of the spectrum; are dictionary files that have been part of word-processing software for decades and indeed also - there are various examples of electronic dictionary devices that are very much like caculators; therein, the amount of hardware/software resources required to make basic dictionaries work - must be minor.\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"Asking ChatGPT to provide some information (given public sources couldn't otherwise be easily identified); ChatGPT provided the following information,\"))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Electronic software dictionaries have a long history dating back to the 1970s. One of the earliest examples of an electronic dictionary was the FED-2, created by the Soviet company \\\"FED\\\" in 1971. It was a translation device that used punch cards and a built-in CRT screen.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"In the 1980s and 1990s, electronic dictionaries started to become more advanced and portable, with the introduction of devices such as the Franklin Electronic Publishers' \\\"Bookman\\\" and the Casio \\\"Data Plus\\\" series, which could fit into a pocket and could be powered by batteries. These early electronic dictionaries were limited in their storage capacity and typically held a small fraction of the words found in print dictionaries.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"In the late 1990s, the first electronic dictionaries with built-in TFT screens and more advanced search functions were developed, such as the Seiko ER6700, which had a 2-megabyte memory and could store around 30,000 words.\")), mdx(\"p\", null, \"As such; there is a spectrum between what is easily achieved, what may be feasibly achieved and in-turn what cannot be achieved at this time; without the use of public APIs.\"), mdx(\"h4\", {\n    \"id\": \"technical-requirements\"\n  }, \"Technical Requirements\"), mdx(\"p\", null, \"The solution that can work, shouldn't consume more than 128MB or at most 1GB of RAM, depending on how the graph model may be processing - complex graphs; which should require upto 2GB RAM to operate in a basic way.  The use of GPU Processing may be employed, but shouldn't be required for whatever the basic solution is. Some GPUs do not have tensor cores whilst others may not support cuda or similar.  Conversely, in future implementations - the use of Neuromorphic Processors is being considered, and perhaps there are significantly beneficial applications for the use of these sorts of hardware components to expressly support the way these fundamental processes are processed. \"), mdx(\"p\", null, \"The complexity of the model will in-turn have various repercussions on performance and resource requirements.  The language model should also be designed to support voice interaction (ie: VoiceToText, and TextToVoice); which in-turn means it should support phonetic analysis. \"), mdx(\"p\", null, \"The language model should be able to work offline; the solution should not require continual communications with a public (cloud) API.   \"), mdx(\"p\", null, \"Perhaps moreover - the difference between 'NLP' and what this process is seeking to achieve, is that the software is not seeking to create an archive of the knowledge of human kind that is available to an AI agent to turn into one massive AI 'language model'; rather, what i'm seeking to achieve is the development of a very well defined vocabulary model, that can support the development of database structures, AI and therein - ontologies & interfaces.\"), mdx(\"p\", null, \"In-order to scope the broad notional concept; there's a question about whether to slim it down or first work to define a 'gold plated' model ie: \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"all the qualities that one might wish for if computing resources for all users wasn't a problem...\"), \"  and thereafter, seek to slim it down as required?  \"), mdx(\"h3\", {\n    \"id\": \"what-would-a-gold-plated-solution-look-like\"\n  }, \"What would a \", mdx(\"em\", {\n    parentName: \"h3\"\n  }, \"\\\"Gold Plated Solution\\\"\"), \" Look Like?\"), mdx(\"p\", null, \"Looking into the history of the english language, evokes an array of considerations that i think are related to Etymology, Semiotics, Epistemology etc.  \"), mdx(\"h4\", {\n    \"id\": \"spacetime-considerations-geospatial--temporal\"\n  }, \"SpaceTime Considerations (GeoSpatial & Temporal)\"), mdx(\"p\", null, \"Languages evolve overtime and in-turn also, relates to places and peoples from different places.  Some of the implications include pictorial languages such as is demonstrated by heraldry whereby the spelling of different words and the general ability to read and write a language was not always common.   The ability to develop a language model that seeks to take into consideration the geospatial relationships of where different words are thought to have originated (often) and the notations of time in relation to those known events, can be processed by AI models in ways that cannot be done by human minds alone, even if they've studied a particular subject or topic over many, many years.  Therein also; it takes humans many years to gain even a basic command of a spoken language, and years further to gain knowledge about the use of that language for writing and reading of other peoples works.\"), mdx(\"p\", null, \"Languages are also, constantly evolving.  As such, the intended meaning of words as were used hundreds and/or thousands of years ago, may be different to the modern meaning of that word or words.   Similarly words are being continually redefined and new words made.\"), mdx(\"h4\", {\n    \"id\": \"the-confluence-of-languages\"\n  }, \"The Confluence of Languages\"), mdx(\"p\", null, \"The english language is not simply 'english', rather, it is made-up of words that come from many other languages and many different peoples from various places, around the world overtime.   The ability to understand the meaning of english words, isn't simply able to be done as well as may otherwise be formed - should the history of those words be considered.\"), mdx(\"h3\", {\n    \"id\": \"mathematics\"\n  }, \"Mathematics\"), mdx(\"p\", null, \"The use of these works, whilst sought to be designed to support Human Centric principals (including Human Centric AI principals); will end-up being processed by a software agent (on a computer).  Perhaps therefore defining in the 'upper ontology' mathematics may in-turn improve support for 'comprehensible sense making' or in otherwords, inferencing, etc.\"), mdx(\"p\", null, \"LINKS:\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/CLLKazan/MathSearch\"\n  }, \"https://github.com/CLLKazan/MathSearch\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/CLLKazan/OntoMathPro\"\n  }, \"https://github.com/CLLKazan/OntoMathPro\")), mdx(\"h4\", {\n    \"id\": \"specialised-vocabularies--field-specific-meanings\"\n  }, \"Specialised Vocabularies & Field Specific Meanings\"), mdx(\"p\", null, \"There are various industries that make use of language of various forms and in various ways.  \"), mdx(\"p\", null, \"Sometimes the meaning that is applied within that professional field; has distinctions to the use of the term in other settings.  As such, the concept topic-field becomes an important attribute when seeking to comprehend the 'meaning' of a statement, that may be employed in relation to a specified field of '\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Liberal_arts_education\"\n  }, \"liberal arts\"), \"' profession, skillset or domain. \"), mdx(\"h4\", {\n    \"id\": \"functional-software-language\"\n  }, \"Functional (Software) Language\"), mdx(\"p\", null, \"Language sets for the useful production of software, may include definitions about protocols and in-turn also API definitions.   Further definitions could be provided about the meaning of various functions provided by various software languages.  \"), mdx(\"h4\", {\n    \"id\": \"translations\"\n  }, \"Translations\"), mdx(\"p\", null, \"A 'gold plated' solution would also be able to support translations between languages with a high-level of accuracy, in real-time. \"), mdx(\"h4\", {\n    \"id\": \"complex-document-graph-support-for-anyuri\"\n  }, \"Complex Document \\\"Graph\\\" support for AnyURI\"), mdx(\"p\", null, \"A gold plated solution might be able to process the text (or indeed also audio) of any webpage or electronic resource, and support a means to both better manage the history of a persons time spent on a computer, supporting improved recall and perhaps also the ability to archive versions of documents and thereafter support the ability to distinguish between versions of the same resource that may either change; or that the context relating to the content artifact changes, as to result in a different sort of meaning / categorisation of the content artifact; and in-turn perhaps also, any other content artifacts that refer to it.\"), mdx(\"h3\", {\n    \"id\": \"socioeconomic-considerations\"\n  }, \"SocioEconomic Considerations.\"), mdx(\"p\", null, \"There is an incredibly high-skilled series of 'jobs' or in-other-words, work, that does continually need to be undertaken and the useful benefit of that work is instrumental. \"), mdx(\"p\", null, \"As is noted below; there are some solutions that are available as 'open source libraries' yet there are other solutions that are made available on a paid basis.   Given the enormous scope of works that could be done towards supporting the commons / common-sense of computer-humanity language systems, whilst the means to make use of these systems should be free of 'survellience' particularly in relation to private use, the idea that all this work can be done 'for free', isn't considered reasonable or consistant with various practical factors that have a firm footing in reality.  As such, some way of ensuring support for those whose job/skillset/life it is to do language related work, is considered both reasonable and important.  \"), mdx(\"h3\", {\n    \"id\": \"defining-ai-related-input\"\n  }, \"Defining AI Related Input.\"), mdx(\"p\", null, \"As is noted in the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/WebScience/SafetyProtocols/AgentLabelling/\",\n    \"title\": \"AgentLabelling\"\n  }, \"AgentLabelling\"), \" note; it is important that the technical delivery is designed in such a way that ensures that, by default, the solution identifies which agent was responsible for which words being added to a document or communication artifact or event; This is likely able to be done via markup that is embedded in the content assets, however the exact solution is presently unknown and yet to be more formerally defined.  Whilst part of the consideration relates more specifically to AI (inc 'autocorrect') the same requirement is usefully important for collaborative documents involving many human actors.\"), mdx(\"h3\", {\n    \"id\": \"summary-gold-plated-solution\"\n  }, \"Summary: \", mdx(\"em\", {\n    parentName: \"h3\"\n  }, \"\\\"Gold Plated Solution\\\"\")), mdx(\"p\", null, \"Whilst these considerations are not yet exhaustive (ie: there's more), and that i have not got into the database (software) methods and implications - as yet... i note again,\"), mdx(\"p\", null, \"It is not presently expected that all of these sorts of qualities are going to be achievable nor is it considered that these qualities, characteristics and related considerations are all required in-order to make a significant improvement above and beyond the manner through which systems are made to operate today.  \"), mdx(\"h2\", {\n    \"id\": \"technology-considerations\"\n  }, \"Technology Considerations\"), mdx(\"p\", null, \"Whilst investigating solutions, an array of existing language models have been identified that provide a great deal of the underlying data that is considered to be required, although the methods to employ best employ them is presently unclear. \"), mdx(\"p\", null, \"Whilst making a note of the work done previously making enquiries with ChatGPT as is illustrated by: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/LanguageModelling/ChatGPTDynamicOntology/\",\n    \"title\": \"ChatGPTDynamicOntology\"\n  }, \"ChatGPTDynamicOntology\"), \" and in-turn the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/LanguageModelling/\",\n    \"title\": \"LanguageModelling\"\n  }, \"LanguageModelling\"), \" folder has been created to 'create space' for more thougher investigation. In-order to illustrate the considerations; i'll start with illustrating the resources that i've found so far. \"), mdx(\"h3\", {\n    \"id\": \"large-language-models\"\n  }, \"Large Language Models.\"), mdx(\"p\", null, \"Framenet: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://framenet.icsi.berkeley.edu/fndrupal/\"\n  }, \"https://framenet.icsi.berkeley.edu/fndrupal/\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/chanind/frame-semantic-transformer\"\n  }, \"https://github.com/chanind/frame-semantic-transformer\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/topics/framenet\"\n  }, \"https://github.com/topics/framenet\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/dbamman/latin-bert\"\n  }, \"https://github.com/dbamman/latin-bert\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://wordnet-rdf.princeton.edu/\"\n  }, \"http://wordnet-rdf.princeton.edu/\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://framenet.icsi.berkeley.edu/fndrupal/\"\n  }, \"https://framenet.icsi.berkeley.edu/fndrupal/\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Cyc\"\n  }, \"https://en.wikipedia.org/wiki/Cyc\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://old.datahub.io/dataset/opencyc\"\n  }, \"https://old.datahub.io/dataset/opencyc\"), \" is unavailable;  a version of it has been found: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/asanchez75/opencyc/blob/master/opencyc-latest.owl.gz\"\n  }, \"https://github.com/asanchez75/opencyc/blob/master/opencyc-latest.owl.gz\"), \" \"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.ontologyportal.org/\"\n  }, \"https://www.ontologyportal.org/\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/ontologyportal/sumo\"\n  }, \"https://github.com/ontologyportal/sumo\")), mdx(\"p\", null, \"OntoWordNet LINKS\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://lists.w3.org/Archives/Public/public-swbp-wg/2005Feb/0066.html\"\n  }, \"https://lists.w3.org/Archives/Public/public-swbp-wg/2005Feb/0066.html\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.w3.org/2001/sw/BestPractices/WNET/\"\n  }, \"https://www.w3.org/2001/sw/BestPractices/WNET/\")), mdx(\"p\", null, \"Other links\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://babelnet.org/\"\n  }, \"https://babelnet.org/\")), mdx(\"p\", null, \"NoteAlso: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.wordsapi.com/\"\n  }, \"https://www.wordsapi.com/\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/alammehwish/framester\"\n  }, \"https://github.com/alammehwish/framester\")), mdx(\"p\", null, \"NOTE: i was also thinking about something that's more like '@enNoun' or '@enNounAu' rather than simply '@en' or '@en_au', etc. But still working on how to formulate the basic concept. Fundamentally, re: nlp / ml/dl, etc. I wasn't sure how complex it might be, whilst seeking to ensure it doesn't consume too much memory / processing power.\"));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"# English Language Modelling\n\n***This Document is a work in progress!***\n\n[[UnderstandingOntologies]]\n\nI'm exploring an idea about forming some sort of semantic database method that would use language (english) to structure the ontological predicates. Part of the objective is to end up with a software model that can operate on a laptop (or mobile phone) privately.  \n\nThe underlying consideration is that the ability to 'think' and write something that may or may not be communicated to anyone else (or any other agent) should not be subject to interference or survellience.  Any implication any use of the english language either written or as is able to be intepreted via sensors (ie: microphones) for natural language processing, should be private - until such a time as the derivatives of that work are shared with someone else (a 3rd party agent); and even then, permissions and rules should be asserted to the rightful use of any-such derivatives of a persons thought-processes.  \n\nYet, then when getting 'stuck into' the design challenge, the implication became a process of engaging in the study of language in a way, that i hadn't done in a similar way earlier. \n\nThis document is work in progress - it will seek to uplift the considerations made in other documents relating to my research of how to form the best possible approach in this area / for this problem; and thereby illustrate my thought-processes in relation to the practical undertaking of trying to figure out what the best possible (based upon what is known now) solutions architecture for addressing this problem; both in the more immediate term, and consequentially thereafter - overtime (growth, evolution, 'upgradability', etc.).  I also want to expressly note; the underlying sentiments being considered in relation to english - as do in-turn relate to my identity, who and how i communicate and 'think' is sought to be supportively considered for others whose life relates to languages other than english.  \n\nTerein also - i am particularly interested in seeking to support indigenous languages, and in other areas - hearldy and similarly pictorially defined languages are also an area of interest..\n\nLanguage, has an enormous role and influence on our minds and experiences as an observer and as an active natural agent.  Without language, without a comprehension of (a) language; we might see the 'data' but we won't understand 'what it says' (information) or the meaning (knowledge) - which in-turn relates to the formation of 'wisdom', in-effect; that is an instrumental part of consciousness, and therefore - of significant importance to HumanCentricAI and HumanCentric Identity modelling requirements and related processes.\n\n***NOTING AGAIN - I DO NOT CONSIDER MYSELF AN EXPERT IN THIS SPECIFIC AREA!!*** \n\nNow therefore,\n\n## Requirement\n\nThe considerations overall relate to the concept of [Upper Ontology](https://en.wikipedia.org/wiki/Upper_ontology)\n\n*In [information science](https://en.wikipedia.org/wiki/Information_science \"Information science\"), an **upper ontology** (also known as a **top-level ontology**, **upper model**, or **foundation ontology**) is an [ontology](https://en.wikipedia.org/wiki/Ontology_(information_science) \"Ontology (information science)\") (in the sense used in information science) which consists of very general terms (such as \"object\", \"property\", \"relation\") that are common across all domains. An important function of an upper ontology is to support broad [semantic interoperability](https://en.wikipedia.org/wiki/Semantic_interoperability \"Semantic interoperability\") among a large number of domain-specific ontologies by providing a common starting point for the formulation of definitions. Terms in the domain ontology are ranked under the terms in the upper ontology, e.g., the upper ontology classes are superclasses or supersets of all the classes in the domain ontologies.*\nSource: [WikiPedia](https://en.wikipedia.org/wiki/Upper_ontology)\n\n\n### Permissive Commons Technology & Webizen Ecosystems\n\nBoth the Permissive Commons Technology and Webizen systems use ontologies as the primary means for defining 'functionality' and the structure of how to access resources. \n\nOntologies are used throughout the systems for many different purposes, including but not limited to - providing the means to structure electronic assets in a manner that is thereby able to be used in a decentralised way (with permissions, defined using ontologies) across the ecosystem.  The historical tools used for ontologies are broadly known to be part of the broader 'semantic web' ecosystem; which declares a HTTP Namespace in connection to an ontology document, which other documents and systems are thereby defined to employ. \n\nPCT and thereby also Webizen systems are designed to provide support for the storage and use of ontologies that are sourced from protocols other than HTTP(s); even though, the primary communications protocols are build upon the use of web-protocols (http, ws, webrtc, etc.); the underlying 'informatics tools' (ie: ontologies and 'hypermedia containers') make use of non-http-protocols, as a means to provide functionality that is not easily facilitated via WWW.  The format of PCT is intended to REQUIRE a HTTP URI as well as information about the location of those ontology assets on other PCT supported protocols. Different protocols support different qualities and will be employed for different purposes; these definitions are intended to be defined - using PCT ontology.  Webizen Agents are intended to function using Ontology.  The extensibility of AI capabilities, is intended to be harmonised into the webizen ecosystem using ontology.  \n\nThe Webizen ecosystem requires support via a VPN like tunnelling technique; in-order to support 'fully qualified domain names' for users, whose devices are connected on dynamic IP addresses behind firewalls.  This in-turn introduces an opportunity to review how DNS might be employed within the network, as to provide support for an ecosystems solution that is made to work in a complimentary manner (ie: doesn't clash) with external / public ICANN DNS.\n\nIn-order to build the software that operates the underlying 'read-write' server/client, a database structure needs to be defined; and thereafter, built upon, using ontologies. \n\nThe below diagram provides a basic summary.\n\n![[webizen_diagram_1-2.jpg]]\n\nTherein - the 'personal vault' - is entirely private, whereas the 'PCT DB' stores and communiates information that is shared with at least one other 'person' (entity or 3rd party agent). The Webizen (ai) agent; is required to operate in a manner that is controlled and defined by the owner of that agent; which thereafter includes a requirement to support the agreements that have been made electronically with others, using cryptographic instruments (credentials, essentially) that are defined - via ontologies. \n\nWhilst there are existing semantic web ontologies; the process of defining a different ecosystem presents an opportunity to redefine how the ontology ecosystem is designed to work 'natively'; therein, whilst mapping to other ontologies is part of how these systems are designed to work;  the question becomes, how might one best form a new solution, in 2023.\n\nA few requirements to support analysis of the context. \n\n### Run Locally\nThe requirement is to end-up with a solution that can be run with a relatively minor amount of hardware resources on a stanard laptop / desktop machine.  This means, that whilst it should be far more sophistocated that traditional 'dictionary' software; it shouldn't require a connection to an online - 'global language model' or 3rd party online service, in-order to function.  As such, there's a variety of considerations about the level of sophistocation that is reasonably feasible; which in-turn, also relates to the approach taken to achieve an outcome.\n\n### Personal Vs. Commons\n\nThe solution should support both; the ability for persons to structure their own private semantic 'datastore' in a manner that reflects how they naturally structure the use of vocabulary with mind, whilst noting that this is subject to change and evolution; as well as, being able to participatorily support shared structures - that may be different or a form of translation from what and how it is that they would personally employ language, etc. \n\nThese considerations are distinct from the misuse of language (ie: false understandings or beliefs that words might mean one thing - when in-fact the term might mean something else entirely or be intepreted to have the opposite meaning, to what the natural agent intended).\n\n\n### Related Notes\n\n**Etymology** \n**Etymology** ([/ˌɛtɪˈmɒlədʒi/](https://en.wikipedia.org/wiki/Help:IPA/English \"Help:IPA/English\") [_ET-im-OL-ə-jee_](https://en.wikipedia.org/wiki/Help:Pronunciation_respelling_key \"Help:Pronunciation respelling key\"))[[1]](https://en.wikipedia.org/wiki/Etymology#cite_note-OED-1) is the study of the [history](https://en.wikipedia.org/wiki/History \"History\") of the [form](https://en.wikipedia.org/wiki/Phonological_change \"Phonological change\") of [words](https://en.wikipedia.org/wiki/Word \"Word\")[[2]](https://en.wikipedia.org/wiki/Etymology#cite_note-2) and, by extension, the origin and evolution of their semantic meaning across time.[[3]](https://en.wikipedia.org/wiki/Etymology#cite_note-3) It is a subfield of [historical linguistics](https://en.wikipedia.org/wiki/Historical_linguistics), and draws upon comparative [semantics](https://en.wikipedia.org/wiki/Semantics \"Semantics\"), [morphology](https://en.wikipedia.org/wiki/Morphology_(linguistics) \"Morphology (linguistics)\"), [semiotics](https://en.wikipedia.org/wiki/Semiotics \"Semiotics\"), and [phonetics](https://en.wikipedia.org/wiki/Phonetics \"Phonetics\").\n\nSource: [WikiPedia](https://en.wikipedia.org/wiki/Etymology)\n\n**Semiotics**\n**Semiotics** (also called **semiotic studies**) is the systematic study of sign processes ([semiosis](https://en.wikipedia.org/wiki/Semiosis \"Semiosis\")) and meaning making. Semiosis is any activity, conduct, or process that involves [signs](https://en.wikipedia.org/wiki/Sign_(semiotics) \"Sign (semiotics)\"), where a sign is defined as anything that communicates something, usually called a [meaning](https://en.wikipedia.org/wiki/Meaning_(semiotics) \"Meaning (semiotics)\"), to the sign's interpreter. The meaning can be intentional such as a word uttered with a specific meaning, or unintentional, such as a symptom being a sign of a particular medical condition. Signs can also communicate feelings (which are usually not considered meanings) and may communicate internally (through thought itself) or through any of the senses: [visual](https://en.wikipedia.org/wiki/Visual_system \"Visual system\"), [auditory](https://en.wikipedia.org/wiki/Hearing \"Hearing\"), [tactile](https://en.wikipedia.org/wiki/Somatosensory_system \"Somatosensory system\"), [olfactory](https://en.wikipedia.org/wiki/Olfaction \"Olfaction\"), or [gustatory](https://en.wikipedia.org/wiki/Taste \"Taste\") (taste). Contemporary semiotics is a branch of science that studies meaning-making and various types of knowledge\n\nSource: [WikiPedia](https://en.wikipedia.org/wiki/Semiotics)\n\n**Epistemology**\n**Epistemology** ([/ɪˌpɪstəˈmɒlədʒi/](https://en.wikipedia.org/wiki/Help:IPA/English \"Help:IPA/English\") ([![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Loudspeaker.svg/11px-Loudspeaker.svg.png)](https://en.wikipedia.org/wiki/File:En-uk-epistemology.ogg \"About this sound\")[listen](https://upload.wikimedia.org/wikipedia/commons/6/63/En-uk-epistemology.ogg \"En-uk-epistemology.ogg\")); from [Ancient Greek](https://en.wikipedia.org/wiki/Ancient_Greek_language \"Ancient Greek language\") [ἐπιστήμη](https://en.wiktionary.org/wiki/%E1%BC%90%CF%80%CE%B9%CF%83%CF%84%CE%AE%CE%BC%CE%B7#Ancient_Greek \"wikt:ἐπιστήμη\") _(_epistḗmē_)_ 'knowledge', and _[-logy](https://en.wikipedia.org/wiki/-logy \"-logy\")_), or the **theory of knowledge**, is the [branch of philosophy](https://en.wikipedia.org/wiki/Outline_of_philosophy \"Outline of philosophy\") concerned with [knowledge](https://en.wikipedia.org/wiki/Knowledge \"Knowledge\"). Epistemology is considered a major subfield of philosophy, along with other major subfields such as [ethics](https://en.wikipedia.org/wiki/Ethics \"Ethics\"), [logic](https://en.wikipedia.org/wiki/Logic \"Logic\"), and [metaphysics](https://en.wikipedia.org/wiki/Metaphysics \"Metaphysics\").\nSource: [WikiPedia](https://en.wikipedia.org/wiki/Epistemology)\n\n## Forming a Hypothesis\n\nThe underlying hypothesis is that there may be a way to define a top-level ontology using natural language (english); and that, if this method is able to be achieved and done so well, then the intent - is to render various very positive implications for the creation of ontologies that make use of that underlying 'core' service / data-structure framework. \n\nSome of the implications may include;\n\n- Significant AI Inferencing Benefits\n- Ability to use the foundational library readily in a way that may both improve the quality of inferencing services whilst also reduce overall energy consuption. \n- The development of tooling that will be an important part of the permissions frameworks (as is thereafter supported by cryptography)\n- An opportunity to enhance the capacity to produce via ontology - a 'universal api', that may speed-up the process of software production and related tooling.\n- It appears that the implication may also be - significant improvements for 'privacy' support.\n\n### Considerations\n\n### Natural Language Processing\n\nAs a consequence of the public release of ChatGPT - large-scale 'natural language' models are perhaps the most significant area of discussion generally - in relation to the use of AI, at the moment.  Consequentially also, it seems to me as though there's also some level of confusion about the nature of natural language processing generally and what it is that i'm working to achieve.  The implicit implication is that these large language models are far too big and hardware intensive to run on any one machine.  Also, they're not simply a model that is about 'english' as a language, rather, services like ChatGPT have a comprehensive knowledge (database) that it has harvested from the internet, that embody the contributions of many billions of persons over time. Perhaps, a better term for it might be that it is a 'knowledge platform' rather than more simply being a 'natural language model'.\n\n*At the opposite end of the spectrum; are dictionary files that have been part of word-processing software for decades and indeed also - there are various examples of electronic dictionary devices that are very much like caculators; therein, the amount of hardware/software resources required to make basic dictionaries work - must be minor.*\n\n***Asking ChatGPT to provide some information (given public sources couldn't otherwise be easily identified); ChatGPT provided the following information,***\n\n*Electronic software dictionaries have a long history dating back to the 1970s. One of the earliest examples of an electronic dictionary was the FED-2, created by the Soviet company \"FED\" in 1971. It was a translation device that used punch cards and a built-in CRT screen.*\n\n*In the 1980s and 1990s, electronic dictionaries started to become more advanced and portable, with the introduction of devices such as the Franklin Electronic Publishers' \"Bookman\" and the Casio \"Data Plus\" series, which could fit into a pocket and could be powered by batteries. These early electronic dictionaries were limited in their storage capacity and typically held a small fraction of the words found in print dictionaries.*\n\n*In the late 1990s, the first electronic dictionaries with built-in TFT screens and more advanced search functions were developed, such as the Seiko ER6700, which had a 2-megabyte memory and could store around 30,000 words.*\n\nAs such; there is a spectrum between what is easily achieved, what may be feasibly achieved and in-turn what cannot be achieved at this time; without the use of public APIs.\n\n#### Technical Requirements\n\nThe solution that can work, shouldn't consume more than 128MB or at most 1GB of RAM, depending on how the graph model may be processing - complex graphs; which should require upto 2GB RAM to operate in a basic way.  The use of GPU Processing may be employed, but shouldn't be required for whatever the basic solution is. Some GPUs do not have tensor cores whilst others may not support cuda or similar.  Conversely, in future implementations - the use of Neuromorphic Processors is being considered, and perhaps there are significantly beneficial applications for the use of these sorts of hardware components to expressly support the way these fundamental processes are processed. \n\nThe complexity of the model will in-turn have various repercussions on performance and resource requirements.  The language model should also be designed to support voice interaction (ie: VoiceToText, and TextToVoice); which in-turn means it should support phonetic analysis. \n\nThe language model should be able to work offline; the solution should not require continual communications with a public (cloud) API.   \n\nPerhaps moreover - the difference between 'NLP' and what this process is seeking to achieve, is that the software is not seeking to create an archive of the knowledge of human kind that is available to an AI agent to turn into one massive AI 'language model'; rather, what i'm seeking to achieve is the development of a very well defined vocabulary model, that can support the development of database structures, AI and therein - ontologies & interfaces.\n\nIn-order to scope the broad notional concept; there's a question about whether to slim it down or first work to define a 'gold plated' model ie: *all the qualities that one might wish for if computing resources for all users wasn't a problem...*  and thereafter, seek to slim it down as required?  \n\n### What would a *\"Gold Plated Solution\"* Look Like?\n\nLooking into the history of the english language, evokes an array of considerations that i think are related to Etymology, Semiotics, Epistemology etc.  \n\n#### SpaceTime Considerations (GeoSpatial & Temporal)\n\nLanguages evolve overtime and in-turn also, relates to places and peoples from different places.  Some of the implications include pictorial languages such as is demonstrated by heraldry whereby the spelling of different words and the general ability to read and write a language was not always common.   The ability to develop a language model that seeks to take into consideration the geospatial relationships of where different words are thought to have originated (often) and the notations of time in relation to those known events, can be processed by AI models in ways that cannot be done by human minds alone, even if they've studied a particular subject or topic over many, many years.  Therein also; it takes humans many years to gain even a basic command of a spoken language, and years further to gain knowledge about the use of that language for writing and reading of other peoples works.\n\nLanguages are also, constantly evolving.  As such, the intended meaning of words as were used hundreds and/or thousands of years ago, may be different to the modern meaning of that word or words.   Similarly words are being continually redefined and new words made.\n\n#### The Confluence of Languages\n\nThe english language is not simply 'english', rather, it is made-up of words that come from many other languages and many different peoples from various places, around the world overtime.   The ability to understand the meaning of english words, isn't simply able to be done as well as may otherwise be formed - should the history of those words be considered.\n\n### Mathematics\n\nThe use of these works, whilst sought to be designed to support Human Centric principals (including Human Centric AI principals); will end-up being processed by a software agent (on a computer).  Perhaps therefore defining in the 'upper ontology' mathematics may in-turn improve support for 'comprehensible sense making' or in otherwords, inferencing, etc.\n\nLINKS:\nhttps://github.com/CLLKazan/MathSearch\nhttps://github.com/CLLKazan/OntoMathPro\n\n#### Specialised Vocabularies & Field Specific Meanings\n\nThere are various industries that make use of language of various forms and in various ways.  \n\nSometimes the meaning that is applied within that professional field; has distinctions to the use of the term in other settings.  As such, the concept topic-field becomes an important attribute when seeking to comprehend the 'meaning' of a statement, that may be employed in relation to a specified field of '[liberal arts](https://en.wikipedia.org/wiki/Liberal_arts_education)' profession, skillset or domain. \n\n#### Functional (Software) Language\n\nLanguage sets for the useful production of software, may include definitions about protocols and in-turn also API definitions.   Further definitions could be provided about the meaning of various functions provided by various software languages.  \n\n#### Translations\nA 'gold plated' solution would also be able to support translations between languages with a high-level of accuracy, in real-time. \n\n#### Complex Document \"Graph\" support for AnyURI\n\nA gold plated solution might be able to process the text (or indeed also audio) of any webpage or electronic resource, and support a means to both better manage the history of a persons time spent on a computer, supporting improved recall and perhaps also the ability to archive versions of documents and thereafter support the ability to distinguish between versions of the same resource that may either change; or that the context relating to the content artifact changes, as to result in a different sort of meaning / categorisation of the content artifact; and in-turn perhaps also, any other content artifacts that refer to it.\n\n### SocioEconomic Considerations.\n\nThere is an incredibly high-skilled series of 'jobs' or in-other-words, work, that does continually need to be undertaken and the useful benefit of that work is instrumental. \n\nAs is noted below; there are some solutions that are available as 'open source libraries' yet there are other solutions that are made available on a paid basis.   Given the enormous scope of works that could be done towards supporting the commons / common-sense of computer-humanity language systems, whilst the means to make use of these systems should be free of 'survellience' particularly in relation to private use, the idea that all this work can be done 'for free', isn't considered reasonable or consistant with various practical factors that have a firm footing in reality.  As such, some way of ensuring support for those whose job/skillset/life it is to do language related work, is considered both reasonable and important.  \n\n### Defining AI Related Input.\n\nAs is noted in the [[AgentLabelling]] note; it is important that the technical delivery is designed in such a way that ensures that, by default, the solution identifies which agent was responsible for which words being added to a document or communication artifact or event; This is likely able to be done via markup that is embedded in the content assets, however the exact solution is presently unknown and yet to be more formerally defined.  Whilst part of the consideration relates more specifically to AI (inc 'autocorrect') the same requirement is usefully important for collaborative documents involving many human actors.\n\n### Summary: *\"Gold Plated Solution\"* \n\nWhilst these considerations are not yet exhaustive (ie: there's more), and that i have not got into the database (software) methods and implications - as yet... i note again,\n\nIt is not presently expected that all of these sorts of qualities are going to be achievable nor is it considered that these qualities, characteristics and related considerations are all required in-order to make a significant improvement above and beyond the manner through which systems are made to operate today.  \n\n## Technology Considerations\n\nWhilst investigating solutions, an array of existing language models have been identified that provide a great deal of the underlying data that is considered to be required, although the methods to employ best employ them is presently unclear. \n\nWhilst making a note of the work done previously making enquiries with ChatGPT as is illustrated by: [[ChatGPTDynamicOntology]] and in-turn the [[LanguageModelling]] folder has been created to 'create space' for more thougher investigation. In-order to illustrate the considerations; i'll start with illustrating the resources that i've found so far. \n\n### Large Language Models.\n\nFramenet: https://framenet.icsi.berkeley.edu/fndrupal/\nhttps://github.com/chanind/frame-semantic-transformer\nhttps://github.com/topics/framenet\n\nhttps://github.com/dbamman/latin-bert\nhttp://wordnet-rdf.princeton.edu/\nhttps://framenet.icsi.berkeley.edu/fndrupal/\nhttps://en.wikipedia.org/wiki/Cyc\nhttps://old.datahub.io/dataset/opencyc is unavailable;  a version of it has been found: https://github.com/asanchez75/opencyc/blob/master/opencyc-latest.owl.gz \n\nhttps://www.ontologyportal.org/\nhttps://github.com/ontologyportal/sumo\n\nOntoWordNet LINKS\nhttps://lists.w3.org/Archives/Public/public-swbp-wg/2005Feb/0066.html\nhttps://www.w3.org/2001/sw/BestPractices/WNET/\n\nOther links\nhttps://babelnet.org/\n\nNoteAlso: https://www.wordsapi.com/\n\nhttps://github.com/alammehwish/framester\n\nNOTE: i was also thinking about something that's more like '@enNoun' or '@enNounAu' rather than simply '@en' or '@en_au', etc. But still working on how to formulate the basic concept. Fundamentally, re: nlp / ml/dl, etc. I wasn't sure how complex it might be, whilst seeking to ensure it doesn't consume too much memory / processing power.\n\n","excerpt":"English Language Modelling This Document is a work in progress! [ UnderstandingOntologies ] I'm exploring an idea about forming some sort o…","outboundReferences":[{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"the-role-of-vocabulary\"\n  }, \"The Role of Vocabulary\"), mdx(\"h4\", {\n    \"id\": \"human-users\"\n  }, \"Human Users\"), mdx(\"p\", null, \"The focus for Human Users presently is English (focus therein - AustralianEnglish, as well as other examples of it) as that's the only natural spoken / written language i am competent in.  Phonetics, tonality and other factors play a role with spoken speech; punctuation and grammar plays a role with written natural language alongside spelling.\"), mdx(\"p\", null, \"Courts use natural langague to process disputes, form common-sense and defined outcomes.  Further considerations are being made in the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/WebScience/EnglishLanguageModelling/\",\n    \"title\": \"EnglishLanguageModelling\"\n  }, \"EnglishLanguageModelling\"), \" document.  This is in-turn not simply about english, but moreover about the broader series of considerations associted with trying to figure out how to define a solution for this component in a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/CommercialModels/BestEfforts/\",\n    \"title\": \"BestEfforts\"\n  }, \"BestEfforts\"), \" and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/CommercialModels/FitForPurpose/\",\n    \"title\": \"FitForPurpose\"\n  }, \"FitForPurpose\"), \" manner.\"), mdx(\"h4\", {\n    \"id\": \"computational-interference\"\n  }, \"Computational Interference\"), mdx(\"p\", null, \"There are many negative implications that develop when even basic AI related processes (ie: spellcheck helpers) re:define a term to another term, that changes the meaning of the sentence or concept that was intended to be communicated by the human being. \"), mdx(\"p\", null, \"These sorts of events create logs; and, complicate assessments - noting - i am not sure of a command that is \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \".wellknown\"), \" that allows a human being to assert a correction for an action that was made by a machine; or, any existing syntax that ensures a machines interference with a persons words is able to be logged, as part of that data-file.  \"), mdx(\"h3\", {\n    \"id\": \"software-agents\"\n  }, \"Software Agents\"), mdx(\"p\", null, \"Software agents fundamentally review english text on a computational basis - ending up with processes parsed in binary. \"), mdx(\"p\", null, \"However; there are various well-defined command structures that are in-effect a machine vocabulary that is contextual to the software / hardware environment. \"), mdx(\"p\", null, \"an instruction set, in-effect...\"), mdx(\"h4\", {\n    \"id\": \"human-centric-software-agent-considerations\"\n  }, \"Human Centric Software Agent Considerations\"), mdx(\"p\", null, \"Therein - one of the objective \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/WebScience/SafetyProtocols/\",\n    \"title\": \"SafetyProtocols\"\n  }, \"SafetyProtocols\"), \" related considerations should include the implications of computer generated deterministic content or artifacts interfering with AI modelling techniques - due to AI related inputs that are not properly labelled.\"), mdx(\"p\", null, \"The example being - 'autocorrect' issues...  changing the meaning of a sentence, and thereafter being employed to determine attributes about the natural agent. \"), mdx(\"h4\", {\n    \"id\": \"natural-language-modelling\"\n  }, \"Natural Language Modelling\"), mdx(\"p\", null, \"The language - english - has evolved over more than 1000 years, which makes it a fairly new language in the scheme of things; yet, the formation of it - has involved the use of many other terms and words that were used by various people who spoke various langauges at various times, in relation to various places.  \"), mdx(\"p\", null, \"Some investigation into related considerations can be found via the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/LanguageModelling/ChatGPTDynamicOntology/\",\n    \"title\": \"ChatGPTDynamicOntology\"\n  }, \"ChatGPTDynamicOntology\"), \" and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/WebScience/ArtificialMinds/AChatGPTExperimentHolborn/\",\n    \"title\": \"AChatGPTExperimentHolborn\"\n  }, \"AChatGPTExperimentHolborn\"), \" chatlogs; and overall the process of gaining the volume of insights considered usefully important, is still a work in progress.  Indeed; there's an array of advanced concepts, that i think - that its unlikely i'm ever the expert in - so, whilst \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/CommercialModels/BestEfforts/\",\n    \"title\": \"BestEfforts\"\n  }, \"BestEfforts\"), \" are being made - the deliberations is, about seeking to ensure the foundational constructs support the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/\",\n    \"title\": \"SocialFactors\"\n  }, \"SocialFactors\"), \" and particularly therein; any \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/WebScience/SafetyProtocols/\",\n    \"title\": \"SafetyProtocols\"\n  }, \"SafetyProtocols\"), \" (whether noted or yet to be noted) that may be of instrumental importance, as to support the broader \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/WebScience/TheValuesProject/\",\n    \"title\": \"TheValuesProject\"\n  }, \"TheValuesProject\"), \" related implicit and explicit requirements. \"), mdx(\"p\", null, \"Anedotally, it appears to me that these sorts of problems - seemingly haven't been formerally addressed in a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/CommercialModels/FitForPurpose/\",\n    \"title\": \"FitForPurpose\"\n  }, \"FitForPurpose\"), \" way - which is unlikely to be due to some form of negligence in relation to the scientists involved at the time (although - \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/SocialAttackVectors/\",\n    \"title\": \"SocialAttackVectors\"\n  }, \"SocialAttackVectors\"), \" are very likely to have played a role with the consequential application of technology); rather, it is more likely that the technology of the time was unable to do the sorts of things that might otherwise be done, and perhaps sacrifices were made; and then built upon by others, using old work as foundational components for new works.  \"), mdx(\"p\", null, \"In-effect, the implication relates to the concept of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/SocialAttackVectors/CyberAttackVectors/TechDebt/\",\n    \"title\": \"TechDebt\"\n  }, \"TechDebt\"), \" although - not as is mentioned currently by that article.   There is a requirement to seek to ensure, that it is human beings who maintain primary responsibility for what it is they do and the effect of what they say.  AI models can be used to pervert and interfere in those sorts of underlying 'caculations' in ways that can lead to unwanted and/or unintended consequences; that in-turn relates to broader issues such as those noted about \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/SocialAttackVectors/CyberAttackVectors/NobodyAI/\",\n    \"title\": \"NobodyAI\"\n  }, \"NobodyAI\"), \".  \"), mdx(\"p\", null, \"So, the design implication; with respect to the broader and future objectives of the webizen ecosystem - in relation to forming a semantic vocabulary method and apparatus (program),\"), mdx(\"p\", null, \"Whilst my study is not exhaustive - noting people spend their entire lives studing these sorts of fields - which is not what i have done or do...  \"), mdx(\"p\", null, \"it appears to me that the roots of english end-up forming a fabric, that likely related to trade and the movement of people (including conflicts) that results in considerations that are temporally geospatial in nature; which thereafter become influenced by the politics and ideologies associated with groups over the course of space-time stuff, in-effect...  \"), mdx(\"p\", null, \"The ability to produce a 'system of excellence' is likely to require an enormous amount of computational capability; and in-turn, be forged through the use of known languages, over the course of at least the last 1500 years; which is a relatively simple task by comparison to many older languages, yet nonetheless - all somewhat 'linked together'...  \"), mdx(\"p\", null, \"These models would need to be defined in a way that supported continual training / learning.\"), mdx(\"p\", null, \"Yet, this is unlikely to provide a solution that is able to be made able to work on the sorts of devices commonly used by people - such as mobile phones and personal computers..  \"), mdx(\"p\", null, \"It is essential to ensure support for a technique that enables the private use of language, in a manner that can result with artifacts that are comprehensble to other Webizen Owners / users (the human beings - and in-turn, group entities - like companies, etc.).\"), mdx(\"p\", null, \"SO therefore; a high-level model is required that can support extensibility; whilst also, providing something that can be used as a basic component that requires relatively little computational resources on the device that it is functioning on.  This is demonstrated by existing dictionary software that has existed over a very long period of time; but, the desired functionality of this component, is considered to be desirably defined to be far more sophistocated.\"), mdx(\"p\", null, \"Fundamentally also: the objective is not to simply support the english language.  As i do not know other languages well enough, the only reasonable approach i have is to focus on the language i know, and hope that some of the insights and that all of the derivative 'product' output; is useful, for those who are better equipped to look at how to implement other languages.  In many ways, this is a sort of moral hygiene consideration; where the preference is, not to define others via a field of work / study / knowledge, that i do not know; which is intended to be intepreted as an attitude relating to care and consideration, rather than the opposite. \"));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/WebizenTechStack/LanguageModelling/","title":"The Role of Vocabulary","shouldShowTitle":false}},{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"understanding-ontologies\"\n  }, \"Understanding Ontologies\"), mdx(\"p\", null, \"It seems important to describe the consequence of 'ontology' not simply from a technical level, but also from a social level...\"), mdx(\"p\", null, \"From a social perspective, an ontology is a shared understanding or interpretation of the world and the concepts that exist within it. It is shaped by the cultural and social context in which it is developed, and it reflects the values, beliefs, and assumptions of the people who create it.\"), mdx(\"p\", null, \"In sociology, the concept of ontology is often used to refer to the way that individuals and groups make sense of the world and their place within it. This includes their understanding of the nature of reality, the categories and concepts that they use to make sense of the world, and the relationships between these concepts.\"), mdx(\"p\", null, \"In social interactions, individuals and groups often have different ontologies, reflecting their different experiences and perspectives. These differences can lead to misunderstandings and conflicts, as people may use different terms and categories to describe the same thing, or may have different assumptions about the nature of reality.\"), mdx(\"p\", null, \"However, ontologies can also be shared and negotiated through social interactions, as individuals and groups engage in dialogue and communication. Through these interactions, people can come to a shared understanding of the world and the concepts that exist within it, allowing them to communicate more effectively and collaborate more effectively.\"), mdx(\"p\", null, \"One of the best examples i know of was done by \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.youtube.com/@ShotsOfAwe\"\n  }, \"Jason Silva: Shots of Awe\"), \" \"), mdx(\"iframe\", {\n    width: \"560\",\n    height: \"315\",\n    src: \"https://www.youtube.com/embed/aigR2UU4R20\",\n    title: \"YouTube video player\",\n    frameBorder: \"0\",\n    allow: \"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\",\n    allowFullScreen: true\n  }), mdx(\"p\", null, \"A discussion about the concept\"), mdx(\"iframe\", {\n    width: \"560\",\n    height: \"315\",\n    src: \"https://www.youtube.com/embed/HTw3jocJBrw\",\n    title: \"YouTube video player\",\n    frameBorder: \"0\",\n    allow: \"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\",\n    allowFullScreen: true\n  }), mdx(\"h2\", {\n    \"id\": \"what-is-ontology-modelling\"\n  }, \"What is Ontology Modelling?\"), mdx(\"p\", null, \"Ontology modeling is the process of creating a structured representation of a domain of knowledge. An ontology is a formal representation of a set of concepts within a domain, and the relationships between those concepts. It is used to define the vocabulary of a domain, as well as the types of relationships that can exist between concepts.\"), mdx(\"p\", null, \"Ontologies are typically created using a formal language, such as the Web Ontology Language (OWL). They can be used to represent a wide range of knowledge, including scientific, medical, and even business knowledge.\"), mdx(\"p\", null, \"There are several benefits to using ontologies in modeling a domain of knowledge. They allow for the creation of a common vocabulary that can be shared by multiple users or systems. They also enable the creation of more precise and unambiguous definitions of concepts, which can improve communication and understanding within a domain. Finally, ontologies can be used to enable automated reasoning, allowing computers to make inferences and draw conclusions based on the knowledge represented in the ontology.\"), mdx(\"p\", null, \"Ontology employs vocabulary and is innately and somewhat inextricably linked with the mechanisms considered instrumental to consciousness; through which we organise  communications of thought and embedded concepts.  These systems lead to an implicit design of embedded ideology, values and belief systems; whether or not it is intended.  \"), mdx(\"h4\", {\n    \"id\": \"semantic-web-historical-notes\"\n  }, \"Semantic Web Historical Notes\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Web\"), \", extension of the\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.britannica.com/topic/World-Wide-Web\"\n  }, \"World Wide Web\"), \"\\xA0(WWW) in which data are given meaning (\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.britannica.com/science/semantics\"\n  }, \"semantics\"), \") to enable\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.britannica.com/technology/computer\"\n  }, \"computers\"), \"\\xA0to look up and \\u201Creason\\u201D in response to user searches. One of the strongest proponents of the Semantic Web is\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.britannica.com/biography/Tim-Berners-Lee\"\n  }, \"Sir Tim Berners-Lee\"), \", the British inventor of the WWW and the director of the\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.britannica.com/topic/World-Wide-Web-Consortium\"\n  }, \"World Wide Web Consortium\"), \"\\xA0(W3C), which oversees standards for the project.\"), mdx(\"p\", null, \"Berners-Lee had\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.merriam-webster.com/dictionary/envisioned\"\n  }, \"envisioned\"), \"\\xA0the Semantic Web by at least 1994, only a few years after he began developing the WWW in 1989. He unveiled his idea for the Semantic Web at the First International WWW Conference, held in 1994, which resulted in the formation of the W3C.\"), mdx(\"p\", null, \"Source:  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.britannica.com/topic/Semantic-Web\"\n  }, \"britannica\"), \" \"), mdx(\"p\", null, \"Part of the history of this project is that it appears to have been initially supported via the DARPA related project that created \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://web.archive.org/web/20030207042906/http://www.daml.org/about.html\"\n  }, \"DAML\"), \" +\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://tomhalljones.com/web/ontology-inference-layer-oil/\"\n  }, \"OIL\"), \".  which then led to \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Web_Ontology_Language\"\n  }, \"OWL\"), \" that provides a top-level concept of \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"owl:thing\"), \", although \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/FOAF/\",\n    \"title\": \"FOAF\"\n  }, \"FOAF\"), \"  (which was originally created prior to OWL) does not define a person as a a subclass of \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"owl:thing\"), \" although other examples of FOAF appear to have changed the semantics to include it.  This may be due to 'tool lock-ins', where some tools are designed to be specifically designed to use / work with OWL.  \"), mdx(\"p\", null, \"Some of these sorts of issues are difficult and confusing to both figure out and thereby form a comprehension about the intended designs / purpose; as the semantics matter, yet the ability to ensure comprehensible meanings - is seemingly challenged in some way; perhaps its just me, or perhaps its a broader problem, idk.  \"), mdx(\"p\", null, \"NOTE:  A great deal of these works are very much centred upon forming an information fabric that renders an environment through which Human Beings employ Tools (ie: ICT) in a manner that defines Human Beings as the primary (yet indirect) agents; not as a 'thing' but rather as 'beings'.  Whilst it appears as though these sorts of sentiments were seemingly expressed in the original \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/FOAF/\",\n    \"title\": \"FOAF\"\n  }, \"FOAF\"), \" works, the confusion (whether its due to my own confusion or other exteral issues or perhaps both) as to whether the predicate is \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"owl:thing\"), \" (whereby a person is a sub-class of thing) or whether human beings are independently represented, is not as clearly defined as is otherwise sought to be addressed.  \"), mdx(\"p\", null, \"Therein - the FOAF project was created sometime between the late 1990's and before 2001 (the history is sometimes hard to find).\"), mdx(\"p\", null, \"The sitaution / growth of the internet at that stage; was at a very different level, as were the circumstances related to what usecases might be reasonably defined for systems of that time.\"), mdx(\"p\", null, \"So, whilst the work done back then was indeed remarkable - and seemingly done in a manner that was mindful of - at least - the basic needs of human beings; perhaps there's validity in seeking to reinvent the modelling to uplift how future systems are made to work.\"), mdx(\"h4\", {\n    \"id\": \"considerations\"\n  }, \"Considerations\"), mdx(\"p\", null, \"The High level concepts that are being considered;\"), mdx(\"p\", null, \"Presently, the primary ontological predicate is mostly \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"owl:thing\"), \" which thereby defines everything described by it a subclass of \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"thing\"), \". Whilst this makes sense for \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"things\"), \", i do not like the concept of human beings defined as a subclass of \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"thing\"), \" nor is it necessarily appropriate to define other parts of life as \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"things\"), \"; so perhaps this can be seperated as to form the logical foundations for seperating the human kind,  the thing created by humankind and things (see - not sure what other term?) of our world, particularly therein - life.\"), mdx(\"p\", null, \"Thereafter; one consitituency of the considerations is how to seperate the Conceptual 'spheres'\"), mdx(\"p\", null, \"The ontological considerations relating to humans should also support considerations about qualia and 'philosophy of mind' related considerations; whereas the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Biosphere\"\n  }, \"Biosphere\"), \" related factors may be subject to some sort of property rights / law related assertions; but they do not exist because of mankind; rather, they are constituencies of what may be referred to as our natural world or what many would consider to be things or parts of 'god', including but not limited to - life.  This in-turn has an array of implications relating to the differences between inventions (of man) and discoveries (of / for mankind). As an extension of these considerations the term \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Infosphere\"\n  }, \"Infosphere\"), \"  is thereby linked to the term \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Inforg\"\n  }, \"inforg\"), \" which i've previously used extensively when seeking to forge appropriate namonclature to describe the informational representation of a human being, and implicitly therein - consciousness; in a manner that is not improperly disruptive to \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/WebScience/SafetyProtocols/FreedomOfThought/\",\n    \"title\": \"FreedomofThought\"\n  }, \"FreedomofThought\"), \".  As a consequence of previous works, i am convinced that there is a meaningful relationship between the field of study and communications of concepts broadly defined as quantum physics. Herein, as the ramifications are difficult to easily provide a mechanism for people to generally test and observe themselves; the implication of how to form meaningful insights or considerations; in so far as i have found, moreover relates to the way in which these concepts relating to physics and natural systems, are described.\"), mdx(\"p\", null, \"One such example that is short, and therefore more useful than the longer presentations and/or lectures on the topic; is the short description provided by Henry Strapp on Quantum Mechanics and Human Consciousness; in it, strapp describes the importance of the role of the observer (the conscious agent).\"), mdx(\"iframe\", {\n    width: \"560\",\n    height: \"315\",\n    src: \"https://www.youtube.com/embed/ZYPjXz1MVv0\",\n    title: \"YouTube video player\",\n    frameBorder: \"0\",\n    allow: \"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\",\n    allowFullScreen: true\n  }), mdx(\"p\", null, \"HTTP(s) based ontologies are fundamental to the Semantic Web; which has later been termed 'linked data'.  \"), mdx(\"p\", null, \"In a w3c post; it describes linked data in the following way,\"), mdx(\"p\", null, \"Tim Berners-Lee, the inventor of the Web and initiator of the Linked Data project, suggested a 5 star deployment scheme for Linked Data. The 5 Star Linked Data system is cumulative. Each additional star presumes the data meets the criteria of the previous step(s).\"), mdx(\"p\", null, \"\\u2606 Data is available on the Web, in whatever format.\\t\"), mdx(\"p\", null, \"\\u2606\\u2606 Available as machine-readable structured data, (i.e., not a scanned image).\"), mdx(\"p\", null, \"\\u2606\\u2606\\u2606 Available in a non-proprietary format, (i.e, CSV, not Microsoft Excel).\\t\"), mdx(\"p\", null, \"\\u2606\\u2606\\u2606\\u2606 Published using open standards from the W3C (RDF and SPARQL).\\t\"), mdx(\"p\", null, \"\\u2606\\u2606\\u2606\\u2606\\u2606 All of the above and links to other Linked Open Data.\"), mdx(\"p\", null, \"The Linked Data mug can be read with both green labels for Linked Open Data, or neither label for Linked Data. Proceeds of the Linked Open Data mug benefit the W3C.\"), mdx(\"p\", null, \"source:  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.w3.org/2011/gld/wiki/5_Star_Linked_Data\"\n  }, \"W3C 5_Star_Linked_Data\")), mdx(\"p\", null, \"More information about the background can be found on  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.w3.org/DesignIssues/LinkedData.html\"\n  }, \"Tim Berners-lee's DesignIssues note on Linked Data\"), \"  and i made a note of it also in \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.w3.org/community/webize/2014/01/17/what-is-5-star-linked-data/\"\n  }, \"Jan 2014 re: Webizing apps\"), \".\"));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/SocialFactors/WebScience/UnderstandingOntologies/","title":"Understanding Ontologies","shouldShowTitle":false}},{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"dynamic-ontology\"\n  }, \"Dynamic Ontology\"), mdx(\"p\", null, \"The below text is sourced via the Q&A with ChatGPT to figure out how to create a dynamic ontology solution.  What i'm then doing, is going through and making notes in interleave. \"), mdx(\"p\", null, \"The solution is not intended to be operated by ChatGPT  - rather, this is intended to be a root resource employed locally on systems. \"), mdx(\"h2\", {\n    \"id\": \"chatgpt-interactive-notes\"\n  }, \"ChatGPT Interactive Notes\"), mdx(\"p\", null, \"I am working on a project that seeks to create innovative semantic web related technology. I don't like OWL being used for human beings and as a means to describe parts of our biosphere that is not property of a company, but rather something that is of earth. To address this problem, i am trying to figure out how to create a machine-learning training program, that would be provided an english language dictionary, including information about the use of words in the context of them being used as a NOUN, PRONOUN, VERB, ADJECTIVE, ADVERB, PREPOSITION, CONJUNCTION or INTERJECTION and related descriptions of the definition provided using the english language. The program would process this information and provide a model that can be used for the purpose of defining a top-level ontology that can be used with RDF and RDFS for the creation of RDF ontologies. How can this be achieved?\"), mdx(\"p\", null, \"ChatGPT:\"), mdx(\"p\", null, \"There are several ways to approach this problem of creating a machine-learning training program that can process an English language dictionary and provide a model for defining a top-level ontology that can be used with RDF and RDFS. One approach would be to use natural language processing (NLP) techniques to automatically extract information about the usage and meaning of words in the dictionary.\"), mdx(\"p\", null, \"One specific method to achieve this would be to use a supervised machine learning algorithm, such as a neural network. This would involve training the algorithm on a large dataset of labeled examples of text, where the label is the part of speech (e.g. noun, verb, adjective) and its definition. The algorithm would learn to predict the part of speech and definition based on the input text.\"), mdx(\"p\", null, \"Another approach would be to use unsupervised learning methods such as topic modeling, where the algorithm would be able to identify the latent topics represented by the words and its definition.\"), mdx(\"p\", null, \"Additionally, it's important to note that this is a big task and it would require a lot of computational power and time to process the data, and might require a team of experts in the field of NLP and machine learning to implement it.\"), mdx(\"p\", null, \"Once you have the model, it can be used to automatically classify new words and phrases and generate the top-level ontology for RDF and RDFS. This would allow you to automatically generate RDF ontologies that are more accurate and comprehensive than those created by manual annotation.\"), mdx(\"p\", null, \"Another approach to achieve this would be to use a combination of rule-based and machine learning methods. In this approach, a set of rules would be manually defined to extract information about the usage and meaning of words in the dictionary. These rules would be based on the grammar and syntax of the English language, and would be used to identify and classify words based on their part of speech and definition.\"), mdx(\"p\", null, \"The rule-based system would be used as a pre-processing step to extract the information, and then a machine learning model would be trained on this pre-processed data to improve the accuracy of the classification.\"), mdx(\"p\", null, \"It's also worth mentioning that it's important to have a large, diverse and representative dataset to train the model on, so that the model can generalize well to unseen data.\"), mdx(\"p\", null, \"Additionally, you may want to consider using pre-trained language models like BERT, RoBERTa, GPT-3, etc, that have been trained on large amounts of text data and can be fine-tuned to perform the specific task of part-of-speech tagging and definition extraction.\"), mdx(\"p\", null, \"Once you have the model, it can be used to automatically classify new words and phrases and generate the top-level ontology for RDF and RDFS. This would allow you to automatically generate RDF ontologies that are more accurate and comprehensive than those created by manual annotation.\"), mdx(\"p\", null, \"Another approach to achieve this would be to use a combination of rule-based and machine learning methods. In this approach, a set of rules would be manually defined to extract information about the usage and meaning of words in the dictionary. These rules would be based on the grammar and syntax of the English language, and would be used to identify and classify words based on their part of speech and definition.\"), mdx(\"p\", null, \"The rule-based system would be used as a pre-processing step to extract the information, and then a machine learning model would be trained on this pre-processed data to improve the accuracy of the classification.\"), mdx(\"p\", null, \"It's also worth mentioning that it's important to have a large, diverse and representative dataset to train the model on, so that the model can generalize well to unseen data.\"), mdx(\"p\", null, \"Additionally, you may want to consider using pre-trained language models like BERT, RoBERTa, GPT-3, etc, that have been trained on large amounts of text data and can be fine-tuned to perform the specific task of part-of-speech tagging and definition extraction.\"), mdx(\"p\", null, \"Once you have the model, it can be used to automatically classify new words and phrases and generate the top-level ontology for RDF and RDFS. This would allow you to automatically generate RDF ontologies that are more accurate and comprehensive than those created by manual annotation.\"), mdx(\"p\", null, \"It's also important to note that once you have the top level ontology, It's important to validate the ontology by testing it on a sample data set, and check for any errors, inconsistencies or missing information, and make adjustments accordingly.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"my Question: Can the English Vocabulary be expressed mathematically?\"))), mdx(\"p\", null, \"The English vocabulary can be expressed mathematically to some extent, but it's important to note that natural language is a complex phenomenon and not all aspects of it can be fully captured by mathematical representation.\"), mdx(\"p\", null, \"One way to express the English vocabulary mathematically is by using mathematical models such as probability and statistics. For example, it's possible to use probability distributions to model the likelihood of different words appearing in a given context, and to use statistical methods to analyze the relationships between different words and their meanings.\"), mdx(\"p\", null, \"Another way to express the English vocabulary mathematically is by using formal language theory, which is a branch of theoretical computer science. Formal languages are a mathematical abstraction of natural languages and can be described using mathematical notation, such as regular expressions, context-free grammars, and formal languages. These formal languages provide a mathematical framework for describing the syntax and structure of natural languages.\"), mdx(\"p\", null, \"Additionally, it's possible to use mathematical models such as vector spaces and tensor representations to represent words and phrases, and to use mathematical operations such as matrix multiplication and dot product to perform operations such as similarity, analogy, and relationship between words.\"), mdx(\"p\", null, \"In summary, while it's possible to express the English vocabulary mathematically to some extent, natural language is a complex phenomenon and not all aspects of it can be fully captured by mathematical representation, and it's important to use a combination of mathematical and computational models to represent natural languages.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"My Question: What are the ontological rules for the english language?\"))), mdx(\"p\", null, \"Ontological rules are guidelines for organizing and structuring knowledge in a specific domain. In the context of the English language, ontological rules would be guidelines for how to organize and structure the vocabulary and grammar of the language in a consistent and logical way.\"), mdx(\"p\", null, \"There are several different ontological frameworks that have been proposed for the English language. Some examples include:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://wordnet-rdf.princeton.edu/\"\n  }, \"WordNet\"), \": This is a lexical database that organizes English words into sets of synonyms (synsets) and describes the relationships between them. WordNet provides a hierarchical structure for the English vocabulary, with nouns, verbs, adjectives, and adverbs arranged in a tree-like structure.\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://framenet.icsi.berkeley.edu/fndrupal/\"\n  }, \"FrameNet\"), \": This is a lexical database that organizes English words into frames, which are sets of words that are related to a specific concept or event. FrameNet provides a way to organize the English vocabulary based on the roles that words play in different situations.\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Cyc\"\n  }, \"Cyc\"), \": This is a large-scale ontology that organizes knowledge about the world in a hierarchical and logical way. Cyc includes a large number of concepts and relations, and provides a framework for organizing the English vocabulary in a consistent and logical way.\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.ontologyportal.org/\"\n  }, \"SUMO\"), \": This is a large-scale ontology that organizes knowledge in a hierarchical and logical way. SUMO provides a framework for organizing the English vocabulary in a consistent and logical way, and includes a large number of concepts and relations.\"))), mdx(\"p\", null, \"\", mdx(\"img\", {\n    parentName: \"p\",\n    \"src\": \"/95680cbb7bd85236ea24bc6f677c79a6/SUMOMILO.gif\",\n    \"title\": \"SUMOMILO.gif\"\n  }), \"\\nImageSource: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.ontologyportal.org/\"\n  }, \"Ontology Portal\")), mdx(\"ol\", {\n    \"start\": 5\n  }, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"OntoWordNet: This is an ontology that is based on WordNet, but it provides a more formal and logical structure for the English vocabulary. It organizes words in a hierarchical structure and provides formal definitions and axioms for the concepts represented by the words.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The General English Ontology (GEO): This is an ontology that provides a general structure for organizing the English vocabulary in a consistent and logical way. The GEO provides a high-level structure for organizing concepts and relationships, and it has been used in a variety of NLP and AI applications.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The OpenCyc: An open-source version of the Cyc ontology, it's a large-scale ontology that organizes knowledge about the world in a hierarchical and logical way. It includes a large number of concepts and relations, and provides a framework for organizing the English vocabulary in a consistent and logical way.\")), mdx(\"p\", null, \"It's important to note that these ontologies and frameworks are not mutually exclusive and they can work together in a complementary way. Additionally, these ontologies are continuously being updated and improved by the community of researchers and practitioners.\"), mdx(\"p\", null, \"In summary, ontological rules for the English language are guidelines for organizing and structuring the vocabulary and grammar of the language in a consistent and logical way. There are different ontological frameworks that have been proposed for the English language, such as WordNet, FrameNet, Cyc, SUMO, OntoWordNet, GEO, and OpenCyc, each with its own strengths and weaknesses and they are continuously being updated and improved by the community.\"), mdx(\"p\", null, \"It's worth noting that these ontologies were created by experts in the field, and they are widely used in NLP and AI applications.\"), mdx(\"p\", null, \"In summary, ontological rules for the English language are guidelines for organizing and structuring the vocabulary and grammar of the language in a consistent and logical way, and there are different ontological frameworks that have been proposed for the English language such as WordNet, FrameNet, Cyc, SUMO, etc.\"), mdx(\"p\", null, \"NOTES:\\nOntoWordNet LINKS\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://lists.w3.org/Archives/Public/public-swbp-wg/2005Feb/0066.html\"\n  }, \"https://lists.w3.org/Archives/Public/public-swbp-wg/2005Feb/0066.html\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.w3.org/2001/sw/BestPractices/WNET/\"\n  }, \"https://www.w3.org/2001/sw/BestPractices/WNET/\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://wordnet-rdf.princeton.edu/\"\n  }, \"http://wordnet-rdf.princeton.edu/\"), \"\\nOther links\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://babelnet.org/\"\n  }, \"https://babelnet.org/\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/ontologyportal/sumo\"\n  }, \"https://github.com/ontologyportal/sumo\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://wordnet-rdf.princeton.edu/about\"\n  }, \"http://wordnet-rdf.princeton.edu/about\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://wordnet-rdf.princeton.edu/\"\n  }, \"http://wordnet-rdf.princeton.edu/\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://old.datahub.io/dataset/opencyc\"\n  }, \"https://old.datahub.io/dataset/opencyc\"), \" is unavailable;  a version of it has been found: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/asanchez75/opencyc/blob/master/opencyc-latest.owl.gz\"\n  }, \"https://github.com/asanchez75/opencyc/blob/master/opencyc-latest.owl.gz\"), \" \"), mdx(\"p\", null, \"noteAlso: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.wordsapi.com/\"\n  }, \"https://www.wordsapi.com/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"My Question:\\nnote; my objective is to specifically seek to maintain the proper use of terms defined using english words. This is distinct to the creation of software that might seek to support NLP related processes for sentences and broader documents. Now Therefore; When defining a high-level schema to describe the logical use of an english term or a group of english terms that are used in camelCase to define an ontological class, subclass, property, relation or datatype; what terms should be used to define the logical use of english terms for the purpose of defining an RDFS ontology document?\"))), mdx(\"p\", null, \"ChatGPT Answer:\"), mdx(\"p\", null, \"When defining a high-level schema to describe the logical use of English terms for the purpose of defining an RDFS ontology document, it's important to use terms that are clear, consistent, and aligned with existing ontologies and standards.\"), mdx(\"p\", null, \"Here are some terms that you may consider using when defining the schema:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Class: A class is a category of things or concepts that share common characteristics. In the context of an RDFS ontology, classes are used to group together resources that have similar properties and relationships.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Subclass: A subclass is a category of things or concepts that are more specific than a general class. In the context of an RDFS ontology, subclasses are used to group together resources that have more specific properties and relationships than a general class.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Property: A property is a characteristic or attribute of a class or individual resource. In the context of an RDFS ontology, properties are used to describe the relationships between classes and individuals.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Relation: A relation is a connection or association between classes or individuals. In the context of an RDFS ontology, relations are used to describe the relationships between classes and individuals.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Datatype: A datatype is a specific type of data, such as a string, integer, or date. In the context of an RDFS ontology, datatypes are used to specify the type of data that a property can hold.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"URI: A URI (Uniform Resource Identifier) is a string of characters that identify a name or a resource on the Internet. In the context of an RDFS ontology, URIs are used to identify and reference classes, properties, and individuals in the ontology.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"RDFS: RDF Schema is a set of classes and properties that provide a vocabulary for expressing constraints on RDF statements.\")), mdx(\"p\", null, \"It's also important to note that when defining the schema, you should use camelCase to define the ontological class, subclass, property, relation, or datatype, as it's one of the conventions followed in RDFS ontologies.\"), mdx(\"p\", null, \"In summary, when defining a high-level schema to describe the logical use of English terms for the purpose of defining an RDFS ontology document, it's important to use terms such as Class, Subclass, Property, Relation, Datatype, URI, RDFS and to use camelCase to define the ontological class, subclass, property, relation, or datatype.\"), mdx(\"p\", null, \"Another important aspect to consider when defining the high-level schema is to align it with existing ontologies and standards. This will make it easier to integrate the ontology with other systems and to ensure that it is consistent with the existing knowledge representation practices.\"), mdx(\"p\", null, \"Some examples of existing ontologies and standards that you may consider aligning your schema with include:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"OWL (Web Ontology Language): OWL is a standard for representing ontologies on the web. It provides a rich set of constructs for describing classes, properties, individuals, and relationships.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"RDF (Resource Description Framework): RDF is a standard for representing information on the web. It provides a way to describe resources and their relationships in a machine-readable format.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"RDFS (RDF Schema): RDFS is a standard for defining vocabularies and constraints on RDF statements. It provides a set of classes and properties that can be used to define the structure of an ontology.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"SKOS (Simple Knowledge Organization System): SKOS is a standard for representing knowledge organization systems, such as thesauri, taxonomies, and other types of controlled vocabularies.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"DC (Dublin Core): DC is a set of 15 properties that can be used to describe resources in a simple, standard way.\")), mdx(\"p\", null, \"By aligning the schema with existing ontologies and standards, you can ensure that the ontology is consistent with the existing knowledge representation practices and it can be easily integrated with other systems.\"), mdx(\"p\", null, \"In summary, when defining a high-level schema to describe the logical use of English terms for the purpose of defining an RDFS ontology document, it's important to use terms such as Class, Subclass, Property, Relation, Datatype, URI, RDFS and to use camelCase to define the ontological class, subclass, property, relation, or datatype. Additionally, aligning the schema with existing ontologies and standards can ensure that the ontology is consistent with the existing knowledge representation practices and it can be easily integrated with other systems.\"), mdx(\"p\", null, \"The only existing ontologies and standards that i want to align the method with is RDF and RDFS. In this case, describe an ontology that provides the constructs for describing the logic of an english dictionary in N3\"), mdx(\"p\", null, \"An ontology that provides the constructs for describing the logic of an English dictionary in N3 (Notation3) using RDF and RDFS could be organized as follows:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Classes: The ontology would define classes for different types of words, such as nouns, verbs, adjectives, and adverbs. These classes would be used to group together resources that have similar properties and relationships.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Properties: The ontology would define properties for describing the characteristics of words, such as their part of speech, definition, and examples of usage. These properties would be used to describe the relationships between classes and individuals.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Relations: The ontology would define relations for describing the connections or associations between words, such as synonyms and antonyms. These relations would be used to describe the relationships between classes and individuals.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Individuals: The ontology would define individuals for each word in the dictionary, with each individual having properties such as part of speech, definition, and examples of usage.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"RDFS: The ontology would use RDFS to define the class hierarchy, properties and restrictions.\")), mdx(\"p\", null, \"Here is an example of how a word \\\"Apple\\\" could be represented in N3 using RDF and RDFS:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"@prefix rdf: [http://www.w3.org/1999/02/22-rdf-syntax-ns#](http://www.w3.org/1999/02/22-rdf-syntax-ns#) . @prefix rdfs: [http://www.w3.org/2000/01/rdf-schema#](http://www.w3.org/2000/01/rdf-schema#) . @prefix dic: [http://example.com/dictionary#](http://example.com/dictionary#) .\\n\\n\")), mdx(\"p\", null, \"dic:Apple a dic:Noun ; rdfs:label \\\"Apple\\\" ; dic:definition \\\"a round fruit with a red, green or yellow skin and a core of small seeds in the middle\\\" ; dic:example \\\"An apple a day keeps the doctor away.\\\" .\"), mdx(\"p\", null, \"In this example, the class \\\"Noun\\\" is defined as a subclass of rdfs:Class, the individual \\\"Apple\\\" is defined as an instance of the class \\\"Noun\\\", and it has properties such as definition and example of usage. The prefix dic: is used to identify the namespace of the ontology, and the properties and classes are defined using the dic: namespace.\"), mdx(\"p\", null, \"Additionally, the ontology could include additional classes and properties to represent more specific information about the words, such as the tense of verbs, singular and plural forms of nouns, comparative and superlative forms of adjectives, etc.\"), mdx(\"p\", null, \"It's also worth noting that, in order to make the ontology more expressive, it can use some additional RDFS constructs such as RDFS:subClassOf, RDFS:domain, RDFS:range, RDFS:subPropertyOf, etc.\"), mdx(\"p\", null, \"Additionally, it's important to note that RDF and RDFS are quite flexible and can be used to represent a wide range of different ontologies and vocabularies. Therefore, you may want to consider consulting existing ontologies and vocabularies, such as WordNet, FrameNet, and others, to identify the best practices and common patterns for representing the logic of an English dictionary.\"), mdx(\"p\", null, \"In summary, an ontology that provides the constructs for describing the logic of an English dictionary in N3 using RDF and RDFS could be organized by defining classes for different types of words, properties for describing the characteristics of words, relations for describing the connections between words, individuals for each word in the dictionary, and using RDFS to define the class hierarchy, properties, and restrictions. Additionally, it can use additional RDFS constructs and also aligning with existing ontologies and standards can help to make the ontology more expressive and consistent.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"My Question: provide a code example in turtle\"))), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-turtle\"\n  }, \"@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\\n@prefix dic: <http://example.com/dictionary#> .\\n\\ndic:Word rdfs:subClassOf rdfs:Resource .\\ndic:Noun rdfs:subClassOf dic:Word .\\ndic:Verb rdfs:subClassOf dic:Word .\\ndic:Adjective rdfs:subClassOf dic:Word .\\ndic:Adverb rdfs:subClassOf dic:Word .\\n\\ndic:partOfSpeech rdfs:domain dic:Word ;\\n                  rdfs:range rdfs:Literal .\\ndic:definition rdfs:domain dic:Word ;\\n                rdfs:range rdfs:Literal .\\ndic:example rdfs:domain dic:Word ;\\n                rdfs:range rdfs:Literal .\\n\\ndic:synonym rdfs:domain dic:Word ;\\n                rdfs:range dic:Word .\\n\\ndic:Apple a dic:Noun ;\\n\\n\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"My Question:\\nhow can multiple prefixes for the same ontological asset be defined so that the ontology document can be provided over multiple protocols (ie: IPFS, WebTorrent, etc) whilst providing the semantic RDF RDFS requirements to define that the document URIs are referring to the same document?\"))), mdx(\"p\", null, \"ChatGPT Response:\"), mdx(\"p\", null, \"When defining an ontology that will be provided over multiple protocols, such as IPFS and WebTorrent, it's important to ensure that the URIs used to reference the ontology document are consistent across all protocols. One way to achieve this is to use multiple prefixes for the same ontological asset, and to define them in such a way that they all refer to the same document.\"), mdx(\"p\", null, \"Here are a few ways to achieve this:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Use a single prefix and different URI schemes: You can use a single prefix and define different URI schemes for the same ontological asset. For example, you can use the prefix \\\"dic:\\\" to refer to the ontology, and then define the URIs as \\\"dic:Apple\\\" for the web, \\\"ipfs:Qm1234567890\\\" for IPFS, and \\\"webtorrent:abcdefgh\\\" for WebTorrent.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Use multiple prefixes and same URI scheme: You can use multiple prefixes for the same ontological asset, and define them to use the same URI scheme. For example, you can use the prefix \\\"dic:\\\" for the web, \\\"ipfs_dic:\\\" for IPFS, and \\\"webtorrent_dic:\\\" for WebTorrent and then define the URIs as \\\"dic:Apple\\\" for the web, \\\"ipfs_dic:Apple\\\" for IPFS, and \\\"webtorrent_dic:Apple\\\" for WebTorrent.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Linked Data Fragments (LDF) : It's a set of conventions that allows to define multiple URIs for the same resource, which can be identified by different access methods. With LDF, you can use the same URI as the representation of the resource, and it will redirect to the appropriate access method.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Use 303 redirection: Use the HTTP 303 status code to redirect requests for the ontology to the appropriate location, depending on the protocol being used. This allows you to use a single URI for the ontology, but redirect requests to the appropriate location based on the protocol being used.\")), mdx(\"p\", null, \"In summary, when defining an ontology that will be provided over multiple protocols, it's important to ensure that the URIs used to reference the ontology document are consistent across all protocols. This can be achieved by using a single prefix and different URI schemes, using multiple prefixes and same URI scheme, using Linked Data Fragments, or using HTTP 303 redirection.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"My question: Provide an example in turtle\"))), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-turtle\"\n  }, \"\\n@prefix dic: <http://example.com/dictionary#> .\\n@prefix ipfs_dic: <ipfs:Qm1234567890/dictionary#> .\\n@prefix webtorrent_dic: <webtorrent:abcdefgh/dictionary#> .\\n\\ndic:Apple a dic:Noun ;\\n    rdfs:label \\\"Apple\\\" ;\\n    dic:definition \\\"a round fruit with a red, green or yellow skin and a core of small seeds in the middle\\\" ;\\n    dic:example \\\"An apple a day keeps the doctor away.\\\" .\\n\\nipfs_dic:Apple owl:sameAs dic:Apple .\\nwebtorrent_dic:Apple owl:sameAs dic:Apple .\\n\\n\")), mdx(\"p\", null, \"In this example, the same class \\\"Apple\\\" is defined using three different prefixes \\\"dic:\\\", \\\"ipfs_dic:\\\", and \\\"webtorrent_dic:\\\", but they refer to the same resource. Then we use the owl:sameAs property to indicate that those resources are the same.\"), mdx(\"p\", null, \"This way, when the ontology is accessed over IPFS, the URI \\\"ipfs_dic:Apple\\\" can be used to reference the class, and when accessed over WebTorrent, the URI \\\"webtorrent_dic:Apple\\\" can be used instead. And, when accessed over the web, the URI \\\"dic:Apple\\\" can be used.\"), mdx(\"p\", null, \"It's also worth noting that, when using the owl:sameAs property, the ontology will be consistent with OWL 2 standard and it will be able to indicate that resources are identical.\"), mdx(\"p\", null, \"Keep in mind that this is an example, and the URIs used in the example are not valid and it's just for illustration purposes.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"My Question:\\nwhat is a solution that provides the ability to define an ontology document as a version that relates to a collection of ontology documents about the same topic. For example; when seeking to describe a law or legislation, the law may change and the ontology document may be only relavent within a particular period of time. So, in turtle, i want to describe a topic collection (ie: a legislative instrument) and relate versions as described in RDF to specific periods of time and provide an ontological reference to the latest version of that document. How could this be achieved? Provide a solution in turtle\"))), mdx(\"p\", null, \"ChatGPT Answer:\\nIn order to define an ontology document as a version that relates to a collection of ontology documents about the same topic, such as a legislative instrument, you can use the RDF and RDFS constructs to describe the topic collection and relate versions to specific periods of time. Here's an example of how this could be achieved in Turtle:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-Turtle\"\n  }, \"@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\\n@prefix law: <http://example.com/legislation#> .\\n@prefix time: <http://www.w3.org/2006/time#> .\\n\\nlaw:LegislativeInstrument rdfs:subClassOf rdfs:Resource .\\nlaw:Version rdfs:subClassOf rdfs:Resource .\\n\\nlaw:hasVersion rdfs:domain law:LegislativeInstrument ;\\n               rdfs:range law:Version .\\n\\nlaw:validFrom rdfs:domain law:Version ;\\n               rdfs:range time:Instant .\\n\\nlaw:validTo rdfs:domain law:Version ;\\n               rdfs:range time:Instant .\\n\\nlaw:latestVersion rdfs:domain law:LegislativeInstrument ;\\n               rdfs:range law:Version .\\n\\nlaw:LegislativeInstrument1 a law:LegislativeInstrument ;\\n    rdfs:label \\\"Legislative Instrument 1\\\" ;\\n    law:hasVersion law:Version1, law:Version2, law:Version3 .\\n\\nlaw:Version1 a law:Version ;\\n    rdfs:label \\\"Version 1\\\" ;\\n    law:validFrom \\\"2022-01-01T00:00:00Z\\\"^^time:Instant ;\\n    law:validTo \\\"2022-12-31T23:59:59Z\\\"^^time:Instant .\\n\\nlaw:Version2 a law:Version ;\\n    rdfs:label \\\"Version 2\\\" ;\\n    law:validFrom \\\"2023-01-01T00:00:00Z\\\"^^time:Instant ;\\n    law:validTo \\\"2023-12-31T23:59:59Z\\\"^^time:Instant .\\n\\nlaw:Version3 a law:Version ;\\n    rdfs:label \\\"Version 3\\\" ;\\n    law:validFrom \\\"2024-01-01T00:00:00Z\\\"^^time:Instant ;\\n    law:validTo \\\"2024-12-31T23:59:59Z\\\"^^time:Instant .\\n\\nlaw:LegislativeInstrument1 law:latestVersion law:Version3 .\\n\\n\")), mdx(\"p\", null, \"In this example, the class \\\"LegislativeInstrument\\\" is defined as a subclass of \\\"Resource\\\", and the class \\\"Version\\\" is defined as a subclass of \\\"Resource\\\" as well. The property \\\"hasVersion\\\" is defined to relate the \\\"LegislativeInstrument\\\" class with the \\\"Version\\\" class. The property \\\"validFrom\\\" and \\\"validTo\\\" are defined to indicate the time range when the version is valid. Finally, the property \\\"latestVersion\\\" is used to indicate the latest version of the legislative instrument.\"), mdx(\"p\", null, \"Here, the specific legislative instrument \\\"LegislativeInstrument1\\\" is defined with three versions \\\"Version1\\\", \\\"Version2\\\" and \\\"Version3\\\". Each version is defined with properties \\\"validFrom\\\" and \\\"validTo\\\" indicating the time range when the version is valid. The latest version \\\"Version3\\\" is indicated using the property \\\"latestVersion\\\".\"), mdx(\"p\", null, \"This way, by using the RDF and RDFS constructs, you can describe the topic collection of a legislative instrument and relate versions to specific periods of time. And also, you can specify the latest version of that document and it will be easy to identify it.\"), mdx(\"p\", null, \"It's worth noting that in this example, I've used the time ontology (time:) to define the time range but you can use other ways to represent time, such as using xsd:dateTime.\"), mdx(\"p\", null, \"It's also worth noting that this is an example, and the URIs and values used in the example are not valid and it's just for illustration purposes.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"My Question:\\nhow can a cryptographic signature be generated on an RDF document to enable a parser to validate whether or not the document has been altered?\"))), mdx(\"p\", null, \"A cryptographic signature can be generated on an RDF document to enable a parser to validate whether or not the document has been altered, by using a digital signature algorithm. A digital signature algorithm, such as RSA or ECDSA, can be used to create a digital signature of the RDF document.\"), mdx(\"p\", null, \"Here's an example of how this could be achieved in Turtle:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-turtle\"\n  }, \"\\n@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\\n@prefix dc: <http://purl.org/dc/elements/1.1/> .\\n@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\\n@prefix sig: <http://example.com/signature#> .\\n\\nsig:Signature rdfs:subClassOf rdfs:Resource .\\nsig:signatureValue rdfs:domain sig:Signature ;\\n                  rdfs:range xsd:base64Binary .\\n\\ndc:creator sig:signatureValue \\\"base64 encoded signature value\\\" .\\ndc:date \\\"2022-09-20T19:20:30-05:00\\\"^^xsd:dateTime .\\n\\n\")), mdx(\"p\", null, \"In this example, we defined a new class \\\"Signature\\\" as a subclass of \\\"Resource\\\" and the property \\\"signatureValue\\\" which is defined to relate the \\\"Signature\\\" class with the value of the signature, which is represented as xsd:base64Binary. Additionally, we use dc:creator and dc:date properties to indicate the signature creator and the date when the signature was generated.\"), mdx(\"p\", null, \"This way, the parser can use the public key of the signature creator to verify the signature value, and check if the document has been altered.\"), mdx(\"p\", null, \"It's important to keep in mind that this is just an example, and in real-world scenarios, the signature should be generated using proper libraries and tools that implement the desired digital signature algorithm. And also it's important to use secure key management techniques to protect the private key.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"my Question;\\nHow do i define a cuDNN training model to process an english dictionary for the purpose of using the vocabulary to define RDF / RDFS ontologies, that do not use OWL\")), mdx(\"p\", null, \"ChatGPT Answer:\"), mdx(\"p\", null, \"The cuDNN library is a GPU-accelerated library for deep neural networks, and it can be used to train models for various tasks such as image classification, natural language processing, and speech recognition.\"), mdx(\"p\", null, \"To define a cuDNN training model to process an English dictionary for the purpose of using the vocabulary to define RDF/RDFS ontologies, you would need to:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Prepare the data: This would involve preprocessing the English dictionary to extract the vocabulary and related information such as part of speech, definition, etc. and format it into a format suitable for training a neural network.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Define the model architecture: This would involve choosing a suitable model architecture that can handle the task of vocabulary extraction, such as a recurrent neural network (RNN) or a transformer-based model.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Train the model: This would involve using cuDNN to train the model on the preprocessed data, using techniques such as backpropagation and stochastic gradient descent.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Use the trained model: Once the model is trained, you can use it to extract vocabulary from new texts and use it to define RDF/RDFS ontologies.\")), mdx(\"p\", null, \"It's worth noting that creating an ontology from text is a complex task, and the final ontology will depend on the specific use case and the ontology model that you choose to represent the vocabulary. Additionally, it's also important to note that using cuDNN for this task is not the most common way, as it's a powerful library that is mostly used for deep learning tasks. There are other libraries and models that might be more suitable for this kind of task, like word2vec, GloVe, or BERT.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"My Question:\\n\", mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"provide an example of preparing hte data in golang and include the syntactic field to define \\\"parts of speech\\\" to distinguish whether a word definition relates to the use of that word in the form of a NOUN, PRONOUN, VERB, ADJECTIVE, ADVERB, PREPOSITION, CONJUNCTION or INTERJECTION.\"))), mdx(\"p\", null, \"Here's an example of how you could prepare the data in Go for a model that aims to distinguish whether a word definition relates to the use of that word in the form of a NOUN, PRONOUN, VERB, ADJECTIVE, ADVERB, PREPOSITION, CONJUNCTION or INTERJECTION:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-go\"\n  }, \"package main\\n\\nimport (\\n    \\\"encoding/json\\\"\\n    \\\"os\\\"\\n)\\n\\ntype Vocab struct {\\n    Word       string `json:\\\"word\\\"`\\n    POS        string `json:\\\"pos\\\"`\\n    Definition string `json:\\\"definition\\\"`\\n}\\n\\nfunc main() {\\n    // load the english dictionary\\n    file, _ := os.Open(\\\"english_dictionary.json\\\")\\n    defer file.Close()\\n\\n    var dictionary map[string]interface{}\\n    json.NewDecoder(file).Decode(&dictionary)\\n\\n    // create a slice to store the vocabulary and related information\\n    var vocab []Vocab\\n\\n    // iterate over the dictionary entries\\n    for word, entry := range dictionary {\\n        pos := entry.(map[string]interface{})[\\\"pos\\\"].(string)\\n        definition := entry.(map[string]interface{})[\\\"definition\\\"].(string)\\n\\n        // add the vocabulary and related information to the vocab slice\\n        vocab = append(vocab, Vocab{Word: word, POS: pos, Definition: definition})\\n    }\\n\\n    // save the vocab slice to a file for training\\n    vocabFile, _ := os.Create(\\\"vocab.json\\\")\\n    defer vocabFile.Close()\\n\\n    json.NewEncoder(vocabFile).Encode(voc\\n\\n\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ChatGPT Question:\\nProvide me an example of how to do step 2, using that model in golang using cuDNN\")), mdx(\"p\", null, \"ChatGPT Answer\\nStep 2 of defining a cuDNN training model to process an English dictionary for the purpose of using the vocabulary to define RDF/RDFS ontologies, would involve defining the model architecture.\"), mdx(\"p\", null, \"Here's an example of how you could define a model architecture in Go using cuDNN:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-go\"\n  }, \"package main\\n\\nimport (\\n    \\\"github.com/dereklstinson/GoCUDA\\\"\\n    \\\"github.com/dereklstinson/GoCUDA/cudnn\\\"\\n)\\n\\nfunc main() {\\n    // create a cudnn handle\\n    handle, _ := cudnn.Create()\\n    defer handle.Destroy()\\n\\n    // define the model architecture\\n    // here we will use a simple feedforward neural network with one hidden layer\\n    inputTensor, _ := cudnn.CreateTensorDescriptor()\\n    defer inputTensor.Destroy()\\n    inputTensor.Set(cudnn.DataTypeFloat, []int32{batchSize, inputSize}, []int32{inputSize, 1})\\n\\n    hiddenTensor, _ := cudnn.CreateTensorDescriptor()\\n    defer hiddenTensor.Destroy()\\n    hiddenTensor.Set(cudnn.DataTypeFloat, []int32{batchSize, hiddenSize}, []int32{hiddenSize, 1})\\n\\n    outputTensor, _ := cudnn.CreateTensorDescriptor()\\n    defer outputTensor.Destroy()\\n    outputTensor.Set(cudnn.DataTypeFloat, []int32{batchSize, outputSize}, []int32{outputSize, 1})\\n\\n    filterDesc, _ := cudnn.CreateFilterDescriptor()\\n    defer\\n    filterDesc.Set(cudnn.DataTypeFloat, []int32{hiddenSize, inputSize})\\n\\n    filterData, _ := GoCUDA.Malloc(filterDesc.Size())\\n    defer filterData.Free()\\n\\n    biasDesc, _ := cudnn.CreateTensorDescriptor()\\n    defer biasDesc.Destroy()\\n    biasDesc.Set(cudnn.DataTypeFloat, []int32{hiddenSize}, []int32{hiddenSize, 1})\\n\\n    biasData, _ := GoCUDA.Malloc(biasDesc.Size())\\n    defer biasData.Free()\\n\\n    // initialize the filter and bias data with random values\\n    rand.Read(filterData.Pointer())\\n    rand.Read(biasData.Pointer())\\n\\n    // create the feedforward neural network\\n    _, _ = handle.CreateFeedForward(inputTensor, filterDesc, filterData, biasDesc, biasData, hiddenTensor, outputTensor)\\n}\\n\\n\")), mdx(\"p\", null, \"This code snippet defines a simple feedforward neural network with one hidden layer, and creates a handle to interact with cuDNN library. It creates the tensor descriptor, filter descriptor, and bias descriptor for the input, hidden, and output layers respectively. It also initializes the filter and bias data with random values using the Go's math/rand package.\"), mdx(\"p\", null, \"It's worth noting that this is just an example, and the actual model architecture will depend on the specific requirements of your use case, and it might require more complex architectures. Also, it's important to note that this example uses a library called GoCUDA which is a Go\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"My question: Provide an example of how to do step 3\")), mdx(\"p\", null, \"Step 3 of defining a cuDNN training model to process an English dictionary for the purpose of using the vocabulary to define RDF/RDFS ontologies, would involve training the model using the preprocessed data.\"), mdx(\"p\", null, \"Here's an example of how you could train the model in Go using cuDNN:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-go\"\n  }, \"package main\\n\\nimport (\\n    \\\"github.com/dereklstinson/GoCUDA\\\"\\n    \\\"github.com/dereklstinson/GoCUDA/cudnn\\\"\\n)\\n\\nfunc main() {\\n    // create a cudnn handle\\n    handle, _ := cudnn.Create()\\n    defer handle.Destroy()\\n\\n    // load the preprocessed data\\n    data, _ := GoCUDA.Malloc(dataSize)\\n    defer data.Free()\\n\\n    labels, _ := GoCUDA.Malloc(labelSize)\\n    defer labels.Free()\\n\\n    // set the data and labels\\n    // ...\\n\\n    // set the training parameters\\n    learningRate := 0.01\\n    weightDecay := 0.0005\\n    momentum := 0.9\\n\\n    // train the model\\n    _, _ = handle.Train(data, labels, learningRate, weightDecay, momentum)\\n}\\n\\n\")), mdx(\"p\", null, \"This code snippet loads the preprocessed data, which is the vocabulary and related information extracted from the English dictionary, and the corresponding labels (the part of speech) into memory, and sets the training parameters such as learning rate, weight decay, and momentum. It then uses the cuDNN library to train the model on the data.\"), mdx(\"p\", null, \"It's important to note that this is a simplified example, and the actual training process will depend on the specific requirements of your use case and the model architecture. Also, it's important to note that this example uses a library called GoCUDA which is a Go library that provides bindings for CUDA, but it doesn't provide bindings for cuDNN library.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"My question; provide an example of step 4\")), mdx(\"p\", null, \"Step 4 of defining a cuDNN training model to process an English dictionary for the purpose of using the vocabulary to define RDF/RDFS ontologies, would involve evaluating the model's performance and fine-tuning it as necessary.\"), mdx(\"p\", null, \"Here's an example of how you could evaluate the model's performance and fine-tune it in Go using cuDNN:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-go\"\n  }, \"\\npackage main\\n\\nimport (\\n    \\\"github.com/dereklstinson/GoCUDA\\\"\\n    \\\"github.com/dereklstinson/GoCUDA/cudnn\\\"\\n)\\n\\nfunc main() {\\n    // create a cudnn handle\\n    handle, _ := cudnn.Create()\\n    defer handle.Destroy()\\n\\n    // load the test data\\n    testData, _ := GoCUDA.Malloc(testDataSize)\\n    defer testData.Free()\\n\\n    testLabels, _ := GoCUDA.Malloc(testLabelSize)\\n    defer testLabels.Free()\\n\\n    // set the test data and labels\\n    // ...\\n\\n    // evaluate the model's performance on the test data\\n    accuracy, _ := handle.Evaluate(testData, testLabels)\\n\\n    // print the accuracy\\n    println(\\\"Accuracy:\\\", accuracy)\\n\\n    // fine-tune the model if necessary\\n    if accuracy < desiredAccuracy {\\n        // adjust the training parameters\\n        learningRate *= 0.1\\n        weightDecay *= 0.1\\n\\n        // retrain the model\\n        _, _ = handle.Train(data, labels, learningRate, weightDecay, momentum)\\n    }\\n}\\n\\n\")), mdx(\"p\", null, \"This code snippet loads test data and labels, and uses the cuDNN library to evaluate the model's performance on this test data. It then prints the accuracy, and if the accuracy is below a certain threshold, it adjusts the training parameters and retrains the model.\"), mdx(\"p\", null, \"It's important to note that this is a simplified example, and the actual evaluation and fine-tuning process will depend on the specific requirements of your use case and the model architecture. Also, it's important to note that this example uses a library called GoCUDA which is a Go library that provides bindings for CUDA, but it doesn't provide bindings for cuDNN library.\"), mdx(\"p\", null, \"As I mentioned earlier, there are no Go libraries that provide bindings for cuDNN, which means that using cuDNN in Go is not a straightforward task, and it would require to use CGo to interact with the cuDNN C library, and this will require a deep understanding of both Go and C programming languages.\"), mdx(\"h3\", {\n    \"id\": \"review-and-considerations\"\n  }, \"Review and considerations\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Its seemingly defined using tensorcores.  my laptop doesn't have tensor cores, only cudacores\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"I didn't know much about the existing solutions like wordnet.\")), mdx(\"h3\", {\n    \"id\": \"following-up\"\n  }, \"Following-up\"), mdx(\"p\", null, \"Overnight, i found the various existing NLP libraries that were highlighted earlier, alongside a relatively easy to use example - \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.wordsapi.com/\"\n  }, \"WordsAPI\"), \" that might be the best choice for producing a Proof of Concept to illustrate the general idea.   Yet, any overly simplified solution (as required to materialise something that demonstrates the general idea); will need an upgrade path.  Furthermore, the method of how to form a longer-term strategy is required.  \"), mdx(\"p\", null, \"It is important to note (as i've started to illustrate \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/FunctionalObjectives/RootConcepts/\",\n    \"title\": \"RootConcepts\"\n  }, \"RootConcepts\"), \" ); that this underlying service MUST be able to be operated privately and in a stand-alone manner.  To achieve this solution, the outcome may be that the first time a topic or word is sought to be processed; an API call might be made to go and get the information that's required to be added to the database.  Presently, i'm unsure of the technical implications relating to any methods that are reasonably available to achieve that;  such as - can it run on a mobile phone or laptop?  etc.\"), mdx(\"p\", null, \"As more work continues on the topic (the next day); the below 'work' was produced,\"), mdx(\"h4\", {\n    \"id\": \"chatgpt\"\n  }, \"ChatGPT\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"My Question:\"), \" what are the root languages for the english vocabulary?\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ChatGPT Answer\"), \":\\nThe English vocabulary is made up of words borrowed from many different languages over the centuries. The main root languages of the English vocabulary are:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Germanic: The Germanic languages, including Old English, are the most important source of words in English. They make up around 50% of the words in the English language. Words from Germanic languages include common words such as \\\"house,\\\" \\\"father,\\\" \\\"mother,\\\" \\\"man,\\\" \\\"woman,\\\" \\\"child,\\\" and \\\"dog.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Latin: Latin is the second most important source of words in English. Latin words make up around 30% of the English vocabulary. Many of these words are technical terms in fields such as science, medicine, and law. Words from Latin include \\\"hospital,\\\" \\\"doctor,\\\" \\\"university,\\\" \\\"species,\\\" \\\"algebra,\\\" \\\"formula,\\\" and \\\"jurisdiction.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"French: French is the third most important source of words in English. French words make up around 10% of the English vocabulary. Many French words were borrowed during the Norman Conquest of England in 1066 and the following centuries of Norman rule. Words from French include \\\"money,\\\" \\\"art,\\\" \\\"government,\\\" \\\"justice,\\\" \\\"royalty,\\\" \\\"diamond,\\\" and \\\"restaurant.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Greek: Greek is the fourth most important source of words in English. Greek words make up around 5% of the English vocabulary. Many Greek words were borrowed through Latin, but some were borrowed directly into English. Words from Greek include \\\"philosophy,\\\" \\\"theology,\\\" \\\"anatomy,\\\" \\\"geometry,\\\" \\\"telephone,\\\" \\\"photograph,\\\" and \\\"encyclopedia.\\\"\")), mdx(\"p\", null, \"Other languages that have contributed to the English vocabulary include Arabic, Italian, Spanish, and many others.\"), mdx(\"p\", null, \"In addition to the root languages mentioned above, there are also many other languages that have contributed to the English vocabulary over time. These include:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Arabic: Many Arabic words were borrowed into English through Latin and Greek. Words from Arabic include \\\"algebra,\\\" \\\"alcohol,\\\" \\\"candy,\\\" \\\"jar,\\\" \\\"lemon,\\\" \\\"magazine,\\\" \\\"sofa,\\\" \\\"sugar,\\\" and \\\"zero.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Italian: Words from Italian include \\\"balcony,\\\" \\\"broccoli,\\\" \\\"cappuccino,\\\" \\\"fiasco,\\\" \\\"gazebo,\\\" \\\"grotto,\\\" \\\"paparazzo,\\\" \\\"piano,\\\" \\\"sonata,\\\" and \\\"terrace.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Spanish: Words from Spanish include \\\"alligator,\\\" \\\"barbecue,\\\" \\\"bronco,\\\" \\\"chocolate,\\\" \\\"coyote,\\\" \\\"guerrilla,\\\" \\\"jaguar,\\\" \\\"mosquito,\\\" \\\"mustang,\\\" \\\"patio,\\\" \\\"siesta,\\\" \\\"sombrero,\\\" \\\"taco,\\\" and \\\"tornado.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Native American languages: Words from Native American languages include \\\"chocolate,\\\" \\\"chipmunk,\\\" \\\"moose,\\\" \\\"opossum,\\\" \\\"pecan,\\\" \\\"racoon,\\\" \\\"skunk,\\\" \\\"squash,\\\" \\\"tobacco,\\\" and \\\"tomato.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Asian languages: Words from Asian languages include \\\"bamboo,\\\" \\\"guru,\\\" \\\"karma,\\\" \\\"pajama,\\\" \\\"tycoon,\\\" \\\"yoga,\\\" and \\\"zen.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"African languages: Words from African languages include \\\"banjo,\\\" \\\"jazz,\\\" \\\"okra,\\\" \\\"yam,\\\" and \\\"Zulu.\\\"\")), mdx(\"p\", null, \"It's worth noting that these are just a few examples of the many languages that have contributed to the English vocabulary over time. The English language is known for its rich history of borrowing words from other languages, and this is one of the reasons why it has such a diverse and dynamic vocabulary.\"), mdx(\"p\", null, \"My question: provide an example relating to norse and old norse \"), mdx(\"p\", null, \"Sure, here are a few examples of words that have been borrowed from Old Norse and Norse into the English language:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Anguish\\\" comes from the Old Norse word \\\"angr\\\" meaning \\\"grief\\\" or \\\"sorrow.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Berserk\\\" comes from the Old Norse word \\\"berserkr\\\" meaning \\\"a wild warrior.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Bliss\\\" comes from the Old Norse word \\\"bliss\\\" meaning \\\"happiness.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Eke\\\" means \\\"also\\\" or \\\"additionally\\\" comes from the Old Norse word \\\"eigi\\\" meaning \\\"also\\\" or \\\"in addition.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Eg\\\" meaning \\\"I\\\" from Old Norse \\\"eg\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Fjord\\\" comes from the Old Norse word \\\"fj\\xF6r\\xF0r\\\" meaning \\\"a narrow inlet of the sea.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Knurl\\\" comes from the Old Norse word \\\"knurr\\\" meaning \\\"a small knot or knob.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Mist\\\" comes from the Old Norse word \\\"mist\\\" meaning \\\"moisture.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Ransack\\\" comes from the Old Norse word \\\"rannsaka\\\" meaning \\\"to search through.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Scowl\\\" comes from the Old Norse word \\\"skul\\\" meaning \\\"a face with a frown.\\\"\")), mdx(\"p\", null, \"It is worth noting that the Norse and Old Norse languages are closely related, and the vast majority of words borrowed into English from Old Norse came directly or indirectly from Norse. Norse is also known as Old Icelandic, it is a Germanic language that was spoken by the Vikings and other inhabitants of the Norse regions of Scandinavia and the North Atlantic islands in the Middle Ages.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"My question: what benefit might the use of a neuromorphic processer provide for processing a natural language model?\")), \"  (note: that was part of the question)\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ChatGPT:\"), \"\\nA neuromorphic processor is a type of computer processor that is designed to mimic the way the human brain works. These processors use artificial neural networks, which are modeled after the structure and function of the human brain, to perform tasks such as pattern recognition and decision-making.\"), mdx(\"p\", null, \"The use of a neuromorphic processor for processing a natural language model could provide several benefits.\"), mdx(\"p\", null, \"-Neuromorphic processors are highly energy-efficient, which makes them well-suited for running large-scale natural language processing models on mobile or embedded devices.\"), mdx(\"p\", null, \"-Neuromorphic processors are also highly parallel, which means they can perform multiple computations simultaneously. This can lead to faster and more efficient processing of natural language models, as well as the ability to handle larger models.\"), mdx(\"p\", null, \"-Neuromorphic processors are also highly adaptable and can learn from new data, which means they can improve their performance over time. This can be particularly useful for natural language processing, as the meaning and usage of words and phrases can change over time, and a model that can adapt to these changes will be more accurate and useful.\"), mdx(\"p\", null, \"-Neuromorphic processors can also be more robust to noise, errors and variations in the data, which can be common in natural language data.\"), mdx(\"p\", null, \"It's worth mentioning that the field of neuromorphic computing and Neuromorphic processors are relatively new and still in development, and more research is needed to fully understand their potential benefits and limitations.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"My Question: what is the earliest known time the english language was first used?\"))), mdx(\"p\", null, \"ChatGPT: \"), mdx(\"p\", null, \"The earliest known use of the English language dates back to the 5th century AD, when Germanic tribes, such as the Angles, Saxons, and Jutes, began to migrate to the island of Great Britain and settled there. These tribes spoke a Germanic language, which over time evolved into Old English.\"), mdx(\"p\", null, \"Old English, also known as Anglo-Saxon, was the language spoken in England from the 5th century to the Norman conquest in 1066 AD. Old English is considered to be the earliest form of the English language, and it was written in the runic alphabet, which was later replaced by the Latin alphabet.\"), mdx(\"p\", null, \"Old English was a complex and inflected language, with a rich vocabulary and many grammatical features. However, it was quite different from the English spoken today and would be difficult for modern speakers to understand without study or translation.\"), mdx(\"p\", null, \"It's worth mentioning that the Angles, Saxons, and Jutes were not the only people that were in Great Britain during this time, there were also the Celts, and others, and they were speaking different languages, and the Germanic language of the invaders slowly replaced the Celtic languages and others, it took several centuries to form the language we know today as English.\"));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/WebizenTechStack/LanguageModelling/ChatGPTDynamicOntology/","title":"Dynamic Ontology","shouldShowTitle":false}},{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"agent-labelling\"\n  }, \"Agent Labelling\"), mdx(\"p\", null, \"It is important that there is a clear means to distinguish between the content, information or processes and decisions that are made by Software Agents (AI) Vs. those made by legal entities; and in-turn also, the ability to dertermine which specific human beings were involved in many or causing any sort of causality related action to occur.\"), mdx(\"p\", null, \"Asking ChatGPT;\"), mdx(\"p\", null, \"My Question:\\nWhat are the sorts of dangers, threats and social attack vectors that may occur if human beings are falsely led to believe they are consuming the work of other human beings or legal entities; when in-fact they're consuming information generated via an artificial intelligence software program?\"), mdx(\"p\", null, \"ChatGPT Answer:\\n\", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"There are several dangers and threats that may occur if individuals are falsely led to believe that they are consuming information generated by other human beings or legal entities when it is actually generated by an artificial intelligence (AI) program. Some of these include:\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Misinformation and disinformation: AI-generated content can be used to spread false or misleading information, which can have negative effects on individuals and society at large.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Manipulation and influence: AI-generated content can be used to manipulate individuals and groups by appealing to their emotions, biases, and prejudices.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Privacy and security concerns: AI-generated content can be used to target individuals with personalized phishing, scams, and other malicious attacks.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Dehumanization and mistrust: People being exposed to AI generated content that is falsely presented as being generated by human could lead to mistrust in human-generated content, leading towards a dehumanization of human expression as well as a mistrust in human-generated content, AI-generated content can be used to perpetuate stereotypes and reinforce societal biases.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Interfere with legal process: AI-generated content can be used to impersonate people or entities for fraudulent activities or illegal activities and could interfere with legal proceedings.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Overall, it is important for individuals to be able to distinguish between AI-generated content and human-generated content in order to make informed decisions and to protect themselves from potential dangers.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Another potential danger of falsely believing that information is generated by human beings when it is actually generated by AI is that it may lead to a lack of critical thinking and evaluation of the information being consumed. If people believe that the information they are consuming is coming from a trusted source, they may be less likely to fact-check or critically evaluate it. This can lead to the spread of misinformation and disinformation, as well as a decrease in people's ability to make well-informed decisions.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Additionally, there may be ethical concerns associated with the use of AI-generated content, particularly when it is used to impersonate human beings or legal entities. The ability to generate content that is indistinguishable from human-generated content raises questions about consent and accountability, as well as potential harms that may be caused by the use of this technology.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Finally, the widespread use of AI-generated content has the potential to disrupt various industries and change the way people think about and interact with information. It could change how professional authors, journalists, and creative professionals work, which could have both positive and negative impacts on the economy and society.\")), mdx(\"p\", null, \"My Question:\\nWhat are some of the threats related to circumstances where government departments and/or employees may use Artificial Intelligence to act in a manner that has human rights implications in relation to the effect of those actions if it is not clearly labelled to have been done via an AI Agent?\"), mdx(\"p\", null, \"ChatGPT Answer: \"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"If government departments or employees use Artificial Intelligence (AI) in a way that has human rights implications and it is not clearly labeled as having been done by an AI agent, there could be several threats. Some of these include:\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"em\", {\n    parentName: \"li\"\n  }, \"Discrimination and bias: If an AI system is not transparent in its decision-making processes, it may perpetuate discrimination and bias against certain individuals or groups, potentially violating their human rights.\"))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"-   Lack of accountability: If an AI system is used to make decisions or take actions that have human rights implications, it can be difficult to hold individuals or organizations accountable if the system is not clearly labeled as an AI agent and its decision-making process is opaque.\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"em\", {\n    parentName: \"li\"\n  }, \"Due process concerns: If an AI system is used to make decisions that affect an individual's rights or freedoms, it may not always provide the same level of due process protections as a human decision-maker. This could lead to violations of human rights and the rule of law.\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"em\", {\n    parentName: \"li\"\n  }, \"Privacy and security: If an AI system is used to process personal data without proper regulation or oversight, it could lead to privacy violations, security breaches, and other harms.\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"em\", {\n    parentName: \"li\"\n  }, \"Lack of transparency: If the actions of an AI agent is not clearly labeled, it can make it difficult for people to understand how decisions are being made, which could lead to mistrust and lack of transparency.\"))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"-   Interference with human autonomy: If an AI agent make decisions that have significant impact on human life, people may lose their autonomy on the decision making process and their right to self-determination.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Overall, it is crucial that government departments and employees are transparent in their use of AI, clearly label any decisions or actions that are made by an AI agent, and ensure that the AI systems they use are fair, accountable, and respect human rights.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Another potential threat is that the AI may have unintended consequences on human rights, if it not properly implemented, tested, and monitored. Even if the AI system is not inherently biased, the data it is trained on may be biased, leading to unjust outcomes.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Additionally, if the use of AI is not transparent and the decision-making processes of the AI system are not explainable, it may be difficult for people to understand how the decisions are being made and to challenge them if they believe that their human rights are being violated.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Moreover, if AI agents are used in law enforcement or security, without proper oversight or regulation, there could be a risk that the AI systems may be used to infringe on individuals\\u2019 rights, such as freedom of speech and freedom of assembly, or to target certain groups based on their ethnicity, religion, or political beliefs.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"It is important that the use of AI by government departments and employees is subject to proper regulation and oversight, so that human rights are protected and that the actions of the AI systems can be transparently tracked and audited.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Finally, It is crucial that the AI system are continuously monitored and evaluated for their impacts on human rights and adjustments or replacements are made if necessary\"), \".\"), mdx(\"p\", null, \"My Question:\\nwhat are some of the potential risks in circumstances relating to foreign governments? \"), mdx(\"p\", null, \"ChatGPT Answer:\"), mdx(\"p\", null, \"There are several potential risks in circumstances related to foreign governments using AI:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Cyber espionage: Foreign governments may use AI to conduct cyber espionage or cyberattacks against other countries, potentially stealing sensitive information or disrupting critical infrastructure.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Misinformation and disinformation: Foreign governments may use AI-generated content to spread false or misleading information, with the intention of manipulating public opinion or undermining the credibility of other governments.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Interference in domestic politics: Foreign governments may use AI to interfere in the domestic politics of other countries, with the goal of swaying elections or influencing policy decisions.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Economic espionage: Foreign governments may use AI to gain an unfair advantage in international trade, by collecting business intelligence and targeting specific industries or companies.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Military advantage: Foreign governments may use AI to enhance their military capabilities, potentially threatening the stability of regions and global security\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Human Rights abuse: AI technology has been used by some governments to track and control their citizens, violating their privacy and freedom. This technology can also be used to identify and monitor individuals based on their ethnicity, religion, or political beliefs, leading to further human rights violations.\")), mdx(\"p\", null, \"Overall, the use of AI by foreign governments has the potential to destabilize international relations and threaten the security and sovereignty of other countries. It is important for governments to be aware of these risks and to take steps to protect against them, through international cooperation, regulation, and diplomacy.\"), mdx(\"p\", null, \"Another potential risk is that foreign governments may use AI in a way that violates international law or human rights. For example, they may use AI-enabled surveillance to target political opponents, or use autonomous weapons to target civilians in warfare. These actions can have significant negative consequences on human rights and global security.\"), mdx(\"p\", null, \"Moreover, the increasing use of AI in economic and technological fields may lead to a power imbalance between countries that have access to advanced AI technology and those that do not, leading to further economic and societal inequality.\"), mdx(\"p\", null, \"Furthermore, if AI is not controlled and regulated properly, foreign governments may use it to violate international norms, such as economic sanctions or arms control agreements.\"), mdx(\"p\", null, \"Lastly, foreign governments may also use AI to target individuals, companies or countries with cyber-attacks and disinformation campaigns for political, economic, or military gain.\"), mdx(\"p\", null, \"To mitigate these risks, it is crucial for countries to work together through international organizations and agreements to establish norms and regulations for the responsible development and use of AI, as well as to cooperate on matters of cyber security, disinformation, and human rights.\"), mdx(\"p\", null, \"My Question:\"), mdx(\"p\", null, \"What are some of the ways AI content and/or software actions could be clearly labelled and associated with the legal entity involved and responsible for that AI content and/or software action, including both any legal personality (ie: government department, institution, corporation or business, ) as well as the specific natural legal entities / individuals (human beings) who were instrumentally involved in enabling or rendering the applied use of AI for the particular artifact or event?\"), mdx(\"p\", null, \"ChatGPT Answer;\"), mdx(\"p\", null, \"There are several ways that AI content and/or software actions can be clearly labeled and associated with the legal entity responsible for them, including both the legal personality (e.g. government department, institution, corporation or business) and the specific natural legal entities/individuals who were involved in enabling or using the AI for the particular artifact or event. Some of these methods include:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Digital Signatures: Using digital signatures to verify the authenticity of AI content or software actions, and to link them to the legal entity or individual responsible for them.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Attribution Statements: Including an attribution statement in the AI content or software that identifies the legal entity or individual responsible for it.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Watermarking: Watermarking AI content or software with unique identifiers that can be used to trace it back to the legal entity or individual responsible for it.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Logging: Keeping detailed logs of who had access to and used the AI system, and what actions they took.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Transparency Reports: Publishing transparency reports that provide information on the legal entities and individuals involved in the development and use of AI, as well as the system's decision-making processes and any human rights considerations.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Certifications: Certifying the AI system by a third-party, that verifies that the system meets certain standards, such as fairness and transparency\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Source codes or system architecture: Making the source codes or system architecture of AI systems available for public inspection, in order for third parties to verify how the systems make decisions.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Human oversight: Ensuring that AI systems are designed with human oversight and decision-making capabilities to make adjustments or corrections if necessary, and keeping records of those adjustments or corrections.\")), mdx(\"p\", null, \"Overall, it is important to ensure that the AI system are clearly labeled and that the legal entity or individual responsible for the system is easily identifiable and can be held accountable for its actions. This can be achieved through a combination of technical and organizational measures, such as the ones listed above, which should be chosen according to the specific context and the potential impacts of the system.\"), mdx(\"p\", null, \"Another way of clearly labelling AI content and/or software actions and associating them with the legal entity responsible for them, is by using blockchain technology, it can enable the creation of an immutable and transparent record of the origin and usage of the AI content or software. This can enable users to verify the authenticity of the content and trace it back to the legal entity or individual that created it, providing a tamper-proof record of the development and usage of the AI system.\"), mdx(\"p\", null, \"Another approach to clearly identify the responsible entity is by using standard data labels, like the \\\"metadata\\\" of digital files, AI artifacts should also have standard labels that clearly identify the legal entity or individual responsible for them, such as the developer, creator, owner, or operator.\"), mdx(\"p\", null, \"Additionally, governments could also play a role in promoting transparency and accountability of AI systems by implementing regulations and guidelines on the labeling of AI content and software actions, and enforcing penalties for non-compliance.\"), mdx(\"p\", null, \"Finally, it is important to note that it is not just a technical problem but also a societal one, and that it requires a multi-stakeholder approach, which includes industry, civil society, and government, to develop a solution and to ensure that it is effectively implemented.\"), mdx(\"p\", null, \"Another way of clearly labeling AI content and/or software actions is by using certification systems. These systems involve an independent third party, such as a regulatory agency or industry group, evaluating the AI system and verifying that it meets certain standards, such as transparency, fairness, and accountability. These certifications can be used to clearly label the AI system and to provide assurance to users that the system has been independently reviewed and found to be trustworthy.\"), mdx(\"p\", null, \"Another way of clearly labelling AI content and/or software actions is by using explainable AI (XAI) techniques, these techniques allow the AI system to explain its decision-making process to users in a way that is easy for humans to understand. This can help users to trust the system and to understand how it makes decisions, and also make it easier for legal entities or individuals to be held accountable for the actions of the system.\"), mdx(\"p\", null, \"Finally, it is important to educate the public about the importance of clearly labeling AI content and/or software actions and associating them with the legal entity responsible for them. This can help to increase awareness of the risks associated with AI and to promote responsible use of the technology.\"), mdx(\"p\", null, \"In summary, there are many methods for clearly labelling AI content and/or software actions and associating them with the legal entity responsible for them, such as digital signatures, attribution statements, watermarking, logging, transparency reports, certifications, blockchain, standard data labels, explainable AI (XAI) and education. These methods can be used in combination to provide a comprehensive approach to transparency and accountability of AI systems.\"), mdx(\"p\", null, \"My Question:\\nHow might an ontology using RDF and common vocabularies be defined to provide a means to deploy these sorts of solutions? Can you give me an example of an RDF OWL ontology?\"), mdx(\"p\", null, \"An ontology using RDF and common vocabularies can provide a structured way to describe and represent information related to the legal entity responsible for AI content and/or software actions, as well as the actions themselves. RDF (Resource Description Framework) is a standard for modeling information on the web, and it provides a way to express the relationships between resources (e.g. documents, people, and concepts) using a graph-based structure.\"), mdx(\"p\", null, \"A simple example of an RDF OWL (Web Ontology Language) ontology for describing AI content and software actions could include classes such as \\\"AI system\\\", \\\"Legal entity\\\", \\\"Individual\\\", \\\"Action\\\", and \\\"Responsibility\\\". Each class would have a set of properties that describe their characteristics and relationships, such as \\\"name\\\", \\\"developer\\\", \\\"owner\\\", \\\"operator\\\", \\\"decision-making process\\\" and \\\"Standards met\\\", respectively.\"), mdx(\"p\", null, \"For example, the class \\\"AI system\\\" could have properties such as \\\"name\\\", \\\"developer\\\", \\\"owner\\\", \\\"operator\\\" and \\\"decision-making process\\\". The class \\\"Legal entity\\\" would have properties such as \\\"name\\\", \\\"type\\\" (e.g. government department, institution, corporation or business), \\\"location\\\", and \\\"jurisdiction\\\". The class \\\"Individual\\\" would have properties such as \\\"name\\\" and \\\"role\\\" (e.g. developer, owner, operator). The class \\\"Action\\\" would have properties such as \\\"name\\\", \\\"date\\\", \\\"type\\\" (e.g. decision, action) and \\\"outcome\\\". The class \\\"Responsibility\\\" would have properties such as \\\"level\\\" (e.g. primary, secondary, etc) and \\\"entity\\\" (e.g. legal entity, individual)\"), mdx(\"p\", null, \"These classes and properties can be interconnected to describe complex relationships between AI systems, legal entities, individuals, and actions, and can be used to trace the origin and usage of AI content and software actions, and to establish accountability and transparency. The use of common vocabularies, such as schema.org and others, would help to standardize the representation of the information and make it more easily understandable and usable by different systems and applications.\"), mdx(\"p\", null, \"It's worth noting that this is just a simple example and that a more comprehensive ontology would be more complex and take into account the specific context and use case. And that, the use of RDF and OWL enables the use of formal reasoning to infer new information from the ontology, which is particularly useful for the transparency and accountability of AI systems.\"), mdx(\"p\", null, \"Additionally, using RDF and OWL to represent an ontology can enable the use of formal reasoning to infer new information from the ontology, this is particularly useful for transparency and accountability of AI systems. For example, by creating inferences rules in the ontology, you can automatically infer information about the legal entities, individuals and actions responsible for an AI system, based on the properties of the AI system.\"), mdx(\"p\", null, \"Moreover, using RDF and OWL in this context can also enable the integration of the ontology with other systems, such as databases, document management systems and even other AI systems. This is particularly useful for creating transparency and accountability solutions, where information about AI systems, legal entities and individuals need to be shared and combined across different systems.\"), mdx(\"p\", null, \"Another advantage of using RDF and OWL is that they can leverage the Linked Data ecosystem, which allows for easy data sharing and integration across different organizations and domains. This allows for more collaboration between different stakeholders, like industry, civil society and government, to help ensure the transparency and accountability of AI systems.\"), mdx(\"p\", null, \"Finally, it is important to note that creating an ontology is just a first step, the ontology itself should be continuously updated, maintained, and evaluated to make sure it is still useful and useful, to address the complexity and dynamic nature of the field of AI.\"), mdx(\"p\", null, \"My Question:\"), mdx(\"p\", null, \"can you write an example in notation3 syntax.\"), mdx(\"p\", null, \"ChatGPT Answer:\"), mdx(\"p\", null, \"Sure, here is an example of an RDF ontology written in Notation3 (N3) syntax to describe an AI system and its responsible legal entities and individuals:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"@prefix ai: <http://example.com/ontology/ai#> .\\n@prefix foaf: <http://xmlns.com/foaf/0.1/> .\\n@prefix org: <http://www.w3.org/ns/org#> .\\n\\nai:MyAI a ai:AI;\\n    ai:name \\\"My AI System\\\";\\n    ai:developer [ a foaf:Person; foaf:name \\\"John Doe\\\" ];\\n    ai:owner [ a org:Organization; org:name \\\"Acme Inc.\\\" ];\\n    ai:operator [ a foaf:Person; foaf:name \\\"Jane Smith\\\" ];\\n    ai:decision-makingProcess \\\"Explainable AI using Decision Trees\\\" .\\n\\n\")), mdx(\"p\", null, \"In this example, the ontology defines a class \\\"AI\\\" (ai:AI) and an instance of that class \\\"MyAI\\\" (ai:MyAI), it also specifies that \\\"MyAI\\\" has a name \\\"My AI System\\\", a developer \\\"John Doe\\\" (foaf:Person), an owner \\\"Acme Inc.\\\" (org:Organization), an operator \\\"Jane Smith\\\" (foaf:Person) and a decision-making process \\\"Explainable AI using Decision Trees\\\"\"), mdx(\"p\", null, \"This ontology uses prefixes to simplify the URIs (ai:, foaf:, org:) used in the statements. The prefixes indicate that the URIs in the ontology are from the given namespace, so \\\"ai:AI\\\" refers to the URI \\\"\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://example.com/ontology/ai#AI\"\n  }, \"http://example.com/ontology/ai#AI\"), \"\\\".\"), mdx(\"p\", null, \"Note that this is a simplified example, in real-world scenarios, the ontology would likely have more classes and properties and also, would relate to other ontologies to provide more context and meaning, such as time, location, standards met, etc.\"), mdx(\"p\", null, \"Additionally, the ontology can include more classes and properties such as \\\"Action\\\", \\\"Responsibility\\\", \\\"Jurisdiction\\\", \\\"Location\\\", \\\"Date\\\", \\\"Standards\\\", \\\"Certification\\\" and \\\"TransparencyReports\\\" that describe the actions taken by the AI system, the level of responsibility of the legal entities and individuals, the jurisdiction, location, date of action, standards met, certifications achieved and transparency reports respectively.\"), mdx(\"p\", null, \"Here's an example of how these classes and properties can be added to the ontology:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"@prefix ai: <http://example.com/ontology/ai#> .\\n@prefix foaf: <http://xmlns.com/foaf/0.1/> .\\n@prefix org: <http://www.w3.org/ns/org#> .\\n@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\\n\\nai:MyAI a ai:AI;\\n    ai:name \\\"My AI System\\\";\\n    ai:developer [ a foaf:Person; foaf:name \\\"John Doe\\\" ];\\n    ai:owner [ a org:Organization; org:name \\\"Acme Inc.\\\" ];\\n    ai:operator [ a foaf:Person; foaf:name \\\"Jane Smith\\\" ];\\n    ai:decision-makingProcess \\\"Explainable AI using Decision Trees\\\" ;\\n    ai:performedAction [ a ai:Action; ai:name \\\"Decision Making\\\";\\n    ai:outcome \\\"Approve the loan\\\";\\n    ai:date \\\"2022-01-12T10:30:00Z\\\"^^xsd:dateTime];\\n    ai:responsibility [ a ai:Responsibility;\\n    ai:level \\\"Primary\\\";\\n    ai:entity [a org:Organization; org:name \\\"Acme Inc.\\\" ]];\\n    ai:jurisdiction \\\"US\\\";\\n    ai:location \\\"New York\\\";\\n    ai:standardsMet \\\"ISO/IEC 27001:2013\\\";\\n    ai:certifications \\\"ISO/IEC 27001:2013 certified\\\";\\n    ai:transparencyReports <http://example.com/reports/myaisystem> .\\n\\n\")), mdx(\"p\", null, \"This enhanced example illustrates how more information can be added to the ontology, such as the actions taken by the AI system, the outcome, the date of the action, the level of responsibility of the legal entities and individuals, the jurisdiction, location, the standards met, certifications achieved, and transparency reports.\"), mdx(\"p\", null, \"It is worth noting that the example provided is not intended to be a complete or perfect ontology but is meant to give an idea of how RDF and OWL can be used to represent an ontology that would help with transparency and accountability of AI systems.\"), mdx(\"p\", null, \"My Question:\"), mdx(\"p\", null, \"can you provide a more comprehensive example in json-ld?\"), mdx(\"p\", null, \"ChatGPT Answer:\"), mdx(\"p\", null, \"Sure, here is a more comprehensive example of an RDF ontology written in JSON-LD (JavaScript Object Notation for Linked Data) syntax to describe an AI system and its responsible legal entities and individuals:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-json\"\n  }, \"\\n{\\n\\n\\xA0 \\xA0 \\\"@context\\\": {\\n\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"rdf\\\": \\\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"rdfs\\\": \\\"http://www.w3.org/2000/01/rdf-schema#\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"xsd\\\": \\\"http://www.w3.org/2001/XMLSchema#\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"foaf\\\": \\\"http://xmlns.com/foaf/0.1/\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"org\\\": \\\"http://www.w3.org/ns/org#\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"ai\\\": \\\"http://example.com/ontology/ai#\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"name\\\": \\\"ai:name\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"developer\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"ai:developer\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"@id\\\"\\n\\xA0 \\xA0 \\xA0 \\xA0 },\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"owner\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"ai:owner\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"@id\\\"\\n\\xA0 \\xA0 \\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"operator\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"ai:operator\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"@id\\\"\\n\\xA0 \\xA0 \\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"decision-makingProcess\\\": \\\"ai:decision-makingProcess\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"performedAction\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"ai:performedAction\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"@id\\\"\\n\\xA0 \\xA0 \\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"outcome\\\": \\\"ai:outcome\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"date\\\": \\\"ai:date\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"responsibility\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"ai:responsibility\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"@id\\\"\\n\\xA0 \\xA0 \\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"level\\\": \\\"ai:level\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"entity\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"ai:entity\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"@id\\\"\\n\\xA0 \\xA0 \\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"jurisdiction\\\": \\\"ai:jurisdiction\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"location\\\": \\\"ai:location\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"standardsMet\\\": \\\"ai:standardsMet\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"certifications\\\": \\\"ai:certifications\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"transparencyReports\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"ai:transparencyReports\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"@id\\\"\\n\\xA0 \\xA0 \\xA0 \\xA0 }\\n\\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\\"@id\\\": \\\"ai:MyAI\\\",\\n\\xA0 \\xA0 \\\"@type\\\": \\\"ai:AI\\\",\\n\\xA0 \\xA0 \\\"name\\\": \\\"My AI System\\\",\\n\\xA0 \\xA0 \\\"developer\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"foaf:JohnDoe\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"foaf:Person\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"name\\\": \\\"John Doe\\\"\\n\\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\\"owner\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"org:AcmeInc\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"org:Organization\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"name\\\": \\\"Acme Inc.\\\"\\n\\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\\"operator\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"foaf:JaneSmith\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"foaf:Person\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"name\\\": \\\"Jane Smith\\\"\\n\\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\\"decision-makingProcess\\\": \\\"Explainable AI using Decision Trees\\\",\\n\\xA0 \\xA0 \\\"performedAction\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"ai:Action1\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"ai:Action\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"name\\\": \\\"Decision Making\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"outcome\\\": \\\"Approve the loan\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"date\\\": \\\"2022-01-12T10:30:00Z\\\"\\n\\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\\"responsibility\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"ai:responsibility1\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"ai:Responsibility\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"level\\\": \\\"Primary\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\\"entity\\\": {\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@id\\\": \\\"org:AcmeInc\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"@type\\\": \\\"org:Organization\\\",\\n\\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\\"name\\\": \\\"Acme Inc.\\\"\\n\\xA0 \\xA0 \\xA0 \\xA0 }\\n\\xA0 \\xA0 },\\n\\n\\xA0 \\xA0 \\\"jurisdiction\\\": \\\"US\\\",\\n\\xA0 \\xA0 \\\"location\\\": \\\"New York\\\",\\n\\xA0 \\xA0 \\\"standardsMet\\\": \\\"ISO/IEC 27001:2013\\\",\\n\\xA0 \\xA0 \\\"certifications\\\": \\\"ISO/IEC 27001:2013 certified\\\",\\n\\xA0 \\xA0 \\\"transparencyReports\\\": \\\"http://example.com/reports/myaisystem\\\"\\n}\\n\")), mdx(\"p\", null, \"In this example, the ontology defines several classes, such as \\\"AI\\\" (ai:AI), \\\"Action\\\" (ai:Action), \\\"Responsibility\\\" (ai:Responsibility), \\\"Person\\\" (foaf:Person), and \\\"Organization\\\" (org:Organization), it also specifies that \\\"MyAI\\\" has a name, developer, owner, operator, decision-making process, performed actions, outcome, date, level of responsibility, and jurisdiction, location, standards met, certifications and transparency reports. \"), mdx(\"p\", null, \"The context provided, maps the prefixes used in the ontology to the corresponding URIs, as well as provides data types and relationships between the different classes and properties. This is used to make the JSON-LD data more easily readable for both machines and humans. As before, it's important to note that this is just an example and that the ontology can be much more detailed, depending on the complexity and dynamic nature of the field of AI.\"), mdx(\"h3\", {\n    \"id\": \"considerations\"\n  }, \"CONSIDERATIONS\"), mdx(\"p\", null, \"Whilst the specific approach certainly requires a great deal more work and consideration, the merit of the underlying notion appears to be considered important even by ChatGPT.  \"), mdx(\"p\", null, \"I hope this explains enough of this underlying consideration as is sought to be sufficiently illustrated, as to be added to the ToDo list for informatics policies relating to the development of webizen systems.\"));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/SocialFactors/WebScience/SafetyProtocols/AgentLabelling/","title":"Agent Labelling","shouldShowTitle":false}}],"inboundReferences":[]},"tagsOutbound":{"nodes":[]}},"pageContext":{"tags":[],"slug":"/SocialFactors/WebScience/EnglishLanguageModelling/","sidebarItems":[{"title":"Categories","items":[{"title":"Documentation Method","url":"/DocumentationMethod/","items":[]},{"title":"Old-Work-Archives","url":"/old-work-archives/","items":[{"title":"2005 Lots of ideas - some big & some small","url":"/old-work-archives/2005LotsOfIdeas-SomeBig&SomeSmall/","items":[]},{"title":"2018-Webizen-Net-Au","url":"/old-work-archives/2018-webizen-net-au/","items":[{"title":"_Link_library_links","url":"","items":[{"title":"Link Library","url":"/old-work-archives/2018-webizen-net-au/_link_library_links/2018-09-23-wp-linked-data/","items":[]}]},{"title":"about","url":"/old-work-archives/2018-webizen-net-au/about/","items":[{"title":"About The Author","url":"/old-work-archives/2018-webizen-net-au/about/about-the-author/","items":[]},{"title":"Applied Theory: Applications for a Human Centric Web","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/","items":[{"title":"Digital Receipts","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/digital-receipts/","items":[]},{"title":"Fake News: Considerations → Principles → The Institution of Socio & Economic Values","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations/","items":[]},{"title":"Healthy Living Economy","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/healthy-living-economy/","items":[]},{"title":"HyperMedia Solutions Adapting HbbTV V2","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/","items":[{"title":"HYPERMEDIA PACKAGES","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/hypermedia-packages/","items":[]},{"title":"USER STORIES: INTERACTIVE VIEWING EXPERIENCE","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/user-stories-interactive-viewing-experience/","items":[]}]},{"title":"Measurements App","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/measurements-app/","items":[]},{"title":"Re:Animation","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/reanimation/","items":[]},{"title":"Solutions to FakeNews: Linked-Data, Ontologies and Verifiable Claims","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/ld-solutions-to-fakenews/","items":[]}]},{"title":"Executive Summary","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/","items":[{"title":"Assisting those who Enforce the Law","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/assisting-those-who-enforce-the-law/","items":[]},{"title":"Consumer Protections","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/consumer-protections/","items":[]},{"title":"Knowledge Banking: Legal Structures","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-banking-legal-structures/","items":[]},{"title":"Knowledge Economics &#8211; Services","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-economics-services/","items":[]},{"title":"Preserving The Freedom to Think","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/preserving-the-freedom-to-think/","items":[]}]},{"title":"History","url":"","items":[{"title":"History: Global Governance and ICT.","url":"/old-work-archives/2018-webizen-net-au/about/history/history-global-governance-ict-1/","items":[]}]},{"title":"Knowledge Banking: A Technical Architecture Summary","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/","items":[{"title":"An introduction to Credentials.","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/","items":[{"title":"credentials and custodianship","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/credentials-and-custodianship/","items":[]},{"title":"DIDs and MultiSig","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/dids-and-multisig/","items":[]}]},{"title":"Personal Augmentation of AI","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/personal-augmentation-of-ai/","items":[]},{"title":"Semantic Inferencing","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/semantic-inferencing/","items":[]},{"title":"Web of Things (IoT+LD)","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/web-of-things-iotld/","items":[]}]},{"title":"References","url":"/old-work-archives/2018-webizen-net-au/about/references/","items":[{"title":"Making the distinction between ‘privacy’ and ‘dignity’.","url":"/old-work-archives/2018-webizen-net-au/about/references/privacy-vs-dignity/","items":[]},{"title":"Roles & Entity Analysis","url":"/old-work-archives/2018-webizen-net-au/about/references/roles-entity-analysis/","items":[]},{"title":"Social Informatics Design Considerations","url":"/old-work-archives/2018-webizen-net-au/about/references/social-informatics-design-concept-and-principles/","items":[]},{"title":"Socio-economic relations | A conceptual model","url":"/old-work-archives/2018-webizen-net-au/about/references/socioeconomic-relations-p1/","items":[]},{"title":"The need for decentralised Open (Linked) Data","url":"/old-work-archives/2018-webizen-net-au/about/references/the-need-for-decentralised-open-linked-data/","items":[]}]},{"title":"The design of new medium","url":"/old-work-archives/2018-webizen-net-au/about/the-design-of-new-medium/","items":[]},{"title":"The need to modernise socioeconomic infrastructure","url":"/old-work-archives/2018-webizen-net-au/about/the-modernisation-of-socioeconomics/","items":[]},{"title":"The Vision","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/","items":[{"title":"Domesticating Pervasive Surveillance","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/a-technical-vision/","items":[]}]}]},{"title":"Posts","url":"","items":[{"title":"About W3C","url":"/old-work-archives/2018-webizen-net-au/posts/About W3C/","items":[]},{"title":"Advanced Functions & Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/posts/Advanced Functions & Facebook Pages/","items":[]},{"title":"Advanced Search & Discovery Tips","url":"/old-work-archives/2018-webizen-net-au/posts/Advanced Search & Discovery Tips/","items":[]},{"title":"An Introduction to Virtual Machines","url":"/old-work-archives/2018-webizen-net-au/posts/An introduction to Virtual Machines/","items":[]},{"title":"Basic Media Analysis & Part 1 (Audio)","url":"/old-work-archives/2018-webizen-net-au/posts/Basic Media Analysis & Part 1 (Audio)/","items":[]},{"title":"Basic Media Analysis & Part 2 (Visual)","url":"/old-work-archives/2018-webizen-net-au/posts/Basic Media Analysis & Part 2 (visual)/","items":[]},{"title":"Basic Media Analysis & Part 3 (Text & Metadata)","url":"/old-work-archives/2018-webizen-net-au/posts/Basic Media Analysis & Part 3 (Text & Metadata)/","items":[]},{"title":"Building an Economy Based upon Knowledge Equity","url":"/old-work-archives/2018-webizen-net-au/posts/Building an Economy based upon Knowledge Equity/","items":[]},{"title":"Choice of Law","url":"/old-work-archives/2018-webizen-net-au/posts/Choice of Law/","items":[]},{"title":"Contemplation of the ITU Dubai Meeting and the Future of the Internet","url":"/old-work-archives/2018-webizen-net-au/posts/Contemplation of the ITU Dubai Meeting and the Future of the Internet/","items":[]},{"title":"Creating a Presence & Online","url":"/old-work-archives/2018-webizen-net-au/posts/Creating a Presence & Online/","items":[]},{"title":"Credentials and Payments by Manu Sporny","url":"/old-work-archives/2018-webizen-net-au/posts/Credentials and Payments by Manu Sporny/","items":[]},{"title":"Data Recovery - Laptop & Computers","url":"/old-work-archives/2018-webizen-net-au/posts/Data Recovery - Laptop & Computers/","items":[]},{"title":"Data Recovery & Collection Mobile Devices","url":"/old-work-archives/2018-webizen-net-au/posts/Data Recovery & Collection Mobile Devices/","items":[]},{"title":"Decentralized Web Conference 2016","url":"/old-work-archives/2018-webizen-net-au/posts/Decentralized Web Conference 2016/","items":[]},{"title":"Decentralized Web Summit 2018","url":"/old-work-archives/2018-webizen-net-au/posts/Decentralized Web Summit 2018/","items":[]},{"title":"Does Anonymity Exist","url":"/old-work-archives/2018-webizen-net-au/posts/Does Anonymity exist/","items":[]},{"title":"Downloading My Data From Social Networks","url":"/old-work-archives/2018-webizen-net-au/posts/Downloading My Data from Social Networks/","items":[]},{"title":"Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/posts/Facebook Pages/","items":[]},{"title":"Google Tracking Data (Geolocation)","url":"/old-work-archives/2018-webizen-net-au/posts/Google Tracking Data (geolocation)/","items":[]},{"title":"Human Consciousness","url":"/old-work-archives/2018-webizen-net-au/posts/Human Consciousness/","items":[]},{"title":"Image Recgonition Video Playlist","url":"/old-work-archives/2018-webizen-net-au/posts/Image Recgonition Video Playlist/","items":[]},{"title":"Inferencing (Introduction)","url":"/old-work-archives/2018-webizen-net-au/posts/Inferencing (introduction)/","items":[]},{"title":"Introduction to AI","url":"/old-work-archives/2018-webizen-net-au/posts/Introduction to AI/","items":[]},{"title":"Introduction to Maltego","url":"/old-work-archives/2018-webizen-net-au/posts/Introduction to Maltego/","items":[]},{"title":"Introduction to Ontologies","url":"/old-work-archives/2018-webizen-net-au/posts/Introduction to Ontologies/","items":[]},{"title":"Introduction to Semantic Web","url":"/old-work-archives/2018-webizen-net-au/posts/Introduction to Semantic Web/","items":[]},{"title":"Knowledge-Capital","url":"/old-work-archives/2018-webizen-net-au/posts/knowledge-capital/","items":[]},{"title":"Logos-Style-Guides-and-Artwork","url":"/old-work-archives/2018-webizen-net-au/posts/logos-style-guides-and-artwork/","items":[]},{"title":"MindMapping & Setting-up a Business & Identity","url":"/old-work-archives/2018-webizen-net-au/posts/MindMapping & Setting-up a business & Identity/","items":[]},{"title":"Openlink Virtuoso","url":"/old-work-archives/2018-webizen-net-au/posts/Openlink Virtuoso/","items":[]},{"title":"OpenRefine","url":"/old-work-archives/2018-webizen-net-au/posts/OpenRefine/","items":[]},{"title":"Projects-Customers-and-Invoicing-Web-Services-for-Startups","url":"/old-work-archives/2018-webizen-net-au/posts/projects-customers-and-invoicing-web-services-for-startups/","items":[]},{"title":"RWW & some Solid History","url":"/old-work-archives/2018-webizen-net-au/posts/RWW & some Solid history/","items":[]},{"title":"Semantic Web (An Intro)","url":"/old-work-archives/2018-webizen-net-au/posts/Semantic Web (An Intro)/","items":[]},{"title":"Setting-up Twitter","url":"/old-work-archives/2018-webizen-net-au/posts/Setting-up Twitter/","items":[]},{"title":"Social Encryption An Introduction","url":"/old-work-archives/2018-webizen-net-au/posts/Social Encryption An Introduction/","items":[]},{"title":"Stock Content","url":"/old-work-archives/2018-webizen-net-au/posts/Stock Content/","items":[]},{"title":"The WayBack Machine","url":"/old-work-archives/2018-webizen-net-au/posts/The WayBack Machine/","items":[]},{"title":"Tim Berners Lee & Turing Lecture","url":"/old-work-archives/2018-webizen-net-au/posts/Tim Berners Lee & Turing Lecture/","items":[]},{"title":"Tools-of-Trade","url":"/old-work-archives/2018-webizen-net-au/posts/tools-of-trade/","items":[]},{"title":"Trust Factory 2017","url":"/old-work-archives/2018-webizen-net-au/posts/Trust Factory 2017/","items":[]},{"title":"Verifiable Claims (An Introduction)","url":"/old-work-archives/2018-webizen-net-au/posts/Verifiable Claims (An Introduction)/","items":[]},{"title":"Web of Things & an Introduction","url":"/old-work-archives/2018-webizen-net-au/posts/Web of Things & an Introduction/","items":[]},{"title":"Web-Persistence","url":"/old-work-archives/2018-webizen-net-au/posts/Web-Persistence/","items":[]},{"title":"Web-Services & Marketing Tools","url":"/old-work-archives/2018-webizen-net-au/posts/Web-Services & Marketing Tools/","items":[]},{"title":"Website Templates","url":"/old-work-archives/2018-webizen-net-au/posts/Website Templates/","items":[]},{"title":"What is <span class=\"textannotation disambiguated wl-thing\" id=\"urn:local-text-annotation-16v2koc9fcuj5lwn7helj9zpo9t4iqv4\" itemid=\"http://data.wordlift.io/wl0293/entity/linked_data\">Linked Data</span>?","url":"/old-work-archives/2018-webizen-net-au/posts/Introduction to Linked Data/","items":[]},{"title":"What Is Linked Data","url":"/old-work-archives/2018-webizen-net-au/posts/What is Linked Data/","items":[]},{"title":"What Is Open Source Intelligence","url":"/old-work-archives/2018-webizen-net-au/posts/What is Open Source Intelligence/","items":[]}]},{"title":"Resource Library","url":"/old-work-archives/2018-webizen-net-au/resource-library/","items":[]}]},{"title":"LinkedIn Articles","url":"/old-work-archives/LinkedInArticles/","items":[{"title":"AI & Software Agents: Social-Engineering Considerations","url":"/old-work-archives/LinkedInArticles/AI&SoftwareAgentsSocial-Engineering Considerations/","items":[]},{"title":"AI, Digital Identity & Guardianship Systems?","url":"/old-work-archives/LinkedInArticles/linkedinNoteAIDigitalIdentity&Guardianship Systems/","items":[]},{"title":"Knowledge & Agent Labelling: Clear Labelling of AI Interactions & some ideas about how to test students, by AI.","url":"/old-work-archives/LinkedInArticles/LinkedInLabellingAiAgents/","items":[]},{"title":"Reinventing the Kindness Equation","url":"/old-work-archives/LinkedInArticles/ReinventingTheKindnessEquation/","items":[]},{"title":"What is the Definition of an 'AI Weapon'","url":"/old-work-archives/LinkedInArticles/WhatIsTheDefinitionOfAnAIWeapon/","items":[]}]},{"title":"WebCivics BizPlan 2018","url":"/old-work-archives/WebCivicsBizPlan2018/","items":[]},{"title":"WebCivics Medium Posts","url":"/old-work-archives/WebCivicsMediumPosts/","items":[{"title":"2019","url":"","items":[{"title":"An Open Letter - What is your Digital Identity Mandate for Humanity","url":"/old-work-archives/WebCivicsMediumPosts/2019/AnOpenLetter-WhatisyourDigitalIdentity MandateforHumanity/","items":[]},{"title":"Building a #NewStart for the Australian Creative Sector.","url":"/old-work-archives/WebCivicsMediumPosts/2019/BuildingaNewStartfortheAustralianCreative Sector./","items":[]},{"title":"Building a Safe Environment for Kids to Thrive with Their ‘Digital Twin’","url":"/old-work-archives/WebCivicsMediumPosts/2019/Building a safe environment for Kids to thrive with their ‘Digital Twin’/","items":[]},{"title":"Causal Relationships between Social informatics design and Quantum Mechanical Phenomenon.","url":"/old-work-archives/WebCivicsMediumPosts/2019/CausalRelationshipsbetweenSocial informaticsdesignandQuantumMechanical Phenomenon./","items":[]},{"title":"Comms & Security Privacy vs. Dignity","url":"/old-work-archives/WebCivicsMediumPosts/2019/Comms&SecurityPrivacyVsDignity/","items":[]},{"title":"Cyber Security Infrastructure, AI & Semantics","url":"/old-work-archives/WebCivicsMediumPosts/2019/CyberSecurityInfrastructureAI&Semantics/","items":[]},{"title":"Dependents The Emergence of Cyber Nation. Estates of ‘Virtual IDentity’","url":"/old-work-archives/WebCivicsMediumPosts/2019/DependentsTheEmergenceOfCyberNationEstatesOfVirtualIDentity/","items":[]},{"title":"Engineering Einstein","url":"/old-work-archives/WebCivicsMediumPosts/2019/EngineeringEinstein/","items":[]},{"title":"Health Informatics History, Challenges & Opportunities","url":"/old-work-archives/WebCivicsMediumPosts/2019/HealthInformaticsHistoryChallenges& Opportunities/","items":[]},{"title":"History Community, Civics & GLAM. Means to Bootstrap Digital Economy Growth & Knowledge Banking Tools.","url":"/old-work-archives/WebCivicsMediumPosts/2019/HistoryCommunityCivics&GLAMMeanstoBootstrapDigitalEconomyGrowth&KnowledgeBankingTools./","items":[]},{"title":"History of Banking, Knowledge Economy and Moral Poverty","url":"/old-work-archives/WebCivicsMediumPosts/2019/History of Banking, Knowledge Economy and Moral Poverty/","items":[]},{"title":"HyperMedia Exhibition & Events Spaces","url":"/old-work-archives/WebCivicsMediumPosts/2019/HyperMediaExhibition&EventsSpaces/","items":[]},{"title":"Inforgs & The Collective Infosphere","url":"/old-work-archives/WebCivicsMediumPosts/2019/Inforgs&TheCollectiveInfosphere/","items":[]},{"title":"Knowledge Age - A conceptual evolution of the Cyber-Physical from our Present Information Age","url":"/old-work-archives/WebCivicsMediumPosts/2019/KnowledgeAge-AConceptualEvolutionoftheCyber-PhysicalfromourPresentInformationAge/","items":[]},{"title":"Knowledge Banking Infrastructure","url":"/old-work-archives/WebCivicsMediumPosts/2019/Knowledge Banking Infrastructure/","items":[]},{"title":"Knowledge Banking Infrastructure - Cyber Socio-Economic Foundations for Our Shared World","url":"/old-work-archives/WebCivicsMediumPosts/2019/Knowledge Banking Infrastructure - Cyber Socio-Economic Foundations for our shared world/","items":[]},{"title":"Knowledge Clouds","url":"/old-work-archives/WebCivicsMediumPosts/2019/Knowledge Clouds/","items":[]},{"title":"Media Analytics & Hyper-Media Services","url":"/old-work-archives/WebCivicsMediumPosts/2019/MediaAnalytics&Hyper-MediaServices/","items":[]},{"title":"Micropayments Standards - An Economic Imperative for the Knowledge Age","url":"/old-work-archives/WebCivicsMediumPosts/2019/MicropaymentsStandards-AnEconomicImperativefortheKnowledgeAge/","items":[]},{"title":"Open Data v3.0 Permissive Commons","url":"/old-work-archives/WebCivicsMediumPosts/2019/OpenDatav3.0PermissiveCommons/","items":[]},{"title":"Skills & Social Activities","url":"/old-work-archives/WebCivicsMediumPosts/2019/Skills&SocialActivities/","items":[]},{"title":"Small to Medium Business, WebPayments & Knowledge Banking","url":"/old-work-archives/WebCivicsMediumPosts/2019/SmallToMediumBusinessWebPayments&KnowledgeBanking/","items":[]},{"title":"Tech for Permissive Commons","url":"/old-work-archives/WebCivicsMediumPosts/2019/TechforPermissiveCommons/","items":[]},{"title":"The Case for a ‘Human Centric’ Global Cyber Infrastructure Project","url":"/old-work-archives/WebCivicsMediumPosts/2019/TheCaseforaHumanCentricGlobalCyberInfrastructureProject/","items":[]},{"title":"The Semantic Inforg & The “Human Centric Web” — Reality Check, Tech.","url":"/old-work-archives/WebCivicsMediumPosts/2019/The Semantic Inforg & The “Human Centric Web” — Reality Check, Tech./","items":[]},{"title":"Tooling for Democracies","url":"/old-work-archives/WebCivicsMediumPosts/2019/ToolingforDemocracies/","items":[]},{"title":"Universitas Doctrina et Sapientiae","url":"/old-work-archives/WebCivicsMediumPosts/2019/UniversitasDoctrinaetSapientiae/","items":[]},{"title":"Why a Trust Factory (“think tank”)","url":"/old-work-archives/WebCivicsMediumPosts/2019/WhyaTrustFactorythinktank/","items":[]},{"title":"WoT Smart Cities Engineering Digital Twin Things & Ecosystems.","url":"/old-work-archives/WebCivicsMediumPosts/2019/WoTSmartCitiesEngineeringDigitalTwinThings&Ecosystems/","items":[]}]},{"title":"During-Covid","url":"","items":[{"title":"A Future For Australians","url":"/old-work-archives/WebCivicsMediumPosts/during-covid/AFutureForAustralians/","items":[]},{"title":"A Future to Support Informed Decisions S.T.E.A.M & Stars","url":"/old-work-archives/WebCivicsMediumPosts/during-covid/AFuturetoSupportInformedDecisionsSTEAM&Stars/","items":[]},{"title":"A Major Manifestation Problem","url":"/old-work-archives/WebCivicsMediumPosts/during-covid/AMajorManifestationProblem/","items":[]},{"title":"Choices about the future of Knowledge Governance & alternatives Solutions to what appears to be how VaccinePassports are now being made","url":"/old-work-archives/WebCivicsMediumPosts/during-covid/ChoicesaboutthefutureofKnowledgeGovernanceAlternativesSolutionstoVaccinePassports/","items":[]},{"title":"Digital Covid19 “Vaccine Passport”","url":"/old-work-archives/WebCivicsMediumPosts/during-covid/DigitalCovid19VaccinePassports/","items":[]},{"title":"Do We Need a Space Time Navigator","url":"/old-work-archives/WebCivicsMediumPosts/during-covid/DoWeNeedaSpaceTimeNavigator/","items":[]},{"title":"Is an International Cyber Migration Even Possible","url":"/old-work-archives/WebCivicsMediumPosts/during-covid/IsanInternationalCyberMigrationEvenPossible/","items":[]}]}]},{"title":"Webizen Group 2015","url":"/old-work-archives/WebizenGroup2015/","items":[]}]},{"title":"Permissive Commons Tech","url":"/PermissiveCommonsTech/","items":[{"title":"DIDs","url":"/PermissiveCommonsTech/DIDs/","items":[]},{"title":"PCTRequirements","url":"/PermissiveCommonsTech/PCTRequirements/","items":[]},{"title":"Problem Statement","url":"/PermissiveCommonsTech/PCTProblemStatement/","items":[]},{"title":"Requirements","url":"","items":[{"title":"Engineering Considerations","url":"/PermissiveCommonsTech/Requirements/PCTEngineeringConsiderations/","items":[{"title":"Cryptographic Signatures","url":"/PermissiveCommonsTech/Requirements/PCTEngineeringConsiderations/CryptographicSignatures/","items":[]},{"title":"Energy Consumption","url":"/PermissiveCommonsTech/Requirements/PCTEngineeringConsiderations/EnergyConsumption/","items":[]},{"title":"ForTheGoodOfHumanity","url":"/PermissiveCommonsTech/Requirements/PCTEngineeringConsiderations/ForTheGoodOfHumanity/","items":[]},{"title":"PCT-DNS Considerations","url":"/PermissiveCommonsTech/Requirements/PCTEngineeringConsiderations/PCT-DNS-Considerations/","items":[]},{"title":"PublishingWorkflow","url":"/PermissiveCommonsTech/Requirements/PCTEngineeringConsiderations/PublishingWorkflow/","items":[]},{"title":"SocioEconomic Relations","url":"/PermissiveCommonsTech/Requirements/PCTEngineeringConsiderations/SocioEconomicRelations/","items":[]},{"title":"Temporal Semantics","url":"/PermissiveCommonsTech/Requirements/PCTEngineeringConsiderations/PCTTemporalSemantics/","items":[]},{"title":"Version Control","url":"/PermissiveCommonsTech/Requirements/PCTEngineeringConsiderations/VersionControl/","items":[]}]},{"title":"PCT Ontology Modelling","url":"/PermissiveCommonsTech/Requirements/PCTOntologyModelling/","items":[]},{"title":"PCT_PeaceInfrastructureProjectRequirements","url":"/PermissiveCommonsTech/Requirements/PCT_PeaceInfrastructureProjectRequirements/","items":[]},{"title":"PCT-Core-Services","url":"/PermissiveCommonsTech/Requirements/PCT-Core-Services/","items":[{"title":"Decentralised Ontologies","url":"/PermissiveCommonsTech/Requirements/PCT-Core-Services/DecentralisedOntologies/","items":[]},{"title":"Human Centric Ontology","url":"/PermissiveCommonsTech/Requirements/PCT-Core-Services/HumanCentricOntology/","items":[]}]},{"title":"PCTSpecifications","url":"/PermissiveCommonsTech/Requirements/PCTSpecifications/","items":[]},{"title":"Permissive Commons Technology Docs","url":"/PermissiveCommonsTech/Requirements/PCTREADME/","items":[]},{"title":"Use Cases","url":"/PermissiveCommonsTech/Requirements/PCTuse-cases/","items":[]}]},{"title":"What are 'The Commons'","url":"/PermissiveCommonsTech/WhatAreTheCommons/","items":[]},{"title":"What is 'Open Data'","url":"/PermissiveCommonsTech/WhatIsOpenData/","items":[]},{"title":"Work in Progress","url":"/PermissiveCommonsTech/PCTWorkInProgress/","items":[{"title":"Collect Existing Ontologies","url":"/PermissiveCommonsTech/PCTWorkInProgress/CollectExistingOntologies/","items":[]},{"title":"Minimum Wages","url":"/PermissiveCommonsTech/PCTWorkInProgress/MinimumWages/","items":[]},{"title":"Ontology in Markdown Example","url":"/PermissiveCommonsTech/PCTWorkInProgress/RDF2MD-Example/","items":[]},{"title":"Permissive Commons Technology (PCT) Requirements.","url":"/PermissiveCommonsTech/PCTWorkInProgress/PermissiveCommonsRequirements/","items":[]},{"title":"Safety Considerations","url":"/PermissiveCommonsTech/PCTWorkInProgress/SafetyConsiderations/","items":[]}]}]},{"title":"Social Factors","url":"/SocialFactors/","items":[{"title":"Background","url":"/SocialFactors/Background/","items":[]},{"title":"Commercial Models","url":"/SocialFactors/CommercialModels/","items":[{"title":"Best Efforts","url":"/SocialFactors/CommercialModels/BestEfforts/","items":[]},{"title":"Currencies","url":"/SocialFactors/CommercialModels/Currencies/","items":[{"title":"Financial Payment Types","url":"/SocialFactors/CommercialModels/Currencies/FinancialPaymentTypes/","items":[]},{"title":"Gifts and Donations","url":"/SocialFactors/CommercialModels/Currencies/GiftsAndDonations/","items":[]},{"title":"Micro Payments","url":"/SocialFactors/CommercialModels/Currencies/Micropayments/","items":[]},{"title":"Non-Financial Currencies","url":"/SocialFactors/CommercialModels/Currencies/Non-FinancialCurrencies/","items":[]}]},{"title":"Economic Systems","url":"/SocialFactors/CommercialModels/EconomicSystems/","items":[]},{"title":"Environmental, Social and Governance (ESG)","url":"/SocialFactors/CommercialModels/ESG/","items":[{"title":"Biosphere Calcs","url":"/SocialFactors/CommercialModels/ESG/BiosphereCalcs/","items":[]},{"title":"Energy Calcs","url":"/SocialFactors/CommercialModels/ESG/EnergyCalcs/","items":[]},{"title":"Sociosphere Calcs","url":"/SocialFactors/CommercialModels/ESG/SocioshereCalcs/","items":[]}]},{"title":"Fit For Purpose","url":"/SocialFactors/CommercialModels/FitForPurpose/","items":[]},{"title":"Hardware Strategy","url":"/SocialFactors/CommercialModels/HardwareStrategy/","items":[]},{"title":"Historical Information","url":"/SocialFactors/CommercialModels/Historical Information/","items":[{"title":"Domains","url":"/SocialFactors/CommercialModels/Historical Information/Domains/","items":[]},{"title":"Value Accounting Initiatives","url":"/SocialFactors/CommercialModels/Historical Information/ValueAccountingInitiatives/","items":[]},{"title":"Web Civics","url":"/SocialFactors/CommercialModels/Historical Information/WebCivics/","items":[]}]},{"title":"The Work Project","url":"/SocialFactors/CommercialModels/WorkProject/","items":[{"title":"Contribution Classifications","url":"/SocialFactors/CommercialModels/WorkProject/ContributionClassifications/","items":[]},{"title":"Equipment and Supplies","url":"/SocialFactors/CommercialModels/WorkProject/EquipmentAndSupplies/","items":[]},{"title":"Intellectual Property","url":"/SocialFactors/CommercialModels/WorkProject/IntellectualProperty/","items":[]},{"title":"Knowledge Work","url":"/SocialFactors/CommercialModels/WorkProject/KnowledgeWork/","items":[]},{"title":"Labour Work","url":"/SocialFactors/CommercialModels/WorkProject/LabourWork/","items":[]},{"title":"Licensing Frameworks","url":"/SocialFactors/CommercialModels/WorkProject/LicensingFrameworks/","items":[]},{"title":"Project Financing","url":"/SocialFactors/CommercialModels/WorkProject/ProjectFinancing/","items":[]},{"title":"Resources","url":"/SocialFactors/CommercialModels/WorkProject/Resources/","items":[]},{"title":"Work Valuation Methods","url":"/SocialFactors/CommercialModels/WorkProject/WorkValuationMethods/","items":[]}]},{"title":"Trust Factory","url":"/SocialFactors/CommercialModels/TrustFactory/","items":[]},{"title":"Webizen","url":"/SocialFactors/CommercialModels/Webizen/","items":[]},{"title":"Webizen Alliance","url":"/SocialFactors/CommercialModels/WebizenAlliance/","items":[{"title":"Community of Practice","url":"/SocialFactors/CommercialModels/WebizenAlliance/CommunityOfPractice/","items":[]},{"title":"Early Stage Income Strategies","url":"/SocialFactors/CommercialModels/WebizenAlliance/EarlyStageIncomeStrategies/","items":[]},{"title":"The Webizen Charter","url":"/SocialFactors/CommercialModels/WebizenAlliance/TheWebizenCharter/","items":[]}]},{"title":"Webizen Pro VAR Solutions","url":"/SocialFactors/CommercialModels/WebizenProVARSolutions/","items":[]},{"title":"WebizenPro Usecases","url":"/SocialFactors/CommercialModels/WebizenProUsecases/","items":[{"title":"Webizen Pro Ecosystem Usecases","url":"/SocialFactors/CommercialModels/WebizenProUsecases/WebizenProEcosystemUsecases/","items":[]},{"title":"Webizen Pro Edge UseCases","url":"/SocialFactors/CommercialModels/WebizenProUsecases/WebizenProEdgeUseCases/","items":[]},{"title":"Webizen Pro Use-Cases","url":"/SocialFactors/CommercialModels/WebizenProUsecases/WebizenProUse-Cases/","items":[]}]}]},{"title":"Commercial-Technical Requirements","url":"/SocialFactors/SocioEconomicTechReqs/","items":[{"title":"Account Creation","url":"/SocialFactors/SocioEconomicTechReqs/AccountCreation/","items":[]},{"title":"Guardianship Relations","url":"/SocialFactors/SocioEconomicTechReqs/GuardianshipRelations/","items":[]},{"title":"Guardianship Semantics","url":"/SocialFactors/SocioEconomicTechReqs/GuardianshipSemantics/","items":[]},{"title":"Support for Human Agency","url":"/SocialFactors/SocioEconomicTechReqs/SupportForHumanAgency/","items":[]}]},{"title":"Peace Infrastructure Project","url":"/SocialFactors/PeaceInfrastructureProject/","items":[{"title":"About the Peace Infrastructure Project","url":"/SocialFactors/PeaceInfrastructureProject/AboutThePeaceInfrastructureProject/","items":[]}]},{"title":"Social Attack Vectors","url":"/SocialFactors/SocialAttackVectors/","items":[{"title":"CommercialExploitation","url":"/SocialFactors/SocialAttackVectors/CommercialExploitation/","items":[]},{"title":"Criminal Activity","url":"/SocialFactors/SocialAttackVectors/CriminalActivity/","items":[{"title":"Corporate Crime","url":"/SocialFactors/SocialAttackVectors/CriminalActivity/CorporateCrime/","items":[]},{"title":"Digital Slavery","url":"/SocialFactors/SocialAttackVectors/CriminalActivity/DigitalSlavery/","items":[]},{"title":"Environmental Crime","url":"/SocialFactors/SocialAttackVectors/CriminalActivity/EnvironmentalCrime/","items":[]},{"title":"Financial Crimes","url":"/SocialFactors/SocialAttackVectors/CriminalActivity/FinancialCrimes/","items":[]},{"title":"Fraud","url":"/SocialFactors/SocialAttackVectors/CriminalActivity/Fraud/","items":[]},{"title":"Proxy Attacks","url":"/SocialFactors/SocialAttackVectors/CriminalActivity/ProxyAttacks/","items":[]}]},{"title":"Cyber Attack Vectors","url":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/","items":[{"title":"Attacks Online","url":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/AttacksOnline/","items":[]},{"title":"Cyber Crime","url":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/CyberCrime/","items":[]},{"title":"NobodyAI","url":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/NobodyAI/","items":[]},{"title":"Tech Debt","url":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/TechDebt/","items":[]}]},{"title":"Dehumanisation","url":"/SocialFactors/SocialAttackVectors/Dehumanisation/","items":[]},{"title":"Dishonesty","url":"/SocialFactors/SocialAttackVectors/Dishonesty/","items":[]},{"title":"Fake News","url":"/SocialFactors/SocialAttackVectors/FakeNews/","items":[]},{"title":"Public Sector Wrong Doings","url":"/SocialFactors/SocialAttackVectors/PublicSectorWrongDoings/","items":[]},{"title":"TemporalAttacks","url":"/SocialFactors/SocialAttackVectors/TemporalAttacks/","items":[]},{"title":"Torts","url":"/SocialFactors/SocialAttackVectors/Torts/","items":[{"title":"Economic Torts","url":"/SocialFactors/SocialAttackVectors/Torts/EconomicTorts/","items":[]},{"title":"Intentional Torts","url":"/SocialFactors/SocialAttackVectors/Torts/IntentionalTorts/","items":[]},{"title":"Negligence","url":"/SocialFactors/SocialAttackVectors/Torts/Negligence/","items":[]},{"title":"Nuisance","url":"/SocialFactors/SocialAttackVectors/Torts/Nuisance/","items":[]}]}]},{"title":"Web Science","url":"/SocialFactors/WebScience/","items":[{"title":"Artificial Minds","url":"/SocialFactors/WebScience/ArtificialMinds/","items":[{"title":"A ChatGPT Experiment: Holborn","url":"/SocialFactors/WebScience/ArtificialMinds/AChatGPTExperimentHolborn/","items":[]},{"title":"Cognitive AI","url":"/SocialFactors/WebScience/ArtificialMinds/CognitiveAI/","items":[{"title":"Cognitive AI","url":"/SocialFactors/WebScience/ArtificialMinds/CognitiveAI/CognitiveAI-WIP/","items":[]},{"title":"Defeasible Logic","url":"/SocialFactors/WebScience/ArtificialMinds/CognitiveAI/DefeasibleLogic/","items":[]},{"title":"Plausible Reasoning","url":"/SocialFactors/WebScience/ArtificialMinds/CognitiveAI/PlausibleReasoning/","items":[]}]},{"title":"The Artificial Minds List","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/","items":[{"title":"Baymax","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Baymax/","items":[]},{"title":"Bishop - Aliens","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Bishop - Aliens/","items":[]},{"title":"Borg - Star Trek","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Borg - Star Trek/","items":[]},{"title":"ChatGPT","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/ChatGPT/","items":[]},{"title":"Edwin Jarvis","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Edwin Jarvis/","items":[]},{"title":"IBM Watson","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/IBM Watson/","items":[]},{"title":"Max - Flight of the Navigator","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Max - Flight of the Navigator/","items":[]},{"title":"Rosie - The Jetsons","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Rosie - The Jetsons/","items":[]},{"title":"Sarah - Eureka","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Sarah - Eureka/","items":[]},{"title":"SkyNet","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/SkyNet/","items":[]},{"title":"The Doctor - Star Trek Voyager","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/The Doctor - Star Trek Voyager/","items":[]}]}]},{"title":"Centricity","url":"/SocialFactors/WebScience/Centricity/","items":[]},{"title":"English Language Modelling","url":"/SocialFactors/WebScience/EnglishLanguageModelling/","items":[]},{"title":"Human-Centric AI Ethics","url":"/SocialFactors/WebScience/HumanCentricAIEthics/","items":[]},{"title":"Learning Modals","url":"/SocialFactors/WebScience/LearningModals/","items":[]},{"title":"Ontology Modelling","url":"/SocialFactors/WebScience/OntologyModelling/","items":[]},{"title":"Permissive Commons","url":"/SocialFactors/WebScience/PermissiveCommons/","items":[{"title":"Biosphere Ontologies","url":"/SocialFactors/WebScience/PermissiveCommons/BiosphereOntologies/","items":[]},{"title":"SocioSphere Ontologies","url":"/SocialFactors/WebScience/PermissiveCommons/SocioSphereOntologies/","items":[]},{"title":"Sustainable Development Goals (ESG)","url":"/SocialFactors/WebScience/PermissiveCommons/SDGs/","items":[]}]},{"title":"Safety Protocols","url":"/SocialFactors/WebScience/SafetyProtocols/","items":[{"title":"Agent Labelling","url":"/SocialFactors/WebScience/SafetyProtocols/AgentLabelling/","items":[]},{"title":"Data Portability","url":"/SocialFactors/WebScience/SafetyProtocols/DataPortability/","items":[]},{"title":"Ending Digital Slavery","url":"/SocialFactors/WebScience/SafetyProtocols/EndingDigitalSlavery/","items":[]},{"title":"Fair Work Protocols","url":"/SocialFactors/WebScience/SafetyProtocols/FairWorkProtocols/","items":[]},{"title":"Freedom of Thought","url":"/SocialFactors/WebScience/SafetyProtocols/FreedomOfThought/","items":[]},{"title":"Human Centric AI","url":"/SocialFactors/WebScience/SafetyProtocols/HumanCentricAI/","items":[]},{"title":"HumanCentric Digital Identity","url":"/SocialFactors/WebScience/SafetyProtocols/HumanCentricDigitalIdentity/","items":[]},{"title":"Knowledge Qualification Methods","url":"/SocialFactors/WebScience/SafetyProtocols/KnowledgeQualificationMethods/","items":[]},{"title":"No Lock-ins","url":"/SocialFactors/WebScience/SafetyProtocols/NoLock-ins/","items":[]},{"title":"Protecting Children","url":"/SocialFactors/WebScience/SafetyProtocols/ProtectingChildren/","items":[]},{"title":"Relationships (Social)","url":"/SocialFactors/WebScience/SafetyProtocols/Relationships(Social)/","items":[]},{"title":"Values Credentials","url":"/SocialFactors/WebScience/SafetyProtocols/Values Credentials/","items":[]}]},{"title":"Science of Consciousness","url":"/SocialFactors/WebScience/ScienceOfConsciousness/","items":[]},{"title":"The Values Project","url":"/SocialFactors/WebScience/TheValuesProject/","items":[]},{"title":"Understanding Ontologies","url":"/SocialFactors/WebScience/UnderstandingOntologies/","items":[]}]},{"title":"Webizen 3.0 Setup User Experience","url":"/SocialFactors/Webizen3.0SetupUserExperience/","items":[]},{"title":"Webizen: For Humans","url":"/SocialFactors/WebizenForHumans/","items":[]}]},{"title":"Webizen Docs Introduction","url":"/","items":[]},{"title":"Webizen Tech Stack","url":"/WebizenTechStack/","items":[{"title":"Authentication Fabric","url":"/WebizenTechStack/AuthenticationFabric/","items":[{"title":"Verifiable Credentials","url":"/WebizenTechStack/AuthenticationFabric/VerifiableCredentials/","items":[]},{"title":"WebAuthn","url":"/WebizenTechStack/AuthenticationFabric/WebAuthn/","items":[]},{"title":"WebID","url":"/WebizenTechStack/AuthenticationFabric/WebID/","items":[]}]},{"title":"Core Services","url":"/WebizenTechStack/CoreServices/","items":[{"title":"Non-HTTP(s) Protocols","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/","items":[{"title":"Chia","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/Chia/","items":[]},{"title":"DAT","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/DAT/","items":[]},{"title":"GIT","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/GIT/","items":[]},{"title":"GUNECO","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/GUNECO/","items":[]},{"title":"Hedera","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/Hedera/","items":[]},{"title":"Holochain","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/Holochain/","items":[]},{"title":"IOTA","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/IOTA/","items":[]},{"title":"IPFS","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/IPFS/","items":[]},{"title":"IPLD","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/IPLD/","items":[]},{"title":"Lightning Network","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/LightningNetwork/","items":[]},{"title":"NYM","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/NYM/","items":[]},{"title":"Obyte","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/obyte/","items":[]},{"title":"WebCash","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/WebCash/","items":[]},{"title":"WebRTC","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/WebRTC/","items":[]},{"title":"WebSockets","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/WebSockets/","items":[]},{"title":"WebTorrent","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/WebTorrent/","items":[]},{"title":"WireGuard","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/WireGuard/","items":[]},{"title":"XRP Ledger","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/XRPLedger/","items":[]}]},{"title":"Verifiable Claims & Credentials","url":"/WebizenTechStack/CoreServices/VerifiableClaims&Credentials/","items":[]}]},{"title":"Core Technologies","url":"/WebizenTechStack/CoreTechnologies/","items":[{"title":"GoLang Libraries","url":"/WebizenTechStack/CoreTechnologies/GoLangLibraries/","items":[]},{"title":"Open Badges","url":"/WebizenTechStack/CoreTechnologies/OpenBadges/","items":[]},{"title":"Semantic Web","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/","items":[{"title":"GRDDL","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/GRDDL/","items":[]},{"title":"Ontologies","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/","items":[{"title":"DAML+OIL","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/DAML+OIL/","items":[]},{"title":"Friend of a Friend (FOAF) Core","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/FOAF/","items":[]},{"title":"HumanRightsOntologies","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/HumanRightsOntologies/","items":[{"title":"UDHR","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/HumanRightsOntologies/UDHR/","items":[]}]},{"title":"LKIF-Core","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/LKIF-Core/","items":[]},{"title":"MD-RDF Ontologies","url":"","items":[{"title":"DataTypesOntology (DTO) Core","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/MD-RDF Ontologies/DataTypes Ontology/","items":[]}]},{"title":"OWL","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/OWL/","items":[]},{"title":"RDFS","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/RDFS/","items":[]},{"title":"Sitemap","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/Sitemap/","items":[]},{"title":"SKOS","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/SKOS/","items":[]},{"title":"SOIC","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/SOIC/","items":[]}]},{"title":"Semantic Web Authentication Tech","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWeb-AUTH/","items":[{"title":"WebID-OIDC","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWeb-AUTH/WebID-OIDC/","items":[]},{"title":"WebID-RSA","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWeb-AUTH/WebID-RSA/","items":[]},{"title":"WebID-TLS","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWeb-AUTH/WebID-TLS/","items":[]}]},{"title":"Sparql Family","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SparqlFamily/","items":[]},{"title":"W3C Specifications","url":"","items":[{"title":"Linked Data Fragments","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/Linked Data Fragments/","items":[]},{"title":"Linked Data Notifications","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/Linked Data Notifications/","items":[]},{"title":"Linked Data Platform","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/Linked Data Platform/","items":[]},{"title":"Linked Media Fragments","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/Linked Media Fragments/","items":[]},{"title":"RDF","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/RDF/","items":[]},{"title":"Web Access Control (WAC)","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/Web Access Control (WAC)/","items":[]},{"title":"Web Of Things","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/Web Of Things/","items":[]},{"title":"WebID Specifications","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/WebID Specifications/","items":[]}]}]},{"title":"Temporal Semantics","url":"/WebizenTechStack/CoreTechnologies/TemporalSemantics/","items":[]}]},{"title":"Engineering Considerations","url":"/WebizenTechStack/EngineeringConsiderations/","items":[{"title":"Containerisation","url":"/WebizenTechStack/EngineeringConsiderations/Containerisation/","items":[]},{"title":"Cryptography","url":"/WebizenTechStack/EngineeringConsiderations/Cryptography/","items":[]},{"title":"Database Requirements","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/","items":[{"title":"DatabaseAlternatives","url":"","items":[{"title":"Akutan","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseAlternatives/akutan/","items":[]},{"title":"Apache Kafka","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseAlternatives/ApacheKafka/","items":[]},{"title":"Bad Wolf","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseAlternatives/BadWolf/","items":[]},{"title":"CayleyGraph","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseAlternatives/CayleyGraph/","items":[]}]},{"title":"DatabaseMethods","url":"","items":[{"title":"BQL","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseMethods/BQL/","items":[]},{"title":"GraphQL","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseMethods/GraphQL/","items":[]},{"title":"Sparql","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseMethods/Sparql/","items":[]}]}]},{"title":"Prolog","url":"/WebizenTechStack/EngineeringConsiderations/Prolog/","items":[]}]},{"title":"Internet","url":"/WebizenTechStack/Internet/","items":[{"title":"DNS Considerations","url":"/WebizenTechStack/Internet/DNSConsiderations/","items":[]},{"title":"List of Protocols ISO model","url":"/WebizenTechStack/Internet/ListOfProtocolsISOmodel/","items":[]}]},{"title":"The Role of Vocabulary","url":"/WebizenTechStack/LanguageModelling/","items":[{"title":"Dynamic Ontology","url":"/WebizenTechStack/LanguageModelling/ChatGPTDynamicOntology/","items":[]},{"title":"TopLevelOntologyNLPResearch","url":"/WebizenTechStack/LanguageModelling/TopLevelOntologyNLPResearch/","items":[]}]},{"title":"Webizen 3.0","url":"/WebizenTechStack/Webizen3.0/","items":[{"title":"Client Software Requirements","url":"/WebizenTechStack/Webizen3.0/ClientSoftwareRequirements/","items":[]},{"title":"Host Software Requirements","url":"/WebizenTechStack/Webizen3.0/HostServiceRequirements/","items":[{"title":"Domain Hosting","url":"/WebizenTechStack/Webizen3.0/HostServiceRequirements/DomainHosting/","items":[]},{"title":"Media Processing","url":"/WebizenTechStack/Webizen3.0/HostServiceRequirements/MediaProcessing/","items":[{"title":"Ffmpeg","url":"/WebizenTechStack/Webizen3.0/HostServiceRequirements/MediaProcessing/ffmpeg/","items":[]},{"title":"Opencv","url":"/WebizenTechStack/Webizen3.0/HostServiceRequirements/MediaProcessing/opencv/","items":[]}]},{"title":"Networking Considerations","url":"/WebizenTechStack/Webizen3.0/HostServiceRequirements/NetworkingConsiderations/","items":[]}]},{"title":"HyperMedia Containers","url":"/WebizenTechStack/Webizen3.0/HyperMediaContainers/","items":[{"title":"Knowledge Documents","url":"/WebizenTechStack/Webizen3.0/HyperMediaContainers/KnowledgeDocuments/","items":[]},{"title":"webizen.n3","url":"/WebizenTechStack/Webizen3.0/HyperMediaContainers/webizen.n3/","items":[]}]},{"title":"Webizen 2.5 Dev in GoLang","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/","items":[{"title":"Chat GPT Supported Notes","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/ChatGPTSupported/","items":[{"title":"Go WebID-OIDC & ChatGPT","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/ChatGPTSupported/GoLangWebIDOIDC/","items":[]}]},{"title":"DevNotesWebizen2.5","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/DevNotesWebizen2.5/","items":[]},{"title":"FunctionalObjectives","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/FunctionalObjectives/","items":[{"title":"FUNCTIONS","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/FunctionalObjectives/FUNCTIONS/","items":[]},{"title":"HelperAppObjectives","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/FunctionalObjectives/HelperAppObjectives/","items":[]},{"title":"PCT-NOTES","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/FunctionalObjectives/PCT-NOTES/","items":[]},{"title":"Webizen - Root Concepts","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/FunctionalObjectives/RootConcepts/","items":[]}]},{"title":"POC of Core Concepts","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/POCOfCoreConcepts/","items":[]},{"title":"POC: Ontology App Development","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/POCOntologyAppDev/","items":[]},{"title":"Sacrifices-Hard Problems","url":"/WebizenTechStack/Webizen3.0/goDevWebizen2.5/Sacrifices-hardproblems/","items":[]}]}]},{"title":"Webizen 3.5","url":"/WebizenTechStack/Webizen3.5/","items":[{"title":"AI Capabilities","url":"/WebizenTechStack/Webizen3.5/AICapabilities/","items":[{"title":"AI Capabilities Objectives","url":"/WebizenTechStack/Webizen3.5/AICapabilities/AICapabilitiesObjectives/","items":[]},{"title":"Audio & Video Analysis","url":"/WebizenTechStack/Webizen3.5/AICapabilities/Audio & Video Analysis/","items":[]},{"title":"Image Analysis","url":"/WebizenTechStack/Webizen3.5/AICapabilities/Image Analysis/","items":[]},{"title":"Text Analysis","url":"/WebizenTechStack/Webizen3.5/AICapabilities/Text Analysis/","items":[]}]},{"title":"Web Of Things (IoT)","url":"/WebizenTechStack/Webizen3.5/WebOfThings(IoT)/","items":[]},{"title":"Webizen AI OS Platform","url":"/WebizenTechStack/Webizen3.5/WebizenAiOS-Platform/","items":[]},{"title":"Webizen Pro Series","url":"/WebizenTechStack/Webizen3.5/WebizenProSeries/","items":[{"title":"Webizen Pro","url":"/WebizenTechStack/Webizen3.5/WebizenProSeries/WebizenPro/","items":[]},{"title":"Webizen Pro - Edge","url":"/WebizenTechStack/Webizen3.5/WebizenProSeries/WebizenPro-Edge/","items":[]},{"title":"WebizenProHardware","url":"/WebizenTechStack/Webizen3.5/WebizenProSeries/WebizenProHardware/","items":[]},{"title":"WebizenProSoftware","url":"/WebizenTechStack/Webizen3.5/WebizenProSeries/WebizenProSoftware/","items":[]}]},{"title":"Webizen Vision","url":"/WebizenTechStack/Webizen3.5/WebizenVision/","items":[]}]},{"title":"Webizen 4.0","url":"/WebizenTechStack/Webizen4.0/","items":[{"title":"MyWebizen","url":"/WebizenTechStack/Webizen4.0/MyWebizen/","items":[]}]},{"title":"Webizen Apps","url":"/WebizenTechStack/WebizenApps/","items":[{"title":"Historical RWW Apps","url":"/WebizenTechStack/WebizenApps/Historical RWW Apps/","items":[]},{"title":"Webizen 3.5 Apps","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/","items":[{"title":"Media Production","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/MediaProduction/","items":[]},{"title":"Mobile Apps","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/MobileApps/","items":[{"title":"Android","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/MobileApps/Android/","items":[]},{"title":"iOS","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/MobileApps/iOS/","items":[]},{"title":"The Webizen (mobile) Agent","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/MobileApps/TheWebizen(mobile)Agent/","items":[]}]},{"title":"Search","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/Search/","items":[]},{"title":"Webizen Host Apps","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/HostApps/","items":[{"title":"Email Services","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/HostApps/EmailServices/","items":[]},{"title":"Webizen Server - WebApps","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/HostApps/WebizenServer-WebApps/","items":[]},{"title":"Website Hosting","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/HostApps/WebsiteHost/","items":[]}]},{"title":"Webizen Manager","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/WebizenManager/","items":[]}]},{"title":"Webizen Interfaces","url":"/WebizenTechStack/WebizenApps/WebizenInterfaces/","items":[{"title":"TheWebizen","url":"/WebizenTechStack/WebizenApps/WebizenInterfaces/TheWebizen/","items":[]}]},{"title":"Webizen3.0Apps","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/","items":[{"title":"Design Goals","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/DesignGoals/","items":[]},{"title":"MobileBasics","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/MobileBasics/","items":[]},{"title":"WADE No-Code - Low-Code","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/NoCodeAppDev/","items":[]},{"title":"Webizen App Spec","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/WebizenAppSpec/","items":[{"title":"DOAP Form Example","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/WebizenAppSpec/DOAP form Example/","items":[]},{"title":"WebSpec","url":"","items":[{"title":"HTML SPECS","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/WebizenAppSpec/WebSpec/HTML SPECS/","items":[]},{"title":"Query Interfaces","url":"","items":[{"title":"GraphQL Query Specs","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/WebizenAppSpec/WebSpec/Query Interfaces/GraphQL Query Specs/","items":[]}]},{"title":"WebPlatformTools","url":"","items":[{"title":"WebAuthn","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/WebizenAppSpec/WebSpec/WebPlatformTools/WebAuthn/","items":[]},{"title":"WebDav","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/WebizenAppSpec/WebSpec/WebPlatformTools/WebDav/","items":[]}]}]}]},{"title":"Webizen Core Apps","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/","items":[{"title":"Agent Directory","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/AgentDirectory/","items":[]},{"title":"Cookie Monster","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/CookieMonster/","items":[]},{"title":"Credentials & Contracts Manager","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Credentials & Contracts Manager/","items":[]},{"title":"HyperMedia Library","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/HyperMediaLibrary/","items":[]},{"title":"Knowledge Clouds","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/KnowledgeClouds/","items":[]},{"title":"Library","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Library/","items":[]},{"title":"TemporalApps","url":"","items":[{"title":"Calendar","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/TemporalApps/Calendar/","items":[]},{"title":"Timeline Interface","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/TemporalApps/Timeline Interface/","items":[]}]},{"title":"The Work Platform","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/TheWorkPlatform/","items":[]},{"title":"Webizen Social","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/WebizenSocial/","items":[]}]},{"title":"Webizen-Connect","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/Webizen-Connect/","items":[{"title":"Data Applications","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/Webizen-Connect/Data Applications/","items":[]},{"title":"Social Media APIs","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/Webizen-Connect/Social Media APIs/","items":[]}]}]}]}]},{"title":"Work in Progress","url":"/WorkInProgress/","items":[]}]}],"tagsGroups":[],"latestPosts":[{"fields":{"slug":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/DAT/","title":"DAT","lastUpdatedAt":"2023-01-18T16:34:54.000Z","lastUpdated":"1/18/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/Holochain/","title":"Holochain","lastUpdatedAt":"2023-01-18T16:34:54.000Z","lastUpdated":"1/18/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/IPLD/","title":"IPLD","lastUpdatedAt":"2023-01-18T16:34:54.000Z","lastUpdated":"1/18/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/WebizenTechStack/CoreTechnologies/SemanticWeb/GRDDL/","title":"GRDDL","lastUpdatedAt":"2023-01-18T16:34:54.000Z","lastUpdated":"1/18/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/DAML+OIL/","title":"DAML+OIL","lastUpdatedAt":"2023-01-18T16:34:54.000Z","lastUpdated":"1/18/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/HumanRightsOntologies/","title":"HumanRightsOntologies","lastUpdatedAt":"2023-01-18T16:34:54.000Z","lastUpdated":"1/18/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/LKIF-Core/","title":"LKIF-Core","lastUpdatedAt":"2023-01-18T16:34:54.000Z","lastUpdated":"1/18/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/FOAF/","title":"Friend of a Friend (FOAF) Core","lastUpdatedAt":"2023-01-18T16:34:54.000Z","lastUpdated":"1/18/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/WebizenTechStack/CoreTechnologies/SemanticWeb/Ontologies/HumanRightsOntologies/UDHR/","title":"UDHR","lastUpdatedAt":"2023-01-18T16:34:54.000Z","lastUpdated":"1/18/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/PermissiveCommonsTech/","title":"Permissive Commons Tech","lastUpdatedAt":"2023-01-18T16:25:14.000Z","lastUpdated":"1/18/2023"},"frontmatter":{"draft":false,"tags":[]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}