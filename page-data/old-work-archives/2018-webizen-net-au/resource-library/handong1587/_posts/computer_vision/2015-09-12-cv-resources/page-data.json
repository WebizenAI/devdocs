{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-12-cv-resources/",
    "result": {"data":{"mdx":{"id":"6b6567a1-4ce4-54b6-886b-94515d909470","tableOfContents":{"items":[{"url":"#courses","title":"Courses"},{"url":"#images-denoising","title":"Images Denoising"},{"url":"#image-blur--deblur","title":"Image Blur / Deblur"},{"url":"#painting","title":"Painting"},{"url":"#image-retrieval","title":"Image Retrieval"},{"url":"#image-summary","title":"Image Summary"},{"url":"#image-retargeting--editing","title":"Image Retargeting / Editing"},{"url":"#image-inpaiting","title":"Image Inpaiting"},{"url":"#image-dithering","title":"Image Dithering"},{"url":"#image-enhancement","title":"Image Enhancement"},{"url":"#image-resizing","title":"Image Resizing"},{"url":"#image-cloning","title":"Image Cloning"},{"url":"#image-compositing","title":"Image Compositing"},{"url":"#image-stylization","title":"Image Stylization"},{"url":"#image-haze-removal","title":"Image Haze Removal"},{"url":"#image-blending","title":"Image Blending","items":[{"url":"#linear-blending","title":"Linear Blending"},{"url":"#poisson-blending","title":"Poisson Blending"}]},{"url":"#image-stitching","title":"Image Stitching"},{"url":"#image-super-resolution","title":"Image Super-Resolution"},{"url":"#photo-collage","title":"Photo Collage"},{"url":"#video-collage","title":"Video Collage"},{"url":"#video-tapestry","title":"Video Tapestry"},{"url":"#video-creativity","title":"Video Creativity"},{"url":"#video-highlights","title":"Video Highlights"},{"url":"#video-summarization","title":"Video Summarization"},{"url":"#activity-recognition","title":"Activity Recognition"},{"url":"#virtual-reality-vr","title":"Virtual Reality (VR)"},{"url":"#slam","title":"SLAM"},{"url":"#optical-flow","title":"Optical Flow"},{"url":"#ocr","title":"OCR"},{"url":"#codec","title":"Codec"},{"url":"#face-alignment","title":"Face Alignment"},{"url":"#papers","title":"Papers"},{"url":"#applications","title":"Applications"},{"url":"#projects","title":"Projects"},{"url":"#resources","title":"Resources"},{"url":"#libraries","title":"Libraries"},{"url":"#datasets","title":"Datasets"},{"url":"#blogs","title":"Blogs"},{"url":"#conferences","title":"Conferences"},{"url":"#resources-1","title":"Resources"}]},"fields":{"title":"Computer Vision Resources","slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-12-cv-resources/","url":"https://devdocs.webizen.org/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-12-cv-resources/","editUrl":"https://github.com/webizenai/devdocs/tree/main/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-12-cv-resources.md","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022","gitCreatedAt":"2022-12-28T19:22:29.000Z","shouldShowTitle":true},"frontmatter":{"title":"Computer Vision Resources","description":null,"imageAlt":null,"tags":[],"date":"2015-09-12T00:00:00.000Z","dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"layout\": \"post\",\n  \"category\": \"computer_vision\",\n  \"title\": \"Computer Vision Resources\",\n  \"date\": \"2015-09-12T00:00:00.000Z\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"courses\"\n  }, \"Courses\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mobile Computer Vision (Spring 2015)\")), mdx(\"img\", {\n    \"src\": \"http://web.stanford.edu/class/cs231m/assets/img/course-splash.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://web.stanford.edu/class/cs231m/\"\n  }, \"http://web.stanford.edu/class/cs231m/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"syllabus: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://web.stanford.edu/class/cs231m/syllabus.html\"\n  }, \"http://web.stanford.edu/class/cs231m/syllabus.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"projects: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://web.stanford.edu/class/cs231m/projects.html\"\n  }, \"http://web.stanford.edu/class/cs231m/projects.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"resources: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://web.stanford.edu/class/cs231m/resources.html\"\n  }, \"http://web.stanford.edu/class/cs231m/resources.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CSCI1950-G Computational Photography\")), mdx(\"img\", {\n    \"src\": \"http://cs.brown.edu/courses/csci1950-g/images/montage_large.jpg\",\n    \"alt\": null\n  }), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://cs.brown.edu/courses/csci1950-g/\"\n  }, \"http://cs.brown.edu/courses/csci1950-g/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MIT CSAIL: 6.819/6.869: Advances in Computer Vision (Fall 2015)\")), mdx(\"img\", {\n    \"src\": \"http://6.869.csail.mit.edu/fa15/images/teaser.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://6.869.csail.mit.edu/fa15/index.html\"\n  }, \"http://6.869.csail.mit.edu/fa15/index.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"EECS 432 Advanced Computer Vision\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"course website: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.ece.northwestern.edu/~yingwu/teaching/EECS432/index.html\"\n  }, \"http://www.ece.northwestern.edu/~yingwu/teaching/EECS432/index.html\"), \"c\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"handouts: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.ece.northwestern.edu/~yingwu/teaching/EECS432/EECS432_hand.html\"\n  }, \"http://www.ece.northwestern.edu/~yingwu/teaching/EECS432/EECS432_hand.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"EECS 286 Advanced Topics in Computer Vision\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://faculty.ucmerced.edu/mhyang/course/eecs286/index.htm\"\n  }, \"http://faculty.ucmerced.edu/mhyang/course/eecs286/index.htm\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"syllabus: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://faculty.ucmerced.edu/mhyang/course/eecs286/syllabus.htm\"\n  }, \"http://faculty.ucmerced.edu/mhyang/course/eecs286/syllabus.htm\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"lectures: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://faculty.ucmerced.edu/mhyang/course/eecs286/lecture.htm\"\n  }, \"http://faculty.ucmerced.edu/mhyang/course/eecs286/lecture.htm\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"lecture(\\\"How to get your CVPR paper rejected?\\\"): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://faculty.ucmerced.edu/mhyang/course/eecs286/lectures/introduction.pptx\"\n  }, \"http://faculty.ucmerced.edu/mhyang/course/eecs286/lectures/introduction.pptx\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CS280: Computer Vision (University of California Berkeley)\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www-inst.eecs.berkeley.edu/~cs280/sp15/index.html\"\n  }, \"http://www-inst.eecs.berkeley.edu/~cs280/sp15/index.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"lectures: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://docs.huihoo.com/computer-vision/berkeley/cs280-computer-vision/\"\n  }, \"http://docs.huihoo.com/computer-vision/berkeley/cs280-computer-vision/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CSCI2951-T Data-driven Computer Vision (Spring 2016)\")), mdx(\"img\", {\n    \"src\": \"http://cs.brown.edu/courses/csci2951-t/images/detection_teaser.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"instructor: Genevieve Patterson\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cs.brown.edu/courses/csci2951-t/\"\n  }, \"http://cs.brown.edu/courses/csci2951-t/\"))), mdx(\"h1\", {\n    \"id\": \"images-denoising\"\n  }, \"Images Denoising\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast Burst Images Denoising\")), mdx(\"img\", {\n    \"src\": \"http://personal.ie.cuhk.edu.hk/~lz013/projects/burstdenoising/intro.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SIGGRAPH Asia 2014. CUHK, Microsoft Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://personal.ie.cuhk.edu.hk/~lz013/projects/BurstDenoising.html\"\n  }, \"http://personal.ie.cuhk.edu.hk/~lz013/projects/BurstDenoising.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://personal.ie.cuhk.edu.hk/~lz013/papers/burstdenoising.pdf\"\n  }, \"http://personal.ie.cuhk.edu.hk/~lz013/papers/burstdenoising.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Robust non-linear regression analysis: A greedy approach employing kernels and application to image denoising\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: KGARD\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1601.00595\"\n  }, \"http://arxiv.org/abs/1601.00595\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code(Matlab): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://bouboulis.mysch.gr/kernels.html\"\n  }, \"http://bouboulis.mysch.gr/kernels.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Blind Image Denoising via Dependent Dirichlet Process Tree\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1601.03117\"\n  }, \"http://arxiv.org/abs/1601.03117\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Image denoising via group sparsity residual constraint\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.03302\"\n  }, \"http://arxiv.org/abs/1609.03302\"))), mdx(\"h1\", {\n    \"id\": \"image-blur--deblur\"\n  }, \"Image Blur / Deblur\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Motion Blurred Images Generation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://home.deib.polimi.it/boracchi/Projects/PSFGeneration.html\"\n  }, \"http://home.deib.polimi.it/boracchi/Projects/PSFGeneration.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code(Matlab): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://home.deib.polimi.it/boracchi/Projects/PSF_generation/PSF_generation.zip\"\n  }, \"http://home.deib.polimi.it/boracchi/Projects/PSF_generation/PSF_generation.zip\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Blind Image Deblurring Using Dark Channel Prior\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Good Regions to Deblur\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://eng.ucmerced.edu/people/zhu/GoodRegion.html\"\n  }, \"https://eng.ucmerced.edu/people/zhu/GoodRegion.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://eng.ucmerced.edu/people/zhu/ECCV12.pdf\"\n  }, \"https://eng.ucmerced.edu/people/zhu/ECCV12.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code(Matlab): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://eng.ucmerced.edu/people/zhu/ECCV12_code.zip\"\n  }, \"https://eng.ucmerced.edu/people/zhu/ECCV12_code.zip\"))), mdx(\"h1\", {\n    \"id\": \"painting\"\n  }, \"Painting\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Real-Time Gradient-Domain Painting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SIGGRAPH 2009\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://graphics.cs.cmu.edu/projects/gradient-paint/\"\n  }, \"http://graphics.cs.cmu.edu/projects/gradient-paint/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://graphics.cs.cmu.edu/projects/gradient-paint/grad.light.r2226.pdf\"\n  }, \"http://graphics.cs.cmu.edu/projects/gradient-paint/grad.light.r2226.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sketch2Photo: Internet Image Montage\")), mdx(\"img\", {\n    \"src\": \"http://cg.cs.tsinghua.edu.cn/montage/figures/teaser.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM SIGGRAPH ASIA 2009\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cg.cs.tsinghua.edu.cn/montage/main.htm\"\n  }, \"http://cg.cs.tsinghua.edu.cn/montage/main.htm\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cg.cs.tsinghua.edu.cn/montage/files/montage.pdf\"\n  }, \"http://cg.cs.tsinghua.edu.cn/montage/files/montage.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Combining Sketch and Tone for Pencil Drawing Production\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NPAR 2012 Best Paper Award\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cse.cuhk.edu.hk/~leojia/projects/pencilsketch/pencil_drawing.htm\"\n  }, \"http://www.cse.cuhk.edu.hk/~leojia/projects/pencilsketch/pencil_drawing.htm\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cse.cuhk.edu.hk/~leojia/projects/pencilsketch/npar12_pencil.pdf\"\n  }, \"http://www.cse.cuhk.edu.hk/~leojia/projects/pencilsketch/npar12_pencil.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/fumin/pencil\"\n  }, \"https://github.com/fumin/pencil\"))), mdx(\"h1\", {\n    \"id\": \"image-retrieval\"\n  }, \"Image Retrieval\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-modal image retrieval with random walk on multi-layer graphs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1607.03406\"\n  }, \"http://arxiv.org/abs/1607.03406\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Content-based image retrieval tutorial\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: KNN, SVM, MatLab GUI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.03811\"\n  }, \"http://arxiv.org/abs/1608.03811\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kirk86/ImageRetrieval\"\n  }, \"https://github.com/kirk86/ImageRetrieval\"))), mdx(\"h1\", {\n    \"id\": \"image-summary\"\n  }, \"Image Summary\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Summarizing Visual Data Using Bidirectional Similarity\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://denis.simakov.info/weizmann/summarization_talk_20101116/summarization.html\"\n  }, \"http://denis.simakov.info/weizmann/summarization_talk_20101116/summarization.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.wisdom.weizmann.ac.il/~vision/VisualSummary/bidirectional_similarity_CVPR2008.pdf\"\n  }, \"http://www.wisdom.weizmann.ac.il/~vision/VisualSummary/bidirectional_similarity_CVPR2008.pdf\"))), mdx(\"h1\", {\n    \"id\": \"image-retargeting--editing\"\n  }, \"Image Retargeting / Editing\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PatchMatch: A Randomized Correspondence Algorithm for Structural Image Editing\")), mdx(\"img\", {\n    \"src\": \"http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/patchmatch_title.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage(paper+code): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/\"\n  }, \"http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/patchmatch.pdf\"\n  }, \"http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/patchmatch.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/patchmatch-2.1.zip\"\n  }, \"http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/patchmatch-2.1.zip\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Generalized PatchMatch Correspondence Algorithm\")), mdx(\"img\", {\n    \"src\": \"http://gfx.cs.princeton.edu/pubs/Barnes_2010_TGP/gpm_teaser.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homapage(paper+code): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://gfx.cs.princeton.edu/pubs/Barnes_2010_TGP/index.php\"\n  }, \"http://gfx.cs.princeton.edu/pubs/Barnes_2010_TGP/index.php\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://gfx.cs.princeton.edu/pubs/Barnes_2010_TGP/generalized_pm.pdf\"\n  }, \"http://gfx.cs.princeton.edu/pubs/Barnes_2010_TGP/generalized_pm.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.princeton.edu/gfx/pubs/Barnes_2009_PAR/patchmatch-2.0.zip\"\n  }, \"http://www.cs.princeton.edu/gfx/pubs/Barnes_2009_PAR/patchmatch-2.0.zip\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Seamless Image Editing\")), mdx(\"img\", {\n    \"src\": \"http://www.cmlab.csie.ntu.edu.tw/~dreamway/seamless/img/teaser.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cmlab.csie.ntu.edu.tw/~dreamway/seamless/\"\n  }, \"http://www.cmlab.csie.ntu.edu.tw/~dreamway/seamless/\"))), mdx(\"h1\", {\n    \"id\": \"image-inpaiting\"\n  }, \"Image Inpaiting\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Patch-based Texture Synthesis for Image Inpainting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.01576\"\n  }, \"http://arxiv.org/abs/1605.01576\"))), mdx(\"h1\", {\n    \"id\": \"image-dithering\"\n  }, \"Image Dithering\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Image Dithering: Eleven Algorithms and Source Code\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.tannerhelland.com/4660/dithering-eleven-algorithms-source-code/\"\n  }, \"http://www.tannerhelland.com/4660/dithering-eleven-algorithms-source-code/\"))), mdx(\"h1\", {\n    \"id\": \"image-enhancement\"\n  }, \"Image Enhancement\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"LIME: A Method for Low-light IMage Enhancement\")), mdx(\"img\", {\n    \"src\": \"http://photo.weibo.com/2578103464/wbphotos/large/mid/3971098712490115/pid/99aabca8jw1f3ibhb6o8ej20ck09cmzl\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.05034\"\n  }, \"http://arxiv.org/abs/1605.05034\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cs.tju.edu.cn/orgs/vision/~xguo/code/LIME.zip\"\n  }, \"http://cs.tju.edu.cn/orgs/vision/~xguo/code/LIME.zip\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"author homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cs.tju.edu.cn/orgs/vision/~xguo/homepage.htm\"\n  }, \"http://cs.tju.edu.cn/orgs/vision/~xguo/homepage.htm\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SelPh: Progressive Learning and Support of Manual Photo Color Enhancement\")), mdx(\"img\", {\n    \"src\": \"http://koyama.xyz/project/SelPh/teaser1.gif\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://koyama.xyz/project/SelPh/\"\n  }, \"http://koyama.xyz/project/SelPh/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://koyama.xyz/project/SelPh/chi2016_paper.pdf\"\n  }, \"http://koyama.xyz/project/SelPh/chi2016_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"bitbucket: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://bitbucket.org/yukikoyama/selph/\"\n  }, \"https://bitbucket.org/yukikoyama/selph/\"))), mdx(\"h1\", {\n    \"id\": \"image-resizing\"\n  }, \"Image Resizing\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://parellagram.com/posts/carving\"\n  }, \"http://parellagram.com/posts/carving\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aaparella/carve\"\n  }, \"https://github.com/aaparella/carve\"))), mdx(\"h1\", {\n    \"id\": \"image-cloning\"\n  }, \"Image Cloning\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Coordinates for Instant Image Cloning\")), mdx(\"img\", {\n    \"src\": \"http://www.cs.huji.ac.il/~danix/mvclone/teaser.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SIGGRAPH 2009\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.huji.ac.il/~danix/mvclone/\"\n  }, \"http://www.cs.huji.ac.il/~danix/mvclone/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.huji.ac.il/~danix/mvclone/files/mvc-final-opt.pdf\"\n  }, \"http://www.cs.huji.ac.il/~danix/mvclone/files/mvc-final-opt.pdf\"))), mdx(\"h1\", {\n    \"id\": \"image-compositing\"\n  }, \"Image Compositing\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Interactive Digital Photomontage\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SIGGRAPH 2004\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://grail.cs.washington.edu/projects/photomontage/\"\n  }, \"http://grail.cs.washington.edu/projects/photomontage/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://grail.cs.washington.edu/projects/photomontage/release/\"\n  }, \"http://grail.cs.washington.edu/projects/photomontage/release/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://grail.cs.washington.edu/projects/photomontage/photomontage.pdf\"\n  }, \"http://grail.cs.washington.edu/projects/photomontage/photomontage.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.researchgate.net/publication/2941744_Interactive_Digital_Photomontage\"\n  }, \"http://www.researchgate.net/publication/2941744_Interactive_Digital_Photomontage\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Panorama Stitching\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CS510 Visual Computing, Project 2: Panorama Stitching\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://web.cecs.pdx.edu/~kstew2/cs510vision/stitcher/\"\n  }, \"http://web.cecs.pdx.edu/~kstew2/cs510vision/stitcher/\")), mdx(\"h1\", {\n    \"id\": \"image-stylization\"\n  }, \"Image Stylization\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"stylize: Regressor based image stylization\")), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/Newmu/stylize/master/resources/iggy.gif\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Newmu/stylize\"\n  }, \"https://github.com/Newmu/stylize\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Procedurally Generating Stylized Farmland Scenes\")), mdx(\"img\", {\n    \"src\": \"http://graphics.cs.williams.edu/courses/cs371/f16/gallery/4-midterm/terrain/TopImage.jpg\",\n    \"alt\": null\n  }), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://graphics.cs.williams.edu/courses/cs371/f16/gallery/4-midterm/terrain/report.md.html\"\n  }, \"http://graphics.cs.williams.edu/courses/cs371/f16/gallery/4-midterm/terrain/report.md.html\")), mdx(\"h1\", {\n    \"id\": \"image-haze-removal\"\n  }, \"Image Haze Removal\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Single Image Haze Removal\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://research.microsoft.com/en-us/um/people/kahe/cvpr09/\"\n  }, \"http://research.microsoft.com/en-us/um/people/kahe/cvpr09/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DehazeNet: An End-to-End System for Single Image Haze Removal\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1601.07661\"\n  }, \"http://arxiv.org/abs/1601.07661\"))), mdx(\"h1\", {\n    \"id\": \"image-blending\"\n  }, \"Image Blending\"), mdx(\"p\", null, \"Linear Blending, Poisson Blending, Multiband Blending, Feather Blending, Alpha Blending, Laplacian Blending\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Image Blending\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"course-info: 15-463: Computational Photography. Alexei Efros, CMU, Spring 2010\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"lecture: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://graphics.cs.cmu.edu/courses/15-463/2010_spring/Lectures/blending.pdf\"\n  }, \"http://graphics.cs.cmu.edu/courses/15-463/2010_spring/Lectures/blending.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CS 195-G: Image Blending\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://cs.brown.edu/courses/csci1950-g/results/proj2/edwallac/\"\n  }, \"https://cs.brown.edu/courses/csci1950-g/results/proj2/edwallac/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Panoramic Image Mosaic\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://pages.cs.wisc.edu/~csverma/CS766_09/ImageMosaic/imagemosaic.html\"\n  }, \"http://pages.cs.wisc.edu/~csverma/CS766_09/ImageMosaic/imagemosaic.html\"))), mdx(\"h2\", {\n    \"id\": \"linear-blending\"\n  }, \"Linear Blending\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Adding (blending) two images using OpenCV\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://docs.opencv.org/master/d5/dc4/tutorial_adding_images.html#gsc.tab=0\"\n  }, \"http://docs.opencv.org/master/d5/dc4/tutorial_adding_images.html#gsc.tab=0\")), mdx(\"h2\", {\n    \"id\": \"poisson-blending\"\n  }, \"Poisson Blending\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Poisson Image Editing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SIGGRAPH 2003\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cs.brown.edu/courses/csci1290/asgn/proj2/resources/PoissonImageEditing.pdf\"\n  }, \"http://cs.brown.edu/courses/csci1290/asgn/proj2/resources/PoissonImageEditing.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.cs.jhu.edu/~misha/Fall07/Papers/Perez03.pdf\"\n  }, \"https://www.cs.jhu.edu/~misha/Fall07/Papers/Perez03.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://graphics.ethz.ch/teaching/former/seminar/handouts/Weyrich_PoissonImageEditing.pdf\"\n  }, \"https://graphics.ethz.ch/teaching/former/seminar/handouts/Weyrich_PoissonImageEditing.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code(Matlab+C#): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://code.google.com/p/imageblending/\"\n  }, \"https://code.google.com/p/imageblending/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/fbessho/PyPoi\"\n  }, \"https://github.com/fbessho/PyPoi\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(C++): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/cheind/poisson-image-editing\"\n  }, \"https://github.com/cheind/poisson-image-editing\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Poisson Blending\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://eric-yuan.me/poisson-blending/\"\n  }, \"http://eric-yuan.me/poisson-blending/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Poisson Blending II\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://eric-yuan.me/poisson-blending-2/\"\n  }, \"http://eric-yuan.me/poisson-blending-2/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://codepad.org/ANqtikKR\"\n  }, \"http://codepad.org/ANqtikKR\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Solving the Discrete Poisson Equation using Jacobi, SOR, Conjugate Gradients, and the FFT\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CS267: Lectures 15 and 16, Mar 5 and 7 1996\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"lecture: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.berkeley.edu/~demmel/cs267/lecture24/lecture24.html\"\n  }, \"http://www.cs.berkeley.edu/~demmel/cs267/lecture24/lecture24.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Gradient Domain Fusion Using Poisson Blending\")), mdx(\"img\", {\n    \"src\": \"http://120.52.72.72/cs.brown.edu/c3pr90ntcsf0/courses/cs129/results/proj2/taox/images/result_09.jpg\",\n    \"alt\": null\n  }), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://cs.brown.edu/courses/cs129/results/proj2/taox/\"\n  }, \"http://cs.brown.edu/courses/cs129/results/proj2/taox/\")), mdx(\"h1\", {\n    \"id\": \"image-stitching\"\n  }, \"Image Stitching\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Natural and Seamless Image Composition with Color Control\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://www3.ntu.edu.sg/home/asjfcai/tip04594.pdf\"\n  }, \"http://www3.ntu.edu.sg/home/asjfcai/tip04594.pdf\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object-aware Gradient-Domain Image Compositing\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://www.cg.cs.tu-bs.de/media/publications/Eisemann11OAG.pdf\"\n  }, \"http://www.cg.cs.tu-bs.de/media/publications/Eisemann11OAG.pdf\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improving Image Matting using Comprehensive Sampling Sets\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Shahrian_Improving_Image_Matting_2013_CVPR_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Shahrian_Improving_Image_Matting_2013_CVPR_paper.pdf\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-scale Image Harmonization\")), mdx(\"img\", {\n    \"src\": \"http://gvi.seas.harvard.edu/sites/all/files/paper-rep-images/harmonization_teaser_3.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://gvi.seas.harvard.edu/paper/multiscale-image-harmonization\"\n  }, \"http://gvi.seas.harvard.edu/paper/multiscale-image-harmonization\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://gvi.seas.harvard.edu/sites/all/files/Harmonization_SIGGRAPH10.pdf\"\n  }, \"http://gvi.seas.harvard.edu/sites/all/files/Harmonization_SIGGRAPH10.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://gvi.seas.harvard.edu/sites/all/files/Harmonization_SIGGRAPH10.pptx\"\n  }, \"http://gvi.seas.harvard.edu/sites/all/files/Harmonization_SIGGRAPH10.pptx\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Drag-and-Drop Pasting\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://research.microsoft.com/pubs/69331/dragdroppasting_siggraph06.pdf\"\n  }, \"http://research.microsoft.com/pubs/69331/dragdroppasting_siggraph06.pdf\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cross Dissolve Without Cross Fade: Preserving Contrast, Color and Salience in Image Compositing\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.cl.cam.ac.uk/research/rainbow/projects/compositing/EG06-Cross-Dissolve-Without-Cross-Fade.pdf\"\n  }, \"https://www.cl.cam.ac.uk/research/rainbow/projects/compositing/EG06-Cross-Dissolve-Without-Cross-Fade.pdf\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Snap Image Composition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://www.cs.huji.ac.il/~peleg/papers/SnapComposition.pdf\"\n  }, \"http://www.cs.huji.ac.il/~peleg/papers/SnapComposition.pdf\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Stitching Stabilizer: Two-frame-stitching Video Stabilization for Embedded Systems\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.06678\"\n  }, \"http://arxiv.org/abs/1603.06678\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Stitching and Matting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"lectures: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2015/bil721/lectures/w06-stitching-matting.pdf\"\n  }, \"http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2015/bil721/lectures/w06-stitching-matting.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Image Stitching\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"lectures: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://courses.engr.illinois.edu/cs498dwh/fa2010/lectures/Lecture%2017%20-%20Photo%20Stitching.pdf\"\n  }, \"https://courses.engr.illinois.edu/cs498dwh/fa2010/lectures/Lecture%2017%20-%20Photo%20Stitching.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Graphics isn't all about 3-D\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"lectures: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://www.cs.cmu.edu/afs/cs/academic/class/15462-s09/www/lec/25/lec25.pdf\"\n  }, \"http://www.cs.cmu.edu/afs/cs/academic/class/15462-s09/www/lec/25/lec25.pdf\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://upcommons.upc.edu/bitstream/handle/2099.1/22861/PujolAlba-TFG-FinalReport.pdf;jsessionid=7AE46AE2A5420F75760F246381D429BC?sequence=5\"\n  }, \"http://upcommons.upc.edu/bitstream/handle/2099.1/22861/PujolAlba-TFG-FinalReport.pdf;jsessionid=7AE46AE2A5420F75760F246381D429BC?sequence=5\")))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Assignment: Image stitching with RANSAC\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"assignments: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://people.cs.umass.edu/~elm/Teaching/Docs/assign_RANSAC.pdf\"\n  }, \"https://people.cs.umass.edu/~elm/Teaching/Docs/assign_RANSAC.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"OpenCV panorama stitching\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.pyimagesearch.com/2016/01/11/opencv-panorama-stitching/\"\n  }, \"http://www.pyimagesearch.com/2016/01/11/opencv-panorama-stitching/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Real-time panorama and image stitching with OpenCV\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.pyimagesearch.com/2016/01/25/real-time-panorama-and-image-stitching-with-opencv/\"\n  }, \"http://www.pyimagesearch.com/2016/01/25/real-time-panorama-and-image-stitching-with-opencv/\"))), mdx(\"h1\", {\n    \"id\": \"image-super-resolution\"\n  }, \"Image Super-Resolution\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Super-Resolution From a Single Image\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.wisdom.weizmann.ac.il/~vision/SingleImageSR.html\"\n  }, \"http://www.wisdom.weizmann.ac.il/~vision/SingleImageSR.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.wisdom.weizmann.ac.il/~vision/single_image_SR/files/single_image_SR.pdf\"\n  }, \"http://www.wisdom.weizmann.ac.il/~vision/single_image_SR/files/single_image_SR.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Aperture-scanning Fourier ptychography for 3D refocusing and super-resolution macroscopic imaging\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.its.caltech.edu/~roarke/research/FPM/FPM_Aperture_Scanning.pdf\"\n  }, \"http://www.its.caltech.edu/~roarke/research/FPM/FPM_Aperture_Scanning.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6754138\"\n  }, \"http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6754138\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Single Image Super-Resolution from Transformed Self-Exemplars\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://sites.google.com/site/jbhuang0604/publications/struct_sr\"\n  }, \"https://sites.google.com/site/jbhuang0604/publications/struct_sr\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jbhuang0604/SelfExSR\"\n  }, \"https://github.com/jbhuang0604/SelfExSR\"))), mdx(\"h1\", {\n    \"id\": \"photo-collage\"\n  }, \"Photo Collage\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AutoCollage\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SIGGRAPH 2006\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://research.microsoft.com/en-us/projects/i3l/autocollage.aspx\"\n  }, \"http://research.microsoft.com/en-us/projects/i3l/autocollage.aspx\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://research.microsoft.com/pubs/67894/autocollage_rotheretal_siggraph2006.pdf\"\n  }, \"http://research.microsoft.com/pubs/67894/autocollage_rotheretal_siggraph2006.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://research.microsoft.com/en-us/UM/cambridge/projects/VisionImageVideoEditing/autocollage/TalkSiggraph2006Compressed.zip\"\n  }, \"http://research.microsoft.com/en-us/UM/cambridge/projects/VisionImageVideoEditing/autocollage/TalkSiggraph2006Compressed.zip\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://research.microsoft.com/en-us/um/cambridge/projects/autocollage/\"\n  }, \"http://research.microsoft.com/en-us/um/cambridge/projects/autocollage/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Picture Collage\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: 2006\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://research.microsoft.com/en-us/um/people/jiansun/papers/PictureCollage_CVPR2006.pdf\"\n  }, \"http://research.microsoft.com/en-us/um/people/jiansun/papers/PictureCollage_CVPR2006.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.89.5727\"\n  }, \"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.89.5727\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Picture Collage\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: 2009\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mmlab.ie.cuhk.edu.hk/archive/2009/07_Picture.pdf\"\n  }, \"http://mmlab.ie.cuhk.edu.hk/archive/2009/07_Picture.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Efficient Optimization of Photo Collage\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://research.microsoft.com/pubs/80783/Collage_techreport.pdf\"\n  }, \"http://research.microsoft.com/pubs/80783/Collage_techreport.pdf\"))), mdx(\"h1\", {\n    \"id\": \"video-collage\"\n  }, \"Video Collage\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Stained-Glass Visualization for Highly Condensed Video Summaries (ICME 2004)\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICME 2004\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.fxpal.com/publications/stained-glass-visualization-for-highly-condensed-video-summaries.pdf\"\n  }, \"https://www.fxpal.com/publications/stained-glass-visualization-for-highly-condensed-video-summaries.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video collage: A novel presentation of video sequence\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICME 2007\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.130.3728&rep=rep1&type=pdf\"\n  }, \"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.130.3728&rep=rep1&type=pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Stained Glass Photo Collages\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://uist.acm.org/archive/adjunct/2004/pdf/posters/p7-girgensohn.pdf\"\n  }, \"http://uist.acm.org/archive/adjunct/2004/pdf/posters/p7-girgensohn.pdf\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Visual Storylines: Semantic Visualization of Movie Sequence\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cg.cs.tsinghua.edu.cn/papers/C&G2012_videostoryline.pdf\"\n  }, \"http://cg.cs.tsinghua.edu.cn/papers/C&G2012_videostoryline.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cg.cs.tsinghua.edu.cn/people/~taochen/papers/VisualStorylines.pdf\"\n  }, \"http://cg.cs.tsinghua.edu.cn/people/~taochen/papers/VisualStorylines.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video collage: presenting a video sequence using a single image\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://iris.usc.edu/people/yangbo/papers/vcj08.pdf\"\n  }, \"http://iris.usc.edu/people/yangbo/papers/vcj08.pdf\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Efficient Optimization of Photo Collage\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://research.microsoft.com/en-us/people/yichenw/collage_techreport.pdf\"\n  }, \"http://research.microsoft.com/en-us/people/yichenw/collage_techreport.pdf\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Puzzle-like Collage (2010)\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://webee.technion.ac.il/~ayellet/Ps/10-PuzzleCollage.pdf\"\n  }, \"http://webee.technion.ac.il/~ayellet/Ps/10-PuzzleCollage.pdf\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Browsing Large Image Datasets through Voronoi Diagrams\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=576998825C3E40A32826A00B64089DF6?doi=10.1.1.230.5997&rep=rep1&type=pdf\"\n  }, \"http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=576998825C3E40A32826A00B64089DF6?doi=10.1.1.230.5997&rep=rep1&type=pdf\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Content-aware Photo Collage Using Circle Packing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: TVCG 2014. NJU\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cs.nju.edu.cn/ywguo/PhotoCollage/Index.html\"\n  }, \"http://cs.nju.edu.cn/ywguo/PhotoCollage/Index.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cs.nju.edu.cn/ywguo/webs/paperdownload/Content-aware%20Photo%20Collage%20Using%20Circle%20Packing.pdf\"\n  }, \"http://cs.nju.edu.cn/ywguo/webs/paperdownload/Content-aware%20Photo%20Collage%20Using%20Circle%20Packing.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cs.nju.edu.cn/ywguo/PhotoCollage/dload.html\"\n  }, \"http://cs.nju.edu.cn/ywguo/PhotoCollage/dload.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Automatic Generation of Social Media Snippets for Mobile Browsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Microsoft Research. ACM Multimedia 2013\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://research.microsoft.com/apps/pubs/default.aspx?id=204877\"\n  }, \"http://research.microsoft.com/apps/pubs/default.aspx?id=204877\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://research.microsoft.com/pubs/204877/mm035-yin.pdf\"\n  }, \"http://research.microsoft.com/pubs/204877/mm035-yin.pdf\"))), mdx(\"h1\", {\n    \"id\": \"video-tapestry\"\n  }, \"Video Tapestry\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Digital Tapestry\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MSR. CVPR 2005\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://research.microsoft.com/apps/pubs/default.aspx?id=67404\"\n  }, \"http://research.microsoft.com/apps/pubs/default.aspx?id=67404\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://pub.ist.ac.at/~vnk/papers/tapestry_cvpr05.pdf\"\n  }, \"http://pub.ist.ac.at/~vnk/papers/tapestry_cvpr05.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video Tapestries with Continuous Temporal Zoom\")), mdx(\"img\", {\n    \"src\": \"http://gfx.cs.princeton.edu/gfx/pubs/Barnes_2010_VTW/teaser.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Princeton. SIGGRAPH 2010\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://gfx.cs.princeton.edu/gfx/pubs/Barnes_2010_VTW/index.php\"\n  }, \"http://gfx.cs.princeton.edu/gfx/pubs/Barnes_2010_VTW/index.php\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.connellybarnes.com/work/publications/2010_tapestry_electronic.pdf\"\n  }, \"http://www.connellybarnes.com/work/publications/2010_tapestry_electronic.pdf\"))), mdx(\"h1\", {\n    \"id\": \"video-creativity\"\n  }, \"Video Creativity\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"6 Seconds of Sound and Vision: Creativity in Micro-Videos\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro:  CVPR 2014\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.di.unito.it/~schifane/dataset/vine-dataset-cvpr14/\"\n  }, \"http://www.di.unito.it/~schifane/dataset/vine-dataset-cvpr14/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1411.4080\"\n  }, \"http://arxiv.org/abs/1411.4080\"))), mdx(\"h1\", {\n    \"id\": \"video-highlights\"\n  }, \"Video Highlights\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Ranking Domain-specific Highlights by Analyzing Edited Videos\")), mdx(\"img\", {\n    \"src\": \"http://aliensunmin.github.io/project/at-a-glance/highlight_teaser.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2014\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://aliensunmin.github.io/project/at-a-glance/\"\n  }, \"http://aliensunmin.github.io/project/at-a-glance/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://grail.cs.washington.edu/wp-content/uploads/2015/08/sun2014rdh.pdf\"\n  }, \"http://grail.cs.washington.edu/wp-content/uploads/2015/08/sun2014rdh.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://drive.google.com/file/d/0ByJgUdTb1N2CM3Y5VU1BRjlmR3c/edit\"\n  }, \"https://drive.google.com/file/d/0ByJgUdTb1N2CM3Y5VU1BRjlmR3c/edit\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"tech: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://drive.google.com/file/d/0ByJgUdTb1N2CM1ktb1N4RVV3Mzg/view\"\n  }, \"https://drive.google.com/file/d/0ByJgUdTb1N2CM1ktb1N4RVV3Mzg/view\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aliensunmin/DomainSpecificHighlight\"\n  }, \"https://github.com/aliensunmin/DomainSpecificHighlight\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Salient Montages from Unconstrained Videos\")), mdx(\"img\", {\n    \"src\": \"http://aliensunmin.github.io/project/at-a-glance/montage_teaser.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://aliensunmin.github.io/project/at-a-glance/\"\n  }, \"http://aliensunmin.github.io/project/at-a-glance/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://grail.cs.washington.edu/wp-content/uploads/2015/08/sun2014smf.pdf\"\n  }, \"http://grail.cs.washington.edu/wp-content/uploads/2015/08/sun2014smf.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://drive.google.com/file/d/0ByJgUdTb1N2CbzNYTjdxX0ZiRmc/edit\"\n  }, \"https://drive.google.com/file/d/0ByJgUdTb1N2CbzNYTjdxX0ZiRmc/edit\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aliensunmin/salientMontages\"\n  }, \"https://github.com/aliensunmin/salientMontages\"))), mdx(\"h1\", {\n    \"id\": \"video-summarization\"\n  }, \"Video Summarization\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Creating Summaries from User Videos\")), mdx(\"img\", {\n    \"src\": \"http://www.vision.ee.ethz.ch/~hegrabne/visualInterestingness/vsum.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2014\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://people.ee.ethz.ch/~gyglim/vsum/index.php\"\n  }, \"https://people.ee.ethz.ch/~gyglim/vsum/index.php\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://people.ee.ethz.ch/~gyglim/vsum/GygliECCV14_vsum.pdf\"\n  }, \"https://people.ee.ethz.ch/~gyglim/vsum/GygliECCV14_vsum.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.vision.ee.ethz.ch/~hegrabne/papers/Gygli2014CreatingSummariesfrom.pdf\"\n  }, \"http://www.vision.ee.ethz.ch/~hegrabne/papers/Gygli2014CreatingSummariesfrom.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://people.ee.ethz.ch/~gyglim/vsum/index.php#sf_code\"\n  }, \"https://people.ee.ethz.ch/~gyglim/vsum/index.php#sf_code\"), \" \")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Joint Summarization of Large-scale Collections of Web Images and Videos for Storyline Reconstruction\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2014\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.cmu.edu/~gunhee/publish/cvpr14_videostory.pdf\"\n  }, \"http://www.cs.cmu.edu/~gunhee/publish/cvpr14_videostory.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video Summarization by Learning Submodular Mixtures of Objectives\")), mdx(\"img\", {\n    \"src\": \"http://www.vision.ee.ethz.ch/~hegrabne/visualInterestingness/vsum2.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Gygli_Video_Summarization_by_2015_CVPR_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Gygli_Video_Summarization_by_2015_CVPR_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TVSum: Summarizing Web Videos Using Titles\")), mdx(\"img\", {\n    \"src\": \"https://qph.is.quoracdn.net/main-qimg-0c0bb88876258e99272200655e2dc2ea?convert_to_webp=true\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Summarizing While Recording: Context-Based Highlight Detection for Egocentric Videos\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: structured SVM (SSVM)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.umiacs.umd.edu/~morariu/publications/LinEgocentricICCVW15.pdf\"\n  }, \"http://www.umiacs.umd.edu/~morariu/publications/LinEgocentricICCVW15.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Title Generation for User Generated Videos\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.07068\"\n  }, \"http://arxiv.org/abs/1608.07068\"))), mdx(\"h1\", {\n    \"id\": \"activity-recognition\"\n  }, \"Activity Recognition\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Latent Hierarchical Model for Activity Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1503.01820\"\n  }, \"http://arxiv.org/abs/1503.01820\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/louxi11/activity_recognition\"\n  }, \"https://github.com/louxi11/activity_recognition\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"author page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://staff.fnwi.uva.nl/n.hu/\"\n  }, \"https://staff.fnwi.uva.nl/n.hu/\"))), mdx(\"h1\", {\n    \"id\": \"virtual-reality-vr\"\n  }, \"Virtual Reality (VR)\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Surround360 System: Facebook's open source hardware and software for capturing stereoscopic 3D 360 video for VR\")), mdx(\"img\", {\n    \"src\": \"https://s2.wp.com/wp-content/themes/vip/fbspherical/images/static/surround-360-inside.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://facebook360.fb.com/facebook-surround-360/\"\n  }, \"https://facebook360.fb.com/facebook-surround-360/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://code.facebook.com/posts/265413023819735/surround-360-is-now-open-source/\"\n  }, \"https://code.facebook.com/posts/265413023819735/surround-360-is-now-open-source/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/facebook/Surround360\"\n  }, \"https://github.com/facebook/Surround360\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Virtual Reality\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Steven M. LaValle. Cambridge University Press 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"book: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://vr.cs.uiuc.edu/\"\n  }, \"http://vr.cs.uiuc.edu/\"))), mdx(\"h1\", {\n    \"id\": \"slam\"\n  }, \"SLAM\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Why SLAM Matters, The Future of Real-Time SLAM, and Deep Learning vs SLAM\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.computervisionblog.com/2016/01/why-slam-matters-future-of-real-time.html?m=1\"\n  }, \"http://www.computervisionblog.com/2016/01/why-slam-matters-future-of-real-time.html?m=1\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"\\u4E00\\u8D77\\u505ARGB-D SLAM\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cnblogs.com/gaoxiang12/tag/%E4%B8%80%E8%B5%B7%E5%81%9ARGB-D%20SLAM/\"\n  }, \"http://www.cnblogs.com/gaoxiang12/tag/%E4%B8%80%E8%B5%B7%E5%81%9ARGB-D%20SLAM/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/gaoxiang12/rgbd-slam-tutorial-gx\"\n  }, \"https://github.com/gaoxiang12/rgbd-slam-tutorial-gx\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PySceneDetect: a command-line application and a Python library for automatically detecting scene changes in video files\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://pyscenedetect.readthedocs.org/en/latest/\"\n  }, \"http://pyscenedetect.readthedocs.org/en/latest/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Future of Real-Time SLAM and Deep Learning vs SLAM\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.computervisionblog.com/2016/01/why-slam-matters-future-of-real-time.html\"\n  }, \"http://www.computervisionblog.com/2016/01/why-slam-matters-future-of-real-time.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Awesome SLAM\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kanster/awesome-slam\"\n  }, \"https://github.com/kanster/awesome-slam\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ORB-SLAM2: Real-Time SLAM for Monocular, Stereo and RGB-D Cameras, with Loop Detection and Relocalization Capabilities\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/raulmur/ORB_SLAM2\"\n  }, \"https://github.com/raulmur/ORB_SLAM2\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cartographer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Cartographer is a system that provides real-time simultaneous localization\\nand mapping (SLAM) in 2D and 3D across multiple platforms and sensor configurations.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/googlecartographer/cartographer\"\n  }, \"https://github.com/googlecartographer/cartographer\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Introducing Cartographer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://opensource.googleblog.com/2016/10/introducing-cartographer.html\"\n  }, \"https://opensource.googleblog.com/2016/10/introducing-cartographer.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Real-Time Loop Closure in 2D LIDAR SLAM\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICRA 2016. Google. Cartographer\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45466.pdf\"\n  }, \"http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45466.pdf\"))), mdx(\"h1\", {\n    \"id\": \"optical-flow\"\n  }, \"Optical Flow\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Database and Evaluation Methodology for Optical Flow\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IJCV 2011\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://vision.middlebury.edu/flow/\"\n  }, \"http://vision.middlebury.edu/flow/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://vision.middlebury.edu/flow/floweval-ijcv2011.pdf\"\n  }, \"http://vision.middlebury.edu/flow/floweval-ijcv2011.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SimpleFlow: A Non-iterative, Sublinear Optical Flow Algorithm\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Eurographics 2012\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://graphics.berkeley.edu/papers/Tao-SAN-2012-05/\"\n  }, \"http://graphics.berkeley.edu/papers/Tao-SAN-2012-05/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://graphics.berkeley.edu/papers/Tao-SAN-2012-05/Tao-SAN-2012-05.pdf\"\n  }, \"http://graphics.berkeley.edu/papers/Tao-SAN-2012-05/Tao-SAN-2012-05.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/graphics.berkeley.edu/papers/Tao-SAN-2012-05/SimpleFlow_Source.zip/\"\n  }, \"graphics.berkeley.edu/papers/Tao-SAN-2012-05/SimpleFlow_Source.zip\"))), mdx(\"h1\", {\n    \"id\": \"ocr\"\n  }, \"OCR\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Ocular: a state-of-the-art historical OCR system\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tberg12/ocular\"\n  }, \"https://github.com/tberg12/ocular\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SESHAT: Handwritten math expression parser\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Seshat is an open-source system for recognizing handwritten mathematical expressions.\\nGiven a sample represented as a sequence of strokes, the parser is able to convert it to LaTeX or other formats like InkML or MathML.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/falvaro/seshat\"\n  }, \"https://github.com/falvaro/seshat\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Awesome OCR: Links to awesome OCR projects\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kba/awesome-ocr\"\n  }, \"https://github.com/kba/awesome-ocr\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"\\u3010OCR/\\u673A\\u5668\\u5B66\\u4E60/\\u641C\\u7D22\\u5F15\\u64CE\\u3011\\u57FA\\u4E8E Tesseract\\u7684\\u56FE\\u6587\\u8BC6\\u522B\\u641C\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/daijiale/OCR_FontsSearchEngine\"\n  }, \"https://github.com/daijiale/OCR_FontsSearchEngine\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Simple + Practical Path to Machine Learning Capability: A Common Benchmark Task\")), mdx(\"img\", {\n    \"src\": \"https://indico.io/blog/wp-content/uploads/2016/09/TF0.5a-1-sm-768x520.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://indico.io/blog/simple-practical-path-to-machine-learning-capability-part2/\"\n  }, \"https://indico.io/blog/simple-practical-path-to-machine-learning-capability-part2/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Optical Character Recognition (OCR)\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://aosabook.org/en/500L/pages/optical-character-recognition-ocr.html\"\n  }, \"http://aosabook.org/en/500L/pages/optical-character-recognition-ocr.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sharingan: Newspaper text and context extractor\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tool to extract news articles from newspaper and give the context about the news\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.vipul.xyz/2017/03/sharingan-newspaper-text-and-context.html\"\n  }, \"http://www.vipul.xyz/2017/03/sharingan-newspaper-text-and-context.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/vipul-sharma20/sharingan\"\n  }, \"https://github.com/vipul-sharma20/sharingan\"))), mdx(\"h1\", {\n    \"id\": \"codec\"\n  }, \"Codec\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"JPEG 101 - How does JPEG work?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arjunsreedharan.org/post/146070390717/jpeg-101-how-does-jpeg-work\"\n  }, \"http://arjunsreedharan.org/post/146070390717/jpeg-101-how-does-jpeg-work\"))), mdx(\"h1\", {\n    \"id\": \"face-alignment\"\n  }, \"Face Alignment\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Supervised Descent Method and its Applications to Face Alignment\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2013\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://patrikhuber.github.io/superviseddescent/\"\n  }, \"http://patrikhuber.github.io/superviseddescent/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://101.96.8.164/www.ri.cmu.edu/pub_files/2013/5/main.pdf\"\n  }, \"http://101.96.8.164/www.ri.cmu.edu/pub_files/2013/5/main.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/patrikhuber/superviseddescent\"\n  }, \"https://github.com/patrikhuber/superviseddescent\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Face Alignment at 3000 FPS via Regressing Local Binary Features\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2014. MSRA\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/yichenw-cvpr14_facealignment.pdf\"\n  }, \"http://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/yichenw-cvpr14_facealignment.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yulequan/face-alignment-in-3000fps\"\n  }, \"https://github.com/yulequan/face-alignment-in-3000fps\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Joint Cascade Face Detection and Alignment\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2014\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.microsoft.com/en-us/research/wp-content/uploads/2016/12/ECCV14_JointCascade.pdf\"\n  }, \"http://www.microsoft.com/en-us/research/wp-content/uploads/2016/12/ECCV14_JointCascade.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/FaceDetect/jointCascade_py\"\n  }, \"https://github.com/FaceDetect/jointCascade_py\"))), mdx(\"h1\", {\n    \"id\": \"papers\"\n  }, \"Papers\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RGB-W: When Vision Meets Wireless\")), mdx(\"img\", {\n    \"src\": \"http://vision.stanford.edu/pubimg/rgbw15_1.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://vision.stanford.edu/pdf/RGBW_ICCV15.pdf\"\n  }, \"http://vision.stanford.edu/pdf/RGBW_ICCV15.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Computational Approach for Obstruction-Free Photography\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://people.csail.mit.edu/mrub/papers/ObstructionFreePhotograpy_SIGGRAPH2015.pdf\"\n  }, \"https://people.csail.mit.edu/mrub/papers/ObstructionFreePhotograpy_SIGGRAPH2015.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"My Text in Your Handwriting\")), mdx(\"img\", {\n    \"src\": \"http://visual.cs.ucl.ac.uk/pubs/handwriting/img/results.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://visual.cs.ucl.ac.uk/pubs/handwriting/\"\n  }, \"http://visual.cs.ucl.ac.uk/pubs/handwriting/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://visual.cs.ucl.ac.uk/pubs/handwriting/handwriting_visual_main.pdf\"\n  }, \"http://visual.cs.ucl.ac.uk/pubs/handwriting/handwriting_visual_main.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Seeing the Arrow of Time\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2013\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: \\\"is it possible to tell whether a video is running forwards or backwards?\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://people.csail.mit.edu/yichangshih/toa_web/\"\n  }, \"http://people.csail.mit.edu/yichangshih/toa_web/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.robots.ox.ac.uk/~vgg/research/arrow/\"\n  }, \"http://www.robots.ox.ac.uk/~vgg/research/arrow/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.robots.ox.ac.uk/~vgg/publications/2014/Pickup14/pickup14.pdf\"\n  }, \"http://www.robots.ox.ac.uk/~vgg/publications/2014/Pickup14/pickup14.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://people.csail.mit.edu/yichangshih/toa_web/ArrowCVPR131101.pdf\"\n  }, \"http://people.csail.mit.edu/yichangshih/toa_web/ArrowCVPR131101.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Time-lapse Mining from Internet Photos\")), mdx(\"img\", {\n    \"src\": \"http://grail.cs.washington.edu/projects/timelapse/teaser2.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SIGGRAPH 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://grail.cs.washington.edu/projects/timelapse/\"\n  }, \"http://grail.cs.washington.edu/projects/timelapse/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://grail.cs.washington.edu/projects/timelapse/TimelapseMiningSIGGRAPH15.pdf\"\n  }, \"http://grail.cs.washington.edu/projects/timelapse/TimelapseMiningSIGGRAPH15.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"wired: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.wired.com/2015/05/crowdsourced-timelapse/\"\n  }, \"https://www.wired.com/2015/05/crowdsourced-timelapse/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"3D Time-lapse Reconstruction from Internet Photos\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2015 (oral)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://grail.cs.washington.edu/projects/timelapse3d/\"\n  }, \"http://grail.cs.washington.edu/projects/timelapse3d/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://grail.cs.washington.edu/projects/timelapse3d/3DTimelapseReconstructionICCV15.pdf\"\n  }, \"http://grail.cs.washington.edu/projects/timelapse3d/3DTimelapseReconstructionICCV15.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Fast Bilateral Solver\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016 Best Honorable Mention Award\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1511.03296\"\n  }, \"https://arxiv.org/abs/1511.03296\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/poolio/bilateral_solver\"\n  }, \"https://github.com/poolio/bilateral_solver\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Are Elephants Bigger than Butterflies? Reasoning about Sizes of Objects\")), mdx(\"img\", {\n    \"src\": \"http://grail.cs.washington.edu/projects/size/images/teaser.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1602.00753\"\n  }, \"http://arxiv.org/abs/1602.00753\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://grail.cs.washington.edu/projects/size/\"\n  }, \"http://grail.cs.washington.edu/projects/size/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Atoms of recognition in human and computer vision\")), mdx(\"img\", {\n    \"src\": \"http://www.wisdom.weizmann.ac.il/~dannyh/Mircs/cover.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.wisdom.weizmann.ac.il/~dannyh/Mircs/mircs.html\"\n  }, \"http://www.wisdom.weizmann.ac.il/~dannyh/Mircs/mircs.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://s3-us-west-1.amazonaws.com/disneyresearch/wp-content/uploads/20150929153916/Live-Texturing-of-Augmented-Reality-Characters-from-Colored-Drawings-Paper.pdf\"\n  }, \"https://s3-us-west-1.amazonaws.com/disneyresearch/wp-content/uploads/20150929153916/Live-Texturing-of-Augmented-Reality-Characters-from-Colored-Drawings-Paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Live Texturing of Augmented Reality Characters from Colored Drawings\")), mdx(\"img\", {\n    \"src\": \"https://www.disneyresearch.com/wp-content/uploads/Live-Texturing-of-Augmented-Reality-Characters-from-Colored-Drawings-Image-1024x576.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.disneyresearch.com/publication/live-texturing-of-augmented-reality-characters/\"\n  }, \"https://www.disneyresearch.com/publication/live-texturing-of-augmented-reality-characters/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Colorization for Image Compression\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1606.06314\"\n  }, \"http://arxiv.org/abs/1606.06314\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Face2Face: Real-time Face Capture and Reenactment of RGB Videos\")), mdx(\"img\", {\n    \"src\": \"http://www.graphics.stanford.edu/~niessner/papers/2016/1facetoface/teaser.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.graphics.stanford.edu/~niessner/thies2016face.html\"\n  }, \"http://www.graphics.stanford.edu/~niessner/thies2016face.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.graphics.stanford.edu/~niessner/papers/2016/1facetoface/thies2016face.pdf\"\n  }, \"http://www.graphics.stanford.edu/~niessner/papers/2016/1facetoface/thies2016face.pdf\"))), mdx(\"h1\", {\n    \"id\": \"applications\"\n  }, \"Applications\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Target acquired: Finding targets in drone and quadcopter video streams using Python and OpenCV\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://www.pyimagesearch.com/2015/05/04/target-acquired-finding-targets-in-drone-and-quadcopter-video-streams-using-python-and-opencv/\"\n  }, \"http://www.pyimagesearch.com/2015/05/04/target-acquired-finding-targets-in-drone-and-quadcopter-video-streams-using-python-and-opencv/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FaceDirector: Continuous Control of Facial Performance in Video\")), mdx(\"img\", {\n    \"src\": \"https://www.disneyresearch.com/wp-content/uploads/FaceDirector-Continuous-Control-of-Facial-Performance-in-Video-Image.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.disneyresearch.com/publication/facedirector/\"\n  }, \"http://www.disneyresearch.com/publication/facedirector/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://disneyresearch.s3-us-west-1.amazonaws.com/wp-content/uploads/20151210174750/FaceDirector-Continuous-Control-of-Facial-Performance-in-Video-Paper.pdf\"\n  }, \"http://disneyresearch.s3-us-west-1.amazonaws.com/wp-content/uploads/20151210174750/FaceDirector-Continuous-Control-of-Facial-Performance-in-Video-Paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Real-time Expression Transfer for Facial Reenactment\")), mdx(\"img\", {\n    \"src\": \"http://graphics.stanford.edu/~niessner/papers/2015/10face/teaser.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://graphics.stanford.edu/~niessner/thies2015realtime.html\"\n  }, \"http://graphics.stanford.edu/~niessner/thies2015realtime.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://graphics.stanford.edu/~niessner/papers/2015/10face/thies2015realtime.pdf\"\n  }, \"http://graphics.stanford.edu/~niessner/papers/2015/10face/thies2015realtime.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Photo Stylistic Brush: Robust Style Transfer via Superpixel-Based Bipartite Graph\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1606.03871\"\n  }, \"http://arxiv.org/abs/1606.03871\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"GMS: Grid-based Motion Statistics for Fast, Ultra-robust Feature Correspondence\")), mdx(\"img\", {\n    \"src\": \"https://i1.wp.com/jwbian.net/wp-content/uploads/2017/03/dog_ours.jpg?resize=768%2C512\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://jwbian.net/gms\"\n  }, \"http://jwbian.net/gms\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/JiawangBian/GMS-Feature-Matcher\"\n  }, \"https://github.com/JiawangBian/GMS-Feature-Matcher\"))), mdx(\"h1\", {\n    \"id\": \"projects\"\n  }, \"Projects\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"OpenBR: Open Source Biometrics, Face Recognition, Age Estimation, Gender Estimation\")), mdx(\"img\", {\n    \"src\": \"http://openbiometrics.org/diagram.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openbiometrics.org/\"\n  }, \"http://openbiometrics.org/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/biometrics/openbr\"\n  }, \"https://github.com/biometrics/openbr\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"docs: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openbiometrics.org/docs/index.html\"\n  }, \"http://openbiometrics.org/docs/index.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SmartMirror\")), mdx(\"p\", {\n    \"align\": \"center\"\n  }, \"\\n  \", mdx(\"img\", {\n    parentName: \"p\",\n    \"src\": \"/docs/SmartMirror_DisplayMenu_Preview.gif\"\n  }), \"       \", mdx(\"img\", {\n    parentName: \"p\",\n    \"src\": \"/docs/SmartMirror_Widget_Preview.gif\"\n  }), \"\\n\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Shinao/SmartMirror\"\n  }, \"https://github.com/Shinao/SmartMirror\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Home Surveilance with Facial Recognition\")), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/BrandonJoffe/home_surveillance/prototype/system/debugging/dashboard.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/BrandonJoffe/home_surveillance\"\n  }, \"https://github.com/BrandonJoffe/home_surveillance\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Image unshredding using a TSP solver\")), mdx(\"img\", {\n    \"src\": \"https://camo.githubusercontent.com/fbf30f6bce6931eee114366a5dc3372f259451ff/68747470733a2f2f726f62696e686f7573746f6e2e6769746875622e696f2f696d6167652d756e736872656464696e672f696d616765732f6c656173742d737175617265732f626c75652d686f75722d70617269732e706e67\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/robinhouston/image-unshredding\"\n  }, \"https://github.com/robinhouston/image-unshredding\"))), mdx(\"h1\", {\n    \"id\": \"resources\"\n  }, \"Resources\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Awesome Computer Vision\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jbhuang0604/awesome-computer-vision\"\n  }, \"https://github.com/jbhuang0604/awesome-computer-vision\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Resources: Visual Recognition and Search\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: \\\"Non-exhaustive list of state-of-the-art implementations related to visual recognition and search\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://rogerioferis.com/VisualRecognitionAndSearch2014/Resources.html\"\n  }, \"http://rogerioferis.com/VisualRecognitionAndSearch2014/Resources.html\"))), mdx(\"h1\", {\n    \"id\": \"libraries\"\n  }, \"Libraries\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BoofCV: an open source Java library for real-time computer vision and robotics applications\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://boofcv.org/index.php?title=Main_Page\"\n  }, \"http://boofcv.org/index.php?title=Main_Page\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"tracking.js: A modern approach for Computer Vision on the web\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://trackingjs.com/\"\n  }, \"https://trackingjs.com/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/eduardolundgren/tracking.js/\"\n  }, \"https://github.com/eduardolundgren/tracking.js/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FastCV Computer Vision SDK\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://developer.qualcomm.com/software/fastcv-sdk\"\n  }, \"https://developer.qualcomm.com/software/fastcv-sdk\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video++, a C++14 high performance video and image processing library\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/matt-42/vpp\"\n  }, \"https://github.com/matt-42/vpp\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"doc: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://documentup.com/matt-42/vpp\"\n  }, \"http://documentup.com/matt-42/vpp\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"VLFeat -- Vision Lab Features Library\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Algorithms include Fisher Vector, VLAD, SIFT, MSER, k-means, hierarchical k-means,\\nagglomerative information bottleneck, SLIC superpixels, quick shift superpixels, large scale SVM training, and many others\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homapage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.vlfeat.org/\"\n  }, \"http://www.vlfeat.org/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/vlfeat/vlfeat\"\n  }, \"https://github.com/vlfeat/vlfeat\"))), mdx(\"h1\", {\n    \"id\": \"datasets\"\n  }, \"Datasets\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CVonline: Image Databases\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase.htm\"\n  }, \"http://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase.htm\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Yet Another Computer Vision Index To Datasets (YACVID)\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://riemenschneider.hayko.at/vision/dataset/\"\n  }, \"http://riemenschneider.hayko.at/vision/dataset/\")), mdx(\"h1\", {\n    \"id\": \"blogs\"\n  }, \"Blogs\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"From feature descriptors to deep learning: 20 years of computer vision\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.computervisionblog.com/2015/01/from-feature-descriptors-to-deep.html\"\n  }, \"http://www.computervisionblog.com/2015/01/from-feature-descriptors-to-deep.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unsupervised Computer Vision: The State of the Art | Stitch Fix Technology \\u2013 Multithreaded\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://multithreaded.stitchfix.com/blog/2016/02/04/computer-vision-state-of-the-art\"\n  }, \"http://multithreaded.stitchfix.com/blog/2016/02/04/computer-vision-state-of-the-art\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://pan.baidu.com/s/1c0Sxzvq\"\n  }, \"http://pan.baidu.com/s/1c0Sxzvq\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Exploring Computer Vision\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Part I: Convolutional Neural Networks: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://indico.io/blog/exploring-computer-vision-convolutional-neural-nets/\"\n  }, \"https://indico.io/blog/exploring-computer-vision-convolutional-neural-nets/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Part II: Transfer Learning: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://indico.io/blog/exploring-computer-vision-transfer-learning/\"\n  }, \"https://indico.io/blog/exploring-computer-vision-transfer-learning/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Image Processing with Numpy\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.degeneratestate.org/posts/2016/Oct/23/image-processing-with-numpy/\"\n  }, \"http://www.degeneratestate.org/posts/2016/Oct/23/image-processing-with-numpy/\"))), mdx(\"h1\", {\n    \"id\": \"conferences\"\n  }, \"Conferences\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SIGGRAPH 2016 papers on the web\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://kesen.realtimerendering.com/sig2016.html\"\n  }, \"http://kesen.realtimerendering.com/sig2016.html\")), mdx(\"h1\", {\n    \"id\": \"resources-1\"\n  }, \"Resources\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Ultimate List of 300+ Computer Vision Resources\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://hackerlists.com/computer-vision-resources/\"\n  }, \"https://hackerlists.com/computer-vision-resources/\"))));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"---\nlayout: post\ncategory: computer_vision\ntitle: Computer Vision Resources\ndate: 2015-09-12\n---\n\n# Courses\n\n**Mobile Computer Vision (Spring 2015)**\n\n![](http://web.stanford.edu/class/cs231m/assets/img/course-splash.png)\n\n- homepage: [http://web.stanford.edu/class/cs231m/](http://web.stanford.edu/class/cs231m/)\n- syllabus: [http://web.stanford.edu/class/cs231m/syllabus.html](http://web.stanford.edu/class/cs231m/syllabus.html)\n- projects: [http://web.stanford.edu/class/cs231m/projects.html](http://web.stanford.edu/class/cs231m/projects.html)\n- resources: [http://web.stanford.edu/class/cs231m/resources.html](http://web.stanford.edu/class/cs231m/resources.html)\n\n**CSCI1950-G Computational Photography**\n\n![](http://cs.brown.edu/courses/csci1950-g/images/montage_large.jpg)\n\n[http://cs.brown.edu/courses/csci1950-g/](http://cs.brown.edu/courses/csci1950-g/)\n\n**MIT CSAIL: 6.819/6.869: Advances in Computer Vision (Fall 2015)**\n\n![](http://6.869.csail.mit.edu/fa15/images/teaser.jpg)\n\n- homepage: [http://6.869.csail.mit.edu/fa15/index.html](http://6.869.csail.mit.edu/fa15/index.html)\n\n**EECS 432 Advanced Computer Vision**\n\n- course website: [http://www.ece.northwestern.edu/~yingwu/teaching/EECS432/index.html](http://www.ece.northwestern.edu/~yingwu/teaching/EECS432/index.html)c\n- handouts: [http://www.ece.northwestern.edu/~yingwu/teaching/EECS432/EECS432_hand.html](http://www.ece.northwestern.edu/~yingwu/teaching/EECS432/EECS432_hand.html)\n\n**EECS 286 Advanced Topics in Computer Vision**\n\n- homepage: [http://faculty.ucmerced.edu/mhyang/course/eecs286/index.htm](http://faculty.ucmerced.edu/mhyang/course/eecs286/index.htm)\n- syllabus: [http://faculty.ucmerced.edu/mhyang/course/eecs286/syllabus.htm](http://faculty.ucmerced.edu/mhyang/course/eecs286/syllabus.htm)\n- lectures: [http://faculty.ucmerced.edu/mhyang/course/eecs286/lecture.htm](http://faculty.ucmerced.edu/mhyang/course/eecs286/lecture.htm)\n- lecture(\"How to get your CVPR paper rejected?\"): [http://faculty.ucmerced.edu/mhyang/course/eecs286/lectures/introduction.pptx](http://faculty.ucmerced.edu/mhyang/course/eecs286/lectures/introduction.pptx)\n\n**CS280: Computer Vision (University of California Berkeley)**\n\n- homepage: [http://www-inst.eecs.berkeley.edu/~cs280/sp15/index.html](http://www-inst.eecs.berkeley.edu/~cs280/sp15/index.html)\n- lectures: [http://docs.huihoo.com/computer-vision/berkeley/cs280-computer-vision/](http://docs.huihoo.com/computer-vision/berkeley/cs280-computer-vision/)\n\n**CSCI2951-T Data-driven Computer Vision (Spring 2016)**\n\n![](http://cs.brown.edu/courses/csci2951-t/images/detection_teaser.png)\n\n- instructor: Genevieve Patterson\n- homepage: [http://cs.brown.edu/courses/csci2951-t/](http://cs.brown.edu/courses/csci2951-t/)\n\n# Images Denoising\n\n**Fast Burst Images Denoising**\n\n![](http://personal.ie.cuhk.edu.hk/~lz013/projects/burstdenoising/intro.png)\n\n- intro: SIGGRAPH Asia 2014. CUHK, Microsoft Research\n- project: [http://personal.ie.cuhk.edu.hk/~lz013/projects/BurstDenoising.html](http://personal.ie.cuhk.edu.hk/~lz013/projects/BurstDenoising.html)\n- paper: [http://personal.ie.cuhk.edu.hk/~lz013/papers/burstdenoising.pdf](http://personal.ie.cuhk.edu.hk/~lz013/papers/burstdenoising.pdf)\n\n**Robust non-linear regression analysis: A greedy approach employing kernels and application to image denoising**\n\n- intro: KGARD\n- arxiv: [http://arxiv.org/abs/1601.00595](http://arxiv.org/abs/1601.00595)\n- code(Matlab): [http://bouboulis.mysch.gr/kernels.html](http://bouboulis.mysch.gr/kernels.html)\n\n**Blind Image Denoising via Dependent Dirichlet Process Tree**\n\n- arxiv: [http://arxiv.org/abs/1601.03117](http://arxiv.org/abs/1601.03117)\n\n**Image denoising via group sparsity residual constraint**\n\n- arxiv: [http://arxiv.org/abs/1609.03302](http://arxiv.org/abs/1609.03302)\n\n# Image Blur / Deblur\n\n**Motion Blurred Images Generation**\n\n- homepage: [http://home.deib.polimi.it/boracchi/Projects/PSFGeneration.html](http://home.deib.polimi.it/boracchi/Projects/PSFGeneration.html)\n- code(Matlab): [http://home.deib.polimi.it/boracchi/Projects/PSF_generation/PSF_generation.zip](http://home.deib.polimi.it/boracchi/Projects/PSF_generation/PSF_generation.zip)\n\n**Blind Image Deblurring Using Dark Channel Prior**\n\n**Good Regions to Deblur**\n\n- project page: [https://eng.ucmerced.edu/people/zhu/GoodRegion.html](https://eng.ucmerced.edu/people/zhu/GoodRegion.html)\n- paper: [https://eng.ucmerced.edu/people/zhu/ECCV12.pdf](https://eng.ucmerced.edu/people/zhu/ECCV12.pdf)\n- code(Matlab): [https://eng.ucmerced.edu/people/zhu/ECCV12_code.zip](https://eng.ucmerced.edu/people/zhu/ECCV12_code.zip)\n\n# Painting\n\n**Real-Time Gradient-Domain Painting**\n\n- intro: SIGGRAPH 2009\n- homepage: [http://graphics.cs.cmu.edu/projects/gradient-paint/](http://graphics.cs.cmu.edu/projects/gradient-paint/)\n- paper: [http://graphics.cs.cmu.edu/projects/gradient-paint/grad.light.r2226.pdf](http://graphics.cs.cmu.edu/projects/gradient-paint/grad.light.r2226.pdf)\n\n**Sketch2Photo: Internet Image Montage**\n\n![](http://cg.cs.tsinghua.edu.cn/montage/figures/teaser.jpg)\n\n- intro: ACM SIGGRAPH ASIA 2009\n- project page: [http://cg.cs.tsinghua.edu.cn/montage/main.htm](http://cg.cs.tsinghua.edu.cn/montage/main.htm)\n- paper: [http://cg.cs.tsinghua.edu.cn/montage/files/montage.pdf](http://cg.cs.tsinghua.edu.cn/montage/files/montage.pdf)\n\n**Combining Sketch and Tone for Pencil Drawing Production**\n\n- intro: NPAR 2012 Best Paper Award\n- homepage: [http://www.cse.cuhk.edu.hk/~leojia/projects/pencilsketch/pencil_drawing.htm](http://www.cse.cuhk.edu.hk/~leojia/projects/pencilsketch/pencil_drawing.htm)\n- paper: [http://www.cse.cuhk.edu.hk/~leojia/projects/pencilsketch/npar12_pencil.pdf](http://www.cse.cuhk.edu.hk/~leojia/projects/pencilsketch/npar12_pencil.pdf)\n- github: [https://github.com/fumin/pencil](https://github.com/fumin/pencil)\n\n# Image Retrieval\n\n**Multi-modal image retrieval with random walk on multi-layer graphs**\n\n- arxiv: [http://arxiv.org/abs/1607.03406](http://arxiv.org/abs/1607.03406)\n\n**Content-based image retrieval tutorial**\n\n- intro: KNN, SVM, MatLab GUI\n- arxiv: [http://arxiv.org/abs/1608.03811](http://arxiv.org/abs/1608.03811)\n- github: [https://github.com/kirk86/ImageRetrieval](https://github.com/kirk86/ImageRetrieval)\n\n# Image Summary\n\n**Summarizing Visual Data Using Bidirectional Similarity**\n\n- homepage: [http://denis.simakov.info/weizmann/summarization_talk_20101116/summarization.html](http://denis.simakov.info/weizmann/summarization_talk_20101116/summarization.html)\n- paper: [http://www.wisdom.weizmann.ac.il/~vision/VisualSummary/bidirectional_similarity_CVPR2008.pdf](http://www.wisdom.weizmann.ac.il/~vision/VisualSummary/bidirectional_similarity_CVPR2008.pdf)\n\n# Image Retargeting / Editing\n\n**PatchMatch: A Randomized Correspondence Algorithm for Structural Image Editing**\n\n![](http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/patchmatch_title.png)\n\n- homepage(paper+code): [http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/](http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/)\n- paper: [http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/patchmatch.pdf](http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/patchmatch.pdf)\n- code: [http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/patchmatch-2.1.zip](http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/patchmatch-2.1.zip)\n\n**The Generalized PatchMatch Correspondence Algorithm**\n\n![](http://gfx.cs.princeton.edu/pubs/Barnes_2010_TGP/gpm_teaser.png)\n\n- homapage(paper+code): [http://gfx.cs.princeton.edu/pubs/Barnes_2010_TGP/index.php](http://gfx.cs.princeton.edu/pubs/Barnes_2010_TGP/index.php)\n- paper: [http://gfx.cs.princeton.edu/pubs/Barnes_2010_TGP/generalized_pm.pdf](http://gfx.cs.princeton.edu/pubs/Barnes_2010_TGP/generalized_pm.pdf)\n- code: [http://www.cs.princeton.edu/gfx/pubs/Barnes_2009_PAR/patchmatch-2.0.zip](http://www.cs.princeton.edu/gfx/pubs/Barnes_2009_PAR/patchmatch-2.0.zip)\n\n**Seamless Image Editing**\n\n![](http://www.cmlab.csie.ntu.edu.tw/~dreamway/seamless/img/teaser.jpg)\n\n- homepage: [http://www.cmlab.csie.ntu.edu.tw/~dreamway/seamless/](http://www.cmlab.csie.ntu.edu.tw/~dreamway/seamless/)\n\n# Image Inpaiting\n\n**Patch-based Texture Synthesis for Image Inpainting**\n\n- arxiv: [http://arxiv.org/abs/1605.01576](http://arxiv.org/abs/1605.01576)\n\n# Image Dithering\n\n**Image Dithering: Eleven Algorithms and Source Code**\n\n- blog: [http://www.tannerhelland.com/4660/dithering-eleven-algorithms-source-code/](http://www.tannerhelland.com/4660/dithering-eleven-algorithms-source-code/)\n\n# Image Enhancement\n\n**LIME: A Method for Low-light IMage Enhancement**\n\n![](http://photo.weibo.com/2578103464/wbphotos/large/mid/3971098712490115/pid/99aabca8jw1f3ibhb6o8ej20ck09cmzl)\n\n- arxiv: [http://arxiv.org/abs/1605.05034](http://arxiv.org/abs/1605.05034)\n- github: [http://cs.tju.edu.cn/orgs/vision/~xguo/code/LIME.zip](http://cs.tju.edu.cn/orgs/vision/~xguo/code/LIME.zip)\n- author homepage: [http://cs.tju.edu.cn/orgs/vision/~xguo/homepage.htm](http://cs.tju.edu.cn/orgs/vision/~xguo/homepage.htm)\n\n**SelPh: Progressive Learning and Support of Manual Photo Color Enhancement**\n\n![](http://koyama.xyz/project/SelPh/teaser1.gif)\n\n- homepage: [http://koyama.xyz/project/SelPh/](http://koyama.xyz/project/SelPh/)\n- paper: [http://koyama.xyz/project/SelPh/chi2016_paper.pdf](http://koyama.xyz/project/SelPh/chi2016_paper.pdf)\n- bitbucket: [https://bitbucket.org/yukikoyama/selph/](https://bitbucket.org/yukikoyama/selph/)\n\n# Image Resizing\n\n- blog: [http://parellagram.com/posts/carving](http://parellagram.com/posts/carving)\n- github: [https://github.com/aaparella/carve](https://github.com/aaparella/carve)\n\n# Image Cloning\n\n**Coordinates for Instant Image Cloning**\n\n![](http://www.cs.huji.ac.il/~danix/mvclone/teaser.jpg)\n\n- intro: SIGGRAPH 2009\n- homepage: [http://www.cs.huji.ac.il/~danix/mvclone/](http://www.cs.huji.ac.il/~danix/mvclone/)\n- paper: [http://www.cs.huji.ac.il/~danix/mvclone/files/mvc-final-opt.pdf](http://www.cs.huji.ac.il/~danix/mvclone/files/mvc-final-opt.pdf)\n\n# Image Compositing\n\n**Interactive Digital Photomontage**\n\n- intro: SIGGRAPH 2004\n- homepage: [http://grail.cs.washington.edu/projects/photomontage/](http://grail.cs.washington.edu/projects/photomontage/)\n- code: [http://grail.cs.washington.edu/projects/photomontage/release/](http://grail.cs.washington.edu/projects/photomontage/release/)\n- paper: [http://grail.cs.washington.edu/projects/photomontage/photomontage.pdf](http://grail.cs.washington.edu/projects/photomontage/photomontage.pdf)\n- paper: [http://www.researchgate.net/publication/2941744_Interactive_Digital_Photomontage](http://www.researchgate.net/publication/2941744_Interactive_Digital_Photomontage)\n\n**Panorama Stitching**\n\n**CS510 Visual Computing, Project 2: Panorama Stitching**\n\n[http://web.cecs.pdx.edu/~kstew2/cs510vision/stitcher/](http://web.cecs.pdx.edu/~kstew2/cs510vision/stitcher/)\n\n# Image Stylization\n\n**stylize: Regressor based image stylization**\n\n![](https://raw.githubusercontent.com/Newmu/stylize/master/resources/iggy.gif)\n\n- github: [https://github.com/Newmu/stylize](https://github.com/Newmu/stylize)\n\n**Procedurally Generating Stylized Farmland Scenes**\n\n![](http://graphics.cs.williams.edu/courses/cs371/f16/gallery/4-midterm/terrain/TopImage.jpg)\n\n[http://graphics.cs.williams.edu/courses/cs371/f16/gallery/4-midterm/terrain/report.md.html](http://graphics.cs.williams.edu/courses/cs371/f16/gallery/4-midterm/terrain/report.md.html)\n\n# Image Haze Removal\n\n**Single Image Haze Removal**\n\n- project page: [http://research.microsoft.com/en-us/um/people/kahe/cvpr09/](http://research.microsoft.com/en-us/um/people/kahe/cvpr09/)\n\n**DehazeNet: An End-to-End System for Single Image Haze Removal**\n\n- arxiv: [http://arxiv.org/abs/1601.07661](http://arxiv.org/abs/1601.07661)\n\n# Image Blending\n\nLinear Blending, Poisson Blending, Multiband Blending, Feather Blending, Alpha Blending, Laplacian Blending\n\n**Image Blending**\n\n- course-info: 15-463: Computational Photography. Alexei Efros, CMU, Spring 2010\n- lecture: [http://graphics.cs.cmu.edu/courses/15-463/2010_spring/Lectures/blending.pdf](http://graphics.cs.cmu.edu/courses/15-463/2010_spring/Lectures/blending.pdf)\n\n**CS 195-G: Image Blending**\n\n- homepage: [https://cs.brown.edu/courses/csci1950-g/results/proj2/edwallac/](https://cs.brown.edu/courses/csci1950-g/results/proj2/edwallac/)\n\n**Panoramic Image Mosaic**\n\n- homepage: [http://pages.cs.wisc.edu/~csverma/CS766_09/ImageMosaic/imagemosaic.html](http://pages.cs.wisc.edu/~csverma/CS766_09/ImageMosaic/imagemosaic.html)\n\n## Linear Blending\n\n**Adding (blending) two images using OpenCV**\n\n[http://docs.opencv.org/master/d5/dc4/tutorial_adding_images.html#gsc.tab=0](http://docs.opencv.org/master/d5/dc4/tutorial_adding_images.html#gsc.tab=0)\n\n## Poisson Blending\n\n**Poisson Image Editing**\n\n- intro: SIGGRAPH 2003\n- paper: [http://cs.brown.edu/courses/csci1290/asgn/proj2/resources/PoissonImageEditing.pdf](http://cs.brown.edu/courses/csci1290/asgn/proj2/resources/PoissonImageEditing.pdf)\n- paper: [https://www.cs.jhu.edu/~misha/Fall07/Papers/Perez03.pdf](https://www.cs.jhu.edu/~misha/Fall07/Papers/Perez03.pdf)\n- slides: [https://graphics.ethz.ch/teaching/former/seminar/handouts/Weyrich_PoissonImageEditing.pdf](https://graphics.ethz.ch/teaching/former/seminar/handouts/Weyrich_PoissonImageEditing.pdf)\n- code(Matlab+C#): [https://code.google.com/p/imageblending/](https://code.google.com/p/imageblending/)\n- github: [https://github.com/fbessho/PyPoi](https://github.com/fbessho/PyPoi)\n- github(C++): [https://github.com/cheind/poisson-image-editing](https://github.com/cheind/poisson-image-editing)\n\n**Poisson Blending**\n\n- blog: [http://eric-yuan.me/poisson-blending/](http://eric-yuan.me/poisson-blending/)\n\n**Poisson Blending II**\n\n- blog: [http://eric-yuan.me/poisson-blending-2/](http://eric-yuan.me/poisson-blending-2/)\n- code: [http://codepad.org/ANqtikKR](http://codepad.org/ANqtikKR)\n\n**Solving the Discrete Poisson Equation using Jacobi, SOR, Conjugate Gradients, and the FFT**\n\n- intro: CS267: Lectures 15 and 16, Mar 5 and 7 1996\n- lecture: [http://www.cs.berkeley.edu/~demmel/cs267/lecture24/lecture24.html](http://www.cs.berkeley.edu/~demmel/cs267/lecture24/lecture24.html)\n\n**Gradient Domain Fusion Using Poisson Blending**\n\n![](http://120.52.72.72/cs.brown.edu/c3pr90ntcsf0/courses/cs129/results/proj2/taox/images/result_09.jpg)\n\n[http://cs.brown.edu/courses/cs129/results/proj2/taox/](http://cs.brown.edu/courses/cs129/results/proj2/taox/)\n\n# Image Stitching\n\n**Natural and Seamless Image Composition with Color Control**\n\n[http://www3.ntu.edu.sg/home/asjfcai/tip04594.pdf](http://www3.ntu.edu.sg/home/asjfcai/tip04594.pdf)\n\n**Object-aware Gradient-Domain Image Compositing**\n\n[http://www.cg.cs.tu-bs.de/media/publications/Eisemann11OAG.pdf](http://www.cg.cs.tu-bs.de/media/publications/Eisemann11OAG.pdf)\n\n**Improving Image Matting using Comprehensive Sampling Sets**\n\n[http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Shahrian_Improving_Image_Matting_2013_CVPR_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Shahrian_Improving_Image_Matting_2013_CVPR_paper.pdf)\n\n**Multi-scale Image Harmonization**\n\n![](http://gvi.seas.harvard.edu/sites/all/files/paper-rep-images/harmonization_teaser_3.png)\n\n- homepage: [http://gvi.seas.harvard.edu/paper/multiscale-image-harmonization](http://gvi.seas.harvard.edu/paper/multiscale-image-harmonization)\n- paper: [http://gvi.seas.harvard.edu/sites/all/files/Harmonization_SIGGRAPH10.pdf](http://gvi.seas.harvard.edu/sites/all/files/Harmonization_SIGGRAPH10.pdf)\n- slides: [http://gvi.seas.harvard.edu/sites/all/files/Harmonization_SIGGRAPH10.pptx](http://gvi.seas.harvard.edu/sites/all/files/Harmonization_SIGGRAPH10.pptx)\n\n**Drag-and-Drop Pasting**\n\n[http://research.microsoft.com/pubs/69331/dragdroppasting_siggraph06.pdf](http://research.microsoft.com/pubs/69331/dragdroppasting_siggraph06.pdf)\n\n**Cross Dissolve Without Cross Fade: Preserving Contrast, Color and Salience in Image Compositing**\n\n[https://www.cl.cam.ac.uk/research/rainbow/projects/compositing/EG06-Cross-Dissolve-Without-Cross-Fade.pdf](https://www.cl.cam.ac.uk/research/rainbow/projects/compositing/EG06-Cross-Dissolve-Without-Cross-Fade.pdf)\n\n**Snap Image Composition**\n\n[http://www.cs.huji.ac.il/~peleg/papers/SnapComposition.pdf](http://www.cs.huji.ac.il/~peleg/papers/SnapComposition.pdf)\n\n**Stitching Stabilizer: Two-frame-stitching Video Stabilization for Embedded Systems**\n\n- arxiv: [http://arxiv.org/abs/1603.06678](http://arxiv.org/abs/1603.06678)\n\n**Stitching and Matting**\n\n- lectures: [http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2015/bil721/lectures/w06-stitching-matting.pdf](http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2015/bil721/lectures/w06-stitching-matting.pdf)\n\n**Image Stitching**\n\n- lectures: [https://courses.engr.illinois.edu/cs498dwh/fa2010/lectures/Lecture%2017%20-%20Photo%20Stitching.pdf](https://courses.engr.illinois.edu/cs498dwh/fa2010/lectures/Lecture%2017%20-%20Photo%20Stitching.pdf)\n\n**Graphics isn't all about 3-D**\n\n- lectures: [http://www.cs.cmu.edu/afs/cs/academic/class/15462-s09/www/lec/25/lec25.pdf](http://www.cs.cmu.edu/afs/cs/academic/class/15462-s09/www/lec/25/lec25.pdf)\n\n- slides: [http://upcommons.upc.edu/bitstream/handle/2099.1/22861/PujolAlba-TFG-FinalReport.pdf;jsessionid=7AE46AE2A5420F75760F246381D429BC?sequence=5](http://upcommons.upc.edu/bitstream/handle/2099.1/22861/PujolAlba-TFG-FinalReport.pdf;jsessionid=7AE46AE2A5420F75760F246381D429BC?sequence=5)\n\n**Assignment: Image stitching with RANSAC**\n\n- assignments: [https://people.cs.umass.edu/~elm/Teaching/Docs/assign_RANSAC.pdf](https://people.cs.umass.edu/~elm/Teaching/Docs/assign_RANSAC.pdf)\n\n**OpenCV panorama stitching**\n\n- blog: [http://www.pyimagesearch.com/2016/01/11/opencv-panorama-stitching/](http://www.pyimagesearch.com/2016/01/11/opencv-panorama-stitching/)\n\n**Real-time panorama and image stitching with OpenCV**\n\n- blog: [http://www.pyimagesearch.com/2016/01/25/real-time-panorama-and-image-stitching-with-opencv/](http://www.pyimagesearch.com/2016/01/25/real-time-panorama-and-image-stitching-with-opencv/)\n\n# Image Super-Resolution\n\n**Super-Resolution From a Single Image**\n\n- project: [http://www.wisdom.weizmann.ac.il/~vision/SingleImageSR.html](http://www.wisdom.weizmann.ac.il/~vision/SingleImageSR.html)\n- paper: [http://www.wisdom.weizmann.ac.il/~vision/single_image_SR/files/single_image_SR.pdf](http://www.wisdom.weizmann.ac.il/~vision/single_image_SR/files/single_image_SR.pdf)\n\n**Aperture-scanning Fourier ptychography for 3D refocusing and super-resolution macroscopic imaging**\n\n- paper: [http://www.its.caltech.edu/~roarke/research/FPM/FPM_Aperture_Scanning.pdf](http://www.its.caltech.edu/~roarke/research/FPM/FPM_Aperture_Scanning.pdf)\n- slides: [http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6754138](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6754138)\n\n**Single Image Super-Resolution from Transformed Self-Exemplars**\n\n- homepage: [https://sites.google.com/site/jbhuang0604/publications/struct_sr](https://sites.google.com/site/jbhuang0604/publications/struct_sr)\n- github: [https://github.com/jbhuang0604/SelfExSR](https://github.com/jbhuang0604/SelfExSR)\n\n# Photo Collage\n\n**AutoCollage**\n\n- intro: SIGGRAPH 2006\n- homepage: [http://research.microsoft.com/en-us/projects/i3l/autocollage.aspx](http://research.microsoft.com/en-us/projects/i3l/autocollage.aspx)\n- paper: [http://research.microsoft.com/pubs/67894/autocollage_rotheretal_siggraph2006.pdf](http://research.microsoft.com/pubs/67894/autocollage_rotheretal_siggraph2006.pdf)\n- slides: [http://research.microsoft.com/en-us/UM/cambridge/projects/VisionImageVideoEditing/autocollage/TalkSiggraph2006Compressed.zip](http://research.microsoft.com/en-us/UM/cambridge/projects/VisionImageVideoEditing/autocollage/TalkSiggraph2006Compressed.zip)\n- demo: [http://research.microsoft.com/en-us/um/cambridge/projects/autocollage/](http://research.microsoft.com/en-us/um/cambridge/projects/autocollage/)\n\n**Picture Collage**\n\n- intro: 2006\n- paper: [http://research.microsoft.com/en-us/um/people/jiansun/papers/PictureCollage_CVPR2006.pdf](http://research.microsoft.com/en-us/um/people/jiansun/papers/PictureCollage_CVPR2006.pdf)\n- paper: [http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.89.5727](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.89.5727)\n\n**Picture Collage**\n\n- intro: 2009\n- paper: [http://mmlab.ie.cuhk.edu.hk/archive/2009/07_Picture.pdf](http://mmlab.ie.cuhk.edu.hk/archive/2009/07_Picture.pdf)\n\n**Efficient Optimization of Photo Collage**\n\n- paper: [http://research.microsoft.com/pubs/80783/Collage_techreport.pdf](http://research.microsoft.com/pubs/80783/Collage_techreport.pdf)\n\n# Video Collage\n\n**Stained-Glass Visualization for Highly Condensed Video Summaries (ICME 2004)**\n\n- intro: ICME 2004\n- paper: [https://www.fxpal.com/publications/stained-glass-visualization-for-highly-condensed-video-summaries.pdf](https://www.fxpal.com/publications/stained-glass-visualization-for-highly-condensed-video-summaries.pdf)\n\n**Video collage: A novel presentation of video sequence**\n\n- intro: ICME 2007\n- paper: [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.130.3728&rep=rep1&type=pdf](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.130.3728&rep=rep1&type=pdf)\n\n**Stained Glass Photo Collages**\n\n[http://uist.acm.org/archive/adjunct/2004/pdf/posters/p7-girgensohn.pdf](http://uist.acm.org/archive/adjunct/2004/pdf/posters/p7-girgensohn.pdf)\n\n**Visual Storylines: Semantic Visualization of Movie Sequence**\n\n- paper: [http://cg.cs.tsinghua.edu.cn/papers/C&G2012_videostoryline.pdf](http://cg.cs.tsinghua.edu.cn/papers/C&G2012_videostoryline.pdf)\n- paper: [http://cg.cs.tsinghua.edu.cn/people/~taochen/papers/VisualStorylines.pdf](http://cg.cs.tsinghua.edu.cn/people/~taochen/papers/VisualStorylines.pdf)\n\n**Video collage: presenting a video sequence using a single image**\n\n[http://iris.usc.edu/people/yangbo/papers/vcj08.pdf](http://iris.usc.edu/people/yangbo/papers/vcj08.pdf)\n\n**Efficient Optimization of Photo Collage**\n\n[http://research.microsoft.com/en-us/people/yichenw/collage_techreport.pdf](http://research.microsoft.com/en-us/people/yichenw/collage_techreport.pdf)\n\n**Puzzle-like Collage (2010)**\n\n[http://webee.technion.ac.il/~ayellet/Ps/10-PuzzleCollage.pdf](http://webee.technion.ac.il/~ayellet/Ps/10-PuzzleCollage.pdf)\n\n**Browsing Large Image Datasets through Voronoi Diagrams**\n\n[http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=576998825C3E40A32826A00B64089DF6?doi=10.1.1.230.5997&rep=rep1&type=pdf](http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=576998825C3E40A32826A00B64089DF6?doi=10.1.1.230.5997&rep=rep1&type=pdf)\n\n**Content-aware Photo Collage Using Circle Packing**\n\n- intro: TVCG 2014. NJU\n- homepage: [http://cs.nju.edu.cn/ywguo/PhotoCollage/Index.html](http://cs.nju.edu.cn/ywguo/PhotoCollage/Index.html)\n- paper: [http://cs.nju.edu.cn/ywguo/webs/paperdownload/Content-aware%20Photo%20Collage%20Using%20Circle%20Packing.pdf](http://cs.nju.edu.cn/ywguo/webs/paperdownload/Content-aware%20Photo%20Collage%20Using%20Circle%20Packing.pdf)\n- demo: [http://cs.nju.edu.cn/ywguo/PhotoCollage/dload.html](http://cs.nju.edu.cn/ywguo/PhotoCollage/dload.html)\n\n**Automatic Generation of Social Media Snippets for Mobile Browsing**\n\n- intro: Microsoft Research. ACM Multimedia 2013\n- homepage: [http://research.microsoft.com/apps/pubs/default.aspx?id=204877](http://research.microsoft.com/apps/pubs/default.aspx?id=204877)\n- paper: [http://research.microsoft.com/pubs/204877/mm035-yin.pdf](http://research.microsoft.com/pubs/204877/mm035-yin.pdf)\n\n# Video Tapestry\n\n**Digital Tapestry**\n\n- intro: MSR. CVPR 2005\n- homepage: [http://research.microsoft.com/apps/pubs/default.aspx?id=67404](http://research.microsoft.com/apps/pubs/default.aspx?id=67404)\n- paper: [http://pub.ist.ac.at/~vnk/papers/tapestry_cvpr05.pdf](http://pub.ist.ac.at/~vnk/papers/tapestry_cvpr05.pdf)\n\n**Video Tapestries with Continuous Temporal Zoom**\n\n![](http://gfx.cs.princeton.edu/gfx/pubs/Barnes_2010_VTW/teaser.png)\n\n- intro: Princeton. SIGGRAPH 2010\n- homepage: [http://gfx.cs.princeton.edu/gfx/pubs/Barnes_2010_VTW/index.php](http://gfx.cs.princeton.edu/gfx/pubs/Barnes_2010_VTW/index.php)\n- paper: [http://www.connellybarnes.com/work/publications/2010_tapestry_electronic.pdf](http://www.connellybarnes.com/work/publications/2010_tapestry_electronic.pdf)\n\n# Video Creativity\n\n**6 Seconds of Sound and Vision: Creativity in Micro-Videos**\n\n- intro:  CVPR 2014\n- homepage: [http://www.di.unito.it/~schifane/dataset/vine-dataset-cvpr14/](http://www.di.unito.it/~schifane/dataset/vine-dataset-cvpr14/)\n- arxiv: [http://arxiv.org/abs/1411.4080](http://arxiv.org/abs/1411.4080)\n\n# Video Highlights\n\n**Ranking Domain-specific Highlights by Analyzing Edited Videos**\n\n![](http://aliensunmin.github.io/project/at-a-glance/highlight_teaser.png)\n\n- intro: ECCV 2014\n- homepage: [http://aliensunmin.github.io/project/at-a-glance/](http://aliensunmin.github.io/project/at-a-glance/)\n- paper: [http://grail.cs.washington.edu/wp-content/uploads/2015/08/sun2014rdh.pdf](http://grail.cs.washington.edu/wp-content/uploads/2015/08/sun2014rdh.pdf)\n- paper: [https://drive.google.com/file/d/0ByJgUdTb1N2CM3Y5VU1BRjlmR3c/edit](https://drive.google.com/file/d/0ByJgUdTb1N2CM3Y5VU1BRjlmR3c/edit)\n- tech: [https://drive.google.com/file/d/0ByJgUdTb1N2CM1ktb1N4RVV3Mzg/view](https://drive.google.com/file/d/0ByJgUdTb1N2CM1ktb1N4RVV3Mzg/view)\n- github: [https://github.com/aliensunmin/DomainSpecificHighlight](https://github.com/aliensunmin/DomainSpecificHighlight)\n\n**Salient Montages from Unconstrained Videos**\n\n![](http://aliensunmin.github.io/project/at-a-glance/montage_teaser.png)\n\n- homepage: [http://aliensunmin.github.io/project/at-a-glance/](http://aliensunmin.github.io/project/at-a-glance/)\n- paper: [http://grail.cs.washington.edu/wp-content/uploads/2015/08/sun2014smf.pdf](http://grail.cs.washington.edu/wp-content/uploads/2015/08/sun2014smf.pdf)\n- paper: [https://drive.google.com/file/d/0ByJgUdTb1N2CbzNYTjdxX0ZiRmc/edit](https://drive.google.com/file/d/0ByJgUdTb1N2CbzNYTjdxX0ZiRmc/edit)\n- github: [https://github.com/aliensunmin/salientMontages](https://github.com/aliensunmin/salientMontages)\n\n# Video Summarization\n\n**Creating Summaries from User Videos**\n\n![](http://www.vision.ee.ethz.ch/~hegrabne/visualInterestingness/vsum.png)\n\n- intro: ECCV 2014\n- project page: [https://people.ee.ethz.ch/~gyglim/vsum/index.php](https://people.ee.ethz.ch/~gyglim/vsum/index.php)\n- paper: [https://people.ee.ethz.ch/~gyglim/vsum/GygliECCV14_vsum.pdf](https://people.ee.ethz.ch/~gyglim/vsum/GygliECCV14_vsum.pdf)\n- paper: [http://www.vision.ee.ethz.ch/~hegrabne/papers/Gygli2014CreatingSummariesfrom.pdf](http://www.vision.ee.ethz.ch/~hegrabne/papers/Gygli2014CreatingSummariesfrom.pdf)\n- code: [https://people.ee.ethz.ch/~gyglim/vsum/index.php#sf_code](https://people.ee.ethz.ch/~gyglim/vsum/index.php#sf_code) \n\n**Joint Summarization of Large-scale Collections of Web Images and Videos for Storyline Reconstruction**\n\n- intro: CVPR 2014\n- paper: [http://www.cs.cmu.edu/~gunhee/publish/cvpr14_videostory.pdf](http://www.cs.cmu.edu/~gunhee/publish/cvpr14_videostory.pdf)\n\n**Video Summarization by Learning Submodular Mixtures of Objectives**\n\n![](http://www.vision.ee.ethz.ch/~hegrabne/visualInterestingness/vsum2.jpg)\n\n- intro: CVPR 2015\n- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Gygli_Video_Summarization_by_2015_CVPR_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Gygli_Video_Summarization_by_2015_CVPR_paper.pdf)\n\n**TVSum: Summarizing Web Videos Using Titles**\n\n![](https://qph.is.quoracdn.net/main-qimg-0c0bb88876258e99272200655e2dc2ea?convert_to_webp=true)\n\n- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf)\n\n**Summarizing While Recording: Context-Based Highlight Detection for Egocentric Videos**\n\n- keywords: structured SVM (SSVM)\n- paper: [http://www.umiacs.umd.edu/~morariu/publications/LinEgocentricICCVW15.pdf](http://www.umiacs.umd.edu/~morariu/publications/LinEgocentricICCVW15.pdf)\n\n**Title Generation for User Generated Videos**\n\n- intro: ECCV 2016\n- arxiv: [http://arxiv.org/abs/1608.07068](http://arxiv.org/abs/1608.07068)\n\n# Activity Recognition\n\n**Latent Hierarchical Model for Activity Recognition**\n\n- paper: [http://arxiv.org/abs/1503.01820](http://arxiv.org/abs/1503.01820)\n- github: [https://github.com/louxi11/activity_recognition](https://github.com/louxi11/activity_recognition)\n- author page: [https://staff.fnwi.uva.nl/n.hu/](https://staff.fnwi.uva.nl/n.hu/)\n\n# Virtual Reality (VR)\n\n**Surround360 System: Facebook's open source hardware and software for capturing stereoscopic 3D 360 video for VR**\n\n![](https://s2.wp.com/wp-content/themes/vip/fbspherical/images/static/surround-360-inside.png)\n\n- homepage: [https://facebook360.fb.com/facebook-surround-360/](https://facebook360.fb.com/facebook-surround-360/)\n- code: [https://code.facebook.com/posts/265413023819735/surround-360-is-now-open-source/](https://code.facebook.com/posts/265413023819735/surround-360-is-now-open-source/)\n- github: [https://github.com/facebook/Surround360](https://github.com/facebook/Surround360)\n\n**Virtual Reality**\n\n- intro: Steven M. LaValle. Cambridge University Press 2016\n- book: [http://vr.cs.uiuc.edu/](http://vr.cs.uiuc.edu/)\n\n# SLAM\n\n**Why SLAM Matters, The Future of Real-Time SLAM, and Deep Learning vs SLAM**\n\n- blog: [http://www.computervisionblog.com/2016/01/why-slam-matters-future-of-real-time.html?m=1](http://www.computervisionblog.com/2016/01/why-slam-matters-future-of-real-time.html?m=1)\n\n**RGB-D SLAM**\n\n- blog: [http://www.cnblogs.com/gaoxiang12/tag/%E4%B8%80%E8%B5%B7%E5%81%9ARGB-D%20SLAM/](http://www.cnblogs.com/gaoxiang12/tag/%E4%B8%80%E8%B5%B7%E5%81%9ARGB-D%20SLAM/)\n- github: [https://github.com/gaoxiang12/rgbd-slam-tutorial-gx](https://github.com/gaoxiang12/rgbd-slam-tutorial-gx)\n\n**PySceneDetect: a command-line application and a Python library for automatically detecting scene changes in video files**\n\n- homepage: [http://pyscenedetect.readthedocs.org/en/latest/](http://pyscenedetect.readthedocs.org/en/latest/)\n\n**The Future of Real-Time SLAM and Deep Learning vs SLAM**\n\n- blog: [http://www.computervisionblog.com/2016/01/why-slam-matters-future-of-real-time.html](http://www.computervisionblog.com/2016/01/why-slam-matters-future-of-real-time.html)\n\n**Awesome SLAM**\n\n- github: [https://github.com/kanster/awesome-slam](https://github.com/kanster/awesome-slam)\n\n**ORB-SLAM2: Real-Time SLAM for Monocular, Stereo and RGB-D Cameras, with Loop Detection and Relocalization Capabilities**\n\n- github: [https://github.com/raulmur/ORB_SLAM2](https://github.com/raulmur/ORB_SLAM2)\n\n**Cartographer**\n\n- intro: Cartographer is a system that provides real-time simultaneous localization \nand mapping (SLAM) in 2D and 3D across multiple platforms and sensor configurations.\n- github: [https://github.com/googlecartographer/cartographer](https://github.com/googlecartographer/cartographer)\n\n**Introducing Cartographer**\n\n- blog: [https://opensource.googleblog.com/2016/10/introducing-cartographer.html](https://opensource.googleblog.com/2016/10/introducing-cartographer.html)\n\n**Real-Time Loop Closure in 2D LIDAR SLAM**\n\n- intro: ICRA 2016. Google. Cartographer\n- paper: [http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45466.pdf](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45466.pdf)\n\n# Optical Flow\n\n**A Database and Evaluation Methodology for Optical Flow**\n\n- intro: IJCV 2011\n- project page: [http://vision.middlebury.edu/flow/](http://vision.middlebury.edu/flow/)\n- paper: [http://vision.middlebury.edu/flow/floweval-ijcv2011.pdf](http://vision.middlebury.edu/flow/floweval-ijcv2011.pdf)\n\n**SimpleFlow: A Non-iterative, Sublinear Optical Flow Algorithm**\n\n- intro: Eurographics 2012\n- project page: [http://graphics.berkeley.edu/papers/Tao-SAN-2012-05/](http://graphics.berkeley.edu/papers/Tao-SAN-2012-05/)\n- paper: [http://graphics.berkeley.edu/papers/Tao-SAN-2012-05/Tao-SAN-2012-05.pdf](http://graphics.berkeley.edu/papers/Tao-SAN-2012-05/Tao-SAN-2012-05.pdf)\n- code: [graphics.berkeley.edu/papers/Tao-SAN-2012-05/SimpleFlow_Source.zip](graphics.berkeley.edu/papers/Tao-SAN-2012-05/SimpleFlow_Source.zip)\n\n# OCR\n\n**Ocular: a state-of-the-art historical OCR system**\n\n- github: [https://github.com/tberg12/ocular](https://github.com/tberg12/ocular)\n\n**SESHAT: Handwritten math expression parser**\n\n- intro: Seshat is an open-source system for recognizing handwritten mathematical expressions. \nGiven a sample represented as a sequence of strokes, the parser is able to convert it to LaTeX or other formats like InkML or MathML.\n- github: [https://github.com/falvaro/seshat](https://github.com/falvaro/seshat)\n\n**Awesome OCR: Links to awesome OCR projects**\n\n- github: [https://github.com/kba/awesome-ocr](https://github.com/kba/awesome-ocr)\n\n**OCR// Tesseract**\n\n- github: [https://github.com/daijiale/OCR_FontsSearchEngine](https://github.com/daijiale/OCR_FontsSearchEngine)\n\n**The Simple + Practical Path to Machine Learning Capability: A Common Benchmark Task**\n\n![](https://indico.io/blog/wp-content/uploads/2016/09/TF0.5a-1-sm-768x520.png)\n\n- blog: [https://indico.io/blog/simple-practical-path-to-machine-learning-capability-part2/](https://indico.io/blog/simple-practical-path-to-machine-learning-capability-part2/)\n\n**Optical Character Recognition (OCR)**\n\n- blog: [http://aosabook.org/en/500L/pages/optical-character-recognition-ocr.html](http://aosabook.org/en/500L/pages/optical-character-recognition-ocr.html)\n\n**Sharingan: Newspaper text and context extractor**\n\n- intro: Tool to extract news articles from newspaper and give the context about the news\n- blog: [http://www.vipul.xyz/2017/03/sharingan-newspaper-text-and-context.html](http://www.vipul.xyz/2017/03/sharingan-newspaper-text-and-context.html)\n- github: [https://github.com/vipul-sharma20/sharingan](https://github.com/vipul-sharma20/sharingan)\n\n# Codec\n\n**JPEG 101 - How does JPEG work?**\n\n- blog: [http://arjunsreedharan.org/post/146070390717/jpeg-101-how-does-jpeg-work](http://arjunsreedharan.org/post/146070390717/jpeg-101-how-does-jpeg-work)\n\n# Face Alignment\n\n**Supervised Descent Method and its Applications to Face Alignment**\n\n- intro: CVPR 2013\n- project page: [http://patrikhuber.github.io/superviseddescent/](http://patrikhuber.github.io/superviseddescent/)\n- paper: [http://101.96.8.164/www.ri.cmu.edu/pub_files/2013/5/main.pdf](http://101.96.8.164/www.ri.cmu.edu/pub_files/2013/5/main.pdf)\n- github: [https://github.com/patrikhuber/superviseddescent](https://github.com/patrikhuber/superviseddescent)\n\n**Face Alignment at 3000 FPS via Regressing Local Binary Features**\n\n- intro: CVPR 2014. MSRA\n- paper: [http://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/yichenw-cvpr14_facealignment.pdf](http://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/yichenw-cvpr14_facealignment.pdf)\n- github: [https://github.com/yulequan/face-alignment-in-3000fps](https://github.com/yulequan/face-alignment-in-3000fps)\n\n**Joint Cascade Face Detection and Alignment**\n\n- intro: ECCV 2014\n- paper: [http://www.microsoft.com/en-us/research/wp-content/uploads/2016/12/ECCV14_JointCascade.pdf](http://www.microsoft.com/en-us/research/wp-content/uploads/2016/12/ECCV14_JointCascade.pdf)\n- github: [https://github.com/FaceDetect/jointCascade_py](https://github.com/FaceDetect/jointCascade_py)\n\n# Papers\n\n**RGB-W: When Vision Meets Wireless**\n\n![](http://vision.stanford.edu/pubimg/rgbw15_1.png)\n\n- paper: [http://vision.stanford.edu/pdf/RGBW_ICCV15.pdf](http://vision.stanford.edu/pdf/RGBW_ICCV15.pdf)\n\n**A Computational Approach for Obstruction-Free Photography**\n\n- paper: [https://people.csail.mit.edu/mrub/papers/ObstructionFreePhotograpy_SIGGRAPH2015.pdf](https://people.csail.mit.edu/mrub/papers/ObstructionFreePhotograpy_SIGGRAPH2015.pdf)\n\n**My Text in Your Handwriting**\n\n![](http://visual.cs.ucl.ac.uk/pubs/handwriting/img/results.jpg)\n\n- homepage: [http://visual.cs.ucl.ac.uk/pubs/handwriting/](http://visual.cs.ucl.ac.uk/pubs/handwriting/)\n- paper: [http://visual.cs.ucl.ac.uk/pubs/handwriting/handwriting_visual_main.pdf](http://visual.cs.ucl.ac.uk/pubs/handwriting/handwriting_visual_main.pdf)\n\n**Seeing the Arrow of Time**\n\n- intro: CVPR 2013\n- intro: \"is it possible to tell whether a video is running forwards or backwards?\"\n- project page: [http://people.csail.mit.edu/yichangshih/toa_web/](http://people.csail.mit.edu/yichangshih/toa_web/)\n- project page: [http://www.robots.ox.ac.uk/~vgg/research/arrow/](http://www.robots.ox.ac.uk/~vgg/research/arrow/)\n- paper: [http://www.robots.ox.ac.uk/~vgg/publications/2014/Pickup14/pickup14.pdf](http://www.robots.ox.ac.uk/~vgg/publications/2014/Pickup14/pickup14.pdf)\n- paper: [http://people.csail.mit.edu/yichangshih/toa_web/ArrowCVPR131101.pdf](http://people.csail.mit.edu/yichangshih/toa_web/ArrowCVPR131101.pdf)\n\n**Time-lapse Mining from Internet Photos**\n\n![](http://grail.cs.washington.edu/projects/timelapse/teaser2.jpg)\n\n- intro: SIGGRAPH 2015\n- project page: [http://grail.cs.washington.edu/projects/timelapse/](http://grail.cs.washington.edu/projects/timelapse/)\n- paper: [http://grail.cs.washington.edu/projects/timelapse/TimelapseMiningSIGGRAPH15.pdf](http://grail.cs.washington.edu/projects/timelapse/TimelapseMiningSIGGRAPH15.pdf)\n- wired: [https://www.wired.com/2015/05/crowdsourced-timelapse/](https://www.wired.com/2015/05/crowdsourced-timelapse/)\n\n**3D Time-lapse Reconstruction from Internet Photos**\n\n- intro: ICCV 2015 (oral)\n- project page: [http://grail.cs.washington.edu/projects/timelapse3d/](http://grail.cs.washington.edu/projects/timelapse3d/)\n- paper: [http://grail.cs.washington.edu/projects/timelapse3d/3DTimelapseReconstructionICCV15.pdf](http://grail.cs.washington.edu/projects/timelapse3d/3DTimelapseReconstructionICCV15.pdf)\n\n**The Fast Bilateral Solver**\n\n- intro: ECCV 2016 Best Honorable Mention Award\n- arxiv: [https://arxiv.org/abs/1511.03296](https://arxiv.org/abs/1511.03296)\n- github: [https://github.com/poolio/bilateral_solver](https://github.com/poolio/bilateral_solver)\n\n**Are Elephants Bigger than Butterflies? Reasoning about Sizes of Objects**\n\n![](http://grail.cs.washington.edu/projects/size/images/teaser.jpg)\n\n- arxiv: [http://arxiv.org/abs/1602.00753](http://arxiv.org/abs/1602.00753)\n- project page: [http://grail.cs.washington.edu/projects/size/](http://grail.cs.washington.edu/projects/size/)\n\n**Atoms of recognition in human and computer vision**\n\n![](http://www.wisdom.weizmann.ac.il/~dannyh/Mircs/cover.jpg)\n\n- homepage: [http://www.wisdom.weizmann.ac.il/~dannyh/Mircs/mircs.html](http://www.wisdom.weizmann.ac.il/~dannyh/Mircs/mircs.html)\n- paper: [https://s3-us-west-1.amazonaws.com/disneyresearch/wp-content/uploads/20150929153916/Live-Texturing-of-Augmented-Reality-Characters-from-Colored-Drawings-Paper.pdf](https://s3-us-west-1.amazonaws.com/disneyresearch/wp-content/uploads/20150929153916/Live-Texturing-of-Augmented-Reality-Characters-from-Colored-Drawings-Paper.pdf)\n\n**Live Texturing of Augmented Reality Characters from Colored Drawings**\n\n![](https://www.disneyresearch.com/wp-content/uploads/Live-Texturing-of-Augmented-Reality-Characters-from-Colored-Drawings-Image-1024x576.png)\n\n- homepage: [https://www.disneyresearch.com/publication/live-texturing-of-augmented-reality-characters/](https://www.disneyresearch.com/publication/live-texturing-of-augmented-reality-characters/)\n\n**Colorization for Image Compression**\n\n- arxiv: [http://arxiv.org/abs/1606.06314](http://arxiv.org/abs/1606.06314)\n\n**Face2Face: Real-time Face Capture and Reenactment of RGB Videos**\n\n![](http://www.graphics.stanford.edu/~niessner/papers/2016/1facetoface/teaser.jpg)\n\n- project page: [http://www.graphics.stanford.edu/~niessner/thies2016face.html](http://www.graphics.stanford.edu/~niessner/thies2016face.html)\n- paper: [http://www.graphics.stanford.edu/~niessner/papers/2016/1facetoface/thies2016face.pdf](http://www.graphics.stanford.edu/~niessner/papers/2016/1facetoface/thies2016face.pdf)\n\n# Applications\n\n**Target acquired: Finding targets in drone and quadcopter video streams using Python and OpenCV**\n[http://www.pyimagesearch.com/2015/05/04/target-acquired-finding-targets-in-drone-and-quadcopter-video-streams-using-python-and-opencv/](http://www.pyimagesearch.com/2015/05/04/target-acquired-finding-targets-in-drone-and-quadcopter-video-streams-using-python-and-opencv/)\n\n**FaceDirector: Continuous Control of Facial Performance in Video**\n\n![](https://www.disneyresearch.com/wp-content/uploads/FaceDirector-Continuous-Control-of-Facial-Performance-in-Video-Image.png)\n\n- homepage: [http://www.disneyresearch.com/publication/facedirector/](http://www.disneyresearch.com/publication/facedirector/)\n- paper: [http://disneyresearch.s3-us-west-1.amazonaws.com/wp-content/uploads/20151210174750/FaceDirector-Continuous-Control-of-Facial-Performance-in-Video-Paper.pdf](http://disneyresearch.s3-us-west-1.amazonaws.com/wp-content/uploads/20151210174750/FaceDirector-Continuous-Control-of-Facial-Performance-in-Video-Paper.pdf)\n\n**Real-time Expression Transfer for Facial Reenactment**\n\n![](http://graphics.stanford.edu/~niessner/papers/2015/10face/teaser.jpg)\n\n- homepage: [http://graphics.stanford.edu/~niessner/thies2015realtime.html](http://graphics.stanford.edu/~niessner/thies2015realtime.html)\n- paper: [http://graphics.stanford.edu/~niessner/papers/2015/10face/thies2015realtime.pdf](http://graphics.stanford.edu/~niessner/papers/2015/10face/thies2015realtime.pdf)\n\n**Photo Stylistic Brush: Robust Style Transfer via Superpixel-Based Bipartite Graph**\n\n- arxiv: [http://arxiv.org/abs/1606.03871](http://arxiv.org/abs/1606.03871)\n\n**GMS: Grid-based Motion Statistics for Fast, Ultra-robust Feature Correspondence**\n\n![](https://i1.wp.com/jwbian.net/wp-content/uploads/2017/03/dog_ours.jpg?resize=768%2C512)\n\n- intro: CVPR 2017\n- project page: [http://jwbian.net/gms](http://jwbian.net/gms)\n- github: [https://github.com/JiawangBian/GMS-Feature-Matcher](https://github.com/JiawangBian/GMS-Feature-Matcher)\n\n# Projects\n\n**OpenBR: Open Source Biometrics, Face Recognition, Age Estimation, Gender Estimation**\n\n![](http://openbiometrics.org/diagram.png)\n\n- homepage: [http://openbiometrics.org/](http://openbiometrics.org/)\n- github: [https://github.com/biometrics/openbr](https://github.com/biometrics/openbr)\n- docs: [http://openbiometrics.org/docs/index.html](http://openbiometrics.org/docs/index.html)\n\n**SmartMirror**\n\n<p align=\"center\">\n  <img src=\"/docs/SmartMirror_DisplayMenu_Preview.gif\"/>       <img src=\"/docs/SmartMirror_Widget_Preview.gif\"/>\n</p>\n\n- github: [https://github.com/Shinao/SmartMirror](https://github.com/Shinao/SmartMirror)\n\n**Home Surveilance with Facial Recognition**\n\n![](https://raw.githubusercontent.com/BrandonJoffe/home_surveillance/prototype/system/debugging/dashboard.png)\n\n- github: [https://github.com/BrandonJoffe/home_surveillance](https://github.com/BrandonJoffe/home_surveillance)\n\n**Image unshredding using a TSP solver**\n\n![](https://camo.githubusercontent.com/fbf30f6bce6931eee114366a5dc3372f259451ff/68747470733a2f2f726f62696e686f7573746f6e2e6769746875622e696f2f696d6167652d756e736872656464696e672f696d616765732f6c656173742d737175617265732f626c75652d686f75722d70617269732e706e67)\n\n- github: [https://github.com/robinhouston/image-unshredding](https://github.com/robinhouston/image-unshredding)\n\n# Resources\n\n**Awesome Computer Vision**\n\n- github: [https://github.com/jbhuang0604/awesome-computer-vision](https://github.com/jbhuang0604/awesome-computer-vision)\n\n**Resources: Visual Recognition and Search**\n\n- intro: \"Non-exhaustive list of state-of-the-art implementations related to visual recognition and search\"\n- blog: [http://rogerioferis.com/VisualRecognitionAndSearch2014/Resources.html](http://rogerioferis.com/VisualRecognitionAndSearch2014/Resources.html)\n\n# Libraries\n\n**BoofCV: an open source Java library for real-time computer vision and robotics applications**\n\n[http://boofcv.org/index.php?title=Main_Page](http://boofcv.org/index.php?title=Main_Page)\n\n**tracking.js: A modern approach for Computer Vision on the web**\n\n- homepage: [https://trackingjs.com/](https://trackingjs.com/)\n- github: [https://github.com/eduardolundgren/tracking.js/](https://github.com/eduardolundgren/tracking.js/)\n\n**FastCV Computer Vision SDK**\n\n- homepage: [https://developer.qualcomm.com/software/fastcv-sdk](https://developer.qualcomm.com/software/fastcv-sdk)\n\n**Video++, a C++14 high performance video and image processing library**\n\n- github: [https://github.com/matt-42/vpp](https://github.com/matt-42/vpp)\n- doc: [http://documentup.com/matt-42/vpp](http://documentup.com/matt-42/vpp)\n\n**VLFeat -- Vision Lab Features Library**\n\n- intro: Algorithms include Fisher Vector, VLAD, SIFT, MSER, k-means, hierarchical k-means, \nagglomerative information bottleneck, SLIC superpixels, quick shift superpixels, large scale SVM training, and many others\n- homapage: [http://www.vlfeat.org/](http://www.vlfeat.org/)\n- github: [https://github.com/vlfeat/vlfeat](https://github.com/vlfeat/vlfeat)\n\n# Datasets\n\n**CVonline: Image Databases**\n\n[http://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase.htm](http://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase.htm)\n\n**Yet Another Computer Vision Index To Datasets (YACVID)**\n\n[http://riemenschneider.hayko.at/vision/dataset/](http://riemenschneider.hayko.at/vision/dataset/)\n\n# Blogs\n\n**From feature descriptors to deep learning: 20 years of computer vision**\n\n- blog: [http://www.computervisionblog.com/2015/01/from-feature-descriptors-to-deep.html](http://www.computervisionblog.com/2015/01/from-feature-descriptors-to-deep.html)\n\n**Unsupervised Computer Vision: The State of the Art | Stitch Fix Technology  Multithreaded**\n\n- blog: [http://multithreaded.stitchfix.com/blog/2016/02/04/computer-vision-state-of-the-art](http://multithreaded.stitchfix.com/blog/2016/02/04/computer-vision-state-of-the-art)\n- slides: [http://pan.baidu.com/s/1c0Sxzvq](http://pan.baidu.com/s/1c0Sxzvq)\n\n**Exploring Computer Vision**\n\n- Part I: Convolutional Neural Networks: [https://indico.io/blog/exploring-computer-vision-convolutional-neural-nets/](https://indico.io/blog/exploring-computer-vision-convolutional-neural-nets/)\n- Part II: Transfer Learning: [https://indico.io/blog/exploring-computer-vision-transfer-learning/](https://indico.io/blog/exploring-computer-vision-transfer-learning/)\n\n**Image Processing with Numpy**\n\n- blog: [http://www.degeneratestate.org/posts/2016/Oct/23/image-processing-with-numpy/](http://www.degeneratestate.org/posts/2016/Oct/23/image-processing-with-numpy/)\n\n# Conferences\n\n**SIGGRAPH 2016 papers on the web**\n\n[http://kesen.realtimerendering.com/sig2016.html](http://kesen.realtimerendering.com/sig2016.html)\n\n# Resources\n\n**The Ultimate List of 300+ Computer Vision Resources**\n\n- blog: [https://hackerlists.com/computer-vision-resources/](https://hackerlists.com/computer-vision-resources/)\n","excerpt":"Courses Mobile Computer Vision (Spring 2015) homepage:  http://web.stanford.edu/class/cs231m/ syllabus:  http://web.stanford.edu/class/cs23","outboundReferences":[],"inboundReferences":[]},"tagsOutbound":{"nodes":[]}},"pageContext":{"tags":[],"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-12-cv-resources/","sidebarItems":[{"title":"Categories","items":[{"title":"Commercial","url":"","items":[{"title":"Commercial Structure","url":"/Commercial/Commercial Structure/","items":[]},{"title":"Community of Practice","url":"/Commercial/Community of Practice/","items":[]},{"title":"Domains","url":"/Commercial/Domains/","items":[]},{"title":"Webizen Alliance","url":"/Commercial/Webizen Alliance/","items":[]}]},{"title":"Core Services","url":"","items":[{"title":"Decentralised Ontologies","url":"/Core Services/Decentralised Ontologies/","items":[]},{"title":"Permissive Commons","url":"/Core Services/Permissive Commons/","items":[]},{"title":"Safety Protocols","url":"","items":[{"title":"Safety Protocols","url":"/Core Services/Safety Protocols/Safety Protocols/","items":[]},{"title":"Social Factors","url":"","items":[{"title":"Best Efforts","url":"/Core Services/Safety Protocols/Social Factors/Best Efforts/","items":[]},{"title":"Ending Digital Slavery","url":"/Core Services/Safety Protocols/Social Factors/Ending Digital Slavery/","items":[]},{"title":"Freedom of Thought","url":"/Core Services/Safety Protocols/Social Factors/Freedom of Thought/","items":[]},{"title":"No Golden Handcuffs","url":"/Core Services/Safety Protocols/Social Factors/No Golden Handcuffs/","items":[]},{"title":"Relationships (Social)","url":"/Core Services/Safety Protocols/Social Factors/Relationships (Social)/","items":[]},{"title":"Social Attack Vectors","url":"/Core Services/Safety Protocols/Social Factors/Social Attack Vectors/","items":[]},{"title":"The Webizen Charter","url":"/Core Services/Safety Protocols/Social Factors/The Webizen Charter/","items":[]}]},{"title":"Values Credentials","url":"/Core Services/Safety Protocols/Values Credentials/","items":[]}]},{"title":"Temporal Semantics","url":"/Core Services/Temporal Semantics/","items":[]},{"title":"Verifiable Claims & Credentials","url":"/Core Services/Verifiable Claims & Credentials/","items":[]},{"title":"Webizen Socio-Economics","url":"","items":[{"title":"Biosphere Ontologies","url":"/Core Services/Webizen Socio-Economics/Biosphere Ontologies/","items":[]},{"title":"Centricity","url":"/Core Services/Webizen Socio-Economics/Centricity/","items":[]},{"title":"Currencies","url":"/Core Services/Webizen Socio-Economics/Currencies/","items":[]},{"title":"SocioSphere Ontologies","url":"/Core Services/Webizen Socio-Economics/SocioSphere Ontologies/","items":[]},{"title":"Sustainable Development Goals (ESG)","url":"/Core Services/Webizen Socio-Economics/Sustainable Development Goals (ESG)/","items":[]}]}]},{"title":"Core Technologies","url":"","items":[{"title":"AUTH","url":"","items":[{"title":"Authentication Fabric","url":"/Core Technologies/AUTH/Authentication Fabric/","items":[]}]},{"title":"Webizen App Spec","url":"","items":[{"title":"SemWebSpecs","url":"","items":[{"title":"Core Ontologies","url":"","items":[{"title":"FOAF","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/FOAF/","items":[]},{"title":"General Ontology Information","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/General Ontology Information/","items":[]},{"title":"Human Rights Ontologies","url":"","items":[{"title":"UDHR","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/Human Rights Ontologies/UDHR/","items":[]}]},{"title":"MD-RDF Ontologies","url":"","items":[{"title":"DataTypesOntology (DTO) Core","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/MD-RDF Ontologies/DataTypes Ontology/","items":[]},{"title":"Friend of a Friend (FOAF) Core","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/MD-RDF Ontologies/FOAF/","items":[]}]},{"title":"OWL","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/OWL/","items":[]},{"title":"RDF Schema 1.1","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/RDFS/","items":[]},{"title":"Sitemap","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/Sitemap/","items":[]},{"title":"SKOS","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/SKOS/","items":[]},{"title":"SOIC","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/SOIC/","items":[]}]},{"title":"Semantic Web - An Introduction","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Semantic Web - An Introduction/","items":[]},{"title":"SemWeb-AUTH","url":"","items":[{"title":"WebID-OIDC","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-OIDC/","items":[]},{"title":"WebID-RSA","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-RSA/","items":[]},{"title":"WebID-TLS","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-TLS/","items":[]}]},{"title":"Sparql","url":"","items":[{"title":"Sparql Family","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Sparql/Sparql Family/","items":[]}]},{"title":"W3C Specifications","url":"","items":[{"title":"Linked Data Fragments","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Fragments/","items":[]},{"title":"Linked Data Notifications","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Notifications/","items":[]},{"title":"Linked Data Platform","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Platform/","items":[]},{"title":"Linked Media Fragments","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Media Fragments/","items":[]},{"title":"RDF","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/RDF/","items":[]},{"title":"Web Access Control (WAC)","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Web Access Control (WAC)/","items":[]},{"title":"Web Of Things","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Web Of Things/","items":[]},{"title":"WebID","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/WebID/","items":[]}]}]},{"title":"Webizen App Spec 1.0","url":"/Core Technologies/Webizen App Spec/Webizen App Spec 1.0/","items":[]},{"title":"WebSpec","url":"","items":[{"title":"HTML SPECS","url":"/Core Technologies/Webizen App Spec/WebSpec/HTML SPECS/","items":[]},{"title":"Query Interfaces","url":"","items":[{"title":"GraphQL","url":"/Core Technologies/Webizen App Spec/WebSpec/Query Interfaces/GraphQL/","items":[]}]},{"title":"WebPlatformTools","url":"","items":[{"title":"WebAuthn","url":"/Core Technologies/Webizen App Spec/WebSpec/WebPlatformTools/WebAuthn/","items":[]},{"title":"WebDav","url":"/Core Technologies/Webizen App Spec/WebSpec/WebPlatformTools/WebDav/","items":[]}]}]}]}]},{"title":"Database Requirements","url":"","items":[{"title":"Database Alternatives","url":"","items":[{"title":"Akutan","url":"/Database requirements/Database Alternatives/akutan/","items":[]},{"title":"CayleyGraph","url":"/Database requirements/Database Alternatives/CayleyGraph/","items":[]}]},{"title":"Database Methods","url":"","items":[{"title":"GraphQL","url":"/Database requirements/Database methods/GraphQL/","items":[]},{"title":"Sparql","url":"/Database requirements/Database methods/Sparql/","items":[]}]}]},{"title":"Host Service Requirements","url":"","items":[{"title":"Domain Hosting","url":"/Host Service Requirements/Domain Hosting/","items":[]},{"title":"Email Services","url":"/Host Service Requirements/Email Services/","items":[]},{"title":"LD_PostOffice_SemanticMGR","url":"/Host Service Requirements/LD_PostOffice_SemanticMGR/","items":[]},{"title":"Media Processing","url":"/Host Service Requirements/Media Processing/","items":[{"title":"Ffmpeg","url":"/Host Service Requirements/Media Processing/ffmpeg/","items":[]},{"title":"Opencv","url":"/Host Service Requirements/Media Processing/opencv/","items":[]}]},{"title":"Website Host","url":"/Host Service Requirements/Website Host/","items":[]}]},{"title":"ICT Stack","url":"","items":[{"title":"General References","url":"","items":[{"title":"List of Protocols ISO Model","url":"/ICT Stack/General References/List of Protocols ISO model/","items":[]}]},{"title":"Internet","url":"","items":[{"title":"Internet Stack","url":"/ICT Stack/Internet/Internet Stack/","items":[]}]}]},{"title":"Implementation V1","url":"","items":[{"title":"App-Design-Sdk-V1","url":"","items":[{"title":"Core Apps","url":"","items":[{"title":"Agent Directory","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Agent Directory/","items":[]},{"title":"Credentials & Contracts Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Credentials & Contracts Manager/","items":[]},{"title":"File (Package) Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/File (package) Manager/","items":[]},{"title":"Temporal Apps","url":"","items":[{"title":"Calendar","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Temporal Apps/Calendar/","items":[]},{"title":"Timeline Interface","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Temporal Apps/Timeline Interface/","items":[]}]},{"title":"Webizen Apps (V1)","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Webizen Apps (v1)/","items":[]},{"title":"Webizen Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Webizen Manager/","items":[]}]},{"title":"Data Applications","url":"/Implementation V1/App-design-sdk-v1/Data Applications/","items":[]},{"title":"Design Goals","url":"","items":[{"title":"Design Goals Overview","url":"/Implementation V1/App-design-sdk-v1/Design Goals/Design Goals Overview/","items":[]}]}]},{"title":"Edge","url":"","items":[{"title":"Webizen Local App Functionality","url":"/Implementation V1/edge/Webizen Local App Functionality/","items":[]}]},{"title":"GoLang Libraries","url":"/Implementation V1/GoLang Libraries/","items":[]},{"title":"Implementation V1 Summary","url":"/Implementation V1/Implementation V1 Summary/","items":[]},{"title":"Vps","url":"","items":[{"title":"Server Functionality Summary (VPS)","url":"/Implementation V1/vps/Server Functionality Summary (VPS)/","items":[]}]},{"title":"Webizen 1.0","url":"/Implementation V1/Webizen 1.0/","items":[]},{"title":"Webizen-Connect","url":"","items":[{"title":"Social Media APIs","url":"/Implementation V1/Webizen-Connect/Social Media APIs/","items":[]},{"title":"Webizen-Connect (Summary)","url":"/Implementation V1/Webizen-Connect/Webizen-Connect (summary)/","items":[]}]}]},{"title":"Non-HTTP(s) Protocols","url":"","items":[{"title":"DAT","url":"/Non-HTTP(s) Protocols/DAT/","items":[]},{"title":"GIT","url":"/Non-HTTP(s) Protocols/GIT/","items":[]},{"title":"GUNECO","url":"/Non-HTTP(s) Protocols/GUNECO/","items":[]},{"title":"IPFS","url":"/Non-HTTP(s) Protocols/IPFS/","items":[]},{"title":"Lightning Network","url":"/Non-HTTP(s) Protocols/Lightning Network/","items":[]},{"title":"Non-HTTP(s) Protocols (& DLTs)","url":"/Non-HTTP(s) Protocols/Non-HTTP(s) Protocols (& DLTs)/","items":[]},{"title":"WebRTC","url":"/Non-HTTP(s) Protocols/WebRTC/","items":[]},{"title":"WebSockets","url":"/Non-HTTP(s) Protocols/WebSockets/","items":[]},{"title":"WebTorrent","url":"/Non-HTTP(s) Protocols/WebTorrent/","items":[]}]},{"title":"Old-Work-Archives","url":"","items":[{"title":"2018-Webizen-Net-Au","url":"","items":[{"title":"_Link_library_links","url":"","items":[{"title":"Link Library","url":"/old-work-archives/2018-webizen-net-au/_link_library_links/2018-09-23-wp-linked-data/","items":[]}]},{"title":"_Posts","url":"","items":[{"title":"About W3C","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-27-about-w3c/","items":[]},{"title":"Advanced Functions &#8211; Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-16-advanced-functions-facebook-pages/","items":[]},{"title":"Advanced Search &#038; Discovery Tips","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-advanced-search-discovery-tips/","items":[]},{"title":"An introduction to Virtual Machines.","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-an-introduction-to-virtual-machines/","items":[]},{"title":"Basic Media Analysis &#8211; Part 1 (Audio)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-30-media-analysis-part-1-audio/","items":[]},{"title":"Basic Media Analysis &#8211; Part 2 (visual)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-31-media-analysis-part-2-visual/","items":[]},{"title":"Basic Media Analysis &#8211; Part 3 (Text &#038; Metadata)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-01-01-basic-media-analysis-part-3-text-metadata/","items":[]},{"title":"Building an Economy based upon Knowledge Equity.","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-25-building-an-economy-based-upon-knowledge-equity/","items":[]},{"title":"Choice of Law","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-26-choice-of-law/","items":[]},{"title":"Contemplation of the ITU Dubai Meeting and the Future of the Internet","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-19-contemplation-of-the-itu-dubai-meeting-and-the-future-of-the-internet/","items":[]},{"title":"Creating a Presence &#8211; Online","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-creating-a-presence-online/","items":[]},{"title":"Credentials and Payments by Manu Sporny","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-credentials-and-payments-by-manu-sporny/","items":[]},{"title":"Data Recovery &#038; Collection: Mobile Devices","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-28-mobile-devices-data-recovery-collection/","items":[]},{"title":"Data Recovery: Laptop &#038; Computers","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-28-data-recovery-laptop-computers/","items":[]},{"title":"Decentralized Web Conference 2016","url":"/old-work-archives/2018-webizen-net-au/_posts/2016-06-09-decentralized-web-2016/","items":[]},{"title":"Decentralized Web Summit 2018","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-decentralized-web-summit-2018/","items":[]},{"title":"Does Anonymity exist?","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-does-anonymity-exist/","items":[]},{"title":"Downloading My Data from Social Networks","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-downloading-my-data-from-social-networks/","items":[]},{"title":"Events","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-events/","items":[]},{"title":"Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-16-facebook-pages/","items":[]},{"title":"Google Tracking Data (geolocation)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-google-tracking/","items":[]},{"title":"Human Consciousness","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-human-consciousness/","items":[]},{"title":"Image Recgonition Video Playlist","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-image-recgonition-video-playlist/","items":[]},{"title":"Inferencing (introduction)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-inferencing-introduction/","items":[]},{"title":"Introduction to AI","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-introduction-to-ai/","items":[]},{"title":"Introduction to Linked Data","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-introduction-to-linked-data/","items":[]},{"title":"Introduction to Maltego","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-introduction-to-maltego/","items":[]},{"title":"Introduction to Ontologies","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-ontologies-intro/","items":[]},{"title":"Introduction to Semantic Web","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-introduction-to-semantic-web/","items":[]},{"title":"Knowledge Capital","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-10-17-knowledge-capital/","items":[]},{"title":"Logo&#8217;s, Style Guides and Artwork","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-logos-style-guides-and-artwork/","items":[]},{"title":"MindMapping &#8211; Setting-up a business &#8211; Identity","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-mindmapping-setting-up-a-business-identity/","items":[]},{"title":"Openlink Virtuoso","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-openlink-virtuoso/","items":[]},{"title":"OpenRefine","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-74-2/","items":[]},{"title":"Projects, Customers and Invoicing &#8211; Web-Services for Startups","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-projects-customers-and-invoicing-web-services-for-startups/","items":[]},{"title":"RWW &#038; some Solid history","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-rww-some-solid-history/","items":[]},{"title":"Semantic Web (An Intro)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-semantic-web-an-intro/","items":[]},{"title":"Setting-up Twitter","url":"/old-work-archives/2018-webizen-net-au/_posts/2013-06-07-setting-up-twitter/","items":[]},{"title":"Social Encryption: An Introduction","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-25-social-encryption-an-introduction/","items":[]},{"title":"Stock Content","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-stock-content/","items":[]},{"title":"The WayBack Machine","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-27-the-wayback-machine/","items":[]},{"title":"Tim Berners Lee &#8211; Turing Lecture","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-05-29-tim-berners-lee-turing-lecture/","items":[]},{"title":"Tools of Trade","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-tools-of-trade/","items":[]},{"title":"Trust Factory 2017","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-trust-factory-2017/","items":[]},{"title":"Verifiable Claims (An Introduction)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-vc-intro/","items":[]},{"title":"Web of Things &#8211; an Introduction","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-web-of-things-an-introduction/","items":[]},{"title":"Web-Persistence","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-web-persistence/","items":[]},{"title":"Web-Services &#8211; Marketing Tools","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-web-services-marketing-tools/","items":[]},{"title":"Website Templates","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-templates/","items":[]},{"title":"What is Linked Data?","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-what-is-linked-data/","items":[]},{"title":"What is Open Source Intelligence?","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-what-is-osint/","items":[]},{"title":"WiX","url":"/old-work-archives/2018-webizen-net-au/_posts/2013-01-01-wix/","items":[]}]},{"title":"about","url":"/old-work-archives/2018-webizen-net-au/about/","items":[{"title":"About The Author","url":"/old-work-archives/2018-webizen-net-au/about/about-the-author/","items":[]},{"title":"Applied Theory: Applications for a Human Centric Web","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/","items":[{"title":"Digital Receipts","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/digital-receipts/","items":[]},{"title":"Fake News: Considerations  Principles  The Institution of Socio &#8211; Economic Values","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations/","items":[]},{"title":"Healthy Living Economy","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/healthy-living-economy/","items":[]},{"title":"HyperMedia Solutions &#8211; Adapting HbbTV V2","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/","items":[{"title":"HYPERMEDIA PACKAGES","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/hypermedia-packages/","items":[]},{"title":"USER STORIES: INTERACTIVE VIEWING EXPERIENCE","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/user-stories-interactive-viewing-experience/","items":[]}]},{"title":"Measurements App","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/measurements-app/","items":[]},{"title":"Re:Animation","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/reanimation/","items":[]},{"title":"Solutions to FakeNews: Linked-Data, Ontologies and Verifiable Claims","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/ld-solutions-to-fakenews/","items":[]}]},{"title":"Executive Summary","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/","items":[{"title":"Assisting those who Enforce the Law","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/assisting-those-who-enforce-the-law/","items":[]},{"title":"Consumer Protections","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/consumer-protections/","items":[]},{"title":"Knowledge Banking: Legal Structures","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-banking-legal-structures/","items":[]},{"title":"Knowledge Economics &#8211; Services","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-economics-services/","items":[]},{"title":"Preserving The Freedom to Think","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/preserving-the-freedom-to-think/","items":[]}]},{"title":"History","url":"/old-work-archives/2018-webizen-net-au/about/history/","items":[{"title":"History: Global Governance and ICT.","url":"/old-work-archives/2018-webizen-net-au/about/history/history-global-governance-ict-1/","items":[]}]},{"title":"Knowledge Banking: A Technical Architecture Summary","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/","items":[{"title":"An introduction to Credentials.","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/","items":[{"title":"credentials and custodianship","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/credentials-and-custodianship/","items":[]},{"title":"DIDs and MultiSig","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/dids-and-multisig/","items":[]}]},{"title":"Personal Augmentation of AI","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/personal-augmentation-of-ai/","items":[]},{"title":"Semantic Inferencing","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/semantic-inferencing/","items":[]},{"title":"Web of Things (IoT+LD)","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/web-of-things-iotld/","items":[]}]},{"title":"References","url":"/old-work-archives/2018-webizen-net-au/about/references/","items":[{"title":"Making the distinction between privacy and dignity.","url":"/old-work-archives/2018-webizen-net-au/about/references/privacy-vs-dignity/","items":[]},{"title":"Roles &#8211; Entity Analysis","url":"/old-work-archives/2018-webizen-net-au/about/references/roles-entity-analysis/","items":[]},{"title":"Social Informatics Design Considerations","url":"/old-work-archives/2018-webizen-net-au/about/references/social-informatics-design-concept-and-principles/","items":[]},{"title":"Socio-economic relations | A conceptual model","url":"/old-work-archives/2018-webizen-net-au/about/references/socioeconomic-relations-p1/","items":[]},{"title":"The need for decentralised Open (Linked) Data","url":"/old-work-archives/2018-webizen-net-au/about/references/the-need-for-decentralised-open-linked-data/","items":[]}]},{"title":"The design of new medium","url":"/old-work-archives/2018-webizen-net-au/about/the-design-of-new-medium/","items":[]},{"title":"The need to modernise socioeconomic infrastructure","url":"/old-work-archives/2018-webizen-net-au/about/the-modernisation-of-socioeconomics/","items":[]},{"title":"The Vision","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/","items":[{"title":"Domesticating Pervasive Surveillance","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/a-technical-vision/","items":[]}]}]},{"title":"An Overview","url":"/old-work-archives/2018-webizen-net-au/the-human-centric-infosphere/","items":[]},{"title":"Resource Library","url":"/old-work-archives/2018-webizen-net-au/resource-library/","items":[{"title":"awesomeLists","url":"","items":[{"title":"Awesome Computer Vision: Awesome","url":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-computer-vision/","items":[]},{"title":"Awesome Natural Language Generation Awesome","url":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awsome-nl-gen/","items":[]},{"title":"Awesome Semantic Web Awesome","url":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-semweb/","items":[]},{"title":"Awesome-General","url":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-general/","items":[]}]},{"title":"Handong1587","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/","items":[{"title":"_Posts","url":"","items":[{"title":"Computer_science","url":"","items":[{"title":"Algorithm and Data Structure Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-algo-resourses/","items":[]},{"title":"Artificial Intelligence Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-ai-resources/","items":[]},{"title":"Big Data Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-09-22-big-data-resources/","items":[]},{"title":"Computer Science Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-cs-resources/","items":[]},{"title":"Data Mining Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-data-mining-resources/","items":[]},{"title":"Data Science Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-data-science-resources/","items":[]},{"title":"Database Systems Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-database-resources/","items":[]},{"title":"Discrete Optimization Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-discrete-optimization/","items":[]},{"title":"Distribued System Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-12-12-ditributed-system-resources/","items":[]},{"title":"Funny Stuffs Of Computer Science","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-11-18-funny-stuffs-of-cs/","items":[]},{"title":"Robotics","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-09-26-robotics-resources/","items":[]},{"title":"Writting CS Papers","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-11-30-writing-papers/","items":[]}]},{"title":"Computer_vision","url":"","items":[{"title":"Computer Vision Datasets","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-24-datasets/","items":[]},{"title":"Computer Vision Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-12-cv-resources/","items":[]},{"title":"Features","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-10-09-features/","items":[]},{"title":"Recognition, Detection, Segmentation and Tracking","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-10-09-recognition-detection-segmentation-tracking/","items":[]},{"title":"Use FFmpeg to Capture I Frames of Video","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2016-03-03-ffmpeg-i-frame/","items":[]},{"title":"Working on OpenCV","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-12-25-working-on-opencv/","items":[]}]},{"title":"Deep_learning","url":"","items":[{"title":"3D","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2021-07-28-3d/","items":[]},{"title":"Acceleration and Model Compression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-cnn-compression-acceleration/","items":[]},{"title":"Acceleration and Model Compression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-knowledge-distillation/","items":[]},{"title":"Adversarial Attacks and Defences","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-adversarial-attacks-and-defences/","items":[]},{"title":"Audio / Image / Video Generation","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-audio-image-video-generation/","items":[]},{"title":"BEV","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2022-06-27-bev/","items":[]},{"title":"Classification / Recognition","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recognition/","items":[]},{"title":"Deep Learning and Autonomous Driving","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-autonomous-driving/","items":[]},{"title":"Deep Learning Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-pose-estimation/","items":[]},{"title":"Deep Learning Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-applications/","items":[]},{"title":"Deep learning Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-courses/","items":[]},{"title":"Deep Learning Frameworks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-frameworks/","items":[]},{"title":"Deep Learning Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-resources/","items":[]},{"title":"Deep Learning Software and Hardware","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-software-hardware/","items":[]},{"title":"Deep Learning Tricks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tricks/","items":[]},{"title":"Deep Learning Tutorials","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tutorials/","items":[]},{"title":"Deep Learning with Machine Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-with-ml/","items":[]},{"title":"Face Recognition","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-face-recognition/","items":[]},{"title":"Fun With Deep Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-fun-with-deep-learning/","items":[]},{"title":"Generative Adversarial Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gan/","items":[]},{"title":"Graph Convolutional Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gcn/","items":[]},{"title":"Image / Video Captioning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-captioning/","items":[]},{"title":"Image Retrieval","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-retrieval/","items":[]},{"title":"Keep Up With New Trends","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2018-09-03-keep-up-with-new-trends/","items":[]},{"title":"LiDAR 3D Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-lidar-3d-detection/","items":[]},{"title":"Natural Language Processing","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nlp/","items":[]},{"title":"Neural Architecture Search","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nas/","items":[]},{"title":"Object Counting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-counting/","items":[]},{"title":"Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-detection/","items":[]},{"title":"OCR","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-ocr/","items":[]},{"title":"Optical Flow","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-optical-flow/","items":[]},{"title":"Re-ID","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-re-id/","items":[]},{"title":"Recommendation System","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recommendation-system/","items":[]},{"title":"Reinforcement Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rl/","items":[]},{"title":"RNN and LSTM","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rnn-and-lstm/","items":[]},{"title":"Segmentation","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-segmentation/","items":[]},{"title":"Style Transfer","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-style-transfer/","items":[]},{"title":"Super-Resolution","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-super-resolution/","items":[]},{"title":"Tracking","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-tracking/","items":[]},{"title":"Training Deep Neural Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-training-dnn/","items":[]},{"title":"Transfer Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-transfer-learning/","items":[]},{"title":"Unsupervised Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-unsupervised-learning/","items":[]},{"title":"Video Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-video-applications/","items":[]},{"title":"Visual Question Answering","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-vqa/","items":[]},{"title":"Visualizing and Interpreting Convolutional Neural Network","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-visulizing-interpreting-cnn/","items":[]}]},{"title":"Leisure","url":"","items":[{"title":"All About Enya","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-all-about-enya/","items":[]},{"title":"Coldplay","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-coldplay/","items":[]},{"title":"Coldplay","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-nightwish/","items":[]},{"title":"Games","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-13-games/","items":[]},{"title":"Green Day","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-greenday/","items":[]},{"title":"Muse! Muse!","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-muse-muse/","items":[]},{"title":"Oasis","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-oasis/","items":[]},{"title":"Paintings By J.M.","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2016-03-08-paintings-by-jm/","items":[]},{"title":"Papers, Blogs and Websites","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-09-27-papers-blogs-and-websites/","items":[]},{"title":"Welcome To The Black Parade","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-welcome-to-the-black-parade/","items":[]}]},{"title":"Machine_learning","url":"","items":[{"title":"Bayesian Methods","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-bayesian-methods/","items":[]},{"title":"Clustering Algorithms Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-clustering/","items":[]},{"title":"Competitions","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-competitions/","items":[]},{"title":"Dimensionality Reduction Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-dimensionality-reduction/","items":[]},{"title":"Fun With Machine Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-fun-with-ml/","items":[]},{"title":"Graphical Models Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-graphical-models/","items":[]},{"title":"Machine Learning Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-ml-courses/","items":[]},{"title":"Machine Learning Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-ml-resources/","items":[]},{"title":"Natural Language Processing","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-nlp/","items":[]},{"title":"Neural Network","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-neural-network/","items":[]},{"title":"Random Field","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-random-field/","items":[]},{"title":"Random Forests","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-random-forests/","items":[]},{"title":"Regression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-regression/","items":[]},{"title":"Support Vector Machine","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-svm/","items":[]},{"title":"Topic Model","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-topic-model/","items":[]}]},{"title":"Mathematics","url":"","items":[{"title":"Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/mathematics/2016-02-24-resources/","items":[]}]},{"title":"Programming_study","url":"","items":[{"title":"Add Lunr Search Plugin For Blog","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-31-add-lunr-search-plugin-for-blog/","items":[]},{"title":"Android Development Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-05-23-android-resources/","items":[]},{"title":"C++ Programming Solutions","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-09-07-cpp-programming-solutions/","items":[]},{"title":"Commands To Suppress Some Building Errors With Visual Studio","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-24-cmds-to-suppress-some-vs-building-Errors/","items":[]},{"title":"Embedding Python In C/C++","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-10-embedding-python-in-cpp/","items":[]},{"title":"Enable Large Addresses On VS2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-12-14-enable-large-addresses/","items":[]},{"title":"Fix min/max Error In VS2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-02-17-min-max-error-in-vs2015/","items":[]},{"title":"Gflags Build Problems on Windows X86 and Visual Studio 2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-23-gflags-build-problems-winx86-vs2015/","items":[]},{"title":"Glog Build Problems on Windows X86 and Visual Studio 2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-23-glog-build-problems-winx86/","items":[]},{"title":"Horrible Wired Errors Come From Simple Stupid Mistake","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-16-horrible-wired-errors-come-from-simple-stupid-mistake/","items":[]},{"title":"Install Jekyll To Fix Some Local Github-pages Defects","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-11-21-install-jekyll/","items":[]},{"title":"Install Therubyracer Failure","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-03-install-therubyracer/","items":[]},{"title":"Notes On Valgrind and Others","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-05-30-notes-on-valgrind/","items":[]},{"title":"PHP Hello World","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-04-php-hello-world/","items":[]},{"title":"Programming Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-07-01-programming-resources/","items":[]},{"title":"PyInstsaller and Others","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-12-24-pyinstaller-and-others/","items":[]},{"title":"Web Development Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-06-21-web-dev-resources/","items":[]},{"title":"Working on Visual Studio","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-04-03-working-on-vs/","items":[]}]},{"title":"Reading_and_thoughts","url":"","items":[{"title":"Book Reading List","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2015-12-04-book-reading-list/","items":[]},{"title":"Funny Papers","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2015-12-04-funny-papers/","items":[]},{"title":"Reading Materials","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2016-01-18-reading-materials/","items":[]}]},{"title":"Study","url":"","items":[{"title":"Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2017-11-28-courses/","items":[]},{"title":"Essay Writting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2016-01-11-essay-writting/","items":[]},{"title":"Job Hunting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2016-06-02-job-hunting/","items":[]},{"title":"Study Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2018-04-18-resources/","items":[]}]},{"title":"Working_on_linux","url":"","items":[{"title":"Create Multiple Forks of a GitHub Repo","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-12-18-create-multi-forks/","items":[]},{"title":"Linux Git Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-08-02-linux-git/","items":[]},{"title":"Linux Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-07-24-linux-resources/","items":[]},{"title":"Linux SVN Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-08-03-linux-svn/","items":[]},{"title":"Setup vsftpd on Ubuntu 14.10","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2016-07-27-setup-vsftpd/","items":[]},{"title":"Useful Linux Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-07-25-useful-linux-commands/","items":[]},{"title":"vsftpd Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2016-07-28-vsftpd-cmd/","items":[]}]},{"title":"Working_on_mac","url":"","items":[{"title":"Mac Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_mac/2015-07-25-mac-resources/","items":[]}]},{"title":"Working_on_windows","url":"","items":[{"title":"FFmpeg Collection of Utility Methods","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2016-06-05-ffmpeg-utilities/","items":[]},{"title":"Windows Commands and Utilities","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2015-10-27-windows-cmds-utils/","items":[]},{"title":"Windows Dev Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2015-10-27-resources/","items":[]}]}]},{"title":"Drafts","url":"","items":[{"title":"2016-12-30-Setup-Opengrok","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-12-30-setup-opengrok/","items":[]},{"title":"2017-01-20-Packing-C++-Project-to-Single-Executable","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2017-01-20-packing-c++-project-to-single-executable/","items":[]},{"title":"Notes On Caffe Development","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-10-notes-on-caffe-dev/","items":[]},{"title":"Notes On Deep Learning Training","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-12-notes-on-dl-training/","items":[]},{"title":"Notes On Discrete Optimization","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-13-notes-on-discrete-optimization/","items":[]},{"title":"Notes On Gecode","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-13-notes-on-gecode/","items":[]},{"title":"Notes On Inside-Outside Net","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-28-notes-on-ion/","items":[]},{"title":"Notes On K-Means","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-06-notes-on-kmeans/","items":[]},{"title":"Notes On L-BFGS","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-07-notes-on-l-bfgs/","items":[]},{"title":"Notes On Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-04-notes-on-object-detection/","items":[]},{"title":"Notes On Perceptrons","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-10-07-notes-on-perceptrons/","items":[]},{"title":"Notes On Quantized Convolutional Neural Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-07-notes-on-quantized-cnn/","items":[]},{"title":"Notes On Stanford CS2321n","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-02-21-notes-on-cs231n/","items":[]},{"title":"Notes on Suffix Array and Manacher Algorithm","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-08-27-notes-on-suffix-array-and-manacher-algorithm/","items":[]},{"title":"Notes On Tensorflow Development","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2017-04-13-notes-on-tensorflow-dev/","items":[]},{"title":"Notes On YOLO","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-14-notes-on-yolo/","items":[]},{"title":"PASCAL VOC (20) / COCO (80) / ImageNet (200) Detection Categories","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-12-23-imagenet-det-cat/","items":[]},{"title":"Softmax Vs Logistic Vs Sigmoid","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-10-softmax-logistic-sigmoid/","items":[]},{"title":"Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognititon","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-08-31-model-ensemble-of-deteciton/","items":[]}]}]}]}]}]},{"title":"Webizen 2.0","url":"","items":[{"title":"AI Capabilities","url":"","items":[{"title":"AI Capabilities Objectives","url":"/Webizen 2.0/AI Capabilities/AI Capabilities Objectives/","items":[]},{"title":"Audio & Video Analysis","url":"/Webizen 2.0/AI Capabilities/Audio & Video Analysis/","items":[]},{"title":"Image Analysis","url":"/Webizen 2.0/AI Capabilities/Image Analysis/","items":[]},{"title":"Text Analysis","url":"/Webizen 2.0/AI Capabilities/Text Analysis/","items":[]}]},{"title":"LOD-a-lot","url":"/Webizen 2.0/AI Related Links & Notes/","items":[]},{"title":"Mobile Apps","url":"","items":[{"title":"Android","url":"/Webizen 2.0/Mobile Apps/Android/","items":[]},{"title":"General Mobile Architecture","url":"/Webizen 2.0/Mobile Apps/General Mobile Architecture/","items":[]},{"title":"iOS","url":"/Webizen 2.0/Mobile Apps/iOS/","items":[]}]},{"title":"Web Of Things (IoT)","url":"","items":[{"title":"Web Of Things (IoT)","url":"/Webizen 2.0/Web Of Things (IoT)/Web Of Things (IoT)/","items":[]}]},{"title":"Webizen 2.0","url":"/Webizen 2.0/Webizen 2.0/","items":[]},{"title":"Webizen AI OS Platform","url":"/Webizen 2.0/Webizen AI OS Platform/","items":[]},{"title":"Webizen Pro Summary","url":"/Webizen 2.0/Webizen Pro Summary/","items":[]}]},{"title":"Webizen V1 Project Documentation","url":"/","items":[]}]}],"tagsGroups":[],"latestPosts":[{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/","title":"Knowledge Banking: A Technical Architecture Summary","lastUpdatedAt":"2022-12-28T20:36:06.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/the-human-centric-infosphere/","title":"An Overview","lastUpdatedAt":"2022-12-28T20:26:34.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/the-design-of-new-medium/","title":"The design of new medium","lastUpdatedAt":"2022-12-28T20:26:34.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/the-modernisation-of-socioeconomics/","title":"The need to modernise socioeconomic infrastructure","lastUpdatedAt":"2022-12-28T20:26:34.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/the-vision/","title":"The Vision","lastUpdatedAt":"2022-12-28T20:26:34.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awsome-nl-gen/","title":"Awesome Natural Language Generation Awesome","lastUpdatedAt":"2022-12-28T20:06:33.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-computer-vision/","title":"Awesome Computer Vision: Awesome","lastUpdatedAt":"2022-12-28T20:06:17.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/","title":"Handong1587","lastUpdatedAt":"2022-12-28T20:06:17.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-general/","title":"Awesome-General","lastUpdatedAt":"2022-12-28T20:06:17.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-semweb/","title":"Awesome Semantic Web Awesome","lastUpdatedAt":"2022-12-28T20:06:17.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}