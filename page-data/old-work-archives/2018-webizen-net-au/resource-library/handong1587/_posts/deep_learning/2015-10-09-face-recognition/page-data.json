{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-face-recognition/",
    "result": {"data":{"mdx":{"id":"f14db79c-0715-59fd-bd79-50e2e68661e4","tableOfContents":{"items":[{"url":"#papers","title":"Papers","items":[{"url":"#facenet","title":"FaceNet"}]},{"url":"#face-verification","title":"Face Verification"},{"url":"#facial-attributes-classification","title":"Facial Attributes Classification"},{"url":"#video-face-recognition","title":"Video Face Recognition"},{"url":"#facial-point--landmark-detection","title":"Facial Point / Landmark Detection"},{"url":"#face-synthesis","title":"Face Synthesis"},{"url":"#projects","title":"Projects","items":[{"url":"#openface","title":"OpenFace"}]},{"url":"#resources","title":"Resources"}]},"fields":{"title":"Face Recognition","slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-face-recognition/","url":"https://devdocs.webizen.org/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-face-recognition/","editUrl":"https://github.com/webizenai/devdocs/tree/main/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-face-recognition.md","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022","gitCreatedAt":"2022-12-28T19:22:29.000Z","shouldShowTitle":true},"frontmatter":{"title":"Face Recognition","description":null,"imageAlt":null,"tags":[],"date":"2015-10-09T00:00:00.000Z","dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"layout\": \"post\",\n  \"category\": \"deep_learning\",\n  \"title\": \"Face Recognition\",\n  \"date\": \"2015-10-09T00:00:00.000Z\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"papers\"\n  }, \"Papers\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning Face Representation from Predicting 10,000 Classes\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2014. DeepID\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mmlab.ie.cuhk.edu.hk/pdf/YiSun_CVPR14.pdf\"\n  }, \"http://mmlab.ie.cuhk.edu.hk/pdf/YiSun_CVPR14.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/stdcoutzyx/DeepID_FaceClassify\"\n  }, \"https://github.com/stdcoutzyx/DeepID_FaceClassify\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"\\u57FA\\u4E8ECaffe\\u7684DeepID2\\u5B9E\\u73B0\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"ol\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.miaoerduo.com/deep-learning/%E5%9F%BA%E4%BA%8Ecaffe%E7%9A%84deepid2%E5%AE%9E%E7%8E%B0%EF%BC%88%E4%B8%8A%EF%BC%89.html\"\n  }, \"http://www.miaoerduo.com/deep-learning/%E5%9F%BA%E4%BA%8Ecaffe%E7%9A%84deepid2%E5%AE%9E%E7%8E%B0%EF%BC%88%E4%B8%8A%EF%BC%89.html\")))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"ol\", {\n    parentName: \"li\",\n    \"start\": 2\n  }, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.miaoerduo.com/deep-learning/%E5%9F%BA%E4%BA%8Ecaffe%E7%9A%84deepid2%E5%AE%9E%E7%8E%B0%EF%BC%88%E4%B8%AD%EF%BC%89.html\"\n  }, \"http://www.miaoerduo.com/deep-learning/%E5%9F%BA%E4%BA%8Ecaffe%E7%9A%84deepid2%E5%AE%9E%E7%8E%B0%EF%BC%88%E4%B8%AD%EF%BC%89.html\")))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"ol\", {\n    parentName: \"li\",\n    \"start\": 3\n  }, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.miaoerduo.com/deep-learning/%E5%9F%BA%E4%BA%8Ecaffe%E7%9A%84deepid2%E5%AE%9E%E7%8E%B0%EF%BC%88%E4%B8%8B%EF%BC%89.html\"\n  }, \"http://www.miaoerduo.com/deep-learning/%E5%9F%BA%E4%BA%8Ecaffe%E7%9A%84deepid2%E5%AE%9E%E7%8E%B0%EF%BC%88%E4%B8%8B%EF%BC%89.html\"))))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deeply learned face representations are sparse, selective, and robust\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: DeepID2+\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1412.1265\"\n  }, \"http://arxiv.org/abs/1412.1265\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"video: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://research.microsoft.com/apps/video/?id=260023\"\n  }, \"http://research.microsoft.com/apps/video/?id=260023\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"mirror: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://pan.baidu.com/s/1boufl3x\"\n  }, \"http://pan.baidu.com/s/1boufl3x\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MobileID: Face Model Compression by Distilling Knowledge from Neurons\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2016 Oral. CUHK\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MobileID is an extremely fast face recognition system by distilling knowledge from DeepID2\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://personal.ie.cuhk.edu.hk/~lz013/projects/MobileID.html\"\n  }, \"http://personal.ie.cuhk.edu.hk/~lz013/projects/MobileID.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://personal.ie.cuhk.edu.hk/~pluo/pdf/aaai16-face-model-compression.pdf\"\n  }, \"http://personal.ie.cuhk.edu.hk/~pluo/pdf/aaai16-face-model-compression.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/liuziwei7/mobile-id\"\n  }, \"https://github.com/liuziwei7/mobile-id\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf\"\n  }, \"http://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.robots.ox.ac.uk/~vgg/software/vgg_face/\"\n  }, \"http://www.robots.ox.ac.uk/~vgg/software/vgg_face/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Keras): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/rcmalli/keras-vggface\"\n  }, \"https://github.com/rcmalli/keras-vggface\"))), mdx(\"h2\", {\n    \"id\": \"facenet\"\n  }, \"FaceNet\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FaceNet: A Unified Embedding for Face Recognition and Clustering\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Inc. CVPR 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1503.03832\"\n  }, \"http://arxiv.org/abs/1503.03832\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Tensorflow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/davidsandberg/facenet\"\n  }, \"https://github.com/davidsandberg/facenet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Caffe): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hizhangp/triplet\"\n  }, \"https://github.com/hizhangp/triplet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Real time face detection and recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Real time face detection and recognition base on opencv/tensorflow/mtcnn/facenet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/shanren7/real_time_face_recognition\"\n  }, \"https://github.com/shanren7/real_time_face_recognition\"))), mdx(\"hr\", null), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1506.07310\"\n  }, \"http://arxiv.org/abs/1506.07310\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Robust Deep Face Representation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1507.04844\"\n  }, \"https://arxiv.org/abs/1507.04844\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Light CNN for Deep Face Representation with Noisy Labels\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1511.02683\"\n  }, \"https://arxiv.org/abs/1511.02683\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/AlfredXiangWu/face_verification_experiment\"\n  }, \"https://github.com/AlfredXiangWu/face_verification_experiment\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pose-Aware Face Recognition in the Wild\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Masi_Pose-Aware_Face_Recognition_CVPR_2016_paper.pdf/\"\n  }, \"www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Masi_Pose-Aware_Face_Recognition_CVPR_2016_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Recurrent Regression for Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1607.06999\"\n  }, \"http://arxiv.org/abs/1607.06999\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Discriminative Feature Learning Approach for Deep Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: center loss\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://ydwen.github.io/papers/WenECCV16.pdf\"\n  }, \"http://ydwen.github.io/papers/WenECCV16.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ydwen/caffe-face\"\n  }, \"https://github.com/ydwen/caffe-face\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/pangyupo/mxnet_center_loss\"\n  }, \"https://github.com/pangyupo/mxnet_center_loss\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Face Recognition with Center Invariant Loss\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM MM Workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www1.ece.neu.edu/~yuewu/files/2017/twu024.pdf\"\n  }, \"http://www1.ece.neu.edu/~yuewu/files/2017/twu024.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"How Image Degradations Affect Deep CNN-based Face Recognition?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.05246\"\n  }, \"http://arxiv.org/abs/1608.05246\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"VIPLFaceNet: An Open Source Deep Face Recognition SDK\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: VIPLFaceNet / SeetaFace Engine\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.03892\"\n  }, \"http://arxiv.org/abs/1609.03892\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SeetaFace Engine\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SeetaFace Engine is an open source C++ face recognition engine, which can run on CPU with no third-party dependence.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/seetaface/SeetaFaceEngine\"\n  }, \"https://github.com/seetaface/SeetaFaceEngine\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Discriminative Feature Learning Approach for Deep Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://ydwen.github.io/papers/WenECCV16.pdf\"\n  }, \"http://ydwen.github.io/papers/WenECCV16.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sparsifying Neural Network Connections for Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.ee.cuhk.edu.hk/~xgwang/papers/sunWTcvpr16.pdf\"\n  }, \"http://www.ee.cuhk.edu.hk/~xgwang/papers/sunWTcvpr16.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Range Loss for Deep Face Recognition with Long-tail\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.08976\"\n  }, \"https://arxiv.org/abs/1611.08976\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards End-to-End Face Recognition through Alignment Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tsinghua University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.07174\"\n  }, \"https://arxiv.org/abs/1701.07174\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Task Convolutional Neural Network for Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.04710\"\n  }, \"https://arxiv.org/abs/1702.04710\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SphereFace: Deep Hypersphere Embedding for Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://wyliu.com/papers/LiuCVPR17.pdf\"\n  }, \"http://wyliu.com/papers/LiuCVPR17.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/wy1iu/sphereface\"\n  }, \"https://github.com/wy1iu/sphereface\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://v-wb.youku.com/v_show/id_XMjk3NTc1NjMxMg==.html\"\n  }, \"http://v-wb.youku.com/v_show/id_XMjk3NTc1NjMxMg==.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning towards Minimum Hyperspherical Energy\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: SphereFace+\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.09298\"\n  }, \"https://arxiv.org/abs/1805.09298\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/wy1iu/sphereface-plus\"\n  }, \"https://github.com/wy1iu/sphereface-plus\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Low Resolution Face Recognition Using a Two-Branch Deep Convolutional Neural Network Architecture\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Amirkabir University of Technology & MIT\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.06247\"\n  }, \"https://arxiv.org/abs/1706.06247\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Enhancing Convolutional Neural Networks for Face Recognition with Occlusion Maps and Batch Triplet Loss\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1707.07923\"\n  }, \"https://arxiv.org/abs/1707.07923\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improving Heterogeneous Face Recognition with Conditional Adversarial Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.02848\"\n  }, \"https://arxiv.org/abs/1709.02848\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Face Sketch Matching via Coupled Deep Transform Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1710.02914\"\n  }, \"https://arxiv.org/abs/1710.02914\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Face Recognition via Centralized Coordinate Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: centralized coordinate learning (CCL)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.05678\"\n  }, \"https://arxiv.org/abs/1801.05678\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ArcFace: Additive Angular Margin Loss for Deep Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.07698\"\n  }, \"https://arxiv.org/abs/1801.07698\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/deepinsight/insightface\"\n  }, \"https://github.com/deepinsight/insightface\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CosFace: Large Margin Cosine Loss for Deep Face Recognition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1801.09414\"\n  }, \"https://arxiv.org/abs/1801.09414\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Ring loss: Convex Feature Normalization for Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.00130\"\n  }, \"https://arxiv.org/abs/1803.00130\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pose-Robust Face Recognition via Deep Residual Equivariant Mapping\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018. CUHK & SenseTime Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.00839\"\n  }, \"https://arxiv.org/abs/1803.00839\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/penincillin/DREAM\"\n  }, \"https://github.com/penincillin/DREAM\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Face Recognition: A Survey\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BUPT\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.06655\"\n  }, \"https://arxiv.org/abs/1804.06655\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Surveillance Face Recognition Challenge\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1804.09691\"\n  }, \"https://arxiv.org/abs/1804.09691\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards Interpretable Face Recognition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.00611\"\n  }, \"https://arxiv.org/abs/1805.00611\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scalable Angular Discriminative Deep Metric Learning for Face Recognition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1804.10899\"\n  }, \"https://arxiv.org/abs/1804.10899\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Minimum Margin Loss for Deep Face Recognition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.06741\"\n  }, \"https://arxiv.org/abs/1805.06741\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Wildest Faces: Face Detection and Recognition in Violent Settings\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.07566\"\n  }, \"https://arxiv.org/abs/1805.07566\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Imbalanced Learning for Face Recognition and Attribute Prediction\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1806.00194\"\n  }, \"https://arxiv.org/abs/1806.00194\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Accurate and Efficient Similarity Search for Large Scale Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BUPT\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1806.00365\"\n  }, \"https://arxiv.org/abs/1806.00365\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Face Recognition in Low Quality Images: A Survey\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.11519\"\n  }, \"https://arxiv.org/abs/1805.11519\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Low Resolution Face Recognition in the Wild\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.11529\"\n  }, \"https://arxiv.org/abs/1805.11529\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"From Face Recognition to Models of Identity: A Bayesian Approach to Learning about Unknown Identities from Unsupervised Data\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.07872\"\n  }, \"https://arxiv.org/abs/1807.07872\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Git Loss for Deep Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.08512\"\n  }, \"https://arxiv.org/abs/1807.08512\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multicolumn Networks for Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.09192\"\n  }, \"https://arxiv.org/abs/1807.09192\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Devil of Face Recognition is in the Noise\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.11649\"\n  }, \"https://arxiv.org/abs/1807.11649\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_ECCV_2018/papers/Liren_Chen_The_Devil_of_ECCV_2018_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_ECCV_2018/papers/Liren_Chen_The_Devil_of_ECCV_2018_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"dataset: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/fwang91/IMDb-Face\"\n  }, \"https://github.com/fwang91/IMDb-Face\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Sketch-Photo Face Recognition Assisted by Facial Attributes\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1808.00059%E4%B8%A4\"\n  }, \"https://arxiv.org/abs/1808.00059\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Global Norm-Aware Pooling for Pose-Robust Face Recognition at Low False Positive Rate\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1808.00435\"\n  }, \"https://arxiv.org/abs/1808.00435\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pairwise Relational Networks for Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.04976\"\n  }, \"https://arxiv.org/abs/1808.04976\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Orthogonal Deep Features Decomposition for Age-Invariant Face Recognition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1810.07599\"\n  }, \"https://arxiv.org/abs/1810.07599\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pairwise Relational Networks using Local Appearance Features for Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2018 R2L workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.06405\"\n  }, \"https://arxiv.org/abs/1811.06405\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Low-resolution Face Recognition in the Wild via Selective Knowledge Distillation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.09998\"\n  }, \"https://arxiv.org/abs/1811.09998\")), mdx(\"p\", null, \"L\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ow-Resolution Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.08965\"\n  }, \"https://arxiv.org/abs/1811.08965\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"dataset: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://qmul-tinyface.github.io/\"\n  }, \"https://qmul-tinyface.github.io/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MobiFace: A Lightweight Deep Learning Face Recognition on Mobile Devices\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.11080\"\n  }, \"https://arxiv.org/abs/1811.11080\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attacks on State-of-the-Art Face Recognition using Attentional Adversarial Attack Generative Network\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.12026\"\n  }, \"https://arxiv.org/abs/1811.12026\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Support Vector Guided Softmax Loss for Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: JD AI research & Chinese Academy of Science\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1812.11317\"\n  }, \"https://arxiv.org/abs/1812.11317\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Linkage Based Face Clustering via Graph Convolution Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.11306\"\n  }, \"https://arxiv.org/abs/1903.11306\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning for Face Recognition: Pride or Prejudiced?\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1904.01219\"\n  }, \"https://arxiv.org/abs/1904.01219\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Efficient Decision-based Black-box Adversarial Attacks on Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.04433\"\n  }, \"https://arxiv.org/abs/1904.04433\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Decorrelated Adversarial Learning for Age-Invariant Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tencent AI Lab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.04972\"\n  }, \"https://arxiv.org/abs/1904.04972\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ShrinkTeaNet: Million-scale Lightweight Face Recognition via Shrinking Teacher-Student Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1905.10620\"\n  }, \"https://arxiv.org/abs/1905.10620\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attentional Feature-Pair Relation Networks for Accurate Face Recognition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1908.06255\"\n  }, \"https://arxiv.org/abs/1908.06255\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Occlusion Robust Face Recognition Based on Mask Learning with PairwiseDifferential Siamese Network\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1908.06290\"\n  }, \"https://arxiv.org/abs/1908.06290\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards Flops-constrained Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019 LFR workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.00632\"\n  }, \"https://arxiv.org/abs/1909.00632\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"VarGFaceNet: An Efficient Variable Group Convolutional Neural Network for Lightweight Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV workshop 2019, champion of deepglintlight track of LFR (2019) challenge\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Horizon Robotics\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1910.04985\"\n  }, \"https://arxiv.org/abs/1910.04985\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_ICCVW_2019/papers/LSR/Yan_VarGFaceNet_An_Efficient_Variable_Group_Convolutional_Neural_Network_for_Lightweight_ICCVW_2019_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_ICCVW_2019/papers/LSR/Yan_VarGFaceNet_An_Efficient_Variable_Group_Convolutional_Neural_Network_for_Lightweight_ICCVW_2019_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zma-c-137/VarGFaceNet\"\n  }, \"https://github.com/zma-c-137/VarGFaceNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards Flops-constrained Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019 LFR workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: 1st place in the ICCV19 Lightweight Face Recognition Challenge, large video track\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Trojans\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.00632\"\n  }, \"https://arxiv.org/abs/1909.00632\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/sciencefans/trojans-face-recognizer\"\n  }, \"https://github.com/sciencefans/trojans-face-recognizer\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unknown Identity Rejection Loss: Utilizing Unlabeled Data for Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019 Lightweight Face Recognition Challenge & Workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1910.10896\"\n  }, \"https://arxiv.org/abs/1910.10896\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FAN: Feature Adaptation Network for Surveillance Face Recognition and Normalization\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Michigan State University & Youtu Lab, Tencent & Microsoft Cloud and AI & Zhejiang University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1911.11680\"\n  }, \"https://arxiv.org/abs/1911.11680\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mis-classified Vector Guided Softmax Loss for Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2019 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1912.00833\"\n  }, \"https://arxiv.org/abs/1912.00833\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Domain Balancing: Face Recognition on Long-Tailed Domains\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Chinese Academy of Sciences & Tianjin University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.13791\"\n  }, \"https://arxiv.org/abs/2003.13791\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CurricularFace: Adaptive Curriculum Learning Loss for Deep Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Youtu Lab, Tencent & Zhejiang University & Michigan State University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arixv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2004.00288\"\n  }, \"https://arxiv.org/abs/2004.00288\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/HuangYG123/CurricularFace\"\n  }, \"https://github.com/HuangYG123/CurricularFace\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Loss Function Search for Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICML 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.06542\"\n  }, \"https://arxiv.org/abs/2007.06542\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Explainable Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://stresearch.github.io/xfr/\"\n  }, \"https://stresearch.github.io/xfr/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2008.00916\"\n  }, \"https://arxiv.org/abs/2008.00916\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/stresearch/xfr\"\n  }, \"https://github.com/stresearch/xfr\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BroadFace: Looking at Tens of Thousands of People at Once for Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2008.06674\"\n  }, \"https://arxiv.org/abs/2008.06674\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Searching for Alignment in Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2102.05447\"\n  }, \"https://arxiv.org/abs/2102.05447\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"When Age-Invariant Face Recognition Meets Face Age Synthesis: A Multi-Task Learning Framework\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Fudan University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.01520\"\n  }, \"https://arxiv.org/abs/2103.01520\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Hzzone/MTLFace\"\n  }, \"https://github.com/Hzzone/MTLFace\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unmasking Face Embeddings by Self-restrained Triplet Loss for Accurate Masked Face Recognition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2103.01716\"\n  }, \"https://arxiv.org/abs/2103.01716\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"WebFace260M: A Benchmark Unveiling the Power of Million-Scale Deep Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tsinghua University & XForwardAI & Imperial College London\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.face-benchmark.org/\"\n  }, \"https://www.face-benchmark.org/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.04098\"\n  }, \"https://arxiv.org/abs/2103.04098\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Face Transformer for Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Beijing University of Posts and Telecommunications\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.14803\"\n  }, \"https://arxiv.org/abs/2103.14803\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MagFace: A Universal Representation for Face Recognition and Quality Assessment\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Algorithm Research, Aibee Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.06627\"\n  }, \"https://arxiv.org/abs/2103.06627\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/IrvingMeng/MagFace\"\n  }, \"https://github.com/IrvingMeng/MagFace\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dynamic Class Queue for Large Scale Face Recognition In the Wild\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2105.11113\"\n  }, \"https://arxiv.org/abs/2105.11113\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bilylee/DCQ\"\n  }, \"https://github.com/bilylee/DCQ\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End2End Occluded Face Recognition by Masking Corrupted Features\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: TPAMI 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2108.09468\"\n  }, \"https://arxiv.org/abs/2108.09468\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AdaFace: Quality Adaptive Margin for Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2204.00964\"\n  }, \"https://arxiv.org/abs/2204.00964\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mk-minchul/AdaFace\"\n  }, \"https://github.com/mk-minchul/AdaFace\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CoupleFace: Relation Matters for Face Recognition Distillation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Beihang University & SenseTime Group Limited & The University of Sydney\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2204.05502\"\n  }, \"https://arxiv.org/abs/2204.05502\"))), mdx(\"h1\", {\n    \"id\": \"face-verification\"\n  }, \"Face Verification\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning Face Representation by Joint Identification-Verification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: DeepID2\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://papers.nips.cc/paper/5416-analog-memories-in-a-balanced-rate-based-network-of-e-i-neurons\"\n  }, \"http://papers.nips.cc/paper/5416-analog-memories-in-a-balanced-rate-based-network-of-e-i-neurons\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepFace: Closing the Gap to Human-Level Performance in Face Verification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2014. Facebook AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf\"\n  }, \"https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://valse.mmcheng.net/ftp/20141126/MingYang.pdf\"\n  }, \"http://valse.mmcheng.net/ftp/20141126/MingYang.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/RiweiChen/DeepFace\"\n  }, \"https://github.com/RiweiChen/DeepFace\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Triplet Probabilistic Embedding for Face Verification and Clustering\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Oral Paper in BTAS 2016; NVIDIA Best paper Award\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1604.05417\"\n  }, \"https://arxiv.org/abs/1604.05417\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Keras): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/meownoid/face-identification-tpe\"\n  }, \"https://github.com/meownoid/face-identification-tpe\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeMeshNet: Blind Face Inpainting for Deep MeshFace Verification\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1611.05271\"\n  }, \"https://arxiv.org/abs/1611.05271\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hybrid Deep Learning for Face Verification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: TPAMI 2016. CNN+RBM\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.ee.cuhk.edu.hk/~xgwang/papers/sunWTpami16.pdf\"\n  }, \"http://www.ee.cuhk.edu.hk/~xgwang/papers/sunWTpami16.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"NormFace: L2 Hypersphere Embedding for Face Verification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.06369\"\n  }, \"https://arxiv.org/abs/1704.06369\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/happynear/NormFace\"\n  }, \"https://github.com/happynear/NormFace\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"L2-constrained Softmax Loss for Discriminative Face Verification\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1703.09507\"\n  }, \"https://arxiv.org/abs/1703.09507\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"von Mises-Fisher Mixture Model-based Deep learning: Application to Face Verification\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1706.04264\"\n  }, \"https://arxiv.org/abs/1706.04264\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Model Distillation with Knowledge Transfer in Face Classification, Alignment and Verification\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.02929\"\n  }, \"https://arxiv.org/abs/1709.02929\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Additive Margin Softmax for Face Verification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: additive margin Softmax (AM-Softmax),\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.05599\"\n  }, \"https://arxiv.org/abs/1801.05599\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/happynear/AMSoftmax\"\n  }, \"https://github.com/happynear/AMSoftmax\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MobileFaceNets: Efficient CNNs for Accurate Real-time Face Verification on Mobile Devices\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Beijing Jiaotong University & Watchdata Inc\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.07573\"\n  }, \"https://arxiv.org/abs/1804.07573\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DisguiseNet : A Contrastive Approach for Disguised Face Verification in the Wild\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1804.09669\"\n  }, \"https://arxiv.org/abs/1804.09669\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An Experimental Evaluation of Covariates Effects on Unconstrained Face Verification\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1808.05508\"\n  }, \"https://arxiv.org/abs/1808.05508\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Verification of Very Low-Resolution Faces Using An Identity-Preserving Deep Face Super-Resolution Network\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1903.10974\"\n  }, \"https://arxiv.org/abs/1903.10974\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"xCos: An Explainable Cosine Metric for Face Verification Task\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2003.05383\"\n  }, \"https://arxiv.org/abs/2003.05383\")), mdx(\"h1\", {\n    \"id\": \"facial-attributes-classification\"\n  }, \"Facial Attributes Classification\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Jointly Learned Deep Architecture for Facial Attribute Analysis and Face Detection in the Wild\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1707.08705\"\n  }, \"https://arxiv.org/abs/1707.08705\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Deep Cascade Network for Unaligned Face Attribute Classification\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.03851\"\n  }, \"https://arxiv.org/abs/1709.03851\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Deep Face Identification Network Enhanced by Facial Attributes Prediction\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.00324\"\n  }, \"https://arxiv.org/abs/1805.00324\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-task Learning of Cascaded CNN for Facial Attribute Classification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Xiamen University & Xiamen University of Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.01290\"\n  }, \"https://arxiv.org/abs/1805.01290\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-label Learning Based Deep Transfer Neural Network for Facial Attribute Classification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Xiamen University & Xiamen University of Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.01282\"\n  }, \"https://arxiv.org/abs/1805.01282\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Survey to Deep Facial Attribute Analysis\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1812.10265\"\n  }, \"https://arxiv.org/abs/1812.10265\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Registration-free Face-SSD: Single shot analysis of smiles, facial attributes, and affect in the wild\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Elsevier CVIU 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1902.04042\"\n  }, \"https://arxiv.org/abs/1902.04042\"))), mdx(\"h1\", {\n    \"id\": \"video-face-recognition\"\n  }, \"Video Face Recognition\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Neural Aggregation Network for Video Face Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Neural Aggregation Network (NAN)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1603.05474\"\n  }, \"https://arxiv.org/abs/1603.05474\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attention-Set based Metric Learning for Video Face Recognition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1704.03805\"\n  }, \"https://arxiv.org/abs/1704.03805\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SeqFace: Make full use of sequence information for face recognitio\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.06524\"\n  }, \"https://arxiv.org/abs/1803.06524\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/huangyangyu/SeqFace\"\n  }, \"https://github.com/huangyangyu/SeqFace\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video Face Recognition: Component-wise Feature Aggregation Network (C-FAN)\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Michigan State University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1902.07327\"\n  }, \"https://arxiv.org/abs/1902.07327\"))), mdx(\"h1\", {\n    \"id\": \"facial-point--landmark-detection\"\n  }, \"Facial Point / Landmark Detection\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Convolutional Network Cascade for Facial Point Detection\")), mdx(\"img\", {\n    \"src\": \"http://mmlab.ie.cuhk.edu.hk/archive/CNN/data/Picture1.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mmlab.ie.cuhk.edu.hk/archive/CNN_FacePoint.htm\"\n  }, \"http://mmlab.ie.cuhk.edu.hk/archive/CNN_FacePoint.htm\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.ee.cuhk.edu.hk/~xgwang/papers/sunWTcvpr13.pdf\"\n  }, \"http://www.ee.cuhk.edu.hk/~xgwang/papers/sunWTcvpr13.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/luoyetx/deep-landmark\"\n  }, \"https://github.com/luoyetx/deep-landmark\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Facial Landmark Detection by Deep Multi-task Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2014\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mmlab.ie.cuhk.edu.hk/projects/TCDCN.html\"\n  }, \"http://mmlab.ie.cuhk.edu.hk/projects/TCDCN.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://personal.ie.cuhk.edu.hk/~ccloy/files/eccv_2014_deepfacealign.pdf\"\n  }, \"http://personal.ie.cuhk.edu.hk/~ccloy/files/eccv_2014_deepfacealign.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Matlab): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zhzhanp/TCDCN-face-alignment\"\n  }, \"https://github.com/zhzhanp/TCDCN-face-alignment\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Recurrent Encoder-Decoder Network for Sequential Face Alignment\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://sites.google.com/site/xipengcshomepage/eccv2016\"\n  }, \"https://sites.google.com/site/xipengcshomepage/eccv2016\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1608.05477\"\n  }, \"https://arxiv.org/abs/1608.05477\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://drive.google.com/file/d/0B-FLp_bljv_1OTVrMF9OM21IbW8/view\"\n  }, \"https://drive.google.com/file/d/0B-FLp_bljv_1OTVrMF9OM21IbW8/view\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xipeng13/recurrent-face-alignment\"\n  }, \"https://github.com/xipeng13/recurrent-face-alignment\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RED-Net: A Recurrent Encoder-Decoder Network for Video-based Face Alignment\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IJCV\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.06066\"\n  }, \"https://arxiv.org/abs/1801.06066\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Detecting facial landmarks in the video based on a hybrid framework\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.06441\"\n  }, \"http://arxiv.org/abs/1609.06441\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Constrained Local Models for Facial Landmark Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.08657\"\n  }, \"https://arxiv.org/abs/1611.08657\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Effective face landmark localization via single deep network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.02719\"\n  }, \"https://arxiv.org/abs/1702.02719\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Convolution Tree with Deconvolution Branches: Exploiting Geometric Relationships for Single Shot Keypoint Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1704.01880\"\n  }, \"https://arxiv.org/abs/1704.01880\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Alignment Network: A convolutional neural network for robust face alignment\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPRW 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.01789\"\n  }, \"https://arxiv.org/abs/1706.01789\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gihtub: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MarekKowalski/DeepAlignmentNetwork\"\n  }, \"https://github.com/MarekKowalski/DeepAlignmentNetwork\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Joint Multi-view Face Alignment in the Wild\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1708.06023\"\n  }, \"https://arxiv.org/abs/1708.06023\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FacePoseNet: Making a Case for Landmark-Free Face Alignment\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1708.07517\"\n  }, \"https://arxiv.org/abs/1708.07517\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Wing Loss for Robust Facial Landmark Localisation with Convolutional Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.06753\"\n  }, \"https://arxiv.org/abs/1711.06753\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Brute-Force Facial Landmark Analysis With A 140,000-Way Classifier\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1802.01777\"\n  }, \"https://arxiv.org/abs/1802.01777\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mtli/BFFL\"\n  }, \"https://github.com/mtli/BFFL\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Style Aggregated Network for Facial Landmark Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.04108\"\n  }, \"https://arxiv.org/abs/1803.04108\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/D-X-Y/SAN\"\n  }, \"https://github.com/D-X-Y/SAN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Adaptive Attention for Joint Facial Action Unit Detection and Face Alignment\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.05588\"\n  }, \"https://arxiv.org/abs/1803.05588\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Supervision-by-Registration: An Unsupervised Approach to Improve the Precision of Facial Landmark Detectors\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Minor modifications to the CVPR 2018 version (add missing references)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.00966\"\n  }, \"https://arxiv.org/abs/1807.00966\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Multi-Center Learning for Face Alignment\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.01558\"\n  }, \"https://arxiv.org/abs/1808.01558\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ZhiwenShao/MCNet-Extension\"\n  }, \"https://github.com/ZhiwenShao/MCNet-Extension\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hierarchical binary CNNs for landmark localization with limited resources\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: TPAMI 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.04803\"\n  }, \"https://arxiv.org/abs/1808.04803\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards Highly Accurate and Stable Face Alignment for High-Resolution Videos\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.00342\"\n  }, \"https://arxiv.org/abs/1811.00342\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tyshiwo/FHR_alignment\"\n  }, \"https://github.com/tyshiwo/FHR_alignment\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Stacked Dense U-Nets with Dual Transformers for Robust Face Alignment\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1812.01936\"\n  }, \"https://arxiv.org/abs/1812.01936\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PFLD: A Practical Facial Landmark Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1902.10859\"\n  }, \"https://arxiv.org/abs/1902.10859\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/guoqiangqi/PFLD\"\n  }, \"https://github.com/guoqiangqi/PFLD\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Alignment: Finding Semantically Consistent Ground-truth for Facial Landmark Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.10661\"\n  }, \"https://arxiv.org/abs/1903.10661\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An Efficient Multitask Neural Network for Face Alignment, Head Pose Estimation and Face Tracking\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Technology Sydney\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.07615\"\n  }, \"https://arxiv.org/abs/2103.07615\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"HIH: Towards More Accurate Face Alignment via Heatmap in Heatmap\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2104.03100\"\n  }, \"https://arxiv.org/abs/2104.03100\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Subpixel Heatmap Regression for Facial Landmark Localization\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Samsung AI Center, Cambridge, UK & Queen Mary University London\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.adrianbulat.com/face-alignment\"\n  }, \"https://www.adrianbulat.com/face-alignment\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2111.02360\"\n  }, \"https://arxiv.org/abs/2111.02360\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/1adrianb/face-alignment\"\n  }, \"https://github.com/1adrianb/face-alignment\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RePFormer: Refinement Pyramid Transformer for Robust Facial Landmark Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The Chinese University of Hong Kong & The Hong Kong University of Science and Technology & IIAI & Terminus Group & Chinese Academy of Sciences\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2207.03917\"\n  }, \"https://arxiv.org/abs/2207.03917\"))), mdx(\"h1\", {\n    \"id\": \"face-synthesis\"\n  }, \"Face Synthesis\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Beyond Face Rotation: Global and Local Perception GAN for Photorealistic and Identity Preserving Frontal View Synthesis\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: TP-GAN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.04086\"\n  }, \"https://arxiv.org/abs/1704.04086\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_ICCV_2017/papers/Huang_Beyond_Face_Rotation_ICCV_2017_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_ICCV_2017/papers/Huang_Beyond_Face_Rotation_ICCV_2017_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, Tensorflow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/HRLTY/TP-GAN\"\n  }, \"https://github.com/HRLTY/TP-GAN\"))), mdx(\"h1\", {\n    \"id\": \"projects\"\n  }, \"Projects\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Using MXNet for Face-related Algorithm\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tornadomeet/mxnet-face\"\n  }, \"https://github.com/tornadomeet/mxnet-face\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"clmtrackr: Javascript library for precise tracking of facial features via Constrained Local Models\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/auduno/clmtrackr\"\n  }, \"https://github.com/auduno/clmtrackr\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://auduno.com/post/61888277175/fitting-faces\"\n  }, \"http://auduno.com/post/61888277175/fitting-faces\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://auduno.github.io/clmtrackr/examples/facesubstitution.html\"\n  }, \"http://auduno.github.io/clmtrackr/examples/facesubstitution.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://auduno.github.io/clmtrackr/face_deformation_video.html\"\n  }, \"http://auduno.github.io/clmtrackr/face_deformation_video.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://auduno.github.io/clmtrackr/examples/clm_emotiondetection.html\"\n  }, \"http://auduno.github.io/clmtrackr/examples/clm_emotiondetection.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://auduno.com/post/84214587523/twisting-faces\"\n  }, \"http://auduno.com/post/84214587523/twisting-faces\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepLogo\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: A brand logo recognition system using deep convolutional neural networks.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/satojkovic/DeepLogo\"\n  }, \"https://github.com/satojkovic/DeepLogo\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep-Leafsnap\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: LeafSnap replicated using deep neural networks to test accuracy compared to traditional computer vision methods.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/sujithv28/Deep-Leafsnap\"\n  }, \"https://github.com/sujithv28/Deep-Leafsnap\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FaceVerification: An Experimental Implementation of Face Verification, 96.8% on LFW\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/happynear/FaceVerification\"\n  }, \"https://github.com/happynear/FaceVerification\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"InsightFace\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Face Recognition Project on MXnet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com//deepinsight/insightface\"\n  }, \"https://github.com//deepinsight/insightface\"))), mdx(\"h2\", {\n    \"id\": \"openface\"\n  }, \"OpenFace\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"OpenFace: Face Recognition with Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cmusatyalab.github.io/openface/\"\n  }, \"http://cmusatyalab.github.io/openface/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/cmusatyalab/openface\"\n  }, \"https://github.com/cmusatyalab/openface\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aybassiouny/OpenFaceCpp\"\n  }, \"https://github.com/aybassiouny/OpenFaceCpp\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"OpenFace 0.2.0: Higher accuracy and halved execution time\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://bamos.github.io/2016/01/19/openface-0.2.0/\"\n  }, \"http://bamos.github.io/2016/01/19/openface-0.2.0/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"OpenFace: A general-purpose face recognition library with mobile applications\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://reports-archive.adm.cs.cmu.edu/anon/anon/usr0/ftp/2016/CMU-CS-16-118.pdf\"\n  }, \"http://reports-archive.adm.cs.cmu.edu/anon/anon/usr0/ftp/2016/CMU-CS-16-118.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"OpenFace: an open source facial behavior analysis toolkit\")), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/TadasBaltrusaitis/OpenFace/master/imgs/multi_face_img.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: a state-of-the art open source tool intended for facial landmark detection, head pose estimation,\\nfacial action unit recognition, and eye-gaze estimation.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/TadasBaltrusaitis/OpenFace\"\n  }, \"https://github.com/TadasBaltrusaitis/OpenFace\"))), mdx(\"h1\", {\n    \"id\": \"resources\"\n  }, \"Resources\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Face-Resources\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/betars/Face-Resources\"\n  }, \"https://github.com/betars/Face-Resources\"))));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"---\nlayout: post\ncategory: deep_learning\ntitle: Face Recognition\ndate: 2015-10-09\n---\n\n# Papers\n\n**Deep Learning Face Representation from Predicting 10,000 Classes**\n\n- intro: CVPR 2014. DeepID\n- paper: [http://mmlab.ie.cuhk.edu.hk/pdf/YiSun_CVPR14.pdf](http://mmlab.ie.cuhk.edu.hk/pdf/YiSun_CVPR14.pdf)\n- github: [https://github.com/stdcoutzyx/DeepID_FaceClassify](https://github.com/stdcoutzyx/DeepID_FaceClassify)\n\n**CaffeDeepID2**\n\n- 1. [http://www.miaoerduo.com/deep-learning/%E5%9F%BA%E4%BA%8Ecaffe%E7%9A%84deepid2%E5%AE%9E%E7%8E%B0%EF%BC%88%E4%B8%8A%EF%BC%89.html](http://www.miaoerduo.com/deep-learning/%E5%9F%BA%E4%BA%8Ecaffe%E7%9A%84deepid2%E5%AE%9E%E7%8E%B0%EF%BC%88%E4%B8%8A%EF%BC%89.html)\n- 2. [http://www.miaoerduo.com/deep-learning/%E5%9F%BA%E4%BA%8Ecaffe%E7%9A%84deepid2%E5%AE%9E%E7%8E%B0%EF%BC%88%E4%B8%AD%EF%BC%89.html](http://www.miaoerduo.com/deep-learning/%E5%9F%BA%E4%BA%8Ecaffe%E7%9A%84deepid2%E5%AE%9E%E7%8E%B0%EF%BC%88%E4%B8%AD%EF%BC%89.html)\n- 3. [http://www.miaoerduo.com/deep-learning/%E5%9F%BA%E4%BA%8Ecaffe%E7%9A%84deepid2%E5%AE%9E%E7%8E%B0%EF%BC%88%E4%B8%8B%EF%BC%89.html](http://www.miaoerduo.com/deep-learning/%E5%9F%BA%E4%BA%8Ecaffe%E7%9A%84deepid2%E5%AE%9E%E7%8E%B0%EF%BC%88%E4%B8%8B%EF%BC%89.html)\n\n**Deeply learned face representations are sparse, selective, and robust**\n\n- intro: DeepID2+\n- arxiv: [http://arxiv.org/abs/1412.1265](http://arxiv.org/abs/1412.1265)\n- video: [http://research.microsoft.com/apps/video/?id=260023](http://research.microsoft.com/apps/video/?id=260023)\n- mirror: [http://pan.baidu.com/s/1boufl3x](http://pan.baidu.com/s/1boufl3x)\n\n**MobileID: Face Model Compression by Distilling Knowledge from Neurons**\n\n- intro: AAAI 2016 Oral. CUHK\n- intro: MobileID is an extremely fast face recognition system by distilling knowledge from DeepID2\n- project page: [http://personal.ie.cuhk.edu.hk/~lz013/projects/MobileID.html](http://personal.ie.cuhk.edu.hk/~lz013/projects/MobileID.html)\n- paper: [http://personal.ie.cuhk.edu.hk/~pluo/pdf/aaai16-face-model-compression.pdf](http://personal.ie.cuhk.edu.hk/~pluo/pdf/aaai16-face-model-compression.pdf)\n- github: [https://github.com/liuziwei7/mobile-id](https://github.com/liuziwei7/mobile-id)\n\n**Deep Face Recognition**\n\n- intro: BMVC 2015\n- paper: [http://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf](http://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf)\n- homepage: [http://www.robots.ox.ac.uk/~vgg/software/vgg_face/](http://www.robots.ox.ac.uk/~vgg/software/vgg_face/)\n- github(Keras): [https://github.com/rcmalli/keras-vggface](https://github.com/rcmalli/keras-vggface)\n\n## FaceNet\n\n**FaceNet: A Unified Embedding for Face Recognition and Clustering**\n\n- intro: Google Inc. CVPR 2015\n- arxiv: [http://arxiv.org/abs/1503.03832](http://arxiv.org/abs/1503.03832)\n- github(Tensorflow): [https://github.com/davidsandberg/facenet](https://github.com/davidsandberg/facenet)\n- github(Caffe): [https://github.com/hizhangp/triplet](https://github.com/hizhangp/triplet)\n\n**Real time face detection and recognition**\n\n- intro: Real time face detection and recognition base on opencv/tensorflow/mtcnn/facenet\n- github: [https://github.com/shanren7/real_time_face_recognition](https://github.com/shanren7/real_time_face_recognition)\n\n- - -\n\n**Targeting Ultimate Accuracy: Face Recognition via Deep Embedding**\n\n- intro: CVPR 2015\n- arxiv: [http://arxiv.org/abs/1506.07310](http://arxiv.org/abs/1506.07310)\n\n**Learning Robust Deep Face Representation**\n\n- arxiv: [https://arxiv.org/abs/1507.04844](https://arxiv.org/abs/1507.04844)\n\n**A Light CNN for Deep Face Representation with Noisy Labels**\n\n- arxiv: [https://arxiv.org/abs/1511.02683](https://arxiv.org/abs/1511.02683)\n- github: [https://github.com/AlfredXiangWu/face_verification_experiment](https://github.com/AlfredXiangWu/face_verification_experiment)\n\n**Pose-Aware Face Recognition in the Wild**\n\n- paper: [www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Masi_Pose-Aware_Face_Recognition_CVPR_2016_paper.pdf](www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Masi_Pose-Aware_Face_Recognition_CVPR_2016_paper.pdf)\n\n**Recurrent Regression for Face Recognition**\n\n- arxiv: [http://arxiv.org/abs/1607.06999](http://arxiv.org/abs/1607.06999)\n\n**A Discriminative Feature Learning Approach for Deep Face Recognition**\n\n- intro: ECCV 2016\n- intro: center loss\n- paper: [http://ydwen.github.io/papers/WenECCV16.pdf](http://ydwen.github.io/papers/WenECCV16.pdf)\n- github: [https://github.com/ydwen/caffe-face](https://github.com/ydwen/caffe-face)\n- github: [https://github.com/pangyupo/mxnet_center_loss](https://github.com/pangyupo/mxnet_center_loss)\n\n**Deep Face Recognition with Center Invariant Loss**\n\n- intro: ACM MM Workshop\n- paper: [http://www1.ece.neu.edu/~yuewu/files/2017/twu024.pdf](http://www1.ece.neu.edu/~yuewu/files/2017/twu024.pdf)\n\n**How Image Degradations Affect Deep CNN-based Face Recognition?**\n\n- arxiv: [http://arxiv.org/abs/1608.05246](http://arxiv.org/abs/1608.05246)\n\n**VIPLFaceNet: An Open Source Deep Face Recognition SDK**\n\n- keywords: VIPLFaceNet / SeetaFace Engine\n- arxiv: [http://arxiv.org/abs/1609.03892](http://arxiv.org/abs/1609.03892)\n\n**SeetaFace Engine**\n\n- intro: SeetaFace Engine is an open source C++ face recognition engine, which can run on CPU with no third-party dependence.\n- github: [https://github.com/seetaface/SeetaFaceEngine](https://github.com/seetaface/SeetaFaceEngine)\n\n**A Discriminative Feature Learning Approach for Deep Face Recognition**\n\n- intro: ECCV 2016\n- paper: [http://ydwen.github.io/papers/WenECCV16.pdf](http://ydwen.github.io/papers/WenECCV16.pdf)\n\n**Sparsifying Neural Network Connections for Face Recognition**\n\n- paper: [http://www.ee.cuhk.edu.hk/~xgwang/papers/sunWTcvpr16.pdf](http://www.ee.cuhk.edu.hk/~xgwang/papers/sunWTcvpr16.pdf)\n\n**Range Loss for Deep Face Recognition with Long-tail**\n\n- arxiv: [https://arxiv.org/abs/1611.08976](https://arxiv.org/abs/1611.08976)\n\n**Towards End-to-End Face Recognition through Alignment Learning**\n\n- intro: Tsinghua University\n- arxiv: [https://arxiv.org/abs/1701.07174](https://arxiv.org/abs/1701.07174)\n\n**Multi-Task Convolutional Neural Network for Face Recognition**\n\n- arxiv: [https://arxiv.org/abs/1702.04710](https://arxiv.org/abs/1702.04710)\n\n**SphereFace: Deep Hypersphere Embedding for Face Recognition**\n\n- intro: CVPR 2017\n- arxiv: [http://wyliu.com/papers/LiuCVPR17.pdf](http://wyliu.com/papers/LiuCVPR17.pdf)\n- github: [https://github.com/wy1iu/sphereface](https://github.com/wy1iu/sphereface)\n- demo: [http://v-wb.youku.com/v_show/id_XMjk3NTc1NjMxMg==.html](http://v-wb.youku.com/v_show/id_XMjk3NTc1NjMxMg==.html)\n\n**Learning towards Minimum Hyperspherical Energy**\n\n- intro: NeurIPS 2018\n- keywords: SphereFace+\n- arxiv: [https://arxiv.org/abs/1805.09298](https://arxiv.org/abs/1805.09298)\n- github: [https://github.com/wy1iu/sphereface-plus](https://github.com/wy1iu/sphereface-plus)\n\n**Low Resolution Face Recognition Using a Two-Branch Deep Convolutional Neural Network Architecture**\n\n- intro: Amirkabir University of Technology & MIT\n- arxiv: [https://arxiv.org/abs/1706.06247](https://arxiv.org/abs/1706.06247)\n\n**Enhancing Convolutional Neural Networks for Face Recognition with Occlusion Maps and Batch Triplet Loss**\n\n[https://arxiv.org/abs/1707.07923](https://arxiv.org/abs/1707.07923)\n\n**Improving Heterogeneous Face Recognition with Conditional Adversarial Networks**\n\n[https://arxiv.org/abs/1709.02848](https://arxiv.org/abs/1709.02848)\n\n**Face Sketch Matching via Coupled Deep Transform Learning**\n\n- intro: ICCV 2017\n- arxiv: [https://arxiv.org/abs/1710.02914](https://arxiv.org/abs/1710.02914)\n\n**Face Recognition via Centralized Coordinate Learning**\n\n- intro: centralized coordinate learning (CCL)\n- arxiv: [https://arxiv.org/abs/1801.05678](https://arxiv.org/abs/1801.05678)\n\n**ArcFace: Additive Angular Margin Loss for Deep Face Recognition**\n\n- arxiv: [https://arxiv.org/abs/1801.07698](https://arxiv.org/abs/1801.07698)\n- github: [https://github.com/deepinsight/insightface](https://github.com/deepinsight/insightface)\n\n**CosFace: Large Margin Cosine Loss for Deep Face Recognition**\n\n[https://arxiv.org/abs/1801.09414](https://arxiv.org/abs/1801.09414)\n\n**Ring loss: Convex Feature Normalization for Face Recognition**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1803.00130](https://arxiv.org/abs/1803.00130)\n\n**Pose-Robust Face Recognition via Deep Residual Equivariant Mapping**\n\n- intro: CVPR 2018. CUHK & SenseTime Research\n- arxiv: [https://arxiv.org/abs/1803.00839](https://arxiv.org/abs/1803.00839)\n- github: [https://github.com/penincillin/DREAM](https://github.com/penincillin/DREAM)\n\n**Deep Face Recognition: A Survey**\n\n- intro: BUPT\n- arxiv: [https://arxiv.org/abs/1804.06655](https://arxiv.org/abs/1804.06655)\n\n**Surveillance Face Recognition Challenge**\n\n[https://arxiv.org/abs/1804.09691](https://arxiv.org/abs/1804.09691)\n\n**Towards Interpretable Face Recognition**\n\n[https://arxiv.org/abs/1805.00611](https://arxiv.org/abs/1805.00611)\n\n**Scalable Angular Discriminative Deep Metric Learning for Face Recognition**\n\n[https://arxiv.org/abs/1804.10899](https://arxiv.org/abs/1804.10899)\n\n**Minimum Margin Loss for Deep Face Recognition**\n\n[https://arxiv.org/abs/1805.06741](https://arxiv.org/abs/1805.06741)\n\n**Wildest Faces: Face Detection and Recognition in Violent Settings**\n\n[https://arxiv.org/abs/1805.07566](https://arxiv.org/abs/1805.07566)\n\n**Deep Imbalanced Learning for Face Recognition and Attribute Prediction**\n\n[https://arxiv.org/abs/1806.00194](https://arxiv.org/abs/1806.00194)\n\n**Accurate and Efficient Similarity Search for Large Scale Face Recognition**\n\n- intro: BUPT\n- arxiv: [https://arxiv.org/abs/1806.00365](https://arxiv.org/abs/1806.00365)\n\n**Face Recognition in Low Quality Images: A Survey**\n\n[https://arxiv.org/abs/1805.11519](https://arxiv.org/abs/1805.11519)\n\n**Low Resolution Face Recognition in the Wild**\n\n[https://arxiv.org/abs/1805.11529](https://arxiv.org/abs/1805.11529)\n\n**From Face Recognition to Models of Identity: A Bayesian Approach to Learning about Unknown Identities from Unsupervised Data**\n\n- intro: ECCV 2018\n- arxiv: [https://arxiv.org/abs/1807.07872](https://arxiv.org/abs/1807.07872)\n\n**Git Loss for Deep Face Recognition**\n\n- intro: BMVC 2018\n- arxiv: [https://arxiv.org/abs/1807.08512](https://arxiv.org/abs/1807.08512)\n\n**Multicolumn Networks for Face Recognition**\n\n- intro: BMVC 2018\n- arxiv: [https://arxiv.org/abs/1807.09192](https://arxiv.org/abs/1807.09192)\n\n**The Devil of Face Recognition is in the Noise**\n\n- intro: ECCV 2018\n- arxiv: [https://arxiv.org/abs/1807.11649](https://arxiv.org/abs/1807.11649)\n- paper: [http://openaccess.thecvf.com/content_ECCV_2018/papers/Liren_Chen_The_Devil_of_ECCV_2018_paper.pdf](http://openaccess.thecvf.com/content_ECCV_2018/papers/Liren_Chen_The_Devil_of_ECCV_2018_paper.pdf)\n- dataset: [https://github.com/fwang91/IMDb-Face](https://github.com/fwang91/IMDb-Face)\n\n**Deep Sketch-Photo Face Recognition Assisted by Facial Attributes**\n\n[https://arxiv.org/abs/1808.00059](https://arxiv.org/abs/1808.00059)\n\n**Global Norm-Aware Pooling for Pose-Robust Face Recognition at Low False Positive Rate**\n\n[https://arxiv.org/abs/1808.00435](https://arxiv.org/abs/1808.00435)\n\n**Pairwise Relational Networks for Face Recognition**\n\n- intro: ECCV 2018\n- arxiv: [https://arxiv.org/abs/1808.04976](https://arxiv.org/abs/1808.04976)\n\n**Orthogonal Deep Features Decomposition for Age-Invariant Face Recognition**\n\n[https://arxiv.org/abs/1810.07599](https://arxiv.org/abs/1810.07599)\n\n**Pairwise Relational Networks using Local Appearance Features for Face Recognition**\n\n- intro: NIPS 2018 R2L workshop\n- arxiv: [https://arxiv.org/abs/1811.06405](https://arxiv.org/abs/1811.06405)\n\n**Low-resolution Face Recognition in the Wild via Selective Knowledge Distillation**\n\n[https://arxiv.org/abs/1811.09998](https://arxiv.org/abs/1811.09998)\n\nL**ow-Resolution Face Recognition**\n\n- arxiv: [https://arxiv.org/abs/1811.08965](https://arxiv.org/abs/1811.08965)\n- dataset: [https://qmul-tinyface.github.io/](https://qmul-tinyface.github.io/)\n\n**MobiFace: A Lightweight Deep Learning Face Recognition on Mobile Devices**\n\n[https://arxiv.org/abs/1811.11080](https://arxiv.org/abs/1811.11080)\n\n**Attacks on State-of-the-Art Face Recognition using Attentional Adversarial Attack Generative Network**\n\n[https://arxiv.org/abs/1811.12026](https://arxiv.org/abs/1811.12026)\n\n**Support Vector Guided Softmax Loss for Face Recognition**\n\n- intro: JD AI research & Chinese Academy of Science\n- arxiv: [https://arxiv.org/abs/1812.11317](https://arxiv.org/abs/1812.11317)\n\n**Linkage Based Face Clustering via Graph Convolution Network**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1903.11306](https://arxiv.org/abs/1903.11306)\n\n**Deep Learning for Face Recognition: Pride or Prejudiced?**\n\n[https://arxiv.org/abs/1904.01219](https://arxiv.org/abs/1904.01219)\n\n**Efficient Decision-based Black-box Adversarial Attacks on Face Recognition**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1904.04433](https://arxiv.org/abs/1904.04433)\n\n**Decorrelated Adversarial Learning for Age-Invariant Face Recognition**\n\n- intro: Tencent AI Lab\n- arxiv: [https://arxiv.org/abs/1904.04972](https://arxiv.org/abs/1904.04972)\n\n**ShrinkTeaNet: Million-scale Lightweight Face Recognition via Shrinking Teacher-Student Networks**\n\n[https://arxiv.org/abs/1905.10620](https://arxiv.org/abs/1905.10620)\n\n**Attentional Feature-Pair Relation Networks for Accurate Face Recognition**\n\n[https://arxiv.org/abs/1908.06255](https://arxiv.org/abs/1908.06255)\n\n**Occlusion Robust Face Recognition Based on Mask Learning with PairwiseDifferential Siamese Network**\n\n[https://arxiv.org/abs/1908.06290](https://arxiv.org/abs/1908.06290)\n\n**Towards Flops-constrained Face Recognition**\n\n- intro: ICCV 2019 LFR workshop\n- arxiv: [https://arxiv.org/abs/1909.00632](https://arxiv.org/abs/1909.00632)\n\n**VarGFaceNet: An Efficient Variable Group Convolutional Neural Network for Lightweight Face Recognition**\n\n- intro: ICCV workshop 2019, champion of deepglintlight track of LFR (2019) challenge\n- intro: Horizon Robotics\n- arxiv: [https://arxiv.org/abs/1910.04985](https://arxiv.org/abs/1910.04985)\n- paper: [http://openaccess.thecvf.com/content_ICCVW_2019/papers/LSR/Yan_VarGFaceNet_An_Efficient_Variable_Group_Convolutional_Neural_Network_for_Lightweight_ICCVW_2019_paper.pdf](http://openaccess.thecvf.com/content_ICCVW_2019/papers/LSR/Yan_VarGFaceNet_An_Efficient_Variable_Group_Convolutional_Neural_Network_for_Lightweight_ICCVW_2019_paper.pdf)\n- github: [https://github.com/zma-c-137/VarGFaceNet](https://github.com/zma-c-137/VarGFaceNet)\n\n**Towards Flops-constrained Face Recognition**\n\n- intro: ICCV 2019 LFR workshop\n- intro: 1st place in the ICCV19 Lightweight Face Recognition Challenge, large video track\n- keywords: Trojans\n- arxiv: [https://arxiv.org/abs/1909.00632](https://arxiv.org/abs/1909.00632)\n- paper: [https://github.com/sciencefans/trojans-face-recognizer](https://github.com/sciencefans/trojans-face-recognizer)\n\n**Unknown Identity Rejection Loss: Utilizing Unlabeled Data for Face Recognition**\n\n- intro: ICCV 2019 Lightweight Face Recognition Challenge & Workshop\n- arxiv: [https://arxiv.org/abs/1910.10896](https://arxiv.org/abs/1910.10896)\n\n**FAN: Feature Adaptation Network for Surveillance Face Recognition and Normalization**\n\n- intro: Michigan State University & Youtu Lab, Tencent & Microsoft Cloud and AI & Zhejiang University\n- arxiv: [https://arxiv.org/abs/1911.11680](https://arxiv.org/abs/1911.11680)\n\n**Mis-classified Vector Guided Softmax Loss for Face Recognition**\n\n- intro: AAAI 2019 oral\n- arxiv: [https://arxiv.org/abs/1912.00833](https://arxiv.org/abs/1912.00833)\n\n**Domain Balancing: Face Recognition on Long-Tailed Domains**\n\n- intro: CVPR 2020\n- intro: Chinese Academy of Sciences & Tianjin University\n- arxiv: [https://arxiv.org/abs/2003.13791](https://arxiv.org/abs/2003.13791)\n\n**CurricularFace: Adaptive Curriculum Learning Loss for Deep Face Recognition**\n\n- intro: CVPR 2020\n- intro: Youtu Lab, Tencent & Zhejiang University & Michigan State University\n- arixv: [https://arxiv.org/abs/2004.00288](https://arxiv.org/abs/2004.00288)\n- github: [https://github.com/HuangYG123/CurricularFace](https://github.com/HuangYG123/CurricularFace)\n\n**Loss Function Search for Face Recognition**\n\n- intro: ICML 2020\n- arxiv: [https://arxiv.org/abs/2007.06542](https://arxiv.org/abs/2007.06542)\n\n**Explainable Face Recognition**\n\n- intro: ECCV 2020\n- project page: [https://stresearch.github.io/xfr/](https://stresearch.github.io/xfr/)\n- arxiv: [https://arxiv.org/abs/2008.00916](https://arxiv.org/abs/2008.00916)\n- github: [https://github.com/stresearch/xfr](https://github.com/stresearch/xfr)\n\n**BroadFace: Looking at Tens of Thousands of People at Once for Face Recognition**\n\n- intro: ECCV 2020\n- arxiv: [https://arxiv.org/abs/2008.06674](https://arxiv.org/abs/2008.06674)\n\n**Searching for Alignment in Face Recognition**\n\n- intro: AAAI 2021\n- arxiv: [https://arxiv.org/abs/2102.05447](https://arxiv.org/abs/2102.05447)\n\n**When Age-Invariant Face Recognition Meets Face Age Synthesis: A Multi-Task Learning Framework**\n\n- intro: CVPR 2021\n- intro: Fudan University\n- arxiv: [https://arxiv.org/abs/2103.01520](https://arxiv.org/abs/2103.01520)\n- github: [https://github.com/Hzzone/MTLFace](https://github.com/Hzzone/MTLFace)\n\n**Unmasking Face Embeddings by Self-restrained Triplet Loss for Accurate Masked Face Recognition**\n\n[https://arxiv.org/abs/2103.01716](https://arxiv.org/abs/2103.01716)\n\n**WebFace260M: A Benchmark Unveiling the Power of Million-Scale Deep Face Recognition**\n\n- intro: CVPR 2021\n- intro: Tsinghua University & XForwardAI & Imperial College London\n- project page: [https://www.face-benchmark.org/](https://www.face-benchmark.org/)\n- arxiv: [https://arxiv.org/abs/2103.04098](https://arxiv.org/abs/2103.04098)\n\n**Face Transformer for Recognition**\n\n- intro: Beijing University of Posts and Telecommunications\n- arxiv: [https://arxiv.org/abs/2103.14803](https://arxiv.org/abs/2103.14803)\n\n**MagFace: A Universal Representation for Face Recognition and Quality Assessment**\n\n- intro: CVPR 2021 oral\n- intro: Algorithm Research, Aibee Inc.\n- arxiv: [https://arxiv.org/abs/2103.06627](https://arxiv.org/abs/2103.06627)\n- github: [https://github.com/IrvingMeng/MagFace](https://github.com/IrvingMeng/MagFace)\n\n**Dynamic Class Queue for Large Scale Face Recognition In the Wild**\n\n- intro: CVPR 2021\n- arxiv: [https://arxiv.org/abs/2105.11113](https://arxiv.org/abs/2105.11113)\n- github: [https://github.com/bilylee/DCQ](https://github.com/bilylee/DCQ)\n\n**End2End Occluded Face Recognition by Masking Corrupted Features**\n\n- intro: TPAMI 2021\n- arxiv: [https://arxiv.org/abs/2108.09468](https://arxiv.org/abs/2108.09468)\n\n**AdaFace: Quality Adaptive Margin for Face Recognition**\n\n- intro: CVPR 2022 oral\n- arxiv: [https://arxiv.org/abs/2204.00964](https://arxiv.org/abs/2204.00964)\n- github: [https://github.com/mk-minchul/AdaFace](https://github.com/mk-minchul/AdaFace)\n\n**CoupleFace: Relation Matters for Face Recognition Distillation**\n\n- intro: Beihang University & SenseTime Group Limited & The University of Sydney\n- arxiv: [https://arxiv.org/abs/2204.05502](https://arxiv.org/abs/2204.05502)\n\n# Face Verification\n\n**Deep Learning Face Representation by Joint Identification-Verification**\n\n- intro: DeepID2\n- paper: [http://papers.nips.cc/paper/5416-analog-memories-in-a-balanced-rate-based-network-of-e-i-neurons](http://papers.nips.cc/paper/5416-analog-memories-in-a-balanced-rate-based-network-of-e-i-neurons)\n\n**DeepFace: Closing the Gap to Human-Level Performance in Face Verification**\n\n- intro: CVPR 2014. Facebook AI Research\n- paper: [https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf](https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf)\n- slides: [http://valse.mmcheng.net/ftp/20141126/MingYang.pdf](http://valse.mmcheng.net/ftp/20141126/MingYang.pdf)\n- github: [https://github.com/RiweiChen/DeepFace](https://github.com/RiweiChen/DeepFace)\n\n**Triplet Probabilistic Embedding for Face Verification and Clustering**\n\n- intro: Oral Paper in BTAS 2016; NVIDIA Best paper Award\n- arxiv: [https://arxiv.org/abs/1604.05417](https://arxiv.org/abs/1604.05417)\n- github(Keras): [https://github.com/meownoid/face-identification-tpe](https://github.com/meownoid/face-identification-tpe)\n\n**DeMeshNet: Blind Face Inpainting for Deep MeshFace Verification**\n\n[https://arxiv.org/abs/1611.05271](https://arxiv.org/abs/1611.05271)\n\n**Hybrid Deep Learning for Face Verification**\n\n- intro: TPAMI 2016. CNN+RBM\n- paper: [http://www.ee.cuhk.edu.hk/~xgwang/papers/sunWTpami16.pdf](http://www.ee.cuhk.edu.hk/~xgwang/papers/sunWTpami16.pdf)\n\n**NormFace: L2 Hypersphere Embedding for Face Verification**\n\n- arxiv: [https://arxiv.org/abs/1704.06369](https://arxiv.org/abs/1704.06369)\n- github: [https://github.com/happynear/NormFace](https://github.com/happynear/NormFace)\n\n**L2-constrained Softmax Loss for Discriminative Face Verification**\n\n[https://arxiv.org/abs/1703.09507](https://arxiv.org/abs/1703.09507)\n\n**von Mises-Fisher Mixture Model-based Deep learning: Application to Face Verification**\n\n[https://arxiv.org/abs/1706.04264](https://arxiv.org/abs/1706.04264)\n\n**Model Distillation with Knowledge Transfer in Face Classification, Alignment and Verification**\n\n[https://arxiv.org/abs/1709.02929](https://arxiv.org/abs/1709.02929)\n\n**Additive Margin Softmax for Face Verification**\n\n- keywords: additive margin Softmax (AM-Softmax),\n- arxiv: [https://arxiv.org/abs/1801.05599](https://arxiv.org/abs/1801.05599)\n- github: [https://github.com/happynear/AMSoftmax](https://github.com/happynear/AMSoftmax)\n\n**MobileFaceNets: Efficient CNNs for Accurate Real-time Face Verification on Mobile Devices**\n\n- intro: Beijing Jiaotong University & Watchdata Inc\n- arxiv: [https://arxiv.org/abs/1804.07573](https://arxiv.org/abs/1804.07573)\n\n**DisguiseNet : A Contrastive Approach for Disguised Face Verification in the Wild**\n\n[https://arxiv.org/abs/1804.09669](https://arxiv.org/abs/1804.09669)\n\n**An Experimental Evaluation of Covariates Effects on Unconstrained Face Verification**\n\n[https://arxiv.org/abs/1808.05508](https://arxiv.org/abs/1808.05508)\n\n**Verification of Very Low-Resolution Faces Using An Identity-Preserving Deep Face Super-Resolution Network**\n\n[https://arxiv.org/abs/1903.10974](https://arxiv.org/abs/1903.10974)\n\n**xCos: An Explainable Cosine Metric for Face Verification Task**\n\n[https://arxiv.org/abs/2003.05383](https://arxiv.org/abs/2003.05383)\n\n# Facial Attributes Classification\n\n**A Jointly Learned Deep Architecture for Facial Attribute Analysis and Face Detection in the Wild**\n\n[https://arxiv.org/abs/1707.08705](https://arxiv.org/abs/1707.08705)\n\n**A Deep Cascade Network for Unaligned Face Attribute Classification**\n\n[https://arxiv.org/abs/1709.03851](https://arxiv.org/abs/1709.03851)\n\n**A Deep Face Identification Network Enhanced by Facial Attributes Prediction**\n\n[https://arxiv.org/abs/1805.00324](https://arxiv.org/abs/1805.00324)\n\n**Multi-task Learning of Cascaded CNN for Facial Attribute Classification**\n\n- intro: Xiamen University & Xiamen University of Technology\n- arxiv: [https://arxiv.org/abs/1805.01290](https://arxiv.org/abs/1805.01290)\n\n**Multi-label Learning Based Deep Transfer Neural Network for Facial Attribute Classification**\n\n- intro: Xiamen University & Xiamen University of Technology\n- arxiv: [https://arxiv.org/abs/1805.01282](https://arxiv.org/abs/1805.01282)\n\n**A Survey to Deep Facial Attribute Analysis**\n\n[https://arxiv.org/abs/1812.10265](https://arxiv.org/abs/1812.10265)\n\n**Registration-free Face-SSD: Single shot analysis of smiles, facial attributes, and affect in the wild**\n\n- intro: Elsevier CVIU 2019\n- arxiv: [https://arxiv.org/abs/1902.04042](https://arxiv.org/abs/1902.04042)\n\n# Video Face Recognition\n\n**Neural Aggregation Network for Video Face Recognition**\n\n- intro: CVPR 2017\n- keywords: Neural Aggregation Network (NAN)\n- arxiv: [https://arxiv.org/abs/1603.05474](https://arxiv.org/abs/1603.05474)\n\n**Attention-Set based Metric Learning for Video Face Recognition**\n\n[https://arxiv.org/abs/1704.03805](https://arxiv.org/abs/1704.03805)\n\n**SeqFace: Make full use of sequence information for face recognitio**\n\n- arxiv: [https://arxiv.org/abs/1803.06524](https://arxiv.org/abs/1803.06524)\n- github: [https://github.com/huangyangyu/SeqFace](https://github.com/huangyangyu/SeqFace)\n\n**Video Face Recognition: Component-wise Feature Aggregation Network (C-FAN)**\n\n- intro: Michigan State University\n- arxiv: [https://arxiv.org/abs/1902.07327](https://arxiv.org/abs/1902.07327)\n\n# Facial Point / Landmark Detection\n\n**Deep Convolutional Network Cascade for Facial Point Detection**\n\n![](http://mmlab.ie.cuhk.edu.hk/archive/CNN/data/Picture1.png)\n\n- homepage: [http://mmlab.ie.cuhk.edu.hk/archive/CNN_FacePoint.htm](http://mmlab.ie.cuhk.edu.hk/archive/CNN_FacePoint.htm)\n- paper: [http://www.ee.cuhk.edu.hk/~xgwang/papers/sunWTcvpr13.pdf](http://www.ee.cuhk.edu.hk/~xgwang/papers/sunWTcvpr13.pdf)\n- github: [https://github.com/luoyetx/deep-landmark](https://github.com/luoyetx/deep-landmark)\n\n**Facial Landmark Detection by Deep Multi-task Learning**\n\n- intro: ECCV 2014\n- project page: [http://mmlab.ie.cuhk.edu.hk/projects/TCDCN.html](http://mmlab.ie.cuhk.edu.hk/projects/TCDCN.html)\n- paper: [http://personal.ie.cuhk.edu.hk/~ccloy/files/eccv_2014_deepfacealign.pdf](http://personal.ie.cuhk.edu.hk/~ccloy/files/eccv_2014_deepfacealign.pdf)\n- github(Matlab): [https://github.com/zhzhanp/TCDCN-face-alignment](https://github.com/zhzhanp/TCDCN-face-alignment)\n\n**A Recurrent Encoder-Decoder Network for Sequential Face Alignment**\n\n- intro: ECCV 2016 oral\n- project page: [https://sites.google.com/site/xipengcshomepage/eccv2016](https://sites.google.com/site/xipengcshomepage/eccv2016)\n- arxiv: [https://arxiv.org/abs/1608.05477](https://arxiv.org/abs/1608.05477)\n- slides: [https://drive.google.com/file/d/0B-FLp_bljv_1OTVrMF9OM21IbW8/view](https://drive.google.com/file/d/0B-FLp_bljv_1OTVrMF9OM21IbW8/view)\n- github: [https://github.com/xipeng13/recurrent-face-alignment](https://github.com/xipeng13/recurrent-face-alignment)\n\n**RED-Net: A Recurrent Encoder-Decoder Network for Video-based Face Alignment**\n\n- intro: IJCV\n- arxiv: [https://arxiv.org/abs/1801.06066](https://arxiv.org/abs/1801.06066)\n\n**Detecting facial landmarks in the video based on a hybrid framework**\n\n- arxiv: [http://arxiv.org/abs/1609.06441](http://arxiv.org/abs/1609.06441)\n\n**Deep Constrained Local Models for Facial Landmark Detection**\n\n- arxiv: [https://arxiv.org/abs/1611.08657](https://arxiv.org/abs/1611.08657)\n\n**Effective face landmark localization via single deep network**\n\n- arxiv: [https://arxiv.org/abs/1702.02719](https://arxiv.org/abs/1702.02719)\n\n**A Convolution Tree with Deconvolution Branches: Exploiting Geometric Relationships for Single Shot Keypoint Detection**\n\n[https://arxiv.org/abs/1704.01880](https://arxiv.org/abs/1704.01880)\n\n**Deep Alignment Network: A convolutional neural network for robust face alignment**\n\n- intro: CVPRW 2017\n- arxiv: [https://arxiv.org/abs/1706.01789](https://arxiv.org/abs/1706.01789)\n- gihtub: [https://github.com/MarekKowalski/DeepAlignmentNetwork](https://github.com/MarekKowalski/DeepAlignmentNetwork)\n\n**Joint Multi-view Face Alignment in the Wild**\n\n[https://arxiv.org/abs/1708.06023](https://arxiv.org/abs/1708.06023)\n\n**FacePoseNet: Making a Case for Landmark-Free Face Alignment**\n\n[https://arxiv.org/abs/1708.07517](https://arxiv.org/abs/1708.07517)\n\n**Wing Loss for Robust Facial Landmark Localisation with Convolutional Neural Networks**\n\n[https://arxiv.org/abs/1711.06753](https://arxiv.org/abs/1711.06753)\n\n**Brute-Force Facial Landmark Analysis With A 140,000-Way Classifier**\n\n- intro: AAAI 2018\n- arxiv: [https://arxiv.org/abs/1802.01777](https://arxiv.org/abs/1802.01777)\n- github: [https://github.com/mtli/BFFL](https://github.com/mtli/BFFL)\n\n**Style Aggregated Network for Facial Landmark Detection**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1803.04108](https://arxiv.org/abs/1803.04108)\n- github: [https://github.com/D-X-Y/SAN](https://github.com/D-X-Y/SAN)\n\n**Deep Adaptive Attention for Joint Facial Action Unit Detection and Face Alignment**\n\n[https://arxiv.org/abs/1803.05588](https://arxiv.org/abs/1803.05588)\n\n**Supervision-by-Registration: An Unsupervised Approach to Improve the Precision of Facial Landmark Detectors**\n\n- intro: Minor modifications to the CVPR 2018 version (add missing references)\n- arxiv: [https://arxiv.org/abs/1807.00966](https://arxiv.org/abs/1807.00966)\n\n**Deep Multi-Center Learning for Face Alignment**\n\n- arxiv: [https://arxiv.org/abs/1808.01558](https://arxiv.org/abs/1808.01558)\n- github: [https://github.com/ZhiwenShao/MCNet-Extension](https://github.com/ZhiwenShao/MCNet-Extension)\n\n**Hierarchical binary CNNs for landmark localization with limited resources**\n\n- intro: TPAMI 2018\n- arxiv: [https://arxiv.org/abs/1808.04803](https://arxiv.org/abs/1808.04803)\n\n**Towards Highly Accurate and Stable Face Alignment for High-Resolution Videos**\n\n- intro: AAAI 2019\n- arxiv: [https://arxiv.org/abs/1811.00342](https://arxiv.org/abs/1811.00342)\n- github: [https://github.com/tyshiwo/FHR_alignment](https://github.com/tyshiwo/FHR_alignment)\n\n**Stacked Dense U-Nets with Dual Transformers for Robust Face Alignment**\n\n[https://arxiv.org/abs/1812.01936](https://arxiv.org/abs/1812.01936)\n\n**PFLD: A Practical Facial Landmark Detector**\n\n- arxiv: [https://arxiv.org/abs/1902.10859](https://arxiv.org/abs/1902.10859)\n- github: [https://github.com/guoqiangqi/PFLD](https://github.com/guoqiangqi/PFLD)\n\n**Semantic Alignment: Finding Semantically Consistent Ground-truth for Facial Landmark Detection**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1903.10661](https://arxiv.org/abs/1903.10661)\n\n**An Efficient Multitask Neural Network for Face Alignment, Head Pose Estimation and Face Tracking**\n\n- intro: University of Technology Sydney\n- arxiv: [https://arxiv.org/abs/2103.07615](https://arxiv.org/abs/2103.07615)\n\n**HIH: Towards More Accurate Face Alignment via Heatmap in Heatmap**\n\n[https://arxiv.org/abs/2104.03100](https://arxiv.org/abs/2104.03100)\n\n**Subpixel Heatmap Regression for Facial Landmark Localization**\n\n- intro: BMVC 2021\n- intro: Samsung AI Center, Cambridge, UK & Queen Mary University London\n- project page: [https://www.adrianbulat.com/face-alignment](https://www.adrianbulat.com/face-alignment)\n- arxiv: [https://arxiv.org/abs/2111.02360](https://arxiv.org/abs/2111.02360)\n- github: [https://github.com/1adrianb/face-alignment](https://github.com/1adrianb/face-alignment)\n\n**RePFormer: Refinement Pyramid Transformer for Robust Facial Landmark Detection**\n\n- intro: The Chinese University of Hong Kong & The Hong Kong University of Science and Technology & IIAI & Terminus Group & Chinese Academy of Sciences\n- arxiv: [https://arxiv.org/abs/2207.03917](https://arxiv.org/abs/2207.03917)\n\n# Face Synthesis\n\n**Beyond Face Rotation: Global and Local Perception GAN for Photorealistic and Identity Preserving Frontal View Synthesis**\n\n- intro: ICCV 2017\n- keywords: TP-GAN\n- arxiv: [https://arxiv.org/abs/1704.04086](https://arxiv.org/abs/1704.04086)\n- paper: [http://openaccess.thecvf.com/content_ICCV_2017/papers/Huang_Beyond_Face_Rotation_ICCV_2017_paper.pdf](http://openaccess.thecvf.com/content_ICCV_2017/papers/Huang_Beyond_Face_Rotation_ICCV_2017_paper.pdf)\n- github(official, Tensorflow): [https://github.com/HRLTY/TP-GAN](https://github.com/HRLTY/TP-GAN)\n\n# Projects\n\n**Using MXNet for Face-related Algorithm**\n\n- github: [https://github.com/tornadomeet/mxnet-face](https://github.com/tornadomeet/mxnet-face)\n\n**clmtrackr: Javascript library for precise tracking of facial features via Constrained Local Models**\n\n- github: [https://github.com/auduno/clmtrackr](https://github.com/auduno/clmtrackr)\n- blog: [http://auduno.com/post/61888277175/fitting-faces](http://auduno.com/post/61888277175/fitting-faces)\n- demo: [http://auduno.github.io/clmtrackr/examples/facesubstitution.html](http://auduno.github.io/clmtrackr/examples/facesubstitution.html)\n- demo: [http://auduno.github.io/clmtrackr/face_deformation_video.html](http://auduno.github.io/clmtrackr/face_deformation_video.html)\n- demo: [http://auduno.github.io/clmtrackr/examples/clm_emotiondetection.html](http://auduno.github.io/clmtrackr/examples/clm_emotiondetection.html)\n- demo: [http://auduno.com/post/84214587523/twisting-faces](http://auduno.com/post/84214587523/twisting-faces)\n\n**DeepLogo**\n\n- intro: A brand logo recognition system using deep convolutional neural networks.\n- github: [https://github.com/satojkovic/DeepLogo](https://github.com/satojkovic/DeepLogo)\n\n**Deep-Leafsnap**\n\n- intro: LeafSnap replicated using deep neural networks to test accuracy compared to traditional computer vision methods.\n- github: [https://github.com/sujithv28/Deep-Leafsnap](https://github.com/sujithv28/Deep-Leafsnap)\n\n**FaceVerification: An Experimental Implementation of Face Verification, 96.8% on LFW**\n\n- github: [https://github.com/happynear/FaceVerification](https://github.com/happynear/FaceVerification)\n\n**InsightFace**\n\n- intro: Face Recognition Project on MXnet\n- arxiv: [https://github.com//deepinsight/insightface](https://github.com//deepinsight/insightface)\n\n## OpenFace\n\n**OpenFace: Face Recognition with Deep Neural Networks**\n\n- homepage: [http://cmusatyalab.github.io/openface/](http://cmusatyalab.github.io/openface/)\n- github: [https://github.com/cmusatyalab/openface](https://github.com/cmusatyalab/openface)\n- github: [https://github.com/aybassiouny/OpenFaceCpp](https://github.com/aybassiouny/OpenFaceCpp)\n\n**OpenFace 0.2.0: Higher accuracy and halved execution time**\n\n- homepage: [http://bamos.github.io/2016/01/19/openface-0.2.0/](http://bamos.github.io/2016/01/19/openface-0.2.0/)\n\n**OpenFace: A general-purpose face recognition library with mobile applications**\n\n- paper: [http://reports-archive.adm.cs.cmu.edu/anon/anon/usr0/ftp/2016/CMU-CS-16-118.pdf](http://reports-archive.adm.cs.cmu.edu/anon/anon/usr0/ftp/2016/CMU-CS-16-118.pdf)\n\n**OpenFace: an open source facial behavior analysis toolkit**\n\n![](https://raw.githubusercontent.com/TadasBaltrusaitis/OpenFace/master/imgs/multi_face_img.png)\n\n- intro: a state-of-the art open source tool intended for facial landmark detection, head pose estimation, \nfacial action unit recognition, and eye-gaze estimation.\n- github: [https://github.com/TadasBaltrusaitis/OpenFace](https://github.com/TadasBaltrusaitis/OpenFace)\n\n# Resources\n\n**Face-Resources**\n\n- github: [https://github.com/betars/Face-Resources](https://github.com/betars/Face-Resources)\n","excerpt":"Papers Deep Learning Face Representation from Predicting 10,000 Classes intro: CVPR 2014. DeepID paper:  http://mmlab.ie.cuhk.edu.hk/pdf/Yi","outboundReferences":[],"inboundReferences":[]},"tagsOutbound":{"nodes":[]}},"pageContext":{"tags":[],"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-face-recognition/","sidebarItems":[{"title":"Categories","items":[{"title":"Commercial","url":"","items":[{"title":"Commercial Structure","url":"/Commercial/Commercial Structure/","items":[]},{"title":"Community of Practice","url":"/Commercial/Community of Practice/","items":[]},{"title":"Domains","url":"/Commercial/Domains/","items":[]},{"title":"Webizen Alliance","url":"/Commercial/Webizen Alliance/","items":[]}]},{"title":"Core Services","url":"","items":[{"title":"Decentralised Ontologies","url":"/Core Services/Decentralised Ontologies/","items":[]},{"title":"Permissive Commons","url":"/Core Services/Permissive Commons/","items":[]},{"title":"Safety Protocols","url":"","items":[{"title":"Safety Protocols","url":"/Core Services/Safety Protocols/Safety Protocols/","items":[]},{"title":"Social Factors","url":"","items":[{"title":"Best Efforts","url":"/Core Services/Safety Protocols/Social Factors/Best Efforts/","items":[]},{"title":"Ending Digital Slavery","url":"/Core Services/Safety Protocols/Social Factors/Ending Digital Slavery/","items":[]},{"title":"Freedom of Thought","url":"/Core Services/Safety Protocols/Social Factors/Freedom of Thought/","items":[]},{"title":"No Golden Handcuffs","url":"/Core Services/Safety Protocols/Social Factors/No Golden Handcuffs/","items":[]},{"title":"Relationships (Social)","url":"/Core Services/Safety Protocols/Social Factors/Relationships (Social)/","items":[]},{"title":"Social Attack Vectors","url":"/Core Services/Safety Protocols/Social Factors/Social Attack Vectors/","items":[]},{"title":"The Webizen Charter","url":"/Core Services/Safety Protocols/Social Factors/The Webizen Charter/","items":[]}]},{"title":"Values Credentials","url":"/Core Services/Safety Protocols/Values Credentials/","items":[]}]},{"title":"Temporal Semantics","url":"/Core Services/Temporal Semantics/","items":[]},{"title":"Verifiable Claims & Credentials","url":"/Core Services/Verifiable Claims & Credentials/","items":[]},{"title":"Webizen Socio-Economics","url":"","items":[{"title":"Biosphere Ontologies","url":"/Core Services/Webizen Socio-Economics/Biosphere Ontologies/","items":[]},{"title":"Centricity","url":"/Core Services/Webizen Socio-Economics/Centricity/","items":[]},{"title":"Currencies","url":"/Core Services/Webizen Socio-Economics/Currencies/","items":[]},{"title":"SocioSphere Ontologies","url":"/Core Services/Webizen Socio-Economics/SocioSphere Ontologies/","items":[]},{"title":"Sustainable Development Goals (ESG)","url":"/Core Services/Webizen Socio-Economics/Sustainable Development Goals (ESG)/","items":[]}]}]},{"title":"Core Technologies","url":"","items":[{"title":"AUTH","url":"","items":[{"title":"Authentication Fabric","url":"/Core Technologies/AUTH/Authentication Fabric/","items":[]}]},{"title":"Webizen App Spec","url":"","items":[{"title":"SemWebSpecs","url":"","items":[{"title":"Core Ontologies","url":"","items":[{"title":"FOAF","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/FOAF/","items":[]},{"title":"General Ontology Information","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/General Ontology Information/","items":[]},{"title":"Human Rights Ontologies","url":"","items":[{"title":"UDHR","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/Human Rights Ontologies/UDHR/","items":[]}]},{"title":"MD-RDF Ontologies","url":"","items":[{"title":"DataTypesOntology (DTO) Core","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/MD-RDF Ontologies/DataTypes Ontology/","items":[]},{"title":"Friend of a Friend (FOAF) Core","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/MD-RDF Ontologies/FOAF/","items":[]}]},{"title":"OWL","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/OWL/","items":[]},{"title":"RDF Schema 1.1","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/RDFS/","items":[]},{"title":"Sitemap","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/Sitemap/","items":[]},{"title":"SKOS","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/SKOS/","items":[]},{"title":"SOIC","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/SOIC/","items":[]}]},{"title":"Semantic Web - An Introduction","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Semantic Web - An Introduction/","items":[]},{"title":"SemWeb-AUTH","url":"","items":[{"title":"WebID-OIDC","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-OIDC/","items":[]},{"title":"WebID-RSA","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-RSA/","items":[]},{"title":"WebID-TLS","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-TLS/","items":[]}]},{"title":"Sparql","url":"","items":[{"title":"Sparql Family","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Sparql/Sparql Family/","items":[]}]},{"title":"W3C Specifications","url":"","items":[{"title":"Linked Data Fragments","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Fragments/","items":[]},{"title":"Linked Data Notifications","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Notifications/","items":[]},{"title":"Linked Data Platform","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Platform/","items":[]},{"title":"Linked Media Fragments","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Media Fragments/","items":[]},{"title":"RDF","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/RDF/","items":[]},{"title":"Web Access Control (WAC)","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Web Access Control (WAC)/","items":[]},{"title":"Web Of Things","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Web Of Things/","items":[]},{"title":"WebID","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/WebID/","items":[]}]}]},{"title":"Webizen App Spec 1.0","url":"/Core Technologies/Webizen App Spec/Webizen App Spec 1.0/","items":[]},{"title":"WebSpec","url":"","items":[{"title":"HTML SPECS","url":"/Core Technologies/Webizen App Spec/WebSpec/HTML SPECS/","items":[]},{"title":"Query Interfaces","url":"","items":[{"title":"GraphQL","url":"/Core Technologies/Webizen App Spec/WebSpec/Query Interfaces/GraphQL/","items":[]}]},{"title":"WebPlatformTools","url":"","items":[{"title":"WebAuthn","url":"/Core Technologies/Webizen App Spec/WebSpec/WebPlatformTools/WebAuthn/","items":[]},{"title":"WebDav","url":"/Core Technologies/Webizen App Spec/WebSpec/WebPlatformTools/WebDav/","items":[]}]}]}]}]},{"title":"Database Requirements","url":"","items":[{"title":"Database Alternatives","url":"","items":[{"title":"Akutan","url":"/Database requirements/Database Alternatives/akutan/","items":[]},{"title":"CayleyGraph","url":"/Database requirements/Database Alternatives/CayleyGraph/","items":[]}]},{"title":"Database Methods","url":"","items":[{"title":"GraphQL","url":"/Database requirements/Database methods/GraphQL/","items":[]},{"title":"Sparql","url":"/Database requirements/Database methods/Sparql/","items":[]}]}]},{"title":"Host Service Requirements","url":"","items":[{"title":"Domain Hosting","url":"/Host Service Requirements/Domain Hosting/","items":[]},{"title":"Email Services","url":"/Host Service Requirements/Email Services/","items":[]},{"title":"LD_PostOffice_SemanticMGR","url":"/Host Service Requirements/LD_PostOffice_SemanticMGR/","items":[]},{"title":"Media Processing","url":"/Host Service Requirements/Media Processing/","items":[{"title":"Ffmpeg","url":"/Host Service Requirements/Media Processing/ffmpeg/","items":[]},{"title":"Opencv","url":"/Host Service Requirements/Media Processing/opencv/","items":[]}]},{"title":"Website Host","url":"/Host Service Requirements/Website Host/","items":[]}]},{"title":"ICT Stack","url":"","items":[{"title":"General References","url":"","items":[{"title":"List of Protocols ISO Model","url":"/ICT Stack/General References/List of Protocols ISO model/","items":[]}]},{"title":"Internet","url":"","items":[{"title":"Internet Stack","url":"/ICT Stack/Internet/Internet Stack/","items":[]}]}]},{"title":"Implementation V1","url":"","items":[{"title":"App-Design-Sdk-V1","url":"","items":[{"title":"Core Apps","url":"","items":[{"title":"Agent Directory","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Agent Directory/","items":[]},{"title":"Credentials & Contracts Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Credentials & Contracts Manager/","items":[]},{"title":"File (Package) Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/File (package) Manager/","items":[]},{"title":"Temporal Apps","url":"","items":[{"title":"Calendar","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Temporal Apps/Calendar/","items":[]},{"title":"Timeline Interface","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Temporal Apps/Timeline Interface/","items":[]}]},{"title":"Webizen Apps (V1)","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Webizen Apps (v1)/","items":[]},{"title":"Webizen Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Webizen Manager/","items":[]}]},{"title":"Data Applications","url":"/Implementation V1/App-design-sdk-v1/Data Applications/","items":[]},{"title":"Design Goals","url":"","items":[{"title":"Design Goals Overview","url":"/Implementation V1/App-design-sdk-v1/Design Goals/Design Goals Overview/","items":[]}]}]},{"title":"Edge","url":"","items":[{"title":"Webizen Local App Functionality","url":"/Implementation V1/edge/Webizen Local App Functionality/","items":[]}]},{"title":"GoLang Libraries","url":"/Implementation V1/GoLang Libraries/","items":[]},{"title":"Implementation V1 Summary","url":"/Implementation V1/Implementation V1 Summary/","items":[]},{"title":"Vps","url":"","items":[{"title":"Server Functionality Summary (VPS)","url":"/Implementation V1/vps/Server Functionality Summary (VPS)/","items":[]}]},{"title":"Webizen 1.0","url":"/Implementation V1/Webizen 1.0/","items":[]},{"title":"Webizen-Connect","url":"","items":[{"title":"Social Media APIs","url":"/Implementation V1/Webizen-Connect/Social Media APIs/","items":[]},{"title":"Webizen-Connect (Summary)","url":"/Implementation V1/Webizen-Connect/Webizen-Connect (summary)/","items":[]}]}]},{"title":"Non-HTTP(s) Protocols","url":"","items":[{"title":"DAT","url":"/Non-HTTP(s) Protocols/DAT/","items":[]},{"title":"GIT","url":"/Non-HTTP(s) Protocols/GIT/","items":[]},{"title":"GUNECO","url":"/Non-HTTP(s) Protocols/GUNECO/","items":[]},{"title":"IPFS","url":"/Non-HTTP(s) Protocols/IPFS/","items":[]},{"title":"Lightning Network","url":"/Non-HTTP(s) Protocols/Lightning Network/","items":[]},{"title":"Non-HTTP(s) Protocols (& DLTs)","url":"/Non-HTTP(s) Protocols/Non-HTTP(s) Protocols (& DLTs)/","items":[]},{"title":"WebRTC","url":"/Non-HTTP(s) Protocols/WebRTC/","items":[]},{"title":"WebSockets","url":"/Non-HTTP(s) Protocols/WebSockets/","items":[]},{"title":"WebTorrent","url":"/Non-HTTP(s) Protocols/WebTorrent/","items":[]}]},{"title":"Old-Work-Archives","url":"","items":[{"title":"2018-Webizen-Net-Au","url":"","items":[{"title":"_Link_library_links","url":"","items":[{"title":"Link Library","url":"/old-work-archives/2018-webizen-net-au/_link_library_links/2018-09-23-wp-linked-data/","items":[]}]},{"title":"_Posts","url":"","items":[{"title":"About W3C","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-27-about-w3c/","items":[]},{"title":"Advanced Functions &#8211; Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-16-advanced-functions-facebook-pages/","items":[]},{"title":"Advanced Search &#038; Discovery Tips","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-advanced-search-discovery-tips/","items":[]},{"title":"An introduction to Virtual Machines.","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-an-introduction-to-virtual-machines/","items":[]},{"title":"Basic Media Analysis &#8211; Part 1 (Audio)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-30-media-analysis-part-1-audio/","items":[]},{"title":"Basic Media Analysis &#8211; Part 2 (visual)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-31-media-analysis-part-2-visual/","items":[]},{"title":"Basic Media Analysis &#8211; Part 3 (Text &#038; Metadata)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-01-01-basic-media-analysis-part-3-text-metadata/","items":[]},{"title":"Building an Economy based upon Knowledge Equity.","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-25-building-an-economy-based-upon-knowledge-equity/","items":[]},{"title":"Choice of Law","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-26-choice-of-law/","items":[]},{"title":"Contemplation of the ITU Dubai Meeting and the Future of the Internet","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-19-contemplation-of-the-itu-dubai-meeting-and-the-future-of-the-internet/","items":[]},{"title":"Creating a Presence &#8211; Online","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-creating-a-presence-online/","items":[]},{"title":"Credentials and Payments by Manu Sporny","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-credentials-and-payments-by-manu-sporny/","items":[]},{"title":"Data Recovery &#038; Collection: Mobile Devices","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-28-mobile-devices-data-recovery-collection/","items":[]},{"title":"Data Recovery: Laptop &#038; Computers","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-28-data-recovery-laptop-computers/","items":[]},{"title":"Decentralized Web Conference 2016","url":"/old-work-archives/2018-webizen-net-au/_posts/2016-06-09-decentralized-web-2016/","items":[]},{"title":"Decentralized Web Summit 2018","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-decentralized-web-summit-2018/","items":[]},{"title":"Does Anonymity exist?","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-does-anonymity-exist/","items":[]},{"title":"Downloading My Data from Social Networks","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-downloading-my-data-from-social-networks/","items":[]},{"title":"Events","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-events/","items":[]},{"title":"Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-16-facebook-pages/","items":[]},{"title":"Google Tracking Data (geolocation)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-google-tracking/","items":[]},{"title":"Human Consciousness","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-human-consciousness/","items":[]},{"title":"Image Recgonition Video Playlist","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-image-recgonition-video-playlist/","items":[]},{"title":"Inferencing (introduction)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-inferencing-introduction/","items":[]},{"title":"Introduction to AI","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-introduction-to-ai/","items":[]},{"title":"Introduction to Linked Data","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-introduction-to-linked-data/","items":[]},{"title":"Introduction to Maltego","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-introduction-to-maltego/","items":[]},{"title":"Introduction to Ontologies","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-ontologies-intro/","items":[]},{"title":"Introduction to Semantic Web","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-introduction-to-semantic-web/","items":[]},{"title":"Knowledge Capital","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-10-17-knowledge-capital/","items":[]},{"title":"Logo&#8217;s, Style Guides and Artwork","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-logos-style-guides-and-artwork/","items":[]},{"title":"MindMapping &#8211; Setting-up a business &#8211; Identity","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-mindmapping-setting-up-a-business-identity/","items":[]},{"title":"Openlink Virtuoso","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-openlink-virtuoso/","items":[]},{"title":"OpenRefine","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-74-2/","items":[]},{"title":"Projects, Customers and Invoicing &#8211; Web-Services for Startups","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-projects-customers-and-invoicing-web-services-for-startups/","items":[]},{"title":"RWW &#038; some Solid history","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-rww-some-solid-history/","items":[]},{"title":"Semantic Web (An Intro)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-semantic-web-an-intro/","items":[]},{"title":"Setting-up Twitter","url":"/old-work-archives/2018-webizen-net-au/_posts/2013-06-07-setting-up-twitter/","items":[]},{"title":"Social Encryption: An Introduction","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-25-social-encryption-an-introduction/","items":[]},{"title":"Stock Content","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-stock-content/","items":[]},{"title":"The WayBack Machine","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-27-the-wayback-machine/","items":[]},{"title":"Tim Berners Lee &#8211; Turing Lecture","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-05-29-tim-berners-lee-turing-lecture/","items":[]},{"title":"Tools of Trade","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-tools-of-trade/","items":[]},{"title":"Trust Factory 2017","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-trust-factory-2017/","items":[]},{"title":"Verifiable Claims (An Introduction)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-vc-intro/","items":[]},{"title":"Web of Things &#8211; an Introduction","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-web-of-things-an-introduction/","items":[]},{"title":"Web-Persistence","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-web-persistence/","items":[]},{"title":"Web-Services &#8211; Marketing Tools","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-web-services-marketing-tools/","items":[]},{"title":"Website Templates","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-templates/","items":[]},{"title":"What is Linked Data?","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-what-is-linked-data/","items":[]},{"title":"What is Open Source Intelligence?","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-what-is-osint/","items":[]},{"title":"WiX","url":"/old-work-archives/2018-webizen-net-au/_posts/2013-01-01-wix/","items":[]}]},{"title":"about","url":"/old-work-archives/2018-webizen-net-au/about/","items":[{"title":"About The Author","url":"/old-work-archives/2018-webizen-net-au/about/about-the-author/","items":[]},{"title":"Applied Theory: Applications for a Human Centric Web","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/","items":[{"title":"Digital Receipts","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/digital-receipts/","items":[]},{"title":"Fake News: Considerations  Principles  The Institution of Socio &#8211; Economic Values","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations/","items":[]},{"title":"Healthy Living Economy","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/healthy-living-economy/","items":[]},{"title":"HyperMedia Solutions &#8211; Adapting HbbTV V2","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/","items":[{"title":"HYPERMEDIA PACKAGES","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/hypermedia-packages/","items":[]},{"title":"USER STORIES: INTERACTIVE VIEWING EXPERIENCE","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/user-stories-interactive-viewing-experience/","items":[]}]},{"title":"Measurements App","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/measurements-app/","items":[]},{"title":"Re:Animation","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/reanimation/","items":[]},{"title":"Solutions to FakeNews: Linked-Data, Ontologies and Verifiable Claims","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/ld-solutions-to-fakenews/","items":[]}]},{"title":"Executive Summary","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/","items":[{"title":"Assisting those who Enforce the Law","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/assisting-those-who-enforce-the-law/","items":[]},{"title":"Consumer Protections","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/consumer-protections/","items":[]},{"title":"Knowledge Banking: Legal Structures","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-banking-legal-structures/","items":[]},{"title":"Knowledge Economics &#8211; Services","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-economics-services/","items":[]},{"title":"Preserving The Freedom to Think","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/preserving-the-freedom-to-think/","items":[]}]},{"title":"History","url":"/old-work-archives/2018-webizen-net-au/about/history/","items":[{"title":"History: Global Governance and ICT.","url":"/old-work-archives/2018-webizen-net-au/about/history/history-global-governance-ict-1/","items":[]}]},{"title":"Knowledge Banking: A Technical Architecture Summary","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/","items":[{"title":"An introduction to Credentials.","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/","items":[{"title":"credentials and custodianship","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/credentials-and-custodianship/","items":[]},{"title":"DIDs and MultiSig","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/dids-and-multisig/","items":[]}]},{"title":"Personal Augmentation of AI","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/personal-augmentation-of-ai/","items":[]},{"title":"Semantic Inferencing","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/semantic-inferencing/","items":[]},{"title":"Web of Things (IoT+LD)","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/web-of-things-iotld/","items":[]}]},{"title":"References","url":"/old-work-archives/2018-webizen-net-au/about/references/","items":[{"title":"Making the distinction between privacy and dignity.","url":"/old-work-archives/2018-webizen-net-au/about/references/privacy-vs-dignity/","items":[]},{"title":"Roles &#8211; Entity Analysis","url":"/old-work-archives/2018-webizen-net-au/about/references/roles-entity-analysis/","items":[]},{"title":"Social Informatics Design Considerations","url":"/old-work-archives/2018-webizen-net-au/about/references/social-informatics-design-concept-and-principles/","items":[]},{"title":"Socio-economic relations | A conceptual model","url":"/old-work-archives/2018-webizen-net-au/about/references/socioeconomic-relations-p1/","items":[]},{"title":"The need for decentralised Open (Linked) Data","url":"/old-work-archives/2018-webizen-net-au/about/references/the-need-for-decentralised-open-linked-data/","items":[]}]},{"title":"The design of new medium","url":"/old-work-archives/2018-webizen-net-au/about/the-design-of-new-medium/","items":[]},{"title":"The need to modernise socioeconomic infrastructure","url":"/old-work-archives/2018-webizen-net-au/about/the-modernisation-of-socioeconomics/","items":[]},{"title":"The Vision","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/","items":[{"title":"Domesticating Pervasive Surveillance","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/a-technical-vision/","items":[]}]}]},{"title":"An Overview","url":"/old-work-archives/2018-webizen-net-au/the-human-centric-infosphere/","items":[]},{"title":"Resource Library","url":"/old-work-archives/2018-webizen-net-au/resource-library/","items":[{"title":"awesomeLists","url":"","items":[{"title":"Awesome Computer Vision: Awesome","url":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-computer-vision/","items":[]},{"title":"Awesome Natural Language Generation Awesome","url":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awsome-nl-gen/","items":[]},{"title":"Awesome Semantic Web Awesome","url":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-semweb/","items":[]},{"title":"Awesome-General","url":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-general/","items":[]}]},{"title":"Handong1587","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/","items":[{"title":"_Posts","url":"","items":[{"title":"Computer_science","url":"","items":[{"title":"Algorithm and Data Structure Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-algo-resourses/","items":[]},{"title":"Artificial Intelligence Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-ai-resources/","items":[]},{"title":"Big Data Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-09-22-big-data-resources/","items":[]},{"title":"Computer Science Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-cs-resources/","items":[]},{"title":"Data Mining Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-data-mining-resources/","items":[]},{"title":"Data Science Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-data-science-resources/","items":[]},{"title":"Database Systems Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-database-resources/","items":[]},{"title":"Discrete Optimization Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-discrete-optimization/","items":[]},{"title":"Distribued System Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-12-12-ditributed-system-resources/","items":[]},{"title":"Funny Stuffs Of Computer Science","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-11-18-funny-stuffs-of-cs/","items":[]},{"title":"Robotics","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-09-26-robotics-resources/","items":[]},{"title":"Writting CS Papers","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-11-30-writing-papers/","items":[]}]},{"title":"Computer_vision","url":"","items":[{"title":"Computer Vision Datasets","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-24-datasets/","items":[]},{"title":"Computer Vision Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-12-cv-resources/","items":[]},{"title":"Features","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-10-09-features/","items":[]},{"title":"Recognition, Detection, Segmentation and Tracking","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-10-09-recognition-detection-segmentation-tracking/","items":[]},{"title":"Use FFmpeg to Capture I Frames of Video","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2016-03-03-ffmpeg-i-frame/","items":[]},{"title":"Working on OpenCV","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-12-25-working-on-opencv/","items":[]}]},{"title":"Deep_learning","url":"","items":[{"title":"3D","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2021-07-28-3d/","items":[]},{"title":"Acceleration and Model Compression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-cnn-compression-acceleration/","items":[]},{"title":"Acceleration and Model Compression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-knowledge-distillation/","items":[]},{"title":"Adversarial Attacks and Defences","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-adversarial-attacks-and-defences/","items":[]},{"title":"Audio / Image / Video Generation","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-audio-image-video-generation/","items":[]},{"title":"BEV","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2022-06-27-bev/","items":[]},{"title":"Classification / Recognition","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recognition/","items":[]},{"title":"Deep Learning and Autonomous Driving","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-autonomous-driving/","items":[]},{"title":"Deep Learning Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-pose-estimation/","items":[]},{"title":"Deep Learning Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-applications/","items":[]},{"title":"Deep learning Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-courses/","items":[]},{"title":"Deep Learning Frameworks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-frameworks/","items":[]},{"title":"Deep Learning Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-resources/","items":[]},{"title":"Deep Learning Software and Hardware","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-software-hardware/","items":[]},{"title":"Deep Learning Tricks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tricks/","items":[]},{"title":"Deep Learning Tutorials","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tutorials/","items":[]},{"title":"Deep Learning with Machine Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-with-ml/","items":[]},{"title":"Face Recognition","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-face-recognition/","items":[]},{"title":"Fun With Deep Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-fun-with-deep-learning/","items":[]},{"title":"Generative Adversarial Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gan/","items":[]},{"title":"Graph Convolutional Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gcn/","items":[]},{"title":"Image / Video Captioning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-captioning/","items":[]},{"title":"Image Retrieval","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-retrieval/","items":[]},{"title":"Keep Up With New Trends","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2018-09-03-keep-up-with-new-trends/","items":[]},{"title":"LiDAR 3D Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-lidar-3d-detection/","items":[]},{"title":"Natural Language Processing","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nlp/","items":[]},{"title":"Neural Architecture Search","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nas/","items":[]},{"title":"Object Counting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-counting/","items":[]},{"title":"Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-detection/","items":[]},{"title":"OCR","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-ocr/","items":[]},{"title":"Optical Flow","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-optical-flow/","items":[]},{"title":"Re-ID","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-re-id/","items":[]},{"title":"Recommendation System","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recommendation-system/","items":[]},{"title":"Reinforcement Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rl/","items":[]},{"title":"RNN and LSTM","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rnn-and-lstm/","items":[]},{"title":"Segmentation","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-segmentation/","items":[]},{"title":"Style Transfer","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-style-transfer/","items":[]},{"title":"Super-Resolution","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-super-resolution/","items":[]},{"title":"Tracking","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-tracking/","items":[]},{"title":"Training Deep Neural Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-training-dnn/","items":[]},{"title":"Transfer Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-transfer-learning/","items":[]},{"title":"Unsupervised Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-unsupervised-learning/","items":[]},{"title":"Video Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-video-applications/","items":[]},{"title":"Visual Question Answering","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-vqa/","items":[]},{"title":"Visualizing and Interpreting Convolutional Neural Network","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-visulizing-interpreting-cnn/","items":[]}]},{"title":"Leisure","url":"","items":[{"title":"All About Enya","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-all-about-enya/","items":[]},{"title":"Coldplay","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-coldplay/","items":[]},{"title":"Coldplay","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-nightwish/","items":[]},{"title":"Games","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-13-games/","items":[]},{"title":"Green Day","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-greenday/","items":[]},{"title":"Muse! Muse!","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-muse-muse/","items":[]},{"title":"Oasis","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-oasis/","items":[]},{"title":"Paintings By J.M.","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2016-03-08-paintings-by-jm/","items":[]},{"title":"Papers, Blogs and Websites","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-09-27-papers-blogs-and-websites/","items":[]},{"title":"Welcome To The Black Parade","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-welcome-to-the-black-parade/","items":[]}]},{"title":"Machine_learning","url":"","items":[{"title":"Bayesian Methods","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-bayesian-methods/","items":[]},{"title":"Clustering Algorithms Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-clustering/","items":[]},{"title":"Competitions","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-competitions/","items":[]},{"title":"Dimensionality Reduction Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-dimensionality-reduction/","items":[]},{"title":"Fun With Machine Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-fun-with-ml/","items":[]},{"title":"Graphical Models Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-graphical-models/","items":[]},{"title":"Machine Learning Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-ml-courses/","items":[]},{"title":"Machine Learning Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-ml-resources/","items":[]},{"title":"Natural Language Processing","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-nlp/","items":[]},{"title":"Neural Network","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-neural-network/","items":[]},{"title":"Random Field","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-random-field/","items":[]},{"title":"Random Forests","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-random-forests/","items":[]},{"title":"Regression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-regression/","items":[]},{"title":"Support Vector Machine","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-svm/","items":[]},{"title":"Topic Model","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-topic-model/","items":[]}]},{"title":"Mathematics","url":"","items":[{"title":"Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/mathematics/2016-02-24-resources/","items":[]}]},{"title":"Programming_study","url":"","items":[{"title":"Add Lunr Search Plugin For Blog","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-31-add-lunr-search-plugin-for-blog/","items":[]},{"title":"Android Development Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-05-23-android-resources/","items":[]},{"title":"C++ Programming Solutions","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-09-07-cpp-programming-solutions/","items":[]},{"title":"Commands To Suppress Some Building Errors With Visual Studio","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-24-cmds-to-suppress-some-vs-building-Errors/","items":[]},{"title":"Embedding Python In C/C++","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-10-embedding-python-in-cpp/","items":[]},{"title":"Enable Large Addresses On VS2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-12-14-enable-large-addresses/","items":[]},{"title":"Fix min/max Error In VS2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-02-17-min-max-error-in-vs2015/","items":[]},{"title":"Gflags Build Problems on Windows X86 and Visual Studio 2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-23-gflags-build-problems-winx86-vs2015/","items":[]},{"title":"Glog Build Problems on Windows X86 and Visual Studio 2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-23-glog-build-problems-winx86/","items":[]},{"title":"Horrible Wired Errors Come From Simple Stupid Mistake","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-16-horrible-wired-errors-come-from-simple-stupid-mistake/","items":[]},{"title":"Install Jekyll To Fix Some Local Github-pages Defects","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-11-21-install-jekyll/","items":[]},{"title":"Install Therubyracer Failure","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-03-install-therubyracer/","items":[]},{"title":"Notes On Valgrind and Others","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-05-30-notes-on-valgrind/","items":[]},{"title":"PHP Hello World","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-04-php-hello-world/","items":[]},{"title":"Programming Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-07-01-programming-resources/","items":[]},{"title":"PyInstsaller and Others","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-12-24-pyinstaller-and-others/","items":[]},{"title":"Web Development Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-06-21-web-dev-resources/","items":[]},{"title":"Working on Visual Studio","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-04-03-working-on-vs/","items":[]}]},{"title":"Reading_and_thoughts","url":"","items":[{"title":"Book Reading List","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2015-12-04-book-reading-list/","items":[]},{"title":"Funny Papers","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2015-12-04-funny-papers/","items":[]},{"title":"Reading Materials","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2016-01-18-reading-materials/","items":[]}]},{"title":"Study","url":"","items":[{"title":"Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2017-11-28-courses/","items":[]},{"title":"Essay Writting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2016-01-11-essay-writting/","items":[]},{"title":"Job Hunting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2016-06-02-job-hunting/","items":[]},{"title":"Study Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2018-04-18-resources/","items":[]}]},{"title":"Working_on_linux","url":"","items":[{"title":"Create Multiple Forks of a GitHub Repo","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-12-18-create-multi-forks/","items":[]},{"title":"Linux Git Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-08-02-linux-git/","items":[]},{"title":"Linux Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-07-24-linux-resources/","items":[]},{"title":"Linux SVN Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-08-03-linux-svn/","items":[]},{"title":"Setup vsftpd on Ubuntu 14.10","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2016-07-27-setup-vsftpd/","items":[]},{"title":"Useful Linux Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-07-25-useful-linux-commands/","items":[]},{"title":"vsftpd Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2016-07-28-vsftpd-cmd/","items":[]}]},{"title":"Working_on_mac","url":"","items":[{"title":"Mac Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_mac/2015-07-25-mac-resources/","items":[]}]},{"title":"Working_on_windows","url":"","items":[{"title":"FFmpeg Collection of Utility Methods","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2016-06-05-ffmpeg-utilities/","items":[]},{"title":"Windows Commands and Utilities","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2015-10-27-windows-cmds-utils/","items":[]},{"title":"Windows Dev Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2015-10-27-resources/","items":[]}]}]},{"title":"Drafts","url":"","items":[{"title":"2016-12-30-Setup-Opengrok","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-12-30-setup-opengrok/","items":[]},{"title":"2017-01-20-Packing-C++-Project-to-Single-Executable","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2017-01-20-packing-c++-project-to-single-executable/","items":[]},{"title":"Notes On Caffe Development","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-10-notes-on-caffe-dev/","items":[]},{"title":"Notes On Deep Learning Training","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-12-notes-on-dl-training/","items":[]},{"title":"Notes On Discrete Optimization","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-13-notes-on-discrete-optimization/","items":[]},{"title":"Notes On Gecode","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-13-notes-on-gecode/","items":[]},{"title":"Notes On Inside-Outside Net","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-28-notes-on-ion/","items":[]},{"title":"Notes On K-Means","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-06-notes-on-kmeans/","items":[]},{"title":"Notes On L-BFGS","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-07-notes-on-l-bfgs/","items":[]},{"title":"Notes On Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-04-notes-on-object-detection/","items":[]},{"title":"Notes On Perceptrons","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-10-07-notes-on-perceptrons/","items":[]},{"title":"Notes On Quantized Convolutional Neural Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-07-notes-on-quantized-cnn/","items":[]},{"title":"Notes On Stanford CS2321n","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-02-21-notes-on-cs231n/","items":[]},{"title":"Notes on Suffix Array and Manacher Algorithm","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-08-27-notes-on-suffix-array-and-manacher-algorithm/","items":[]},{"title":"Notes On Tensorflow Development","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2017-04-13-notes-on-tensorflow-dev/","items":[]},{"title":"Notes On YOLO","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-14-notes-on-yolo/","items":[]},{"title":"PASCAL VOC (20) / COCO (80) / ImageNet (200) Detection Categories","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-12-23-imagenet-det-cat/","items":[]},{"title":"Softmax Vs Logistic Vs Sigmoid","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-10-softmax-logistic-sigmoid/","items":[]},{"title":"Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognititon","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-08-31-model-ensemble-of-deteciton/","items":[]}]}]}]}]}]},{"title":"Webizen 2.0","url":"","items":[{"title":"AI Capabilities","url":"","items":[{"title":"AI Capabilities Objectives","url":"/Webizen 2.0/AI Capabilities/AI Capabilities Objectives/","items":[]},{"title":"Audio & Video Analysis","url":"/Webizen 2.0/AI Capabilities/Audio & Video Analysis/","items":[]},{"title":"Image Analysis","url":"/Webizen 2.0/AI Capabilities/Image Analysis/","items":[]},{"title":"Text Analysis","url":"/Webizen 2.0/AI Capabilities/Text Analysis/","items":[]}]},{"title":"LOD-a-lot","url":"/Webizen 2.0/AI Related Links & Notes/","items":[]},{"title":"Mobile Apps","url":"","items":[{"title":"Android","url":"/Webizen 2.0/Mobile Apps/Android/","items":[]},{"title":"General Mobile Architecture","url":"/Webizen 2.0/Mobile Apps/General Mobile Architecture/","items":[]},{"title":"iOS","url":"/Webizen 2.0/Mobile Apps/iOS/","items":[]}]},{"title":"Web Of Things (IoT)","url":"","items":[{"title":"Web Of Things (IoT)","url":"/Webizen 2.0/Web Of Things (IoT)/Web Of Things (IoT)/","items":[]}]},{"title":"Webizen 2.0","url":"/Webizen 2.0/Webizen 2.0/","items":[]},{"title":"Webizen AI OS Platform","url":"/Webizen 2.0/Webizen AI OS Platform/","items":[]},{"title":"Webizen Pro Summary","url":"/Webizen 2.0/Webizen Pro Summary/","items":[]}]},{"title":"Webizen V1 Project Documentation","url":"/","items":[]}]}],"tagsGroups":[],"latestPosts":[{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/","title":"Knowledge Banking: A Technical Architecture Summary","lastUpdatedAt":"2022-12-28T20:36:06.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/the-human-centric-infosphere/","title":"An Overview","lastUpdatedAt":"2022-12-28T20:26:34.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/the-design-of-new-medium/","title":"The design of new medium","lastUpdatedAt":"2022-12-28T20:26:34.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/the-modernisation-of-socioeconomics/","title":"The need to modernise socioeconomic infrastructure","lastUpdatedAt":"2022-12-28T20:26:34.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/the-vision/","title":"The Vision","lastUpdatedAt":"2022-12-28T20:26:34.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awsome-nl-gen/","title":"Awesome Natural Language Generation Awesome","lastUpdatedAt":"2022-12-28T20:06:33.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-computer-vision/","title":"Awesome Computer Vision: Awesome","lastUpdatedAt":"2022-12-28T20:06:17.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/","title":"Handong1587","lastUpdatedAt":"2022-12-28T20:06:17.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-general/","title":"Awesome-General","lastUpdatedAt":"2022-12-28T20:06:17.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-semweb/","title":"Awesome Semantic Web Awesome","lastUpdatedAt":"2022-12-28T20:06:17.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}