{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-audio-image-video-generation/",
    "result": {"data":{"mdx":{"id":"1e555500-430e-524f-8061-3878b9e1cf9c","tableOfContents":{"items":[{"url":"#papers","title":"Papers"},{"url":"#face-image-generation","title":"Face Image Generation"},{"url":"#person-image-generation","title":"Person Image Generation"},{"url":"#video-generation","title":"Video Generation"},{"url":"#deep-generative-model","title":"Deep Generative Model"},{"url":"#blogs","title":"Blogs"},{"url":"#projects","title":"Projects"}]},"fields":{"title":"Audio / Image / Video Generation","slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-audio-image-video-generation/","url":"https://devdocs.webizen.org/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-audio-image-video-generation/","editUrl":"https://github.com/webizenai/devdocs/tree/main/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-audio-image-video-generation.md","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022","gitCreatedAt":"2022-12-28T19:22:29.000Z","shouldShowTitle":true},"frontmatter":{"title":"Audio / Image / Video Generation","description":null,"imageAlt":null,"tags":[],"date":"2015-10-09T00:00:00.000Z","dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"layout\": \"post\",\n  \"category\": \"deep_learning\",\n  \"title\": \"Audio / Image / Video Generation\",\n  \"date\": \"2015-10-09T00:00:00.000Z\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"papers\"\n  }, \"Papers\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Optimizing Neural Networks That Generate Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: 2014 PhD thesis\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper : \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.toronto.edu/~tijmen/tijmen_thesis.pdf\"\n  }, \"http://www.cs.toronto.edu/~tijmen/tijmen_thesis.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mrkulk/Unsupervised-Capsule-Network\"\n  }, \"https://github.com/mrkulk/Unsupervised-Capsule-Network\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning to Generate Chairs, Tables and Cars with Convolutional Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1411.5928\"\n  }, \"http://arxiv.org/abs/1411.5928\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DRAW: A Recurrent Neural Network For Image Generation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google DeepMind\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1502.04623\"\n  }, \"http://arxiv.org/abs/1502.04623\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/vivanov879/draw\"\n  }, \"https://github.com/vivanov879/draw\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Theano): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jbornschein/draw\"\n  }, \"https://github.com/jbornschein/draw\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Lasagne): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/skaae/lasagne-draw\"\n  }, \"https://github.com/skaae/lasagne-draw\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"youtube: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=Zt-7MI9eKEo&hd=1\"\n  }, \"https://www.youtube.com/watch?v=Zt-7MI9eKEo&hd=1\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"video: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://pan.baidu.com/s/1gd3W6Fh\"\n  }, \"http://pan.baidu.com/s/1gd3W6Fh\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"What is DRAW (Deep Recurrent Attentive Writer)?\")), mdx(\"img\", {\n    \"src\": \"http://kvfrans.com/content/images/2016/06/gencnn-afe135ff8d2725325a22455a488562b0e1cb7ac6a3f60b3cecb373fd043eb202.svg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://kvfrans.com/what-is-draw-deep-recurrent-attentive-writer/\"\n  }, \"http://kvfrans.com/what-is-draw-deep-recurrent-attentive-writer/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(tensorflow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kvfrans/draw\"\n  }, \"https://github.com/kvfrans/draw\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Colorizing the DRAW Model\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://kvfrans.com/colorizing-the-draw-model/\"\n  }, \"http://kvfrans.com/colorizing-the-draw-model/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kvfrans/draw-color\"\n  }, \"https://github.com/kvfrans/draw-color\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Understanding and Implementing Deepmind's DRAW Model\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://evjang.com/articles/draw\"\n  }, \"http://evjang.com/articles/draw\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ericjang/draw\"\n  }, \"https://github.com/ericjang/draw\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generative Image Modeling Using Spatial LSTMs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1506.03478\"\n  }, \"http://arxiv.org/abs/1506.03478\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lucastheis/ride/\"\n  }, \"https://github.com/lucastheis/ride/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Conditional generative adversarial nets for convolutional face generation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.foldl.me/uploads/2015/conditional-gans-face-generation/paper.pdf\"\n  }, \"http://www.foldl.me/uploads/2015/conditional-gans-face-generation/paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.foldl.me/2015/conditional-gans-face-generation/\"\n  }, \"http://www.foldl.me/2015/conditional-gans-face-generation/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hans/adversarial\"\n  }, \"https://github.com/hans/adversarial\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generating Images from Captions with Attention\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1511.02793\"\n  }, \"http://arxiv.org/abs/1511.02793\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/emansim/text2image\"\n  }, \"https://github.com/emansim/text2image\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.toronto.edu/~emansim/cap2im.html\"\n  }, \"http://www.cs.toronto.edu/~emansim/cap2im.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attribute2Image: Conditional Image Generation from Visual Attributes\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Michigan & Adobe Research & NEC Labs\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://sites.google.com/site/attribute2image/\"\n  }, \"https://sites.google.com/site/attribute2image/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1512.00570\"\n  }, \"http://arxiv.org/abs/1512.00570\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Torch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xcyan/eccv16_attr2img\"\n  }, \"https://github.com/xcyan/eccv16_attr2img\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Autoencoding beyond pixels using a learned similarity metric\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1512.09300\"\n  }, \"http://arxiv.org/abs/1512.09300\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://algoalgebra.csa.iisc.ernet.in/deepimagine/\"\n  }, \"http://algoalgebra.csa.iisc.ernet.in/deepimagine/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/andersbll/autoencoding_beyond_pixels\"\n  }, \"https://github.com/andersbll/autoencoding_beyond_pixels\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Tensorflow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/timsainb/Tensorflow-MultiGPU-VAE-GAN\"\n  }, \"https://github.com/timsainb/Tensorflow-MultiGPU-VAE-GAN\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"video: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://video.weibo.com/show?fid=1034:f00b4e5a34e8c1ebe78ccd00da95f9e0\"\n  }, \"http://video.weibo.com/show?fid=1034:f00b4e5a34e8c1ebe78ccd00da95f9e0\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/stitchfix/fauxtograph\"\n  }, \"https://github.com/stitchfix/fauxtograph\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Visual Analogy-Making\")), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/carpedm20/visual-analogy-tensorflow/83893d866557239a890053b55cb7105ebf54045e/assets/model.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://papers.nips.cc/paper/5845-deep-visual-analogy-making\"\n  }, \"https://papers.nips.cc/paper/5845-deep-visual-analogy-making\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Tensorflow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/carpedm20/visual-analogy-tensorflow\"\n  }, \"https://github.com/carpedm20/visual-analogy-tensorflow\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://slideplayer.com/slide/9147672/\"\n  }, \"http://slideplayer.com/slide/9147672/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"mirror: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://pan.baidu.com/s/1pKgrdnt\"\n  }, \"http://pan.baidu.com/s/1pKgrdnt\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pixel Recurrent Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google DeepMind. ICML 2016 best paper. PixelRNN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1601.06759\"\n  }, \"http://arxiv.org/abs/1601.06759\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/igul222/pixel_rnn\"\n  }, \"https://github.com/igul222/pixel_rnn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Tensorflow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/carpedm20/pixel-rnn-tensorflow\"\n  }, \"https://github.com/carpedm20/pixel-rnn-tensorflow\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes(by Hugo Larochelle): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.evernote.com/shard/s189/sh/fdf61a28-f4b6-491b-bef1-f3e148185b18/aba21367d1b3730d9334ed91d3250848\"\n  }, \"https://www.evernote.com/shard/s189/sh/fdf61a28-f4b6-491b-bef1-f3e148185b18/aba21367d1b3730d9334ed91d3250848\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"video(by Hugo Larochelle): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.periscope.tv/hugo_larochelle/1ypKdnMkjBnJW\"\n  }, \"https://www.periscope.tv/hugo_larochelle/1ypKdnMkjBnJW\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generating images with recurrent adversarial networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1602.05110\"\n  }, \"http://arxiv.org/abs/1602.05110\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jiwoongim/GRAN\"\n  }, \"https://github.com/jiwoongim/GRAN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pixel-Level Domain Transfer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Torch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/fxia22/PixelDTGAN\"\n  }, \"https://github.com/fxia22/PixelDTGAN\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"author page(Code and dataset): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://dgyoo.github.io/\"\n  }, \"https://dgyoo.github.io/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generative Adversarial Text to Image Synthesis\")), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/reedscot/icml2016/master/images/dcgan_network.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICML 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.05396\"\n  }, \"http://arxiv.org/abs/1605.05396\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/embeddings-for-image-classification/generative-adversarial-text-to-image-synthesis/\"\n  }, \"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/embeddings-for-image-classification/generative-adversarial-text-to-image-synthesis/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/reedscot/icml2016\"\n  }, \"https://github.com/reedscot/icml2016\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code+dataset: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://datasets.d2.mpi-inf.mpg.de/akata/cub_txt.tar.gz\"\n  }, \"http://datasets.d2.mpi-inf.mpg.de/akata/cub_txt.tar.gz\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Conditional Image Generation with PixelCNN Decoders\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google DeepMind. PixelCNN 2.0\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1606.05328\"\n  }, \"http://arxiv.org/abs/1606.05328\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Theano): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kundan2510/pixelCNN\"\n  }, \"https://github.com/kundan2510/pixelCNN\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gtihub(Torch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/dritchie/pixelCNN\"\n  }, \"https://github.com/dritchie/pixelCNN\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Tensorflow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/anantzoid/Conditional-PixelCNN-decoder\"\n  }, \"https://github.com/anantzoid/Conditional-PixelCNN-decoder\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Inverting face embeddings with convolutional neural networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1606.04189\"\n  }, \"http://arxiv.org/abs/1606.04189\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/pavelgonchar/face-transfer-tensorflow\"\n  }, \"https://github.com/pavelgonchar/face-transfer-tensorflow\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unsupervised Cross-Domain Image Generation\")), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/yunjey/dtn-tensorflow/master/jpg/dtn.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Facebook AI Research. Domain Transfer Network (DTN)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.02200\"\n  }, \"https://arxiv.org/abs/1611.02200\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(TensorFlow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yunjey/dtn-tensorflow\"\n  }, \"https://github.com/yunjey/dtn-tensorflow\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PixelCNN++: A PixelCNN Implementation with Discretized Logistic Mixture Likelihood and Other Modifications\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: OpenAI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.05517\"\n  }, \"https://arxiv.org/abs/1701.05517\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openreview.net/pdf?id=BJrFC6ceg\"\n  }, \"http://openreview.net/pdf?id=BJrFC6ceg\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/openai/pixel-cnn\"\n  }, \"https://github.com/openai/pixel-cnn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generating Interpretable Images with Controllable Structure\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google DeepMind\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.scottreed.info/files/iclr2017.pdf\"\n  }, \"http://www.scottreed.info/files/iclr2017.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning to Generate Images of Outdoor Scenes from Attributes and Semantic Layouts\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.00215\"\n  }, \"https://arxiv.org/abs/1612.00215\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Plug & Play Generative Networks: Conditional Iterative Generation of Images in Latent Space\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Wyoming & Geometric Intelligence & Montreal Institute for Learning Algorithms & University of Freiburg\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.evolvingai.org/ppgn\"\n  }, \"http://www.evolvingai.org/ppgn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.evolvingai.org/files/nguyen2016ppgn_v1.pdf\"\n  }, \"http://www.evolvingai.org/files/nguyen2016ppgn_v1.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Evolving-AI-Lab/ppgn\"\n  }, \"https://github.com/Evolving-AI-Lab/ppgn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Image Generation and Editing with Variational Info Generative AdversarialNetworks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.04568\"\n  }, \"https://arxiv.org/abs/1701.04568\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepFace: Face Generation using Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.01876\"\n  }, \"https://arxiv.org/abs/1701.01876\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-View Image Generation from a Single-View\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Southwest Jiaotong University & National University of Singapore\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.04886\"\n  }, \"https://arxiv.org/abs/1704.04886\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generative Cooperative Net for Image Generation and Data Augmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1705.02887\"\n  }, \"https://arxiv.org/abs/1705.02887\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Statistics of Deep Generated Images\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1708.02688\"\n  }, \"https://arxiv.org/abs/1708.02688\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sketch-to-Image Generation Using Deep Contextual Completion\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.08972\"\n  }, \"https://arxiv.org/abs/1711.08972\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Energy-relaxed Wassertein GANs(EnergyWGAN): Towards More Stable and High Resolution Image Generation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.01026\"\n  }, \"https://arxiv.org/abs/1712.01026\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spatial PixelCNN: Generating Images from Patches\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.00714\"\n  }, \"https://arxiv.org/abs/1712.00714\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Visual to Sound: Generating Natural Sound for Videos in the Wild\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of North Carolina at Chapel Hill & Adobe Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://bvision11.cs.unc.edu/bigpen/yipin/visual2sound_webpage/visual2sound.html\"\n  }, \"http://bvision11.cs.unc.edu/bigpen/yipin/visual2sound_webpage/visual2sound.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.01393\"\n  }, \"https://arxiv.org/abs/1712.01393\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semi-supervised FusedGAN for Conditional Image Generation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1801.05551\"\n  }, \"https://arxiv.org/abs/1801.05551\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Image Transformer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Brain & UC Berkeley\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1802.05751\"\n  }, \"https://arxiv.org/abs/1802.05751\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unpaired Multi-Domain Image Generation via Regularized Conditional GANs\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.02456\"\n  }, \"https://arxiv.org/abs/1805.02456\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Transferring GANs: generating images from limited data\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Universitat Aut`onoma de Barcelona\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.01677\"\n  }, \"https://arxiv.org/abs/1805.01677\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yaxingwang/Transferring-GANs\"\n  }, \"https://github.com/yaxingwang/Transferring-GANs\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cross Domain Image Generation through Latent Space Exploration with Adversarial Loss\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.10130\"\n  }, \"https://arxiv.org/abs/1805.10130\")), mdx(\"h1\", {\n    \"id\": \"face-image-generation\"\n  }, \"Face Image Generation\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fader Networks: Manipulating Images by Sliding Attributes\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2017. Facebook AI Research & Sorbonne Universit\\xE9\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.00409\"\n  }, \"https://arxiv.org/abs/1706.00409\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com//facebookresearch/FaderNetworks\"\n  }, \"https://github.com//facebookresearch/FaderNetworks\"))), mdx(\"h1\", {\n    \"id\": \"person-image-generation\"\n  }, \"Person Image Generation\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Disentangled Person Image Generation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018 spotlight\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: KU-Leuven/PSI & Max Planck Institute for Informatics & ETH Zurich\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.02621\"\n  }, \"https://arxiv.org/abs/1712.02621\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pose Guided Person Image Generation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1705.09368\"\n  }, \"https://arxiv.org/abs/1705.09368\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"poster: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://homes.esat.kuleuven.be/~liqianma/NIPS17_PG2/NIPS17_PG2_poster.pdf\"\n  }, \"https://homes.esat.kuleuven.be/~liqianma/NIPS17_PG2/NIPS17_PG2_poster.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deformable GANs for Pose-based Human Image Generation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Trento & Inria Grenoble Rhone-Alpes\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.00055\"\n  }, \"https://arxiv.org/abs/1801.00055\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/AliaksandrSiarohin/pose-gan\"\n  }, \"https://github.com/AliaksandrSiarohin/pose-gan\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unpaired Pose Guided Human Image Generation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1901.02284\"\n  }, \"https://arxiv.org/abs/1901.02284\")), mdx(\"h1\", {\n    \"id\": \"video-generation\"\n  }, \"Video Generation\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MoCoGAN: Decomposing Motion and Content for Video Generation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.04993\"\n  }, \"https://arxiv.org/abs/1707.04993\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/sergeytulyakov/mocogan\"\n  }, \"https://github.com/sergeytulyakov/mocogan\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(PyTorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/DLHacks/mocogan\"\n  }, \"https://github.com/DLHacks/mocogan\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attentive Semantic Video Generation using Captions\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1708.05980\"\n  }, \"https://arxiv.org/abs/1708.05980\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hierarchical Video Generation from Orthogonal Information: Optical Flow and Texture\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI2018. The University of Tokyo\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.mi.t.u-tokyo.ac.jp/assets/publication/hierarchical_video_generation_sup/\"\n  }, \"http://www.mi.t.u-tokyo.ac.jp/assets/publication/hierarchical_video_generation_sup/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.09618\"\n  }, \"https://arxiv.org/abs/1711.09618\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards an Understanding of Our World by GANing Videos in the Wild\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ETH Zurich\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.11453\"\n  }, \"https://arxiv.org/abs/1711.11453\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com//bernhard2202/improved-video-gan\"\n  }, \"https://github.com//bernhard2202/improved-video-gan\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video Generation from Single Semantic Label Map\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.04480\"\n  }, \"https://arxiv.org/abs/1903.04480\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/junting/seg2vid\"\n  }, \"https://github.com/junting/seg2vid\"))), mdx(\"h1\", {\n    \"id\": \"deep-generative-model\"\n  }, \"Deep Generative Model\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Digit Fantasies by a Deep Generative Model\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.dpkingma.com/sgvb_mnist_demo/demo.html\"\n  }, \"http://www.dpkingma.com/sgvb_mnist_demo/demo.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Conditional generative adversarial nets for convolutional face generation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.foldl.me/uploads/2015/conditional-gans-face-generation/paper.pdf\"\n  }, \"http://www.foldl.me/uploads/2015/conditional-gans-face-generation/paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.foldl.me/2015/conditional-gans-face-generation/\"\n  }, \"http://www.foldl.me/2015/conditional-gans-face-generation/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hans/adversarial\"\n  }, \"https://github.com/hans/adversarial\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://soumith.ch/eyescream/\"\n  }, \"http://soumith.ch/eyescream/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.nyu.edu/~denton/\"\n  }, \"http://www.cs.nyu.edu/~denton/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1506.05751\"\n  }, \"http://arxiv.org/abs/1506.05751\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://soumith.ch/eyescream/\"\n  }, \"http://soumith.ch/eyescream/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://colinraffel.com/wiki/deep_generative_image_models_using_a_laplacian_pyramid_of_adversarial_networks\"\n  }, \"http://colinraffel.com/wiki/deep_generative_image_models_using_a_laplacian_pyramid_of_adversarial_networks\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Torch convolutional GAN: Generating Faces with Torch\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://torch.ch/blog/2015/11/13/gan.html\"\n  }, \"http://torch.ch/blog/2015/11/13/gan.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/skaae/torch-gan\"\n  }, \"https://github.com/skaae/torch-gan\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"One-Shot Generalization in Deep Generative Models\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google DeepMind. ICML 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.05106\"\n  }, \"http://arxiv.org/abs/1603.05106\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generative Image Modeling using Style and Structure Adversarial Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.05631\"\n  }, \"http://arxiv.org/abs/1603.05631\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xiaolonw/ss-gan\"\n  }, \"https://github.com/xiaolonw/ss-gan\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Synthesizing Dynamic Textures and Sounds by Spatial-Temporal Generative ConvNet\")), mdx(\"img\", {\n    \"src\": \"http://www.stat.ucla.edu/~jxie/STGConvNet/STGConvNet_file/video/water_stone1.gif\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.stat.ucla.edu/~jxie/STGConvNet/STGConvNet.html\"\n  }, \"http://www.stat.ucla.edu/~jxie/STGConvNet/STGConvNet.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.stat.ucla.edu/~jxie/STGConvNet/STGConvNet_file/doc/STGConvNet.pdf\"\n  }, \"http://www.stat.ucla.edu/~jxie/STGConvNet/STGConvNet_file/doc/STGConvNet.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Synthesizing the preferred inputs for neurons in neural networks via deep generator networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.09304\"\n  }, \"http://arxiv.org/abs/1605.09304\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ArtGAN: Artwork Synthesis with Conditional Categorial GANs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.03410\"\n  }, \"https://arxiv.org/abs/1702.03410\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning to Generate Chairs with Generative Adversarial Nets\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1705.10413\"\n  }, \"https://arxiv.org/abs/1705.10413\")), mdx(\"h1\", {\n    \"id\": \"blogs\"\n  }, \"Blogs\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Torch convolutional GAN: Generating Faces with Torch\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://torch.ch/blog/2015/11/13/gan.html\"\n  }, \"http://torch.ch/blog/2015/11/13/gan.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/skaae/torch-gan\"\n  }, \"https://github.com/skaae/torch-gan\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generating Large Images from Latent Vectors\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://blog.otoro.net/2016/04/01/generating-large-images-from-latent-vectors/\"\n  }, \"http://blog.otoro.net/2016/04/01/generating-large-images-from-latent-vectors/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generating Faces with Deconvolution Networks\")), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/zo7/facegen/master/img/example.gif\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://zo7.github.io/blog/2016/09/25/generating-faces.html\"\n  }, \"https://zo7.github.io/blog/2016/09/25/generating-faces.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zo7/facegen\"\n  }, \"https://github.com/zo7/facegen\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attention Models in Image and Caption Generation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://casmls.github.io/general/2016/10/16/attention_model.html\"\n  }, \"https://casmls.github.io/general/2016/10/16/attention_model.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deconvolution and Checkerboard Artifacts\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \":star::star::star::star::star:\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Brain & Universit\\xE9 de Montr\\xE9al\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://distill.pub/2016/deconv-checkerboard/\"\n  }, \"http://distill.pub/2016/deconv-checkerboard/\"))), mdx(\"h1\", {\n    \"id\": \"projects\"\n  }, \"Projects\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generate cat images with neural networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aleju/cat-generator\"\n  }, \"https://github.com/aleju/cat-generator\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TF-VAE-GAN-DRAW\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: A collection of generative methods implemented with TensorFlow\\n(Deep Convolutional Generative Adversarial Networks (DCGAN),\\nVariational Autoencoder (VAE)\\nand DRAW: A Recurrent Neural Network For Image Generation).\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ikostrikov/TensorFlow-VAE-GAN-DRAW\"\n  }, \"https://github.com/ikostrikov/TensorFlow-VAE-GAN-DRAW\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generating Large Images from Latent Vectors\")), mdx(\"img\", {\n    \"src\": \"http://blog.otoro.net/assets/20160401/png/generator_example.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://blog.otoro.net/2016/04/01/generating-large-images-from-latent-vectors/\"\n  }, \"http://blog.otoro.net/2016/04/01/generating-large-images-from-latent-vectors/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hardmaru/cppn-gan-vae-tensorflow\"\n  }, \"https://github.com/hardmaru/cppn-gan-vae-tensorflow\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generating Large Images from Latent Vectors - Part Two\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://blog.otoro.net/2016/06/02/generating-large-images-from-latent-vectors-part-two/\"\n  }, \"http://blog.otoro.net/2016/06/02/generating-large-images-from-latent-vectors-part-two/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hardmaru/resnet-cppn-gan-tensorflow\"\n  }, \"https://github.com/hardmaru/resnet-cppn-gan-tensorflow\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Analyzing 50k fonts using deep neural networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://erikbern.com/2016/01/21/analyzing-50k-fonts-using-deep-neural-networks/\"\n  }, \"https://erikbern.com/2016/01/21/analyzing-50k-fonts-using-deep-neural-networks/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/erikbern/deep-fonts\"\n  }, \"https://github.com/erikbern/deep-fonts\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generate cat images with neural networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: GAN, spatial transformers, weight initialization and LeakyReLUs.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aleju/cat-generator\"\n  }, \"https://github.com/aleju/cat-generator\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generate human faces with neural networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aleju/face-generator\"\n  }, \"https://github.com/aleju/face-generator\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A TensorFlow implementation of DeepMind's WaveNet paper\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: This is a TensorFlow implementation of the WaveNet generative neural network architecture for image generation.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Zeta36/tensorflow-image-wavenet\"\n  }, \"https://github.com/Zeta36/tensorflow-image-wavenet\"))));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"---\r\nlayout: post\r\ncategory: deep_learning\r\ntitle: Audio / Image / Video Generation\r\ndate: 2015-10-09\r\n---\r\n\r\n# Papers\r\n\r\n**Optimizing Neural Networks That Generate Images**\r\n\r\n- intro: 2014 PhD thesis\r\n- paper : [http://www.cs.toronto.edu/~tijmen/tijmen_thesis.pdf](http://www.cs.toronto.edu/~tijmen/tijmen_thesis.pdf)\r\n- github: [https://github.com/mrkulk/Unsupervised-Capsule-Network](https://github.com/mrkulk/Unsupervised-Capsule-Network)\r\n\r\n**Learning to Generate Chairs, Tables and Cars with Convolutional Networks**\r\n\r\n- arxiv: [http://arxiv.org/abs/1411.5928](http://arxiv.org/abs/1411.5928)\r\n\r\n**DRAW: A Recurrent Neural Network For Image Generation**\r\n\r\n- intro: Google DeepMind\r\n- arxiv: [http://arxiv.org/abs/1502.04623](http://arxiv.org/abs/1502.04623)\r\n- github: [https://github.com/vivanov879/draw](https://github.com/vivanov879/draw)\r\n- github(Theano): [https://github.com/jbornschein/draw](https://github.com/jbornschein/draw)\r\n- github(Lasagne): [https://github.com/skaae/lasagne-draw](https://github.com/skaae/lasagne-draw)\r\n- youtube: [https://www.youtube.com/watch?v=Zt-7MI9eKEo&hd=1](https://www.youtube.com/watch?v=Zt-7MI9eKEo&hd=1)\r\n- video: [http://pan.baidu.com/s/1gd3W6Fh](http://pan.baidu.com/s/1gd3W6Fh)\r\n\r\n**What is DRAW (Deep Recurrent Attentive Writer)?**\r\n\r\n![](http://kvfrans.com/content/images/2016/06/gencnn-afe135ff8d2725325a22455a488562b0e1cb7ac6a3f60b3cecb373fd043eb202.svg)\r\n\r\n- blog: [http://kvfrans.com/what-is-draw-deep-recurrent-attentive-writer/](http://kvfrans.com/what-is-draw-deep-recurrent-attentive-writer/)\r\n- github(tensorflow): [https://github.com/kvfrans/draw](https://github.com/kvfrans/draw)\r\n\r\n**Colorizing the DRAW Model**\r\n\r\n- blog: [http://kvfrans.com/colorizing-the-draw-model/](http://kvfrans.com/colorizing-the-draw-model/)\r\n- github: [https://github.com/kvfrans/draw-color](https://github.com/kvfrans/draw-color)\r\n\r\n**Understanding and Implementing Deepmind's DRAW Model**\r\n\r\n- blog: [http://evjang.com/articles/draw](http://evjang.com/articles/draw)\r\n- github: [https://github.com/ericjang/draw](https://github.com/ericjang/draw)\r\n\r\n**Generative Image Modeling Using Spatial LSTMs**\r\n\r\n- arxiv: [http://arxiv.org/abs/1506.03478](http://arxiv.org/abs/1506.03478)\r\n- github: [https://github.com/lucastheis/ride/](https://github.com/lucastheis/ride/)\r\n\r\n**Conditional generative adversarial nets for convolutional face generation**\r\n\r\n- paper: [http://www.foldl.me/uploads/2015/conditional-gans-face-generation/paper.pdf](http://www.foldl.me/uploads/2015/conditional-gans-face-generation/paper.pdf)\r\n- blog: [http://www.foldl.me/2015/conditional-gans-face-generation/](http://www.foldl.me/2015/conditional-gans-face-generation/)\r\n- github: [https://github.com/hans/adversarial](https://github.com/hans/adversarial)\r\n\r\n**Generating Images from Captions with Attention**\r\n\r\n- arxiv: [http://arxiv.org/abs/1511.02793](http://arxiv.org/abs/1511.02793)\r\n- github: [https://github.com/emansim/text2image](https://github.com/emansim/text2image)\r\n- demo: [http://www.cs.toronto.edu/~emansim/cap2im.html](http://www.cs.toronto.edu/~emansim/cap2im.html)\r\n\r\n**Attribute2Image: Conditional Image Generation from Visual Attributes**\r\n\r\n- intro: University of Michigan & Adobe Research & NEC Labs\r\n- project page: [https://sites.google.com/site/attribute2image/](https://sites.google.com/site/attribute2image/)\r\n- arxiv: [http://arxiv.org/abs/1512.00570](http://arxiv.org/abs/1512.00570)\r\n- github(Torch): [https://github.com/xcyan/eccv16_attr2img](https://github.com/xcyan/eccv16_attr2img)\r\n\r\n**Autoencoding beyond pixels using a learned similarity metric**\r\n\r\n- arxiv: [http://arxiv.org/abs/1512.09300](http://arxiv.org/abs/1512.09300)\r\n- demo: [http://algoalgebra.csa.iisc.ernet.in/deepimagine/](http://algoalgebra.csa.iisc.ernet.in/deepimagine/)\r\n- github: [https://github.com/andersbll/autoencoding_beyond_pixels](https://github.com/andersbll/autoencoding_beyond_pixels)\r\n- github(Tensorflow): [https://github.com/timsainb/Tensorflow-MultiGPU-VAE-GAN](https://github.com/timsainb/Tensorflow-MultiGPU-VAE-GAN)\r\n- video: [http://video.weibo.com/show?fid=1034:f00b4e5a34e8c1ebe78ccd00da95f9e0](http://video.weibo.com/show?fid=1034:f00b4e5a34e8c1ebe78ccd00da95f9e0)\r\n- github: [https://github.com/stitchfix/fauxtograph](https://github.com/stitchfix/fauxtograph)\r\n\r\n**Deep Visual Analogy-Making**\r\n\r\n![](https://raw.githubusercontent.com/carpedm20/visual-analogy-tensorflow/83893d866557239a890053b55cb7105ebf54045e/assets/model.png)\r\n\r\n- paper: [https://papers.nips.cc/paper/5845-deep-visual-analogy-making](https://papers.nips.cc/paper/5845-deep-visual-analogy-making)\r\n- github(Tensorflow): [https://github.com/carpedm20/visual-analogy-tensorflow](https://github.com/carpedm20/visual-analogy-tensorflow)\r\n- slides: [http://slideplayer.com/slide/9147672/](http://slideplayer.com/slide/9147672/)\r\n- mirror: [http://pan.baidu.com/s/1pKgrdnt](http://pan.baidu.com/s/1pKgrdnt)\r\n\r\n**Pixel Recurrent Neural Networks**\r\n\r\n- intro: Google DeepMind. ICML 2016 best paper. PixelRNN\r\n- arxiv: [http://arxiv.org/abs/1601.06759](http://arxiv.org/abs/1601.06759)\r\n- github: [https://github.com/igul222/pixel_rnn](https://github.com/igul222/pixel_rnn)\r\n- github(Tensorflow): [https://github.com/carpedm20/pixel-rnn-tensorflow](https://github.com/carpedm20/pixel-rnn-tensorflow)\r\n- notes(by Hugo Larochelle): [https://www.evernote.com/shard/s189/sh/fdf61a28-f4b6-491b-bef1-f3e148185b18/aba21367d1b3730d9334ed91d3250848](https://www.evernote.com/shard/s189/sh/fdf61a28-f4b6-491b-bef1-f3e148185b18/aba21367d1b3730d9334ed91d3250848)\r\n- video(by Hugo Larochelle): [https://www.periscope.tv/hugo_larochelle/1ypKdnMkjBnJW](https://www.periscope.tv/hugo_larochelle/1ypKdnMkjBnJW)\r\n\r\n**Generating images with recurrent adversarial networks**\r\n\r\n- arxiv: [http://arxiv.org/abs/1602.05110](http://arxiv.org/abs/1602.05110)\r\n- github: [https://github.com/jiwoongim/GRAN](https://github.com/jiwoongim/GRAN)\r\n\r\n**Pixel-Level Domain Transfer**\r\n\r\n- intro: ECCV 2016\r\n- github(Torch): [https://github.com/fxia22/PixelDTGAN](https://github.com/fxia22/PixelDTGAN)\r\n- author page(Code and dataset): [https://dgyoo.github.io/](https://dgyoo.github.io/)\r\n\r\n**Generative Adversarial Text to Image Synthesis**\r\n\r\n![](https://raw.githubusercontent.com/reedscot/icml2016/master/images/dcgan_network.jpg)\r\n\r\n- intro: ICML 2016\r\n- arxiv: [http://arxiv.org/abs/1605.05396](http://arxiv.org/abs/1605.05396)\r\n- project page: [https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/embeddings-for-image-classification/generative-adversarial-text-to-image-synthesis/](https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/embeddings-for-image-classification/generative-adversarial-text-to-image-synthesis/)\r\n- github: [https://github.com/reedscot/icml2016](https://github.com/reedscot/icml2016)\r\n- code+dataset: [http://datasets.d2.mpi-inf.mpg.de/akata/cub_txt.tar.gz](http://datasets.d2.mpi-inf.mpg.de/akata/cub_txt.tar.gz)\r\n\r\n**Conditional Image Generation with PixelCNN Decoders**\r\n\r\n- intro: Google DeepMind. PixelCNN 2.0\r\n- arxiv: [http://arxiv.org/abs/1606.05328](http://arxiv.org/abs/1606.05328)\r\n- github(Theano): [https://github.com/kundan2510/pixelCNN](https://github.com/kundan2510/pixelCNN)\r\n- gtihub(Torch): [https://github.com/dritchie/pixelCNN](https://github.com/dritchie/pixelCNN)\r\n- github(Tensorflow): [https://github.com/anantzoid/Conditional-PixelCNN-decoder](https://github.com/anantzoid/Conditional-PixelCNN-decoder)\r\n\r\n**Inverting face embeddings with convolutional neural networks**\r\n\r\n- arxiv: [http://arxiv.org/abs/1606.04189](http://arxiv.org/abs/1606.04189)\r\n- github: [https://github.com/pavelgonchar/face-transfer-tensorflow](https://github.com/pavelgonchar/face-transfer-tensorflow)\r\n\r\n**Unsupervised Cross-Domain Image Generation**\r\n\r\n![](https://raw.githubusercontent.com/yunjey/dtn-tensorflow/master/jpg/dtn.jpg)\r\n\r\n- intro: Facebook AI Research. Domain Transfer Network (DTN)\r\n- arxiv: [https://arxiv.org/abs/1611.02200](https://arxiv.org/abs/1611.02200)\r\n- github(TensorFlow): [https://github.com/yunjey/dtn-tensorflow](https://github.com/yunjey/dtn-tensorflow)\r\n\r\n**PixelCNN++: A PixelCNN Implementation with Discretized Logistic Mixture Likelihood and Other Modifications**\r\n\r\n- intro: OpenAI\r\n- arxiv: [https://arxiv.org/abs/1701.05517](https://arxiv.org/abs/1701.05517)\r\n- paper: [http://openreview.net/pdf?id=BJrFC6ceg](http://openreview.net/pdf?id=BJrFC6ceg)\r\n- github: [https://github.com/openai/pixel-cnn](https://github.com/openai/pixel-cnn)\r\n\r\n**Generating Interpretable Images with Controllable Structure**\r\n\r\n- intro: Google DeepMind\r\n- paper: [http://www.scottreed.info/files/iclr2017.pdf](http://www.scottreed.info/files/iclr2017.pdf)\r\n\r\n**Learning to Generate Images of Outdoor Scenes from Attributes and Semantic Layouts**\r\n\r\n- arxiv: [https://arxiv.org/abs/1612.00215](https://arxiv.org/abs/1612.00215)\r\n\r\n**Plug & Play Generative Networks: Conditional Iterative Generation of Images in Latent Space**\r\n\r\n- intro: University of Wyoming & Geometric Intelligence & Montreal Institute for Learning Algorithms & University of Freiburg\r\n- project page: [http://www.evolvingai.org/ppgn](http://www.evolvingai.org/ppgn)\r\n- paper: [http://www.evolvingai.org/files/nguyen2016ppgn_v1.pdf](http://www.evolvingai.org/files/nguyen2016ppgn_v1.pdf)\r\n- github: [https://github.com/Evolving-AI-Lab/ppgn](https://github.com/Evolving-AI-Lab/ppgn)\r\n\r\n**Image Generation and Editing with Variational Info Generative AdversarialNetworks**\r\n\r\n- arxiv: [https://arxiv.org/abs/1701.04568](https://arxiv.org/abs/1701.04568)\r\n\r\n**DeepFace: Face Generation using Deep Learning**\r\n\r\n- arxiv: [https://arxiv.org/abs/1701.01876](https://arxiv.org/abs/1701.01876)\r\n\r\n**Multi-View Image Generation from a Single-View**\r\n\r\n- intro: Southwest Jiaotong University & National University of Singapore\r\n- arxiv: [https://arxiv.org/abs/1704.04886](https://arxiv.org/abs/1704.04886)\r\n\r\n**Generative Cooperative Net for Image Generation and Data Augmentation**\r\n\r\n[https://arxiv.org/abs/1705.02887](https://arxiv.org/abs/1705.02887)\r\n\r\n**Statistics of Deep Generated Images**\r\n\r\n[https://arxiv.org/abs/1708.02688](https://arxiv.org/abs/1708.02688)\r\n\r\n**Sketch-to-Image Generation Using Deep Contextual Completion**\r\n\r\n[https://arxiv.org/abs/1711.08972](https://arxiv.org/abs/1711.08972)\r\n\r\n**Energy-relaxed Wassertein GANs(EnergyWGAN): Towards More Stable and High Resolution Image Generation**\r\n\r\n[https://arxiv.org/abs/1712.01026](https://arxiv.org/abs/1712.01026)\r\n\r\n**Spatial PixelCNN: Generating Images from Patches**\r\n\r\n[https://arxiv.org/abs/1712.00714](https://arxiv.org/abs/1712.00714)\r\n\r\n**Visual to Sound: Generating Natural Sound for Videos in the Wild**\r\n\r\n- intro: University of North Carolina at Chapel Hill & Adobe Research\r\n- project page: [http://bvision11.cs.unc.edu/bigpen/yipin/visual2sound_webpage/visual2sound.html](http://bvision11.cs.unc.edu/bigpen/yipin/visual2sound_webpage/visual2sound.html)\r\n- arxiv: [https://arxiv.org/abs/1712.01393](https://arxiv.org/abs/1712.01393)\r\n\r\n**Semi-supervised FusedGAN for Conditional Image Generation**\r\n\r\n[https://arxiv.org/abs/1801.05551](https://arxiv.org/abs/1801.05551)\r\n\r\n**Image Transformer**\r\n\r\n- intro: Google Brain & UC Berkeley\r\n- arxiv: [https://arxiv.org/abs/1802.05751](https://arxiv.org/abs/1802.05751)\r\n\r\n**Unpaired Multi-Domain Image Generation via Regularized Conditional GANs**\r\n\r\n[https://arxiv.org/abs/1805.02456](https://arxiv.org/abs/1805.02456)\r\n\r\n**Transferring GANs: generating images from limited data**\r\n\r\n- intro: Universitat Aut`onoma de Barcelona\r\n- arxiv: [https://arxiv.org/abs/1805.01677](https://arxiv.org/abs/1805.01677)\r\n- github: [https://github.com/yaxingwang/Transferring-GANs](https://github.com/yaxingwang/Transferring-GANs)\r\n\r\n**Cross Domain Image Generation through Latent Space Exploration with Adversarial Loss**\r\n\r\n[https://arxiv.org/abs/1805.10130](https://arxiv.org/abs/1805.10130)\r\n\r\n# Face Image Generation\r\n\r\n**Fader Networks: Manipulating Images by Sliding Attributes**\r\n\r\n- intro: NIPS 2017. Facebook AI Research & Sorbonne Université\r\n- arxiv: [https://arxiv.org/abs/1706.00409](https://arxiv.org/abs/1706.00409)\r\n- github: [https://github.com//facebookresearch/FaderNetworks](https://github.com//facebookresearch/FaderNetworks)\r\n\r\n# Person Image Generation\r\n\r\n**Disentangled Person Image Generation**\r\n\r\n- intro: CVPR 2018 spotlight\r\n- intro: KU-Leuven/PSI & Max Planck Institute for Informatics & ETH Zurich\r\n- arxiv: [https://arxiv.org/abs/1712.02621](https://arxiv.org/abs/1712.02621)\r\n\r\n**Pose Guided Person Image Generation**\r\n\r\n- intro: NIPS 2017\r\n- arxiv: [https://arxiv.org/abs/1705.09368](https://arxiv.org/abs/1705.09368)\r\n- poster: [https://homes.esat.kuleuven.be/~liqianma/NIPS17_PG2/NIPS17_PG2_poster.pdf](https://homes.esat.kuleuven.be/~liqianma/NIPS17_PG2/NIPS17_PG2_poster.pdf)\r\n\r\n**Deformable GANs for Pose-based Human Image Generation**\r\n\r\n- intro: University of Trento & Inria Grenoble Rhone-Alpes\r\n- arxiv: [https://arxiv.org/abs/1801.00055](https://arxiv.org/abs/1801.00055)\r\n- github: [https://github.com/AliaksandrSiarohin/pose-gan](https://github.com/AliaksandrSiarohin/pose-gan)\r\n\r\n**Unpaired Pose Guided Human Image Generation**\r\n\r\n[https://arxiv.org/abs/1901.02284](https://arxiv.org/abs/1901.02284)\r\n\r\n# Video Generation\r\n\r\n**MoCoGAN: Decomposing Motion and Content for Video Generation**\r\n\r\n- arxiv: [https://arxiv.org/abs/1707.04993](https://arxiv.org/abs/1707.04993)\r\n- github: [https://github.com/sergeytulyakov/mocogan](https://github.com/sergeytulyakov/mocogan)\r\n- github(PyTorch): [https://github.com/DLHacks/mocogan](https://github.com/DLHacks/mocogan)\r\n\r\n**Attentive Semantic Video Generation using Captions**\r\n\r\n[https://arxiv.org/abs/1708.05980](https://arxiv.org/abs/1708.05980)\r\n\r\n**Hierarchical Video Generation from Orthogonal Information: Optical Flow and Texture**\r\n\r\n- intro: AAAI2018. The University of Tokyo\r\n- project page: [http://www.mi.t.u-tokyo.ac.jp/assets/publication/hierarchical_video_generation_sup/](http://www.mi.t.u-tokyo.ac.jp/assets/publication/hierarchical_video_generation_sup/)\r\n- arxiv: [https://arxiv.org/abs/1711.09618](https://arxiv.org/abs/1711.09618)\r\n\r\n**Towards an Understanding of Our World by GANing Videos in the Wild**\r\n\r\n- intro: ETH Zurich\r\n- arxiv: [https://arxiv.org/abs/1711.11453](https://arxiv.org/abs/1711.11453)\r\n- github: [https://github.com//bernhard2202/improved-video-gan](https://github.com//bernhard2202/improved-video-gan)\r\n\r\n**Video Generation from Single Semantic Label Map**\r\n\r\n- intro: CVPR 2019\r\n- arxiv: [https://arxiv.org/abs/1903.04480](https://arxiv.org/abs/1903.04480)\r\n- github: [https://github.com/junting/seg2vid](https://github.com/junting/seg2vid)\r\n\r\n# Deep Generative Model\r\n\r\n**Digit Fantasies by a Deep Generative Model**\r\n\r\n- demo: [http://www.dpkingma.com/sgvb_mnist_demo/demo.html](http://www.dpkingma.com/sgvb_mnist_demo/demo.html)\r\n\r\n**Conditional generative adversarial nets for convolutional face generation**\r\n\r\n- paper: [http://www.foldl.me/uploads/2015/conditional-gans-face-generation/paper.pdf](http://www.foldl.me/uploads/2015/conditional-gans-face-generation/paper.pdf)\r\n- blog: [http://www.foldl.me/2015/conditional-gans-face-generation/](http://www.foldl.me/2015/conditional-gans-face-generation/)\r\n- github: [https://github.com/hans/adversarial](https://github.com/hans/adversarial)\r\n\r\n**Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks**\r\n\r\n- intro: NIPS 2015\r\n- project page: [http://soumith.ch/eyescream/](http://soumith.ch/eyescream/)\r\n- homepage: [http://www.cs.nyu.edu/~denton/](http://www.cs.nyu.edu/~denton/)\r\n- arxiv: [http://arxiv.org/abs/1506.05751](http://arxiv.org/abs/1506.05751)\r\n- code: [http://soumith.ch/eyescream/](http://soumith.ch/eyescream/)\r\n- notes: [http://colinraffel.com/wiki/deep_generative_image_models_using_a_laplacian_pyramid_of_adversarial_networks](http://colinraffel.com/wiki/deep_generative_image_models_using_a_laplacian_pyramid_of_adversarial_networks)\r\n\r\n**Torch convolutional GAN: Generating Faces with Torch**\r\n\r\n- blog: [http://torch.ch/blog/2015/11/13/gan.html](http://torch.ch/blog/2015/11/13/gan.html)\r\n- github: [https://github.com/skaae/torch-gan](https://github.com/skaae/torch-gan)\r\n\r\n**One-Shot Generalization in Deep Generative Models**\r\n\r\n- intro: Google DeepMind. ICML 2016\r\n- arxiv: [http://arxiv.org/abs/1603.05106](http://arxiv.org/abs/1603.05106)\r\n\r\n**Generative Image Modeling using Style and Structure Adversarial Networks**\r\n\r\n- arxiv: [http://arxiv.org/abs/1603.05631](http://arxiv.org/abs/1603.05631)\r\n- github: [https://github.com/xiaolonw/ss-gan](https://github.com/xiaolonw/ss-gan)\r\n\r\n**Synthesizing Dynamic Textures and Sounds by Spatial-Temporal Generative ConvNet**\r\n\r\n![](http://www.stat.ucla.edu/~jxie/STGConvNet/STGConvNet_file/video/water_stone1.gif)\r\n\r\n- project page: [http://www.stat.ucla.edu/~jxie/STGConvNet/STGConvNet.html](http://www.stat.ucla.edu/~jxie/STGConvNet/STGConvNet.html)\r\n- paper: [http://www.stat.ucla.edu/~jxie/STGConvNet/STGConvNet_file/doc/STGConvNet.pdf](http://www.stat.ucla.edu/~jxie/STGConvNet/STGConvNet_file/doc/STGConvNet.pdf)\r\n\r\n**Synthesizing the preferred inputs for neurons in neural networks via deep generator networks**\r\n\r\n- arxiv: [http://arxiv.org/abs/1605.09304](http://arxiv.org/abs/1605.09304)\r\n\r\n**ArtGAN: Artwork Synthesis with Conditional Categorial GANs**\r\n\r\n- arxiv: [https://arxiv.org/abs/1702.03410](https://arxiv.org/abs/1702.03410)\r\n\r\n**Learning to Generate Chairs with Generative Adversarial Nets**\r\n\r\n[https://arxiv.org/abs/1705.10413](https://arxiv.org/abs/1705.10413)\r\n\r\n# Blogs\r\n\r\n**Torch convolutional GAN: Generating Faces with Torch**\r\n\r\n- blog: [http://torch.ch/blog/2015/11/13/gan.html](http://torch.ch/blog/2015/11/13/gan.html)\r\n- github: [https://github.com/skaae/torch-gan](https://github.com/skaae/torch-gan)\r\n\r\n**Generating Large Images from Latent Vectors**\r\n\r\n[http://blog.otoro.net/2016/04/01/generating-large-images-from-latent-vectors/](http://blog.otoro.net/2016/04/01/generating-large-images-from-latent-vectors/)\r\n\r\n**Generating Faces with Deconvolution Networks**\r\n\r\n![](https://raw.githubusercontent.com/zo7/facegen/master/img/example.gif)\r\n\r\n- blog: [https://zo7.github.io/blog/2016/09/25/generating-faces.html](https://zo7.github.io/blog/2016/09/25/generating-faces.html)\r\n- github: [https://github.com/zo7/facegen](https://github.com/zo7/facegen)\r\n\r\n**Attention Models in Image and Caption Generation**\r\n\r\n- blog: [https://casmls.github.io/general/2016/10/16/attention_model.html](https://casmls.github.io/general/2016/10/16/attention_model.html)\r\n\r\n**Deconvolution and Checkerboard Artifacts**\r\n\r\n- :star::star::star::star::star:\r\n- intro: Google Brain & Université de Montréal\r\n- blog: [http://distill.pub/2016/deconv-checkerboard/](http://distill.pub/2016/deconv-checkerboard/)\r\n\r\n# Projects\r\n\r\n**Generate cat images with neural networks**\r\n\r\n- github: [https://github.com/aleju/cat-generator](https://github.com/aleju/cat-generator)\r\n\r\n**TF-VAE-GAN-DRAW**\r\n\r\n- intro: A collection of generative methods implemented with TensorFlow \r\n(Deep Convolutional Generative Adversarial Networks (DCGAN), \r\nVariational Autoencoder (VAE) \r\nand DRAW: A Recurrent Neural Network For Image Generation).\r\n- github: [https://github.com/ikostrikov/TensorFlow-VAE-GAN-DRAW](https://github.com/ikostrikov/TensorFlow-VAE-GAN-DRAW)\r\n\r\n**Generating Large Images from Latent Vectors**\r\n\r\n![](http://blog.otoro.net/assets/20160401/png/generator_example.png)\r\n\r\n- project page: [http://blog.otoro.net/2016/04/01/generating-large-images-from-latent-vectors/](http://blog.otoro.net/2016/04/01/generating-large-images-from-latent-vectors/)\r\n- github: [https://github.com/hardmaru/cppn-gan-vae-tensorflow](https://github.com/hardmaru/cppn-gan-vae-tensorflow)\r\n\r\n**Generating Large Images from Latent Vectors - Part Two**\r\n\r\n- project page: [http://blog.otoro.net/2016/06/02/generating-large-images-from-latent-vectors-part-two/](http://blog.otoro.net/2016/06/02/generating-large-images-from-latent-vectors-part-two/)\r\n- github: [https://github.com/hardmaru/resnet-cppn-gan-tensorflow](https://github.com/hardmaru/resnet-cppn-gan-tensorflow)\r\n\r\n**Analyzing 50k fonts using deep neural networks**\r\n\r\n- blog: [https://erikbern.com/2016/01/21/analyzing-50k-fonts-using-deep-neural-networks/](https://erikbern.com/2016/01/21/analyzing-50k-fonts-using-deep-neural-networks/)\r\n- github: [https://github.com/erikbern/deep-fonts](https://github.com/erikbern/deep-fonts)\r\n\r\n**Generate cat images with neural networks**\r\n\r\n- intro: GAN, spatial transformers, weight initialization and LeakyReLUs.\r\n- github: [https://github.com/aleju/cat-generator](https://github.com/aleju/cat-generator)\r\n\r\n**Generate human faces with neural networks**\r\n\r\n- github: [https://github.com/aleju/face-generator](https://github.com/aleju/face-generator)\r\n\r\n**A TensorFlow implementation of DeepMind's WaveNet paper**\r\n\r\n- intro: This is a TensorFlow implementation of the WaveNet generative neural network architecture for image generation.\r\n- github: [https://github.com/Zeta36/tensorflow-image-wavenet](https://github.com/Zeta36/tensorflow-image-wavenet)\r\n","excerpt":"Papers Optimizing Neural Networks That Generate Images intro: 2014 PhD thesis paper :  http://www.cs.toronto.edu/~tijmen/tijmen_thesis.pdf …","outboundReferences":[],"inboundReferences":[]},"tagsOutbound":{"nodes":[]}},"pageContext":{"tags":[],"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-audio-image-video-generation/","sidebarItems":[{"title":"Categories","items":[{"title":"Commercial","url":"","items":[{"title":"Commercial Structure","url":"/Commercial/Commercial Structure/","items":[]},{"title":"Community of Practice","url":"/Commercial/Community of Practice/","items":[]},{"title":"Domains","url":"/Commercial/Domains/","items":[]},{"title":"Webizen Alliance","url":"/Commercial/Webizen Alliance/","items":[]}]},{"title":"Core Services","url":"","items":[{"title":"Decentralised Ontologies","url":"/Core Services/Decentralised Ontologies/","items":[]},{"title":"Permissive Commons","url":"/Core Services/Permissive Commons/","items":[]},{"title":"Safety Protocols","url":"","items":[{"title":"Safety Protocols","url":"/Core Services/Safety Protocols/Safety Protocols/","items":[]},{"title":"Social Factors","url":"","items":[{"title":"Best Efforts","url":"/Core Services/Safety Protocols/Social Factors/Best Efforts/","items":[]},{"title":"Ending Digital Slavery","url":"/Core Services/Safety Protocols/Social Factors/Ending Digital Slavery/","items":[]},{"title":"Freedom of Thought","url":"/Core Services/Safety Protocols/Social Factors/Freedom of Thought/","items":[]},{"title":"No Golden Handcuffs","url":"/Core Services/Safety Protocols/Social Factors/No Golden Handcuffs/","items":[]},{"title":"Relationships (Social)","url":"/Core Services/Safety Protocols/Social Factors/Relationships (Social)/","items":[]},{"title":"Social Attack Vectors","url":"/Core Services/Safety Protocols/Social Factors/Social Attack Vectors/","items":[]},{"title":"The Webizen Charter","url":"/Core Services/Safety Protocols/Social Factors/The Webizen Charter/","items":[]}]},{"title":"Values Credentials","url":"/Core Services/Safety Protocols/Values Credentials/","items":[]}]},{"title":"Temporal Semantics","url":"/Core Services/Temporal Semantics/","items":[]},{"title":"Verifiable Claims & Credentials","url":"/Core Services/Verifiable Claims & Credentials/","items":[]},{"title":"Webizen Socio-Economics","url":"","items":[{"title":"Biosphere Ontologies","url":"/Core Services/Webizen Socio-Economics/Biosphere Ontologies/","items":[]},{"title":"Centricity","url":"/Core Services/Webizen Socio-Economics/Centricity/","items":[]},{"title":"Currencies","url":"/Core Services/Webizen Socio-Economics/Currencies/","items":[]},{"title":"SocioSphere Ontologies","url":"/Core Services/Webizen Socio-Economics/SocioSphere Ontologies/","items":[]},{"title":"Sustainable Development Goals (ESG)","url":"/Core Services/Webizen Socio-Economics/Sustainable Development Goals (ESG)/","items":[]}]}]},{"title":"Core Technologies","url":"","items":[{"title":"AUTH","url":"","items":[{"title":"Authentication Fabric","url":"/Core Technologies/AUTH/Authentication Fabric/","items":[]}]},{"title":"Webizen App Spec","url":"","items":[{"title":"SemWebSpecs","url":"","items":[{"title":"Core Ontologies","url":"","items":[{"title":"FOAF","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/FOAF/","items":[]},{"title":"General Ontology Information","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/General Ontology Information/","items":[]},{"title":"Human Rights Ontologies","url":"","items":[{"title":"UDHR","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/Human Rights Ontologies/UDHR/","items":[]}]},{"title":"MD-RDF Ontologies","url":"","items":[{"title":"DataTypesOntology (DTO) Core","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/MD-RDF Ontologies/DataTypes Ontology/","items":[]},{"title":"Friend of a Friend (FOAF) Core","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/MD-RDF Ontologies/FOAF/","items":[]}]},{"title":"OWL","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/OWL/","items":[]},{"title":"RDF Schema 1.1","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/RDFS/","items":[]},{"title":"Sitemap","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/Sitemap/","items":[]},{"title":"SKOS","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/SKOS/","items":[]},{"title":"SOIC","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/SOIC/","items":[]}]},{"title":"Semantic Web - An Introduction","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Semantic Web - An Introduction/","items":[]},{"title":"SemWeb-AUTH","url":"","items":[{"title":"WebID-OIDC","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-OIDC/","items":[]},{"title":"WebID-RSA","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-RSA/","items":[]},{"title":"WebID-TLS","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-TLS/","items":[]}]},{"title":"Sparql","url":"","items":[{"title":"Sparql Family","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Sparql/Sparql Family/","items":[]}]},{"title":"W3C Specifications","url":"","items":[{"title":"Linked Data Fragments","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Fragments/","items":[]},{"title":"Linked Data Notifications","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Notifications/","items":[]},{"title":"Linked Data Platform","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Platform/","items":[]},{"title":"Linked Media Fragments","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Media Fragments/","items":[]},{"title":"RDF","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/RDF/","items":[]},{"title":"Web Access Control (WAC)","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Web Access Control (WAC)/","items":[]},{"title":"Web Of Things","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Web Of Things/","items":[]},{"title":"WebID","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/WebID/","items":[]}]}]},{"title":"Webizen App Spec 1.0","url":"/Core Technologies/Webizen App Spec/Webizen App Spec 1.0/","items":[]},{"title":"WebSpec","url":"","items":[{"title":"HTML SPECS","url":"/Core Technologies/Webizen App Spec/WebSpec/HTML SPECS/","items":[]},{"title":"Query Interfaces","url":"","items":[{"title":"GraphQL","url":"/Core Technologies/Webizen App Spec/WebSpec/Query Interfaces/GraphQL/","items":[]}]},{"title":"WebPlatformTools","url":"","items":[{"title":"WebAuthn","url":"/Core Technologies/Webizen App Spec/WebSpec/WebPlatformTools/WebAuthn/","items":[]},{"title":"WebDav","url":"/Core Technologies/Webizen App Spec/WebSpec/WebPlatformTools/WebDav/","items":[]}]}]}]}]},{"title":"Database Requirements","url":"","items":[{"title":"Database Alternatives","url":"","items":[{"title":"Akutan","url":"/Database requirements/Database Alternatives/akutan/","items":[]},{"title":"CayleyGraph","url":"/Database requirements/Database Alternatives/CayleyGraph/","items":[]}]},{"title":"Database Methods","url":"","items":[{"title":"GraphQL","url":"/Database requirements/Database methods/GraphQL/","items":[]},{"title":"Sparql","url":"/Database requirements/Database methods/Sparql/","items":[]}]}]},{"title":"Host Service Requirements","url":"","items":[{"title":"Domain Hosting","url":"/Host Service Requirements/Domain Hosting/","items":[]},{"title":"Email Services","url":"/Host Service Requirements/Email Services/","items":[]},{"title":"LD_PostOffice_SemanticMGR","url":"/Host Service Requirements/LD_PostOffice_SemanticMGR/","items":[]},{"title":"Media Processing","url":"/Host Service Requirements/Media Processing/","items":[{"title":"Ffmpeg","url":"/Host Service Requirements/Media Processing/ffmpeg/","items":[]},{"title":"Opencv","url":"/Host Service Requirements/Media Processing/opencv/","items":[]}]},{"title":"Website Host","url":"/Host Service Requirements/Website Host/","items":[]}]},{"title":"ICT Stack","url":"","items":[{"title":"General References","url":"","items":[{"title":"List of Protocols ISO Model","url":"/ICT Stack/General References/List of Protocols ISO model/","items":[]}]},{"title":"Internet","url":"","items":[{"title":"Internet Stack","url":"/ICT Stack/Internet/Internet Stack/","items":[]}]}]},{"title":"Implementation V1","url":"","items":[{"title":"App-Design-Sdk-V1","url":"","items":[{"title":"Core Apps","url":"","items":[{"title":"Agent Directory","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Agent Directory/","items":[]},{"title":"Credentials & Contracts Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Credentials & Contracts Manager/","items":[]},{"title":"File (Package) Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/File (package) Manager/","items":[]},{"title":"Temporal Apps","url":"","items":[{"title":"Calendar","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Temporal Apps/Calendar/","items":[]},{"title":"Timeline Interface","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Temporal Apps/Timeline Interface/","items":[]}]},{"title":"Webizen Apps (V1)","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Webizen Apps (v1)/","items":[]},{"title":"Webizen Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Webizen Manager/","items":[]}]},{"title":"Data Applications","url":"/Implementation V1/App-design-sdk-v1/Data Applications/","items":[]},{"title":"Design Goals","url":"","items":[{"title":"Design Goals Overview","url":"/Implementation V1/App-design-sdk-v1/Design Goals/Design Goals Overview/","items":[]}]}]},{"title":"Edge","url":"","items":[{"title":"Webizen Local App Functionality","url":"/Implementation V1/edge/Webizen Local App Functionality/","items":[]}]},{"title":"GoLang Libraries","url":"/Implementation V1/GoLang Libraries/","items":[]},{"title":"Implementation V1 Summary","url":"/Implementation V1/Implementation V1 Summary/","items":[]},{"title":"Vps","url":"","items":[{"title":"Server Functionality Summary (VPS)","url":"/Implementation V1/vps/Server Functionality Summary (VPS)/","items":[]}]},{"title":"Webizen 1.0","url":"/Implementation V1/Webizen 1.0/","items":[]},{"title":"Webizen-Connect","url":"","items":[{"title":"Social Media APIs","url":"/Implementation V1/Webizen-Connect/Social Media APIs/","items":[]},{"title":"Webizen-Connect (Summary)","url":"/Implementation V1/Webizen-Connect/Webizen-Connect (summary)/","items":[]}]}]},{"title":"Non-HTTP(s) Protocols","url":"","items":[{"title":"DAT","url":"/Non-HTTP(s) Protocols/DAT/","items":[]},{"title":"GIT","url":"/Non-HTTP(s) Protocols/GIT/","items":[]},{"title":"GUNECO","url":"/Non-HTTP(s) Protocols/GUNECO/","items":[]},{"title":"IPFS","url":"/Non-HTTP(s) Protocols/IPFS/","items":[]},{"title":"Lightning Network","url":"/Non-HTTP(s) Protocols/Lightning Network/","items":[]},{"title":"Non-HTTP(s) Protocols (& DLTs)","url":"/Non-HTTP(s) Protocols/Non-HTTP(s) Protocols (& DLTs)/","items":[]},{"title":"WebRTC","url":"/Non-HTTP(s) Protocols/WebRTC/","items":[]},{"title":"WebSockets","url":"/Non-HTTP(s) Protocols/WebSockets/","items":[]},{"title":"WebTorrent","url":"/Non-HTTP(s) Protocols/WebTorrent/","items":[]}]},{"title":"Old-Work-Archives","url":"","items":[{"title":"2018-Webizen-Net-Au","url":"","items":[{"title":"_Link_library_links","url":"","items":[{"title":"Link Library","url":"/old-work-archives/2018-webizen-net-au/_link_library_links/2018-09-23-wp-linked-data/","items":[]}]},{"title":"_Posts","url":"","items":[{"title":"About W3C","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-27-about-w3c/","items":[]},{"title":"Advanced Functions &#8211; Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-16-advanced-functions-facebook-pages/","items":[]},{"title":"Advanced Search &#038; Discovery Tips","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-advanced-search-discovery-tips/","items":[]},{"title":"An introduction to Virtual Machines.","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-an-introduction-to-virtual-machines/","items":[]},{"title":"Basic Media Analysis &#8211; Part 1 (Audio)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-30-media-analysis-part-1-audio/","items":[]},{"title":"Basic Media Analysis &#8211; Part 2 (visual)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-31-media-analysis-part-2-visual/","items":[]},{"title":"Basic Media Analysis &#8211; Part 3 (Text &#038; Metadata)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-01-01-basic-media-analysis-part-3-text-metadata/","items":[]},{"title":"Building an Economy based upon Knowledge Equity.","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-25-building-an-economy-based-upon-knowledge-equity/","items":[]},{"title":"Choice of Law","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-26-choice-of-law/","items":[]},{"title":"Contemplation of the ITU Dubai Meeting and the Future of the Internet","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-19-contemplation-of-the-itu-dubai-meeting-and-the-future-of-the-internet/","items":[]},{"title":"Creating a Presence &#8211; Online","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-creating-a-presence-online/","items":[]},{"title":"Credentials and Payments by Manu Sporny","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-credentials-and-payments-by-manu-sporny/","items":[]},{"title":"Data Recovery &#038; Collection: Mobile Devices","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-28-mobile-devices-data-recovery-collection/","items":[]},{"title":"Data Recovery: Laptop &#038; Computers","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-28-data-recovery-laptop-computers/","items":[]},{"title":"Decentralized Web Conference 2016","url":"/old-work-archives/2018-webizen-net-au/_posts/2016-06-09-decentralized-web-2016/","items":[]},{"title":"Decentralized Web Summit 2018","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-decentralized-web-summit-2018/","items":[]},{"title":"Does Anonymity exist?","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-does-anonymity-exist/","items":[]},{"title":"Downloading My Data from Social Networks","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-downloading-my-data-from-social-networks/","items":[]},{"title":"Events","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-events/","items":[]},{"title":"Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-16-facebook-pages/","items":[]},{"title":"Google Tracking Data (geolocation)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-google-tracking/","items":[]},{"title":"Human Consciousness","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-human-consciousness/","items":[]},{"title":"Image Recgonition Video Playlist","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-image-recgonition-video-playlist/","items":[]},{"title":"Inferencing (introduction)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-inferencing-introduction/","items":[]},{"title":"Introduction to AI","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-introduction-to-ai/","items":[]},{"title":"Introduction to Linked Data","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-introduction-to-linked-data/","items":[]},{"title":"Introduction to Maltego","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-introduction-to-maltego/","items":[]},{"title":"Introduction to Ontologies","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-ontologies-intro/","items":[]},{"title":"Introduction to Semantic Web","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-introduction-to-semantic-web/","items":[]},{"title":"Knowledge Capital","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-10-17-knowledge-capital/","items":[]},{"title":"Logo&#8217;s, Style Guides and Artwork","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-logos-style-guides-and-artwork/","items":[]},{"title":"MindMapping &#8211; Setting-up a business &#8211; Identity","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-mindmapping-setting-up-a-business-identity/","items":[]},{"title":"Openlink Virtuoso","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-openlink-virtuoso/","items":[]},{"title":"OpenRefine","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-74-2/","items":[]},{"title":"Projects, Customers and Invoicing &#8211; Web-Services for Startups","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-projects-customers-and-invoicing-web-services-for-startups/","items":[]},{"title":"RWW &#038; some Solid history","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-rww-some-solid-history/","items":[]},{"title":"Semantic Web (An Intro)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-semantic-web-an-intro/","items":[]},{"title":"Setting-up Twitter","url":"/old-work-archives/2018-webizen-net-au/_posts/2013-06-07-setting-up-twitter/","items":[]},{"title":"Social Encryption: An Introduction","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-25-social-encryption-an-introduction/","items":[]},{"title":"Stock Content","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-stock-content/","items":[]},{"title":"The WayBack Machine","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-27-the-wayback-machine/","items":[]},{"title":"Tim Berners Lee &#8211; Turing Lecture","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-05-29-tim-berners-lee-turing-lecture/","items":[]},{"title":"Tools of Trade","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-tools-of-trade/","items":[]},{"title":"Trust Factory 2017","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-trust-factory-2017/","items":[]},{"title":"Verifiable Claims (An Introduction)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-vc-intro/","items":[]},{"title":"Web of Things &#8211; an Introduction","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-web-of-things-an-introduction/","items":[]},{"title":"Web-Persistence","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-web-persistence/","items":[]},{"title":"Web-Services &#8211; Marketing Tools","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-web-services-marketing-tools/","items":[]},{"title":"Website Templates","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-templates/","items":[]},{"title":"What is Linked Data?","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-what-is-linked-data/","items":[]},{"title":"What is Open Source Intelligence?","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-what-is-osint/","items":[]},{"title":"WiX","url":"/old-work-archives/2018-webizen-net-au/_posts/2013-01-01-wix/","items":[]}]},{"title":"about","url":"/old-work-archives/2018-webizen-net-au/about/","items":[{"title":"About The Author","url":"/old-work-archives/2018-webizen-net-au/about/about-the-author/","items":[]},{"title":"Applied Theory: Applications for a Human Centric Web","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/","items":[{"title":"Digital Receipts","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/digital-receipts/","items":[]},{"title":"Fake News: Considerations → Principles → The Institution of Socio &#8211; Economic Values","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations-%e2%86%92-principles-%e2%86%92-the-institution-of-socio-economic-values/","items":[{"title":"Solutions to FakeNews: Linked-Data, Ontologies and Verifiable Claims","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations-%e2%86%92-principles-%e2%86%92-the-institution-of-socio-economic-values/solutions-to-fakenews-linked-data-ontologies-and-verifiable-claims/","items":[]}]},{"title":"Healthy Living Economy","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/healthy-living-economy/","items":[]},{"title":"HyperMedia Solutions &#8211; Adapting HbbTV V2","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/","items":[{"title":"HYPERMEDIA PACKAGES","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/hypermedia-packages/","items":[]},{"title":"USER STORIES: INTERACTIVE VIEWING EXPERIENCE","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/user-stories-interactive-viewing-experience/","items":[]}]},{"title":"Measurements App","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/measurements-app/","items":[]},{"title":"Re:Animation","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/reanimation/","items":[]}]},{"title":"Executive Summary","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/","items":[{"title":"Assisting those who Enforce the Law","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/assisting-those-who-enforce-the-law/","items":[]},{"title":"Consumer Protections","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/consumer-protections/","items":[]},{"title":"Knowledge Banking: Legal Structures","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-banking-legal-structures/","items":[]},{"title":"Knowledge Economics &#8211; Services","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-economics-services/","items":[]},{"title":"Preserving The Freedom to Think","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/preserving-the-freedom-to-think/","items":[]}]},{"title":"History","url":"/old-work-archives/2018-webizen-net-au/about/history/","items":[{"title":"History: Global Governance and ICT.","url":"/old-work-archives/2018-webizen-net-au/about/history/history-global-governance-ict-1/","items":[]}]},{"title":"Knowledge Banking: A Technical Architecture Summary","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/","items":[{"title":"An introduction to Credentials.","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/","items":[{"title":"credentials and custodianship","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/credentials-and-custodianship/","items":[]},{"title":"DIDs and MultiSig","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/dids-and-multisig/","items":[]}]},{"title":"Personal Augmentation of AI","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/personal-augmentation-of-ai/","items":[]},{"title":"Semantic Inferencing","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/semantic-inferencing/","items":[]},{"title":"Web of Things (IoT+LD)","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/web-of-things-iotld/","items":[]}]},{"title":"References","url":"/old-work-archives/2018-webizen-net-au/about/references/","items":[{"title":"Making the distinction between ‘privacy’ and ‘dignity’.","url":"/old-work-archives/2018-webizen-net-au/about/references/privacy-vs-dignity/","items":[]},{"title":"Roles &#8211; Entity Analysis","url":"/old-work-archives/2018-webizen-net-au/about/references/roles-entity-analysis/","items":[]},{"title":"Social Informatics Design Considerations","url":"/old-work-archives/2018-webizen-net-au/about/references/social-informatics-design-concept-and-principles/","items":[]},{"title":"Socio-economic relations | A conceptual model","url":"/old-work-archives/2018-webizen-net-au/about/references/socioeconomic-relations-p1/","items":[]},{"title":"The need for decentralised Open (Linked) Data","url":"/old-work-archives/2018-webizen-net-au/about/references/the-need-for-decentralised-open-linked-data/","items":[]}]},{"title":"The design of new medium","url":"/old-work-archives/2018-webizen-net-au/about/the-design-of-new-medium/","items":[]},{"title":"The need to modernise socioeconomic infrastructure","url":"/old-work-archives/2018-webizen-net-au/about/the-modernisation-of-socioeconomics/","items":[]},{"title":"The Vision","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/","items":[{"title":"Domesticating Pervasive Surveillance","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/a-technical-vision/","items":[]}]}]},{"title":"An Overview","url":"/old-work-archives/2018-webizen-net-au/the-human-centric-infosphere/","items":[]},{"title":"Embed Link","url":"/old-work-archives/2018-webizen-net-au/embed-link/","items":[]},{"title":"Posts","url":"/old-work-archives/2018-webizen-net-au/posts/","items":[]},{"title":"Privacy Policy","url":"/old-work-archives/2018-webizen-net-au/privacy-policy/","items":[]},{"title":"Resource Library","url":"/old-work-archives/2018-webizen-net-au/resource-library/","items":[{"title":"Handong1587","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/","items":[{"title":"_Posts","url":"","items":[{"title":"Computer_science","url":"","items":[{"title":"Algorithm and Data Structure Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-algo-resourses/","items":[]},{"title":"Artificial Intelligence Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-ai-resources/","items":[]},{"title":"Big Data Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-09-22-big-data-resources/","items":[]},{"title":"Computer Science Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-cs-resources/","items":[]},{"title":"Data Mining Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-data-mining-resources/","items":[]},{"title":"Data Science Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-data-science-resources/","items":[]},{"title":"Database Systems Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-database-resources/","items":[]},{"title":"Discrete Optimization Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-discrete-optimization/","items":[]},{"title":"Distribued System Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-12-12-ditributed-system-resources/","items":[]},{"title":"Funny Stuffs Of Computer Science","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-11-18-funny-stuffs-of-cs/","items":[]},{"title":"Robotics","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-09-26-robotics-resources/","items":[]},{"title":"Writting CS Papers","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-11-30-writing-papers/","items":[]}]},{"title":"Computer_vision","url":"","items":[{"title":"Computer Vision Datasets","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-24-datasets/","items":[]},{"title":"Computer Vision Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-12-cv-resources/","items":[]},{"title":"Features","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-10-09-features/","items":[]},{"title":"Recognition, Detection, Segmentation and Tracking","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-10-09-recognition-detection-segmentation-tracking/","items":[]},{"title":"Use FFmpeg to Capture I Frames of Video","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2016-03-03-ffmpeg-i-frame/","items":[]},{"title":"Working on OpenCV","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-12-25-working-on-opencv/","items":[]}]},{"title":"Deep_learning","url":"","items":[{"title":"3D","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2021-07-28-3d/","items":[]},{"title":"Acceleration and Model Compression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-cnn-compression-acceleration/","items":[]},{"title":"Acceleration and Model Compression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-knowledge-distillation/","items":[]},{"title":"Adversarial Attacks and Defences","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-adversarial-attacks-and-defences/","items":[]},{"title":"Audio / Image / Video Generation","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-audio-image-video-generation/","items":[]},{"title":"BEV","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2022-06-27-bev/","items":[]},{"title":"Classification / Recognition","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recognition/","items":[]},{"title":"Deep Learning and Autonomous Driving","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-autonomous-driving/","items":[]},{"title":"Deep Learning Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-pose-estimation/","items":[]},{"title":"Deep Learning Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-applications/","items":[]},{"title":"Deep learning Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-courses/","items":[]},{"title":"Deep Learning Frameworks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-frameworks/","items":[]},{"title":"Deep Learning Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-resources/","items":[]},{"title":"Deep Learning Software and Hardware","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-software-hardware/","items":[]},{"title":"Deep Learning Tricks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tricks/","items":[]},{"title":"Deep Learning Tutorials","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tutorials/","items":[]},{"title":"Deep Learning with Machine Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-with-ml/","items":[]},{"title":"Face Recognition","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-face-recognition/","items":[]},{"title":"Fun With Deep Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-fun-with-deep-learning/","items":[]},{"title":"Generative Adversarial Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gan/","items":[]},{"title":"Graph Convolutional Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gcn/","items":[]},{"title":"Image / Video Captioning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-captioning/","items":[]},{"title":"Image Retrieval","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-retrieval/","items":[]},{"title":"Keep Up With New Trends","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2018-09-03-keep-up-with-new-trends/","items":[]},{"title":"LiDAR 3D Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-lidar-3d-detection/","items":[]},{"title":"Natural Language Processing","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nlp/","items":[]},{"title":"Neural Architecture Search","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nas/","items":[]},{"title":"Object Counting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-counting/","items":[]},{"title":"Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-detection/","items":[]},{"title":"OCR","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-ocr/","items":[]},{"title":"Optical Flow","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-optical-flow/","items":[]},{"title":"Re-ID","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-re-id/","items":[]},{"title":"Recommendation System","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recommendation-system/","items":[]},{"title":"Reinforcement Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rl/","items":[]},{"title":"RNN and LSTM","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rnn-and-lstm/","items":[]},{"title":"Segmentation","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-segmentation/","items":[]},{"title":"Style Transfer","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-style-transfer/","items":[]},{"title":"Super-Resolution","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-super-resolution/","items":[]},{"title":"Tracking","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-tracking/","items":[]},{"title":"Training Deep Neural Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-training-dnn/","items":[]},{"title":"Transfer Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-transfer-learning/","items":[]},{"title":"Unsupervised Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-unsupervised-learning/","items":[]},{"title":"Video Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-video-applications/","items":[]},{"title":"Visual Question Answering","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-vqa/","items":[]},{"title":"Visualizing and Interpreting Convolutional Neural Network","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-visulizing-interpreting-cnn/","items":[]}]},{"title":"Leisure","url":"","items":[{"title":"All About Enya","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-all-about-enya/","items":[]},{"title":"Coldplay","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-coldplay/","items":[]},{"title":"Coldplay","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-nightwish/","items":[]},{"title":"Games","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-13-games/","items":[]},{"title":"Green Day","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-greenday/","items":[]},{"title":"Muse! Muse!","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-muse-muse/","items":[]},{"title":"Oasis","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-oasis/","items":[]},{"title":"Paintings By J.M.","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2016-03-08-paintings-by-jm/","items":[]},{"title":"Papers, Blogs and Websites","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-09-27-papers-blogs-and-websites/","items":[]},{"title":"Welcome To The Black Parade","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-welcome-to-the-black-parade/","items":[]}]},{"title":"Machine_learning","url":"","items":[{"title":"Bayesian Methods","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-bayesian-methods/","items":[]},{"title":"Clustering Algorithms Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-clustering/","items":[]},{"title":"Competitions","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-competitions/","items":[]},{"title":"Dimensionality Reduction Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-dimensionality-reduction/","items":[]},{"title":"Fun With Machine Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-fun-with-ml/","items":[]},{"title":"Graphical Models Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-graphical-models/","items":[]},{"title":"Machine Learning Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-ml-courses/","items":[]},{"title":"Machine Learning Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-ml-resources/","items":[]},{"title":"Natural Language Processing","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-nlp/","items":[]},{"title":"Neural Network","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-neural-network/","items":[]},{"title":"Random Field","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-random-field/","items":[]},{"title":"Random Forests","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-random-forests/","items":[]},{"title":"Regression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-regression/","items":[]},{"title":"Support Vector Machine","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-svm/","items":[]},{"title":"Topic Model","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-topic-model/","items":[]}]},{"title":"Mathematics","url":"","items":[{"title":"Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/mathematics/2016-02-24-resources/","items":[]}]},{"title":"Programming_study","url":"","items":[{"title":"Add Lunr Search Plugin For Blog","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-31-add-lunr-search-plugin-for-blog/","items":[]},{"title":"Android Development Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-05-23-android-resources/","items":[]},{"title":"C++ Programming Solutions","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-09-07-cpp-programming-solutions/","items":[]},{"title":"Commands To Suppress Some Building Errors With Visual Studio","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-24-cmds-to-suppress-some-vs-building-Errors/","items":[]},{"title":"Embedding Python In C/C++","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-10-embedding-python-in-cpp/","items":[]},{"title":"Enable Large Addresses On VS2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-12-14-enable-large-addresses/","items":[]},{"title":"Fix min/max Error In VS2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-02-17-min-max-error-in-vs2015/","items":[]},{"title":"Gflags Build Problems on Windows X86 and Visual Studio 2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-23-gflags-build-problems-winx86-vs2015/","items":[]},{"title":"Glog Build Problems on Windows X86 and Visual Studio 2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-23-glog-build-problems-winx86/","items":[]},{"title":"Horrible Wired Errors Come From Simple Stupid Mistake","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-16-horrible-wired-errors-come-from-simple-stupid-mistake/","items":[]},{"title":"Install Jekyll To Fix Some Local Github-pages Defects","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-11-21-install-jekyll/","items":[]},{"title":"Install Therubyracer Failure","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-03-install-therubyracer/","items":[]},{"title":"Notes On Valgrind and Others","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-05-30-notes-on-valgrind/","items":[]},{"title":"PHP Hello World","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-04-php-hello-world/","items":[]},{"title":"Programming Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-07-01-programming-resources/","items":[]},{"title":"PyInstsaller and Others","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-12-24-pyinstaller-and-others/","items":[]},{"title":"Web Development Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-06-21-web-dev-resources/","items":[]},{"title":"Working on Visual Studio","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-04-03-working-on-vs/","items":[]}]},{"title":"Reading_and_thoughts","url":"","items":[{"title":"Book Reading List","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2015-12-04-book-reading-list/","items":[]},{"title":"Funny Papers","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2015-12-04-funny-papers/","items":[]},{"title":"Reading Materials","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2016-01-18-reading-materials/","items":[]}]},{"title":"Study","url":"","items":[{"title":"Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2017-11-28-courses/","items":[]},{"title":"Essay Writting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2016-01-11-essay-writting/","items":[]},{"title":"Job Hunting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2016-06-02-job-hunting/","items":[]},{"title":"Study Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2018-04-18-resources/","items":[]}]},{"title":"Working_on_linux","url":"","items":[{"title":"Create Multiple Forks of a GitHub Repo","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-12-18-create-multi-forks/","items":[]},{"title":"Linux Git Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-08-02-linux-git/","items":[]},{"title":"Linux Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-07-24-linux-resources/","items":[]},{"title":"Linux SVN Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-08-03-linux-svn/","items":[]},{"title":"Setup vsftpd on Ubuntu 14.10","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2016-07-27-setup-vsftpd/","items":[]},{"title":"Useful Linux Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-07-25-useful-linux-commands/","items":[]},{"title":"vsftpd Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2016-07-28-vsftpd-cmd/","items":[]}]},{"title":"Working_on_mac","url":"","items":[{"title":"Mac Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_mac/2015-07-25-mac-resources/","items":[]}]},{"title":"Working_on_windows","url":"","items":[{"title":"FFmpeg Collection of Utility Methods","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2016-06-05-ffmpeg-utilities/","items":[]},{"title":"Windows Commands and Utilities","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2015-10-27-windows-cmds-utils/","items":[]},{"title":"Windows Dev Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2015-10-27-resources/","items":[]}]}]},{"title":"Drafts","url":"","items":[{"title":"2016-12-30-Setup-Opengrok","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-12-30-setup-opengrok/","items":[]},{"title":"2017-01-20-Packing-C++-Project-to-Single-Executable","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2017-01-20-packing-c++-project-to-single-executable/","items":[]},{"title":"Notes On Caffe Development","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-10-notes-on-caffe-dev/","items":[]},{"title":"Notes On Deep Learning Training","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-12-notes-on-dl-training/","items":[]},{"title":"Notes On Discrete Optimization","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-13-notes-on-discrete-optimization/","items":[]},{"title":"Notes On Gecode","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-13-notes-on-gecode/","items":[]},{"title":"Notes On Inside-Outside Net","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-28-notes-on-ion/","items":[]},{"title":"Notes On K-Means","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-06-notes-on-kmeans/","items":[]},{"title":"Notes On L-BFGS","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-07-notes-on-l-bfgs/","items":[]},{"title":"Notes On Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-04-notes-on-object-detection/","items":[]},{"title":"Notes On Perceptrons","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-10-07-notes-on-perceptrons/","items":[]},{"title":"Notes On Quantized Convolutional Neural Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-07-notes-on-quantized-cnn/","items":[]},{"title":"Notes On Stanford CS2321n","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-02-21-notes-on-cs231n/","items":[]},{"title":"Notes on Suffix Array and Manacher Algorithm","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-08-27-notes-on-suffix-array-and-manacher-algorithm/","items":[]},{"title":"Notes On Tensorflow Development","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2017-04-13-notes-on-tensorflow-dev/","items":[]},{"title":"Notes On YOLO","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-14-notes-on-yolo/","items":[]},{"title":"PASCAL VOC (20) / COCO (80) / ImageNet (200) Detection Categories","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-12-23-imagenet-det-cat/","items":[]},{"title":"Softmax Vs Logistic Vs Sigmoid","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-10-softmax-logistic-sigmoid/","items":[]},{"title":"Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognititon","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-08-31-model-ensemble-of-deteciton/","items":[]}]}]}]}]}]},{"title":"Webizen 2.0","url":"","items":[{"title":"AI Capabilities","url":"","items":[{"title":"AI Capabilities Objectives","url":"/Webizen 2.0/AI Capabilities/AI Capabilities Objectives/","items":[]},{"title":"Audio & Video Analysis","url":"/Webizen 2.0/AI Capabilities/Audio & Video Analysis/","items":[]},{"title":"Image Analysis","url":"/Webizen 2.0/AI Capabilities/Image Analysis/","items":[]},{"title":"Text Analysis","url":"/Webizen 2.0/AI Capabilities/Text Analysis/","items":[]}]},{"title":"LOD-a-lot","url":"/Webizen 2.0/AI Related Links & Notes/","items":[]},{"title":"Mobile Apps","url":"","items":[{"title":"Android","url":"/Webizen 2.0/Mobile Apps/Android/","items":[]},{"title":"General Mobile Architecture","url":"/Webizen 2.0/Mobile Apps/General Mobile Architecture/","items":[]},{"title":"iOS","url":"/Webizen 2.0/Mobile Apps/iOS/","items":[]}]},{"title":"Web Of Things (IoT)","url":"","items":[{"title":"Web Of Things (IoT)","url":"/Webizen 2.0/Web Of Things (IoT)/Web Of Things (IoT)/","items":[]}]},{"title":"Webizen 2.0","url":"/Webizen 2.0/Webizen 2.0/","items":[]},{"title":"Webizen AI OS Platform","url":"/Webizen 2.0/Webizen AI OS Platform/","items":[]},{"title":"Webizen Pro Summary","url":"/Webizen 2.0/Webizen Pro Summary/","items":[]}]},{"title":"Webizen V1 Project Documentation","url":"/","items":[]}]}],"tagsGroups":[],"latestPosts":[{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/","title":"Handong1587","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-08-27-notes-on-suffix-array-and-manacher-algorithm/","title":"Notes on Suffix Array and Manacher Algorithm","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-10-07-notes-on-perceptrons/","title":"Notes On Perceptrons","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-04-notes-on-object-detection/","title":"Notes On Object Detection","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-10-notes-on-caffe-dev/","title":"Notes On Caffe Development","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-07-notes-on-l-bfgs/","title":"Notes On L-BFGS","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-10-softmax-logistic-sigmoid/","title":"Softmax Vs Logistic Vs Sigmoid","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-12-notes-on-dl-training/","title":"Notes On Deep Learning Training","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-14-notes-on-yolo/","title":"Notes On YOLO","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-28-notes-on-ion/","title":"Notes On Inside-Outside Net","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}