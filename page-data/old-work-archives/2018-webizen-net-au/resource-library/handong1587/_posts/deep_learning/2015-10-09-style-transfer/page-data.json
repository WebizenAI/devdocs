{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-style-transfer/",
    "result": {"data":{"mdx":{"id":"fde121eb-0053-57fd-9d51-ef549d0851ef","tableOfContents":{"items":[{"url":"#neural-art","title":"Neural Art"},{"url":"#neural-art-on-audio","title":"Neural Art On Audio"},{"url":"#neural-art-on-video","title":"Neural Art On Video"},{"url":"#neural-doodle","title":"Neural Doodle"},{"url":"#deep-dreams","title":"Deep Dreams"},{"url":"#image-stylization","title":"Image Stylization"}]},"fields":{"title":"Style Transfer","slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-style-transfer/","url":"https://devdocs.webizen.org/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-style-transfer/","editUrl":"https://github.com/webizenai/devdocs/tree/main/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-style-transfer.md","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022","gitCreatedAt":"2022-12-28T19:22:29.000Z","shouldShowTitle":true},"frontmatter":{"title":"Style Transfer","description":null,"imageAlt":null,"tags":[],"date":"2015-10-09T00:00:00.000Z","dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"layout\": \"post\",\n  \"category\": \"deep_learning\",\n  \"title\": \"Style Transfer\",\n  \"date\": \"2015-10-09T00:00:00.000Z\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"neural-art\"\n  }, \"Neural Art\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Neural Algorithm of Artistic Style\")), mdx(\"img\", {\n    \"src\": \"/assets/fun_with_dl/a_nerual_algorithm_of_artistic_style.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1508.06576\"\n  }, \"http://arxiv.org/abs/1508.06576\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gitxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://gitxiv.com/posts/jG46ukGod8R7Rdtud/a-neural-algorithm-of-artistic-style\"\n  }, \"http://gitxiv.com/posts/jG46ukGod8R7Rdtud/a-neural-algorithm-of-artistic-style\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kaishengtai/neuralart\"\n  }, \"https://github.com/kaishengtai/neuralart\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jcjohnson/neural-style\"\n  }, \"https://github.com/jcjohnson/neural-style\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/andersbll/neural_artistic_style\"\n  }, \"https://github.com/andersbll/neural_artistic_style\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"ipn: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://nbviewer.ipython.org/github/Lasagne/Recipes/blob/master/examples/styletransfer/Art%20Style%20Transfer.ipynb\"\n  }, \"http://nbviewer.ipython.org/github/Lasagne/Recipes/blob/master/examples/styletransfer/Art%20Style%20Transfer.ipynb\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mbartoli/neural-animation\"\n  }, \"https://github.com/mbartoli/neural-animation\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/memisevic/artify\"\n  }, \"https://github.com/memisevic/artify\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mattya/chainer-gogh\"\n  }, \"https://github.com/mattya/chainer-gogh\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(TensorFlow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/anishathalye/neural-style\"\n  }, \"https://github.com/anishathalye/neural-style\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/woodrush/neural-art-tf\"\n  }, \"https://github.com/woodrush/neural-art-tf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/dmlc/mxnet/tree/master/example/neural-style\"\n  }, \"https://github.com/dmlc/mxnet/tree/master/example/neural-style\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://deepart.io/\"\n  }, \"http://deepart.io/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Teaonly/easyStyle\"\n  }, \"https://github.com/Teaonly/easyStyle\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ckmarkoh/neuralart_tensorflow\"\n  }, \"https://github.com/ckmarkoh/neuralart_tensorflow\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/fzliu/style-transfer\"\n  }, \"https://github.com/fzliu/style-transfer\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/titu1994/Neural-Style-Transfer\"\n  }, \"https://github.com/titu1994/Neural-Style-Transfer\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/saikatbsk/Vincent-AI-Artist\"\n  }, \"https://github.com/saikatbsk/Vincent-AI-Artist\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zhaw/neural_style\"\n  }, \"https://github.com/zhaw/neural_style\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Image Style Transfer Using Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf/\"\n  }, \"www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Artificial Startup Style: Neural art about startup fashion\")), mdx(\"img\", {\n    \"src\": \"https://cdn-images-1.medium.com/max/800/1*n2cmWDB42iUij8TCil9yLA.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/data-engineering/artificial-startup-style-437f6090b1f7#.8u06gq42e\"\n  }, \"https://medium.com/data-engineering/artificial-startup-style-437f6090b1f7#.8u06gq42e\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"From Pixels to Paragraphs: How artistic experiments with deep learning guard us from hype\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/@genekogan/from-pixels-to-paragraphs-eb2763da0e9b#.er3djn9z9\"\n  }, \"https://medium.com/@genekogan/from-pixels-to-paragraphs-eb2763da0e9b#.er3djn9z9\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Experiments with style transfer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"website: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mtyka.github.io/code/2015/10/02/experiments-with-style-transfer.html\"\n  }, \"http://mtyka.github.io/code/2015/10/02/experiments-with-style-transfer.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Style Transfer for Headshot Portraits (SIGGRAPH 2014)\")), mdx(\"img\", {\n    \"src\": \"https://people.csail.mit.edu/yichangshih/portrait_web/teaser.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://people.csail.mit.edu/yichangshih/portrait_web/\"\n  }, \"https://people.csail.mit.edu/yichangshih/portrait_web/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Teaching recurrent Neural Networks about Monet\")), mdx(\"img\", {\n    \"src\": \"/assets/fun_with_dl/keras_monet_output_sample.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://blog.manugarri.com/teaching-recurrent-neural-networks-about-monet/\"\n  }, \"http://blog.manugarri.com/teaching-recurrent-neural-networks-about-monet/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/manugarri/keras_monet\"\n  }, \"https://github.com/manugarri/keras_monet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Content Aware Neural Style Transfer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1601.04568\"\n  }, \"http://arxiv.org/abs/1601.04568\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis\")), mdx(\"undefined\", null, mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/chuanli11/CNNMRF/master/data/examples/content.jpg\",\n    \"width\": 150\n  }), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/chuanli11/CNNMRF/master/data/examples/style.jpg\",\n    \"width\": 150\n  }), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/chuanli11/CNNMRF/master/data/examples/Interpolation/3_balanced.png\",\n    \"width\": 150\n  })), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1601.04589\"\n  }, \"http://arxiv.org/abs/1601.04589\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/chuanli11/CNNMRF\"\n  }, \"https://github.com/chuanli11/CNNMRF\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Stylenet: Neural Network with Style Synthesis\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/machrisaa/stylenet\"\n  }, \"https://github.com/machrisaa/stylenet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Ostagram\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: This program presents web-service for algorithm combining the content of one image\\nwith the style of another image using convolutional neural networks\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/SergeyMorugin/ostagram\"\n  }, \"https://github.com/SergeyMorugin/ostagram\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Exploring the Neural Algorithm of Artistic Style\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: A short class project report\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1602.07188\"\n  }, \"http://arxiv.org/abs/1602.07188\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Perceptual Losses for Real-Time Style Transfer and Super-Resolution\")), mdx(\"img\", {\n    \"src\": \"https://github.com/jcjohnson/fast-neural-style/blob/master/images/webcam.gif?raw=true\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Justin Johnson, Alexandre Alahi, Li Fei-Fei. ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.08155\"\n  }, \"http://arxiv.org/abs/1603.08155\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jcjohnson/fast-neural-style\"\n  }, \"https://github.com/jcjohnson/fast-neural-style\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yusuketomoto/chainer-fast-neuralstyle\"\n  }, \"https://github.com/yusuketomoto/chainer-fast-neuralstyle\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/awentzonline/keras-rtst\"\n  }, \"https://github.com/awentzonline/keras-rtst\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Keras): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/titu1994/Fast-Neural-Style\"\n  }, \"https://github.com/titu1994/Fast-Neural-Style\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gtihub(Tensorflow): \", \"[https://github.com/junrushao1994/fast-neural-style.tf]\", \" (\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/junrushao1994/fast-neural-style.tf\"\n  }, \"https://github.com/junrushao1994/fast-neural-style.tf\"), \")\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(PyTorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bengxy/FastNeuralStyle\"\n  }, \"https://github.com/bengxy/FastNeuralStyle\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Image transformation networks with fancy loss functions\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Fast neural style in tensorflow based on \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.08155\"\n  }, \"http://arxiv.org/abs/1603.08155\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://olavnymoen.com/2016/07/07/image-transformation-network\"\n  }, \"http://olavnymoen.com/2016/07/07/image-transformation-network\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/OlavHN/fast-neural-style\"\n  }, \"https://github.com/OlavHN/fast-neural-style\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improving the Neural Algorithm of Artistic Style\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.04603\"\n  }, \"http://arxiv.org/abs/1605.04603\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CubistMirror: an openframeworks app which repeatedly applies real-time style transfer on a webcam\")), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/genekogan/CubistMirror/master/photos/cubist_mirror_1.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/genekogan/CubistMirror\"\n  }, \"https://github.com/genekogan/CubistMirror\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Transfer Style But Not Color\")), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/pavelgonchar/color-independent-style-transfer/master/results-ny.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://blog.deepart.io/2016/06/04/color-independent-style-transfer/\"\n  }, \"http://blog.deepart.io/2016/06/04/color-independent-style-transfer/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/pavelgonchar/color-independent-style-transfer\"\n  }, \"https://github.com/pavelgonchar/color-independent-style-transfer\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"neural-art-mini: Lightweight version of mxnet neural art implementation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Lightweight version of mxnet neural art implementation using ~4.8M SqueezeNet model.\\nCompressed model is less than 500KB\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/pavelgonchar/neural-art-mini\"\n  }, \"https://github.com/pavelgonchar/neural-art-mini\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Preserving Color in Neural Artistic Style Transfer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1606.05897\"\n  }, \"http://arxiv.org/abs/1606.05897\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End to End Neural Art with Generative Models\")), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/art/net.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://dmlc.ml/mxnet/2016/06/20/end-to-end-neural-style.html\"\n  }, \"http://dmlc.ml/mxnet/2016/06/20/end-to-end-neural-style.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/dmlc/mxnet/tree/master/example/neural-style\"\n  }, \"https://github.com/dmlc/mxnet/tree/master/example/neural-style\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Neural Style Explained\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://kvfrans.com/neural-style-explained/\"\n  }, \"http://kvfrans.com/neural-style-explained/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kvfrans/neural-style\"\n  }, \"https://github.com/kvfrans/neural-style\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Texture Networks: Feed-forward Synthesis of Textures and Stylized Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IMCL 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.03417\"\n  }, \"http://arxiv.org/abs/1603.03417\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/DmitryUlyanov/texture_nets\"\n  }, \"https://github.com/DmitryUlyanov/texture_nets\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://blog.acolyer.org/2016/09/23/texture-networks-feed-forward-synthesis-of-textures-and-stylized-images/\"\n  }, \"https://blog.acolyer.org/2016/09/23/texture-networks-feed-forward-synthesis-of-textures-and-stylized-images/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tgyg-jegli/tf_texture_net\"\n  }, \"https://github.com/tgyg-jegli/tf_texture_net\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Typographic Style\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1603.04000\"\n  }, \"https://arxiv.org/abs/1603.04000\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Instance Normalization: The Missing Ingredient for Fast Stylization\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1607.08022\"\n  }, \"http://arxiv.org/abs/1607.08022\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Painting style transfer for head portraits using convolutional neural networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://dl.acm.org/citation.cfm?id=2925968\"\n  }, \"http://dl.acm.org/citation.cfm?id=2925968\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"sci-hub: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://dl.acm.org.sci-hub.cc/citation.cfm?doid=2897824.2925968\"\n  }, \"http://dl.acm.org.sci-hub.cc/citation.cfm?doid=2897824.2925968\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Style-Transfer via Texture-Synthesis\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.03057\"\n  }, \"http://arxiv.org/abs/1609.03057\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"neural-style-tf: TensorFlow implementation of Neural Style\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/cysmith/neural-style-tf\"\n  }, \"https://github.com/cysmith/neural-style-tf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Convolutional Networks as Models of Generalization and Blending Within Visual Creativity\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: In Proceedings of the 7th International Conference on Computational Creativity. Palo Alto: Association for the Advancement of Artificial Intelligence (AAAI) Press (2016)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.02478\"\n  }, \"https://arxiv.org/abs/1610.02478\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Learned Representation For Artistic Style\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Brain\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.07629\"\n  }, \"https://arxiv.org/abs/1610.07629\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://research.googleblog.com/2016/10/supercharging-style-transfer.html\"\n  }, \"https://research.googleblog.com/2016/10/supercharging-style-transfer.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tensorflow/magenta/tree/master/magenta/models/image_stylization\"\n  }, \"https://github.com/tensorflow/magenta/tree/master/magenta/models/image_stylization\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Tensorflow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Heumi/Fast_Multi_Style_Transfer-tf\"\n  }, \"https://github.com/Heumi/Fast_Multi_Style_Transfer-tf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"How to Fake It As an Artist with Docker, AWS and Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/@lherrera/how-to-fake-it-as-an-artist-with-docker-aws-and-deep-learning-6d42f4acd890#.eq9gcgkzh\"\n  }, \"https://medium.com/@lherrera/how-to-fake-it-as-an-artist-with-docker-aws-and-deep-learning-6d42f4acd890#.eq9gcgkzh\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multistyle Pastiche Generator\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://magenta.tensorflow.org/2016/11/01/multistyle-pastiche-generator/\"\n  }, \"https://magenta.tensorflow.org/2016/11/01/multistyle-pastiche-generator/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast Style Transfer in TensorFlow\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Video Stylization, Image Stylization\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lengstrom/fast-style-transfer\"\n  }, \"https://github.com/lengstrom/fast-style-transfer\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Neural Style Transfer For Chinese Fonts\")), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/kaonashi-tyc/Rewrite/master/images/mixed_font.gif\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kaonashi-tyc/Rewrite\"\n  }, \"https://github.com/kaonashi-tyc/Rewrite\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Neural Style Representations and the Large-Scale Classification of Artistic Style\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.05368\"\n  }, \"https://arxiv.org/abs/1611.05368\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Controlling Perceptual Factors in Neural Style Transfer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Tubingen & Adobe Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.07865\"\n  }, \"https://arxiv.org/abs/1611.07865\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Awesome Typography: Statistics-Based Text Effects Transfer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.09026\"\n  }, \"https://arxiv.org/abs/1611.09026\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast Patch-based Style Transfer of Arbitrary Style\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.04337\"\n  }, \"https://arxiv.org/abs/1612.04337\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/rtqichen/style-swap\"\n  }, \"https://github.com/rtqichen/style-swap\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Demystifying Neural Style Transfer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IJCAI 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Peking University & TuSimple\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.01036\"\n  }, \"https://arxiv.org/abs/1701.01036\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lyttonhao/Neural-Style-MMD\"\n  }, \"https://github.com/lyttonhao/Neural-Style-MMD\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Son of Zorn's Lemma: Targeted Style Transfer Using Instance-aware Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.02357\"\n  }, \"https://arxiv.org/abs/1701.02357\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bringing Impressionism to Life with Neural Style Transfer in Come Swim\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: a case study of how Neural Style Transfer can be used in a movie production context\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Kristen Stewart !\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.04928\"\n  }, \"https://arxiv.org/abs/1701.04928\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pytorch tutorials for Neural Style transfert\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/alexis-jacq/Pytorch-Tutorials\"\n  }, \"https://github.com/alexis-jacq/Pytorch-Tutorials\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Stable and Controllable Neural Texture Synthesis and Style Transfer Using Histogram Losses\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.08893\"\n  }, \"https://arxiv.org/abs/1701.08893\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Arbitrary Style Transfer In Real-Time With Adaptive Instance Normalization\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017. Cornell University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://openreview.net/pdf?id=B1fUVMzKg\"\n  }, \"https://openreview.net/pdf?id=B1fUVMzKg\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Torch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xunhuang1995/AdaIN-style\"\n  }, \"https://github.com/xunhuang1995/AdaIN-style\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(TensorFlow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/elleryqueenhomels/arbitrary_style_transfer\"\n  }, \"https://github.com/elleryqueenhomels/arbitrary_style_transfer\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Picking an optimizer for Style Transfer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/slavv/picking-an-optimizer-for-style-transfer-86e7b8cba84b#.cgv2oreaq\"\n  }, \"https://medium.com/slavv/picking-an-optimizer-for-style-transfer-86e7b8cba84b#.cgv2oreaq\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/slavivanov/Style-Tranfer\"\n  }, \"https://github.com/slavivanov/Style-Tranfer\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-style Generative Network for Real-time Transfer\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1703.06953\"\n  }, \"https://arxiv.org/abs/1703.06953\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Photo Style Transfer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.07511\"\n  }, \"https://arxiv.org/abs/1703.07511\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Torch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/luanfujun/deep-photo-styletransfer\"\n  }, \"https://github.com/luanfujun/deep-photo-styletransfer\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Docker): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/martinbenson/deep-photo-styletransfer\"\n  }, \"https://github.com/martinbenson/deep-photo-styletransfer\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Lightweight Neural Style on Pytorch\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/lizeng614/SqueezeNet-Neural-Style-Pytorch\"\n  }, \"https://github.com/lizeng614/SqueezeNet-Neural-Style-Pytorch\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"StyleBank: An Explicit Representation for Neural Image Style Transfer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.09210\"\n  }, \"https://arxiv.org/abs/1703.09210\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"How to Make an Image More Memorable? A Deep Style Transfer Approach\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM ICMR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.01745\"\n  }, \"https://arxiv.org/abs/1704.01745\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Visual Attribute Transfer through Deep Image Analogy\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SIGGRAPH 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Deep Image Analogy\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1705.01088\"\n  }, \"https://arxiv.org/abs/1705.01088\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/msracver/Deep-Image-Analogy\"\n  }, \"https://github.com/msracver/Deep-Image-Analogy\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Characterizing and Improving Stability in Neural Style Transfer\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1705.02092\"\n  }, \"https://arxiv.org/abs/1705.02092\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards Metamerism via Foveated Style Transfer\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1705.10041\"\n  }, \"https://arxiv.org/abs/1705.10041\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Style Transfer for Sketches with Enhanced Residual U-net and Auxiliary Classifier GAN\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1706.03319\"\n  }, \"https://arxiv.org/abs/1706.03319\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Meta Networks for Neural Style Transfer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1709.04111\"\n  }, \"https://arxiv.org/abs/1709.04111\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/FalongShen/styletransfer\"\n  }, \"https://github.com/FalongShen/styletransfer\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Neural Color Transfer between Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Hong Kong University of Science and Technology & Microsoft Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1710.00756\"\n  }, \"https://arxiv.org/abs/1710.00756\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improved Style Transfer by Respecting Inter-layer Correlations\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1801.01933\"\n  }, \"https://arxiv.org/abs/1801.01933\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Face Destylization\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1802.01237\"\n  }, \"https://arxiv.org/abs/1802.01237\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unsupervised Typography Transfer\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1802.02595\"\n  }, \"https://arxiv.org/abs/1802.02595\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Stereoscopic Neural Style Transfer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1802.10591\"\n  }, \"https://arxiv.org/abs/1802.10591\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Arbitrary Style Transfer with Deep Feature Reshuffle\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.04103\"\n  }, \"https://arxiv.org/abs/1805.04103\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Avatar-Net: Multi-scale Zero-shot Style Transfer by Feature Decoration\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018. CUHK & SenseTime\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.03857\"\n  }, \"https://arxiv.org/abs/1805.03857\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Beyond Textures: Learning from Multi-domain Artistic Images for Arbitrary Style Transfer\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.09987\"\n  }, \"https://arxiv.org/abs/1805.09987\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Comprehensive Comparison between Neural Style Transfer and Universal Style Transfer\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1806.00868\"\n  }, \"https://arxiv.org/abs/1806.00868\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unbiased Image Style Transfer\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1807.01424\"\n  }, \"https://arxiv.org/abs/1807.01424\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Uncorrelated Feature Encoding for Faster Image Style Transfer\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1807.01493\"\n  }, \"https://arxiv.org/abs/1807.01493\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Adjustable Real-time Style Transfer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Illinois at Urbana-Champaign && Google Brain\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.08560\"\n  }, \"https://arxiv.org/abs/1811.08560\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Automated Deep Photo Style Transfer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Tubingen\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.03915\"\n  }, \"https://arxiv.org/abs/1901.03915\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attention-aware Multi-stroke Style Transfer\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1901.05127\"\n  }, \"https://arxiv.org/abs/1901.05127\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"StyleNAS: An Empirical Study of Neural Architecture Search to Uncover Surprisingly Fast End-to-End Universal Style Transfer Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1906.02470\"\n  }, \"https://arxiv.org/abs/1906.02470\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"StyleNAS: An Empirical Study of Neural Architecture Search to Uncover Surprisingly Fast End-to-End Universal Style Transfer Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1906.02470\"\n  }, \"https://arxiv.org/abs/1906.02470\")), mdx(\"h1\", {\n    \"id\": \"neural-art-on-audio\"\n  }, \"Neural Art On Audio\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MSc AI Project on generative deep networks and neural style transfer for audio\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Fr-d-rik/generative_audio\"\n  }, \"https://github.com/Fr-d-rik/generative_audio\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project report: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Fr-d-rik/generative_audio/blob/master/docs/project_report.pdf\"\n  }, \"https://github.com/Fr-d-rik/generative_audio/blob/master/docs/project_report.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Neural Song Style\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Audio style transfer AI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/rupeshs/neuralsongstyle\"\n  }, \"https://github.com/rupeshs/neuralsongstyle\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Time Domain Neural Audio Style Transfer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.11160\"\n  }, \"https://arxiv.org/abs/1711.11160\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com//pkmital/time-domain-neural-audio-style-transfer\"\n  }, \"https://github.com//pkmital/time-domain-neural-audio-style-transfer\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Linear Transformations for Fast Arbitrary Style Transfer\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1808.04537\"\n  }, \"https://arxiv.org/abs/1808.04537\")), mdx(\"h1\", {\n    \"id\": \"neural-art-on-video\"\n  }, \"Neural Art On Video\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"neural-style-video\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://larseidnes.com/2015/12/18/painting-videos-with-neural-networks/\"\n  }, \"http://larseidnes.com/2015/12/18/painting-videos-with-neural-networks/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/larspars/neural-style-video\"\n  }, \"https://github.com/larspars/neural-style-video\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Instructions for making a Neural-Style movie\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"website: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://gist.github.com/genekogan/d61c8010d470e1dbe15d\"\n  }, \"https://gist.github.com/genekogan/d61c8010d470e1dbe15d\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"sample: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://vimeo.com/139123754\"\n  }, \"https://vimeo.com/139123754\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Artistic style transfer for videos\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1604.08610\"\n  }, \"http://arxiv.org/abs/1604.08610\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/manuelruder/artistic-videos\"\n  }, \"https://github.com/manuelruder/artistic-videos\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Artistic style transfer for videos and spherical images\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1708.04538\"\n  }, \"https://arxiv.org/abs/1708.04538\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"How Deep Learning Can Paint Videos in the Style of Art\\u2019s Great Masters\")), mdx(\"img\", {\n    \"src\": \"https://blogs.nvidia.com/wp-content/uploads/2016/05/artistic-video-1200x528.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://blogs.nvidia.com/blog/2016/05/25/deep-learning-paints-videos/\"\n  }, \"https://blogs.nvidia.com/blog/2016/05/25/deep-learning-paints-videos/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepMovie: Using Optical Flow and Deep Neural Networks to Stylize Movies\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.08153\"\n  }, \"http://arxiv.org/abs/1605.08153\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Coherent Online Video Style Transfer\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1703.09211\"\n  }, \"https://arxiv.org/abs/1703.09211\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Laplacian-Steered Neural Style Transfer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM Multimedia Conference (MM) 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.01253\"\n  }, \"https://arxiv.org/abs/1707.01253\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Real-Time Neural Style Transfer for Videos\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tsinghua University & Tencent AI Lab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Real-Time_Neural_Style_CVPR_2017_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Real-Time_Neural_Style_CVPR_2017_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Content GAN for Few-Shot Font Style Transfer\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.00516\"\n  }, \"https://arxiv.org/abs/1712.00516\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Painterly Harmonization\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.03189\"\n  }, \"https://arxiv.org/abs/1804.03189\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/luanfujun/deep-painterly-harmonization\"\n  }, \"https://github.com/luanfujun/deep-painterly-harmonization\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ReCoNet: Real-time Coherent Video Style Transfer Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The University of Hong Kong\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arixv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.01197\"\n  }, \"https://arxiv.org/abs/1807.01197\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"supp: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.dropbox.com/s/go6f7uopjjsala7/ReCoNet%20Supplementary%20Material.pdf?dl=0\"\n  }, \"https://www.dropbox.com/s/go6f7uopjjsala7/ReCoNet%20Supplementary%20Material.pdf?dl=0\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fully-Featured Attribute Transfer\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1902.06258\"\n  }, \"https://arxiv.org/abs/1902.06258\")), mdx(\"h1\", {\n    \"id\": \"neural-doodle\"\n  }, \"Neural Doodle\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://nucl.ai/semantic-style-transfer.pdf\"\n  }, \"http://nucl.ai/semantic-style-transfer.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"reddit: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.reddit.com/r/MachineLearning/comments/48zstj/my_wip_implementation_of_neural_image_analogies/\"\n  }, \"https://www.reddit.com/r/MachineLearning/comments/48zstj/my_wip_implementation_of_neural_image_analogies/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/alexjc/neural-doodle\"\n  }, \"https://github.com/alexjc/neural-doodle\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Neural Doodle\")), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/alexjc/neural-doodle/master/docs/Workflow.gif\",\n    \"alt\": null\n  }), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/alexjc/neural-doodle/master/docs/Landscape_example.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/alexjc/neural-doodle\"\n  }, \"https://github.com/alexjc/neural-doodle\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Faster neural doodle\")), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/DmitryUlyanov/fast-neural-doodle/master/data/Renoir/grid.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/DmitryUlyanov/fast-neural-doodle\"\n  }, \"https://github.com/DmitryUlyanov/fast-neural-doodle\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Feed-forward neural doodle\")), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/DmitryUlyanov/online-neural-doodle/master/data/starry/grid.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://dmitryulyanov.github.io/feed-forward-neural-doodle/\"\n  }, \"http://dmitryulyanov.github.io/feed-forward-neural-doodle/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/DmitryUlyanov/online-neural-doodle\"\n  }, \"https://github.com/DmitryUlyanov/online-neural-doodle\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://likemo.net/\"\n  }, \"http://likemo.net/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"neural image analogies: Generate image analogies using neural matching and blending\")), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/awentzonline/image-analogies/master/examples/images/sugarskull-analogy.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/awentzonline/image-analogies\"\n  }, \"https://github.com/awentzonline/image-analogies\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Neural doodle with Keras\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/fchollet/keras/blob/master/examples/neural_doodle.py\"\n  }, \"https://github.com/fchollet/keras/blob/master/examples/neural_doodle.py\")), mdx(\"h1\", {\n    \"id\": \"deep-dreams\"\n  }, \"Deep Dreams\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"deepdream\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/google/deepdream\"\n  }, \"https://github.com/google/deepdream\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"cnn-vis: Use CNNs to generate images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jcjohnson/cnn-vis\"\n  }, \"https://github.com/jcjohnson/cnn-vis\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"bat-country: A lightweight, extendible, easy to use Python package for deep dreaming and image generation with Caffe and CNNs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jrosebr1/bat-country\"\n  }, \"https://github.com/jrosebr1/bat-country\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepDreaming with TensorFlow\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"ipn: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://nbviewer.jupyter.org/github/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb\"\n  }, \"http://nbviewer.jupyter.org/github/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"deepdraw\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/auduno/deepdraw\"\n  }, \"https://github.com/auduno/deepdraw\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Understanding Deep Dreams\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.alanzucconi.com/2015/07/06/live-your-deepdream-how-to-recreate-the-inceptionism-effect/\"\n  }, \"http://www.alanzucconi.com/2015/07/06/live-your-deepdream-how-to-recreate-the-inceptionism-effect/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generating Deep Dreams\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog\\uFF1A\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.alanzucconi.com/2016/05/25/generating-deep-dreams/\"\n  }, \"http://www.alanzucconi.com/2016/05/25/generating-deep-dreams/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Audio Deepdream: Optimizing Raw Audio With Convolutional Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Brain\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://wp.nyu.edu/ismir2016/wp-content/uploads/sites/2294/2016/08/ardila-audio.pdf\"\n  }, \"https://wp.nyu.edu/ismir2016/wp-content/uploads/sites/2294/2016/08/ardila-audio.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"examples: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://drive.google.com/drive/folders/0B7NUtSSG_AgqZWF1ajdhSjhEMlk\"\n  }, \"https://drive.google.com/drive/folders/0B7NUtSSG_AgqZWF1ajdhSjhEMlk\"))), mdx(\"h1\", {\n    \"id\": \"image-stylization\"\n  }, \"Image Stylization\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Automatic Portrait Segmentation for Image Stylization\")), mdx(\"img\", {\n    \"src\": \"http://xiaoyongshen.me/webpage_portrait/figures/teaser.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The Chinese University of Hong Kong & Adobe Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page(data+code): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://xiaoyongshen.me/webpage_portrait/index.html\"\n  }, \"http://xiaoyongshen.me/webpage_portrait/index.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cse.cuhk.edu.hk/leojia/papers/portrait_eg16.pdf\"\n  }, \"http://www.cse.cuhk.edu.hk/leojia/papers/portrait_eg16.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Tensorflow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/PetroWu/AutoPortraitMatting\"\n  }, \"https://github.com/PetroWu/AutoPortraitMatting\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Transfiguring Portraits\")), mdx(\"img\", {\n    \"src\": \"/assets/fun_with_dl/Transfiguring_Portraits.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://homes.cs.washington.edu/~kemelmi/Transfiguring_Portraits_Kemelmacher_SIGGRAPH2016.pdf\"\n  }, \"http://homes.cs.washington.edu/~kemelmi/Transfiguring_Portraits_Kemelmacher_SIGGRAPH2016.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Stylize Aesthetic QR Code\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Zhengzhou University & Zhejiang University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.01146\"\n  }, \"https://arxiv.org/abs/1803.01146\"))));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"---\r\nlayout: post\r\ncategory: deep_learning\r\ntitle: Style Transfer\r\ndate: 2015-10-09\r\n---\r\n\r\n# Neural Art\r\n\r\n**A Neural Algorithm of Artistic Style**\r\n\r\n![](/assets/fun_with_dl/a_nerual_algorithm_of_artistic_style.jpg)\r\n\r\n- arxiv: [http://arxiv.org/abs/1508.06576](http://arxiv.org/abs/1508.06576)\r\n- gitxiv: [http://gitxiv.com/posts/jG46ukGod8R7Rdtud/a-neural-algorithm-of-artistic-style](http://gitxiv.com/posts/jG46ukGod8R7Rdtud/a-neural-algorithm-of-artistic-style)\r\n- github: [https://github.com/kaishengtai/neuralart](https://github.com/kaishengtai/neuralart)\r\n- github: [https://github.com/jcjohnson/neural-style](https://github.com/jcjohnson/neural-style)\r\n- github: [https://github.com/andersbll/neural_artistic_style](https://github.com/andersbll/neural_artistic_style)\r\n- ipn: [http://nbviewer.ipython.org/github/Lasagne/Recipes/blob/master/examples/styletransfer/Art%20Style%20Transfer.ipynb](http://nbviewer.ipython.org/github/Lasagne/Recipes/blob/master/examples/styletransfer/Art%20Style%20Transfer.ipynb)\r\n- github: [https://github.com/mbartoli/neural-animation](https://github.com/mbartoli/neural-animation)\r\n- github: [https://github.com/memisevic/artify](https://github.com/memisevic/artify)\r\n- github: [https://github.com/mattya/chainer-gogh](https://github.com/mattya/chainer-gogh)\r\n- github(TensorFlow): [https://github.com/anishathalye/neural-style](https://github.com/anishathalye/neural-style)\r\n- github: [https://github.com/woodrush/neural-art-tf](https://github.com/woodrush/neural-art-tf)\r\n- github: [https://github.com/dmlc/mxnet/tree/master/example/neural-style](https://github.com/dmlc/mxnet/tree/master/example/neural-style)\r\n- demo: [http://deepart.io/](http://deepart.io/)\r\n- github: [https://github.com/Teaonly/easyStyle](https://github.com/Teaonly/easyStyle)\r\n- github: [https://github.com/ckmarkoh/neuralart_tensorflow](https://github.com/ckmarkoh/neuralart_tensorflow)\r\n- github: [https://github.com/fzliu/style-transfer](https://github.com/fzliu/style-transfer)\r\n- github: [https://github.com/titu1994/Neural-Style-Transfer](https://github.com/titu1994/Neural-Style-Transfer)\r\n- github: [https://github.com/saikatbsk/Vincent-AI-Artist](https://github.com/saikatbsk/Vincent-AI-Artist)\r\n- github: [https://github.com/zhaw/neural_style](https://github.com/zhaw/neural_style)\r\n\r\n**Image Style Transfer Using Convolutional Neural Networks**\r\n\r\n- paper: [www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf](www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf)\r\n\r\n**Artificial Startup Style: Neural art about startup fashion**\r\n\r\n![](https://cdn-images-1.medium.com/max/800/1*n2cmWDB42iUij8TCil9yLA.png)\r\n\r\n- blog: [https://medium.com/data-engineering/artificial-startup-style-437f6090b1f7#.8u06gq42e](https://medium.com/data-engineering/artificial-startup-style-437f6090b1f7#.8u06gq42e)\r\n\r\n**From Pixels to Paragraphs: How artistic experiments with deep learning guard us from hype**\r\n\r\n- blog: [https://medium.com/@genekogan/from-pixels-to-paragraphs-eb2763da0e9b#.er3djn9z9](https://medium.com/@genekogan/from-pixels-to-paragraphs-eb2763da0e9b#.er3djn9z9)\r\n\r\n**Experiments with style transfer**\r\n\r\n- website: [http://mtyka.github.io/code/2015/10/02/experiments-with-style-transfer.html](http://mtyka.github.io/code/2015/10/02/experiments-with-style-transfer.html)\r\n\r\n**Style Transfer for Headshot Portraits (SIGGRAPH 2014)**\r\n\r\n![](https://people.csail.mit.edu/yichangshih/portrait_web/teaser.jpg)\r\n\r\n- project: [https://people.csail.mit.edu/yichangshih/portrait_web/](https://people.csail.mit.edu/yichangshih/portrait_web/)\r\n\r\n**Teaching recurrent Neural Networks about Monet**\r\n\r\n![](/assets/fun_with_dl/keras_monet_output_sample.png)\r\n\r\n- blog: [http://blog.manugarri.com/teaching-recurrent-neural-networks-about-monet/](http://blog.manugarri.com/teaching-recurrent-neural-networks-about-monet/)\r\n- github: [https://github.com/manugarri/keras_monet](https://github.com/manugarri/keras_monet)\r\n\r\n**Content Aware Neural Style Transfer**\r\n\r\n- arxiv: [http://arxiv.org/abs/1601.04568](http://arxiv.org/abs/1601.04568)\r\n\r\n**Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis**\r\n\r\n<img src=\"https://raw.githubusercontent.com/chuanli11/CNNMRF/master/data/examples/content.jpg\" width=\"150\" />\r\n<img src=\"https://raw.githubusercontent.com/chuanli11/CNNMRF/master/data/examples/style.jpg\" width=\"150\" />\r\n<img src=\"https://raw.githubusercontent.com/chuanli11/CNNMRF/master/data/examples/Interpolation/3_balanced.png\" width=\"150\" />\r\n\r\n- arxiv: [http://arxiv.org/abs/1601.04589](http://arxiv.org/abs/1601.04589)\r\n- github: [https://github.com/chuanli11/CNNMRF](https://github.com/chuanli11/CNNMRF)\r\n\r\n**Stylenet: Neural Network with Style Synthesis**\r\n\r\n- github: [https://github.com/machrisaa/stylenet](https://github.com/machrisaa/stylenet)\r\n\r\n**Ostagram**\r\n\r\n- intro: This program presents web-service for algorithm combining the content of one image \r\nwith the style of another image using convolutional neural networks\r\n- github: [https://github.com/SergeyMorugin/ostagram](https://github.com/SergeyMorugin/ostagram)\r\n\r\n**Exploring the Neural Algorithm of Artistic Style**\r\n\r\n- intro: A short class project report\r\n- arxiv: [http://arxiv.org/abs/1602.07188](http://arxiv.org/abs/1602.07188)\r\n\r\n**Perceptual Losses for Real-Time Style Transfer and Super-Resolution**\r\n\r\n![](https://github.com/jcjohnson/fast-neural-style/blob/master/images/webcam.gif?raw=true)\r\n\r\n- intro: Justin Johnson, Alexandre Alahi, Li Fei-Fei. ECCV 2016\r\n- arxiv: [http://arxiv.org/abs/1603.08155](http://arxiv.org/abs/1603.08155)\r\n- github: [https://github.com/jcjohnson/fast-neural-style](https://github.com/jcjohnson/fast-neural-style)\r\n- github: [https://github.com/yusuketomoto/chainer-fast-neuralstyle](https://github.com/yusuketomoto/chainer-fast-neuralstyle)\r\n- github: [https://github.com/awentzonline/keras-rtst](https://github.com/awentzonline/keras-rtst)\r\n- github(Keras): [https://github.com/titu1994/Fast-Neural-Style](https://github.com/titu1994/Fast-Neural-Style)\r\n- gtihub(Tensorflow): [https://github.com/junrushao1994/fast-neural-style.tf] (https://github.com/junrushao1994/fast-neural-style.tf)\r\n- github(PyTorch): [https://github.com/bengxy/FastNeuralStyle](https://github.com/bengxy/FastNeuralStyle)\r\n\r\n**Image transformation networks with fancy loss functions**\r\n\r\n- intro: Fast neural style in tensorflow based on [http://arxiv.org/abs/1603.08155](http://arxiv.org/abs/1603.08155)\r\n- blog: [http://olavnymoen.com/2016/07/07/image-transformation-network](http://olavnymoen.com/2016/07/07/image-transformation-network)\r\n- github: [https://github.com/OlavHN/fast-neural-style](https://github.com/OlavHN/fast-neural-style)\r\n\r\n**Improving the Neural Algorithm of Artistic Style**\r\n\r\n- arxiv: [http://arxiv.org/abs/1605.04603](http://arxiv.org/abs/1605.04603)\r\n\r\n**CubistMirror: an openframeworks app which repeatedly applies real-time style transfer on a webcam**\r\n\r\n![](https://raw.githubusercontent.com/genekogan/CubistMirror/master/photos/cubist_mirror_1.jpg)\r\n\r\n- github: [https://github.com/genekogan/CubistMirror](https://github.com/genekogan/CubistMirror)\r\n\r\n**Transfer Style But Not Color**\r\n\r\n![](https://raw.githubusercontent.com/pavelgonchar/color-independent-style-transfer/master/results-ny.jpg)\r\n\r\n- blog: [http://blog.deepart.io/2016/06/04/color-independent-style-transfer/](http://blog.deepart.io/2016/06/04/color-independent-style-transfer/)\r\n- github: [https://github.com/pavelgonchar/color-independent-style-transfer](https://github.com/pavelgonchar/color-independent-style-transfer)\r\n\r\n**neural-art-mini: Lightweight version of mxnet neural art implementation**\r\n\r\n- intro: Lightweight version of mxnet neural art implementation using ~4.8M SqueezeNet model. \r\nCompressed model is less than 500KB\r\n- github: [https://github.com/pavelgonchar/neural-art-mini](https://github.com/pavelgonchar/neural-art-mini)\r\n\r\n**Preserving Color in Neural Artistic Style Transfer**\r\n\r\n- arxiv: [http://arxiv.org/abs/1606.05897](http://arxiv.org/abs/1606.05897)\r\n\r\n**End to End Neural Art with Generative Models**\r\n\r\n![](https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/art/net.png)\r\n\r\n- blog: [http://dmlc.ml/mxnet/2016/06/20/end-to-end-neural-style.html](http://dmlc.ml/mxnet/2016/06/20/end-to-end-neural-style.html)\r\n- github: [https://github.com/dmlc/mxnet/tree/master/example/neural-style](https://github.com/dmlc/mxnet/tree/master/example/neural-style)\r\n\r\n**Neural Style Explained**\r\n\r\n- blog: [http://kvfrans.com/neural-style-explained/](http://kvfrans.com/neural-style-explained/)\r\n- github: [https://github.com/kvfrans/neural-style](https://github.com/kvfrans/neural-style)\r\n\r\n**Texture Networks: Feed-forward Synthesis of Textures and Stylized Images**\r\n\r\n- intro: IMCL 2016\r\n- arxiv: [http://arxiv.org/abs/1603.03417](http://arxiv.org/abs/1603.03417)\r\n- github: [https://github.com/DmitryUlyanov/texture_nets](https://github.com/DmitryUlyanov/texture_nets)\r\n- notes: [https://blog.acolyer.org/2016/09/23/texture-networks-feed-forward-synthesis-of-textures-and-stylized-images/](https://blog.acolyer.org/2016/09/23/texture-networks-feed-forward-synthesis-of-textures-and-stylized-images/)\r\n- github: [https://github.com/tgyg-jegli/tf_texture_net](https://github.com/tgyg-jegli/tf_texture_net)\r\n\r\n**Learning Typographic Style**\r\n\r\n- arxiv: [https://arxiv.org/abs/1603.04000](https://arxiv.org/abs/1603.04000)\r\n\r\n**Instance Normalization: The Missing Ingredient for Fast Stylization**\r\n\r\n- arxiv: [http://arxiv.org/abs/1607.08022](http://arxiv.org/abs/1607.08022)\r\n\r\n**Painting style transfer for head portraits using convolutional neural networks**\r\n\r\n- paper: [http://dl.acm.org/citation.cfm?id=2925968](http://dl.acm.org/citation.cfm?id=2925968)\r\n- sci-hub: [http://dl.acm.org.sci-hub.cc/citation.cfm?doid=2897824.2925968](http://dl.acm.org.sci-hub.cc/citation.cfm?doid=2897824.2925968)\r\n\r\n**Style-Transfer via Texture-Synthesis**\r\n\r\n- arxiv: [http://arxiv.org/abs/1609.03057](http://arxiv.org/abs/1609.03057)\r\n\r\n**neural-style-tf: TensorFlow implementation of Neural Style**\r\n\r\n- github: [https://github.com/cysmith/neural-style-tf](https://github.com/cysmith/neural-style-tf)\r\n\r\n**Deep Convolutional Networks as Models of Generalization and Blending Within Visual Creativity**\r\n\r\n- intro: In Proceedings of the 7th International Conference on Computational Creativity. Palo Alto: Association for the Advancement of Artificial Intelligence (AAAI) Press (2016)\r\n- arxiv: [https://arxiv.org/abs/1610.02478](https://arxiv.org/abs/1610.02478)\r\n\r\n**A Learned Representation For Artistic Style**\r\n\r\n- intro: Google Brain\r\n- arxiv: [https://arxiv.org/abs/1610.07629](https://arxiv.org/abs/1610.07629)\r\n- blog: [https://research.googleblog.com/2016/10/supercharging-style-transfer.html](https://research.googleblog.com/2016/10/supercharging-style-transfer.html)\r\n- github: [https://github.com/tensorflow/magenta/tree/master/magenta/models/image_stylization](https://github.com/tensorflow/magenta/tree/master/magenta/models/image_stylization)\r\n- github(Tensorflow): [https://github.com/Heumi/Fast_Multi_Style_Transfer-tf](https://github.com/Heumi/Fast_Multi_Style_Transfer-tf)\r\n\r\n**How to Fake It As an Artist with Docker, AWS and Deep Learning**\r\n\r\n- blog: [https://medium.com/@lherrera/how-to-fake-it-as-an-artist-with-docker-aws-and-deep-learning-6d42f4acd890#.eq9gcgkzh](https://medium.com/@lherrera/how-to-fake-it-as-an-artist-with-docker-aws-and-deep-learning-6d42f4acd890#.eq9gcgkzh)\r\n\r\n**Multistyle Pastiche Generator**\r\n\r\n- blog: [https://magenta.tensorflow.org/2016/11/01/multistyle-pastiche-generator/](https://magenta.tensorflow.org/2016/11/01/multistyle-pastiche-generator/)\r\n\r\n**Fast Style Transfer in TensorFlow**\r\n\r\n- intro: Video Stylization, Image Stylization\r\n- github: [https://github.com/lengstrom/fast-style-transfer](https://github.com/lengstrom/fast-style-transfer)\r\n\r\n**Neural Style Transfer For Chinese Fonts**\r\n\r\n![](https://raw.githubusercontent.com/kaonashi-tyc/Rewrite/master/images/mixed_font.gif)\r\n\r\n- github: [https://github.com/kaonashi-tyc/Rewrite](https://github.com/kaonashi-tyc/Rewrite)\r\n\r\n**Neural Style Representations and the Large-Scale Classification of Artistic Style**\r\n\r\n- arxiv: [https://arxiv.org/abs/1611.05368](https://arxiv.org/abs/1611.05368)\r\n\r\n**Controlling Perceptual Factors in Neural Style Transfer**\r\n\r\n- intro: University of Tubingen & Adobe Research\r\n- arxiv: [https://arxiv.org/abs/1611.07865](https://arxiv.org/abs/1611.07865)\r\n\r\n**Awesome Typography: Statistics-Based Text Effects Transfer**\r\n\r\n- arxiv: [https://arxiv.org/abs/1611.09026](https://arxiv.org/abs/1611.09026)\r\n\r\n**Fast Patch-based Style Transfer of Arbitrary Style**\r\n\r\n- arxiv: [https://arxiv.org/abs/1612.04337](https://arxiv.org/abs/1612.04337)\r\n- github: [https://github.com/rtqichen/style-swap](https://github.com/rtqichen/style-swap)\r\n\r\n**Demystifying Neural Style Transfer**\r\n\r\n- intro: IJCAI 2017\r\n- intro: Peking University & TuSimple\r\n- arxiv: [https://arxiv.org/abs/1701.01036](https://arxiv.org/abs/1701.01036)\r\n- github: [https://github.com/lyttonhao/Neural-Style-MMD](https://github.com/lyttonhao/Neural-Style-MMD)\r\n\r\n**Son of Zorn's Lemma: Targeted Style Transfer Using Instance-aware Semantic Segmentation**\r\n\r\n- arxiv: [https://arxiv.org/abs/1701.02357](https://arxiv.org/abs/1701.02357)\r\n\r\n**Bringing Impressionism to Life with Neural Style Transfer in Come Swim**\r\n\r\n- intro: a case study of how Neural Style Transfer can be used in a movie production context\r\n- keywords: Kristen Stewart !\r\n- arxiv: [https://arxiv.org/abs/1701.04928](https://arxiv.org/abs/1701.04928)\r\n\r\n**Pytorch tutorials for Neural Style transfert**\r\n\r\n- github: [https://github.com/alexis-jacq/Pytorch-Tutorials](https://github.com/alexis-jacq/Pytorch-Tutorials)\r\n\r\n**Stable and Controllable Neural Texture Synthesis and Style Transfer Using Histogram Losses**\r\n\r\n- arxiv: [https://arxiv.org/abs/1701.08893](https://arxiv.org/abs/1701.08893)\r\n\r\n**Arbitrary Style Transfer In Real-Time With Adaptive Instance Normalization**\r\n\r\n- intro: ICCV 2017. Cornell University\r\n- paper: [https://openreview.net/pdf?id=B1fUVMzKg](https://openreview.net/pdf?id=B1fUVMzKg)\r\n- github(Torch): [https://github.com/xunhuang1995/AdaIN-style](https://github.com/xunhuang1995/AdaIN-style)\r\n- github(TensorFlow): [https://github.com/elleryqueenhomels/arbitrary_style_transfer](https://github.com/elleryqueenhomels/arbitrary_style_transfer)\r\n\r\n**Picking an optimizer for Style Transfer**\r\n\r\n- blog: [https://medium.com/slavv/picking-an-optimizer-for-style-transfer-86e7b8cba84b#.cgv2oreaq](https://medium.com/slavv/picking-an-optimizer-for-style-transfer-86e7b8cba84b#.cgv2oreaq)\r\n- github: [https://github.com/slavivanov/Style-Tranfer](https://github.com/slavivanov/Style-Tranfer)\r\n\r\n**Multi-style Generative Network for Real-time Transfer**\r\n\r\n[https://arxiv.org/abs/1703.06953](https://arxiv.org/abs/1703.06953)\r\n\r\n**Deep Photo Style Transfer**\r\n\r\n- arxiv: [https://arxiv.org/abs/1703.07511](https://arxiv.org/abs/1703.07511)\r\n- github(Torch): [https://github.com/luanfujun/deep-photo-styletransfer](https://github.com/luanfujun/deep-photo-styletransfer)\r\n- github(Docker): [https://github.com/martinbenson/deep-photo-styletransfer](https://github.com/martinbenson/deep-photo-styletransfer)\r\n\r\n**Lightweight Neural Style on Pytorch**\r\n\r\n[https://github.com/lizeng614/SqueezeNet-Neural-Style-Pytorch](https://github.com/lizeng614/SqueezeNet-Neural-Style-Pytorch)\r\n\r\n**StyleBank: An Explicit Representation for Neural Image Style Transfer**\r\n\r\n- intro: CVPR 2017\r\n- arxiv: [https://arxiv.org/abs/1703.09210](https://arxiv.org/abs/1703.09210)\r\n\r\n**How to Make an Image More Memorable? A Deep Style Transfer Approach**\r\n\r\n- intro: ACM ICMR 2017\r\n- arxiv: [https://arxiv.org/abs/1704.01745](https://arxiv.org/abs/1704.01745)\r\n\r\n**Visual Attribute Transfer through Deep Image Analogy**\r\n\r\n- intro: SIGGRAPH 2017\r\n- keywords: Deep Image Analogy\r\n- arxiv: [https://arxiv.org/abs/1705.01088](https://arxiv.org/abs/1705.01088)\r\n- github: [https://github.com/msracver/Deep-Image-Analogy](https://github.com/msracver/Deep-Image-Analogy)\r\n\r\n**Characterizing and Improving Stability in Neural Style Transfer**\r\n\r\n[https://arxiv.org/abs/1705.02092](https://arxiv.org/abs/1705.02092)\r\n\r\n**Towards Metamerism via Foveated Style Transfer**\r\n\r\n[https://arxiv.org/abs/1705.10041](https://arxiv.org/abs/1705.10041)\r\n\r\n**Style Transfer for Sketches with Enhanced Residual U-net and Auxiliary Classifier GAN**\r\n\r\n[https://arxiv.org/abs/1706.03319](https://arxiv.org/abs/1706.03319)\r\n\r\n**Meta Networks for Neural Style Transfer**\r\n\r\n- arxiv: [https://arxiv.org/abs/1709.04111](https://arxiv.org/abs/1709.04111)\r\n- github: [https://github.com/FalongShen/styletransfer](https://github.com/FalongShen/styletransfer)\r\n\r\n**Neural Color Transfer between Images**\r\n\r\n- intro: Hong Kong University of Science and Technology & Microsoft Research\r\n- arxiv: [https://arxiv.org/abs/1710.00756](https://arxiv.org/abs/1710.00756)\r\n\r\n**Improved Style Transfer by Respecting Inter-layer Correlations**\r\n\r\n[https://arxiv.org/abs/1801.01933](https://arxiv.org/abs/1801.01933)\r\n\r\n**Face Destylization**\r\n\r\n[https://arxiv.org/abs/1802.01237](https://arxiv.org/abs/1802.01237)\r\n\r\n**Unsupervised Typography Transfer**\r\n\r\n[https://arxiv.org/abs/1802.02595](https://arxiv.org/abs/1802.02595)\r\n\r\n**Stereoscopic Neural Style Transfer**\r\n\r\n- intro: CVPR 2018\r\n- arxiv: [https://arxiv.org/abs/1802.10591](https://arxiv.org/abs/1802.10591)\r\n\r\n**Arbitrary Style Transfer with Deep Feature Reshuffle**\r\n\r\n[https://arxiv.org/abs/1805.04103](https://arxiv.org/abs/1805.04103)\r\n\r\n**Avatar-Net: Multi-scale Zero-shot Style Transfer by Feature Decoration**\r\n\r\n- intro: CVPR 2018. CUHK & SenseTime\r\n- arxiv: [https://arxiv.org/abs/1805.03857](https://arxiv.org/abs/1805.03857)\r\n\r\n**Beyond Textures: Learning from Multi-domain Artistic Images for Arbitrary Style Transfer**\r\n\r\n[https://arxiv.org/abs/1805.09987](https://arxiv.org/abs/1805.09987)\r\n\r\n**A Comprehensive Comparison between Neural Style Transfer and Universal Style Transfer**\r\n\r\n[https://arxiv.org/abs/1806.00868](https://arxiv.org/abs/1806.00868)\r\n\r\n**Unbiased Image Style Transfer**\r\n\r\n[https://arxiv.org/abs/1807.01424](https://arxiv.org/abs/1807.01424)\r\n\r\n**Uncorrelated Feature Encoding for Faster Image Style Transfer**\r\n\r\n[https://arxiv.org/abs/1807.01493](https://arxiv.org/abs/1807.01493)\r\n\r\n**Adjustable Real-time Style Transfer**\r\n\r\n- intro: University of Illinois at Urbana-Champaign && Google Brain\r\n- arxiv: [https://arxiv.org/abs/1811.08560](https://arxiv.org/abs/1811.08560)\r\n\r\n**Automated Deep Photo Style Transfer**\r\n\r\n- intro: University of Tubingen\r\n- arxiv: [https://arxiv.org/abs/1901.03915](https://arxiv.org/abs/1901.03915)\r\n\r\n**Attention-aware Multi-stroke Style Transfer**\r\n\r\n[https://arxiv.org/abs/1901.05127](https://arxiv.org/abs/1901.05127)\r\n\r\n**StyleNAS: An Empirical Study of Neural Architecture Search to Uncover Surprisingly Fast End-to-End Universal Style Transfer Networks**\r\n\r\n[https://arxiv.org/abs/1906.02470](https://arxiv.org/abs/1906.02470)\r\n\r\n**StyleNAS: An Empirical Study of Neural Architecture Search to Uncover Surprisingly Fast End-to-End Universal Style Transfer Networks**\r\n\r\n[https://arxiv.org/abs/1906.02470](https://arxiv.org/abs/1906.02470)\r\n\r\n# Neural Art On Audio\r\n\r\n**MSc AI Project on generative deep networks and neural style transfer for audio**\r\n\r\n- github: [https://github.com/Fr-d-rik/generative_audio](https://github.com/Fr-d-rik/generative_audio)\r\n- project report: [https://github.com/Fr-d-rik/generative_audio/blob/master/docs/project_report.pdf](https://github.com/Fr-d-rik/generative_audio/blob/master/docs/project_report.pdf)\r\n\r\n**Neural Song Style**\r\n\r\n- intro: Audio style transfer AI\r\n- github: [https://github.com/rupeshs/neuralsongstyle](https://github.com/rupeshs/neuralsongstyle)\r\n\r\n**Time Domain Neural Audio Style Transfer**\r\n\r\n- intro: NIPS 2017\r\n- arxiv: [https://arxiv.org/abs/1711.11160](https://arxiv.org/abs/1711.11160)\r\n- github: [https://github.com//pkmital/time-domain-neural-audio-style-transfer](https://github.com//pkmital/time-domain-neural-audio-style-transfer)\r\n\r\n**Learning Linear Transformations for Fast Arbitrary Style Transfer**\r\n\r\n[https://arxiv.org/abs/1808.04537](https://arxiv.org/abs/1808.04537)\r\n\r\n# Neural Art On Video\r\n\r\n**neural-style-video**\r\n\r\n- blog: [http://larseidnes.com/2015/12/18/painting-videos-with-neural-networks/](http://larseidnes.com/2015/12/18/painting-videos-with-neural-networks/)\r\n- github: [https://github.com/larspars/neural-style-video](https://github.com/larspars/neural-style-video)\r\n\r\n**Instructions for making a Neural-Style movie**\r\n\r\n- website: [https://gist.github.com/genekogan/d61c8010d470e1dbe15d](https://gist.github.com/genekogan/d61c8010d470e1dbe15d)\r\n- sample: [https://vimeo.com/139123754](https://vimeo.com/139123754)\r\n\r\n**Artistic style transfer for videos**\r\n\r\n- arxiv: [http://arxiv.org/abs/1604.08610](http://arxiv.org/abs/1604.08610)\r\n- github: [https://github.com/manuelruder/artistic-videos](https://github.com/manuelruder/artistic-videos)\r\n\r\n**Artistic style transfer for videos and spherical images**\r\n\r\n[https://arxiv.org/abs/1708.04538](https://arxiv.org/abs/1708.04538)\r\n\r\n**How Deep Learning Can Paint Videos in the Style of Art’s Great Masters**\r\n\r\n![](https://blogs.nvidia.com/wp-content/uploads/2016/05/artistic-video-1200x528.jpg)\r\n\r\n- blog: [https://blogs.nvidia.com/blog/2016/05/25/deep-learning-paints-videos/](https://blogs.nvidia.com/blog/2016/05/25/deep-learning-paints-videos/)\r\n\r\n**DeepMovie: Using Optical Flow and Deep Neural Networks to Stylize Movies**\r\n\r\n- arxiv: [http://arxiv.org/abs/1605.08153](http://arxiv.org/abs/1605.08153)\r\n\r\n**Coherent Online Video Style Transfer**\r\n\r\n[https://arxiv.org/abs/1703.09211](https://arxiv.org/abs/1703.09211)\r\n\r\n**Laplacian-Steered Neural Style Transfer**\r\n\r\n- intro: ACM Multimedia Conference (MM) 2017\r\n- arxiv: [https://arxiv.org/abs/1707.01253](https://arxiv.org/abs/1707.01253)\r\n\r\n**Real-Time Neural Style Transfer for Videos**\r\n\r\n- intro: Tsinghua University & Tencent AI Lab\r\n- paper: [http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Real-Time_Neural_Style_CVPR_2017_paper.pdf](http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Real-Time_Neural_Style_CVPR_2017_paper.pdf)\r\n\r\n**Multi-Content GAN for Few-Shot Font Style Transfer**\r\n\r\n[https://arxiv.org/abs/1712.00516](https://arxiv.org/abs/1712.00516)\r\n\r\n**Deep Painterly Harmonization**\r\n\r\n- arxiv: [https://arxiv.org/abs/1804.03189](https://arxiv.org/abs/1804.03189)\r\n- github: [https://github.com/luanfujun/deep-painterly-harmonization](https://github.com/luanfujun/deep-painterly-harmonization)\r\n\r\n**ReCoNet: Real-time Coherent Video Style Transfer Network**\r\n\r\n- intro: The University of Hong Kong\r\n- arixv: [https://arxiv.org/abs/1807.01197](https://arxiv.org/abs/1807.01197)\r\n- supp: [https://www.dropbox.com/s/go6f7uopjjsala7/ReCoNet%20Supplementary%20Material.pdf?dl=0](https://www.dropbox.com/s/go6f7uopjjsala7/ReCoNet%20Supplementary%20Material.pdf?dl=0)\r\n\r\n**Fully-Featured Attribute Transfer**\r\n\r\n[https://arxiv.org/abs/1902.06258](https://arxiv.org/abs/1902.06258)\r\n\r\n# Neural Doodle\r\n\r\n**Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks**\r\n\r\n- paper: [http://nucl.ai/semantic-style-transfer.pdf](http://nucl.ai/semantic-style-transfer.pdf)\r\n- reddit: [https://www.reddit.com/r/MachineLearning/comments/48zstj/my_wip_implementation_of_neural_image_analogies/](https://www.reddit.com/r/MachineLearning/comments/48zstj/my_wip_implementation_of_neural_image_analogies/)\r\n- github: [https://github.com/alexjc/neural-doodle](https://github.com/alexjc/neural-doodle)\r\n\r\n**Neural Doodle**\r\n\r\n![](https://raw.githubusercontent.com/alexjc/neural-doodle/master/docs/Workflow.gif)\r\n![](https://raw.githubusercontent.com/alexjc/neural-doodle/master/docs/Landscape_example.png)\r\n\r\n- github: [https://github.com/alexjc/neural-doodle](https://github.com/alexjc/neural-doodle)\r\n\r\n**Faster neural doodle**\r\n\r\n![](https://raw.githubusercontent.com/DmitryUlyanov/fast-neural-doodle/master/data/Renoir/grid.png)\r\n\r\n- github: [https://github.com/DmitryUlyanov/fast-neural-doodle](https://github.com/DmitryUlyanov/fast-neural-doodle)\r\n\r\n**Feed-forward neural doodle**\r\n\r\n![](https://raw.githubusercontent.com/DmitryUlyanov/online-neural-doodle/master/data/starry/grid.png)\r\n\r\n- blog: [http://dmitryulyanov.github.io/feed-forward-neural-doodle/](http://dmitryulyanov.github.io/feed-forward-neural-doodle/)\r\n- github: [https://github.com/DmitryUlyanov/online-neural-doodle](https://github.com/DmitryUlyanov/online-neural-doodle)\r\n- demo: [http://likemo.net/](http://likemo.net/)\r\n\r\n**neural image analogies: Generate image analogies using neural matching and blending**\r\n\r\n![](https://raw.githubusercontent.com/awentzonline/image-analogies/master/examples/images/sugarskull-analogy.jpg)\r\n\r\n- github: [https://github.com/awentzonline/image-analogies](https://github.com/awentzonline/image-analogies)\r\n\r\n**Neural doodle with Keras**\r\n\r\n[https://github.com/fchollet/keras/blob/master/examples/neural_doodle.py](https://github.com/fchollet/keras/blob/master/examples/neural_doodle.py)\r\n\r\n# Deep Dreams\r\n\r\n**deepdream**\r\n\r\n- github: [https://github.com/google/deepdream](https://github.com/google/deepdream)\r\n\r\n**cnn-vis: Use CNNs to generate images**\r\n\r\n- github: [https://github.com/jcjohnson/cnn-vis](https://github.com/jcjohnson/cnn-vis)\r\n\r\n**bat-country: A lightweight, extendible, easy to use Python package for deep dreaming and image generation with Caffe and CNNs**\r\n\r\n- github: [https://github.com/jrosebr1/bat-country](https://github.com/jrosebr1/bat-country)\r\n\r\n**DeepDreaming with TensorFlow**\r\n\r\n- ipn: [http://nbviewer.jupyter.org/github/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb](http://nbviewer.jupyter.org/github/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb)\r\n\r\n**deepdraw**\r\n\r\n- github: [https://github.com/auduno/deepdraw](https://github.com/auduno/deepdraw)\r\n\r\n**Understanding Deep Dreams**\r\n\r\n- blog: [http://www.alanzucconi.com/2015/07/06/live-your-deepdream-how-to-recreate-the-inceptionism-effect/](http://www.alanzucconi.com/2015/07/06/live-your-deepdream-how-to-recreate-the-inceptionism-effect/)\r\n\r\n**Generating Deep Dreams**\r\n\r\n- blog：[http://www.alanzucconi.com/2016/05/25/generating-deep-dreams/](http://www.alanzucconi.com/2016/05/25/generating-deep-dreams/)\r\n\r\n**Audio Deepdream: Optimizing Raw Audio With Convolutional Networks**\r\n\r\n- intro: Google Brain\r\n- paper: [https://wp.nyu.edu/ismir2016/wp-content/uploads/sites/2294/2016/08/ardila-audio.pdf](https://wp.nyu.edu/ismir2016/wp-content/uploads/sites/2294/2016/08/ardila-audio.pdf)\r\n- examples: [https://drive.google.com/drive/folders/0B7NUtSSG_AgqZWF1ajdhSjhEMlk](https://drive.google.com/drive/folders/0B7NUtSSG_AgqZWF1ajdhSjhEMlk)\r\n\r\n# Image Stylization\r\n\r\n**Automatic Portrait Segmentation for Image Stylization**\r\n\r\n![](http://xiaoyongshen.me/webpage_portrait/figures/teaser.png)\r\n\r\n- intro: The Chinese University of Hong Kong & Adobe Research\r\n- project page(data+code): [http://xiaoyongshen.me/webpage_portrait/index.html](http://xiaoyongshen.me/webpage_portrait/index.html)\r\n- paper: [http://www.cse.cuhk.edu.hk/leojia/papers/portrait_eg16.pdf](http://www.cse.cuhk.edu.hk/leojia/papers/portrait_eg16.pdf)\r\n- github(Tensorflow): [https://github.com/PetroWu/AutoPortraitMatting](https://github.com/PetroWu/AutoPortraitMatting)\r\n\r\n**Transfiguring Portraits**\r\n\r\n![](/assets/fun_with_dl/Transfiguring_Portraits.jpg)\r\n\r\n- paper: [http://homes.cs.washington.edu/~kemelmi/Transfiguring_Portraits_Kemelmacher_SIGGRAPH2016.pdf](http://homes.cs.washington.edu/~kemelmi/Transfiguring_Portraits_Kemelmacher_SIGGRAPH2016.pdf)\r\n\r\n**Stylize Aesthetic QR Code**\r\n\r\n- intro: Zhengzhou University & Zhejiang University\r\n- arxiv: [https://arxiv.org/abs/1803.01146](https://arxiv.org/abs/1803.01146)\r\n","excerpt":"Neural Art A Neural Algorithm of Artistic Style arxiv:  http://arxiv.org/abs/1508.06576 gitxiv:  http://gitxiv.com/posts/jG46ukGod8R7Rdtud/…","outboundReferences":[],"inboundReferences":[]},"tagsOutbound":{"nodes":[]}},"pageContext":{"tags":[],"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-style-transfer/","sidebarItems":[{"title":"Categories","items":[{"title":"Commercial","url":"","items":[{"title":"Commercial Structure","url":"/Commercial/Commercial Structure/","items":[]},{"title":"Community of Practice","url":"/Commercial/Community of Practice/","items":[]},{"title":"Domains","url":"/Commercial/Domains/","items":[]},{"title":"Webizen Alliance","url":"/Commercial/Webizen Alliance/","items":[]}]},{"title":"Core Services","url":"","items":[{"title":"Decentralised Ontologies","url":"/Core Services/Decentralised Ontologies/","items":[]},{"title":"Permissive Commons","url":"/Core Services/Permissive Commons/","items":[]},{"title":"Safety Protocols","url":"","items":[{"title":"Safety Protocols","url":"/Core Services/Safety Protocols/Safety Protocols/","items":[]},{"title":"Social Factors","url":"","items":[{"title":"Best Efforts","url":"/Core Services/Safety Protocols/Social Factors/Best Efforts/","items":[]},{"title":"Ending Digital Slavery","url":"/Core Services/Safety Protocols/Social Factors/Ending Digital Slavery/","items":[]},{"title":"Freedom of Thought","url":"/Core Services/Safety Protocols/Social Factors/Freedom of Thought/","items":[]},{"title":"No Golden Handcuffs","url":"/Core Services/Safety Protocols/Social Factors/No Golden Handcuffs/","items":[]},{"title":"Relationships (Social)","url":"/Core Services/Safety Protocols/Social Factors/Relationships (Social)/","items":[]},{"title":"Social Attack Vectors","url":"/Core Services/Safety Protocols/Social Factors/Social Attack Vectors/","items":[]},{"title":"The Webizen Charter","url":"/Core Services/Safety Protocols/Social Factors/The Webizen Charter/","items":[]}]},{"title":"Values Credentials","url":"/Core Services/Safety Protocols/Values Credentials/","items":[]}]},{"title":"Temporal Semantics","url":"/Core Services/Temporal Semantics/","items":[]},{"title":"Verifiable Claims & Credentials","url":"/Core Services/Verifiable Claims & Credentials/","items":[]},{"title":"Webizen Socio-Economics","url":"","items":[{"title":"Biosphere Ontologies","url":"/Core Services/Webizen Socio-Economics/Biosphere Ontologies/","items":[]},{"title":"Centricity","url":"/Core Services/Webizen Socio-Economics/Centricity/","items":[]},{"title":"Currencies","url":"/Core Services/Webizen Socio-Economics/Currencies/","items":[]},{"title":"SocioSphere Ontologies","url":"/Core Services/Webizen Socio-Economics/SocioSphere Ontologies/","items":[]},{"title":"Sustainable Development Goals (ESG)","url":"/Core Services/Webizen Socio-Economics/Sustainable Development Goals (ESG)/","items":[]}]}]},{"title":"Core Technologies","url":"","items":[{"title":"AUTH","url":"","items":[{"title":"Authentication Fabric","url":"/Core Technologies/AUTH/Authentication Fabric/","items":[]}]},{"title":"Webizen App Spec","url":"","items":[{"title":"SemWebSpecs","url":"","items":[{"title":"Core Ontologies","url":"","items":[{"title":"FOAF","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/FOAF/","items":[]},{"title":"General Ontology Information","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/General Ontology Information/","items":[]},{"title":"Human Rights Ontologies","url":"","items":[{"title":"UDHR","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/Human Rights Ontologies/UDHR/","items":[]}]},{"title":"MD-RDF Ontologies","url":"","items":[{"title":"DataTypesOntology (DTO) Core","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/MD-RDF Ontologies/DataTypes Ontology/","items":[]},{"title":"Friend of a Friend (FOAF) Core","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/MD-RDF Ontologies/FOAF/","items":[]}]},{"title":"OWL","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/OWL/","items":[]},{"title":"RDF Schema 1.1","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/RDFS/","items":[]},{"title":"Sitemap","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/Sitemap/","items":[]},{"title":"SKOS","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/SKOS/","items":[]},{"title":"SOIC","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/SOIC/","items":[]}]},{"title":"Semantic Web - An Introduction","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Semantic Web - An Introduction/","items":[]},{"title":"SemWeb-AUTH","url":"","items":[{"title":"WebID-OIDC","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-OIDC/","items":[]},{"title":"WebID-RSA","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-RSA/","items":[]},{"title":"WebID-TLS","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-TLS/","items":[]}]},{"title":"Sparql","url":"","items":[{"title":"Sparql Family","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Sparql/Sparql Family/","items":[]}]},{"title":"W3C Specifications","url":"","items":[{"title":"Linked Data Fragments","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Fragments/","items":[]},{"title":"Linked Data Notifications","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Notifications/","items":[]},{"title":"Linked Data Platform","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Platform/","items":[]},{"title":"Linked Media Fragments","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Media Fragments/","items":[]},{"title":"RDF","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/RDF/","items":[]},{"title":"Web Access Control (WAC)","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Web Access Control (WAC)/","items":[]},{"title":"Web Of Things","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Web Of Things/","items":[]},{"title":"WebID","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/WebID/","items":[]}]}]},{"title":"Webizen App Spec 1.0","url":"/Core Technologies/Webizen App Spec/Webizen App Spec 1.0/","items":[]},{"title":"WebSpec","url":"","items":[{"title":"HTML SPECS","url":"/Core Technologies/Webizen App Spec/WebSpec/HTML SPECS/","items":[]},{"title":"Query Interfaces","url":"","items":[{"title":"GraphQL","url":"/Core Technologies/Webizen App Spec/WebSpec/Query Interfaces/GraphQL/","items":[]}]},{"title":"WebPlatformTools","url":"","items":[{"title":"WebAuthn","url":"/Core Technologies/Webizen App Spec/WebSpec/WebPlatformTools/WebAuthn/","items":[]},{"title":"WebDav","url":"/Core Technologies/Webizen App Spec/WebSpec/WebPlatformTools/WebDav/","items":[]}]}]}]}]},{"title":"Database Requirements","url":"","items":[{"title":"Database Alternatives","url":"","items":[{"title":"Akutan","url":"/Database requirements/Database Alternatives/akutan/","items":[]},{"title":"CayleyGraph","url":"/Database requirements/Database Alternatives/CayleyGraph/","items":[]}]},{"title":"Database Methods","url":"","items":[{"title":"GraphQL","url":"/Database requirements/Database methods/GraphQL/","items":[]},{"title":"Sparql","url":"/Database requirements/Database methods/Sparql/","items":[]}]}]},{"title":"Host Service Requirements","url":"","items":[{"title":"Domain Hosting","url":"/Host Service Requirements/Domain Hosting/","items":[]},{"title":"Email Services","url":"/Host Service Requirements/Email Services/","items":[]},{"title":"LD_PostOffice_SemanticMGR","url":"/Host Service Requirements/LD_PostOffice_SemanticMGR/","items":[]},{"title":"Media Processing","url":"/Host Service Requirements/Media Processing/","items":[{"title":"Ffmpeg","url":"/Host Service Requirements/Media Processing/ffmpeg/","items":[]},{"title":"Opencv","url":"/Host Service Requirements/Media Processing/opencv/","items":[]}]},{"title":"Website Host","url":"/Host Service Requirements/Website Host/","items":[]}]},{"title":"ICT Stack","url":"","items":[{"title":"General References","url":"","items":[{"title":"List of Protocols ISO Model","url":"/ICT Stack/General References/List of Protocols ISO model/","items":[]}]},{"title":"Internet","url":"","items":[{"title":"Internet Stack","url":"/ICT Stack/Internet/Internet Stack/","items":[]}]}]},{"title":"Implementation V1","url":"","items":[{"title":"App-Design-Sdk-V1","url":"","items":[{"title":"Core Apps","url":"","items":[{"title":"Agent Directory","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Agent Directory/","items":[]},{"title":"Credentials & Contracts Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Credentials & Contracts Manager/","items":[]},{"title":"File (Package) Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/File (package) Manager/","items":[]},{"title":"Temporal Apps","url":"","items":[{"title":"Calendar","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Temporal Apps/Calendar/","items":[]},{"title":"Timeline Interface","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Temporal Apps/Timeline Interface/","items":[]}]},{"title":"Webizen Apps (V1)","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Webizen Apps (v1)/","items":[]},{"title":"Webizen Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Webizen Manager/","items":[]}]},{"title":"Data Applications","url":"/Implementation V1/App-design-sdk-v1/Data Applications/","items":[]},{"title":"Design Goals","url":"","items":[{"title":"Design Goals Overview","url":"/Implementation V1/App-design-sdk-v1/Design Goals/Design Goals Overview/","items":[]}]}]},{"title":"Edge","url":"","items":[{"title":"Webizen Local App Functionality","url":"/Implementation V1/edge/Webizen Local App Functionality/","items":[]}]},{"title":"GoLang Libraries","url":"/Implementation V1/GoLang Libraries/","items":[]},{"title":"Implementation V1 Summary","url":"/Implementation V1/Implementation V1 Summary/","items":[]},{"title":"Vps","url":"","items":[{"title":"Server Functionality Summary (VPS)","url":"/Implementation V1/vps/Server Functionality Summary (VPS)/","items":[]}]},{"title":"Webizen 1.0","url":"/Implementation V1/Webizen 1.0/","items":[]},{"title":"Webizen-Connect","url":"","items":[{"title":"Social Media APIs","url":"/Implementation V1/Webizen-Connect/Social Media APIs/","items":[]},{"title":"Webizen-Connect (Summary)","url":"/Implementation V1/Webizen-Connect/Webizen-Connect (summary)/","items":[]}]}]},{"title":"Non-HTTP(s) Protocols","url":"","items":[{"title":"DAT","url":"/Non-HTTP(s) Protocols/DAT/","items":[]},{"title":"GIT","url":"/Non-HTTP(s) Protocols/GIT/","items":[]},{"title":"GUNECO","url":"/Non-HTTP(s) Protocols/GUNECO/","items":[]},{"title":"IPFS","url":"/Non-HTTP(s) Protocols/IPFS/","items":[]},{"title":"Lightning Network","url":"/Non-HTTP(s) Protocols/Lightning Network/","items":[]},{"title":"Non-HTTP(s) Protocols (& DLTs)","url":"/Non-HTTP(s) Protocols/Non-HTTP(s) Protocols (& DLTs)/","items":[]},{"title":"WebRTC","url":"/Non-HTTP(s) Protocols/WebRTC/","items":[]},{"title":"WebSockets","url":"/Non-HTTP(s) Protocols/WebSockets/","items":[]},{"title":"WebTorrent","url":"/Non-HTTP(s) Protocols/WebTorrent/","items":[]}]},{"title":"Old-Work-Archives","url":"","items":[{"title":"2018-Webizen-Net-Au","url":"","items":[{"title":"_Link_library_links","url":"","items":[{"title":"Link Library","url":"/old-work-archives/2018-webizen-net-au/_link_library_links/2018-09-23-wp-linked-data/","items":[]}]},{"title":"_Posts","url":"","items":[{"title":"About W3C","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-27-about-w3c/","items":[]},{"title":"Advanced Functions &#8211; Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-16-advanced-functions-facebook-pages/","items":[]},{"title":"Advanced Search &#038; Discovery Tips","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-advanced-search-discovery-tips/","items":[]},{"title":"An introduction to Virtual Machines.","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-an-introduction-to-virtual-machines/","items":[]},{"title":"Basic Media Analysis &#8211; Part 1 (Audio)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-30-media-analysis-part-1-audio/","items":[]},{"title":"Basic Media Analysis &#8211; Part 2 (visual)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-31-media-analysis-part-2-visual/","items":[]},{"title":"Basic Media Analysis &#8211; Part 3 (Text &#038; Metadata)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-01-01-basic-media-analysis-part-3-text-metadata/","items":[]},{"title":"Building an Economy based upon Knowledge Equity.","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-25-building-an-economy-based-upon-knowledge-equity/","items":[]},{"title":"Choice of Law","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-26-choice-of-law/","items":[]},{"title":"Contemplation of the ITU Dubai Meeting and the Future of the Internet","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-19-contemplation-of-the-itu-dubai-meeting-and-the-future-of-the-internet/","items":[]},{"title":"Creating a Presence &#8211; Online","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-creating-a-presence-online/","items":[]},{"title":"Credentials and Payments by Manu Sporny","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-credentials-and-payments-by-manu-sporny/","items":[]},{"title":"Data Recovery &#038; Collection: Mobile Devices","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-28-mobile-devices-data-recovery-collection/","items":[]},{"title":"Data Recovery: Laptop &#038; Computers","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-28-data-recovery-laptop-computers/","items":[]},{"title":"Decentralized Web Conference 2016","url":"/old-work-archives/2018-webizen-net-au/_posts/2016-06-09-decentralized-web-2016/","items":[]},{"title":"Decentralized Web Summit 2018","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-decentralized-web-summit-2018/","items":[]},{"title":"Does Anonymity exist?","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-does-anonymity-exist/","items":[]},{"title":"Downloading My Data from Social Networks","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-downloading-my-data-from-social-networks/","items":[]},{"title":"Events","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-events/","items":[]},{"title":"Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-16-facebook-pages/","items":[]},{"title":"Google Tracking Data (geolocation)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-google-tracking/","items":[]},{"title":"Human Consciousness","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-human-consciousness/","items":[]},{"title":"Image Recgonition Video Playlist","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-image-recgonition-video-playlist/","items":[]},{"title":"Inferencing (introduction)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-inferencing-introduction/","items":[]},{"title":"Introduction to AI","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-introduction-to-ai/","items":[]},{"title":"Introduction to Linked Data","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-introduction-to-linked-data/","items":[]},{"title":"Introduction to Maltego","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-introduction-to-maltego/","items":[]},{"title":"Introduction to Ontologies","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-ontologies-intro/","items":[]},{"title":"Introduction to Semantic Web","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-introduction-to-semantic-web/","items":[]},{"title":"Knowledge Capital","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-10-17-knowledge-capital/","items":[]},{"title":"Logo&#8217;s, Style Guides and Artwork","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-logos-style-guides-and-artwork/","items":[]},{"title":"MindMapping &#8211; Setting-up a business &#8211; Identity","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-mindmapping-setting-up-a-business-identity/","items":[]},{"title":"Openlink Virtuoso","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-openlink-virtuoso/","items":[]},{"title":"OpenRefine","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-74-2/","items":[]},{"title":"Projects, Customers and Invoicing &#8211; Web-Services for Startups","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-projects-customers-and-invoicing-web-services-for-startups/","items":[]},{"title":"RWW &#038; some Solid history","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-rww-some-solid-history/","items":[]},{"title":"Semantic Web (An Intro)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-semantic-web-an-intro/","items":[]},{"title":"Setting-up Twitter","url":"/old-work-archives/2018-webizen-net-au/_posts/2013-06-07-setting-up-twitter/","items":[]},{"title":"Social Encryption: An Introduction","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-25-social-encryption-an-introduction/","items":[]},{"title":"Stock Content","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-stock-content/","items":[]},{"title":"The WayBack Machine","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-27-the-wayback-machine/","items":[]},{"title":"Tim Berners Lee &#8211; Turing Lecture","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-05-29-tim-berners-lee-turing-lecture/","items":[]},{"title":"Tools of Trade","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-tools-of-trade/","items":[]},{"title":"Trust Factory 2017","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-trust-factory-2017/","items":[]},{"title":"Verifiable Claims (An Introduction)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-vc-intro/","items":[]},{"title":"Web of Things &#8211; an Introduction","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-web-of-things-an-introduction/","items":[]},{"title":"Web-Persistence","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-web-persistence/","items":[]},{"title":"Web-Services &#8211; Marketing Tools","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-web-services-marketing-tools/","items":[]},{"title":"Website Templates","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-templates/","items":[]},{"title":"What is Linked Data?","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-what-is-linked-data/","items":[]},{"title":"What is Open Source Intelligence?","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-what-is-osint/","items":[]},{"title":"WiX","url":"/old-work-archives/2018-webizen-net-au/_posts/2013-01-01-wix/","items":[]}]},{"title":"about","url":"/old-work-archives/2018-webizen-net-au/about/","items":[{"title":"About The Author","url":"/old-work-archives/2018-webizen-net-au/about/about-the-author/","items":[]},{"title":"Applied Theory: Applications for a Human Centric Web","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/","items":[{"title":"Digital Receipts","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/digital-receipts/","items":[]},{"title":"Fake News: Considerations → Principles → The Institution of Socio &#8211; Economic Values","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations/","items":[]},{"title":"Healthy Living Economy","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/healthy-living-economy/","items":[]},{"title":"HyperMedia Solutions &#8211; Adapting HbbTV V2","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/","items":[{"title":"HYPERMEDIA PACKAGES","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/hypermedia-packages/","items":[]},{"title":"USER STORIES: INTERACTIVE VIEWING EXPERIENCE","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/user-stories-interactive-viewing-experience/","items":[]}]},{"title":"Measurements App","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/measurements-app/","items":[]},{"title":"Re:Animation","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/reanimation/","items":[]},{"title":"Solutions to FakeNews: Linked-Data, Ontologies and Verifiable Claims","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/ld-solutions-to-fakenews/","items":[]}]},{"title":"Executive Summary","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/","items":[{"title":"Assisting those who Enforce the Law","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/assisting-those-who-enforce-the-law/","items":[]},{"title":"Consumer Protections","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/consumer-protections/","items":[]},{"title":"Knowledge Banking: Legal Structures","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-banking-legal-structures/","items":[]},{"title":"Knowledge Economics &#8211; Services","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-economics-services/","items":[]},{"title":"Preserving The Freedom to Think","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/preserving-the-freedom-to-think/","items":[]}]},{"title":"History","url":"/old-work-archives/2018-webizen-net-au/about/history/","items":[{"title":"History: Global Governance and ICT.","url":"/old-work-archives/2018-webizen-net-au/about/history/history-global-governance-ict-1/","items":[]}]},{"title":"Knowledge Banking: A Technical Architecture Summary","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/","items":[{"title":"An introduction to Credentials.","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/","items":[{"title":"credentials and custodianship","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/credentials-and-custodianship/","items":[]},{"title":"DIDs and MultiSig","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/dids-and-multisig/","items":[]}]},{"title":"Personal Augmentation of AI","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/personal-augmentation-of-ai/","items":[]},{"title":"Semantic Inferencing","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/semantic-inferencing/","items":[]},{"title":"Web of Things (IoT+LD)","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/web-of-things-iotld/","items":[]}]},{"title":"References","url":"/old-work-archives/2018-webizen-net-au/about/references/","items":[{"title":"Making the distinction between ‘privacy’ and ‘dignity’.","url":"/old-work-archives/2018-webizen-net-au/about/references/privacy-vs-dignity/","items":[]},{"title":"Roles &#8211; Entity Analysis","url":"/old-work-archives/2018-webizen-net-au/about/references/roles-entity-analysis/","items":[]},{"title":"Social Informatics Design Considerations","url":"/old-work-archives/2018-webizen-net-au/about/references/social-informatics-design-concept-and-principles/","items":[]},{"title":"Socio-economic relations | A conceptual model","url":"/old-work-archives/2018-webizen-net-au/about/references/socioeconomic-relations-p1/","items":[]},{"title":"The need for decentralised Open (Linked) Data","url":"/old-work-archives/2018-webizen-net-au/about/references/the-need-for-decentralised-open-linked-data/","items":[]}]},{"title":"The design of new medium","url":"/old-work-archives/2018-webizen-net-au/about/the-design-of-new-medium/","items":[]},{"title":"The need to modernise socioeconomic infrastructure","url":"/old-work-archives/2018-webizen-net-au/about/the-modernisation-of-socioeconomics/","items":[]},{"title":"The Vision","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/","items":[{"title":"Domesticating Pervasive Surveillance","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/a-technical-vision/","items":[]}]}]},{"title":"An Overview","url":"/old-work-archives/2018-webizen-net-au/the-human-centric-infosphere/","items":[]},{"title":"Resource Library","url":"/old-work-archives/2018-webizen-net-au/resource-library/","items":[{"title":"awesomeLists","url":"","items":[{"title":"Awesome Computer Vision: Awesome","url":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-computer-vision/","items":[]},{"title":"Awesome Natural Language Generation Awesome","url":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awsome-nl-gen/","items":[]},{"title":"Awesome Semantic Web Awesome","url":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-semweb/","items":[]},{"title":"Awesome-General","url":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-general/","items":[]}]},{"title":"Handong1587","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/","items":[{"title":"_Posts","url":"","items":[{"title":"Computer_science","url":"","items":[{"title":"Algorithm and Data Structure Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-algo-resourses/","items":[]},{"title":"Artificial Intelligence Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-ai-resources/","items":[]},{"title":"Big Data Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-09-22-big-data-resources/","items":[]},{"title":"Computer Science Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-cs-resources/","items":[]},{"title":"Data Mining Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-data-mining-resources/","items":[]},{"title":"Data Science Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-data-science-resources/","items":[]},{"title":"Database Systems Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-database-resources/","items":[]},{"title":"Discrete Optimization Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-discrete-optimization/","items":[]},{"title":"Distribued System Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-12-12-ditributed-system-resources/","items":[]},{"title":"Funny Stuffs Of Computer Science","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-11-18-funny-stuffs-of-cs/","items":[]},{"title":"Robotics","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-09-26-robotics-resources/","items":[]},{"title":"Writting CS Papers","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-11-30-writing-papers/","items":[]}]},{"title":"Computer_vision","url":"","items":[{"title":"Computer Vision Datasets","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-24-datasets/","items":[]},{"title":"Computer Vision Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-12-cv-resources/","items":[]},{"title":"Features","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-10-09-features/","items":[]},{"title":"Recognition, Detection, Segmentation and Tracking","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-10-09-recognition-detection-segmentation-tracking/","items":[]},{"title":"Use FFmpeg to Capture I Frames of Video","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2016-03-03-ffmpeg-i-frame/","items":[]},{"title":"Working on OpenCV","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-12-25-working-on-opencv/","items":[]}]},{"title":"Deep_learning","url":"","items":[{"title":"3D","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2021-07-28-3d/","items":[]},{"title":"Acceleration and Model Compression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-cnn-compression-acceleration/","items":[]},{"title":"Acceleration and Model Compression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-knowledge-distillation/","items":[]},{"title":"Adversarial Attacks and Defences","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-adversarial-attacks-and-defences/","items":[]},{"title":"Audio / Image / Video Generation","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-audio-image-video-generation/","items":[]},{"title":"BEV","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2022-06-27-bev/","items":[]},{"title":"Classification / Recognition","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recognition/","items":[]},{"title":"Deep Learning and Autonomous Driving","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-autonomous-driving/","items":[]},{"title":"Deep Learning Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-pose-estimation/","items":[]},{"title":"Deep Learning Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-applications/","items":[]},{"title":"Deep learning Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-courses/","items":[]},{"title":"Deep Learning Frameworks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-frameworks/","items":[]},{"title":"Deep Learning Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-resources/","items":[]},{"title":"Deep Learning Software and Hardware","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-software-hardware/","items":[]},{"title":"Deep Learning Tricks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tricks/","items":[]},{"title":"Deep Learning Tutorials","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tutorials/","items":[]},{"title":"Deep Learning with Machine Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-with-ml/","items":[]},{"title":"Face Recognition","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-face-recognition/","items":[]},{"title":"Fun With Deep Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-fun-with-deep-learning/","items":[]},{"title":"Generative Adversarial Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gan/","items":[]},{"title":"Graph Convolutional Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gcn/","items":[]},{"title":"Image / Video Captioning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-captioning/","items":[]},{"title":"Image Retrieval","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-retrieval/","items":[]},{"title":"Keep Up With New Trends","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2018-09-03-keep-up-with-new-trends/","items":[]},{"title":"LiDAR 3D Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-lidar-3d-detection/","items":[]},{"title":"Natural Language Processing","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nlp/","items":[]},{"title":"Neural Architecture Search","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nas/","items":[]},{"title":"Object Counting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-counting/","items":[]},{"title":"Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-detection/","items":[]},{"title":"OCR","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-ocr/","items":[]},{"title":"Optical Flow","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-optical-flow/","items":[]},{"title":"Re-ID","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-re-id/","items":[]},{"title":"Recommendation System","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recommendation-system/","items":[]},{"title":"Reinforcement Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rl/","items":[]},{"title":"RNN and LSTM","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rnn-and-lstm/","items":[]},{"title":"Segmentation","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-segmentation/","items":[]},{"title":"Style Transfer","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-style-transfer/","items":[]},{"title":"Super-Resolution","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-super-resolution/","items":[]},{"title":"Tracking","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-tracking/","items":[]},{"title":"Training Deep Neural Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-training-dnn/","items":[]},{"title":"Transfer Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-transfer-learning/","items":[]},{"title":"Unsupervised Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-unsupervised-learning/","items":[]},{"title":"Video Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-video-applications/","items":[]},{"title":"Visual Question Answering","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-vqa/","items":[]},{"title":"Visualizing and Interpreting Convolutional Neural Network","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-visulizing-interpreting-cnn/","items":[]}]},{"title":"Leisure","url":"","items":[{"title":"All About Enya","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-all-about-enya/","items":[]},{"title":"Coldplay","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-coldplay/","items":[]},{"title":"Coldplay","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-nightwish/","items":[]},{"title":"Games","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-13-games/","items":[]},{"title":"Green Day","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-greenday/","items":[]},{"title":"Muse! Muse!","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-muse-muse/","items":[]},{"title":"Oasis","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-oasis/","items":[]},{"title":"Paintings By J.M.","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2016-03-08-paintings-by-jm/","items":[]},{"title":"Papers, Blogs and Websites","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-09-27-papers-blogs-and-websites/","items":[]},{"title":"Welcome To The Black Parade","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-welcome-to-the-black-parade/","items":[]}]},{"title":"Machine_learning","url":"","items":[{"title":"Bayesian Methods","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-bayesian-methods/","items":[]},{"title":"Clustering Algorithms Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-clustering/","items":[]},{"title":"Competitions","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-competitions/","items":[]},{"title":"Dimensionality Reduction Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-dimensionality-reduction/","items":[]},{"title":"Fun With Machine Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-fun-with-ml/","items":[]},{"title":"Graphical Models Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-graphical-models/","items":[]},{"title":"Machine Learning Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-ml-courses/","items":[]},{"title":"Machine Learning Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-ml-resources/","items":[]},{"title":"Natural Language Processing","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-nlp/","items":[]},{"title":"Neural Network","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-neural-network/","items":[]},{"title":"Random Field","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-random-field/","items":[]},{"title":"Random Forests","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-random-forests/","items":[]},{"title":"Regression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-regression/","items":[]},{"title":"Support Vector Machine","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-svm/","items":[]},{"title":"Topic Model","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-topic-model/","items":[]}]},{"title":"Mathematics","url":"","items":[{"title":"Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/mathematics/2016-02-24-resources/","items":[]}]},{"title":"Programming_study","url":"","items":[{"title":"Add Lunr Search Plugin For Blog","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-31-add-lunr-search-plugin-for-blog/","items":[]},{"title":"Android Development Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-05-23-android-resources/","items":[]},{"title":"C++ Programming Solutions","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-09-07-cpp-programming-solutions/","items":[]},{"title":"Commands To Suppress Some Building Errors With Visual Studio","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-24-cmds-to-suppress-some-vs-building-Errors/","items":[]},{"title":"Embedding Python In C/C++","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-10-embedding-python-in-cpp/","items":[]},{"title":"Enable Large Addresses On VS2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-12-14-enable-large-addresses/","items":[]},{"title":"Fix min/max Error In VS2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-02-17-min-max-error-in-vs2015/","items":[]},{"title":"Gflags Build Problems on Windows X86 and Visual Studio 2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-23-gflags-build-problems-winx86-vs2015/","items":[]},{"title":"Glog Build Problems on Windows X86 and Visual Studio 2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-23-glog-build-problems-winx86/","items":[]},{"title":"Horrible Wired Errors Come From Simple Stupid Mistake","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-16-horrible-wired-errors-come-from-simple-stupid-mistake/","items":[]},{"title":"Install Jekyll To Fix Some Local Github-pages Defects","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-11-21-install-jekyll/","items":[]},{"title":"Install Therubyracer Failure","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-03-install-therubyracer/","items":[]},{"title":"Notes On Valgrind and Others","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-05-30-notes-on-valgrind/","items":[]},{"title":"PHP Hello World","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-04-php-hello-world/","items":[]},{"title":"Programming Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-07-01-programming-resources/","items":[]},{"title":"PyInstsaller and Others","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-12-24-pyinstaller-and-others/","items":[]},{"title":"Web Development Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-06-21-web-dev-resources/","items":[]},{"title":"Working on Visual Studio","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-04-03-working-on-vs/","items":[]}]},{"title":"Reading_and_thoughts","url":"","items":[{"title":"Book Reading List","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2015-12-04-book-reading-list/","items":[]},{"title":"Funny Papers","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2015-12-04-funny-papers/","items":[]},{"title":"Reading Materials","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2016-01-18-reading-materials/","items":[]}]},{"title":"Study","url":"","items":[{"title":"Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2017-11-28-courses/","items":[]},{"title":"Essay Writting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2016-01-11-essay-writting/","items":[]},{"title":"Job Hunting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2016-06-02-job-hunting/","items":[]},{"title":"Study Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2018-04-18-resources/","items":[]}]},{"title":"Working_on_linux","url":"","items":[{"title":"Create Multiple Forks of a GitHub Repo","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-12-18-create-multi-forks/","items":[]},{"title":"Linux Git Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-08-02-linux-git/","items":[]},{"title":"Linux Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-07-24-linux-resources/","items":[]},{"title":"Linux SVN Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-08-03-linux-svn/","items":[]},{"title":"Setup vsftpd on Ubuntu 14.10","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2016-07-27-setup-vsftpd/","items":[]},{"title":"Useful Linux Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-07-25-useful-linux-commands/","items":[]},{"title":"vsftpd Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2016-07-28-vsftpd-cmd/","items":[]}]},{"title":"Working_on_mac","url":"","items":[{"title":"Mac Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_mac/2015-07-25-mac-resources/","items":[]}]},{"title":"Working_on_windows","url":"","items":[{"title":"FFmpeg Collection of Utility Methods","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2016-06-05-ffmpeg-utilities/","items":[]},{"title":"Windows Commands and Utilities","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2015-10-27-windows-cmds-utils/","items":[]},{"title":"Windows Dev Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2015-10-27-resources/","items":[]}]}]},{"title":"Drafts","url":"","items":[{"title":"2016-12-30-Setup-Opengrok","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-12-30-setup-opengrok/","items":[]},{"title":"2017-01-20-Packing-C++-Project-to-Single-Executable","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2017-01-20-packing-c++-project-to-single-executable/","items":[]},{"title":"Notes On Caffe Development","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-10-notes-on-caffe-dev/","items":[]},{"title":"Notes On Deep Learning Training","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-12-notes-on-dl-training/","items":[]},{"title":"Notes On Discrete Optimization","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-13-notes-on-discrete-optimization/","items":[]},{"title":"Notes On Gecode","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-13-notes-on-gecode/","items":[]},{"title":"Notes On Inside-Outside Net","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-28-notes-on-ion/","items":[]},{"title":"Notes On K-Means","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-06-notes-on-kmeans/","items":[]},{"title":"Notes On L-BFGS","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-07-notes-on-l-bfgs/","items":[]},{"title":"Notes On Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-04-notes-on-object-detection/","items":[]},{"title":"Notes On Perceptrons","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-10-07-notes-on-perceptrons/","items":[]},{"title":"Notes On Quantized Convolutional Neural Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-07-notes-on-quantized-cnn/","items":[]},{"title":"Notes On Stanford CS2321n","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-02-21-notes-on-cs231n/","items":[]},{"title":"Notes on Suffix Array and Manacher Algorithm","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-08-27-notes-on-suffix-array-and-manacher-algorithm/","items":[]},{"title":"Notes On Tensorflow Development","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2017-04-13-notes-on-tensorflow-dev/","items":[]},{"title":"Notes On YOLO","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-14-notes-on-yolo/","items":[]},{"title":"PASCAL VOC (20) / COCO (80) / ImageNet (200) Detection Categories","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-12-23-imagenet-det-cat/","items":[]},{"title":"Softmax Vs Logistic Vs Sigmoid","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-10-softmax-logistic-sigmoid/","items":[]},{"title":"Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognititon","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-08-31-model-ensemble-of-deteciton/","items":[]}]}]}]}]}]},{"title":"Webizen 2.0","url":"","items":[{"title":"AI Capabilities","url":"","items":[{"title":"AI Capabilities Objectives","url":"/Webizen 2.0/AI Capabilities/AI Capabilities Objectives/","items":[]},{"title":"Audio & Video Analysis","url":"/Webizen 2.0/AI Capabilities/Audio & Video Analysis/","items":[]},{"title":"Image Analysis","url":"/Webizen 2.0/AI Capabilities/Image Analysis/","items":[]},{"title":"Text Analysis","url":"/Webizen 2.0/AI Capabilities/Text Analysis/","items":[]}]},{"title":"LOD-a-lot","url":"/Webizen 2.0/AI Related Links & Notes/","items":[]},{"title":"Mobile Apps","url":"","items":[{"title":"Android","url":"/Webizen 2.0/Mobile Apps/Android/","items":[]},{"title":"General Mobile Architecture","url":"/Webizen 2.0/Mobile Apps/General Mobile Architecture/","items":[]},{"title":"iOS","url":"/Webizen 2.0/Mobile Apps/iOS/","items":[]}]},{"title":"Web Of Things (IoT)","url":"","items":[{"title":"Web Of Things (IoT)","url":"/Webizen 2.0/Web Of Things (IoT)/Web Of Things (IoT)/","items":[]}]},{"title":"Webizen 2.0","url":"/Webizen 2.0/Webizen 2.0/","items":[]},{"title":"Webizen AI OS Platform","url":"/Webizen 2.0/Webizen AI OS Platform/","items":[]},{"title":"Webizen Pro Summary","url":"/Webizen 2.0/Webizen Pro Summary/","items":[]}]},{"title":"Webizen V1 Project Documentation","url":"/","items":[]}]}],"tagsGroups":[],"latestPosts":[{"fields":{"slug":"/","title":"Webizen V1 Project Documentation","lastUpdatedAt":"2022-12-28T20:55:56.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/","title":"Knowledge Banking: A Technical Architecture Summary","lastUpdatedAt":"2022-12-28T20:36:06.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/the-human-centric-infosphere/","title":"An Overview","lastUpdatedAt":"2022-12-28T20:26:34.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/the-design-of-new-medium/","title":"The design of new medium","lastUpdatedAt":"2022-12-28T20:26:34.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/the-modernisation-of-socioeconomics/","title":"The need to modernise socioeconomic infrastructure","lastUpdatedAt":"2022-12-28T20:26:34.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/the-vision/","title":"The Vision","lastUpdatedAt":"2022-12-28T20:26:34.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awsome-nl-gen/","title":"Awesome Natural Language Generation Awesome","lastUpdatedAt":"2022-12-28T20:06:33.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-computer-vision/","title":"Awesome Computer Vision: Awesome","lastUpdatedAt":"2022-12-28T20:06:17.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/","title":"Handong1587","lastUpdatedAt":"2022-12-28T20:06:17.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-general/","title":"Awesome-General","lastUpdatedAt":"2022-12-28T20:06:17.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}