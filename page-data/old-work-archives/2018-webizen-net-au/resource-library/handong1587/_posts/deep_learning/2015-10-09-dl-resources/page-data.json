{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-resources/",
    "result": {"data":{"mdx":{"id":"997afd6c-6ec8-5906-9c48-933627b3f3b1","tableOfContents":{"items":[{"url":"#imagenet","title":"ImageNet","items":[{"url":"#alexnet","title":"AlexNet"},{"url":"#network-in-network","title":"Network In Network"},{"url":"#googlenet-inception-v1","title":"GoogLeNet (Inception V1)"},{"url":"#vggnet","title":"VGGNet"},{"url":"#inception-v2","title":"Inception-V2"},{"url":"#inception-v3","title":"Inception-V3"},{"url":"#resnet","title":"ResNet"},{"url":"#resnet-v2","title":"ResNet-V2"},{"url":"#inception-v4--inception-resnet-v2","title":"Inception-V4 / Inception-ResNet-V2"},{"url":"#resnext","title":"ResNeXt"},{"url":"#resnest","title":"ResNeSt"},{"url":"#residual-networks-variants","title":"Residual Networks Variants"},{"url":"#densenet","title":"DenseNet"},{"url":"#densenet-20","title":"DenseNet 2.0"},{"url":"#xception","title":"Xception"},{"url":"#mobilenets","title":"MobileNets"},{"url":"#mobilenetv2","title":"MobileNetV2"},{"url":"#shufflenet","title":"ShuffleNet"},{"url":"#shufflenet-v2","title":"ShuffleNet V2"},{"url":"#senet","title":"SENet"},{"url":"#genet","title":"GENet"},{"url":"#imagenet-projects","title":"ImageNet Projects"}]},{"url":"#pre-training","title":"Pre-training"},{"url":"#transformers","title":"Transformers"},{"url":"#semi-supervised-learning","title":"Semi-Supervised Learning"},{"url":"#multi-label-learning","title":"Multi-label Learning"},{"url":"#multi-task-learning","title":"Multi-task Learning"},{"url":"#multi-modal-learning","title":"Multi-modal Learning"},{"url":"#debugging-deep-learning","title":"Debugging Deep Learning"},{"url":"#understanding-cnn","title":"Understanding CNN"},{"url":"#deep-learning-networks","title":"Deep Learning Networks","items":[{"url":"#convolutions--filters","title":"Convolutions / Filters"},{"url":"#highway-networks","title":"Highway Networks"},{"url":"#spatial-transformer-networks","title":"Spatial Transformer Networks"},{"url":"#fractalnet","title":"FractalNet"}]},{"url":"#generative-models","title":"Generative Models"},{"url":"#deep-learning-and-robots","title":"Deep Learning and Robots"},{"url":"#deep-learning-on-mobile--embedded-devices","title":"Deep Learning on Mobile / Embedded Devices"},{"url":"#benchmarks","title":"Benchmarks"},{"url":"#papers","title":"Papers","items":[{"url":"#tutorials-and-surveys","title":"Tutorials and Surveys"},{"url":"#mathematics-of-deep-learning","title":"Mathematics of Deep Learning"},{"url":"#local-minima","title":"Local Minima"},{"url":"#dive-into-cnn","title":"Dive Into CNN"},{"url":"#separable-convolutions--grouped-convolutions","title":"Separable Convolutions / Grouped Convolutions"},{"url":"#stdp","title":"STDP"},{"url":"#target-propagation","title":"Target Propagation"},{"url":"#zero-shot-learning","title":"Zero Shot Learning"},{"url":"#incremental-learning","title":"Incremental Learning"},{"url":"#ensemble-deep-learning","title":"Ensemble Deep Learning"},{"url":"#domain-adaptation","title":"Domain Adaptation"},{"url":"#embedding","title":"Embedding"},{"url":"#regression","title":"Regression"},{"url":"#capsnets","title":"CapsNets"},{"url":"#low-light","title":"Low Light"},{"url":"#computer-vision","title":"Computer Vision"}]},{"url":"#projects","title":"Projects"},{"url":"#readings-and-questions","title":"Readings and Questions"},{"url":"#resources","title":"Resources","items":[{"url":"#arxiv-pages","title":"Arxiv Pages"},{"url":"#arxiv-sanity-preserver","title":"Arxiv Sanity Preserver"},{"url":"#papers-with-code","title":"Papers with Code"}]},{"url":"#tools","title":"Tools"},{"url":"#challenges--hackathons","title":"Challenges / Hackathons"},{"url":"#books","title":"Books"},{"url":"#blogs","title":"Blogs"}]},"fields":{"title":"Deep Learning Resources","slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-resources/","url":"https://devdocs.webizen.org/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-resources/","editUrl":"https://github.com/webizenai/devdocs/tree/main/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-resources.md","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022","gitCreatedAt":"2022-12-28T19:22:29.000Z","shouldShowTitle":true},"frontmatter":{"title":"Deep Learning Resources","description":null,"imageAlt":null,"tags":[],"date":"2015-10-09T00:00:00.000Z","dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"layout\": \"post\",\n  \"category\": \"deep_learning\",\n  \"title\": \"Deep Learning Resources\",\n  \"date\": \"2015-10-09T00:00:00.000Z\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"imagenet\"\n  }, \"ImageNet\"), mdx(\"p\", null, \"Single-model on 224x224\"), mdx(\"table\", null, mdx(\"thead\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"thead\"\n  }, mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Method\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"top1\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"top5\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Model Size\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Speed\"))), mdx(\"tbody\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"ResNet-101\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"78.0%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"94.0%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"ResNet-200\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"78.3%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"94.2%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Inception-v3\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Inception-v4\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Inception-ResNet-v2\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"ResNet-50\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"77.8%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"ResNet-101\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"79.6%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"94.7%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })))), mdx(\"p\", null, \"Single-model on 320\\xD7320 / 299\\xD7299\"), mdx(\"table\", null, mdx(\"thead\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"thead\"\n  }, mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Method\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"top1\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"top5\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Model Size\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Speed\"))), mdx(\"tbody\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"ResNet-101\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"ResNet-200\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"79.9%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"95.2%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Inception-v3\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"78.8%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"94.4%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Inception-v4\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"80.0%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"95.0%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Inception-ResNet-v2\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"80.1%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"95.1%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"ResNet-50\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"ResNet-101\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"80.9%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"95.6%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })))), mdx(\"h2\", {\n    \"id\": \"alexnet\"\n  }, \"AlexNet\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ImageNet Classification with Deep Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"nips-page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-\"\n  }, \"http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\"\n  }, \"http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.image-net.org/challenges/LSVRC/2012/supervision.pdf\"\n  }, \"http://www.image-net.org/challenges/LSVRC/2012/supervision.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://code.google.com/p/cuda-convnet/\"\n  }, \"https://code.google.com/p/cuda-convnet/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/dnouri/cuda-convnet\"\n  }, \"https://github.com/dnouri/cuda-convnet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://code.google.com/p/cuda-convnet2/\"\n  }, \"https://code.google.com/p/cuda-convnet2/\"))), mdx(\"h2\", {\n    \"id\": \"network-in-network\"\n  }, \"Network In Network\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Network In Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR 2014\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1312.4400\"\n  }, \"http://arxiv.org/abs/1312.4400\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gitxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://gitxiv.com/posts/PA98qGuMhsijsJzgX/network-in-network-nin\"\n  }, \"http://gitxiv.com/posts/PA98qGuMhsijsJzgX/network-in-network-nin\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code(Caffe, official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://gist.github.com/mavenlin/d802a5849de39225bcc6\"\n  }, \"https://gist.github.com/mavenlin/d802a5849de39225bcc6\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Batch-normalized Maxout Network in Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1511.02583\"\n  }, \"http://arxiv.org/abs/1511.02583\"))), mdx(\"h2\", {\n    \"id\": \"googlenet-inception-v1\"\n  }, \"GoogLeNet (Inception V1)\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Going Deeper with Convolutions\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1409.4842\"\n  }, \"http://arxiv.org/abs/1409.4842\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/google/inception\"\n  }, \"https://github.com/google/inception\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/soumith/inception.torch\"\n  }, \"https://github.com/soumith/inception.torch\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Building a deeper understanding of images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://googleresearch.blogspot.jp/2014/09/building-deeper-understanding-of-images.html\"\n  }, \"http://googleresearch.blogspot.jp/2014/09/building-deeper-understanding-of-images.html\"))), mdx(\"h2\", {\n    \"id\": \"vggnet\"\n  }, \"VGGNet\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Very Deep Convolutional Networks for Large-Scale Image Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.robots.ox.ac.uk/~vgg/research/very_deep/\"\n  }, \"http://www.robots.ox.ac.uk/~vgg/research/very_deep/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1409.1556\"\n  }, \"http://arxiv.org/abs/1409.1556\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://llcao.net/cu-deeplearning15/presentation/cc3580_Simonyan.pptx\"\n  }, \"http://llcao.net/cu-deeplearning15/presentation/cc3580_Simonyan.pptx\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.robots.ox.ac.uk/~karen/pdf/ILSVRC_2014.pdf\"\n  }, \"http://www.robots.ox.ac.uk/~karen/pdf/ILSVRC_2014.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://deeplearning.cs.cmu.edu/slides.2015/25.simonyan.pdf\"\n  }, \"http://deeplearning.cs.cmu.edu/slides.2015/25.simonyan.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, deprecated Caffe API): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://gist.github.com/ksimonyan/211839e770f7b538e2d8\"\n  }, \"https://gist.github.com/ksimonyan/211839e770f7b538e2d8\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ruimashita/caffe-train\"\n  }, \"https://github.com/ruimashita/caffe-train\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Tensorflow VGG16 and VGG19\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/machrisaa/tensorflow-vgg\"\n  }, \"https://github.com/machrisaa/tensorflow-vgg\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RepVGG: Making VGG-style ConvNets Great Again\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BNRist & Tsinghua University & MEGVII Technology & Hong Kong University of Science and Technology & Aberystwyth University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2101.03697\"\n  }, \"https://arxiv.org/abs/2101.03697\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/DingXiaoH/RepVGG\"\n  }, \"https://github.com/DingXiaoH/RepVGG\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/megvii-model/RepVGG\"\n  }, \"https://github.com/megvii-model/RepVGG\"))), mdx(\"h2\", {\n    \"id\": \"inception-v2\"\n  }, \"Inception-V2\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ImageNet top-5 error: 4.82%\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: internal covariate shift problem\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1502.03167\"\n  }, \"http://arxiv.org/abs/1502.03167\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://standardfrancis.wordpress.com/2015/04/16/batch-normalization/\"\n  }, \"https://standardfrancis.wordpress.com/2015/04/16/batch-normalization/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://blog.csdn.net/happynear/article/details/44238541\"\n  }, \"http://blog.csdn.net/happynear/article/details/44238541\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lim0606/caffe-googlenet-bn\"\n  }, \"https://github.com/lim0606/caffe-googlenet-bn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ImageNet pre-trained models with batch normalization\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.01452\"\n  }, \"https://arxiv.org/abs/1612.01452\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.inf-cv.uni-jena.de/Research/CNN+Models.html\"\n  }, \"http://www.inf-cv.uni-jena.de/Research/CNN+Models.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/cvjena/cnn-models\"\n  }, \"https://github.com/cvjena/cnn-models\"))), mdx(\"h2\", {\n    \"id\": \"inception-v3\"\n  }, \"Inception-V3\"), mdx(\"p\", null, \"Inception-V3 = Inception-V2 + BN-auxiliary (fully connected layer of the auxiliary classifier is also batch-normalized,\\nnot just the convolutions)\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rethinking the Inception Architecture for Computer Vision\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: \\\"21.2% top-1 and 5.6% top-5 error for single frame evaluation using a network;\\n3.5% top-5 error and 17.3% top-1 error With an ensemble of 4 models and multi-crop evaluation.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1512.00567\"\n  }, \"http://arxiv.org/abs/1512.00567\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Moodstocks/inception-v3.torch\"\n  }, \"https://github.com/Moodstocks/inception-v3.torch\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Inception in TensorFlow\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: demonstrate how to train the Inception v3 architecture\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tensorflow/models/tree/master/inception\"\n  }, \"https://github.com/tensorflow/models/tree/master/inception\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Train your own image classifier with Inception in TensorFlow\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Inception-v3\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://research.googleblog.com/2016/03/train-your-own-image-classifier-with.html\"\n  }, \"https://research.googleblog.com/2016/03/train-your-own-image-classifier-with.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Notes on the TensorFlow Implementation of Inception v3\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://pseudoprofound.wordpress.com/2016/08/28/notes-on-the-tensorflow-implementation-of-inception-v3/\"\n  }, \"https://pseudoprofound.wordpress.com/2016/08/28/notes-on-the-tensorflow-implementation-of-inception-v3/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Training an InceptionV3-based image classifier with your own dataset\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/danielvarga/keras-finetuning\"\n  }, \"https://github.com/danielvarga/keras-finetuning\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Inception-BN full for Caffe: Inception-BN ImageNet (21K classes) model for Caffe\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/pertusa/InceptionBN-21K-for-Caffe\"\n  }, \"https://github.com/pertusa/InceptionBN-21K-for-Caffe\"))), mdx(\"h2\", {\n    \"id\": \"resnet\"\n  }, \"ResNet\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Residual Learning for Image Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016 Best Paper Award\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1512.03385\"\n  }, \"http://arxiv.org/abs/1512.03385\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://research.microsoft.com/en-us/um/people/kahe/ilsvrc15/ilsvrc2015_deep_residual_learning_kaiminghe.pdf\"\n  }, \"http://research.microsoft.com/en-us/um/people/kahe/ilsvrc15/ilsvrc2015_deep_residual_learning_kaiminghe.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gitxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://gitxiv.com/posts/LgPRdTY3cwPBiMKbm/deep-residual-learning-for-image-recognition\"\n  }, \"http://gitxiv.com/posts/LgPRdTY3cwPBiMKbm/deep-residual-learning-for-image-recognition\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/KaimingHe/deep-residual-networks\"\n  }, \"https://github.com/KaimingHe/deep-residual-networks\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ry/tensorflow-resnet\"\n  }, \"https://github.com/ry/tensorflow-resnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Third-party re-implementations\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/KaimingHe/deep-residual-networks#third-party-re-implementations\"\n  }, \"https://github.com/KaimingHe/deep-residual-networks#third-party-re-implementations\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Training and investigating Residual Nets\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Facebook AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://torch.ch/blog/2016/02/04/resnets.html\"\n  }, \"http://torch.ch/blog/2016/02/04/resnets.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/facebook/fb.resnet.torch\"\n  }, \"https://github.com/facebook/fb.resnet.torch\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"resnet.torch: an updated version of fb.resnet.torch with many changes.\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/erogol/resnet.torch\"\n  }, \"https://github.com/erogol/resnet.torch\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Highway Networks and Deep Residual Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://yanran.li/peppypapers/2016/01/10/highway-networks-and-deep-residual-networks.html\"\n  }, \"http://yanran.li/peppypapers/2016/01/10/highway-networks-and-deep-residual-networks.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Interpretating Deep Residual Learning Blocks as Locally Recurrent Connections\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://matrixmashing.wordpress.com/2016/01/29/interpretating-deep-residual-learning-blocks-as-locally-recurrent-connections/\"\n  }, \"https://matrixmashing.wordpress.com/2016/01/29/interpretating-deep-residual-learning-blocks-as-locally-recurrent-connections/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Lab41 Reading Group: Deep Residual Learning for Image Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://gab41.lab41.org/lab41-reading-group-deep-residual-learning-for-image-recognition-ffeb94745a1f\"\n  }, \"https://gab41.lab41.org/lab41-reading-group-deep-residual-learning-for-image-recognition-ffeb94745a1f\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"50-layer ResNet, trained on ImageNet, classifying webcam\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://ml4a.github.io/demos/keras.js/\"\n  }, \"https://ml4a.github.io/demos/keras.js/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Reproduced ResNet on CIFAR-10 and CIFAR-100 dataset.\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tensorflow/models/tree/master/resnet\"\n  }, \"https://github.com/tensorflow/models/tree/master/resnet\"))), mdx(\"h2\", {\n    \"id\": \"resnet-v2\"\n  }, \"ResNet-V2\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Identity Mappings in Deep Residual Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016. ResNet-v2\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.05027\"\n  }, \"http://arxiv.org/abs/1603.05027\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/KaimingHe/resnet-1k-layers\"\n  }, \"https://github.com/KaimingHe/resnet-1k-layers\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tornadomeet/ResNet\"\n  }, \"https://github.com/tornadomeet/ResNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Residual Networks for Image Classification with Python + NumPy\")), mdx(\"img\", {\n    \"src\": \"https://dnlcrl.github.io/assets/thesis-post/Diagramma.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://dnlcrl.github.io/projects/2016/06/22/Deep-Residual-Networks-for-Image-Classification-with-Python+NumPy.html\"\n  }, \"https://dnlcrl.github.io/projects/2016/06/22/Deep-Residual-Networks-for-Image-Classification-with-Python+NumPy.html\"))), mdx(\"h2\", {\n    \"id\": \"inception-v4--inception-resnet-v2\"\n  }, \"Inception-V4 / Inception-ResNet-V2\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Inception-V4, Inception-Resnet And The Impact Of Residual Connections On Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Workshop track - ICLR 2016. 3.08 % top-5 error on ImageNet CLS\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: \\\"achieve 3.08% top-5 error on the test set of the ImageNet classification (CLS) challenge\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1602.07261\"\n  }, \"http://arxiv.org/abs/1602.07261\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Keras): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kentsommer/keras-inceptionV4\"\n  }, \"https://github.com/kentsommer/keras-inceptionV4\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The inception-resnet-v2 models trained from scratch via torch\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lim0606/torch-inception-resnet-v2\"\n  }, \"https://github.com/lim0606/torch-inception-resnet-v2\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Inception v4 in Keras\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Inception-v4, Inception - Resnet-v1 and v2\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/titu1994/Inception-v4\"\n  }, \"https://github.com/titu1994/Inception-v4\"))), mdx(\"h2\", {\n    \"id\": \"resnext\"\n  }, \"ResNeXt\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Aggregated Residual Transformations for Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017. UC San Diego & Facebook AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.05431\"\n  }, \"https://arxiv.org/abs/1611.05431\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Torch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/facebookresearch/ResNeXt\"\n  }, \"https://github.com/facebookresearch/ResNeXt\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/dmlc/mxnet/blob/master/example/image-classification/symbol/resnext.py\"\n  }, \"https://github.com/dmlc/mxnet/blob/master/example/image-classification/symbol/resnext.py\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"dataset: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://data.dmlc.ml/models/imagenet/resnext/\"\n  }, \"http://data.dmlc.ml/models/imagenet/resnext/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"reddit: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.reddit.com/r/MachineLearning/comments/5haml9/p_implementation_of_aggregated_residual/\"\n  }, \"https://www.reddit.com/r/MachineLearning/comments/5haml9/p_implementation_of_aggregated_residual/\"))), mdx(\"h2\", {\n    \"id\": \"resnest\"\n  }, \"ResNeSt\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ResNeSt: Split-Attention Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Amazon & University of California\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2004.08955\"\n  }, \"https://arxiv.org/abs/2004.08955\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zhanghang1989/ResNeSt\"\n  }, \"https://github.com/zhanghang1989/ResNeSt\"))), mdx(\"h2\", {\n    \"id\": \"residual-networks-variants\"\n  }, \"Residual Networks Variants\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Resnet in Resnet: Generalizing Residual Architectures\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://beta.openreview.net/forum?id=lx9l4r36gU2OVPy8Cv9g\"\n  }, \"http://beta.openreview.net/forum?id=lx9l4r36gU2OVPy8Cv9g\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.08029\"\n  }, \"http://arxiv.org/abs/1603.08029\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Residual Networks are Exponential Ensembles of Relatively Shallow Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.06431\"\n  }, \"http://arxiv.org/abs/1605.06431\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Wide Residual Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.07146\"\n  }, \"http://arxiv.org/abs/1605.07146\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/szagoruyko/wide-residual-networks\"\n  }, \"https://github.com/szagoruyko/wide-residual-networks\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/asmith26/wide_resnets_keras\"\n  }, \"https://github.com/asmith26/wide_resnets_keras\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ritchieng/wideresnet-tensorlayer\"\n  }, \"https://github.com/ritchieng/wideresnet-tensorlayer\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xternalz/WideResNet-pytorch\"\n  }, \"https://github.com/xternalz/WideResNet-pytorch\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Torch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/meliketoy/wide-residual-network\"\n  }, \"https://github.com/meliketoy/wide-residual-network\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Residual Networks of Residual Networks: Multilevel Residual Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.02908\"\n  }, \"http://arxiv.org/abs/1608.02908\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Residual Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.05672\"\n  }, \"http://arxiv.org/abs/1609.05672\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/masoudabd/multi-resnet\"\n  }, \"https://github.com/masoudabd/multi-resnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Pyramidal Residual Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: PyramidNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.02915\"\n  }, \"https://arxiv.org/abs/1610.02915\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jhkim89/PyramidNet\"\n  }, \"https://github.com/jhkim89/PyramidNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Identity Mappings with Residual Gates\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.01260\"\n  }, \"https://arxiv.org/abs/1611.01260\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Wider or Deeper: Revisiting the ResNet Model for Visual Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: image classification, semantic image segmentation\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.10080\"\n  }, \"https://arxiv.org/abs/1611.10080\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/itijyou/ademxapp\"\n  }, \"https://github.com/itijyou/ademxapp\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Pyramidal Residual Networks with Separated Stochastic Depth\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.01230\"\n  }, \"https://arxiv.org/abs/1612.01230\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spatially Adaptive Computation Time for Residual Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Higher School of Economics & Google & CMU\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.02297\"\n  }, \"https://arxiv.org/abs/1612.02297\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ShaResNet: reducing residual network parameter number by sharing weights\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.08782\"\n  }, \"https://arxiv.org/abs/1702.08782\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aboulch/sharesnet\"\n  }, \"https://github.com/aboulch/sharesnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sharing Residual Units Through Collective Tensor Factorization in Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Collective Residual Networks\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.02180\"\n  }, \"https://arxiv.org/abs/1703.02180\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(MXNet): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/cypw/CRU-Net\"\n  }, \"https://github.com/cypw/CRU-Net\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Residual Attention Network for Image Classification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017 Spotlight. SenseTime Group Limited & Tsinghua University & The Chinese University of Hong Kong\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ImageNet (4.8% single model and single crop, top-5 error)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.06904\"\n  }, \"https://arxiv.org/abs/1704.06904\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Caffe): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/buptwangfei/residual-attention-network\"\n  }, \"https://github.com/buptwangfei/residual-attention-network\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dilated Residual Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017. Princeton University & Intel Labs\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Dilated Residual Networks (DRN)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://vladlen.info/publications/dilated-residual-networks/\"\n  }, \"http://vladlen.info/publications/dilated-residual-networks/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1705.09914\"\n  }, \"https://arxiv.org/abs/1705.09914\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://vladlen.info/papers/DRN.pdf\"\n  }, \"http://vladlen.info/papers/DRN.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dynamic Steerable Blocks in Deep Residual Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Amsterdam & ESAT-PSI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.00598\"\n  }, \"https://arxiv.org/abs/1706.00598\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Deep ResNet Blocks Sequentially using Boosting Theory\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Microsoft Research & Princeton University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.04964\"\n  }, \"https://arxiv.org/abs/1706.04964\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Strict Identity Mappings in Deep Residual Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: epsilon-ResNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.01661\"\n  }, \"https://arxiv.org/abs/1804.01661\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spiking Deep Residual Network\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.01352\"\n  }, \"https://arxiv.org/abs/1805.01352\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Norm-Preservation: Why Residual Networks Can Become Extremely Deep?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Central Florida\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.07477\"\n  }, \"https://arxiv.org/abs/1805.07477\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Carnegie Mellon University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2009.08453\"\n  }, \"https://arxiv.org/abs/2009.08453\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/szq0214/MEAL-V2\"\n  }, \"https://github.com/szq0214/MEAL-V2\"))), mdx(\"h2\", {\n    \"id\": \"densenet\"\n  }, \"DenseNet\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Densely Connected Convolutional Networks\")), mdx(\"img\", {\n    \"src\": \"https://cloud.githubusercontent.com/assets/8370623/17981496/fa648b32-6ad1-11e6-9625-02fdd72fdcd3.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017 best paper. Cornell University & Tsinghua University. DenseNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.06993\"\n  }, \"http://arxiv.org/abs/1608.06993\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/liuzhuang13/DenseNet\"\n  }, \"https://github.com/liuzhuang13/DenseNet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Lasagne): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Lasagne/Recipes/tree/master/papers/densenet\"\n  }, \"https://github.com/Lasagne/Recipes/tree/master/papers/densenet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Keras): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/DenseNet\"\n  }, \"https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/DenseNet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Caffe): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/liuzhuang13/DenseNetCaffe\"\n  }, \"https://github.com/liuzhuang13/DenseNetCaffe\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Tensorflow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/YixuanLi/densenet-tensorflow\"\n  }, \"https://github.com/YixuanLi/densenet-tensorflow\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Keras): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/titu1994/DenseNet\"\n  }, \"https://github.com/titu1994/DenseNet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(PyTorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bamos/densenet.pytorch\"\n  }, \"https://github.com/bamos/densenet.pytorch\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(PyTorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/andreasveit/densenet-pytorch\"\n  }, \"https://github.com/andreasveit/densenet-pytorch\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Tensorflow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ikhlestov/vision_networks\"\n  }, \"https://github.com/ikhlestov/vision_networks\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Memory-Efficient Implementation of DenseNets\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Cornell University & Fudan University & Facebook AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.06990\"\n  }, \"https://arxiv.org/abs/1707.06990\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/liuzhuang13/DenseNet/tree/master/models\"\n  }, \"https://github.com/liuzhuang13/DenseNet/tree/master/models\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/gpleiss/efficient_densenet_pytorch\"\n  }, \"https://github.com/gpleiss/efficient_densenet_pytorch\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/taineleau/efficient_densenet_mxnet\"\n  }, \"https://github.com/taineleau/efficient_densenet_mxnet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Tongcheng/DN_CaffeScript\"\n  }, \"https://github.com/Tongcheng/DN_CaffeScript\"))), mdx(\"h2\", {\n    \"id\": \"densenet-20\"\n  }, \"DenseNet 2.0\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CondenseNet: An Efficient DenseNet using Learned Group Convolutions\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.09224\"\n  }, \"https://arxiv.org/abs/1711.09224\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com//ShichenLiu/CondenseNet\"\n  }, \"https://github.com//ShichenLiu/CondenseNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multimodal Densenet\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.07407\"\n  }, \"https://arxiv.org/abs/1811.07407\")), mdx(\"h2\", {\n    \"id\": \"xception\"\n  }, \"Xception\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning with Separable Convolutions\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Xception: Deep Learning with Depthwise Separable Convolutions\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017. Extreme Inception\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.02357\"\n  }, \"https://arxiv.org/abs/1610.02357\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://keras.io/applications/#xception\"\n  }, \"https://keras.io/applications/#xception\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Keras): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/fchollet/deep-learning-models/blob/master/xception.py\"\n  }, \"https://github.com/fchollet/deep-learning-models/blob/master/xception.py\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://gist.github.com/culurciello/554c8e56d3bbaf7c66bf66c6089dc221\"\n  }, \"https://gist.github.com/culurciello/554c8e56d3bbaf7c66bf66c6089dc221\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kwotsin/Tensorflow-Xception\"\n  }, \"https://github.com/kwotsin/Tensorflow-Xception\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com//bruinxiong/xception.mxnet\"\n  }, \"https://github.com//bruinxiong/xception.mxnet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.shortscience.org/paper?bibtexKey=journals%2Fcorr%2F1610.02357\"\n  }, \"http://www.shortscience.org/paper?bibtexKey=journals%2Fcorr%2F1610.02357\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards a New Interpretation of Separable Convolutions\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.04489\"\n  }, \"https://arxiv.org/abs/1701.04489\"))), mdx(\"h2\", {\n    \"id\": \"mobilenets\"\n  }, \"MobileNets\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.04861\"\n  }, \"https://arxiv.org/abs/1704.04861\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/rcmalli/keras-mobilenet\"\n  }, \"https://github.com/rcmalli/keras-mobilenet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/marvis/pytorch-mobilenet\"\n  }, \"https://github.com/marvis/pytorch-mobilenet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Tensorflow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Zehaos/MobileNet\"\n  }, \"https://github.com/Zehaos/MobileNet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/shicai/MobileNet-Caffe\"\n  }, \"https://github.com/shicai/MobileNet-Caffe\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hollance/MobileNet-CoreML\"\n  }, \"https://github.com/hollance/MobileNet-CoreML\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/KeyKy/mobilenet-mxnet\"\n  }, \"https://github.com/KeyKy/mobilenet-mxnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MobileNets: Open-Source Models for Efficient On-Device Vision\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://research.googleblog.com/2017/06/mobilenets-open-source-models-for.html\"\n  }, \"https://research.googleblog.com/2017/06/mobilenets-open-source-models-for.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tensorflow/models/blob/master/slim/nets/mobilenet_v1.md\"\n  }, \"https://github.com/tensorflow/models/blob/master/slim/nets/mobilenet_v1.md\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Google\\u2019s MobileNets on the iPhone\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://machinethink.net/blog/googles-mobile-net-architecture-on-iphone/\"\n  }, \"http://machinethink.net/blog/googles-mobile-net-architecture-on-iphone/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hollance/MobileNet-CoreML\"\n  }, \"https://github.com/hollance/MobileNet-CoreML\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Depth_conv-for-mobileNet\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com//LamHoCN/Depth_conv-for-mobileNet\"\n  }, \"https://github.com//LamHoCN/Depth_conv-for-mobileNet\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Enhanced Hybrid MobileNet\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.04698\"\n  }, \"https://arxiv.org/abs/1712.04698\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FD-MobileNet: Improved MobileNet with a Fast Downsampling Strategy\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1802.03750\"\n  }, \"https://arxiv.org/abs/1802.03750\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Quantization-Friendly Separable Convolution for MobileNets\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: THE 1ST WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING FOR EMBEDDED APPLICATIONS (EMC2)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.08607\"\n  }, \"https://arxiv.org/abs/1803.08607\"))), mdx(\"h2\", {\n    \"id\": \"mobilenetv2\"\n  }, \"MobileNetV2\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Inverted Residuals and Linear Bottlenecks: Mobile Networks forClassification, Detection and Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: MobileNetV2, SSDLite, DeepLabv3\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.04381\"\n  }, \"https://arxiv.org/abs/1801.04381\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet\"\n  }, \"https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/liangfu/mxnet-mobilenet-v2\"\n  }, \"https://github.com/liangfu/mxnet-mobilenet-v2\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://research.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html\"\n  }, \"https://research.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PydMobileNet: Improved Version of MobileNets with Pyramid Depthwise Separable Convolution\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.07083\"\n  }, \"https://arxiv.org/abs/1811.07083\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rethinking Depthwise Separable Convolutions: How Intra-Kernel Correlations Lead to Improved MobileNets\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.13549\"\n  }, \"https://arxiv.org/abs/2003.13549\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zeiss-microscopy/BSConv\"\n  }, \"https://github.com/zeiss-microscopy/BSConv\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rethinking Bottleneck Structure for Efficient Mobile Network Design\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: National University of Singapore & Yitu Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.02269\"\n  }, \"https://arxiv.org/abs/2007.02269\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zhoudaquan/rethinking_bottleneck_design\"\n  }, \"https://github.com/zhoudaquan/rethinking_bottleneck_design\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mobile-Former: Bridging MobileNet and Transformer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Microsoft & University of Science and Technology of China\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2108.05895\"\n  }, \"https://arxiv.org/abs/2108.05895\"))), mdx(\"h2\", {\n    \"id\": \"shufflenet\"\n  }, \"ShuffleNet\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Megvii Inc (Face++)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.01083\"\n  }, \"https://arxiv.org/abs/1707.01083\"))), mdx(\"h2\", {\n    \"id\": \"shufflenet-v2\"\n  }, \"ShuffleNet V2\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018. Megvii Inc (Face++) & Tsinghua University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", \"[https://arxiv.org/abs/1807.11164]\", \"\\uFF08\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.11164\"\n  }, \"https://arxiv.org/abs/1807.11164\"))), mdx(\"h2\", {\n    \"id\": \"senet\"\n  }, \"SENet\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Squeeze-and-Excitation Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ILSVRC 2017 image classification winner. Momenta & University of Oxford\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1709.01507\"\n  }, \"https://arxiv.org/abs/1709.01507\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, Caffe): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hujie-frank/SENet\"\n  }, \"https://github.com/hujie-frank/SENet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bruinxiong/SENet.mxnet\"\n  }, \"https://github.com/bruinxiong/SENet.mxnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Competitive Inner-Imaging Squeeze and Excitation for Residual Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.08920\"\n  }, \"https://arxiv.org/abs/1807.08920\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/scut-aitcm/CompetitiveSENet\"\n  }, \"https://github.com/scut-aitcm/CompetitiveSENet\"))), mdx(\"h2\", {\n    \"id\": \"genet\"\n  }, \"GENet\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hujie-frank/GENet\"\n  }, \"https://github.com/hujie-frank/GENet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A ConvNet for the 2020s\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Facebook AI Research (FAIR) & UC Berkeley\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2201.03545\"\n  }, \"https://arxiv.org/abs/2201.03545\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/facebookresearch/ConvNeXt\"\n  }, \"https://github.com/facebookresearch/ConvNeXt\"))), mdx(\"h2\", {\n    \"id\": \"imagenet-projects\"\n  }, \"ImageNet Projects\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Training an Object Classifier in Torch-7 on multiple GPUs over ImageNet\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: an imagenet example in torch\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/soumith/imagenet-multiGPU.torch\"\n  }, \"https://github.com/soumith/imagenet-multiGPU.torch\"))), mdx(\"h1\", {\n    \"id\": \"pre-training\"\n  }, \"Pre-training\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Exploring the Limits of Weakly Supervised Pretraining\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: report the highest ImageNet-1k single-crop, top-1 accuracy to date: 85.4% (97.6% top-5)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://research.fb.com/publications/exploring-the-limits-of-weakly-supervised-pretraining/\"\n  }, \"https://research.fb.com/publications/exploring-the-limits-of-weakly-supervised-pretraining/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rethinking ImageNet Pre-training\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Facebook AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.08883\"\n  }, \"https://arxiv.org/abs/1811.08883\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Revisiting Pre-training: An Efficient Training Method for Image Classification\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.09347\"\n  }, \"https://arxiv.org/abs/1811.09347\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rethinking Pre-training and Self-training\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Research, Brain Team\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2006.06882\"\n  }, \"https://arxiv.org/abs/2006.06882\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tensorflow/tpu/tree/master/models/official/detection/projects/self_training\"\n  }, \"https://github.com/tensorflow/tpu/tree/master/models/official/detection/projects/self_training\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Exploring the Limits of Large Scale Pre-training\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2110.02095\"\n  }, \"https://arxiv.org/abs/2110.02095\"))), mdx(\"h1\", {\n    \"id\": \"transformers\"\n  }, \"Transformers\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: National University of Singapore & YITU Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2101.11986\"\n  }, \"https://arxiv.org/abs/2101.11986\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yitu-opensource/T2T-ViT\"\n  }, \"https://github.com/yitu-opensource/T2T-ViT\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Incorporating Convolution Designs into Visual Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SenseTime Research & Nanyang Technological University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.11816\"\n  }, \"https://arxiv.org/abs/2103.11816\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepViT: Towards Deeper Vision Transformer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: National University of Singapore & ByteDance US AI Lab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.11886\"\n  }, \"https://arxiv.org/abs/2103.11886\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021 best paper\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Microsoft Research Asia\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.14030\"\n  }, \"https://arxiv.org/abs/2103.14030\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/microsoft/Swin-Transformer\"\n  }, \"https://github.com/microsoft/Swin-Transformer\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rethinking the Design Principles of Robust Vision Transformer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2105.07926\"\n  }, \"https://arxiv.org/abs/2105.07926\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/vtddggg/Robust-Vision-Transformer\"\n  }, \"https://github.com/vtddggg/Robust-Vision-Transformer\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scale Efficiently: Insights from Pre-training and Fine-tuning Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Research & DeepMind\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2109.10686\"\n  }, \"https://arxiv.org/abs/2109.10686\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"How Do Vision Transformers Work?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR 2022 Spotlight\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Yonsei University & NAVER AI Lab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2202.06709\"\n  }, \"https://arxiv.org/abs/2202.06709\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xxxnell/how-do-vits-work\"\n  }, \"https://github.com/xxxnell/how-do-vits-work\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MulT: An End-to-End Multitask Learning Transformer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://ivrl.github.io/MulT/\"\n  }, \"https://ivrl.github.io/MulT/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2205.08303\"\n  }, \"https://arxiv.org/abs/2205.08303\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"EfficientFormer: Vision Transformers at MobileNet Speed\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Snap Inc. & Northeastern University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2206.01191\"\n  }, \"https://arxiv.org/abs/2206.01191\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/snap-research/EfficientFormer\"\n  }, \"https://github.com/snap-research/EfficientFormer\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SimA: Simple Softmax-free Attention for Vision Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Maryland & University of California\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2206.08898\"\n  }, \"https://arxiv.org/abs/2206.08898\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gihtub: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/UCDvision/sima\"\n  }, \"https://github.com/UCDvision/sima\"))), mdx(\"h1\", {\n    \"id\": \"semi-supervised-learning\"\n  }, \"Semi-Supervised Learning\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semi-Supervised Learning with Graphs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Label Propagation\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://pages.cs.wisc.edu/~jerryzhu/pub/thesis.pdf\"\n  }, \"http://pages.cs.wisc.edu/~jerryzhu/pub/thesis.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog(\\\"\\u6807\\u7B7E\\u4F20\\u64AD\\u7B97\\u6CD5\\uFF08Label Propagation\\uFF09\\u53CAPython\\u5B9E\\u73B0\\\"): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://blog.csdn.net/zouxy09/article/details/49105265\"\n  }, \"http://blog.csdn.net/zouxy09/article/details/49105265\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semi-Supervised Learning with Ladder Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1507.02672\"\n  }, \"http://arxiv.org/abs/1507.02672\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/CuriousAI/ladder\"\n  }, \"https://github.com/CuriousAI/ladder\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/rinuboney/ladder\"\n  }, \"https://github.com/rinuboney/ladder\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semi-supervised Feature Transfer: The Practical Benefit of Deep Learning Today?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.kdnuggets.com/2016/07/semi-supervised-feature-transfer-deep-learning.html\"\n  }, \"http://www.kdnuggets.com/2016/07/semi-supervised-feature-transfer-deep-learning.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Temporal Ensembling for Semi-Supervised Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.02242\"\n  }, \"https://arxiv.org/abs/1610.02242\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/smlaine2/tempens\"\n  }, \"https://github.com/smlaine2/tempens\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR 2017 best paper award\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.05755\"\n  }, \"https://arxiv.org/abs/1610.05755\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tensorflow/models/tree/8505222ea1f26692df05e65e35824c6c71929bb5/privacy\"\n  }, \"https://github.com/tensorflow/models/tree/8505222ea1f26692df05e65e35824c6c71929bb5/privacy\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Infinite Variational Autoencoder for Semi-Supervised Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.07800\"\n  }, \"https://arxiv.org/abs/1611.07800\"))), mdx(\"h1\", {\n    \"id\": \"multi-label-learning\"\n  }, \"Multi-label Learning\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CNN: Single-label to Multi-label\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1406.5726\"\n  }, \"http://arxiv.org/abs/1406.5726\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning for Multi-label Classification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1502.05988\"\n  }, \"http://arxiv.org/abs/1502.05988\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://meka.sourceforge.net\"\n  }, \"http://meka.sourceforge.net\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Predicting Unseen Labels using Label Hierarchies in Large-Scale Multi-label Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECML 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.kdsl.tu-darmstadt.de/fileadmin/user_upload/Group_KDSL/PUnL_ECML2015_camera_ready.pdf\"\n  }, \"https://www.kdsl.tu-darmstadt.de/fileadmin/user_upload/Group_KDSL/PUnL_ECML2015_camera_ready.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning with a Wasserstein Loss\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cbcl.mit.edu/wasserstein/\"\n  }, \"http://cbcl.mit.edu/wasserstein/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1506.05439\"\n  }, \"http://arxiv.org/abs/1506.05439\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cbcl.mit.edu/wasserstein/yfcc100m_labels.tar.gz\"\n  }, \"http://cbcl.mit.edu/wasserstein/yfcc100m_labels.tar.gz\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"MIT news: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://news.mit.edu/2015/more-flexible-machine-learning-1001\"\n  }, \"http://news.mit.edu/2015/more-flexible-machine-learning-1001\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICML 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1602.02068\"\n  }, \"http://arxiv.org/abs/1602.02068\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/gokceneraslan/SparseMax.torch\"\n  }, \"https://github.com/gokceneraslan/SparseMax.torch\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Unbabel/sparsemax\"\n  }, \"https://github.com/Unbabel/sparsemax\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CNN-RNN: A Unified Framework for Multi-label Image Classification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1604.04573\"\n  }, \"http://arxiv.org/abs/1604.04573\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improving Multi-label Learning with Missing Labels by Structured Semantic Correlations\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.01441\"\n  }, \"http://arxiv.org/abs/1608.01441\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Extreme Multi-label Loss Functions for Recommendation, Tagging, Ranking & Other Missing Label Applications\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Indian Institute of Technology Delhi & MSR\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://manikvarma.github.io/pubs/jain16.pdf\"\n  }, \"https://manikvarma.github.io/pubs/jain16.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Label Image Classification with Regional Latent Semantic Dependencies\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Regional Latent Semantic Dependencies model (RLSD), RNN, RPN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.01082\"\n  }, \"https://arxiv.org/abs/1612.01082\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Privileged Multi-label Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Peking University & University of Technology Sydney & University of Sydney\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.07194\"\n  }, \"https://arxiv.org/abs/1701.07194\"))), mdx(\"h1\", {\n    \"id\": \"multi-task-learning\"\n  }, \"Multi-task Learning\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multitask Learning / Domain Adaptation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.cornell.edu/~kilian/research/multitasklearning/multitasklearning.html\"\n  }, \"http://www.cs.cornell.edu/~kilian/research/multitasklearning/multitasklearning.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"multi-task learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"discussion: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/memect/hao/issues/93\"\n  }, \"https://github.com/memect/hao/issues/93\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning and Transferring Multi-task Deep Representation for Face Alignment\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1408.3967\"\n  }, \"http://arxiv.org/abs/1408.3967\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-task learning of facial landmarks and expression\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.uoguelph.ca/~gwtaylor/publications/gwtaylor_crv2014.pdf\"\n  }, \"http://www.uoguelph.ca/~gwtaylor/publications/gwtaylor_crv2014.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Task Deep Visual-Semantic Embedding for Video Thumbnail Selection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro:  CVPR 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Liu_Multi-Task_Deep_Visual-Semantic_2015_CVPR_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Liu_Multi-Task_Deep_Visual-Semantic_2015_CVPR_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Multiple Tasks with Deep Relationship Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1506.02117\"\n  }, \"https://arxiv.org/abs/1506.02117\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning deep representation of multityped objects and tasks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.01359\"\n  }, \"http://arxiv.org/abs/1603.01359\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cross-stitch Networks for Multi-task Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1604.03539\"\n  }, \"http://arxiv.org/abs/1604.03539\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Task Learning in Tensorflow (Part 1)\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://jg8610.github.io/Multi-Task/\"\n  }, \"https://jg8610.github.io/Multi-Task/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Multi-Task Learning with Shared Memory\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: EMNLP 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.07222\"\n  }, \"http://arxiv.org/abs/1609.07222\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning to Push by Grasping: Using multiple tasks for effective learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.09025\"\n  }, \"http://arxiv.org/abs/1609.09025\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Identifying beneficial task relations for multi-task learning in deep neural networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: EACL 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.08303\"\n  }, \"https://arxiv.org/abs/1702.08303\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jbingel/eacl2017_mtl\"\n  }, \"https://github.com/jbingel/eacl2017_mtl\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Cambridge\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1705.07115\"\n  }, \"https://arxiv.org/abs/1705.07115\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"One Model To Learn Them All\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Brain & University of Toronto\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.05137\"\n  }, \"https://arxiv.org/abs/1706.05137\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tensorflow/tensor2tensor\"\n  }, \"https://github.com/tensorflow/tensor2tensor\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MultiModel: Multi-Task Machine Learning Across Domains\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://research.googleblog.com/2017/06/multimodel-multi-task-machine-learning.html\"\n  }, \"https://research.googleblog.com/2017/06/multimodel-multi-task-machine-learning.html\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An Overview of Multi-Task Learning in Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Aylien Ltd\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.05098\"\n  }, \"https://arxiv.org/abs/1706.05098\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.05769\"\n  }, \"https://arxiv.org/abs/1711.05769\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/arunmallya/packnet\"\n  }, \"https://github.com/arunmallya/packnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End-to-End Multi-Task Learning with Attention\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Imperial College London\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.10704\"\n  }, \"https://arxiv.org/abs/1803.10704\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cross-connected Networks for Multi-task Learning of Detection and Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.05569\"\n  }, \"https://arxiv.org/abs/1805.05569\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Auxiliary Tasks in Multi-task Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.06334\"\n  }, \"https://arxiv.org/abs/1805.06334\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"K For The Price Of 1: Parameter Efficient Multi-task And Transfer Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The University of Chicago & Google\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1810.10703\"\n  }, \"https://arxiv.org/abs/1810.10703\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Which Tasks Should Be Learned Together in Multi-task Learning?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICML 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Stanford\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://taskgrouping.stanford.edu/\"\n  }, \"http://taskgrouping.stanford.edu/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1905.07553\"\n  }, \"https://arxiv.org/abs/1905.07553\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"OmniNet: A unified architecture for multi-modal multi-task learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.07804\"\n  }, \"https://arxiv.org/abs/1907.07804\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/subho406/OmniNet\"\n  }, \"https://github.com/subho406/OmniNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Elastic Networks with Model Selection for Multi-Task Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.04860\"\n  }, \"https://arxiv.org/abs/1909.04860\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AdaShare: Learning What To Share For Efficient Deep Multi-Task Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Boston University & IBM Research & MIT-IBM Watson AI Lab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1911.12423\"\n  }, \"https://arxiv.org/abs/1911.12423\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Task Learning for Dense Prediction Tasks: A Survey\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: T-PAMI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2004.13379\"\n  }, \"https://arxiv.org/abs/2004.13379\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/SimonVandenhende/Multi-Task-Learning-PyTorch\"\n  }, \"https://github.com/SimonVandenhende/Multi-Task-Learning-PyTorch\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MTI-Net: Multi-Scale Task Interaction Networks for Multi-Task Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020 spotlight\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: MTI-Net\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2001.06902\"\n  }, \"https://arxiv.org/abs/2001.06902\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/SimonVandenhende/Multi-Task-Learning-PyTorch\"\n  }, \"https://github.com/SimonVandenhende/Multi-Task-Learning-PyTorch\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Exploring Relational Context for Multi-Task Dense Prediction\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ETH Zurich\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.13874\"\n  }, \"https://arxiv.org/abs/2104.13874\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cross-task Attention Mechanism for Dense Multi-task Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Inria, France & Valeo.ai, France\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2206.08927\"\n  }, \"https://arxiv.org/abs/2206.08927\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/cv-rits/DenseMTL\"\n  }, \"https://github.com/cv-rits/DenseMTL\"))), mdx(\"h1\", {\n    \"id\": \"multi-modal-learning\"\n  }, \"Multi-modal Learning\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multimodal Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://ai.stanford.edu/~ang/papers/nipsdlufl10-MultimodalDeepLearning.pdf\"\n  }, \"http://ai.stanford.edu/~ang/papers/nipsdlufl10-MultimodalDeepLearning.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multimodal Convolutional Neural Networks for Matching Image and Sentence\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mcnn.noahlab.com.hk/project.html\"\n  }, \"http://mcnn.noahlab.com.hk/project.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mcnn.noahlab.com.hk/ICCV2015.pdf\"\n  }, \"http://mcnn.noahlab.com.hk/ICCV2015.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1504.06063\"\n  }, \"http://arxiv.org/abs/1504.06063\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A C++ library for Multimodal Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1512.06927\"\n  }, \"http://arxiv.org/abs/1512.06927\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Jian-23/Deep-Learning-Library\"\n  }, \"https://github.com/Jian-23/Deep-Learning-Library\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multimodal Learning for Image Captioning and Visual Question Answering\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://research.microsoft.com/pubs/264769/UCB_XiaodongHe.6.pdf\"\n  }, \"http://research.microsoft.com/pubs/264769/UCB_XiaodongHe.6.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi modal retrieval and generation with deep distributed models\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.slideshare.net/roelofp/multi-modal-retrieval-and-generation-with-deep-distributed-models\"\n  }, \"http://www.slideshare.net/roelofp/multi-modal-retrieval-and-generation-with-deep-distributed-models\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://pan.baidu.com/s/1kUSjn4z\"\n  }, \"http://pan.baidu.com/s/1kUSjn4z\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Aligned Cross-Modal Representations from Weakly Aligned Data\")), mdx(\"img\", {\n    \"src\": \"http://projects.csail.mit.edu/cmplaces/imgs/teaser.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://projects.csail.mit.edu/cmplaces/index.html\"\n  }, \"http://projects.csail.mit.edu/cmplaces/index.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://projects.csail.mit.edu/cmplaces/content/paper.pdf\"\n  }, \"http://projects.csail.mit.edu/cmplaces/content/paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Variational methods for Conditional Multimodal Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.01801\"\n  }, \"http://arxiv.org/abs/1603.01801\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Training and Evaluating Multimodal Word Embeddings with Large-scale Web Annotated Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2016. University of California & Pinterest\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.stat.ucla.edu/~junhua.mao/multimodal_embedding.html\"\n  }, \"http://www.stat.ucla.edu/~junhua.mao/multimodal_embedding.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.08321\"\n  }, \"https://arxiv.org/abs/1611.08321\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Multi-Modal Image Correspondence Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.01225\"\n  }, \"https://arxiv.org/abs/1612.01225\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multimodal Deep Learning (D4L4 Deep Learning for Speech and Language UPC 2017)\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.slideshare.net/xavigiro/multimodal-deep-learning-d4l4-deep-learning-for-speech-and-language-upc-2017\"\n  }, \"http://www.slideshare.net/xavigiro/multimodal-deep-learning-d4l4-deep-learning-for-speech-and-language-upc-2017\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multimodal Learning with Transformers: A Survey\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Oxford & University of Surrey\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2206.06488\"\n  }, \"https://arxiv.org/abs/2206.06488\"))), mdx(\"h1\", {\n    \"id\": \"debugging-deep-learning\"\n  }, \"Debugging Deep Learning\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Some tips for debugging deep learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.lab41.org/some-tips-for-debugging-in-deep-learning-2/\"\n  }, \"http://www.lab41.org/some-tips-for-debugging-in-deep-learning-2/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Introduction to debugging neural networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://russellsstewart.com/notes/0.html\"\n  }, \"http://russellsstewart.com/notes/0.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"reddit: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.reddit.com/r/MachineLearning/comments/4du7gv/introduction_to_debugging_neural_networks\"\n  }, \"https://www.reddit.com/r/MachineLearning/comments/4du7gv/introduction_to_debugging_neural_networks\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"How to Visualize, Monitor and Debug Neural Network Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://deeplearning4j.org/visualization\"\n  }, \"http://deeplearning4j.org/visualization\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning from learning curves\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Kaggle\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/@dsouza.amanda/learning-from-learning-curves-1a82c6f98f49#.o5synrvvl\"\n  }, \"https://medium.com/@dsouza.amanda/learning-from-learning-curves-1a82c6f98f49#.o5synrvvl\"))), mdx(\"h1\", {\n    \"id\": \"understanding-cnn\"\n  }, \"Understanding CNN\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Understanding the Effective Receptive Field in Deep Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.toronto.edu/~wenjie/papers/nips16/top.pdf\"\n  }, \"http://www.cs.toronto.edu/~wenjie/papers/nips16/top.pdf\"))), mdx(\"h1\", {\n    \"id\": \"deep-learning-networks\"\n  }, \"Deep Learning Networks\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PCANet: A Simple Deep Learning Baseline for Image Classification?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arixv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1404.3606\"\n  }, \"http://arxiv.org/abs/1404.3606\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code(Matlab): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mx.nthu.edu.tw/~tsunghan/download/PCANet_demo_pyramid.rar\"\n  }, \"http://mx.nthu.edu.tw/~tsunghan/download/PCANet_demo_pyramid.rar\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"mirror: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://pan.baidu.com/s/1mg24b3a\"\n  }, \"http://pan.baidu.com/s/1mg24b3a\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(C++): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Ldpe2G/PCANet\"\n  }, \"https://github.com/Ldpe2G/PCANet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Python): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/IshitaTakeshi/PCANet\"\n  }, \"https://github.com/IshitaTakeshi/PCANet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Convolutional Kernel Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2014\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1406.3332\"\n  }, \"http://arxiv.org/abs/1406.3332\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deeply-supervised Nets\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: DSN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1409.5185\"\n  }, \"http://arxiv.org/abs/1409.5185\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://vcl.ucsd.edu/~sxie/2014/09/12/dsn-project/\"\n  }, \"http://vcl.ucsd.edu/~sxie/2014/09/12/dsn-project/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/s9xie/DSN\"\n  }, \"https://github.com/s9xie/DSN\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://zhangliliang.com/2014/11/02/paper-note-dsn/\"\n  }, \"http://zhangliliang.com/2014/11/02/paper-note-dsn/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FitNets: Hints for Thin Deep Nets\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1412.6550\"\n  }, \"https://arxiv.org/abs/1412.6550\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/adri-romsor/FitNets\"\n  }, \"https://github.com/adri-romsor/FitNets\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Striving for Simplicity: The All Convolutional Net\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR-2015 workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1412.6806\"\n  }, \"http://arxiv.org/abs/1412.6806\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"How these researchers tried something unconventional to come out with a smaller yet better Image Recognition.\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: All Convolutional Network: (\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1412.6806#\"\n  }, \"https://arxiv.org/abs/1412.6806#\"), \") implementation in Keras\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/@matelabs_ai/how-these-researchers-tried-something-unconventional-to-came-out-with-a-smaller-yet-better-image-544327f30e72#.pfdbvdmuh\"\n  }, \"https://medium.com/@matelabs_ai/how-these-researchers-tried-something-unconventional-to-came-out-with-a-smaller-yet-better-image-544327f30e72#.pfdbvdmuh\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MateLabs/All-Conv-Keras\"\n  }, \"https://github.com/MateLabs/All-Conv-Keras\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pointer Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1506.03134\"\n  }, \"https://arxiv.org/abs/1506.03134\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/vshallc/PtrNets\"\n  }, \"https://github.com/vshallc/PtrNets\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(TensorFlow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ikostrikov/TensorFlow-Pointer-Networks\"\n  }, \"https://github.com/ikostrikov/TensorFlow-Pointer-Networks\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(TensorFlow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/devsisters/pointer-network-tensorflow\"\n  }, \"https://github.com/devsisters/pointer-network-tensorflow\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/pointer-networks.md\"\n  }, \"https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/pointer-networks.md\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pointer Networks in TensorFlow (with sample code)\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/@devnag/pointer-networks-in-tensorflow-with-sample-code-14645063f264#.sxipqfj30\"\n  }, \"https://medium.com/@devnag/pointer-networks-in-tensorflow-with-sample-code-14645063f264#.sxipqfj30\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/devnag/tensorflow-pointer-networks\"\n  }, \"https://github.com/devnag/tensorflow-pointer-networks\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rectified Factor Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1502.06464\"\n  }, \"http://arxiv.org/abs/1502.06464\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/untom/librfn\"\n  }, \"https://github.com/untom/librfn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Correlational Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1504.07225\"\n  }, \"http://arxiv.org/abs/1504.07225\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/apsarath/CorrNet\"\n  }, \"https://github.com/apsarath/CorrNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Diversity Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1511.05077\"\n  }, \"http://arxiv.org/abs/1511.05077\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Competitive Multi-scale Convolution\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1511.05635\"\n  }, \"http://arxiv.org/abs/1511.05635\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://zhuanlan.zhihu.com/p/22377389\"\n  }, \"https://zhuanlan.zhihu.com/p/22377389\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Unified Approach for Learning the Parameters of Sum-Product Networks (SPN)\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: \\\"The Sum-Product Network (SPN) is a new type of machine learning model\\nwith fast exact probabilistic inference over many layers.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1601.00318\"\n  }, \"http://arxiv.org/abs/1601.00318\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://spn.cs.washington.edu/index.shtml\"\n  }, \"http://spn.cs.washington.edu/index.shtml\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://spn.cs.washington.edu/code.shtml\"\n  }, \"http://spn.cs.washington.edu/code.shtml\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Awesome Sum-Product Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/arranger1044/awesome-spn\"\n  }, \"https://github.com/arranger1044/awesome-spn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Recombinator Networks: Learning Coarse-to-Fine Feature Aggregation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1511.07356\"\n  }, \"http://arxiv.org/abs/1511.07356\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Honari_Recombinator_Networks_Learning_CVPR_2016_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Honari_Recombinator_Networks_Learning_CVPR_2016_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/SinaHonari/RCN\"\n  }, \"https://github.com/SinaHonari/RCN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dynamic Capacity Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICML 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1511.07838\"\n  }, \"http://arxiv.org/abs/1511.07838\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Tensorflow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/beopst/dcn.tf\"\n  }, \"https://github.com/beopst/dcn.tf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"review: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.erogol.com/1314-2/\"\n  }, \"http://www.erogol.com/1314-2/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bitwise Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://paris.cs.illinois.edu/pubs/minje-icmlw2015.pdf\"\n  }, \"http://paris.cs.illinois.edu/pubs/minje-icmlw2015.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://minjekim.com/demo_bnn.html\"\n  }, \"http://minjekim.com/demo_bnn.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Discriminative Features via Label Consistent Neural Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1602.01168\"\n  }, \"http://arxiv.org/abs/1602.01168\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Theory of Generative ConvNet\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.stat.ucla.edu/~ywu/GenerativeConvNet/main.html\"\n  }, \"http://www.stat.ucla.edu/~ywu/GenerativeConvNet/main.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1602.03264\"\n  }, \"http://arxiv.org/abs/1602.03264\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.stat.ucla.edu/~ywu/GenerativeConvNet/doc/code.zip\"\n  }, \"http://www.stat.ucla.edu/~ywu/GenerativeConvNet/doc/code.zip\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"How to Train Deep Variational Autoencoders and Probabilistic Ladder Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1602.02282\"\n  }, \"http://arxiv.org/abs/1602.02282\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Group Equivariant Convolutional Networks (G-CNNs)\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1602.07576\"\n  }, \"http://arxiv.org/abs/1602.07576\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Spiking Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1602.08323\"\n  }, \"http://arxiv.org/abs/1602.08323\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/petered/spiking-mlp\"\n  }, \"https://github.com/petered/spiking-mlp\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Low-rank passthrough neural networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.03116\"\n  }, \"http://arxiv.org/abs/1603.03116\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Avmb/lowrank-gru\"\n  }, \"https://github.com/Avmb/lowrank-gru\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Single Image 3D Interpreter Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016 (oral)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1604.08685\"\n  }, \"https://arxiv.org/abs/1604.08685\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deeply-Fused Nets\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.07716\"\n  }, \"http://arxiv.org/abs/1605.07716\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SNN: Stacked Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.08512\"\n  }, \"http://arxiv.org/abs/1605.08512\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Universal Correspondence Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2016 full oral presentation. Stanford University & NEC Laboratories America\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cvgl.stanford.edu/projects/ucn/\"\n  }, \"http://cvgl.stanford.edu/projects/ucn/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1606.03558\"\n  }, \"https://arxiv.org/abs/1606.03558\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Progressive Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google DeepMind\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1606.04671\"\n  }, \"https://arxiv.org/abs/1606.04671\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/synpon/prog_nn\"\n  }, \"https://github.com/synpon/prog_nn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yao62995/A3C\"\n  }, \"https://github.com/yao62995/A3C\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Holistic SparseCNN: Forging the Trident of Accuracy, Speed, and Size\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.01409\"\n  }, \"http://arxiv.org/abs/1608.01409\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mollifying Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"author: Caglar Gulcehre, Marcin Moczulski, Francesco Visin, Yoshua Bengio\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.04980\"\n  }, \"http://arxiv.org/abs/1608.04980\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Domain Separation Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Brain & Imperial College London & Google Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1608.06019\"\n  }, \"https://arxiv.org/abs/1608.06019\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tensorflow/models/tree/master/domain_adaptation\"\n  }, \"https://github.com/tensorflow/models/tree/master/domain_adaptation\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Local Binary Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.06049\"\n  }, \"http://arxiv.org/abs/1608.06049\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CliqueCNN: Deep Unsupervised Exemplar Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.08792\"\n  }, \"http://arxiv.org/abs/1608.08792\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/asanakoy/cliquecnn\"\n  }, \"https://github.com/asanakoy/cliquecnn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Convexified Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.01000\"\n  }, \"http://arxiv.org/abs/1609.01000\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-scale brain networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.08828\"\n  }, \"http://arxiv.org/abs/1608.08828\"))), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.11473\"\n  }, \"https://arxiv.org/abs/1711.11473\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Input Convex Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.07152\"\n  }, \"http://arxiv.org/abs/1609.07152\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/locuslab/icnn\"\n  }, \"https://github.com/locuslab/icnn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"HyperNetworks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1609.09106\"\n  }, \"https://arxiv.org/abs/1609.09106\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://blog.otoro.net/2016/09/28/hyper-networks/\"\n  }, \"http://blog.otoro.net/2016/09/28/hyper-networks/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hardmaru/supercell/blob/master/assets/MNIST_Static_HyperNetwork_Example.ipynb\"\n  }, \"https://github.com/hardmaru/supercell/blob/master/assets/MNIST_Static_HyperNetwork_Example.ipynb\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"HyperLSTM\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hardmaru/supercell/blob/master/supercell.py\"\n  }, \"https://github.com/hardmaru/supercell/blob/master/supercell.py\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"X-CNN: Cross-modal Convolutional Neural Networks for Sparse Datasets\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.00163\"\n  }, \"https://arxiv.org/abs/1610.00163\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Tensor Switching Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arixiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.10087\"\n  }, \"https://arxiv.org/abs/1610.10087\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/coxlab/tsnet\"\n  }, \"https://github.com/coxlab/tsnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Harvard University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.eecs.harvard.edu/~htk/publication/2016-icpr-teerapittayanon-mcdanel-kung.pdf\"\n  }, \"http://www.eecs.harvard.edu/~htk/publication/2016-icpr-teerapittayanon-mcdanel-kung.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kunglab/branchynet\"\n  }, \"https://github.com/kunglab/branchynet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spectral Convolution Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.05378\"\n  }, \"https://arxiv.org/abs/1611.05378\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DelugeNets: Deep Networks with Massive and Flexible Cross-layer Information Inflows\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.05552\"\n  }, \"https://arxiv.org/abs/1611.05552\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xternalz/DelugeNets\"\n  }, \"https://github.com/xternalz/DelugeNets\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PolyNet: A Pursuit of Structural Diversity in Very Deep Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.05725\"\n  }, \"https://arxiv.org/abs/1611.05725\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"poster: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mmlab.ie.cuhk.edu.hk/projects/cu_deeplink/polynet_poster.pdf\"\n  }, \"http://mmlab.ie.cuhk.edu.hk/projects/cu_deeplink/polynet_poster.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Weakly Supervised Cascaded Convolutional Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.08258\"\n  }, \"https://arxiv.org/abs/1611.08258\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepSetNet: Predicting Sets with Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: multi-class image classification and pedestrian detection\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.08998\"\n  }, \"https://arxiv.org/abs/1611.08998\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Steerable CNNs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Amsterdam\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.08498\"\n  }, \"https://arxiv.org/abs/1612.08498\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Feedback Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://feedbacknet.stanford.edu/\"\n  }, \"http://feedbacknet.stanford.edu/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.09508\"\n  }, \"https://arxiv.org/abs/1612.09508\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"youtube: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://youtu.be/MY5Uhv38Ttg\"\n  }, \"https://youtu.be/MY5Uhv38Ttg\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Oriented Response Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.01833\"\n  }, \"https://arxiv.org/abs/1701.01833\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"OptNet: Differentiable Optimization as a Layer in Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.00443\"\n  }, \"https://arxiv.org/abs/1703.00443\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/locuslab/optnet\"\n  }, \"https://github.com/locuslab/optnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A fast and differentiable QP solver for PyTorch\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/locuslab/qpth\"\n  }, \"https://github.com/locuslab/qpth\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Meta Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1703.00837\"\n  }, \"https://arxiv.org/abs/1703.00837\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deformable Convolutional Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017 oral. Microsoft Research Asia\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: deformable convolution, deformable RoI pooling\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.06211\"\n  }, \"https://arxiv.org/abs/1703.06211\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"sliedes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.jifengdai.org/slides/Deformable_Convolutional_Networks_Oral.pdf\"\n  }, \"http://www.jifengdai.org/slides/Deformable_Convolutional_Networks_Oral.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/msracver/Deformable-ConvNets\"\n  }, \"https://github.com/msracver/Deformable-ConvNets\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/felixlaumon/deform-conv\"\n  }, \"https://github.com/felixlaumon/deform-conv\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/oeway/pytorch-deform-conv\"\n  }, \"https://github.com/oeway/pytorch-deform-conv\"))), mdx(\"p\", null, \"Deformable ConvNets v2: More Deformable, Better Results**\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Science and Technology of China & Microsoft Research Asia\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: DCNv2\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.11168\"\n  }, \"https://arxiv.org/abs/1811.11168\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/msracver/Deformable-ConvNets/tree/master/DCNv2_op\"\n  }, \"https://github.com/msracver/Deformable-ConvNets/tree/master/DCNv2_op\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Second-order Convolutional Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1703.06817\"\n  }, \"https://arxiv.org/abs/1703.06817\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Gabor Convolutional Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1705.01450\"\n  }, \"https://arxiv.org/abs/1705.01450\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Rotation Equivariant Network\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1705.08623\"\n  }, \"https://arxiv.org/abs/1705.08623\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dense Transformer Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Washington State University & University of California, Davis\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1705.08881\"\n  }, \"https://arxiv.org/abs/1705.08881\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/divelab/dtn\"\n  }, \"https://github.com/divelab/dtn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Complex Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: [Universit\\xE9 de Montr\\xE9al & INRS-EMT & Microsoft Maluuba\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1705.09792\"\n  }, \"https://arxiv.org/abs/1705.09792\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ChihebTrabelsi/deep_complex_networks\"\n  }, \"https://github.com/ChihebTrabelsi/deep_complex_networks\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Quaternion Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Louisiana\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.04604\"\n  }, \"https://arxiv.org/abs/1712.04604\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DiracNets: Training Very Deep Neural Networks Without Skip-Connections\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Universit\\xE9 Paris-Est\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.00388\"\n  }, \"https://arxiv.org/abs/1706.00388\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/szagoruyko/diracnets\"\n  }, \"https://github.com/szagoruyko/diracnets\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dual Path Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: National University of Singapore\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.01629\"\n  }, \"https://arxiv.org/abs/1707.01629\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(MXNet): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/cypw/DPNs\"\n  }, \"https://github.com/cypw/DPNs\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Primal-Dual Group Convolutions for Deep Neural Networks\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Interleaved Group Convolutions for Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: interleaved group convolutional neural networks (IGCNets), IGCV1\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.02725\"\n  }, \"https://arxiv.org/abs/1707.02725\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gihtub: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hellozting/InterleavedGroupConvolutions\"\n  }, \"https://github.com/hellozting/InterleavedGroupConvolutions\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"IGCV2: Interleaved Structured Sparse Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.06202\"\n  }, \"https://arxiv.org/abs/1804.06202\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"IGCV3: Interleaved Low-Rank Group Convolutions for Efficient Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Scinence and Technology of China & Microsoft Reserach Asia\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1806.00178\"\n  }, \"https://arxiv.org/abs/1806.00178\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/homles11/IGCV3\"\n  }, \"https://github.com/homles11/IGCV3\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sensor Transformation Attention Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1708.01015\"\n  }, \"https://arxiv.org/abs/1708.01015\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sparsity Invariant CNNs\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1708.06500\"\n  }, \"https://arxiv.org/abs/1708.06500\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SPARCNN: SPAtially Related Convolutional Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1708.07522\"\n  }, \"https://arxiv.org/abs/1708.07522\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.01686\"\n  }, \"https://arxiv.org/abs/1709.01686\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Polar Transformer Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.01889\"\n  }, \"https://arxiv.org/abs/1709.01889\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Tensor Product Generation Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.09118\"\n  }, \"https://arxiv.org/abs/1709.09118\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Competitive Pathway Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACML 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1709.10282\"\n  }, \"https://arxiv.org/abs/1709.10282\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/JiaRenChang/CoPaNet\"\n  }, \"https://github.com/JiaRenChang/CoPaNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Context Embedding Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1710.01691\"\n  }, \"https://arxiv.org/abs/1710.01691\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generalization in Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MIT & University of Montreal\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1710.05468\"\n  }, \"https://arxiv.org/abs/1710.05468\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Understanding Deep Learning Generalization by Maximum Entropy\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Science and Technology of China & Beijing Jiaotong University & Chinese Academy of Sciences\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.07758\"\n  }, \"https://arxiv.org/abs/1711.07758\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Do Convolutional Neural Networks Learn Class Hierarchy?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Bosch Research North America & Michigan State University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1710.06501\"\n  }, \"https://arxiv.org/abs/1710.06501\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"video demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://vimeo.com/228263798\"\n  }, \"https://vimeo.com/228263798\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Hyperspherical Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.03189\"\n  }, \"https://arxiv.org/abs/1711.03189\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Beyond Sparsity: Tree Regularization of Deep Models for Interpretability\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.06178\"\n  }, \"https://arxiv.org/abs/1711.06178\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Neural Motifs: Scene Graph Parsing with Global Context\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Stacked Motif Networks\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.06640\"\n  }, \"https://arxiv.org/abs/1711.06640\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Priming Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.05918\"\n  }, \"https://arxiv.org/abs/1711.05918\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Three Factors Influencing Minima in SGD\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.04623\"\n  }, \"https://arxiv.org/abs/1711.04623\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BPGrad: Towards Global Optimality in Deep Learning via Branch and Pruning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.06959\"\n  }, \"https://arxiv.org/abs/1711.06959\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BlockDrop: Dynamic Inference Paths in Residual Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: UMD & UT Austin & IBM Research & Fusemachines Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.08393\"\n  }, \"https://arxiv.org/abs/1711.08393\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Wasserstein Introspective Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.08875\"\n  }, \"https://arxiv.org/abs/1711.08875\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SkipNet: Learning Dynamic Routing in Convolutional Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.09485\"\n  }, \"https://arxiv.org/abs/1711.09485\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Do Convolutional Neural Networks act as Compositional Nearest Neighbors?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CMU & West Virginia University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.10683\"\n  }, \"https://arxiv.org/abs/1711.10683\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ConvNets and ImageNet Beyond Accuracy: Explanations, Bias Detection, Adversarial Examples and Model Criticism\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Facebook AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.11443\"\n  }, \"https://arxiv.org/abs/1711.11443\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Broadcasting Convolutional Network\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.02517\"\n  }, \"https://arxiv.org/abs/1712.02517\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Point-wise Convolutional Neural Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Singapore University of Technology and Design\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.05245\"\n  }, \"https://arxiv.org/abs/1712.05245\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ScreenerNet: Learning Curriculum for Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Intel Corporation & Allen Institute for Artificial Intelligence\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: curricular learning, deep learning, deep q-learning\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.00904\"\n  }, \"https://arxiv.org/abs/1801.00904\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sparsely Connected Convolutional Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1801.05895\"\n  }, \"https://arxiv.org/abs/1801.05895\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spherical CNNs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR 2018 best paper award. University of Amsterdam & EPFL\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.10130\"\n  }, \"https://arxiv.org/abs/1801.10130\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, PyTorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jonas-koehler/s2cnn\"\n  }, \"https://github.com/jonas-koehler/s2cnn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Going Deeper in Spiking Neural Networks: VGG and Residual Architectures\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Purdue University & Oculus Research & Facebook Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1802.02627\"\n  }, \"https://arxiv.org/abs/1802.02627\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rotate your Networks: Better Weight Consolidation and Less Catastrophic Forgetting\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1802.02950\"\n  }, \"https://arxiv.org/abs/1802.02950\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Convolutional Neural Networks with Alternately Updated Clique\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1802.10419\"\n  }, \"https://arxiv.org/abs/1802.10419\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/iboing/CliqueNet\"\n  }, \"https://github.com/iboing/CliqueNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Decoupled Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018 (Spotlight)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.08071\"\n  }, \"https://arxiv.org/abs/1804.08071\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Optical Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.06082\"\n  }, \"https://arxiv.org/abs/1805.06082\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Regularization Learning Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Weizmann Institute of Science\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Regularization Learning Networks (RLNs), Counterfactual Loss, tabular datasets\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.06440\"\n  }, \"https://arxiv.org/abs/1805.06440\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bilinear Attention Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.07932\"\n  }, \"https://arxiv.org/abs/1805.07932\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cautious Deep Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.09460\"\n  }, \"https://arxiv.org/abs/1805.09460\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Perturbative Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: We introduce a very simple, yet effective, module called a perturbation layer as an alternative to a convolutional layer\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://xujuefei.com/pnn.html\"\n  }, \"http://xujuefei.com/pnn.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1806.01817\"\n  }, \"https://arxiv.org/abs/1806.01817\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Lightweight Probabilistic Deep Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.11327\"\n  }, \"https://arxiv.org/abs/1805.11327\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Channel Gating Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.12549\"\n  }, \"https://arxiv.org/abs/1805.12549\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Evenly Cascaded Convolutional Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1807.00456\"\n  }, \"https://arxiv.org/abs/1807.00456\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SGAD: Soft-Guided Adaptively-Dropped Neural Network\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1807.01430\"\n  }, \"https://arxiv.org/abs/1807.01430\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Explainable Neural Computation via Stack Neural Module Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.08556\"\n  }, \"https://arxiv.org/abs/1807.08556\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rank-1 Convolutional Neural Network\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1808.04303\"\n  }, \"https://arxiv.org/abs/1808.04303\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Neural Network Encapsulation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.03749\"\n  }, \"https://arxiv.org/abs/1808.03749\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Penetrating the Fog: the Path to Efficient CNN Models\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1810.04231\"\n  }, \"https://arxiv.org/abs/1810.04231\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A2-Nets: Double Attention Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1810.11579\"\n  }, \"https://arxiv.org/abs/1810.11579\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Global Second-order Pooling Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.12006\"\n  }, \"https://arxiv.org/abs/1811.12006\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ESPNetv2: A Light-weight, Power Efficient, and General Purpose Convolutional Neural Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Washington & Allen Institute for AI (AI2) & XNOR.AI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.11431\"\n  }, \"https://arxiv.org/abs/1811.11431\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/sacmehta/ESPNetv2\"\n  }, \"https://github.com/sacmehta/ESPNetv2\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Kernel Transformer Networks for Compact Spherical Convolution\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1812.03115\"\n  }, \"https://arxiv.org/abs/1812.03115\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"UAN: Unified Attention Network for Convolutional Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1901.05376\"\n  }, \"https://arxiv.org/abs/1901.05376\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"One-Class Convolutional Neural Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Johns Hopkins University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.08688\"\n  }, \"https://arxiv.org/abs/1901.08688\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/otkupjnoz/oc-cnn\"\n  }, \"https://github.com/otkupjnoz/oc-cnn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Selective Kernel Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"inrtro: Nanjing University of Science and Technology & Momenta & Nanjing University & Tsinghua University]\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.06586\"\n  }, \"https://arxiv.org/abs/1903.06586\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/implus/SKNet\"\n  }, \"https://github.com/implus/SKNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Universally Slimmable Networks and Improved Training Techniques\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.05134\"\n  }, \"https://arxiv.org/abs/1903.05134\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dynamic Slimmable Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.13258\"\n  }, \"https://arxiv.org/abs/2103.13258\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/changlin31/DS-Net\"\n  }, \"https://github.com/changlin31/DS-Net\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Adaptively Connected Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.03579\"\n  }, \"https://arxiv.org/abs/1904.03579\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/wanggrun/Adaptively-Connected-Neural-Networks\"\n  }, \"https://github.com/wanggrun/Adaptively-Connected-Neural-Networks\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Transformable Bottleneck Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1904.06458\"\n  }, \"https://arxiv.org/abs/1904.06458\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pixel-Adaptive Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.05373\"\n  }, \"https://arxiv.org/abs/1904.05373\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attention Augmented Convolutional Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Brain\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.09925\"\n  }, \"https://arxiv.org/abs/1904.09925\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spatial Group-wise Enhance: Improving Semantic Feature Learning in Convolutional Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1905.09646\"\n  }, \"https://arxiv.org/abs/1905.09646\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/implus/PytorchInsight\"\n  }, \"https://github.com/implus/PytorchInsight\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"EnsembleNet: End-to-End Optimization of Multi-headed Models\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google AI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1905.09979\"\n  }, \"https://arxiv.org/abs/1905.09979\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MixNet: Mixed Depthwise Convolutional Kernels\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.09595\"\n  }, \"https://arxiv.org/abs/1907.09595\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet/mixnet\"\n  }, \"https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet/mixnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"HarDNet: A Low Memory Traffic Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: National Tsing Hua University & University of Michigan\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.00948\"\n  }, \"https://arxiv.org/abs/1909.00948\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"\\u03A0\\u2212 nets: Deep Polynomial Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.03828\"\n  }, \"https://arxiv.org/abs/2003.03828\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Circle Loss: A Unified Perspective of Pair Similarity Optimization\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: 1Megvii Inc. & Beihang University & Australian National University & Tsinghua University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2002.10857\"\n  }, \"https://arxiv.org/abs/2002.10857\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Designing Network Design Spaces\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Facebook AI Research (FAIR)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.13678\"\n  }, \"https://arxiv.org/abs/2003.13678\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"WeightNet: Revisiting the Design Space of Weight Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.11823\"\n  }, \"https://arxiv.org/abs/2007.11823\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/megvii-model/WeightNet\"\n  }, \"https://github.com/megvii-model/WeightNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Disentangled Non-Local Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2006.06668\"\n  }, \"https://arxiv.org/abs/2006.06668\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dynamic Neural Networks: A Survey\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tsinghua University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2102.04906\"\n  }, \"https://arxiv.org/abs/2102.04906\"))), mdx(\"h2\", {\n    \"id\": \"convolutions--filters\"\n  }, \"Convolutions / Filters\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Warped Convolutions: Efficient Invariance to Spatial Transformations\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.04382\"\n  }, \"http://arxiv.org/abs/1609.04382\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Coordinating Filters for Faster Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.09746\"\n  }, \"https://arxiv.org/abs/1703.09746\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/wenwei202/caffe/tree/sfm\"\n  }, \"https://github.com/wenwei202/caffe/tree/sfm\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Shift: A Zero FLOP, Zero Parameter Alternative to Spatial Convolutions\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: UC Berkeley\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.08141\"\n  }, \"https://arxiv.org/abs/1711.08141\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spatially-Adaptive Filter Units for Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Ljubljana & University of Birmingham\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.11473\"\n  }, \"https://arxiv.org/abs/1711.11473\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"clcNet: Improving the Efficiency of Convolutional Neural Network using Channel Local Convolutions\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.06145\"\n  }, \"https://arxiv.org/abs/1712.06145\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DCFNet: Deep Neural Network with Decomposed Convolutional Filters\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1802.04145\"\n  }, \"https://arxiv.org/abs/1802.04145\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast End-to-End Trainable Guided Filter\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://wuhuikai.me/DeepGuidedFilterProject/\"\n  }, \"http://wuhuikai.me/DeepGuidedFilterProject/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gtihub(official, PyTorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/wuhuikai/DeepGuidedFilter\"\n  }, \"https://github.com/wuhuikai/DeepGuidedFilter\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Diagonalwise Refactorization: An Efficient Training Method for Depthwise Convolutions\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.09926\"\n  }, \"https://arxiv.org/abs/1803.09926\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/clavichord93/diagonalwise-refactorization-tensorflow\"\n  }, \"https://github.com/clavichord93/diagonalwise-refactorization-tensorflow\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Use of symmetric kernels for convolutional neural networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICDSIAI 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.09421\"\n  }, \"https://arxiv.org/abs/1805.09421\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"EasyConvPooling: Random Pooling with Easy Convolution for Accelerating Training and Testing\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1806.01729\"\n  }, \"https://arxiv.org/abs/1806.01729\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Targeted Kernel Networks: Faster Convolutions with Attentive Regularization\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1806.00523\"\n  }, \"https://arxiv.org/abs/1806.00523\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Uber AI Labs & Uber Technologies\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.03247\"\n  }, \"https://arxiv.org/abs/1807.03247\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/uber-research/CoordConv\"\n  }, \"https://github.com/uber-research/CoordConv\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"youtube: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=8yFQc6elePA\"\n  }, \"https://www.youtube.com/watch?v=8yFQc6elePA\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Network Decoupling: From Regular to Depthwise Separable Convolutions\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1808.05517\"\n  }, \"https://arxiv.org/abs/1808.05517\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Partial Convolution based Padding\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NVIDIA Corporation\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv; \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.11718\"\n  }, \"https://arxiv.org/abs/1811.11718\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/NVIDIA/partialconv\"\n  }, \"https://github.com/NVIDIA/partialconv\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DSConv: Efficient Convolution Operator\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1901.01928\"\n  }, \"https://arxiv.org/abs/1901.01928\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CircConv: A Structured Convolution with Low Complexity\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1902.11268\"\n  }, \"https://arxiv.org/abs/1902.11268\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Accelerating Large-Kernel Convolution Using Summed-Area Tables\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Princeton University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1906.11367\"\n  }, \"https://arxiv.org/abs/1906.11367\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mapped Convolutions\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of North Carolina at Chapel Hill\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1906.11096\"\n  }, \"https://arxiv.org/abs/1906.11096\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Universal Pooling -- A New Pooling Method for Convolutional Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1907.11440\"\n  }, \"https://arxiv.org/abs/1907.11440\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dilated Point Convolutions: On the Receptive Field of Point Convolutions\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1907.12046\"\n  }, \"https://arxiv.org/abs/1907.12046\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"LIP: Local Importance-based Pooling\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1908.04156\"\n  }, \"https://arxiv.org/abs/1908.04156\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Generalized Max Pooling\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICDAR\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1908.05040\"\n  }, \"https://arxiv.org/abs/1908.05040\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MixConv: Mixed Depthwise Convolutional Kernels\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro:BMVC 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.09595\"\n  }, \"https://arxiv.org/abs/1907.09595\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet/mixnet\"\n  }, \"https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet/mixnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: UC Berkeley & USTC & MSRA\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1910.02940\"\n  }, \"https://arxiv.org/abs/1910.02940\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dynamic Convolution: Attention over Convolution Kernels\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Microsoft\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1912.03458\"\n  }, \"https://arxiv.org/abs/1912.03458\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pyramidal Convolution: Rethinking Convolutional Neural Networks for Visual Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2006.11538\"\n  }, \"https://arxiv.org/abs/2006.11538\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/iduta/pyconv\"\n  }, \"https://github.com/iduta/pyconv\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gihtub: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/iduta/pyconvsegnet\"\n  }, \"https://github.com/iduta/pyconvsegnet\"))), mdx(\"h2\", {\n    \"id\": \"highway-networks\"\n  }, \"Highway Networks\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Highway Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICML 2015 Deep Learning workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: shortcut connections with gating functions. These gates are data-dependent and have parameters\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1505.00387\"\n  }, \"http://arxiv.org/abs/1505.00387\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(PyTorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/analvikingur/pytorch_Highway\"\n  }, \"https://github.com/analvikingur/pytorch_Highway\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Highway Networks with TensorFlow\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/jim-fleming/highway-networks-with-tensorflow-1e6dfa667daa#.71fgztsb6\"\n  }, \"https://medium.com/jim-fleming/highway-networks-with-tensorflow-1e6dfa667daa#.71fgztsb6\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Very Deep Learning with Highway Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage(papers+code+FAQ): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://people.idsia.ch/~rupesh/very_deep_learning/\"\n  }, \"http://people.idsia.ch/~rupesh/very_deep_learning/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Training Very Deep Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Extends \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1505.00387\"\n  }, \"Highway Networks\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://people.idsia.ch/~rupesh/very_deep_learning/\"\n  }, \"http://people.idsia.ch/~rupesh/very_deep_learning/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1507.06228\"\n  }, \"http://arxiv.org/abs/1507.06228\"))), mdx(\"h2\", {\n    \"id\": \"spatial-transformer-networks\"\n  }, \"Spatial Transformer Networks\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spatial Transformer Networks\")), mdx(\"img\", {\n    \"src\": \"https://camo.githubusercontent.com/bb81d6267f2123d59979453526d958a58899bb4f/687474703a2f2f692e696d6775722e636f6d2f4578474456756c2e706e67\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1506.02025\"\n  }, \"http://arxiv.org/abs/1506.02025\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gitxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://gitxiv.com/posts/5WTXTLuEA4Hd8W84G/spatial-transformer-networks\"\n  }, \"http://gitxiv.com/posts/5WTXTLuEA4Hd8W84G/spatial-transformer-networks\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/daerduoCarey/SpatialTransformerLayer\"\n  }, \"https://github.com/daerduoCarey/SpatialTransformerLayer\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/qassemoquab/stnbhwd\"\n  }, \"https://github.com/qassemoquab/stnbhwd\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/skaae/transformer_network\"\n  }, \"https://github.com/skaae/transformer_network\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Caffe): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/happynear/SpatialTransformerLayer\"\n  }, \"https://github.com/happynear/SpatialTransformerLayer\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/daviddao/spatial-transformer-tensorflow\"\n  }, \"https://github.com/daviddao/spatial-transformer-tensorflow\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"caffe-issue: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/BVLC/caffe/issues/3114\"\n  }, \"https://github.com/BVLC/caffe/issues/3114\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://lasagne.readthedocs.org/en/latest/modules/layers/special.html#lasagne.layers.TransformerLayer\"\n  }, \"https://lasagne.readthedocs.org/en/latest/modules/layers/special.html#lasagne.layers.TransformerLayer\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"ipn(Lasagne): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://nbviewer.jupyter.org/github/Lasagne/Recipes/blob/master/examples/spatial_transformer_network.ipynb\"\n  }, \"http://nbviewer.jupyter.org/github/Lasagne/Recipes/blob/master/examples/spatial_transformer_network.ipynb\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.evernote.com/shard/s189/sh/ad8a38de-9e98-4e06-b09e-574bd62893ff/32f72798c095dd7672f4cb017a32d9b4\"\n  }, \"https://www.evernote.com/shard/s189/sh/ad8a38de-9e98-4e06-b09e-574bd62893ff/32f72798c095dd7672f4cb017a32d9b4\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"youtube: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=6NOQC_fl1hQ\"\n  }, \"https://www.youtube.com/watch?v=6NOQC_fl1hQ\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The power of Spatial Transformer Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://torch.ch/blog/2015/09/07/spatial_transformers.html\"\n  }, \"http://torch.ch/blog/2015/09/07/spatial_transformers.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/moodstocks/gtsrb.torch\"\n  }, \"https://github.com/moodstocks/gtsrb.torch\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Recurrent Spatial Transformer Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1509.05329\"\n  }, \"http://arxiv.org/abs/1509.05329\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning Paper Implementations: Spatial Transformer Networks - Part I\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://kevinzakka.github.io/2017/01/10/stn-part1/\"\n  }, \"https://kevinzakka.github.io/2017/01/10/stn-part1/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kevinzakka/blog-code/tree/master/spatial_transformer\"\n  }, \"https://github.com/kevinzakka/blog-code/tree/master/spatial_transformer\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Top-down Flow Transformer Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.02400\"\n  }, \"https://arxiv.org/abs/1712.02400\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Non-Parametric Transformation Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CMU\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.04520\"\n  }, \"https://arxiv.org/abs/1801.04520\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hierarchical Spatial Transformer Network\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1801.09467\"\n  }, \"https://arxiv.org/abs/1801.09467\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spatial Transformer Introspective Neural Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Johns Hopkins University & Shanghai University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.06447\"\n  }, \"https://arxiv.org/abs/1805.06447\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeSTNet: Densely Fused Spatial Transformer Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.04050\"\n  }, \"https://arxiv.org/abs/1807.04050\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MIST: Multiple Instance Spatial Transformer Network\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.10725\"\n  }, \"https://arxiv.org/abs/1811.10725\")), mdx(\"h2\", {\n    \"id\": \"fractalnet\"\n  }, \"FractalNet\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FractalNet: Ultra-Deep Neural Networks without Residuals\")), mdx(\"img\", {\n    \"src\": \"http://people.cs.uchicago.edu/~larsson/fractalnet/overview.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://people.cs.uchicago.edu/~larsson/fractalnet/\"\n  }, \"http://people.cs.uchicago.edu/~larsson/fractalnet/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.07648\"\n  }, \"http://arxiv.org/abs/1605.07648\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/gustavla/fractalnet\"\n  }, \"https://github.com/gustavla/fractalnet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/edgelord/FractalNet\"\n  }, \"https://github.com/edgelord/FractalNet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Keras): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/snf/keras-fractalnet\"\n  }, \"https://github.com/snf/keras-fractalnet\"))), mdx(\"h1\", {\n    \"id\": \"generative-models\"\n  }, \"Generative Models\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Max-margin Deep Generative Models\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1504.06787\"\n  }, \"http://arxiv.org/abs/1504.06787\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zhenxuan00/mmdgm\"\n  }, \"https://github.com/zhenxuan00/mmdgm\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Discriminative Regularization for Generative Models\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1602.03220\"\n  }, \"http://arxiv.org/abs/1602.03220\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/vdumoulin/discgen\"\n  }, \"https://github.com/vdumoulin/discgen\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Auxiliary Deep Generative Models\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1602.05473\"\n  }, \"http://arxiv.org/abs/1602.05473\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/larsmaaloee/auxiliary-deep-generative-models\"\n  }, \"https://github.com/larsmaaloee/auxiliary-deep-generative-models\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sampling Generative Networks: Notes on a Few Effective Techniques\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.04468\"\n  }, \"http://arxiv.org/abs/1609.04468\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/dribnet/plat\"\n  }, \"https://github.com/dribnet/plat\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Conditional Image Synthesis With Auxiliary Classifier GANs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.09585\"\n  }, \"https://arxiv.org/abs/1610.09585\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/buriburisuri/ac-gan\"\n  }, \"https://github.com/buriburisuri/ac-gan\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Keras): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lukedeo/keras-acgan\"\n  }, \"https://github.com/lukedeo/keras-acgan\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"On the Quantitative Analysis of Decoder-Based Generative Models\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Toronto & OpenAI & CMU\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.04273\"\n  }, \"https://arxiv.org/abs/1611.04273\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tonywu95/eval_gen\"\n  }, \"https://github.com/tonywu95/eval_gen\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Boosted Generative Models\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.08484\"\n  }, \"https://arxiv.org/abs/1702.08484\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://openreview.net/pdf?id=HyY4Owjll\"\n  }, \"https://openreview.net/pdf?id=HyY4Owjll\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An Architecture for Deep, Hierarchical Generative Models\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.04739\"\n  }, \"https://arxiv.org/abs/1612.04739\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Philip-Bachman/MatNets-NIPS\"\n  }, \"https://github.com/Philip-Bachman/MatNets-NIPS\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning and Hierarchal Generative Models\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2016. MIT\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.09057\"\n  }, \"https://arxiv.org/abs/1612.09057\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Probabilistic Torch\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Probabilistic Torch is library for deep generative models that extends PyTorch\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/probtorch/probtorch\"\n  }, \"https://github.com/probtorch/probtorch\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Tutorial on Deep Generative Models\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: UAI 2017 Tutorial: Shakir Mohamed & Danilo Rezende (DeepMind)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"youtube: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=JrO5fSskISY\"\n  }, \"https://www.youtube.com/watch?v=JrO5fSskISY\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"mirror: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.bilibili.com/video/av16428277/\"\n  }, \"https://www.bilibili.com/video/av16428277/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.shakirm.com/slides/DeepGenModelsTutorial.pdf\"\n  }, \"http://www.shakirm.com/slides/DeepGenModelsTutorial.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Note on the Inception Score\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Stanford University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.01973\"\n  }, \"https://arxiv.org/abs/1801.01973\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Gradient Layer: Enhancing the Convergence of Adversarial Training for Generative Models\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AISTATS 2018. The University of Tokyo\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.02227\"\n  }, \"https://arxiv.org/abs/1801.02227\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Batch Normalization in the final layer of generative networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.07389\"\n  }, \"https://arxiv.org/abs/1805.07389\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Structured Generative Models\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tsinghua University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.03877\"\n  }, \"https://arxiv.org/abs/1807.03877\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"VFunc: a Deep Generative Model for Functions\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICML 2018 workshop on Prediction and Generative Modeling in Reinforcement Learning. Microsoft Research & McGill University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.04106\"\n  }, \"https://arxiv.org/abs/1807.04106\"))), mdx(\"h1\", {\n    \"id\": \"deep-learning-and-robots\"\n  }, \"Deep Learning and Robots\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Robot Learning Manipulation Action Plans by \\\"Watching\\\" Unconstrained Videos from the World Wide Web\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.umiacs.umd.edu/~yzyang/paper/YouCookMani_CameraReady.pdf\"\n  }, \"http://www.umiacs.umd.edu/~yzyang/paper/YouCookMani_CameraReady.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"author page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.umiacs.umd.edu/~yzyang/\"\n  }, \"http://www.umiacs.umd.edu/~yzyang/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End-to-End Training of Deep Visuomotor Policies\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1504.00702\"\n  }, \"http://arxiv.org/abs/1504.00702\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Comment on Open AI\\u2019s Efforts to Robot Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://gridworld.wordpress.com/2016/07/28/comment-on-open-ais-efforts-to-robot-learning/\"\n  }, \"https://gridworld.wordpress.com/2016/07/28/comment-on-open-ais-efforts-to-robot-learning/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Curious Robot: Learning Visual Representations via Physical Interactions\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1604.01360\"\n  }, \"http://arxiv.org/abs/1604.01360\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"How to build a robot that \\u201Csees\\u201D with $100 and TensorFlow\")), mdx(\"img\", {\n    \"src\": \"https://d3ansictanv2wj.cloudfront.net/Figure_5-5b104cf7a53a9c1ee95110b78fb14256.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.oreilly.com/learning/how-to-build-a-robot-that-sees-with-100-and-tensorflow\"\n  }, \"https://www.oreilly.com/learning/how-to-build-a-robot-that-sees-with-100-and-tensorflow\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Visual Foresight for Planning Robot Motion\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://sites.google.com/site/brainrobotdata/\"\n  }, \"https://sites.google.com/site/brainrobotdata/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.00696\"\n  }, \"https://arxiv.org/abs/1610.00696\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"video: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://sites.google.com/site/robotforesight/\"\n  }, \"https://sites.google.com/site/robotforesight/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sim-to-Real Robot Learning from Pixels with Progressive Nets\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google DeepMind\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.04286\"\n  }, \"https://arxiv.org/abs/1610.04286\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards Lifelong Self-Supervision: A Deep Learning Direction for Robotics\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.00201\"\n  }, \"https://arxiv.org/abs/1611.00201\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Differentiable Physics Engine for Deep Learning in Robotics\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openreview.net/pdf?id=SyEiHNKxx\"\n  }, \"http://openreview.net/pdf?id=SyEiHNKxx\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep-learning in Mobile Robotics - from Perception to Control Systems: A Survey on Why and Why not\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: City University of Hong Kong & Hong Kong University of Science and Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.07139\"\n  }, \"https://arxiv.org/abs/1612.07139\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Robotic Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://simons.berkeley.edu/talks/sergey-levine-01-24-2017-1\"\n  }, \"https://simons.berkeley.edu/talks/sergey-levine-01-24-2017-1\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"youtube: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=jtjW5Pye_44\"\n  }, \"https://www.youtube.com/watch?v=jtjW5Pye_44\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning in Robotics: A Review of Recent Research\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1707.07217\"\n  }, \"https://arxiv.org/abs/1707.07217\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning for Robotics\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: by Pieter Abbeel\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"video: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.facebook.com/nipsfoundation/videos/1554594181298482/\"\n  }, \"https://www.facebook.com/nipsfoundation/videos/1554594181298482/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"mirror: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.bilibili.com/video/av17078186/\"\n  }, \"https://www.bilibili.com/video/av17078186/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.dropbox.com/s/4fhczb9cxkuqalf/2017_11_xx_BARS-Abbeel.pdf?dl=0\"\n  }, \"https://www.dropbox.com/s/4fhczb9cxkuqalf/2017_11_xx_BARS-Abbeel.pdf?dl=0\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DroNet: Learning to Fly by Driving\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://rpg.ifi.uzh.ch/dronet.html\"\n  }, \"http://rpg.ifi.uzh.ch/dronet.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://rpg.ifi.uzh.ch/docs/RAL18_Loquercio.pdf\"\n  }, \"http://rpg.ifi.uzh.ch/docs/RAL18_Loquercio.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/uzh-rpg/rpg_public_dronet\"\n  }, \"https://github.com/uzh-rpg/rpg_public_dronet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Survey on Deep Learning Methods for Robot Vision\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.10862\"\n  }, \"https://arxiv.org/abs/1803.10862\")), mdx(\"h1\", {\n    \"id\": \"deep-learning-on-mobile--embedded-devices\"\n  }, \"Deep Learning on Mobile / Embedded Devices\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Convolutional neural networks on the iPhone with VGGNet\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://matthijshollemans.com/2016/08/30/vggnet-convolutional-neural-network-iphone/\"\n  }, \"http://matthijshollemans.com/2016/08/30/vggnet-convolutional-neural-network-iphone/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hollance/VGGNet-Metal\"\n  }, \"https://github.com/hollance/VGGNet-Metal\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TensorFlow for Mobile Poets\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://petewarden.com/2016/09/27/tensorflow-for-mobile-poets/\"\n  }, \"https://petewarden.com/2016/09/27/tensorflow-for-mobile-poets/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Convolutional Neural Network(CNN) for Android\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CnnForAndroid:A Classification Project using Convolutional Neural Network(CNN) in Android platform\\u3002It also support Caffe Model\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zhangqianhui/CnnForAndroid\"\n  }, \"https://github.com/zhangqianhui/CnnForAndroid\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TensorFlow on Android\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.oreilly.com/learning/tensorflow-on-android\"\n  }, \"https://www.oreilly.com/learning/tensorflow-on-android\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Experimenting with TensorFlow on Android\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"part 1: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/@mgazar/experimenting-with-tensorflow-on-android-pt-1-362683b31838#.5gbp2d4st\"\n  }, \"https://medium.com/@mgazar/experimenting-with-tensorflow-on-android-pt-1-362683b31838#.5gbp2d4st\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"part 2: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/@mgazar/experimenting-with-tensorflow-on-android-part-2-12f3dc294eaf#.2gx3o65f5\"\n  }, \"https://medium.com/@mgazar/experimenting-with-tensorflow-on-android-part-2-12f3dc294eaf#.2gx3o65f5\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MostafaGazar/tensorflow\"\n  }, \"https://github.com/MostafaGazar/tensorflow\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"XNOR.ai frees AI from the prison of the supercomputer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://techcrunch.com/2017/01/19/xnor-ai-frees-ai-from-the-prison-of-the-supercomputer/\"\n  }, \"https://techcrunch.com/2017/01/19/xnor-ai-frees-ai-from-the-prison-of-the-supercomputer/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Embedded and mobile deep learning research resources\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/csarron/emdl\"\n  }, \"https://github.com/csarron/emdl\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Modeling the Resource Requirements of Convolutional Neural Networks on Mobile Devices\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.09118\"\n  }, \"https://arxiv.org/abs/1709.09118\")), mdx(\"h1\", {\n    \"id\": \"benchmarks\"\n  }, \"Benchmarks\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning\\u2019s Accuracy\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://deeplearning4j.org/accuracy.html\"\n  }, \"http://deeplearning4j.org/accuracy.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Benchmarks for popular CNN models\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Benchmarks for popular convolutional neural network models on CPU and different GPUs, with and without cuDNN.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jcjohnson/cnn-benchmarks\"\n  }, \"https://github.com/jcjohnson/cnn-benchmarks\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning Benchmarks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://add-for.com/deep-learning-benchmarks/\"\n  }, \"http://add-for.com/deep-learning-benchmarks/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"cudnn-rnn-benchmarks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MaximumEntropy/cudnn_rnn_theano_benchmarks\"\n  }, \"https://github.com/MaximumEntropy/cudnn_rnn_theano_benchmarks\"))), mdx(\"h1\", {\n    \"id\": \"papers\"\n  }, \"Papers\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Reweighted Wake-Sleep\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1406.2751\"\n  }, \"http://arxiv.org/abs/1406.2751\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jbornschein/reweighted-ws\"\n  }, \"https://github.com/jbornschein/reweighted-ws\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Probabilistic Backpropagation for Scalable Learning of Bayesian Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1502.05336\"\n  }, \"http://arxiv.org/abs/1502.05336\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/HIPS/Probabilistic-Backpropagation\"\n  }, \"https://github.com/HIPS/Probabilistic-Backpropagation\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deeply-Supervised Nets\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1409.5185\"\n  }, \"http://arxiv.org/abs/1409.5185\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mbhenaff/spectral-lib\"\n  }, \"https://github.com/mbhenaff/spectral-lib\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Nature 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"author: Yann LeCun, Yoshua Bengio & Geoffrey Hinton\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf\"\n  }, \"http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"On the Expressive Power of Deep Learning: A Tensor Analysis\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1509.05009\"\n  }, \"http://arxiv.org/abs/1509.05009\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Understanding and Predicting Image Memorability at a Large Scale\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MIT. ICCV 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://memorability.csail.mit.edu/\"\n  }, \"http://memorability.csail.mit.edu/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://people.csail.mit.edu/khosla/papers/iccv2015_khosla.pdf\"\n  }, \"https://people.csail.mit.edu/khosla/papers/iccv2015_khosla.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://memorability.csail.mit.edu/download.html\"\n  }, \"http://memorability.csail.mit.edu/download.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"reviews: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://petapixel.com/2015/12/18/how-memorable-are-times-top-10-photos-of-2015-to-a-computer/\"\n  }, \"http://petapixel.com/2015/12/18/how-memorable-are-times-top-10-photos-of-2015-to-a-computer/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards Open Set Deep Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1511.06233\"\n  }, \"http://arxiv.org/abs/1511.06233\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/abhijitbendale/OSDN\"\n  }, \"https://github.com/abhijitbendale/OSDN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Structured Prediction Energy Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICML 2016. SPEN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1511.06350\"\n  }, \"http://arxiv.org/abs/1511.06350\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/davidBelanger/SPEN\"\n  }, \"https://github.com/davidBelanger/SPEN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Neural Networks predict Hierarchical Spatio-temporal Cortical Dynamics of Human Visual Object Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1601.02970\"\n  }, \"http://arxiv.org/abs/1601.02970\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://brainmodels.csail.mit.edu/dnn/drawCNN/\"\n  }, \"http://brainmodels.csail.mit.edu/dnn/drawCNN/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Recent Advances in Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1512.07108\"\n  }, \"http://arxiv.org/abs/1512.07108\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Understanding Deep Convolutional Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1601.04920\"\n  }, \"http://arxiv.org/abs/1601.04920\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepCare: A Deep Dynamic Memory Model for Predictive Medicine\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1602.00357\"\n  }, \"http://arxiv.org/abs/1602.00357\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Exploiting Cyclic Symmetry in Convolutional Neural Networks\")), mdx(\"img\", {\n    \"src\": \"http://benanne.github.io/images/cyclicroll.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICML 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1602.02660\"\n  }, \"http://arxiv.org/abs/1602.02660\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Winning solution for the National Data Science Bowl competition on Kaggle (plankton classification)): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/benanne/kaggle-ndsb\"\n  }, \"https://github.com/benanne/kaggle-ndsb\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"ref(use Cyclic pooling): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://benanne.github.io/2015/03/17/plankton.html\"\n  }, \"http://benanne.github.io/2015/03/17/plankton.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cross-dimensional Weighting for Aggregated Deep Convolutional Features\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1512.04065\"\n  }, \"http://arxiv.org/abs/1512.04065\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yahoo/crow\"\n  }, \"https://github.com/yahoo/crow\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Understanding Visual Concepts with Continuation Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://willwhitney.github.io/understanding-visual-concepts/\"\n  }, \"http://willwhitney.github.io/understanding-visual-concepts/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1602.06822\"\n  }, \"http://arxiv.org/abs/1602.06822\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/willwhitney/understanding-visual-concepts\"\n  }, \"https://github.com/willwhitney/understanding-visual-concepts\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Efficient Algorithms with Hierarchical Attentive Memory\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1602.03218\"\n  }, \"http://arxiv.org/abs/1602.03218\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Smerity/tf-ham\"\n  }, \"https://github.com/Smerity/tf-ham\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DrMAD: Distilling Reverse-Mode Automatic Differentiation for Optimizing Hyperparameters of Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1601.00917\"\n  }, \"http://arxiv.org/abs/1601.00917\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bigaidream-projects/drmad\"\n  }, \"https://github.com/bigaidream-projects/drmad\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Do Deep Convolutional Nets Really Need to be Deep (Or Even Convolutional)?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.05691\"\n  }, \"http://arxiv.org/abs/1603.05691\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"review: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.erogol.com/paper-review-deep-convolutional-nets-really-need-deep-even-convolutional/\"\n  }, \"http://www.erogol.com/paper-review-deep-convolutional-nets-really-need-deep-even-convolutional/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Harnessing Deep Neural Networks with Logic Rules\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.06318\"\n  }, \"http://arxiv.org/abs/1603.06318\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Degrees of Freedom in Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.09260\"\n  }, \"http://arxiv.org/abs/1603.09260\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Networks with Stochastic Depth\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.09382\"\n  }, \"http://arxiv.org/abs/1603.09382\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yueatsprograms/Stochastic_Depth\"\n  }, \"https://github.com/yueatsprograms/Stochastic_Depth\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes(\\\"Stochastic Depth Networks will Become the New Normal\\\"): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://deliprao.com/archives/134\"\n  }, \"http://deliprao.com/archives/134\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/dblN/stochastic_depth_keras\"\n  }, \"https://github.com/dblN/stochastic_depth_keras\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yasunorikudo/chainer-ResDrop\"\n  }, \"https://github.com/yasunorikudo/chainer-ResDrop\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"review: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/@tim_nth/review-deep-networks-with-stochastic-depth-51bd53acfe72\"\n  }, \"https://medium.com/@tim_nth/review-deep-networks-with-stochastic-depth-51bd53acfe72\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"LIFT: Learned Invariant Feature Transform\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.09114\"\n  }, \"http://arxiv.org/abs/1603.09114\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/cvlab-epfl/LIFT\"\n  }, \"https://github.com/cvlab-epfl/LIFT\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bridging the Gaps Between Residual Learning, Recurrent Neural Networks and Visual Cortex\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1604.03640\"\n  }, \"https://arxiv.org/abs/1604.03640\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://prlab.tudelft.nl/sites/default/files/rnnResnetCortex.pdf\"\n  }, \"http://prlab.tudelft.nl/sites/default/files/rnnResnetCortex.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Understanding How Image Quality Affects Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1604.04004\"\n  }, \"http://arxiv.org/abs/1604.04004\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"reddit: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.reddit.com/r/MachineLearning/comments/4exk3u/dcnns_are_more_sensitive_to_blur_and_noise_than/\"\n  }, \"https://www.reddit.com/r/MachineLearning/comments/4exk3u/dcnns_are_more_sensitive_to_blur_and_noise_than/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Embedding for Spatial Role Labeling\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.08474\"\n  }, \"http://arxiv.org/abs/1603.08474\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/oswaldoludwig/visually-informed-embedding-of-word-VIEW-\"\n  }, \"https://github.com/oswaldoludwig/visually-informed-embedding-of-word-VIEW-\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unreasonable Effectiveness of Learning Neural Nets: Accessible States and Robust Ensembles\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.06444\"\n  }, \"http://arxiv.org/abs/1605.06444\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Deep Representation for Imbalanced Classification\")), mdx(\"img\", {\n    \"src\": \"http://mmlab.ie.cuhk.edu.hk/projects/LMLE/method.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Deep Learning Large Margin Local Embedding (LMLE)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mmlab.ie.cuhk.edu.hk/projects/LMLE.html\"\n  }, \"http://mmlab.ie.cuhk.edu.hk/projects/LMLE.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://personal.ie.cuhk.edu.hk/~ccloy/files/cvpr_2016_imbalanced.pdf\"\n  }, \"http://personal.ie.cuhk.edu.hk/~ccloy/files/cvpr_2016_imbalanced.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mmlab.ie.cuhk.edu.hk/projects/LMLE/lmle_code.zip\"\n  }, \"http://mmlab.ie.cuhk.edu.hk/projects/LMLE/lmle_code.zip\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Newtonian Image Understanding: Unfolding the Dynamics of Objects in Static Images\")), mdx(\"img\", {\n    \"src\": \"http://allenai.org/images/projects/plato_newton.png?cb=1466683222538\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://allenai.org/plato/newtonian-understanding/\"\n  }, \"http://allenai.org/plato/newtonian-understanding/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1511.04048\"\n  }, \"http://arxiv.org/abs/1511.04048\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/roozbehm/newtonian\"\n  }, \"https://github.com/roozbehm/newtonian\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepMath - Deep Sequence Models for Premise Selection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1606.04442\"\n  }, \"https://arxiv.org/abs/1606.04442\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tensorflow/deepmath\"\n  }, \"https://github.com/tensorflow/deepmath\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Convolutional Neural Networks Analyzed via Convolutional Sparse Coding\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1607.08194\"\n  }, \"http://arxiv.org/abs/1607.08194\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Systematic evaluation of CNN advances on the ImageNet\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1606.02228\"\n  }, \"http://arxiv.org/abs/1606.02228\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ducha-aiki/caffenet-benchmark\"\n  }, \"https://github.com/ducha-aiki/caffenet-benchmark\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Why does deep and cheap learning work so well?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Harvard and MIT\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.08225\"\n  }, \"http://arxiv.org/abs/1608.08225\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"review: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.technologyreview.com/s/602344/the-extraordinary-link-between-deep-neural-networks-and-the-nature-of-the-universe/\"\n  }, \"https://www.technologyreview.com/s/602344/the-extraordinary-link-between-deep-neural-networks-and-the-nature-of-the-universe/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A scalable convolutional neural network for task-specified scenarios via knowledge distillation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.05695\"\n  }, \"http://arxiv.org/abs/1609.05695\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Alternating Back-Propagation for Generator Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page(code+data): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.stat.ucla.edu/~ywu/ABP/main.html\"\n  }, \"http://www.stat.ucla.edu/~ywu/ABP/main.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.stat.ucla.edu/~ywu/ABP/doc/arXivABP.pdf\"\n  }, \"http://www.stat.ucla.edu/~ywu/ABP/doc/arXivABP.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Novel Representation of Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.01549\"\n  }, \"https://arxiv.org/abs/1610.01549\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Optimization of Convolutional Neural Network using Microcanonical Annealing Algorithm\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IEEE ICACSIS 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.02306\"\n  }, \"https://arxiv.org/abs/1610.02306\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Uncertainty in Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: PhD Thesis. Cambridge Machine Learning Group\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mlg.eng.cam.ac.uk/yarin/blog_2248.html\"\n  }, \"http://mlg.eng.cam.ac.uk/yarin/blog_2248.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"thesis: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mlg.eng.cam.ac.uk/yarin/thesis/thesis.pdf\"\n  }, \"http://mlg.eng.cam.ac.uk/yarin/thesis/thesis.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Convolutional Neural Network Design Patterns\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.00847\"\n  }, \"https://arxiv.org/abs/1611.00847\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/iPhysicist/CNNDesignPatterns\"\n  }, \"https://github.com/iPhysicist/CNNDesignPatterns\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Extensions and Limitations of the Neural GPU\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.00736\"\n  }, \"https://arxiv.org/abs/1611.00736\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/openai/ecprice-neural-gpu\"\n  }, \"https://github.com/openai/ecprice-neural-gpu\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Neural Functional Programming\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.01988\"\n  }, \"https://arxiv.org/abs/1611.01988\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Information Propagation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.01232\"\n  }, \"https://arxiv.org/abs/1611.01232\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Compressed Learning: A Deep Neural Network Approach\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.09615\"\n  }, \"https://arxiv.org/abs/1610.09615\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A backward pass through a CNN using a generative model of its activations\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.02767\"\n  }, \"https://arxiv.org/abs/1611.02767\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Understanding deep learning requires rethinking generalization\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR 2017 best paper. MIT & Google Brain & UC Berkeley & Google DeepMind\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.03530\"\n  }, \"https://arxiv.org/abs/1611.03530\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"example code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/pluskid/fitting-random-labels\"\n  }, \"https://github.com/pluskid/fitting-random-labels\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://theneuralperspective.com/2017/01/24/understanding-deep-learning-requires-rethinking-generalization/\"\n  }, \"https://theneuralperspective.com/2017/01/24/understanding-deep-learning-requires-rethinking-generalization/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning the Number of Neurons in Deep Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.06321\"\n  }, \"https://arxiv.org/abs/1611.06321\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Survey of Expressivity in Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in Complex Systems\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Brain & Cornell University & Stanford University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.08083\"\n  }, \"https://arxiv.org/abs/1611.08083\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Designing Neural Network Architectures using Reinforcement Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MIT\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://bowenbaker.github.io/metaqnn/\"\n  }, \"https://bowenbaker.github.io/metaqnn/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.02167\"\n  }, \"https://arxiv.org/abs/1611.02167\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards Robust Deep Neural Networks with BANG\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Colorado\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.00138\"\n  }, \"https://arxiv.org/abs/1612.00138\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Quantization: Encoding Convolutional Activations with Deep Generative Model\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Science and Technology of China & MSR\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.09502\"\n  }, \"https://arxiv.org/abs/1611.09502\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Probabilistic Theory of Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1504.00641\"\n  }, \"https://arxiv.org/abs/1504.00641\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Probabilistic Framework for Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Rice University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.01936\"\n  }, \"https://arxiv.org/abs/1612.01936\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.03928\"\n  }, \"https://arxiv.org/abs/1612.03928\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(PyTorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/szagoruyko/attention-transfer\"\n  }, \"https://github.com/szagoruyko/attention-transfer\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Risk versus Uncertainty in Deep Learning: Bayes, Bootstrap and the Dangers of Dropout\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Deepmind\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://bayesiandeeplearning.org/papers/BDL_4.pdf\"\n  }, \"http://bayesiandeeplearning.org/papers/BDL_4.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Brain & Jagiellonian University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Sparsely-Gated Mixture-of-Experts layer (MoE), language modeling and machine translation\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.06538\"\n  }, \"https://arxiv.org/abs/1701.06538\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"reddit: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.reddit.com/r/MachineLearning/comments/5pud72/research_outrageously_large_neural_networks_the/\"\n  }, \"https://www.reddit.com/r/MachineLearning/comments/5pud72/research_outrageously_large_neural_networks_the/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Network Guided Proof Search\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Research & University of Innsbruck\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.06972\"\n  }, \"https://arxiv.org/abs/1701.06972\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PathNet: Evolution Channels Gradient Descent in Super Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google DeepMind & Google Brain\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.08734\"\n  }, \"https://arxiv.org/abs/1701.08734\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/intuitionmachine/pathnet-a-modular-deep-learning-architecture-for-agi-5302fcf53273#.8f0o6w3en\"\n  }, \"https://medium.com/intuitionmachine/pathnet-a-modular-deep-learning-architecture-for-agi-5302fcf53273#.8f0o6w3en\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.01135\"\n  }, \"https://arxiv.org/abs/1702.01135\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Power of Sparsity in Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.06257\"\n  }, \"https://arxiv.org/abs/1702.06257\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning across scales - A multiscale method for Convolution Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.02009\"\n  }, \"https://arxiv.org/abs/1703.02009\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Stacking-based Deep Neural Network: Deep Analytic Network on Convolutional Spectral Histogram Features\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.01396\"\n  }, \"https://arxiv.org/abs/1703.01396\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Compositional Object-Based Approach to Learning Physical Dynamics\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR 2017. Neural Physics Engine\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://openreview.net/pdf?id=Bkab5dqxe\"\n  }, \"https://openreview.net/pdf?id=Bkab5dqxe\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mbchang/dynamics\"\n  }, \"https://github.com/mbchang/dynamics\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Genetic CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.01513\"\n  }, \"https://arxiv.org/abs/1703.01513\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Tensorflow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aqibsaeed/Genetic-CNN\"\n  }, \"https://github.com/aqibsaeed/Genetic-CNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Sets\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Amazon Web Services & CMU\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: statistic estimation, point cloud classification, set expansion, and image tagging\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.06114\"\n  }, \"https://arxiv.org/abs/1703.06114\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multiscale Hierarchical Convolutional Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.04140\"\n  }, \"https://arxiv.org/abs/1703.04140\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jhjacobsen/HierarchicalCNN\"\n  }, \"https://github.com/jhjacobsen/HierarchicalCNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Neural Networks Do Not Recognize Negative Images\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1703.06857\"\n  }, \"https://arxiv.org/abs/1703.06857\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Failures of Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.07950\"\n  }, \"https://arxiv.org/abs/1703.07950\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/shakedshammah/failures_of_DL\"\n  }, \"https://github.com/shakedshammah/failures_of_DL\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Scale Dense Convolutional Networks for Efficient Prediction\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Cornell University & Tsinghua University & Fudan University & Facebook AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.09844\"\n  }, \"https://arxiv.org/abs/1703.09844\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/gaohuang/MSDNet\"\n  }, \"https://github.com/gaohuang/MSDNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scaling the Scattering Transform: Deep Hybrid Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.08961\"\n  }, \"https://arxiv.org/abs/1703.08961\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/edouardoyallon/scalingscattering\"\n  }, \"https://github.com/edouardoyallon/scalingscattering\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(CuPy/PyTorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/edouardoyallon/pyscatwave\"\n  }, \"https://github.com/edouardoyallon/pyscatwave\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning is Robust to Massive Label Noise\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1705.10694\"\n  }, \"https://arxiv.org/abs/1705.10694\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Input Fast-Forwarding for Better Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICIAR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Fast-Forward Network (FFNet)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1705.08479\"\n  }, \"https://arxiv.org/abs/1705.08479\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Mutual Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: deep mutual learning (DML)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.00384\"\n  }, \"https://arxiv.org/abs/1706.00384\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, TensorFlow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/YingZhangDUT/Deep-Mutual-Learning\"\n  }, \"https://github.com/YingZhangDUT/Deep-Mutual-Learning\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Automated Problem Identification: Regression vs Classification via Evolutionary Deep Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Cape Town\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.00703\"\n  }, \"https://arxiv.org/abs/1707.00703\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Revisiting Unreasonable Effectiveness of Data in Deep Learning Era\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Research & CMU\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.02968\"\n  }, \"https://arxiv.org/abs/1707.02968\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://research.googleblog.com/2017/07/revisiting-unreasonable-effectiveness.html\"\n  }, \"https://research.googleblog.com/2017/07/revisiting-unreasonable-effectiveness.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Layer Aggregation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: UC Berkeley\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.06484\"\n  }, \"https://arxiv.org/abs/1707.06484\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improving Robustness of Feature Representations to Image Deformations using Powered Convolution in CNNs\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1707.07830\"\n  }, \"https://arxiv.org/abs/1707.07830\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning uncertainty in regression tasks by deep neural networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Free University of Berlin\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.07287\"\n  }, \"https://arxiv.org/abs/1707.07287\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generalizing the Convolution Operator in Convolutional Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1707.09864\"\n  }, \"https://arxiv.org/abs/1707.09864\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Convolution with Logarithmic Filter Groups for Efficient Shallow CNN\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1707.09855\"\n  }, \"https://arxiv.org/abs/1707.09855\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Multi-View Learning with Stochastic Decorrelation Loss\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1707.09669\"\n  }, \"https://arxiv.org/abs/1707.09669\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Take it in your stride: Do we need striding in CNNs?\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.02502\"\n  }, \"https://arxiv.org/abs/1712.02502\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Security Risks in Deep Learning Implementation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Qihoo 360 Security Research Lab & University of Georgia & University of Virginia\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.11008\"\n  }, \"https://arxiv.org/abs/1711.11008\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Online Learning with Gated Linear Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: DeepMind\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.01897\"\n  }, \"https://arxiv.org/abs/1712.01897\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"On the Information Bottleneck Theory of Deep Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://openreview.net/forum?id=ry_WPG-A-&noteId=ry_WPG-A\"\n  }, \"https://openreview.net/forum?id=ry_WPG-A-\", \"\\xAC\", \"eId=ry_WPG-A\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Unreasonable Effectiveness of Deep Features as a Perceptual Metric\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://richzhang.github.io/PerceptualSimilarity/\"\n  }, \"https://richzhang.github.io/PerceptualSimilarity/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.03924\"\n  }, \"https://arxiv.org/abs/1801.03924\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com//richzhang/PerceptualSimilarity\"\n  }, \"https://github.com//richzhang/PerceptualSimilarity\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Less is More: Culling the Training Set to Improve Robustness of Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of California, Davis\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.02850\"\n  }, \"https://arxiv.org/abs/1801.02850\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards an Understanding of Neural Networks in Natural-Image Spaces\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1801.09097\"\n  }, \"https://arxiv.org/abs/1801.09097\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Private-Feature Extraction\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1802.03151\"\n  }, \"https://arxiv.org/abs/1802.03151\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Not All Samples Are Created Equal: Deep Learning with Importance Sampling\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Idiap Research Institute\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.00942\"\n  }, \"https://arxiv.org/abs/1803.00942\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Label Refinery: Improving ImageNet Classification through Label Progression\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Using a Label Refinery improves the state-of-the-art top-1 accuracy of (1) AlexNet from 59.3 to 67.2,\\n(2) MobileNet from 70.6 to 73.39, (3) MobileNet-0.25 from 50.6 to 55.59,\\n(4) VGG19 from 72.7 to 75.46, and (5) Darknet19 from 72.9 to 74.47.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: XNOR AI, University of Washington, Allen AI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.02641\"\n  }, \"https://arxiv.org/abs/1805.02641\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hessamb/label-refinery\"\n  }, \"https://github.com/hessamb/label-refinery\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"How Many Samples are Needed to Learn a Convolutional Neural Network?\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.07883\"\n  }, \"https://arxiv.org/abs/1805.07883\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"VisualBackProp for learning using privileged information with CNNs\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.09474\"\n  }, \"https://arxiv.org/abs/1805.09474\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BAM: Bottleneck Attention Module\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2018 (oral). Lunit Inc. & Adobe Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.06514\"\n  }, \"https://arxiv.org/abs/1807.06514\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CBAM: Convolutional Block Attention Module\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018. Lunit Inc. & Adobe Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.06521\"\n  }, \"https://arxiv.org/abs/1807.06521\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scale equivariance in CNNs with vector fields\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICML/FAIM 2018 workshop on Towards learning with limited labels: Equivariance, Invariance, and Beyond (oral presentation)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.11783\"\n  }, \"https://arxiv.org/abs/1807.11783\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Downsampling leads to Image Memorization in Convolutional Autoencoders\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1810.10333\"\n  }, \"https://arxiv.org/abs/1810.10333\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Do Normalization Layers in a Deep ConvNet Really Need to Be Distinct?\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.07727\"\n  }, \"https://arxiv.org/abs/1811.07727\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Are All Training Examples Created Equal? An Empirical Study\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.12569\"\n  }, \"https://arxiv.org/abs/1811.12569\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.12231\"\n  }, \"https://arxiv.org/abs/1811.12231\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepFashion2: A Versatile Benchmark for Detection, Pose Estimation, Segmentation and Re-Identification of Clothing Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The Chinese University of Hong Kong & SenseTime Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Match R-CNN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.07973\"\n  }, \"https://arxiv.org/abs/1901.07973\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Comprehensive Overhaul of Feature Distillation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1904.01866\"\n  }, \"https://arxiv.org/abs/1904.01866\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mesh R-CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Facebook AI Research (FAIR)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1906.02739\"\n  }, \"https://arxiv.org/abs/1906.02739\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ViP: Virtual Pooling for Accelerating CNN-based Image Classification and Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1906.07912\"\n  }, \"https://arxiv.org/abs/1906.07912\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"VarGNet: Variable Group Convolutional Neural Network for Efficient Embedded Computing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Horizon Robotics\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.05653\"\n  }, \"https://arxiv.org/abs/1907.05653\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Anchor Loss: Modulating Loss Scale based on Prediction Difficulty\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.11155\"\n  }, \"https://arxiv.org/abs/1909.11155\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Why ReLU networks yield high-confidence predictions far away from the training data and how to mitigate the problem\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1812.05720\"\n  }, \"https://arxiv.org/abs/1812.05720\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/max-andr/relu_networks_overconfident\"\n  }, \"https://github.com/max-andr/relu_networks_overconfident\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Feature Space Augmentation for Long-Tailed Data\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2008.03673\"\n  }, \"https://arxiv.org/abs/2008.03673\"))), mdx(\"h2\", {\n    \"id\": \"tutorials-and-surveys\"\n  }, \"Tutorials and Surveys\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Survey: Time Travel in Deep Learning Space: An Introduction to Deep Learning Models and How Deep Learning Models Evolved from the Initial Ideas\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1510.04781\"\n  }, \"http://arxiv.org/abs/1510.04781\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"On the Origin of Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CMU. 70 pages, 200 references\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.07800\"\n  }, \"https://arxiv.org/abs/1702.07800\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Efficient Processing of Deep Neural Networks: A Tutorial and Survey\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MIT\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.09039\"\n  }, \"https://arxiv.org/abs/1703.09039\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The History Began from AlexNet: A Comprehensive Survey on Deep Learning Approaches\")), mdx(\"p\", null, \"{\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.01164%7D(https://arxiv.org/abs/1803.01164)\"\n  }, \"https://arxiv.org/abs/1803.01164}(https://arxiv.org/abs/1803.01164)\")), mdx(\"h2\", {\n    \"id\": \"mathematics-of-deep-learning\"\n  }, \"Mathematics of Deep Learning\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Mathematical Theory of Deep Convolutional Neural Networks for Feature Extraction\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1512.06293\"\n  }, \"http://arxiv.org/abs/1512.06293\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mathematics of Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Johns Hopkins University & New York University & Tel-Aviv University & University of California, Los Angeles\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.04741\"\n  }, \"https://arxiv.org/abs/1712.04741\"))), mdx(\"h2\", {\n    \"id\": \"local-minima\"\n  }, \"Local Minima\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Local minima in training of deep networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: DeepMind\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.06310\"\n  }, \"https://arxiv.org/abs/1611.06310\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep linear neural networks with arbitrary loss: All local minima are global\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CMU & University of Southern California & Facebook Artificial Intelligence Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.00779\"\n  }, \"https://arxiv.org/abs/1712.00779\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Gradient Descent Learns One-hidden-layer CNN: Don't be Afraid of Spurious Local Minima\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Loyola Marymount University & California State University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.01473\"\n  }, \"https://arxiv.org/abs/1712.01473\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CNNs are Globally Optimal Given Multi-Layer Support\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CMU\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.02501\"\n  }, \"https://arxiv.org/abs/1712.02501\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spurious Local Minima are Common in Two-Layer ReLU Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.08968\"\n  }, \"https://arxiv.org/abs/1712.08968\")), mdx(\"h2\", {\n    \"id\": \"dive-into-cnn\"\n  }, \"Dive Into CNN\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Structured Receptive Fields in CNNs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1605.02971\"\n  }, \"https://arxiv.org/abs/1605.02971\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jhjacobsen/RFNN\"\n  }, \"https://github.com/jhjacobsen/RFNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"How ConvNets model Non-linear Transformations\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.07664\"\n  }, \"https://arxiv.org/abs/1702.07664\"))), mdx(\"h2\", {\n    \"id\": \"separable-convolutions--grouped-convolutions\"\n  }, \"Separable Convolutions / Grouped Convolutions\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Factorized Convolutional Neural Networks\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Design of Efficient Convolutional Layers using Single Intra-channel Convolution, Topological Subdivisioning and Spatial \\\"Bottleneck\\\" Structure\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.04337\"\n  }, \"http://arxiv.org/abs/1608.04337\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"XSepConv: Extremely Separated Convolution\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tsinghua University & University College London\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2002.12046\"\n  }, \"https://arxiv.org/abs/2002.12046\"))), mdx(\"h2\", {\n    \"id\": \"stdp\"\n  }, \"STDP\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A biological gradient descent for prediction through a combination of STDP and homeostatic plasticity\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1206.4812\"\n  }, \"http://arxiv.org/abs/1206.4812\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An objective function for STDP\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1509.05936\"\n  }, \"http://arxiv.org/abs/1509.05936\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards a Biologically Plausible Backprop\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1602.05179\"\n  }, \"http://arxiv.org/abs/1602.05179\"))), mdx(\"h2\", {\n    \"id\": \"target-propagation\"\n  }, \"Target Propagation\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"How Auto-Encoders Could Provide Credit Assignment in Deep Networks via Target Propagation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1407.7906\"\n  }, \"http://arxiv.org/abs/1407.7906\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Difference Target Propagation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1412.7525\"\n  }, \"http://arxiv.org/abs/1412.7525\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/donghyunlee/dtp\"\n  }, \"https://github.com/donghyunlee/dtp\"))), mdx(\"h2\", {\n    \"id\": \"zero-shot-learning\"\n  }, \"Zero Shot Learning\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning a Deep Embedding Model for Zero-Shot Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.05088\"\n  }, \"https://arxiv.org/abs/1611.05088\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Zero-Shot (Deep) Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://amundtveit.com/2016/11/18/zero-shot-deep-learning/\"\n  }, \"https://amundtveit.com/2016/11/18/zero-shot-deep-learning/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Zero-shot learning experiments by deep learning.\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/Elyorcv/zsl-deep-learning\"\n  }, \"https://github.com/Elyorcv/zsl-deep-learning\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Zero-Shot Learning - The Good, the Bad and the Ugly\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.04394\"\n  }, \"https://arxiv.org/abs/1703.04394\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Autoencoder for Zero-Shot Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://elyorcv.github.io/projects/sae\"\n  }, \"https://elyorcv.github.io/projects/sae\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.08345\"\n  }, \"https://arxiv.org/abs/1704.08345\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Elyorcv/SAE\"\n  }, \"https://github.com/Elyorcv/SAE\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Zero-Shot Learning via Category-Specific Visual-Semantic Mapping\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.06167\"\n  }, \"https://arxiv.org/abs/1711.06167\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Zero-Shot Learning via Class-Conditioned Deep Generative Models\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.05820\"\n  }, \"https://arxiv.org/abs/1711.05820\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Feature Generating Networks for Zero-Shot Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.00981\"\n  }, \"https://arxiv.org/abs/1712.00981\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Zero-Shot Visual Recognition using Semantics-Preserving Adversarial Embedding Network\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.01928\"\n  }, \"https://arxiv.org/abs/1712.01928\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Combining Deep Universal Features, Semantic Attributes, and Hierarchical Classification for Zero-Shot Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: extension to work published in conference proceedings of 2017 IAPR MVA Conference\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.03151\"\n  }, \"https://arxiv.org/abs/1712.03151\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Context Label Embedding\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Multi-Context Label Embedding (MCLE) \"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.01199\"\n  }, \"https://arxiv.org/abs/1805.01199\"))), mdx(\"h2\", {\n    \"id\": \"incremental-learning\"\n  }, \"Incremental Learning\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"iCaRL: Incremental Classifier and Representation Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.07725\"\n  }, \"https://arxiv.org/abs/1611.07725\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FearNet: Brain-Inspired Model for Incremental Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.10563\"\n  }, \"https://arxiv.org/abs/1711.10563\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Incremental Learning in Deep Convolutional Neural Networks Using Partial Network Sharing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Purdue University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.02719\"\n  }, \"https://arxiv.org/abs/1712.02719\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Incremental Classifier Learning with Generative Adversarial Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1802.00853\"\n  }, \"https://arxiv.org/abs/1802.00853\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learn the new, keep the old: Extending pretrained models with new anatomy and images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MICCAI 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1806.00265\"\n  }, \"https://arxiv.org/abs/1806.00265\"))), mdx(\"h2\", {\n    \"id\": \"ensemble-deep-learning\"\n  }, \"Ensemble Deep Learning\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Convolutional Neural Fabrics\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1606.02492\"\n  }, \"http://arxiv.org/abs/1606.02492\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/shreyassaxena/convolutional-neural-fabrics\"\n  }, \"https://github.com/shreyassaxena/convolutional-neural-fabrics\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Stochastic Multiple Choice Learning for Training Diverse Deep Ensembles\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1606.07839\"\n  }, \"https://arxiv.org/abs/1606.07839\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"youtube: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=KjUfMtZjyfg&feature=youtu.be\"\n  }, \"https://www.youtube.com/watch?v=KjUfMtZjyfg&feature=youtu.be\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Snapshot Ensembles: Train 1, Get M for Free\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openreview.net/pdf?id=BJYwwY9ll\"\n  }, \"http://openreview.net/pdf?id=BJYwwY9ll\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Torch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/gaohuang/SnapshotEnsemble\"\n  }, \"https://github.com/gaohuang/SnapshotEnsemble\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/titu1994/Snapshot-Ensembles\"\n  }, \"https://github.com/titu1994/Snapshot-Ensembles\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Ensemble Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://amundtveit.com/2016/12/02/ensemble-deep-learning/\"\n  }, \"https://amundtveit.com/2016/12/02/ensemble-deep-learning/\"))), mdx(\"h2\", {\n    \"id\": \"domain-adaptation\"\n  }, \"Domain Adaptation\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Adversarial Discriminative Domain Adaptation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: UC Berkeley & Stanford University & Boston University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.05464\"\n  }, \"https://arxiv.org/abs/1702.05464\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com//corenel/pytorch-adda\"\n  }, \"https://github.com//corenel/pytorch-adda\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Parameter Reference Loss for Unsupervised Domain Adaptation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.07170\"\n  }, \"https://arxiv.org/abs/1711.07170\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Residual Parameter Transfer for Deep Domain Adaptation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.07714\"\n  }, \"https://arxiv.org/abs/1711.07714\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Adversarial Feature Augmentation for Unsupervised Domain Adaptation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.08561\"\n  }, \"https://arxiv.org/abs/1711.08561\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Image to Image Translation for Domain Adaptation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.00479\"\n  }, \"https://arxiv.org/abs/1712.00479\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Incremental Adversarial Domain Adaptation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.07436\"\n  }, \"https://arxiv.org/abs/1712.07436\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Visual Domain Adaptation: A Survey\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1802.03601\"\n  }, \"https://arxiv.org/abs/1802.03601\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unsupervised Domain Adaptation: A Multi-task Learning-based Method\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.09208\"\n  }, \"https://arxiv.org/abs/1803.09208\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Importance Weighted Adversarial Nets for Partial Domain Adaptation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.09210\"\n  }, \"https://arxiv.org/abs/1803.09210\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Open Set Domain Adaptation by Backpropagation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1804.10427\"\n  }, \"https://arxiv.org/abs/1804.10427\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Sampling Policies for Domain Adaptation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CMU\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.07641\"\n  }, \"https://arxiv.org/abs/1805.07641\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Adversarial Domain Adaptation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2018 Oral.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1809.02176\"\n  }, \"https://arxiv.org/abs/1809.02176\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unsupervised Domain Adaptation: An Adaptive Feature Norm Approach\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Sun Yat-sen University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.07456\"\n  }, \"https://arxiv.org/abs/1811.07456\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jihanyang/AFN/\"\n  }, \"https://github.com/jihanyang/AFN/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-source Distilling Domain Adaptation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1911.11554\"\n  }, \"https://arxiv.org/abs/1911.11554\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/daoyuan98/MDDA\"\n  }, \"https://github.com/daoyuan98/MDDA\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"awsome-domain-adaptation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/zhaoxin94/awsome-domain-adaptation\"\n  }, \"https://github.com/zhaoxin94/awsome-domain-adaptation\")), mdx(\"h2\", {\n    \"id\": \"embedding\"\n  }, \"Embedding\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Deep Embeddings with Histogram Loss\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.00822\"\n  }, \"https://arxiv.org/abs/1611.00822\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Full-Network Embedding in a Multimodal Embedding Pipeline\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1707.09872\"\n  }, \"https://arxiv.org/abs/1707.09872\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Clustering-driven Deep Embedding with Pairwise Constraints\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.08457\"\n  }, \"https://arxiv.org/abs/1803.08457\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Mixture of Experts via Shallow Embedding\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1806.01531\"\n  }, \"https://arxiv.org/abs/1806.01531\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning to Learn from Web Data through Deep Semantic Embeddings\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV MULA Workshop 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.06368\"\n  }, \"https://arxiv.org/abs/1808.06368\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Heated-Up Softmax Embedding\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1809.04157\"\n  }, \"https://arxiv.org/abs/1809.04157\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Virtual Class Enhanced Discriminative Embedding Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.12611\"\n  }, \"https://arxiv.org/abs/1811.12611\"))), mdx(\"h2\", {\n    \"id\": \"regression\"\n  }, \"Regression\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Comprehensive Analysis of Deep Regression\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.08450\"\n  }, \"https://arxiv.org/abs/1803.08450\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Neural Motifs: Scene Graph Parsing with Global Context\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018. University of Washington\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://rowanzellers.com/neuralmotifs/\"\n  }, \"http://rowanzellers.com/neuralmotifs/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.06640\"\n  }, \"https://arxiv.org/abs/1711.06640\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/rowanz/neural-motifs\"\n  }, \"https://github.com/rowanz/neural-motifs\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://rowanzellers.com/scenegraph2/\"\n  }, \"https://rowanzellers.com/scenegraph2/\"))), mdx(\"h2\", {\n    \"id\": \"capsnets\"\n  }, \"CapsNets\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dynamic Routing Between Capsules\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Sara Sabour, Nicholas Frosst, Geoffrey E Hinton\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Brain, Toronto\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1710.09829\"\n  }, \"https://arxiv.org/abs/1710.09829\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, Tensorflow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Sarasra/models/tree/master/research/capsules\"\n  }, \"https://github.com/Sarasra/models/tree/master/research/capsules\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Capsule Networks (CapsNets) \\u2013 Tutorial\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"youtube: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=pPN8d0E3900\"\n  }, \"https://www.youtube.com/watch?v=pPN8d0E3900\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"mirror: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.bilibili.com/video/av16594836/\"\n  }, \"http://www.bilibili.com/video/av16594836/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improved Explainability of Capsule Networks: Relevance Path by Agreement\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Concordia University & University of Toronto\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1802.10204\"\n  }, \"https://arxiv.org/abs/1802.10204\"))), mdx(\"h2\", {\n    \"id\": \"low-light\"\n  }, \"Low Light\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Exploring Image Enhancement for Salient Object Detection in Low Light Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM Transactions on Multimedia Computing, Communications, and Applications\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.16124\"\n  }, \"https://arxiv.org/abs/2007.16124\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"NOD: Taking a Closer Look at Detection under Extreme Low-Light Conditions with Night Object Detection Dataset\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2110.10364\"\n  }, \"https://arxiv.org/abs/2110.10364\"))), mdx(\"h2\", {\n    \"id\": \"computer-vision\"\n  }, \"Computer Vision\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Taxonomy of Deep Convolutional Neural Nets for Computer Vision\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1601.06615\"\n  }, \"http://arxiv.org/abs/1601.06615\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"On the usability of deep networks for object-based image analysis\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: GEOBIA 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.06845\"\n  }, \"http://arxiv.org/abs/1609.06845\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Recursive Filters for Low-Level Vision via a Hybrid Neural Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.sifeiliu.net/linear-rnn\"\n  }, \"http://www.sifeiliu.net/linear-rnn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://faculty.ucmerced.edu/mhyang/papers/eccv16_rnn_filter.pdf\"\n  }, \"http://faculty.ucmerced.edu/mhyang/papers/eccv16_rnn_filter.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"poster: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.eccv2016.org/files/posters/O-3A-03.pdf\"\n  }, \"http://www.eccv2016.org/files/posters/O-3A-03.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Liusifei/caffe-lowlevel\"\n  }, \"https://github.com/Liusifei/caffe-lowlevel\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Toward Geometric Deep SLAM\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Magic Leap, Inc\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.07410\"\n  }, \"https://arxiv.org/abs/1707.07410\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Dual Convolutional Neural Networks for Low-Level Vision\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.05020\"\n  }, \"https://arxiv.org/abs/1805.05020\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Not just a matter of semantics: the relationship between visual similarity and semantic similarity\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.07120\"\n  }, \"https://arxiv.org/abs/1811.07120\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DF-SLAM: A Deep-Learning Enhanced Visual SLAM System based on Deep Local Features\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BUPT & Megvii\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.07223\"\n  }, \"https://arxiv.org/abs/1901.07223\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"GN-Net: The Gauss-Newton Loss for Deep Direct SLAM\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Technical University of Munich & Artisense\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.11932\"\n  }, \"https://arxiv.org/abs/1904.11932\"))), mdx(\"h3\", {\n    \"id\": \"all-in-one-network\"\n  }, \"All-In-One Network\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"HyperFace: A Deep Multi-task Learning Framework for Face Detection, Landmark Localization, Pose Estimation, and Gender Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1603.01249\"\n  }, \"https://arxiv.org/abs/1603.01249\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"summary: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aleju/papers/blob/master/neural-nets/HyperFace.md\"\n  }, \"https://github.com/aleju/papers/blob/master/neural-nets/HyperFace.md\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"UberNet: Training a `Universal' Convolutional Neural Network for Low-, Mid-, and High-Level Vision using Diverse Datasets and Limited Memory\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.02132\"\n  }, \"http://arxiv.org/abs/1609.02132\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cvn.ecp.fr/ubernet/\"\n  }, \"http://cvn.ecp.fr/ubernet/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An All-In-One Convolutional Neural Network for Face Analysis\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: simultaneous face detection, face alignment, pose estimation, gender recognition, smile detection, age estimation and face recognition \"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.00851\"\n  }, \"https://arxiv.org/abs/1611.00851\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MultiNet: Real-time Joint Semantic Reasoning for Autonomous Driving\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: first place on Kitti Road Segmentation.\\njoint classification, detection and semantic segmentation via a unified architecture, less than 100 ms to perform all tasks\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.07695\"\n  }, \"https://arxiv.org/abs/1612.07695\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MarvinTeichmann/MultiNet\"\n  }, \"https://github.com/MarvinTeichmann/MultiNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Adversarial Collaboration: Joint Unsupervised Learning of Depth, Camera Motion, Optical Flow and Motion Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.09806\"\n  }, \"https://arxiv.org/abs/1805.09806\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Visual Person Understanding through Multi-Task and Multi-Dataset Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: RWTH Aachen University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1906.03019\"\n  }, \"https://arxiv.org/abs/1906.03019\"))), mdx(\"h3\", {\n    \"id\": \"deep-learning-for-data-structures\"\n  }, \"Deep Learning for Data Structures\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Case for Learned Index Structures\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MIT & Google\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: B-Tree-Index, Hash-Index, BitMap-Index\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.01208\"\n  }, \"https://arxiv.org/abs/1712.01208\"))), mdx(\"h1\", {\n    \"id\": \"projects\"\n  }, \"Projects\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Top Deep Learning Projects\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aymericdamien/TopDeepLearning\"\n  }, \"https://github.com/aymericdamien/TopDeepLearning\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"deepnet: Implementation of some deep learning algorithms\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/nitishsrivastava/deepnet\"\n  }, \"https://github.com/nitishsrivastava/deepnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepNeuralClassifier(Julia): Deep neural network using rectified linear units to classify hand written digits from the MNIST dataset\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jostmey/DeepNeuralClassifier\"\n  }, \"https://github.com/jostmey/DeepNeuralClassifier\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Clarifai Node.js Demo\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/patcat/Clarifai-Node-Demo\"\n  }, \"https://github.com/patcat/Clarifai-Node-Demo\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog(\\\"How to Make Your Web App Smarter with Image Recognition\\\"): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.sitepoint.com/how-to-make-your-web-app-smarter-with-image-recognition/\"\n  }, \"http://www.sitepoint.com/how-to-make-your-web-app-smarter-with-image-recognition/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning in Rust\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog(\\\"baby steps\\\"): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/@tedsta/deep-learning-in-rust-7e228107cccc#.t0pskuwkm\"\n  }, \"https://medium.com/@tedsta/deep-learning-in-rust-7e228107cccc#.t0pskuwkm\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog(\\\"a walk in the park\\\"): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/@tedsta/deep-learning-in-rust-a-walk-in-the-park-fed6c87165ea#.pucj1l5yx\"\n  }, \"https://medium.com/@tedsta/deep-learning-in-rust-a-walk-in-the-park-fed6c87165ea#.pucj1l5yx\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tedsta/deeplearn-rs\"\n  }, \"https://github.com/tedsta/deeplearn-rs\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Implementation of state-of-art models in Torch\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aciditeam/torch-models\"\n  }, \"https://github.com/aciditeam/torch-models\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning (Python, C, C++, Java, Scala, Go)\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yusugomori/DeepLearning\"\n  }, \"https://github.com/yusugomori/DeepLearning\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"deepmark: THE Deep Learning Benchmarks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/DeepMark/deepmark\"\n  }, \"https://github.com/DeepMark/deepmark\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Siamese Net\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: \\\"This package shows how to train a siamese network using Lasagne and Theano and includes network definitions\\nfor state-of-the-art networks including: DeepID, DeepID2, Chopra et. al, and Hani et. al.\\nWe also include one pre-trained model using a custom convolutional network.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Kadenze/siamese_net\"\n  }, \"https://github.com/Kadenze/siamese_net\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PRE-TRAINED CONVNETS AND OBJECT LOCALISATION IN KERAS\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://blog.heuritech.com/2016/04/26/pre-trained-convnets-and-object-localisation-in-keras/\"\n  }, \"https://blog.heuritech.com/2016/04/26/pre-trained-convnets-and-object-localisation-in-keras/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/heuritech/convnets-keras\"\n  }, \"https://github.com/heuritech/convnets-keras\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning algorithms with TensorFlow: Ready to use implementations of various Deep Learning algorithms using TensorFlow\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.gabrieleangeletti.com/\"\n  }, \"http://www.gabrieleangeletti.com/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/blackecho/Deep-Learning-TensorFlow\"\n  }, \"https://github.com/blackecho/Deep-Learning-TensorFlow\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast Multi-threaded VGG 19 Feature Extractor\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/coreylynch/vgg-19-feature-extractor\"\n  }, \"https://github.com/coreylynch/vgg-19-feature-extractor\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Live demo of neural network classifying images\")), mdx(\"img\", {\n    \"src\": \"/assets/cnn-materials/nn_classify_images_live_demo.jpg\",\n    \"alt\": null\n  }), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://ml4a.github.io/dev/demos/cifar_confusion.html#\"\n  }, \"http://ml4a.github.io/dev/demos/cifar_confusion.html#\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"mojo cnn: c++ convolutional neural network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: the fast and easy header only c++ convolutional neural network package\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/gnawice/mojo-cnn\"\n  }, \"https://github.com/gnawice/mojo-cnn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepHeart: Neural networks for monitoring cardiac data\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jisaacso/DeepHeart\"\n  }, \"https://github.com/jisaacso/DeepHeart\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Water: Deep Learning in H2O using Native GPU Backends\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Native implementation of Deep Learning models for GPU backends (mxnet, Caffe, TensorFlow, etc.)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/h2oai/deepwater\"\n  }, \"https://github.com/h2oai/deepwater\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Greentea LibDNN: Greentea LibDNN - a universal convolution implementation supporting CUDA and OpenCL\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/naibaf7/libdnn\"\n  }, \"https://github.com/naibaf7/libdnn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dracula: A spookily good Part of Speech Tagger optimized for Twitter\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: A deep, LSTM-based part of speech tagger and sentiment analyser using character embeddings instead of words.\\nCompatible with Theano and TensorFlow. Optimized for Twitter.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://dracula.sentimentron.co.uk/\"\n  }, \"http://dracula.sentimentron.co.uk/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"speech tagging demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://dracula.sentimentron.co.uk/pos-demo/\"\n  }, \"http://dracula.sentimentron.co.uk/pos-demo/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"sentiment demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://dracula.sentimentron.co.uk/sentiment-demo/\"\n  }, \"http://dracula.sentimentron.co.uk/sentiment-demo/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Sentimentron/Dracula\"\n  }, \"https://github.com/Sentimentron/Dracula\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Trained image classification models for Keras\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Keras code and weights files for popular deep learning models.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: VGG16, VGG19, ResNet50, Inception v3\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/fchollet/deep-learning-models\"\n  }, \"https://github.com/fchollet/deep-learning-models\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PyCNN: Cellular Neural Networks Image Processing Python Library\")), mdx(\"img\", {\n    \"src\": \"https://camo.githubusercontent.com/0c5fd234a144b3d2145a133466766b2ecd9d3f3c/687474703a2f2f7777772e6973697765622e65652e6574687a2e63682f6861656e6767692f434e4e5f7765622f434e4e5f666967757265732f626c6f636b6469616772616d2e676966\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://blog.ankitaggarwal.me/PyCNN/\"\n  }, \"http://blog.ankitaggarwal.me/PyCNN/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ankitaggarwal011/PyCNN\"\n  }, \"https://github.com/ankitaggarwal011/PyCNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"regl-cnn: Digit recognition with Convolutional Neural Networks in WebGL\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: TensorFlow, WebGL, \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mikolalysenko/regl\"\n  }, \"regl\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Erkaman/regl-cnn/\"\n  }, \"https://github.com/Erkaman/regl-cnn/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://erkaman.github.io/regl-cnn/src/demo.html\"\n  }, \"https://erkaman.github.io/regl-cnn/src/demo.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"dagstudio: Directed Acyclic Graph Studio with Javascript D3\")), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/TimZaman/dagstudio/master/misc/20160907_dagstudio_ex.gif\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/TimZaman/dagstudio\"\n  }, \"https://github.com/TimZaman/dagstudio\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"NEUGO: Neural Networks in Go\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/wh1t3w01f/neugo\"\n  }, \"https://github.com/wh1t3w01f/neugo\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"gvnn: Neural Network Library for Geometric Computer Vision\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1607.07405\"\n  }, \"http://arxiv.org/abs/1607.07405\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ankurhanda/gvnn\"\n  }, \"https://github.com/ankurhanda/gvnn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepForge: A development environment for deep learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/dfst/deepforge\"\n  }, \"https://github.com/dfst/deepforge\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Implementation of recent Deep Learning papers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: DenseNet / DeconvNet / DenseRecNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tdeboissiere/DeepLearningImplementations\"\n  }, \"https://github.com/tdeboissiere/DeepLearningImplementations\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"GPU-accelerated Theano & Keras on Windows 10 native\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/philferriere/dlwin\"\n  }, \"https://github.com/philferriere/dlwin\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Head Pose and Gaze Direction Estimation Using Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mpatacchiola/deepgaze\"\n  }, \"https://github.com/mpatacchiola/deepgaze\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Intel(R) Math Kernel Library for Deep Neural Networks (Intel(R) MKL-DNN)\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://01.org/mkl-dnn\"\n  }, \"https://01.org/mkl-dnn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/01org/mkl-dnn\"\n  }, \"https://github.com/01org/mkl-dnn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep CNN and RNN - Deep convolution/recurrent neural network project with TensorFlow\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tobegit3hub/deep_cnn\"\n  }, \"https://github.com/tobegit3hub/deep_cnn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Experimental implementation of novel neural network structures\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: binarynet / ternarynet / qrnn / vae / gcnn\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/DingKe/nn_playground\"\n  }, \"https://github.com/DingKe/nn_playground\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"WaterNet: A convolutional neural network that identifies water in satellite images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/treigerm/WaterNet\"\n  }, \"https://github.com/treigerm/WaterNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Kur: Descriptive Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/deepgram/kur\"\n  }, \"https://github.com/deepgram/kur\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"docs: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://kur.deepgram.com/\"\n  }, \"http://kur.deepgram.com/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Development of JavaScript-based deep learning platform and application to distributed training\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Workshop paper for ICLR2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.01846\"\n  }, \"https://arxiv.org/abs/1702.01846\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mil-tokyo\"\n  }, \"https://github.com/mil-tokyo\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"NewralNet\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: A lightweight, easy to use and open source Java library for experimenting with\\nfeed-forward neural nets and deep learning.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gitlab: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://gitlab.com/flimmerkiste/NewralNet\"\n  }, \"https://gitlab.com/flimmerkiste/NewralNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FeatherCNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: FeatherCNN is a high performance inference engine for convolutional neural networks\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Tencent/FeatherCNN\"\n  }, \"https://github.com/Tencent/FeatherCNN\"))), mdx(\"h1\", {\n    \"id\": \"readings-and-questions\"\n  }, \"Readings and Questions\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"What you wanted to know about AI\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://fastml.com/what-you-wanted-to-know-about-ai/\"\n  }, \"http://fastml.com/what-you-wanted-to-know-about-ai/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Epoch vs iteration when training neural networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"stackoverflow: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://stackoverflow.com/questions/4752626/epoch-vs-iteration-when-training-neural-networks\"\n  }, \"http://stackoverflow.com/questions/4752626/epoch-vs-iteration-when-training-neural-networks\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Questions to Ask When Applying Deep Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://deeplearning4j.org/questions.html\"\n  }, \"http://deeplearning4j.org/questions.html\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"How can I know if Deep Learning works better for a specific problem than SVM or random forest?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/rasbt/python-machine-learning-book/blob/master/faq/deeplearn-vs-svm-randomforest.md\"\n  }, \"https://github.com/rasbt/python-machine-learning-book/blob/master/faq/deeplearn-vs-svm-randomforest.md\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"What is the difference between deep learning and usual machine learning?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"note: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/rasbt/python-machine-learning-book/blob/master/faq/difference-deep-and-normal-learning.md\"\n  }, \"https://github.com/rasbt/python-machine-learning-book/blob/master/faq/difference-deep-and-normal-learning.md\"))), mdx(\"h1\", {\n    \"id\": \"resources\"\n  }, \"Resources\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Awesome Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ChristosChristofidis/awesome-deep-learning\"\n  }, \"https://github.com/ChristosChristofidis/awesome-deep-learning\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Awesome-deep-vision: A curated list of deep learning resources for computer vision\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"website: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://jiwonkim.org/awesome-deep-vision/\"\n  }, \"http://jiwonkim.org/awesome-deep-vision/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kjw0612/awesome-deep-vision\"\n  }, \"https://github.com/kjw0612/awesome-deep-vision\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Applied Deep Learning Resources: A collection of research articles, blog posts, slides and code snippets about deep learning in applied settings.\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kristjankorjus/applied-deep-learning-resources\"\n  }, \"https://github.com/kristjankorjus/applied-deep-learning-resources\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning Libraries by Language\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"website: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.teglor.com/b/deep-learning-libraries-language-cm569/\"\n  }, \"http://www.teglor.com/b/deep-learning-libraries-language-cm569/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning Resources\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://yanirseroussi.com/deep-learning-resources/\"\n  }, \"http://yanirseroussi.com/deep-learning-resources/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning Resources\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://omtcyfz.github.io/2016/08/29/Deep-Learning-Resources.html\"\n  }, \"https://omtcyfz.github.io/2016/08/29/Deep-Learning-Resources.html\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Turing Machine: musings on theory & code(DEEP LEARNING REVOLUTION, summer 2015, state of the art & topnotch links)\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://vzn1.wordpress.com/2015/09/01/deep-learning-revolution-summer-2015-state-of-the-art-topnotch-links/\"\n  }, \"https://vzn1.wordpress.com/2015/09/01/deep-learning-revolution-summer-2015-state-of-the-art-topnotch-links/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BICV Group: Biologically Inspired Computer Vision research group\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://www.bicv.org/deep-learning/\"\n  }, \"http://www.bicv.org/deep-learning/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Deep Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://rt.dgyblog.com/ref/ref-learning-deep-learning.html\"\n  }, \"http://rt.dgyblog.com/ref/ref-learning-deep-learning.html\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Summaries and notes on Deep Learning research papers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/dennybritz/deeplearning-papernotes\"\n  }, \"https://github.com/dennybritz/deeplearning-papernotes\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning Glossary\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: \\\"Simple, opinionated explanations of various things encountered in Deep Learning / AI / ML.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"author: Ryan Dahl, author of NodeJS. \"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ry/deep_learning_glossary\"\n  }, \"https://github.com/ry/deep_learning_glossary\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Deep Learning Playbook\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://medium.com/@jiefeng/deep-learning-playbook-c5ebe34f8a1a#.eg9cdz5ak\"\n  }, \"https://medium.com/@jiefeng/deep-learning-playbook-c5ebe34f8a1a#.eg9cdz5ak\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning Study: Study of HeXA@UNIST in Preparation for Submission\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/carpedm20/deep-learning-study\"\n  }, \"https://github.com/carpedm20/deep-learning-study\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning Books\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://machinelearningmastery.com/deep-learning-books/\"\n  }, \"http://machinelearningmastery.com/deep-learning-books/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"awesome-very-deep-learning: A curated list of papers and code about very deep neural networks (50+ layers)\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/daviddao/awesome-very-deep-learning\"\n  }, \"https://github.com/daviddao/awesome-very-deep-learning\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning Resources and Tutorials using Keras and Lasagne\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Vict0rSch/deep_learning\"\n  }, \"https://github.com/Vict0rSch/deep_learning\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning: Definition, Resources, Comparison with Machine Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.datasciencecentral.com/profiles/blogs/deep-learning-definition-resources-comparison-with-machine-learni\"\n  }, \"http://www.datasciencecentral.com/profiles/blogs/deep-learning-definition-resources-comparison-with-machine-learni\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Awesome - Most Cited Deep Learning Papers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/terryum/awesome-deep-learning-papers\"\n  }, \"https://github.com/terryum/awesome-deep-learning-papers\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The most cited papers in computer vision and deep learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://computervisionblog.wordpress.com/2016/06/19/the-most-cited-papers-in-computer-vision-and-deep-learning/\"\n  }, \"https://computervisionblog.wordpress.com/2016/06/19/the-most-cited-papers-in-computer-vision-and-deep-learning/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"deep learning papers: A place to collect papers that are related to deep learning and computational biology\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/pimentel/deep_learning_papers\"\n  }, \"https://github.com/pimentel/deep_learning_papers\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"papers-I-read\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: \\\"I am trying a new initiative - a-paper-a-week. This repository will hold all those papers and related summaries and notes.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/shagunsodhani/papers-I-read\"\n  }, \"https://github.com/shagunsodhani/papers-I-read\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"LEARNING DEEP LEARNING - MY TOP-FIVE LIST\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/\"\n  }, \"http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"awesome-free-deep-learning-papers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/HFTrader/awesome-free-deep-learning-papers\"\n  }, \"https://github.com/HFTrader/awesome-free-deep-learning-papers\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepLearningBibliography: Bibliography for Publications about Deep Learning using GPU\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://memkite.com/deep-learning-bibliography/\"\n  }, \"http://memkite.com/deep-learning-bibliography/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/memkite/DeepLearningBibliography\"\n  }, \"https://github.com/memkite/DeepLearningBibliography\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning Papers Reading Roadmap\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap\"\n  }, \"https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"deep-learning-papers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Papers about deep learning ordered by task, date. Current state-of-the-art papers are labelled.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/sbrugman/deep-learning-papers/blob/master/README.md\"\n  }, \"https://github.com/sbrugman/deep-learning-papers/blob/master/README.md\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning and applications in Startups, CV, Text Mining, NLP\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lipiji/app-dl\"\n  }, \"https://github.com/lipiji/app-dl\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ml4a-guides - a collection of practical resources for working with machine learning software, including code and tutorials\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://ml4a.github.io/guides/\"\n  }, \"http://ml4a.github.io/guides/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"deep-learning-resources\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: A Collection of resources I have found useful on my journey finding my way through the world of Deep Learning.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/chasingbob/deep-learning-resources\"\n  }, \"https://github.com/chasingbob/deep-learning-resources\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"21 Deep Learning Videos, Tutorials & Courses on Youtube from 2016\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.analyticsvidhya.com/blog/2016/12/21-deep-learning-videos-tutorials-courses-on-youtube-from-2016/\"\n  }, \"https://www.analyticsvidhya.com/blog/2016/12/21-deep-learning-videos-tutorials-courses-on-youtube-from-2016/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Awesome Deep learning papers and other resources\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/endymecy/awesome-deeplearning-resources\"\n  }, \"https://github.com/endymecy/awesome-deeplearning-resources\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"awesome-deep-vision-web-demo\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: A curated list of awesome deep vision web demo\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hwalsuklee/awesome-deep-vision-web-demo\"\n  }, \"https://github.com/hwalsuklee/awesome-deep-vision-web-demo\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Summaries of machine learning papers\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/aleju/papers\"\n  }, \"https://github.com/aleju/papers\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Awesome Deep Learning Resources\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/guillaume-chevalier/awesome-deep-learning-resources\"\n  }, \"https://github.com/guillaume-chevalier/awesome-deep-learning-resources\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Virginia Tech Vision and Learning Reading Group\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com//vt-vl-lab/reading_group\"\n  }, \"https://github.com//vt-vl-lab/reading_group\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MEGALODON: ML/DL Resources At One Place\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Various ML/DL Resources organised at a single place.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com//vyraun/Megalodon\"\n  }, \"https://github.com//vyraun/Megalodon\"))), mdx(\"h2\", {\n    \"id\": \"arxiv-pages\"\n  }, \"Arxiv Pages\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Neural and Evolutionary Computing\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/list/cs.NE/recent\"\n  }, \"https://arxiv.org/list/cs.NE/recent\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/list/cs.LG/recent\"\n  }, \"https://arxiv.org/list/cs.LG/recent\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Computer Vision and Pattern Recognition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/list/cs.CV/recent\"\n  }, \"https://arxiv.org/list/cs.CV/recent\")), mdx(\"h2\", {\n    \"id\": \"arxiv-sanity-preserver\"\n  }, \"Arxiv Sanity Preserver\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Built by @karpathy to accelerate research.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.arxiv-sanity.com/\"\n  }, \"http://www.arxiv-sanity.com/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Today's Deep Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://todaysdeeplearning.com/\"\n  }, \"http://todaysdeeplearning.com/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"arXiv Analytics\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://arxitics.com/\"\n  }, \"http://arxitics.com/\")), mdx(\"h2\", {\n    \"id\": \"papers-with-code\"\n  }, \"Papers with Code\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Papers with Code\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://paperswithcode.com/\"\n  }, \"https://paperswithcode.com/\")), mdx(\"h1\", {\n    \"id\": \"tools\"\n  }, \"Tools\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DNNGraph - A deep neural network model generation DSL in Haskell\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://ajtulloch.github.io/dnngraph/\"\n  }, \"http://ajtulloch.github.io/dnngraph/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep playground: an interactive visualization of neural networks, written in typescript using d3.js\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.23990&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification\"\n  }, \"http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle\", \"\\xAE\", \"Dataset=reg-plane&learningRate=0.03\", \"\\xAE\", \"ularizationRate=0&noise=0&networkShape=4,2&seed=0.23990&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tensorflow/playground\"\n  }, \"https://github.com/tensorflow/playground\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Neural Network Package\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: This package provides an easy and modular way to build and train simple or complex neural networks using Torch\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/torch/nn\"\n  }, \"https://github.com/torch/nn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"deepdish: Deep learning and data science tools from the University of Chicago\"), \"\\n\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"deepdish: Serving Up Chicago-Style Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://deepdish.io/\"\n  }, \"http://deepdish.io/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/uchicago-cs/deepdish\"\n  }, \"https://github.com/uchicago-cs/deepdish\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AETROS CLI: Console application to manage deep neural network training in AETROS Trainer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Create, train and monitor deep neural networks using a model designer.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://aetros.com/\"\n  }, \"http://aetros.com/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aetros/aetros-cli\"\n  }, \"https://github.com/aetros/aetros-cli\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning Studio: Cloud platform for designing Deep Learning AI without programming\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://deepcognition.ai/\"\n  }, \"http://deepcognition.ai/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"cuda-on-cl: Build NVIDIA\\xAE CUDA\\u2122 code for OpenCL\\u2122 1.2 devices\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hughperkins/cuda-on-cl\"\n  }, \"https://github.com/hughperkins/cuda-on-cl\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Receptive Field Calculator\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://fomoro.com/tools/receptive-fields/\"\n  }, \"http://fomoro.com/tools/receptive-fields/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"example: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://fomoro.com/tools/receptive-fields/#3,1,1,VALID;3,1,1,VALID;3,1,1,VALID\"\n  }, \"http://fomoro.com/tools/receptive-fields/#3,1,1,VALID;3,1,1,VALID;3,1,1,VALID\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"receptivefield\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: (PyTorch/Keras/TensorFlow)Gradient based receptive field estimation for Convolutional Neural Networks\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com//fornaxai/receptivefield\"\n  }, \"https://github.com//fornaxai/receptivefield\"))), mdx(\"h1\", {\n    \"id\": \"challenges--hackathons\"\n  }, \"Challenges / Hackathons\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Open Images Challenge 2018\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://storage.googleapis.com/openimages/web/challenge.html\"\n  }, \"https://storage.googleapis.com/openimages/web/challenge.html\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"VisionHack 2017\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: 10 - 14 Sep 2017, Moscow, Russia\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: a full-fledged hackathon that will last three full days\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://visionhack.misis.ru/\"\n  }, \"http://visionhack.misis.ru/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"NVIDIA AI City Challenge Workshop at CVPR 2018\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://www.aicitychallenge.org/\"\n  }, \"http://www.aicitychallenge.org/\")), mdx(\"h1\", {\n    \"id\": \"books\"\n  }, \"Books\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"author: Ian Goodfellow, Aaron Courville and Yoshua Bengio\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.deeplearningbook.org/\"\n  }, \"http://www.deeplearningbook.org/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"website: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://goodfeli.github.io/dlbook/\"\n  }, \"http://goodfeli.github.io/dlbook/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/HFTrader/DeepLearningBook\"\n  }, \"https://github.com/HFTrader/DeepLearningBook\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes(\\\"Deep Learning for Beginners\\\"): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://randomekek.github.io/deep/deeplearning.html\"\n  }, \"http://randomekek.github.io/deep/deeplearning.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fundamentals of Deep Learning: Designing Next-Generation Artificial Intelligence Algorithms\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"author: Nikhil Buduma\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"book review: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.opengardensblog.futuretext.com/archives/2015/08/book-review-fundamentals-of-deep-learning-designing-next-generation-artificial-intelligence-algorithms-by-nikhil-buduma.html\"\n  }, \"http://www.opengardensblog.futuretext.com/archives/2015/08/book-review-fundamentals-of-deep-learning-designing-next-generation-artificial-intelligence-algorithms-by-nikhil-buduma.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/darksigma/Fundamentals-of-Deep-Learning-Book\"\n  }, \"https://github.com/darksigma/Fundamentals-of-Deep-Learning-Book\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FIRST CONTACT WITH TENSORFLOW: Get started with with Deep Learning programming\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"author: Jordi Torres\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"book: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.jorditorres.org/first-contact-with-tensorflow/\"\n  }, \"http://www.jorditorres.org/first-contact-with-tensorflow/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"\\u300A\\u89E3\\u6790\\u5377\\u79EF\\u795E\\u7ECF\\u7F51\\u7EDC\\u2014\\u6DF1\\u5EA6\\u5B66\\u4E60\\u5B9E\\u8DF5\\u624B\\u518C\\u300B\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: by \\u9B4F\\u79C0\\u53C2\\uFF08Xiu-Shen WEI\\uFF09\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://lamda.nju.edu.cn/weixs/book/CNN_book.html\"\n  }, \"http://lamda.nju.edu.cn/weixs/book/CNN_book.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Make Your Own Neural Network: IPython Neural Networks on a Raspberry Pi Zero\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"book: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://makeyourownneuralnetwork.blogspot.jp/2016/03/ipython-neural-networks-on-raspberry-pi.html\"\n  }, \"http://makeyourownneuralnetwork.blogspot.jp/2016/03/ipython-neural-networks-on-raspberry-pi.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/makeyourownneuralnetwork/makeyourownneuralnetwork\"\n  }, \"https://github.com/makeyourownneuralnetwork/makeyourownneuralnetwork\"))), mdx(\"h1\", {\n    \"id\": \"blogs\"\n  }, \"Blogs\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Neural Networks and Deep Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://neuralnetworksanddeeplearning.com\"\n  }, \"http://neuralnetworksanddeeplearning.com\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning Reading List\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://deeplearning.net/reading-list/\"\n  }, \"http://deeplearning.net/reading-list/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"WILDML: A BLOG ABOUT MACHINE LEARNING, DEEP LEARNING AND NLP.\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://www.wildml.com/\"\n  }, \"http://www.wildml.com/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Andrej Karpathy blog\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://karpathy.github.io/\"\n  }, \"http://karpathy.github.io/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rodrigob's github page\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://rodrigob.github.io/\"\n  }, \"http://rodrigob.github.io/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"colah's blog\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://colah.github.io/\"\n  }, \"http://colah.github.io/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"What My Deep Model Doesn't Know...\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html\"\n  }, \"http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Christoph Feichtenhofer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: PhD Student, Graz University of Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://feichtenhofer.github.io/\"\n  }, \"http://feichtenhofer.github.io/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Image recognition is not enough: As with language, photos need contextual intelligence\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://medium.com/@ken_getquik/image-recognition-is-not-enough-293cd7d58004#.dex817l2z\"\n  }, \"https://medium.com/@ken_getquik/image-recognition-is-not-enough-293cd7d58004#.dex817l2z\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ResNets, HighwayNets, and DenseNets, Oh My!\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/@awjuliani/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32#.pgltg8pro\"\n  }, \"https://medium.com/@awjuliani/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32#.pgltg8pro\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/awjuliani/TF-Tutorials/blob/master/Deep%20Network%20Comparison.ipynb\"\n  }, \"https://github.com/awjuliani/TF-Tutorials/blob/master/Deep%20Network%20Comparison.ipynb\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Frontiers of Memory and Attention in Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"sldies: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://slides.com/smerity/quora-frontiers-of-memory-and-attention#/\"\n  }, \"http://slides.com/smerity/quora-frontiers-of-memory-and-attention#/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Design Patterns for Deep Learning Architectures\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://www.deeplearningpatterns.com/doku.php\"\n  }, \"http://www.deeplearningpatterns.com/doku.php\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Building a Deep Learning Powered GIF Search Engine\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/@zan2434/building-a-deep-learning-powered-gif-search-engine-a3eb309d7525\"\n  }, \"https://medium.com/@zan2434/building-a-deep-learning-powered-gif-search-engine-a3eb309d7525\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"850k Images in 24 hours: Automating Deep Learning Dataset Creation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://gab41.lab41.org/850k-images-in-24-hours-automating-deep-learning-dataset-creation-60bdced04275#.xhq9feuxx\"\n  }, \"https://gab41.lab41.org/850k-images-in-24-hours-automating-deep-learning-dataset-creation-60bdced04275#.xhq9feuxx\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"How six lines of code + SQL Server can bring Deep Learning to ANY App\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://blogs.technet.microsoft.com/dataplatforminsider/2017/01/05/how-six-lines-of-code-sql-server-can-bring-deep-learning-to-any-app/\"\n  }, \"https://blogs.technet.microsoft.com/dataplatforminsider/2017/01/05/how-six-lines-of-code-sql-server-can-bring-deep-learning-to-any-app/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Microsoft/SQL-Server-R-Services-Samples/tree/master/Galaxies\"\n  }, \"https://github.com/Microsoft/SQL-Server-R-Services-Samples/tree/master/Galaxies\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Neural Network Architectures\")), mdx(\"img\", {\n    \"src\": \"https://culurciello.github.io/assets/nets/acc_vs_net_vs_ops.svg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/towards-data-science/neural-network-architectures-156e5bad51ba#.m8y39oih6\"\n  }, \"https://medium.com/towards-data-science/neural-network-architectures-156e5bad51ba#.m8y39oih6\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://culurciello.github.io/tech/2016/06/04/nets.html\"\n  }, \"https://culurciello.github.io/tech/2016/06/04/nets.html\"))));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"---\nlayout: post\ncategory: deep_learning\ntitle: Deep Learning Resources\ndate: 2015-10-09\n---\n\n# ImageNet\n\nSingle-model on 224x224\n\n| Method              | top1        | top5        | Model Size  | Speed       |\n|:-------------------:|:-----------:|:-----------:|:-----------:|:-----------:|\n| ResNet-101          | 78.0%       | 94.0%       |             |             |\n| ResNet-200          | 78.3%       | 94.2%       |             |             |\n| Inception-v3        |             |             |             |             |\n| Inception-v4        |             |             |             |             |\n| Inception-ResNet-v2 |             |             |             |             |\n| ResNet-50           | 77.8%       |             |             |             |\n| ResNet-101          | 79.6%       | 94.7%       |             |             |\n\nSingle-model on 320320 / 299299\n\n| Method              | top1        | top5        | Model Size  | Speed       |\n|:-------------------:|:-----------:|:-----------:|:-----------:|:-----------:|\n| ResNet-101          |             |             |             |             |\n| ResNet-200          | 79.9%       | 95.2%       |             |             |\n| Inception-v3        | 78.8%       | 94.4%       |             |             |\n| Inception-v4        | 80.0%       | 95.0%       |             |             |\n| Inception-ResNet-v2 | 80.1%       | 95.1%       |             |             |\n| ResNet-50           |             |             |             |             |\n| ResNet-101          | 80.9%       | 95.6%       |             |             |\n\n## AlexNet\n\n**ImageNet Classification with Deep Convolutional Neural Networks**\n\n- nips-page: [http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-)\n- paper: [http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\n- slides: [http://www.image-net.org/challenges/LSVRC/2012/supervision.pdf](http://www.image-net.org/challenges/LSVRC/2012/supervision.pdf)\n- code: [https://code.google.com/p/cuda-convnet/](https://code.google.com/p/cuda-convnet/)\n- github: [https://github.com/dnouri/cuda-convnet](https://github.com/dnouri/cuda-convnet)\n- code: [https://code.google.com/p/cuda-convnet2/](https://code.google.com/p/cuda-convnet2/)\n\n## Network In Network\n\n**Network In Network**\n\n- intro: ICLR 2014\n- arxiv: [http://arxiv.org/abs/1312.4400](http://arxiv.org/abs/1312.4400)\n- gitxiv: [http://gitxiv.com/posts/PA98qGuMhsijsJzgX/network-in-network-nin](http://gitxiv.com/posts/PA98qGuMhsijsJzgX/network-in-network-nin)\n- code(Caffe, official): [https://gist.github.com/mavenlin/d802a5849de39225bcc6](https://gist.github.com/mavenlin/d802a5849de39225bcc6)\n\n**Batch-normalized Maxout Network in Network**\n\n- arxiv: [http://arxiv.org/abs/1511.02583](http://arxiv.org/abs/1511.02583)\n\n## GoogLeNet (Inception V1)\n\n**Going Deeper with Convolutions**\n\n- arxiv: [http://arxiv.org/abs/1409.4842](http://arxiv.org/abs/1409.4842)\n- github: [https://github.com/google/inception](https://github.com/google/inception)\n- github: [https://github.com/soumith/inception.torch](https://github.com/soumith/inception.torch)\n\n**Building a deeper understanding of images**\n\n- blog: [http://googleresearch.blogspot.jp/2014/09/building-deeper-understanding-of-images.html](http://googleresearch.blogspot.jp/2014/09/building-deeper-understanding-of-images.html)\n\n## VGGNet\n\n**Very Deep Convolutional Networks for Large-Scale Image Recognition**\n\n- homepage: [http://www.robots.ox.ac.uk/~vgg/research/very_deep/](http://www.robots.ox.ac.uk/~vgg/research/very_deep/)\n- arxiv: [http://arxiv.org/abs/1409.1556](http://arxiv.org/abs/1409.1556)\n- slides: [http://llcao.net/cu-deeplearning15/presentation/cc3580_Simonyan.pptx](http://llcao.net/cu-deeplearning15/presentation/cc3580_Simonyan.pptx)\n- slides: [http://www.robots.ox.ac.uk/~karen/pdf/ILSVRC_2014.pdf](http://www.robots.ox.ac.uk/~karen/pdf/ILSVRC_2014.pdf)\n- slides: [http://deeplearning.cs.cmu.edu/slides.2015/25.simonyan.pdf](http://deeplearning.cs.cmu.edu/slides.2015/25.simonyan.pdf)\n- github(official, deprecated Caffe API): [https://gist.github.com/ksimonyan/211839e770f7b538e2d8](https://gist.github.com/ksimonyan/211839e770f7b538e2d8)\n- github: [https://github.com/ruimashita/caffe-train](https://github.com/ruimashita/caffe-train)\n\n**Tensorflow VGG16 and VGG19**\n\n- github: [https://github.com/machrisaa/tensorflow-vgg](https://github.com/machrisaa/tensorflow-vgg)\n\n**RepVGG: Making VGG-style ConvNets Great Again**\n\n- intro: BNRist & Tsinghua University & MEGVII Technology & Hong Kong University of Science and Technology & Aberystwyth University\n- arxiv: [https://arxiv.org/abs/2101.03697](https://arxiv.org/abs/2101.03697)\n- github: [https://github.com/DingXiaoH/RepVGG](https://github.com/DingXiaoH/RepVGG)\n- github: [https://github.com/megvii-model/RepVGG](https://github.com/megvii-model/RepVGG)\n\n## Inception-V2\n\n**Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift**\n\n- intro: ImageNet top-5 error: 4.82%\n- keywords: internal covariate shift problem\n- arxiv: [http://arxiv.org/abs/1502.03167](http://arxiv.org/abs/1502.03167)\n- blog: [https://standardfrancis.wordpress.com/2015/04/16/batch-normalization/](https://standardfrancis.wordpress.com/2015/04/16/batch-normalization/)\n- notes: [http://blog.csdn.net/happynear/article/details/44238541](http://blog.csdn.net/happynear/article/details/44238541)\n- github: [https://github.com/lim0606/caffe-googlenet-bn](https://github.com/lim0606/caffe-googlenet-bn)\n\n**ImageNet pre-trained models with batch normalization**\n\n- arxiv: [https://arxiv.org/abs/1612.01452](https://arxiv.org/abs/1612.01452)\n- project page: [http://www.inf-cv.uni-jena.de/Research/CNN+Models.html](http://www.inf-cv.uni-jena.de/Research/CNN+Models.html)\n- github: [https://github.com/cvjena/cnn-models](https://github.com/cvjena/cnn-models)\n\n## Inception-V3\n\nInception-V3 = Inception-V2 + BN-auxiliary (fully connected layer of the auxiliary classifier is also batch-normalized, \nnot just the convolutions)\n\n**Rethinking the Inception Architecture for Computer Vision**\n\n- intro: \"21.2% top-1 and 5.6% top-5 error for single frame evaluation using a network; \n3.5% top-5 error and 17.3% top-1 error With an ensemble of 4 models and multi-crop evaluation.\"\n- arxiv: [http://arxiv.org/abs/1512.00567](http://arxiv.org/abs/1512.00567)\n- github: [https://github.com/Moodstocks/inception-v3.torch](https://github.com/Moodstocks/inception-v3.torch)\n\n**Inception in TensorFlow**\n\n- intro: demonstrate how to train the Inception v3 architecture\n- github: [https://github.com/tensorflow/models/tree/master/inception](https://github.com/tensorflow/models/tree/master/inception)\n\n**Train your own image classifier with Inception in TensorFlow**\n\n- intro: Inception-v3\n- blog: [https://research.googleblog.com/2016/03/train-your-own-image-classifier-with.html](https://research.googleblog.com/2016/03/train-your-own-image-classifier-with.html)\n\n**Notes on the TensorFlow Implementation of Inception v3**\n\n[https://pseudoprofound.wordpress.com/2016/08/28/notes-on-the-tensorflow-implementation-of-inception-v3/](https://pseudoprofound.wordpress.com/2016/08/28/notes-on-the-tensorflow-implementation-of-inception-v3/)\n\n**Training an InceptionV3-based image classifier with your own dataset**\n\n- github: [https://github.com/danielvarga/keras-finetuning](https://github.com/danielvarga/keras-finetuning)\n\n**Inception-BN full for Caffe: Inception-BN ImageNet (21K classes) model for Caffe**\n\n- github: [https://github.com/pertusa/InceptionBN-21K-for-Caffe](https://github.com/pertusa/InceptionBN-21K-for-Caffe)\n\n## ResNet\n\n**Deep Residual Learning for Image Recognition**\n\n- intro: CVPR 2016 Best Paper Award\n- arxiv: [http://arxiv.org/abs/1512.03385](http://arxiv.org/abs/1512.03385)\n- slides: [http://research.microsoft.com/en-us/um/people/kahe/ilsvrc15/ilsvrc2015_deep_residual_learning_kaiminghe.pdf](http://research.microsoft.com/en-us/um/people/kahe/ilsvrc15/ilsvrc2015_deep_residual_learning_kaiminghe.pdf)\n- gitxiv: [http://gitxiv.com/posts/LgPRdTY3cwPBiMKbm/deep-residual-learning-for-image-recognition](http://gitxiv.com/posts/LgPRdTY3cwPBiMKbm/deep-residual-learning-for-image-recognition)\n- github: [https://github.com/KaimingHe/deep-residual-networks](https://github.com/KaimingHe/deep-residual-networks)\n- github: [https://github.com/ry/tensorflow-resnet](https://github.com/ry/tensorflow-resnet)\n\n**Third-party re-implementations**\n\n[https://github.com/KaimingHe/deep-residual-networks#third-party-re-implementations](https://github.com/KaimingHe/deep-residual-networks#third-party-re-implementations)\n\n**Training and investigating Residual Nets**\n\n- intro: Facebook AI Research\n- blog: [http://torch.ch/blog/2016/02/04/resnets.html](http://torch.ch/blog/2016/02/04/resnets.html)\n- github: [https://github.com/facebook/fb.resnet.torch](https://github.com/facebook/fb.resnet.torch)\n\n**resnet.torch: an updated version of fb.resnet.torch with many changes.**\n\n- github: [https://github.com/erogol/resnet.torch](https://github.com/erogol/resnet.torch)\n\n**Highway Networks and Deep Residual Networks**\n\n- blog: [http://yanran.li/peppypapers/2016/01/10/highway-networks-and-deep-residual-networks.html](http://yanran.li/peppypapers/2016/01/10/highway-networks-and-deep-residual-networks.html)\n\n**Interpretating Deep Residual Learning Blocks as Locally Recurrent Connections**\n\n- blog: [https://matrixmashing.wordpress.com/2016/01/29/interpretating-deep-residual-learning-blocks-as-locally-recurrent-connections/](https://matrixmashing.wordpress.com/2016/01/29/interpretating-deep-residual-learning-blocks-as-locally-recurrent-connections/)\n\n**Lab41 Reading Group: Deep Residual Learning for Image Recognition**\n\n- blog: [https://gab41.lab41.org/lab41-reading-group-deep-residual-learning-for-image-recognition-ffeb94745a1f](https://gab41.lab41.org/lab41-reading-group-deep-residual-learning-for-image-recognition-ffeb94745a1f)\n\n**50-layer ResNet, trained on ImageNet, classifying webcam**\n\n- homepage: [https://ml4a.github.io/demos/keras.js/](https://ml4a.github.io/demos/keras.js/)\n\n**Reproduced ResNet on CIFAR-10 and CIFAR-100 dataset.**\n\n- github: [https://github.com/tensorflow/models/tree/master/resnet](https://github.com/tensorflow/models/tree/master/resnet)\n\n## ResNet-V2\n\n**Identity Mappings in Deep Residual Networks**\n\n- intro: ECCV 2016. ResNet-v2\n- arxiv: [http://arxiv.org/abs/1603.05027](http://arxiv.org/abs/1603.05027)\n- github: [https://github.com/KaimingHe/resnet-1k-layers](https://github.com/KaimingHe/resnet-1k-layers)\n- github: [https://github.com/tornadomeet/ResNet](https://github.com/tornadomeet/ResNet)\n\n**Deep Residual Networks for Image Classification with Python + NumPy**\n\n![](https://dnlcrl.github.io/assets/thesis-post/Diagramma.png)\n\n- blog: [https://dnlcrl.github.io/projects/2016/06/22/Deep-Residual-Networks-for-Image-Classification-with-Python+NumPy.html](https://dnlcrl.github.io/projects/2016/06/22/Deep-Residual-Networks-for-Image-Classification-with-Python+NumPy.html)\n\n## Inception-V4 / Inception-ResNet-V2\n\n**Inception-V4, Inception-Resnet And The Impact Of Residual Connections On Learning**\n\n- intro: Workshop track - ICLR 2016. 3.08 % top-5 error on ImageNet CLS\n- intro: \"achieve 3.08% top-5 error on the test set of the ImageNet classification (CLS) challenge\"\n- arxiv: [http://arxiv.org/abs/1602.07261](http://arxiv.org/abs/1602.07261)\n- github(Keras): [https://github.com/kentsommer/keras-inceptionV4](https://github.com/kentsommer/keras-inceptionV4)\n\n**The inception-resnet-v2 models trained from scratch via torch**\n\n- github: [https://github.com/lim0606/torch-inception-resnet-v2](https://github.com/lim0606/torch-inception-resnet-v2)\n\n**Inception v4 in Keras**\n\n- intro: Inception-v4, Inception - Resnet-v1 and v2\n- github: [https://github.com/titu1994/Inception-v4](https://github.com/titu1994/Inception-v4)\n\n## ResNeXt\n\n**Aggregated Residual Transformations for Deep Neural Networks**\n\n- intro: CVPR 2017. UC San Diego & Facebook AI Research\n- arxiv: [https://arxiv.org/abs/1611.05431](https://arxiv.org/abs/1611.05431)\n- github(Torch): [https://github.com/facebookresearch/ResNeXt](https://github.com/facebookresearch/ResNeXt)\n- github: [https://github.com/dmlc/mxnet/blob/master/example/image-classification/symbol/resnext.py](https://github.com/dmlc/mxnet/blob/master/example/image-classification/symbol/resnext.py)\n- dataset: [http://data.dmlc.ml/models/imagenet/resnext/](http://data.dmlc.ml/models/imagenet/resnext/)\n- reddit: [https://www.reddit.com/r/MachineLearning/comments/5haml9/p_implementation_of_aggregated_residual/](https://www.reddit.com/r/MachineLearning/comments/5haml9/p_implementation_of_aggregated_residual/)\n\n## ResNeSt\n\n**ResNeSt: Split-Attention Networks**\n\n- intro: Amazon & University of California\n- arxiv: [https://arxiv.org/abs/2004.08955](https://arxiv.org/abs/2004.08955)\n- github: [https://github.com/zhanghang1989/ResNeSt](https://github.com/zhanghang1989/ResNeSt)\n\n## Residual Networks Variants\n\n**Resnet in Resnet: Generalizing Residual Architectures**\n\n- paper: [http://beta.openreview.net/forum?id=lx9l4r36gU2OVPy8Cv9g](http://beta.openreview.net/forum?id=lx9l4r36gU2OVPy8Cv9g)\n- arxiv: [http://arxiv.org/abs/1603.08029](http://arxiv.org/abs/1603.08029)\n\n**Residual Networks are Exponential Ensembles of Relatively Shallow Networks**\n\n- arxiv: [http://arxiv.org/abs/1605.06431](http://arxiv.org/abs/1605.06431)\n\n**Wide Residual Networks**\n\n- intro: BMVC 2016\n- arxiv: [http://arxiv.org/abs/1605.07146](http://arxiv.org/abs/1605.07146)\n- github: [https://github.com/szagoruyko/wide-residual-networks](https://github.com/szagoruyko/wide-residual-networks)\n- github: [https://github.com/asmith26/wide_resnets_keras](https://github.com/asmith26/wide_resnets_keras)\n- github: [https://github.com/ritchieng/wideresnet-tensorlayer](https://github.com/ritchieng/wideresnet-tensorlayer)\n- github: [https://github.com/xternalz/WideResNet-pytorch](https://github.com/xternalz/WideResNet-pytorch)\n- github(Torch): [https://github.com/meliketoy/wide-residual-network](https://github.com/meliketoy/wide-residual-network)\n\n**Residual Networks of Residual Networks: Multilevel Residual Networks**\n\n- arxiv: [http://arxiv.org/abs/1608.02908](http://arxiv.org/abs/1608.02908)\n\n**Multi-Residual Networks**\n\n- arxiv: [http://arxiv.org/abs/1609.05672](http://arxiv.org/abs/1609.05672)\n- github: [https://github.com/masoudabd/multi-resnet](https://github.com/masoudabd/multi-resnet)\n\n**Deep Pyramidal Residual Networks**\n\n- intro: PyramidNet\n- arxiv: [https://arxiv.org/abs/1610.02915](https://arxiv.org/abs/1610.02915)\n- github: [https://github.com/jhkim89/PyramidNet](https://github.com/jhkim89/PyramidNet)\n\n**Learning Identity Mappings with Residual Gates**\n\n- arxiv: [https://arxiv.org/abs/1611.01260](https://arxiv.org/abs/1611.01260)\n\n**Wider or Deeper: Revisiting the ResNet Model for Visual Recognition**\n\n- intro: image classification, semantic image segmentation\n- arxiv: [https://arxiv.org/abs/1611.10080](https://arxiv.org/abs/1611.10080)\n- github: [https://github.com/itijyou/ademxapp](https://github.com/itijyou/ademxapp)\n\n**Deep Pyramidal Residual Networks with Separated Stochastic Depth**\n\n- arxiv: [https://arxiv.org/abs/1612.01230](https://arxiv.org/abs/1612.01230)\n\n**Spatially Adaptive Computation Time for Residual Networks**\n\n- intro: Higher School of Economics & Google & CMU\n- arxiv: [https://arxiv.org/abs/1612.02297](https://arxiv.org/abs/1612.02297)\n\n**ShaResNet: reducing residual network parameter number by sharing weights**\n\n- arxiv: [https://arxiv.org/abs/1702.08782](https://arxiv.org/abs/1702.08782)\n- github: [https://github.com/aboulch/sharesnet](https://github.com/aboulch/sharesnet)\n\n**Sharing Residual Units Through Collective Tensor Factorization in Deep Neural Networks**\n\n- intro: Collective Residual Networks\n- arxiv: [https://arxiv.org/abs/1703.02180](https://arxiv.org/abs/1703.02180)\n- github(MXNet): [https://github.com/cypw/CRU-Net](https://github.com/cypw/CRU-Net)\n\n**Residual Attention Network for Image Classification**\n\n- intro: CVPR 2017 Spotlight. SenseTime Group Limited & Tsinghua University & The Chinese University of Hong Kong\n- intro: ImageNet (4.8% single model and single crop, top-5 error)\n- arxiv: [https://arxiv.org/abs/1704.06904](https://arxiv.org/abs/1704.06904)\n- github(Caffe): [https://github.com/buptwangfei/residual-attention-network](https://github.com/buptwangfei/residual-attention-network)\n\n**Dilated Residual Networks**\n\n- intro: CVPR 2017. Princeton University & Intel Labs\n- keywords: Dilated Residual Networks (DRN)\n- project page: [http://vladlen.info/publications/dilated-residual-networks/](http://vladlen.info/publications/dilated-residual-networks/)\n- arxiv: [https://arxiv.org/abs/1705.09914](https://arxiv.org/abs/1705.09914)\n- paper: [http://vladlen.info/papers/DRN.pdf](http://vladlen.info/papers/DRN.pdf)\n\n**Dynamic Steerable Blocks in Deep Residual Networks**\n\n- intro: University of Amsterdam & ESAT-PSI\n- arxiv: [https://arxiv.org/abs/1706.00598](https://arxiv.org/abs/1706.00598)\n\n**Learning Deep ResNet Blocks Sequentially using Boosting Theory**\n\n- intro: Microsoft Research & Princeton University\n- arxiv: [https://arxiv.org/abs/1706.04964](https://arxiv.org/abs/1706.04964)\n\n**Learning Strict Identity Mappings in Deep Residual Networks**\n\n- keywords: epsilon-ResNet\n- arxiv: [https://arxiv.org/abs/1804.01661](https://arxiv.org/abs/1804.01661)\n\n**Spiking Deep Residual Network**\n\n[https://arxiv.org/abs/1805.01352](https://arxiv.org/abs/1805.01352)\n\n**Norm-Preservation: Why Residual Networks Can Become Extremely Deep?**\n\n- intro: University of Central Florida\n- arxiv: [https://arxiv.org/abs/1805.07477](https://arxiv.org/abs/1805.07477)\n\n**MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks**\n\n- intro: Carnegie Mellon University\n- arxiv: [https://arxiv.org/abs/2009.08453](https://arxiv.org/abs/2009.08453)\n- github: [https://github.com/szq0214/MEAL-V2](https://github.com/szq0214/MEAL-V2)\n\n## DenseNet\n\n**Densely Connected Convolutional Networks**\n\n![](https://cloud.githubusercontent.com/assets/8370623/17981496/fa648b32-6ad1-11e6-9625-02fdd72fdcd3.jpg)\n\n- intro: CVPR 2017 best paper. Cornell University & Tsinghua University. DenseNet\n- arxiv: [http://arxiv.org/abs/1608.06993](http://arxiv.org/abs/1608.06993)\n- github: [https://github.com/liuzhuang13/DenseNet](https://github.com/liuzhuang13/DenseNet)\n- github(Lasagne): [https://github.com/Lasagne/Recipes/tree/master/papers/densenet](https://github.com/Lasagne/Recipes/tree/master/papers/densenet)\n- github(Keras): [https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/DenseNet](https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/DenseNet)\n- github(Caffe): [https://github.com/liuzhuang13/DenseNetCaffe](https://github.com/liuzhuang13/DenseNetCaffe)\n- github(Tensorflow): [https://github.com/YixuanLi/densenet-tensorflow](https://github.com/YixuanLi/densenet-tensorflow)\n- github(Keras): [https://github.com/titu1994/DenseNet](https://github.com/titu1994/DenseNet)\n- github(PyTorch): [https://github.com/bamos/densenet.pytorch](https://github.com/bamos/densenet.pytorch)\n- github(PyTorch): [https://github.com/andreasveit/densenet-pytorch](https://github.com/andreasveit/densenet-pytorch)\n- github(Tensorflow): [https://github.com/ikhlestov/vision_networks](https://github.com/ikhlestov/vision_networks)\n\n**Memory-Efficient Implementation of DenseNets**\n\n- intro: Cornell University & Fudan University & Facebook AI Research\n- arxiv: [https://arxiv.org/abs/1707.06990](https://arxiv.org/abs/1707.06990)\n- github: [https://github.com/liuzhuang13/DenseNet/tree/master/models](https://github.com/liuzhuang13/DenseNet/tree/master/models)\n- github: [https://github.com/gpleiss/efficient_densenet_pytorch](https://github.com/gpleiss/efficient_densenet_pytorch)\n- github: [https://github.com/taineleau/efficient_densenet_mxnet](https://github.com/taineleau/efficient_densenet_mxnet)\n- github: [https://github.com/Tongcheng/DN_CaffeScript](https://github.com/Tongcheng/DN_CaffeScript)\n\n## DenseNet 2.0\n\n**CondenseNet: An Efficient DenseNet using Learned Group Convolutions**\n\n- arxiv: [https://arxiv.org/abs/1711.09224](https://arxiv.org/abs/1711.09224)\n- github: [https://github.com//ShichenLiu/CondenseNet](https://github.com//ShichenLiu/CondenseNet)\n\n**Multimodal Densenet**\n\n[https://arxiv.org/abs/1811.07407](https://arxiv.org/abs/1811.07407)\n\n## Xception\n\n**Deep Learning with Separable Convolutions**\n\n**Xception: Deep Learning with Depthwise Separable Convolutions**\n\n- intro: CVPR 2017. Extreme Inception\n- arxiv: [https://arxiv.org/abs/1610.02357](https://arxiv.org/abs/1610.02357)\n- code: [https://keras.io/applications/#xception](https://keras.io/applications/#xception)\n- github(Keras): [https://github.com/fchollet/deep-learning-models/blob/master/xception.py](https://github.com/fchollet/deep-learning-models/blob/master/xception.py)\n- github: [https://gist.github.com/culurciello/554c8e56d3bbaf7c66bf66c6089dc221](https://gist.github.com/culurciello/554c8e56d3bbaf7c66bf66c6089dc221)\n- github: [https://github.com/kwotsin/Tensorflow-Xception](https://github.com/kwotsin/Tensorflow-Xception)\n- github: [https://github.com//bruinxiong/xception.mxnet](https://github.com//bruinxiong/xception.mxnet)\n- notes: [http://www.shortscience.org/paper?bibtexKey=journals%2Fcorr%2F1610.02357](http://www.shortscience.org/paper?bibtexKey=journals%2Fcorr%2F1610.02357)\n\n**Towards a New Interpretation of Separable Convolutions**\n\n- arxiv: [https://arxiv.org/abs/1701.04489](https://arxiv.org/abs/1701.04489)\n\n## MobileNets\n\n**MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications**\n\n- intro: Google\n- arxiv: [https://arxiv.org/abs/1704.04861](https://arxiv.org/abs/1704.04861)\n- github: [https://github.com/rcmalli/keras-mobilenet](https://github.com/rcmalli/keras-mobilenet)\n- github: [https://github.com/marvis/pytorch-mobilenet](https://github.com/marvis/pytorch-mobilenet)\n- github(Tensorflow): [https://github.com/Zehaos/MobileNet](https://github.com/Zehaos/MobileNet)\n- github: [https://github.com/shicai/MobileNet-Caffe](https://github.com/shicai/MobileNet-Caffe)\n- github: [https://github.com/hollance/MobileNet-CoreML](https://github.com/hollance/MobileNet-CoreML)\n- github: [https://github.com/KeyKy/mobilenet-mxnet](https://github.com/KeyKy/mobilenet-mxnet)\n\n**MobileNets: Open-Source Models for Efficient On-Device Vision**\n\n- blog: [https://research.googleblog.com/2017/06/mobilenets-open-source-models-for.html](https://research.googleblog.com/2017/06/mobilenets-open-source-models-for.html)\n- github: [https://github.com/tensorflow/models/blob/master/slim/nets/mobilenet_v1.md](https://github.com/tensorflow/models/blob/master/slim/nets/mobilenet_v1.md)\n\n**Googles MobileNets on the iPhone**\n\n- blog: [http://machinethink.net/blog/googles-mobile-net-architecture-on-iphone/](http://machinethink.net/blog/googles-mobile-net-architecture-on-iphone/)\n- github: [https://github.com/hollance/MobileNet-CoreML](https://github.com/hollance/MobileNet-CoreML)\n\n**Depth_conv-for-mobileNet**\n\n[https://github.com//LamHoCN/Depth_conv-for-mobileNet](https://github.com//LamHoCN/Depth_conv-for-mobileNet)\n\n**The Enhanced Hybrid MobileNet**\n\n[https://arxiv.org/abs/1712.04698](https://arxiv.org/abs/1712.04698)\n\n**FD-MobileNet: Improved MobileNet with a Fast Downsampling Strategy**\n\n[https://arxiv.org/abs/1802.03750](https://arxiv.org/abs/1802.03750)\n\n**A Quantization-Friendly Separable Convolution for MobileNets**\n\n- intro: THE 1ST WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING FOR EMBEDDED APPLICATIONS (EMC2)\n- arxiv: [https://arxiv.org/abs/1803.08607](https://arxiv.org/abs/1803.08607)\n\n## MobileNetV2\n\n**Inverted Residuals and Linear Bottlenecks: Mobile Networks forClassification, Detection and Segmentation**\n\n- intro: Google\n- keywords: MobileNetV2, SSDLite, DeepLabv3\n- arxiv: [https://arxiv.org/abs/1801.04381](https://arxiv.org/abs/1801.04381)\n- github: [https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet](https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet)\n- github: [https://github.com/liangfu/mxnet-mobilenet-v2](https://github.com/liangfu/mxnet-mobilenet-v2)\n- blog: [https://research.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html](https://research.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html)\n\n**PydMobileNet: Improved Version of MobileNets with Pyramid Depthwise Separable Convolution**\n\n[https://arxiv.org/abs/1811.07083](https://arxiv.org/abs/1811.07083)\n\n**Rethinking Depthwise Separable Convolutions: How Intra-Kernel Correlations Lead to Improved MobileNets**\n\n- intro: CVPR 2020\n- arxiv: [https://arxiv.org/abs/2003.13549](https://arxiv.org/abs/2003.13549)\n- github: [https://github.com/zeiss-microscopy/BSConv](https://github.com/zeiss-microscopy/BSConv)\n\n**Rethinking Bottleneck Structure for Efficient Mobile Network Design**\n\n- intro: ECCV 2020\n- intro: National University of Singapore & Yitu Technology\n- arxiv: [https://arxiv.org/abs/2007.02269](https://arxiv.org/abs/2007.02269)\n- github: [https://github.com/zhoudaquan/rethinking_bottleneck_design](https://github.com/zhoudaquan/rethinking_bottleneck_design)\n\n**Mobile-Former: Bridging MobileNet and Transformer**\n\n- intro: Microsoft & University of Science and Technology of China\n- arxiv: [https://arxiv.org/abs/2108.05895](https://arxiv.org/abs/2108.05895)\n\n## ShuffleNet\n\n**ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices**\n\n- intro: Megvii Inc (Face++)\n- arxiv: [https://arxiv.org/abs/1707.01083](https://arxiv.org/abs/1707.01083)\n\n## ShuffleNet V2\n\n**ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design**\n\n- intro: ECCV 2018. Megvii Inc (Face++) & Tsinghua University\n- arxiv: [https://arxiv.org/abs/1807.11164]https://arxiv.org/abs/1807.11164\n\n## SENet\n\n**Squeeze-and-Excitation Networks**\n\n- intro: CVPR 2018\n- intro: ILSVRC 2017 image classification winner. Momenta & University of Oxford\n- arxiv: [https://arxiv.org/abs/1709.01507](https://arxiv.org/abs/1709.01507)\n- github(official, Caffe): [https://github.com/hujie-frank/SENet](https://github.com/hujie-frank/SENet)\n- github: [https://github.com/bruinxiong/SENet.mxnet](https://github.com/bruinxiong/SENet.mxnet)\n\n**Competitive Inner-Imaging Squeeze and Excitation for Residual Network**\n\n- arxiv: [https://arxiv.org/abs/1807.08920](https://arxiv.org/abs/1807.08920)\n- github: [https://github.com/scut-aitcm/CompetitiveSENet](https://github.com/scut-aitcm/CompetitiveSENet)\n\n## GENet\n\n**Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks**\n\n- intro: NIPS 2018\n- github: [https://github.com/hujie-frank/GENet](https://github.com/hujie-frank/GENet)\n\n**A ConvNet for the 2020s**\n\n- intro: Facebook AI Research (FAIR) & UC Berkeley\n- arxiv: [https://arxiv.org/abs/2201.03545](https://arxiv.org/abs/2201.03545)\n- github: [https://github.com/facebookresearch/ConvNeXt](https://github.com/facebookresearch/ConvNeXt)\n\n## ImageNet Projects\n\n**Training an Object Classifier in Torch-7 on multiple GPUs over ImageNet**\n\n- intro: an imagenet example in torch\n- github: [https://github.com/soumith/imagenet-multiGPU.torch](https://github.com/soumith/imagenet-multiGPU.torch)\n\n# Pre-training\n\n**Exploring the Limits of Weakly Supervised Pretraining**\n\n- intro: report the highest ImageNet-1k single-crop, top-1 accuracy to date: 85.4% (97.6% top-5)\n- paper: [https://research.fb.com/publications/exploring-the-limits-of-weakly-supervised-pretraining/](https://research.fb.com/publications/exploring-the-limits-of-weakly-supervised-pretraining/)\n\n**Rethinking ImageNet Pre-training**\n\n- intro: Facebook AI Research\n- arxiv: [https://arxiv.org/abs/1811.08883](https://arxiv.org/abs/1811.08883)\n\n**Revisiting Pre-training: An Efficient Training Method for Image Classification**\n\n[https://arxiv.org/abs/1811.09347](https://arxiv.org/abs/1811.09347)\n\n**Rethinking Pre-training and Self-training**\n\n- intro: NeurIPS 2020\n- intro: Google Research, Brain Team\n- arxiv: [https://arxiv.org/abs/2006.06882](https://arxiv.org/abs/2006.06882)\n- github: [https://github.com/tensorflow/tpu/tree/master/models/official/detection/projects/self_training](https://github.com/tensorflow/tpu/tree/master/models/official/detection/projects/self_training)\n\n**Exploring the Limits of Large Scale Pre-training**\n\n- intro: Google Research\n- arxiv: [https://arxiv.org/abs/2110.02095](https://arxiv.org/abs/2110.02095)\n\n# Transformers\n\n**Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet**\n\n- intro: National University of Singapore & YITU Technology\n- arxiv: [https://arxiv.org/abs/2101.11986](https://arxiv.org/abs/2101.11986)\n- github: [https://github.com/yitu-opensource/T2T-ViT](https://github.com/yitu-opensource/T2T-ViT)\n\n**Incorporating Convolution Designs into Visual Transformers**\n\n- intro: SenseTime Research & Nanyang Technological University\n- arxiv: [https://arxiv.org/abs/2103.11816](https://arxiv.org/abs/2103.11816)\n\n**DeepViT: Towards Deeper Vision Transformer**\n\n- intro: National University of Singapore & ByteDance US AI Lab\n- arxiv: [https://arxiv.org/abs/2103.11886](https://arxiv.org/abs/2103.11886)\n\n**Swin Transformer: Hierarchical Vision Transformer using Shifted Windows**\n\n- intro: ICCV 2021 best paper\n- intro: Microsoft Research Asia\n- arxiv: [https://arxiv.org/abs/2103.14030](https://arxiv.org/abs/2103.14030)\n- github: [https://github.com/microsoft/Swin-Transformer](https://github.com/microsoft/Swin-Transformer)\n\n**Rethinking the Design Principles of Robust Vision Transformer**\n\n- arxiv: [https://arxiv.org/abs/2105.07926](https://arxiv.org/abs/2105.07926)\n- github: [https://github.com/vtddggg/Robust-Vision-Transformer](https://github.com/vtddggg/Robust-Vision-Transformer)\n\n**Scale Efficiently: Insights from Pre-training and Fine-tuning Transformers**\n\n- intro: Google Research & DeepMind\n- arxiv: [https://arxiv.org/abs/2109.10686](https://arxiv.org/abs/2109.10686)\n\n**How Do Vision Transformers Work?**\n\n- intro: ICLR 2022 Spotlight\n- intro: Yonsei University & NAVER AI Lab\n- arxiv: [https://arxiv.org/abs/2202.06709](https://arxiv.org/abs/2202.06709)\n- github: [https://github.com/xxxnell/how-do-vits-work](https://github.com/xxxnell/how-do-vits-work)\n\n**MulT: An End-to-End Multitask Learning Transformer**\n\n- intro: CVPR 2022\n- project page: [https://ivrl.github.io/MulT/](https://ivrl.github.io/MulT/)\n- arxiv: [https://arxiv.org/abs/2205.08303](https://arxiv.org/abs/2205.08303)\n\n**EfficientFormer: Vision Transformers at MobileNet Speed**\n\n- intro: Snap Inc. & Northeastern University\n- arxiv: [https://arxiv.org/abs/2206.01191](https://arxiv.org/abs/2206.01191)\n- github: [https://github.com/snap-research/EfficientFormer](https://github.com/snap-research/EfficientFormer)\n\n**SimA: Simple Softmax-free Attention for Vision Transformers**\n\n- intro: University of Maryland & University of California\n- arxiv: [https://arxiv.org/abs/2206.08898](https://arxiv.org/abs/2206.08898)\n- gihtub: [https://github.com/UCDvision/sima](https://github.com/UCDvision/sima)\n\n# Semi-Supervised Learning\n\n**Semi-Supervised Learning with Graphs**\n\n- intro: Label Propagation\n- paper: [http://pages.cs.wisc.edu/~jerryzhu/pub/thesis.pdf](http://pages.cs.wisc.edu/~jerryzhu/pub/thesis.pdf)\n- blog(\"Label PropagationPython\"): [http://blog.csdn.net/zouxy09/article/details/49105265](http://blog.csdn.net/zouxy09/article/details/49105265)\n\n**Semi-Supervised Learning with Ladder Networks**\n\n- arxiv: [http://arxiv.org/abs/1507.02672](http://arxiv.org/abs/1507.02672)\n- github: [https://github.com/CuriousAI/ladder](https://github.com/CuriousAI/ladder)\n- github: [https://github.com/rinuboney/ladder](https://github.com/rinuboney/ladder)\n\n**Semi-supervised Feature Transfer: The Practical Benefit of Deep Learning Today?**\n\n- blog: [http://www.kdnuggets.com/2016/07/semi-supervised-feature-transfer-deep-learning.html](http://www.kdnuggets.com/2016/07/semi-supervised-feature-transfer-deep-learning.html)\n\n**Temporal Ensembling for Semi-Supervised Learning**\n\n- intro: ICLR 2017\n- arxiv: [https://arxiv.org/abs/1610.02242](https://arxiv.org/abs/1610.02242)\n- github: [https://github.com/smlaine2/tempens](https://github.com/smlaine2/tempens)\n\n**Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data**\n\n- intro: ICLR 2017 best paper award\n- arxiv: [https://arxiv.org/abs/1610.05755](https://arxiv.org/abs/1610.05755)\n- github: [https://github.com/tensorflow/models/tree/8505222ea1f26692df05e65e35824c6c71929bb5/privacy](https://github.com/tensorflow/models/tree/8505222ea1f26692df05e65e35824c6c71929bb5/privacy)\n\n**Infinite Variational Autoencoder for Semi-Supervised Learning**\n\n- arxiv: [https://arxiv.org/abs/1611.07800](https://arxiv.org/abs/1611.07800)\n\n# Multi-label Learning\n\n**CNN: Single-label to Multi-label**\n\n- arxiv: [http://arxiv.org/abs/1406.5726](http://arxiv.org/abs/1406.5726)\n\n**Deep Learning for Multi-label Classification**\n\n- arxiv: [http://arxiv.org/abs/1502.05988](http://arxiv.org/abs/1502.05988)\n- github: [http://meka.sourceforge.net](http://meka.sourceforge.net)\n\n**Predicting Unseen Labels using Label Hierarchies in Large-Scale Multi-label Learning**\n\n- intro: ECML 2015\n- paper: [https://www.kdsl.tu-darmstadt.de/fileadmin/user_upload/Group_KDSL/PUnL_ECML2015_camera_ready.pdf](https://www.kdsl.tu-darmstadt.de/fileadmin/user_upload/Group_KDSL/PUnL_ECML2015_camera_ready.pdf)\n\n**Learning with a Wasserstein Loss**\n\n- project page: [http://cbcl.mit.edu/wasserstein/](http://cbcl.mit.edu/wasserstein/)\n- arxiv: [http://arxiv.org/abs/1506.05439](http://arxiv.org/abs/1506.05439)\n- code: [http://cbcl.mit.edu/wasserstein/yfcc100m_labels.tar.gz](http://cbcl.mit.edu/wasserstein/yfcc100m_labels.tar.gz)\n- MIT news: [http://news.mit.edu/2015/more-flexible-machine-learning-1001](http://news.mit.edu/2015/more-flexible-machine-learning-1001)\n\n**From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification**\n\n- intro: ICML 2016\n- arxiv: [http://arxiv.org/abs/1602.02068](http://arxiv.org/abs/1602.02068)\n- github: [https://github.com/gokceneraslan/SparseMax.torch](https://github.com/gokceneraslan/SparseMax.torch)\n- github: [https://github.com/Unbabel/sparsemax](https://github.com/Unbabel/sparsemax)\n\n**CNN-RNN: A Unified Framework for Multi-label Image Classification**\n\n- arxiv: [http://arxiv.org/abs/1604.04573](http://arxiv.org/abs/1604.04573)\n\n**Improving Multi-label Learning with Missing Labels by Structured Semantic Correlations**\n\n- arxiv: [http://arxiv.org/abs/1608.01441](http://arxiv.org/abs/1608.01441)\n\n**Extreme Multi-label Loss Functions for Recommendation, Tagging, Ranking & Other Missing Label Applications**\n\n- intro: Indian Institute of Technology Delhi & MSR\n- paper: [https://manikvarma.github.io/pubs/jain16.pdf](https://manikvarma.github.io/pubs/jain16.pdf)\n\n**Multi-Label Image Classification with Regional Latent Semantic Dependencies**\n\n- intro: Regional Latent Semantic Dependencies model (RLSD), RNN, RPN\n- arxiv: [https://arxiv.org/abs/1612.01082](https://arxiv.org/abs/1612.01082)\n\n**Privileged Multi-label Learning**\n\n- intro: Peking University & University of Technology Sydney & University of Sydney\n- arxiv: [https://arxiv.org/abs/1701.07194](https://arxiv.org/abs/1701.07194)\n\n# Multi-task Learning\n\n**Multitask Learning / Domain Adaptation**\n\n- homepage: [http://www.cs.cornell.edu/~kilian/research/multitasklearning/multitasklearning.html](http://www.cs.cornell.edu/~kilian/research/multitasklearning/multitasklearning.html)\n\n**multi-task learning**\n\n- discussion: [https://github.com/memect/hao/issues/93](https://github.com/memect/hao/issues/93)\n\n**Learning and Transferring Multi-task Deep Representation for Face Alignment**\n\n- arxiv: [http://arxiv.org/abs/1408.3967](http://arxiv.org/abs/1408.3967)\n\n**Multi-task learning of facial landmarks and expression**\n\n- paper: [http://www.uoguelph.ca/~gwtaylor/publications/gwtaylor_crv2014.pdf](http://www.uoguelph.ca/~gwtaylor/publications/gwtaylor_crv2014.pdf)\n\n**Multi-Task Deep Visual-Semantic Embedding for Video Thumbnail Selection**\n\n- intro:  CVPR 2015\n- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Liu_Multi-Task_Deep_Visual-Semantic_2015_CVPR_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Liu_Multi-Task_Deep_Visual-Semantic_2015_CVPR_paper.pdf)\n\n**Learning Multiple Tasks with Deep Relationship Networks**\n\n- arxiv: [https://arxiv.org/abs/1506.02117](https://arxiv.org/abs/1506.02117)\n\n**Learning deep representation of multityped objects and tasks**\n\n- arxiv: [http://arxiv.org/abs/1603.01359](http://arxiv.org/abs/1603.01359)\n\n**Cross-stitch Networks for Multi-task Learning**\n\n- arxiv: [http://arxiv.org/abs/1604.03539](http://arxiv.org/abs/1604.03539)\n\n**Multi-Task Learning in Tensorflow (Part 1)**\n\n- blog: [https://jg8610.github.io/Multi-Task/](https://jg8610.github.io/Multi-Task/)\n\n**Deep Multi-Task Learning with Shared Memory**\n\n- intro: EMNLP 2016\n- arxiv: [http://arxiv.org/abs/1609.07222](http://arxiv.org/abs/1609.07222)\n\n**Learning to Push by Grasping: Using multiple tasks for effective learning**\n\n- arxiv: [http://arxiv.org/abs/1609.09025](http://arxiv.org/abs/1609.09025)\n\n**Identifying beneficial task relations for multi-task learning in deep neural networks**\n\n- intro: EACL 2017\n- arxiv: [https://arxiv.org/abs/1702.08303](https://arxiv.org/abs/1702.08303)\n- github: [https://github.com/jbingel/eacl2017_mtl](https://github.com/jbingel/eacl2017_mtl)\n\n**Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics**\n\n- intro: University of Cambridge\n- arxiv: [https://arxiv.org/abs/1705.07115](https://arxiv.org/abs/1705.07115)\n\n**One Model To Learn Them All**\n\n- intro: Google Brain & University of Toronto\n- arxiv: [https://arxiv.org/abs/1706.05137](https://arxiv.org/abs/1706.05137)\n- github: [https://github.com/tensorflow/tensor2tensor](https://github.com/tensorflow/tensor2tensor)\n\n**MultiModel: Multi-Task Machine Learning Across Domains**\n\n[https://research.googleblog.com/2017/06/multimodel-multi-task-machine-learning.html](https://research.googleblog.com/2017/06/multimodel-multi-task-machine-learning.html)\n\n**An Overview of Multi-Task Learning in Deep Neural Networks**\n\n- intro: Aylien Ltd\n- arxiv: [https://arxiv.org/abs/1706.05098](https://arxiv.org/abs/1706.05098)\n\n**PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning**\n\n- arxiv: [https://arxiv.org/abs/1711.05769](https://arxiv.org/abs/1711.05769)\n- github: [https://github.com/arunmallya/packnet](https://github.com/arunmallya/packnet)\n\n**End-to-End Multi-Task Learning with Attention**\n\n- intro: Imperial College London\n- arxiv: [https://arxiv.org/abs/1803.10704](https://arxiv.org/abs/1803.10704)\n\n**Cross-connected Networks for Multi-task Learning of Detection and Segmentation**\n\n[https://arxiv.org/abs/1805.05569](https://arxiv.org/abs/1805.05569)\n\n**Auxiliary Tasks in Multi-task Learning**\n\n[https://arxiv.org/abs/1805.06334](https://arxiv.org/abs/1805.06334)\n\n**K For The Price Of 1: Parameter Efficient Multi-task And Transfer Learning**\n\n- intro: The University of Chicago & Google\n- arxiv: [https://arxiv.org/abs/1810.10703](https://arxiv.org/abs/1810.10703)\n\n**Which Tasks Should Be Learned Together in Multi-task Learning?**\n\n- intro: ICML 2020\n- intro: Stanford\n- project page: [http://taskgrouping.stanford.edu/](http://taskgrouping.stanford.edu/)\n- arxiv: [https://arxiv.org/abs/1905.07553](https://arxiv.org/abs/1905.07553)\n\n**OmniNet: A unified architecture for multi-modal multi-task learning**\n\n- arxiv: [https://arxiv.org/abs/1907.07804](https://arxiv.org/abs/1907.07804)\n- github: [https://github.com/subho406/OmniNet](https://github.com/subho406/OmniNet)\n\n**Deep Elastic Networks with Model Selection for Multi-Task Learning**\n\n- intro: ICCV 2019\n- arxiv: [https://arxiv.org/abs/1909.04860](https://arxiv.org/abs/1909.04860)\n\n**AdaShare: Learning What To Share For Efficient Deep Multi-Task Learning**\n\n- intro: Boston University & IBM Research & MIT-IBM Watson AI Lab\n- arxiv: [https://arxiv.org/abs/1911.12423](https://arxiv.org/abs/1911.12423)\n\n**Multi-Task Learning for Dense Prediction Tasks: A Survey**\n\n- intro: T-PAMI\n- arxiv: [https://arxiv.org/abs/2004.13379](https://arxiv.org/abs/2004.13379)\n- github: [https://github.com/SimonVandenhende/Multi-Task-Learning-PyTorch](https://github.com/SimonVandenhende/Multi-Task-Learning-PyTorch)\n\n**MTI-Net: Multi-Scale Task Interaction Networks for Multi-Task Learning**\n\n- intro: ECCV 2020 spotlight\n- keywords: MTI-Net\n- arxiv: [https://arxiv.org/abs/2001.06902](https://arxiv.org/abs/2001.06902)\n- github: [https://github.com/SimonVandenhende/Multi-Task-Learning-PyTorch](https://github.com/SimonVandenhende/Multi-Task-Learning-PyTorch)\n\n**Exploring Relational Context for Multi-Task Dense Prediction**\n\n- intro: ETH Zurich\n- arxiv: [https://arxiv.org/abs/2104.13874](https://arxiv.org/abs/2104.13874)\n\n**Cross-task Attention Mechanism for Dense Multi-task Learning**\n\n- intro: Inria, France & Valeo.ai, France\n- arxiv: [https://arxiv.org/abs/2206.08927](https://arxiv.org/abs/2206.08927)\n- github: [https://github.com/cv-rits/DenseMTL](https://github.com/cv-rits/DenseMTL)\n\n# Multi-modal Learning\n\n**Multimodal Deep Learning**\n\n- paper: [http://ai.stanford.edu/~ang/papers/nipsdlufl10-MultimodalDeepLearning.pdf](http://ai.stanford.edu/~ang/papers/nipsdlufl10-MultimodalDeepLearning.pdf)\n\n**Multimodal Convolutional Neural Networks for Matching Image and Sentence**\n\n- homepage: [http://mcnn.noahlab.com.hk/project.html](http://mcnn.noahlab.com.hk/project.html)\n- paper: [http://mcnn.noahlab.com.hk/ICCV2015.pdf](http://mcnn.noahlab.com.hk/ICCV2015.pdf)\n- arxiv: [http://arxiv.org/abs/1504.06063](http://arxiv.org/abs/1504.06063)\n\n**A C++ library for Multimodal Deep Learning**\n\n- arxiv: [http://arxiv.org/abs/1512.06927](http://arxiv.org/abs/1512.06927)\n- github: [https://github.com/Jian-23/Deep-Learning-Library](https://github.com/Jian-23/Deep-Learning-Library)\n\n**Multimodal Learning for Image Captioning and Visual Question Answering**\n\n- slides: [http://research.microsoft.com/pubs/264769/UCB_XiaodongHe.6.pdf](http://research.microsoft.com/pubs/264769/UCB_XiaodongHe.6.pdf)\n\n**Multi modal retrieval and generation with deep distributed models**\n\n- slides: [http://www.slideshare.net/roelofp/multi-modal-retrieval-and-generation-with-deep-distributed-models](http://www.slideshare.net/roelofp/multi-modal-retrieval-and-generation-with-deep-distributed-models)\n- slides: [http://pan.baidu.com/s/1kUSjn4z](http://pan.baidu.com/s/1kUSjn4z)\n\n**Learning Aligned Cross-Modal Representations from Weakly Aligned Data**\n\n![](http://projects.csail.mit.edu/cmplaces/imgs/teaser.png)\n\n- homepage: [http://projects.csail.mit.edu/cmplaces/index.html](http://projects.csail.mit.edu/cmplaces/index.html)\n- paper: [http://projects.csail.mit.edu/cmplaces/content/paper.pdf](http://projects.csail.mit.edu/cmplaces/content/paper.pdf)\n\n**Variational methods for Conditional Multimodal Deep Learning**\n\n- arxiv: [http://arxiv.org/abs/1603.01801](http://arxiv.org/abs/1603.01801)\n\n**Training and Evaluating Multimodal Word Embeddings with Large-scale Web Annotated Images**\n\n- intro: NIPS 2016. University of California & Pinterest\n- project page: [http://www.stat.ucla.edu/~junhua.mao/multimodal_embedding.html](http://www.stat.ucla.edu/~junhua.mao/multimodal_embedding.html)\n- arxiv: [https://arxiv.org/abs/1611.08321](https://arxiv.org/abs/1611.08321)\n\n**Deep Multi-Modal Image Correspondence Learning**\n\n- arxiv: [https://arxiv.org/abs/1612.01225](https://arxiv.org/abs/1612.01225)\n\n**Multimodal Deep Learning (D4L4 Deep Learning for Speech and Language UPC 2017)**\n\n- slides: [http://www.slideshare.net/xavigiro/multimodal-deep-learning-d4l4-deep-learning-for-speech-and-language-upc-2017](http://www.slideshare.net/xavigiro/multimodal-deep-learning-d4l4-deep-learning-for-speech-and-language-upc-2017)\n\n**Multimodal Learning with Transformers: A Survey**\n\n- intro: University of Oxford & University of Surrey\n- arxiv: [https://arxiv.org/abs/2206.06488](https://arxiv.org/abs/2206.06488)\n\n# Debugging Deep Learning\n\n**Some tips for debugging deep learning**\n\n- blog: [http://www.lab41.org/some-tips-for-debugging-in-deep-learning-2/](http://www.lab41.org/some-tips-for-debugging-in-deep-learning-2/)\n\n**Introduction to debugging neural networks**\n\n- blog: [http://russellsstewart.com/notes/0.html](http://russellsstewart.com/notes/0.html)\n- reddit: [https://www.reddit.com/r/MachineLearning/comments/4du7gv/introduction_to_debugging_neural_networks](https://www.reddit.com/r/MachineLearning/comments/4du7gv/introduction_to_debugging_neural_networks)\n\n**How to Visualize, Monitor and Debug Neural Network Learning**\n\n- blog: [http://deeplearning4j.org/visualization](http://deeplearning4j.org/visualization)\n\n**Learning from learning curves**\n\n- intro: Kaggle\n- blog: [https://medium.com/@dsouza.amanda/learning-from-learning-curves-1a82c6f98f49#.o5synrvvl](https://medium.com/@dsouza.amanda/learning-from-learning-curves-1a82c6f98f49#.o5synrvvl)\n\n# Understanding CNN\n\n**Understanding the Effective Receptive Field in Deep Convolutional Neural Networks**\n\n- intro: NIPS 2016\n- paper: [http://www.cs.toronto.edu/~wenjie/papers/nips16/top.pdf](http://www.cs.toronto.edu/~wenjie/papers/nips16/top.pdf)\n\n# Deep Learning Networks\n\n**PCANet: A Simple Deep Learning Baseline for Image Classification?**\n\n- arixv: [http://arxiv.org/abs/1404.3606](http://arxiv.org/abs/1404.3606)\n- code(Matlab): [http://mx.nthu.edu.tw/~tsunghan/download/PCANet_demo_pyramid.rar](http://mx.nthu.edu.tw/~tsunghan/download/PCANet_demo_pyramid.rar)\n- mirror: [http://pan.baidu.com/s/1mg24b3a](http://pan.baidu.com/s/1mg24b3a)\n- github(C++): [https://github.com/Ldpe2G/PCANet](https://github.com/Ldpe2G/PCANet)\n- github(Python): [https://github.com/IshitaTakeshi/PCANet](https://github.com/IshitaTakeshi/PCANet)\n\n**Convolutional Kernel Networks**\n\n- intro: NIPS 2014\n- arxiv: [http://arxiv.org/abs/1406.3332](http://arxiv.org/abs/1406.3332)\n\n**Deeply-supervised Nets**\n\n- intro: DSN\n- arxiv: [http://arxiv.org/abs/1409.5185](http://arxiv.org/abs/1409.5185)\n- homepage: [http://vcl.ucsd.edu/~sxie/2014/09/12/dsn-project/](http://vcl.ucsd.edu/~sxie/2014/09/12/dsn-project/)\n- github: [https://github.com/s9xie/DSN](https://github.com/s9xie/DSN)\n- notes: [http://zhangliliang.com/2014/11/02/paper-note-dsn/](http://zhangliliang.com/2014/11/02/paper-note-dsn/)\n\n**FitNets: Hints for Thin Deep Nets**\n\n- arxiv: [https://arxiv.org/abs/1412.6550](https://arxiv.org/abs/1412.6550)\n- github: [https://github.com/adri-romsor/FitNets](https://github.com/adri-romsor/FitNets)\n\n**Striving for Simplicity: The All Convolutional Net**\n\n- intro: ICLR-2015 workshop\n- arxiv: [http://arxiv.org/abs/1412.6806](http://arxiv.org/abs/1412.6806)\n\n**How these researchers tried something unconventional to come out with a smaller yet better Image Recognition.**\n\n- intro: All Convolutional Network: (https://arxiv.org/abs/1412.6806#) implementation in Keras\n- blog: [https://medium.com/@matelabs_ai/how-these-researchers-tried-something-unconventional-to-came-out-with-a-smaller-yet-better-image-544327f30e72#.pfdbvdmuh](https://medium.com/@matelabs_ai/how-these-researchers-tried-something-unconventional-to-came-out-with-a-smaller-yet-better-image-544327f30e72#.pfdbvdmuh)\n- blog: [https://github.com/MateLabs/All-Conv-Keras](https://github.com/MateLabs/All-Conv-Keras)\n\n**Pointer Networks**\n\n- arxiv: [https://arxiv.org/abs/1506.03134](https://arxiv.org/abs/1506.03134)\n- github: [https://github.com/vshallc/PtrNets](https://github.com/vshallc/PtrNets)\n- github(TensorFlow): [https://github.com/ikostrikov/TensorFlow-Pointer-Networks](https://github.com/ikostrikov/TensorFlow-Pointer-Networks)\n- github(TensorFlow): [https://github.com/devsisters/pointer-network-tensorflow](https://github.com/devsisters/pointer-network-tensorflow)\n- notes: [https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/pointer-networks.md](https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/pointer-networks.md)\n\n**Pointer Networks in TensorFlow (with sample code)**\n\n- blog: [https://medium.com/@devnag/pointer-networks-in-tensorflow-with-sample-code-14645063f264#.sxipqfj30](https://medium.com/@devnag/pointer-networks-in-tensorflow-with-sample-code-14645063f264#.sxipqfj30)\n- github: [https://github.com/devnag/tensorflow-pointer-networks](https://github.com/devnag/tensorflow-pointer-networks)\n\n**Rectified Factor Networks**\n\n- arxiv: [http://arxiv.org/abs/1502.06464](http://arxiv.org/abs/1502.06464)\n- github: [https://github.com/untom/librfn](https://github.com/untom/librfn)\n\n**Correlational Neural Networks**\n\n- arxiv: [http://arxiv.org/abs/1504.07225](http://arxiv.org/abs/1504.07225)\n- github: [https://github.com/apsarath/CorrNet](https://github.com/apsarath/CorrNet)\n\n**Diversity Networks**\n\n- arxiv: [http://arxiv.org/abs/1511.05077](http://arxiv.org/abs/1511.05077)\n\n**Competitive Multi-scale Convolution**\n\n- arxiv: [http://arxiv.org/abs/1511.05635](http://arxiv.org/abs/1511.05635)\n- blog: [https://zhuanlan.zhihu.com/p/22377389](https://zhuanlan.zhihu.com/p/22377389)\n\n**A Unified Approach for Learning the Parameters of Sum-Product Networks (SPN)**\n\n- intro: \"The Sum-Product Network (SPN) is a new type of machine learning model \nwith fast exact probabilistic inference over many layers.\"\n- arxiv: [http://arxiv.org/abs/1601.00318](http://arxiv.org/abs/1601.00318)\n- homepage: [http://spn.cs.washington.edu/index.shtml](http://spn.cs.washington.edu/index.shtml)\n- code: [http://spn.cs.washington.edu/code.shtml](http://spn.cs.washington.edu/code.shtml)\n\n**Awesome Sum-Product Networks**\n\n- github: [https://github.com/arranger1044/awesome-spn](https://github.com/arranger1044/awesome-spn)\n\n**Recombinator Networks: Learning Coarse-to-Fine Feature Aggregation**\n\n- intro: CVPR 2016\n- arxiv: [http://arxiv.org/abs/1511.07356](http://arxiv.org/abs/1511.07356)\n- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Honari_Recombinator_Networks_Learning_CVPR_2016_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Honari_Recombinator_Networks_Learning_CVPR_2016_paper.pdf)\n- github: [https://github.com/SinaHonari/RCN](https://github.com/SinaHonari/RCN)\n\n**Dynamic Capacity Networks**\n\n- intro: ICML 2016\n- arxiv: [http://arxiv.org/abs/1511.07838](http://arxiv.org/abs/1511.07838)\n- github(Tensorflow): [https://github.com/beopst/dcn.tf](https://github.com/beopst/dcn.tf)\n- review: [http://www.erogol.com/1314-2/](http://www.erogol.com/1314-2/)\n\n**Bitwise Neural Networks**\n\n- paper: [http://paris.cs.illinois.edu/pubs/minje-icmlw2015.pdf](http://paris.cs.illinois.edu/pubs/minje-icmlw2015.pdf)\n- demo: [http://minjekim.com/demo_bnn.html](http://minjekim.com/demo_bnn.html)\n\n**Learning Discriminative Features via Label Consistent Neural Network**\n\n- arxiv: [http://arxiv.org/abs/1602.01168](http://arxiv.org/abs/1602.01168)\n\n**A Theory of Generative ConvNet**\n\n- project page: [http://www.stat.ucla.edu/~ywu/GenerativeConvNet/main.html](http://www.stat.ucla.edu/~ywu/GenerativeConvNet/main.html)\n- arxiv: [http://arxiv.org/abs/1602.03264](http://arxiv.org/abs/1602.03264)\n- code: [http://www.stat.ucla.edu/~ywu/GenerativeConvNet/doc/code.zip](http://www.stat.ucla.edu/~ywu/GenerativeConvNet/doc/code.zip)\n\n**How to Train Deep Variational Autoencoders and Probabilistic Ladder Networks**\n\n- arxiv: [http://arxiv.org/abs/1602.02282](http://arxiv.org/abs/1602.02282)\n\n**Group Equivariant Convolutional Networks (G-CNNs)**\n\n- arxiv: [http://arxiv.org/abs/1602.07576](http://arxiv.org/abs/1602.07576)\n\n**Deep Spiking Networks**\n\n- arxiv: [http://arxiv.org/abs/1602.08323](http://arxiv.org/abs/1602.08323)\n- github: [https://github.com/petered/spiking-mlp](https://github.com/petered/spiking-mlp)\n\n**Low-rank passthrough neural networks**\n\n- arxiv: [http://arxiv.org/abs/1603.03116](http://arxiv.org/abs/1603.03116)\n- github: [https://github.com/Avmb/lowrank-gru](https://github.com/Avmb/lowrank-gru)\n\n**Single Image 3D Interpreter Network**\n\n- intro: ECCV 2016 (oral)\n- arxiv: [https://arxiv.org/abs/1604.08685](https://arxiv.org/abs/1604.08685)\n\n**Deeply-Fused Nets**\n\n- arxiv: [http://arxiv.org/abs/1605.07716](http://arxiv.org/abs/1605.07716)\n\n**SNN: Stacked Neural Networks**\n\n- arxiv: [http://arxiv.org/abs/1605.08512](http://arxiv.org/abs/1605.08512)\n\n**Universal Correspondence Network**\n\n- intro: NIPS 2016 full oral presentation. Stanford University & NEC Laboratories America\n- project page: [http://cvgl.stanford.edu/projects/ucn/](http://cvgl.stanford.edu/projects/ucn/)\n- arxiv: [https://arxiv.org/abs/1606.03558](https://arxiv.org/abs/1606.03558)\n\n**Progressive Neural Networks**\n\n- intro: Google DeepMind\n- arxiv: [https://arxiv.org/abs/1606.04671](https://arxiv.org/abs/1606.04671)\n- github: [https://github.com/synpon/prog_nn](https://github.com/synpon/prog_nn)\n- github: [https://github.com/yao62995/A3C](https://github.com/yao62995/A3C)\n\n**Holistic SparseCNN: Forging the Trident of Accuracy, Speed, and Size**\n\n- arxiv: [http://arxiv.org/abs/1608.01409](http://arxiv.org/abs/1608.01409)\n\n**Mollifying Networks**\n\n- author: Caglar Gulcehre, Marcin Moczulski, Francesco Visin, Yoshua Bengio\n- arxiv: [http://arxiv.org/abs/1608.04980](http://arxiv.org/abs/1608.04980)\n\n**Domain Separation Networks**\n\n- intro: NIPS 2016\n- intro: Google Brain & Imperial College London & Google Research\n- arxiv: [https://arxiv.org/abs/1608.06019](https://arxiv.org/abs/1608.06019)\n- github: [https://github.com/tensorflow/models/tree/master/domain_adaptation](https://github.com/tensorflow/models/tree/master/domain_adaptation)\n\n**Local Binary Convolutional Neural Networks**\n\n- arxiv: [http://arxiv.org/abs/1608.06049](http://arxiv.org/abs/1608.06049)\n\n**CliqueCNN: Deep Unsupervised Exemplar Learning**\n\n- intro: NIPS 2016\n- arxiv: [http://arxiv.org/abs/1608.08792](http://arxiv.org/abs/1608.08792)\n- github: [https://github.com/asanakoy/cliquecnn](https://github.com/asanakoy/cliquecnn)\n\n**Convexified Convolutional Neural Networks**\n\n- arxiv: [http://arxiv.org/abs/1609.01000](http://arxiv.org/abs/1609.01000)\n\n**Multi-scale brain networks**\n\n- arxiv: [http://arxiv.org/abs/1608.08828](http://arxiv.org/abs/1608.08828)\n\n[https://arxiv.org/abs/1711.11473](https://arxiv.org/abs/1711.11473)\n\n**Input Convex Neural Networks**\n\n- arxiv: [http://arxiv.org/abs/1609.07152](http://arxiv.org/abs/1609.07152)\n- github: [https://github.com/locuslab/icnn](https://github.com/locuslab/icnn)\n\n**HyperNetworks**\n\n- arxiv: [https://arxiv.org/abs/1609.09106](https://arxiv.org/abs/1609.09106)\n- blog: [http://blog.otoro.net/2016/09/28/hyper-networks/](http://blog.otoro.net/2016/09/28/hyper-networks/)\n- github: [https://github.com/hardmaru/supercell/blob/master/assets/MNIST_Static_HyperNetwork_Example.ipynb](https://github.com/hardmaru/supercell/blob/master/assets/MNIST_Static_HyperNetwork_Example.ipynb)\n\n**HyperLSTM**\n\n- github: [https://github.com/hardmaru/supercell/blob/master/supercell.py](https://github.com/hardmaru/supercell/blob/master/supercell.py)\n\n**X-CNN: Cross-modal Convolutional Neural Networks for Sparse Datasets**\n\n- arxiv: [https://arxiv.org/abs/1610.00163](https://arxiv.org/abs/1610.00163)\n\n**Tensor Switching Networks**\n\n- intro: NIPS 2016\n- arixiv: [https://arxiv.org/abs/1610.10087](https://arxiv.org/abs/1610.10087)\n- github: [https://github.com/coxlab/tsnet](https://github.com/coxlab/tsnet)\n\n**BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks**\n\n- intro: Harvard University\n- paper: [http://www.eecs.harvard.edu/~htk/publication/2016-icpr-teerapittayanon-mcdanel-kung.pdf](http://www.eecs.harvard.edu/~htk/publication/2016-icpr-teerapittayanon-mcdanel-kung.pdf)\n- github: [https://github.com/kunglab/branchynet](https://github.com/kunglab/branchynet)\n\n**Spectral Convolution Networks**\n\n- arxiv: [https://arxiv.org/abs/1611.05378](https://arxiv.org/abs/1611.05378)\n\n**DelugeNets: Deep Networks with Massive and Flexible Cross-layer Information Inflows**\n\n- arxiv: [https://arxiv.org/abs/1611.05552](https://arxiv.org/abs/1611.05552)\n- github: [https://github.com/xternalz/DelugeNets](https://github.com/xternalz/DelugeNets)\n\n**PolyNet: A Pursuit of Structural Diversity in Very Deep Networks**\n\n- arxiv: [https://arxiv.org/abs/1611.05725](https://arxiv.org/abs/1611.05725)\n- poster: [http://mmlab.ie.cuhk.edu.hk/projects/cu_deeplink/polynet_poster.pdf](http://mmlab.ie.cuhk.edu.hk/projects/cu_deeplink/polynet_poster.pdf)\n\n**Weakly Supervised Cascaded Convolutional Networks**\n\n- arxiv: [https://arxiv.org/abs/1611.08258](https://arxiv.org/abs/1611.08258)\n\n**DeepSetNet: Predicting Sets with Deep Neural Networks**\n\n- intro: multi-class image classification and pedestrian detection\n- arxiv: [https://arxiv.org/abs/1611.08998](https://arxiv.org/abs/1611.08998)\n\n**Steerable CNNs**\n\n- intro: University of Amsterdam\n- arxiv: [https://arxiv.org/abs/1612.08498](https://arxiv.org/abs/1612.08498)\n\n**Feedback Networks**\n\n- project page: [http://feedbacknet.stanford.edu/](http://feedbacknet.stanford.edu/)\n- arxiv: [https://arxiv.org/abs/1612.09508](https://arxiv.org/abs/1612.09508)\n- youtube: [https://youtu.be/MY5Uhv38Ttg](https://youtu.be/MY5Uhv38Ttg)\n\n**Oriented Response Networks**\n\n- arxiv: [https://arxiv.org/abs/1701.01833](https://arxiv.org/abs/1701.01833)\n\n**OptNet: Differentiable Optimization as a Layer in Neural Networks**\n\n- arxiv: [https://arxiv.org/abs/1703.00443](https://arxiv.org/abs/1703.00443)\n- github: [https://github.com/locuslab/optnet](https://github.com/locuslab/optnet)\n\n**A fast and differentiable QP solver for PyTorch**\n\n- github: [https://github.com/locuslab/qpth](https://github.com/locuslab/qpth)\n\n**Meta Networks**\n\n[https://arxiv.org/abs/1703.00837](https://arxiv.org/abs/1703.00837)\n\n**Deformable Convolutional Networks**\n\n- intro: ICCV 2017 oral. Microsoft Research Asia\n- keywords: deformable convolution, deformable RoI pooling\n- arxiv: [https://arxiv.org/abs/1703.06211](https://arxiv.org/abs/1703.06211)\n- sliedes: [http://www.jifengdai.org/slides/Deformable_Convolutional_Networks_Oral.pdf](http://www.jifengdai.org/slides/Deformable_Convolutional_Networks_Oral.pdf)\n- github(official): [https://github.com/msracver/Deformable-ConvNets](https://github.com/msracver/Deformable-ConvNets)\n- github: [https://github.com/felixlaumon/deform-conv](https://github.com/felixlaumon/deform-conv)\n- github: [https://github.com/oeway/pytorch-deform-conv](https://github.com/oeway/pytorch-deform-conv)\n\nDeformable ConvNets v2: More Deformable, Better Results**\n\n- intro: University of Science and Technology of China & Microsoft Research Asia\n- keywords: DCNv2\n- arxiv: [https://arxiv.org/abs/1811.11168](https://arxiv.org/abs/1811.11168)\n- github: [https://github.com/msracver/Deformable-ConvNets/tree/master/DCNv2_op](https://github.com/msracver/Deformable-ConvNets/tree/master/DCNv2_op)\n\n**Second-order Convolutional Neural Networks**\n\n[https://arxiv.org/abs/1703.06817](https://arxiv.org/abs/1703.06817)\n\n**Gabor Convolutional Networks**\n\n[https://arxiv.org/abs/1705.01450](https://arxiv.org/abs/1705.01450)\n\n**Deep Rotation Equivariant Network**\n\n[https://arxiv.org/abs/1705.08623](https://arxiv.org/abs/1705.08623)\n\n**Dense Transformer Networks**\n\n- intro: Washington State University & University of California, Davis\n- arxiv: [https://arxiv.org/abs/1705.08881](https://arxiv.org/abs/1705.08881)\n- github: [https://github.com/divelab/dtn](https://github.com/divelab/dtn)\n\n**Deep Complex Networks**\n\n- intro: [Universit de Montral & INRS-EMT & Microsoft Maluuba\n- arxiv: [https://arxiv.org/abs/1705.09792](https://arxiv.org/abs/1705.09792)\n- github: [https://github.com/ChihebTrabelsi/deep_complex_networks](https://github.com/ChihebTrabelsi/deep_complex_networks)\n\n**Deep Quaternion Networks**\n\n- intro: University of Louisiana\n- arxiv: [https://arxiv.org/abs/1712.04604](https://arxiv.org/abs/1712.04604)\n\n**DiracNets: Training Very Deep Neural Networks Without Skip-Connections**\n\n- intro: Universit Paris-Est\n- arxiv: [https://arxiv.org/abs/1706.00388](https://arxiv.org/abs/1706.00388)\n- github: [https://github.com/szagoruyko/diracnets](https://github.com/szagoruyko/diracnets)\n\n**Dual Path Networks**\n\n- intro: National University of Singapore\n- arxiv: [https://arxiv.org/abs/1707.01629](https://arxiv.org/abs/1707.01629)\n- github(MXNet): [https://github.com/cypw/DPNs](https://github.com/cypw/DPNs)\n\n**Primal-Dual Group Convolutions for Deep Neural Networks**\n\n**Interleaved Group Convolutions for Deep Neural Networks**\n\n- intro: ICCV 2017\n- keywords: interleaved group convolutional neural networks (IGCNets), IGCV1\n- arxiv: [https://arxiv.org/abs/1707.02725](https://arxiv.org/abs/1707.02725)\n- gihtub: [https://github.com/hellozting/InterleavedGroupConvolutions](https://github.com/hellozting/InterleavedGroupConvolutions)\n\n**IGCV2: Interleaved Structured Sparse Convolutional Neural Networks**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1804.06202](https://arxiv.org/abs/1804.06202)\n\n**IGCV3: Interleaved Low-Rank Group Convolutions for Efficient Deep Neural Networks**\n\n- intro: University of Scinence and Technology of China & Microsoft Reserach Asia\n- arxiv: [https://arxiv.org/abs/1806.00178](https://arxiv.org/abs/1806.00178)\n- github(official): [https://github.com/homles11/IGCV3](https://github.com/homles11/IGCV3)\n\n**Sensor Transformation Attention Networks**\n\n[https://arxiv.org/abs/1708.01015](https://arxiv.org/abs/1708.01015)\n\n**Sparsity Invariant CNNs**\n\n[https://arxiv.org/abs/1708.06500](https://arxiv.org/abs/1708.06500)\n\n**SPARCNN: SPAtially Related Convolutional Neural Networks**\n\n[https://arxiv.org/abs/1708.07522](https://arxiv.org/abs/1708.07522)\n\n**BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks**\n\n[https://arxiv.org/abs/1709.01686](https://arxiv.org/abs/1709.01686)\n\n**Polar Transformer Networks**\n\n[https://arxiv.org/abs/1709.01889](https://arxiv.org/abs/1709.01889)\n\n**Tensor Product Generation Networks**\n\n[https://arxiv.org/abs/1709.09118](https://arxiv.org/abs/1709.09118)\n\n**Deep Competitive Pathway Networks**\n\n- intro: ACML 2017\n- arxiv: [https://arxiv.org/abs/1709.10282](https://arxiv.org/abs/1709.10282)\n- github: [https://github.com/JiaRenChang/CoPaNet](https://github.com/JiaRenChang/CoPaNet)\n\n**Context Embedding Networks**\n\n[https://arxiv.org/abs/1710.01691](https://arxiv.org/abs/1710.01691)\n\n**Generalization in Deep Learning**\n\n- intro: MIT & University of Montreal\n- arxiv: [https://arxiv.org/abs/1710.05468](https://arxiv.org/abs/1710.05468)\n\n**Understanding Deep Learning Generalization by Maximum Entropy**\n\n- intro: University of Science and Technology of China & Beijing Jiaotong University & Chinese Academy of Sciences\n- arxiv: [https://arxiv.org/abs/1711.07758](https://arxiv.org/abs/1711.07758)\n\n**Do Convolutional Neural Networks Learn Class Hierarchy?**\n\n- intro: Bosch Research North America & Michigan State University\n- arxiv: [https://arxiv.org/abs/1710.06501](https://arxiv.org/abs/1710.06501)\n- video demo: [https://vimeo.com/228263798](https://vimeo.com/228263798)\n\n**Deep Hyperspherical Learning**\n\n- intro: NIPS 2017\n- arxiv: [https://arxiv.org/abs/1711.03189](https://arxiv.org/abs/1711.03189)\n\n**Beyond Sparsity: Tree Regularization of Deep Models for Interpretability**\n\n- intro: AAAI 2018\n- arxiv: [https://arxiv.org/abs/1711.06178](https://arxiv.org/abs/1711.06178)\n\n**Neural Motifs: Scene Graph Parsing with Global Context**\n\n- keywords: Stacked Motif Networks\n- arxiv: [https://arxiv.org/abs/1711.06640](https://arxiv.org/abs/1711.06640)\n\n**Priming Neural Networks**\n\n[https://arxiv.org/abs/1711.05918](https://arxiv.org/abs/1711.05918)\n\n**Three Factors Influencing Minima in SGD**\n\n[https://arxiv.org/abs/1711.04623](https://arxiv.org/abs/1711.04623)\n\n**BPGrad: Towards Global Optimality in Deep Learning via Branch and Pruning**\n\n[https://arxiv.org/abs/1711.06959](https://arxiv.org/abs/1711.06959)\n\n**BlockDrop: Dynamic Inference Paths in Residual Networks**\n\n- intro: UMD & UT Austin & IBM Research & Fusemachines Inc.\n- arxiv: [https://arxiv.org/abs/1711.08393](https://arxiv.org/abs/1711.08393)\n\n**Wasserstein Introspective Neural Networks**\n\n[https://arxiv.org/abs/1711.08875](https://arxiv.org/abs/1711.08875)\n\n**SkipNet: Learning Dynamic Routing in Convolutional Networks**\n\n[https://arxiv.org/abs/1711.09485](https://arxiv.org/abs/1711.09485)\n\n**Do Convolutional Neural Networks act as Compositional Nearest Neighbors?**\n\n- intro: CMU & West Virginia University\n- arxiv: [https://arxiv.org/abs/1711.10683](https://arxiv.org/abs/1711.10683)\n\n**ConvNets and ImageNet Beyond Accuracy: Explanations, Bias Detection, Adversarial Examples and Model Criticism**\n\n- intro: Facebook AI Research\n- arxiv: [https://arxiv.org/abs/1711.11443](https://arxiv.org/abs/1711.11443)\n\n**Broadcasting Convolutional Network**\n\n[https://arxiv.org/abs/1712.02517](https://arxiv.org/abs/1712.02517)\n\n**Point-wise Convolutional Neural Network**\n\n- intro: Singapore University of Technology and Design\n- arxiv: [https://arxiv.org/abs/1712.05245](https://arxiv.org/abs/1712.05245)\n\n**ScreenerNet: Learning Curriculum for Neural Networks**\n\n- intro: Intel Corporation & Allen Institute for Artificial Intelligence\n- keywords: curricular learning, deep learning, deep q-learning\n- arxiv: [https://arxiv.org/abs/1801.00904](https://arxiv.org/abs/1801.00904)\n\n**Sparsely Connected Convolutional Networks**\n\n[https://arxiv.org/abs/1801.05895](https://arxiv.org/abs/1801.05895)\n\n**Spherical CNNs**\n\n- intro: ICLR 2018 best paper award. University of Amsterdam & EPFL\n- arxiv: [https://arxiv.org/abs/1801.10130](https://arxiv.org/abs/1801.10130)\n- github(official, PyTorch): [https://github.com/jonas-koehler/s2cnn](https://github.com/jonas-koehler/s2cnn)\n\n**Going Deeper in Spiking Neural Networks: VGG and Residual Architectures**\n\n- intro: Purdue University & Oculus Research & Facebook Research\n- arxiv: [https://arxiv.org/abs/1802.02627](https://arxiv.org/abs/1802.02627)\n\n**Rotate your Networks: Better Weight Consolidation and Less Catastrophic Forgetting**\n\n[https://arxiv.org/abs/1802.02950](https://arxiv.org/abs/1802.02950)\n\n**Convolutional Neural Networks with Alternately Updated Clique**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1802.10419](https://arxiv.org/abs/1802.10419)\n- github: [https://github.com/iboing/CliqueNet](https://github.com/iboing/CliqueNet)\n\n**Decoupled Networks**\n\n- intro: CVPR 2018 (Spotlight)\n- arxiv: [https://arxiv.org/abs/1804.08071](https://arxiv.org/abs/1804.08071)\n\n**Optical Neural Networks**\n\n[https://arxiv.org/abs/1805.06082](https://arxiv.org/abs/1805.06082)\n\n**Regularization Learning Networks**\n\n- intro: Weizmann Institute of Science\n- keywords: Regularization Learning Networks (RLNs), Counterfactual Loss, tabular datasets\n- arxiv: [https://arxiv.org/abs/1805.06440](https://arxiv.org/abs/1805.06440)\n\n**Bilinear Attention Networks**\n\n[https://arxiv.org/abs/1805.07932](https://arxiv.org/abs/1805.07932)\n\n**Cautious Deep Learning**\n\n[https://arxiv.org/abs/1805.09460](https://arxiv.org/abs/1805.09460)\n\n**Perturbative Neural Networks**\n\n- intro: CVPR 2018\n- intro: We introduce a very simple, yet effective, module called a perturbation layer as an alternative to a convolutional layer\n- project page: [http://xujuefei.com/pnn.html](http://xujuefei.com/pnn.html)\n- arxiv: [https://arxiv.org/abs/1806.01817](https://arxiv.org/abs/1806.01817)\n\n**Lightweight Probabilistic Deep Networks**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1805.11327](https://arxiv.org/abs/1805.11327)\n\n**Channel Gating Neural Networks**\n\n[https://arxiv.org/abs/1805.12549](https://arxiv.org/abs/1805.12549)\n\n**Evenly Cascaded Convolutional Networks**\n\n[https://arxiv.org/abs/1807.00456](https://arxiv.org/abs/1807.00456)\n\n**SGAD: Soft-Guided Adaptively-Dropped Neural Network**\n\n[https://arxiv.org/abs/1807.01430](https://arxiv.org/abs/1807.01430)\n\n**Explainable Neural Computation via Stack Neural Module Networks**\n\n- intro: ECCV 2018\n- arxiv: [https://arxiv.org/abs/1807.08556](https://arxiv.org/abs/1807.08556)\n\n**Rank-1 Convolutional Neural Network**\n\n[https://arxiv.org/abs/1808.04303](https://arxiv.org/abs/1808.04303)\n\n**Neural Network Encapsulation**\n\n- intro: ECCV 2018\n- arxiv: [https://arxiv.org/abs/1808.03749](https://arxiv.org/abs/1808.03749)\n\n**Penetrating the Fog: the Path to Efficient CNN Models**\n\n[https://arxiv.org/abs/1810.04231](https://arxiv.org/abs/1810.04231)\n\n**A2-Nets: Double Attention Networks**\n\n- intro: NIPS 2018\n- arxiv: [https://arxiv.org/abs/1810.11579](https://arxiv.org/abs/1810.11579)\n\n**Global Second-order Pooling Neural Networks**\n\n[https://arxiv.org/abs/1811.12006](https://arxiv.org/abs/1811.12006)\n\n**ESPNetv2: A Light-weight, Power Efficient, and General Purpose Convolutional Neural Network**\n\n- intro: University of Washington & Allen Institute for AI (AI2) & XNOR.AI\n- arxiv: [https://arxiv.org/abs/1811.11431](https://arxiv.org/abs/1811.11431)\n- github: [https://github.com/sacmehta/ESPNetv2](https://github.com/sacmehta/ESPNetv2)\n\n**Kernel Transformer Networks for Compact Spherical Convolution**\n\n[https://arxiv.org/abs/1812.03115](https://arxiv.org/abs/1812.03115)\n\n**UAN: Unified Attention Network for Convolutional Neural Networks**\n\n[https://arxiv.org/abs/1901.05376](https://arxiv.org/abs/1901.05376)\n\n**One-Class Convolutional Neural Network**\n\n- intro: Johns Hopkins University\n- arxiv: [https://arxiv.org/abs/1901.08688](https://arxiv.org/abs/1901.08688)\n- github: [https://github.com/otkupjnoz/oc-cnn](https://github.com/otkupjnoz/oc-cnn)\n\n**Selective Kernel Networks**\n\n- intro: CVPR 2019\n- inrtro: Nanjing University of Science and Technology & Momenta & Nanjing University & Tsinghua University]\n- arxiv: [https://arxiv.org/abs/1903.06586](https://arxiv.org/abs/1903.06586)\n- github: [https://github.com/implus/SKNet](https://github.com/implus/SKNet)\n\n**Universally Slimmable Networks and Improved Training Techniques**\n\n- intro: ICLR 2019\n- arxiv: [https://arxiv.org/abs/1903.05134](https://arxiv.org/abs/1903.05134)\n\n**Dynamic Slimmable Network**\n\n- intro: CVPR 2021 oral\n- arxiv: [https://arxiv.org/abs/2103.13258](https://arxiv.org/abs/2103.13258)\n- github: [https://github.com/changlin31/DS-Net](https://github.com/changlin31/DS-Net)\n\n**Adaptively Connected Neural Networks**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1904.03579](https://arxiv.org/abs/1904.03579)\n- github: [https://github.com/wanggrun/Adaptively-Connected-Neural-Networks](https://github.com/wanggrun/Adaptively-Connected-Neural-Networks)\n\n**Transformable Bottleneck Networks**\n\n[https://arxiv.org/abs/1904.06458](https://arxiv.org/abs/1904.06458)\n\n**Pixel-Adaptive Convolutional Neural Networks**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1904.05373](https://arxiv.org/abs/1904.05373)\n\n**Attention Augmented Convolutional Networks**\n\n- intro: Google Brain\n- arxiv: [https://arxiv.org/abs/1904.09925](https://arxiv.org/abs/1904.09925)\n\n**Spatial Group-wise Enhance: Improving Semantic Feature Learning in Convolutional Networks**\n\n- arxiv: [https://arxiv.org/abs/1905.09646](https://arxiv.org/abs/1905.09646)\n- github: [https://github.com/implus/PytorchInsight](https://github.com/implus/PytorchInsight)\n\n**EnsembleNet: End-to-End Optimization of Multi-headed Models**\n\n- intro: Google AI\n- arxiv: [https://arxiv.org/abs/1905.09979](https://arxiv.org/abs/1905.09979)\n\n**MixNet: Mixed Depthwise Convolutional Kernels**\n\n- intro: BMVC 2019\n- arxiv: [https://arxiv.org/abs/1907.09595](https://arxiv.org/abs/1907.09595)\n- github: [https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet/mixnet](https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet/mixnet)\n\n**HarDNet: A Low Memory Traffic Network**\n\n- intro: ICCV 2019\n- intro: National Tsing Hua University & University of Michigan\n- arxiv: [https://arxiv.org/abs/1909.00948](https://arxiv.org/abs/1909.00948)\n\n** nets: Deep Polynomial Neural Networks**\n\n- intro: CVPR 2020\n- arxiv: [https://arxiv.org/abs/2003.03828](https://arxiv.org/abs/2003.03828)\n\n**Circle Loss: A Unified Perspective of Pair Similarity Optimization**\n\n- intro: 1Megvii Inc. & Beihang University & Australian National University & Tsinghua University\n- arxiv: [https://arxiv.org/abs/2002.10857](https://arxiv.org/abs/2002.10857)\n\n**Designing Network Design Spaces**\n\n- intro: CVPR 2020\n- intro: Facebook AI Research (FAIR)\n- arxiv: [https://arxiv.org/abs/2003.13678](https://arxiv.org/abs/2003.13678)\n\n**WeightNet: Revisiting the Design Space of Weight Networks**\n\n- intro: ECCV 2020\n- arxiv: [https://arxiv.org/abs/2007.11823](https://arxiv.org/abs/2007.11823)\n- github: [https://github.com/megvii-model/WeightNet](https://github.com/megvii-model/WeightNet)\n\n**Disentangled Non-Local Neural Networks**\n\n[https://arxiv.org/abs/2006.06668](https://arxiv.org/abs/2006.06668)\n\n**Dynamic Neural Networks: A Survey**\n\n- intro: Tsinghua University\n- arxiv: [https://arxiv.org/abs/2102.04906](https://arxiv.org/abs/2102.04906)\n\n## Convolutions / Filters\n\n**Warped Convolutions: Efficient Invariance to Spatial Transformations**\n\n- arxiv: [http://arxiv.org/abs/1609.04382](http://arxiv.org/abs/1609.04382)\n\n**Coordinating Filters for Faster Deep Neural Networks**\n\n- arxiv: [https://arxiv.org/abs/1703.09746](https://arxiv.org/abs/1703.09746)\n- github: [https://github.com/wenwei202/caffe/tree/sfm](https://github.com/wenwei202/caffe/tree/sfm)\n\n**Shift: A Zero FLOP, Zero Parameter Alternative to Spatial Convolutions**\n\n- intro: UC Berkeley\n- arxiv: [https://arxiv.org/abs/1711.08141](https://arxiv.org/abs/1711.08141)\n\n**Spatially-Adaptive Filter Units for Deep Neural Networks**\n\n- intro: University of Ljubljana & University of Birmingham\n- arxiv: [https://arxiv.org/abs/1711.11473](https://arxiv.org/abs/1711.11473)\n\n**clcNet: Improving the Efficiency of Convolutional Neural Network using Channel Local Convolutions**\n\n[https://arxiv.org/abs/1712.06145](https://arxiv.org/abs/1712.06145)\n\n**DCFNet: Deep Neural Network with Decomposed Convolutional Filters**\n\n[https://arxiv.org/abs/1802.04145](https://arxiv.org/abs/1802.04145)\n\n**Fast End-to-End Trainable Guided Filter**\n\n- intro: CVPR 2018\n- project page: [http://wuhuikai.me/DeepGuidedFilterProject/](http://wuhuikai.me/DeepGuidedFilterProject/)\n- gtihub(official, PyTorch): [https://github.com/wuhuikai/DeepGuidedFilter](https://github.com/wuhuikai/DeepGuidedFilter)\n\n**Diagonalwise Refactorization: An Efficient Training Method for Depthwise Convolutions**\n\n- arxiv: [https://arxiv.org/abs/1803.09926](https://arxiv.org/abs/1803.09926)\n- github: [https://github.com/clavichord93/diagonalwise-refactorization-tensorflow](https://github.com/clavichord93/diagonalwise-refactorization-tensorflow)\n\n**Use of symmetric kernels for convolutional neural networks**\n\n- intro: ICDSIAI 2018\n- arxiv: [https://arxiv.org/abs/1805.09421](https://arxiv.org/abs/1805.09421)\n\n**EasyConvPooling: Random Pooling with Easy Convolution for Accelerating Training and Testing**\n\n[https://arxiv.org/abs/1806.01729](https://arxiv.org/abs/1806.01729)\n\n**Targeted Kernel Networks: Faster Convolutions with Attentive Regularization**\n\n[https://arxiv.org/abs/1806.00523](https://arxiv.org/abs/1806.00523)\n\n**An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution**\n\n- intro: NeurIPS 2018\n- intro: Uber AI Labs & Uber Technologies\n- arxiv: [https://arxiv.org/abs/1807.03247](https://arxiv.org/abs/1807.03247)\n- github: [https://github.com/uber-research/CoordConv](https://github.com/uber-research/CoordConv)\n- youtube: [https://www.youtube.com/watch?v=8yFQc6elePA](https://www.youtube.com/watch?v=8yFQc6elePA)\n\n**Network Decoupling: From Regular to Depthwise Separable Convolutions**\n\n[https://arxiv.org/abs/1808.05517](https://arxiv.org/abs/1808.05517)\n\n**Partial Convolution based Padding**\n\n- intro: NVIDIA Corporation\n- arxiv; [https://arxiv.org/abs/1811.11718](https://arxiv.org/abs/1811.11718)\n- github: [https://github.com/NVIDIA/partialconv](https://github.com/NVIDIA/partialconv)\n\n**DSConv: Efficient Convolution Operator**\n\n[https://arxiv.org/abs/1901.01928](https://arxiv.org/abs/1901.01928)\n\n**CircConv: A Structured Convolution with Low Complexity**\n\n- intro: AAAI 2019\n- arxiv: [https://arxiv.org/abs/1902.11268](https://arxiv.org/abs/1902.11268)\n\n**Accelerating Large-Kernel Convolution Using Summed-Area Tables**\n\n- intro: Princeton University\n- arxiv: [https://arxiv.org/abs/1906.11367](https://arxiv.org/abs/1906.11367)\n\n**Mapped Convolutions**\n\n- intro: University of North Carolina at Chapel Hill\n- arxiv: [https://arxiv.org/abs/1906.11096](https://arxiv.org/abs/1906.11096)\n\n**Universal Pooling -- A New Pooling Method for Convolutional Neural Networks**\n\n[https://arxiv.org/abs/1907.11440](https://arxiv.org/abs/1907.11440)\n\n**Dilated Point Convolutions: On the Receptive Field of Point Convolutions**\n\n[https://arxiv.org/abs/1907.12046](https://arxiv.org/abs/1907.12046)\n\n**LIP: Local Importance-based Pooling**\n\n- intro: ICCV 2019\n- arxiv: [https://arxiv.org/abs/1908.04156](https://arxiv.org/abs/1908.04156)\n\n**Deep Generalized Max Pooling**\n\n- intro: ICDAR\n- arxiv: [https://arxiv.org/abs/1908.05040](https://arxiv.org/abs/1908.05040)\n\n**MixConv: Mixed Depthwise Convolutional Kernels**\n\n- intro:BMVC 2019\n- arxiv: [https://arxiv.org/abs/1907.09595](https://arxiv.org/abs/1907.09595)\n- github: [https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet/mixnet](https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet/mixnet)\n\n**Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation**\n\n- intro: UC Berkeley & USTC & MSRA\n- arxiv: [https://arxiv.org/abs/1910.02940](https://arxiv.org/abs/1910.02940)\n\n**Dynamic Convolution: Attention over Convolution Kernels**\n\n- intro: CVPR 2020 oral\n- intro: Microsoft\n- arxiv: [https://arxiv.org/abs/1912.03458](https://arxiv.org/abs/1912.03458)\n\n**Pyramidal Convolution: Rethinking Convolutional Neural Networks for Visual Recognition**\n\n- arxiv: [https://arxiv.org/abs/2006.11538](https://arxiv.org/abs/2006.11538)\n- github: [https://github.com/iduta/pyconv](https://github.com/iduta/pyconv)\n- gihtub: [https://github.com/iduta/pyconvsegnet](https://github.com/iduta/pyconvsegnet)\n\n## Highway Networks\n\n**Highway Networks**\n\n- intro: ICML 2015 Deep Learning workshop\n- intro: shortcut connections with gating functions. These gates are data-dependent and have parameters\n- arxiv: [http://arxiv.org/abs/1505.00387](http://arxiv.org/abs/1505.00387)\n- github(PyTorch): [https://github.com/analvikingur/pytorch_Highway](https://github.com/analvikingur/pytorch_Highway)\n\n**Highway Networks with TensorFlow**\n\n- blog: [https://medium.com/jim-fleming/highway-networks-with-tensorflow-1e6dfa667daa#.71fgztsb6](https://medium.com/jim-fleming/highway-networks-with-tensorflow-1e6dfa667daa#.71fgztsb6)\n\n**Very Deep Learning with Highway Networks**\n\n- homepage(papers+code+FAQ): [http://people.idsia.ch/~rupesh/very_deep_learning/](http://people.idsia.ch/~rupesh/very_deep_learning/)\n\n**Training Very Deep Networks**\n\n- intro: Extends [Highway Networks](https://arxiv.org/abs/1505.00387)\n- project page: [http://people.idsia.ch/~rupesh/very_deep_learning/](http://people.idsia.ch/~rupesh/very_deep_learning/)\n- arxiv: [http://arxiv.org/abs/1507.06228](http://arxiv.org/abs/1507.06228)\n\n## Spatial Transformer Networks\n\n**Spatial Transformer Networks**\n\n![](https://camo.githubusercontent.com/bb81d6267f2123d59979453526d958a58899bb4f/687474703a2f2f692e696d6775722e636f6d2f4578474456756c2e706e67)\n\n- intro: NIPS 2015\n- arxiv: [http://arxiv.org/abs/1506.02025](http://arxiv.org/abs/1506.02025)\n- gitxiv: [http://gitxiv.com/posts/5WTXTLuEA4Hd8W84G/spatial-transformer-networks](http://gitxiv.com/posts/5WTXTLuEA4Hd8W84G/spatial-transformer-networks)\n- github: [https://github.com/daerduoCarey/SpatialTransformerLayer](https://github.com/daerduoCarey/SpatialTransformerLayer)\n- github: [https://github.com/qassemoquab/stnbhwd](https://github.com/qassemoquab/stnbhwd)\n- github: [https://github.com/skaae/transformer_network](https://github.com/skaae/transformer_network)\n- github(Caffe): [https://github.com/happynear/SpatialTransformerLayer](https://github.com/happynear/SpatialTransformerLayer)\n- github: [https://github.com/daviddao/spatial-transformer-tensorflow](https://github.com/daviddao/spatial-transformer-tensorflow)\n- caffe-issue: [https://github.com/BVLC/caffe/issues/3114](https://github.com/BVLC/caffe/issues/3114)\n- code: [https://lasagne.readthedocs.org/en/latest/modules/layers/special.html#lasagne.layers.TransformerLayer](https://lasagne.readthedocs.org/en/latest/modules/layers/special.html#lasagne.layers.TransformerLayer)\n- ipn(Lasagne): [http://nbviewer.jupyter.org/github/Lasagne/Recipes/blob/master/examples/spatial_transformer_network.ipynb](http://nbviewer.jupyter.org/github/Lasagne/Recipes/blob/master/examples/spatial_transformer_network.ipynb)\n- notes: [https://www.evernote.com/shard/s189/sh/ad8a38de-9e98-4e06-b09e-574bd62893ff/32f72798c095dd7672f4cb017a32d9b4](https://www.evernote.com/shard/s189/sh/ad8a38de-9e98-4e06-b09e-574bd62893ff/32f72798c095dd7672f4cb017a32d9b4)\n- youtube: [https://www.youtube.com/watch?v=6NOQC_fl1hQ](https://www.youtube.com/watch?v=6NOQC_fl1hQ)\n\n**The power of Spatial Transformer Networks**\n\n- blog: [http://torch.ch/blog/2015/09/07/spatial_transformers.html](http://torch.ch/blog/2015/09/07/spatial_transformers.html)\n- github: [https://github.com/moodstocks/gtsrb.torch](https://github.com/moodstocks/gtsrb.torch)\n\n**Recurrent Spatial Transformer Networks**\n\n- paper: [http://arxiv.org/abs/1509.05329](http://arxiv.org/abs/1509.05329)\n\n**Deep Learning Paper Implementations: Spatial Transformer Networks - Part I**\n\n- blog: [https://kevinzakka.github.io/2017/01/10/stn-part1/](https://kevinzakka.github.io/2017/01/10/stn-part1/)\n- github: [https://github.com/kevinzakka/blog-code/tree/master/spatial_transformer](https://github.com/kevinzakka/blog-code/tree/master/spatial_transformer)\n\n**Top-down Flow Transformer Networks**\n\n[https://arxiv.org/abs/1712.02400](https://arxiv.org/abs/1712.02400)\n\n**Non-Parametric Transformation Networks**\n\n- intro: CMU\n- arxiv: [https://arxiv.org/abs/1801.04520](https://arxiv.org/abs/1801.04520)\n\n**Hierarchical Spatial Transformer Network**\n\n[https://arxiv.org/abs/1801.09467](https://arxiv.org/abs/1801.09467)\n\n**Spatial Transformer Introspective Neural Network**\n\n- intro: Johns Hopkins University & Shanghai University\n- arxiv: [https://arxiv.org/abs/1805.06447](https://arxiv.org/abs/1805.06447)\n\n**DeSTNet: Densely Fused Spatial Transformer Networks**\n\n- intro: BMVC 2018\n- arxiv: [https://arxiv.org/abs/1807.04050](https://arxiv.org/abs/1807.04050)\n\n**MIST: Multiple Instance Spatial Transformer Network**\n\n[https://arxiv.org/abs/1811.10725](https://arxiv.org/abs/1811.10725)\n\n## FractalNet\n\n**FractalNet: Ultra-Deep Neural Networks without Residuals**\n\n![](http://people.cs.uchicago.edu/~larsson/fractalnet/overview.png)\n\n- project: [http://people.cs.uchicago.edu/~larsson/fractalnet/](http://people.cs.uchicago.edu/~larsson/fractalnet/)\n- arxiv: [http://arxiv.org/abs/1605.07648](http://arxiv.org/abs/1605.07648)\n- github: [https://github.com/gustavla/fractalnet](https://github.com/gustavla/fractalnet)\n- github: [https://github.com/edgelord/FractalNet](https://github.com/edgelord/FractalNet)\n- github(Keras): [https://github.com/snf/keras-fractalnet](https://github.com/snf/keras-fractalnet)\n\n# Generative Models\n\n**Max-margin Deep Generative Models**\n\n- intro: NIPS 2015\n- arxiv: [http://arxiv.org/abs/1504.06787](http://arxiv.org/abs/1504.06787)\n- github: [https://github.com/zhenxuan00/mmdgm](https://github.com/zhenxuan00/mmdgm)\n\n**Discriminative Regularization for Generative Models**\n\n- arxiv: [http://arxiv.org/abs/1602.03220](http://arxiv.org/abs/1602.03220)\n- github: [https://github.com/vdumoulin/discgen](https://github.com/vdumoulin/discgen)\n\n**Auxiliary Deep Generative Models**\n\n- arxiv: [http://arxiv.org/abs/1602.05473](http://arxiv.org/abs/1602.05473)\n- github: [https://github.com/larsmaaloee/auxiliary-deep-generative-models](https://github.com/larsmaaloee/auxiliary-deep-generative-models)\n\n**Sampling Generative Networks: Notes on a Few Effective Techniques**\n\n- arxiv: [http://arxiv.org/abs/1609.04468](http://arxiv.org/abs/1609.04468)\n- paper: [https://github.com/dribnet/plat](https://github.com/dribnet/plat)\n\n**Conditional Image Synthesis With Auxiliary Classifier GANs**\n\n- arxiv: [https://arxiv.org/abs/1610.09585](https://arxiv.org/abs/1610.09585)\n- github: [https://github.com/buriburisuri/ac-gan](https://github.com/buriburisuri/ac-gan)\n- github(Keras): [https://github.com/lukedeo/keras-acgan](https://github.com/lukedeo/keras-acgan)\n\n**On the Quantitative Analysis of Decoder-Based Generative Models**\n\n- intro: University of Toronto & OpenAI & CMU\n- arxiv: [https://arxiv.org/abs/1611.04273](https://arxiv.org/abs/1611.04273)\n- github: [https://github.com/tonywu95/eval_gen](https://github.com/tonywu95/eval_gen)\n\n**Boosted Generative Models**\n\n- arxiv: [https://arxiv.org/abs/1702.08484](https://arxiv.org/abs/1702.08484)\n- paper: [https://openreview.net/pdf?id=HyY4Owjll](https://openreview.net/pdf?id=HyY4Owjll)\n\n**An Architecture for Deep, Hierarchical Generative Models**\n\n- intro: NIPS 2016\n- arxiv: [https://arxiv.org/abs/1612.04739](https://arxiv.org/abs/1612.04739)\n- github: [https://github.com/Philip-Bachman/MatNets-NIPS](https://github.com/Philip-Bachman/MatNets-NIPS)\n\n**Deep Learning and Hierarchal Generative Models**\n\n- intro: NIPS 2016. MIT\n- arxiv: [https://arxiv.org/abs/1612.09057](https://arxiv.org/abs/1612.09057)\n\n**Probabilistic Torch**\n\n- intro: Probabilistic Torch is library for deep generative models that extends PyTorch\n- github: [https://github.com/probtorch/probtorch](https://github.com/probtorch/probtorch)\n\n**Tutorial on Deep Generative Models**\n\n- intro: UAI 2017 Tutorial: Shakir Mohamed & Danilo Rezende (DeepMind)\n- youtube: [https://www.youtube.com/watch?v=JrO5fSskISY](https://www.youtube.com/watch?v=JrO5fSskISY)\n- mirror: [https://www.bilibili.com/video/av16428277/](https://www.bilibili.com/video/av16428277/)\n- slides: [http://www.shakirm.com/slides/DeepGenModelsTutorial.pdf](http://www.shakirm.com/slides/DeepGenModelsTutorial.pdf)\n\n**A Note on the Inception Score**\n\n- intro: Stanford University\n- arxiv: [https://arxiv.org/abs/1801.01973](https://arxiv.org/abs/1801.01973)\n\n**Gradient Layer: Enhancing the Convergence of Adversarial Training for Generative Models**\n\n- intro: AISTATS 2018. The University of Tokyo\n- arxiv: [https://arxiv.org/abs/1801.02227](https://arxiv.org/abs/1801.02227)\n\n**Batch Normalization in the final layer of generative networks**\n\n[https://arxiv.org/abs/1805.07389](https://arxiv.org/abs/1805.07389)\n\n**Deep Structured Generative Models**\n\n- intro: Tsinghua University\n- arxiv: [https://arxiv.org/abs/1807.03877](https://arxiv.org/abs/1807.03877)\n\n**VFunc: a Deep Generative Model for Functions**\n\n- intro: ICML 2018 workshop on Prediction and Generative Modeling in Reinforcement Learning. Microsoft Research & McGill University\n- arxiv: [https://arxiv.org/abs/1807.04106](https://arxiv.org/abs/1807.04106)\n\n# Deep Learning and Robots\n\n**Robot Learning Manipulation Action Plans by \"Watching\" Unconstrained Videos from the World Wide Web**\n\n- intro: AAAI 2015\n- paper: [http://www.umiacs.umd.edu/~yzyang/paper/YouCookMani_CameraReady.pdf](http://www.umiacs.umd.edu/~yzyang/paper/YouCookMani_CameraReady.pdf)\n- author page: [http://www.umiacs.umd.edu/~yzyang/](http://www.umiacs.umd.edu/~yzyang/)\n\n**End-to-End Training of Deep Visuomotor Policies**\n\n- arxiv: [http://arxiv.org/abs/1504.00702](http://arxiv.org/abs/1504.00702)\n\n**Comment on Open AIs Efforts to Robot Learning**\n\n- blog: [https://gridworld.wordpress.com/2016/07/28/comment-on-open-ais-efforts-to-robot-learning/](https://gridworld.wordpress.com/2016/07/28/comment-on-open-ais-efforts-to-robot-learning/)\n\n**The Curious Robot: Learning Visual Representations via Physical Interactions**\n\n- arxiv: [http://arxiv.org/abs/1604.01360](http://arxiv.org/abs/1604.01360)\n\n**How to build a robot that sees with $100 and TensorFlow**\n\n![](https://d3ansictanv2wj.cloudfront.net/Figure_5-5b104cf7a53a9c1ee95110b78fb14256.jpg)\n\n- blog: [https://www.oreilly.com/learning/how-to-build-a-robot-that-sees-with-100-and-tensorflow](https://www.oreilly.com/learning/how-to-build-a-robot-that-sees-with-100-and-tensorflow)\n\n**Deep Visual Foresight for Planning Robot Motion**\n\n- project page: [https://sites.google.com/site/brainrobotdata/](https://sites.google.com/site/brainrobotdata/)\n- arxiv: [https://arxiv.org/abs/1610.00696](https://arxiv.org/abs/1610.00696)\n- video: [https://sites.google.com/site/robotforesight/](https://sites.google.com/site/robotforesight/)\n\n**Sim-to-Real Robot Learning from Pixels with Progressive Nets**\n\n- intro: Google DeepMind\n- arxiv: [https://arxiv.org/abs/1610.04286](https://arxiv.org/abs/1610.04286)\n\n**Towards Lifelong Self-Supervision: A Deep Learning Direction for Robotics**\n\n- arxiv: [https://arxiv.org/abs/1611.00201](https://arxiv.org/abs/1611.00201)\n\n**A Differentiable Physics Engine for Deep Learning in Robotics**\n\n- paper: [http://openreview.net/pdf?id=SyEiHNKxx](http://openreview.net/pdf?id=SyEiHNKxx)\n\n**Deep-learning in Mobile Robotics - from Perception to Control Systems: A Survey on Why and Why not**\n\n- intro: City University of Hong Kong & Hong Kong University of Science and Technology\n- arxiv: [https://arxiv.org/abs/1612.07139](https://arxiv.org/abs/1612.07139)\n\n**Deep Robotic Learning**\n\n- intro: [https://simons.berkeley.edu/talks/sergey-levine-01-24-2017-1](https://simons.berkeley.edu/talks/sergey-levine-01-24-2017-1)\n- youtube: [https://www.youtube.com/watch?v=jtjW5Pye_44](https://www.youtube.com/watch?v=jtjW5Pye_44)\n\n**Deep Learning in Robotics: A Review of Recent Research**\n\n[https://arxiv.org/abs/1707.07217](https://arxiv.org/abs/1707.07217)\n\n**Deep Learning for Robotics**\n\n- intro: by Pieter Abbeel\n- video: [https://www.facebook.com/nipsfoundation/videos/1554594181298482/](https://www.facebook.com/nipsfoundation/videos/1554594181298482/)\n- mirror: [https://www.bilibili.com/video/av17078186/](https://www.bilibili.com/video/av17078186/)\n- slides: [https://www.dropbox.com/s/4fhczb9cxkuqalf/2017_11_xx_BARS-Abbeel.pdf?dl=0](https://www.dropbox.com/s/4fhczb9cxkuqalf/2017_11_xx_BARS-Abbeel.pdf?dl=0)\n\n**DroNet: Learning to Fly by Driving**\n\n- project page: [http://rpg.ifi.uzh.ch/dronet.html](http://rpg.ifi.uzh.ch/dronet.html)\n- paper: [http://rpg.ifi.uzh.ch/docs/RAL18_Loquercio.pdf](http://rpg.ifi.uzh.ch/docs/RAL18_Loquercio.pdf)\n- github: [https://github.com/uzh-rpg/rpg_public_dronet](https://github.com/uzh-rpg/rpg_public_dronet)\n\n**A Survey on Deep Learning Methods for Robot Vision**\n\n[https://arxiv.org/abs/1803.10862](https://arxiv.org/abs/1803.10862)\n\n# Deep Learning on Mobile / Embedded Devices\n\n**Convolutional neural networks on the iPhone with VGGNet**\n\n- blog: [http://matthijshollemans.com/2016/08/30/vggnet-convolutional-neural-network-iphone/](http://matthijshollemans.com/2016/08/30/vggnet-convolutional-neural-network-iphone/)\n- github: [https://github.com/hollance/VGGNet-Metal](https://github.com/hollance/VGGNet-Metal)\n\n**TensorFlow for Mobile Poets**\n\n- blog: [https://petewarden.com/2016/09/27/tensorflow-for-mobile-poets/](https://petewarden.com/2016/09/27/tensorflow-for-mobile-poets/)\n\n**The Convolutional Neural Network(CNN) for Android**\n\n- intro: CnnForAndroid:A Classification Project using Convolutional Neural Network(CNN) in Android platformIt also support Caffe Model\n- github: [https://github.com/zhangqianhui/CnnForAndroid](https://github.com/zhangqianhui/CnnForAndroid)\n\n**TensorFlow on Android**\n\n- blog: [https://www.oreilly.com/learning/tensorflow-on-android](https://www.oreilly.com/learning/tensorflow-on-android)\n\n**Experimenting with TensorFlow on Android**\n\n- part 1: [https://medium.com/@mgazar/experimenting-with-tensorflow-on-android-pt-1-362683b31838#.5gbp2d4st](https://medium.com/@mgazar/experimenting-with-tensorflow-on-android-pt-1-362683b31838#.5gbp2d4st)\n- part 2: [https://medium.com/@mgazar/experimenting-with-tensorflow-on-android-part-2-12f3dc294eaf#.2gx3o65f5](https://medium.com/@mgazar/experimenting-with-tensorflow-on-android-part-2-12f3dc294eaf#.2gx3o65f5)\n- github: [https://github.com/MostafaGazar/tensorflow](https://github.com/MostafaGazar/tensorflow)\n\n**XNOR.ai frees AI from the prison of the supercomputer**\n\n- blog: [https://techcrunch.com/2017/01/19/xnor-ai-frees-ai-from-the-prison-of-the-supercomputer/](https://techcrunch.com/2017/01/19/xnor-ai-frees-ai-from-the-prison-of-the-supercomputer/)\n\n**Embedded and mobile deep learning research resources**\n\n[https://github.com/csarron/emdl](https://github.com/csarron/emdl)\n\n**Modeling the Resource Requirements of Convolutional Neural Networks on Mobile Devices**\n\n[https://arxiv.org/abs/1709.09118](https://arxiv.org/abs/1709.09118)\n\n# Benchmarks\n\n**Deep Learnings Accuracy**\n\n- blog: [http://deeplearning4j.org/accuracy.html](http://deeplearning4j.org/accuracy.html)\n\n**Benchmarks for popular CNN models**\n\n- intro: Benchmarks for popular convolutional neural network models on CPU and different GPUs, with and without cuDNN.\n- github: [https://github.com/jcjohnson/cnn-benchmarks](https://github.com/jcjohnson/cnn-benchmarks)\n\n**Deep Learning Benchmarks**\n\n[http://add-for.com/deep-learning-benchmarks/](http://add-for.com/deep-learning-benchmarks/)\n\n**cudnn-rnn-benchmarks**\n\n- github: [https://github.com/MaximumEntropy/cudnn_rnn_theano_benchmarks](https://github.com/MaximumEntropy/cudnn_rnn_theano_benchmarks)\n\n# Papers\n\n**Reweighted Wake-Sleep**\n\n- paper: [http://arxiv.org/abs/1406.2751](http://arxiv.org/abs/1406.2751)\n- github: [https://github.com/jbornschein/reweighted-ws](https://github.com/jbornschein/reweighted-ws)\n\n**Probabilistic Backpropagation for Scalable Learning of Bayesian Neural Networks**\n\n- paper: [http://arxiv.org/abs/1502.05336](http://arxiv.org/abs/1502.05336)\n- github: [https://github.com/HIPS/Probabilistic-Backpropagation](https://github.com/HIPS/Probabilistic-Backpropagation)\n\n**Deeply-Supervised Nets**\n\n- paper: [http://arxiv.org/abs/1409.5185](http://arxiv.org/abs/1409.5185)\n- github: [https://github.com/mbhenaff/spectral-lib](https://github.com/mbhenaff/spectral-lib)\n\n**Deep learning**\n\n- intro: Nature 2015\n- author: Yann LeCun, Yoshua Bengio & Geoffrey Hinton\n- paper: [http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf](http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf)\n\n**On the Expressive Power of Deep Learning: A Tensor Analysis**\n\n- paper: [http://arxiv.org/abs/1509.05009](http://arxiv.org/abs/1509.05009)\n\n**Understanding and Predicting Image Memorability at a Large Scale**\n\n- intro: MIT. ICCV 2015\n- homepage: [http://memorability.csail.mit.edu/](http://memorability.csail.mit.edu/)\n- paper: [https://people.csail.mit.edu/khosla/papers/iccv2015_khosla.pdf](https://people.csail.mit.edu/khosla/papers/iccv2015_khosla.pdf)\n- code: [http://memorability.csail.mit.edu/download.html](http://memorability.csail.mit.edu/download.html)\n- reviews: [http://petapixel.com/2015/12/18/how-memorable-are-times-top-10-photos-of-2015-to-a-computer/](http://petapixel.com/2015/12/18/how-memorable-are-times-top-10-photos-of-2015-to-a-computer/)\n\n**Towards Open Set Deep Networks**\n\n- arxiv: [http://arxiv.org/abs/1511.06233](http://arxiv.org/abs/1511.06233)\n- github: [https://github.com/abhijitbendale/OSDN](https://github.com/abhijitbendale/OSDN)\n\n**Structured Prediction Energy Networks**\n\n- intro: ICML 2016. SPEN\n- arxiv: [http://arxiv.org/abs/1511.06350](http://arxiv.org/abs/1511.06350)\n- github: [https://github.com/davidBelanger/SPEN](https://github.com/davidBelanger/SPEN)\n\n**Deep Neural Networks predict Hierarchical Spatio-temporal Cortical Dynamics of Human Visual Object Recognition**\n\n- arxiv: [http://arxiv.org/abs/1601.02970](http://arxiv.org/abs/1601.02970)\n- demo: [http://brainmodels.csail.mit.edu/dnn/drawCNN/](http://brainmodels.csail.mit.edu/dnn/drawCNN/)\n\n**Recent Advances in Convolutional Neural Networks**\n\n- arxiv: [http://arxiv.org/abs/1512.07108](http://arxiv.org/abs/1512.07108)\n\n**Understanding Deep Convolutional Networks**\n\n- arxiv: [http://arxiv.org/abs/1601.04920](http://arxiv.org/abs/1601.04920)\n\n**DeepCare: A Deep Dynamic Memory Model for Predictive Medicine**\n\n- arxiv: [http://arxiv.org/abs/1602.00357](http://arxiv.org/abs/1602.00357)\n\n**Exploiting Cyclic Symmetry in Convolutional Neural Networks**\n\n![](http://benanne.github.io/images/cyclicroll.png)\n\n- intro: ICML 2016\n- arxiv: [http://arxiv.org/abs/1602.02660](http://arxiv.org/abs/1602.02660)\n- github(Winning solution for the National Data Science Bowl competition on Kaggle (plankton classification)): [https://github.com/benanne/kaggle-ndsb](https://github.com/benanne/kaggle-ndsb)\n- ref(use Cyclic pooling): [http://benanne.github.io/2015/03/17/plankton.html](http://benanne.github.io/2015/03/17/plankton.html)\n\n**Cross-dimensional Weighting for Aggregated Deep Convolutional Features**\n\n- arxiv: [http://arxiv.org/abs/1512.04065](http://arxiv.org/abs/1512.04065)\n- github: [https://github.com/yahoo/crow](https://github.com/yahoo/crow)\n\n**Understanding Visual Concepts with Continuation Learning**\n\n- project page: [http://willwhitney.github.io/understanding-visual-concepts/](http://willwhitney.github.io/understanding-visual-concepts/)\n- arxiv: [http://arxiv.org/abs/1602.06822](http://arxiv.org/abs/1602.06822)\n- github: [https://github.com/willwhitney/understanding-visual-concepts](https://github.com/willwhitney/understanding-visual-concepts)\n\n**Learning Efficient Algorithms with Hierarchical Attentive Memory**\n\n- arxiv: [http://arxiv.org/abs/1602.03218](http://arxiv.org/abs/1602.03218)\n- github: [https://github.com/Smerity/tf-ham](https://github.com/Smerity/tf-ham)\n\n**DrMAD: Distilling Reverse-Mode Automatic Differentiation for Optimizing Hyperparameters of Deep Neural Networks**\n\n- arxiv: [http://arxiv.org/abs/1601.00917](http://arxiv.org/abs/1601.00917)\n- github: [https://github.com/bigaidream-projects/drmad](https://github.com/bigaidream-projects/drmad)\n\n**Do Deep Convolutional Nets Really Need to be Deep (Or Even Convolutional)?**\n\n- arxiv: [http://arxiv.org/abs/1603.05691](http://arxiv.org/abs/1603.05691)\n- review: [http://www.erogol.com/paper-review-deep-convolutional-nets-really-need-deep-even-convolutional/](http://www.erogol.com/paper-review-deep-convolutional-nets-really-need-deep-even-convolutional/)\n\n**Harnessing Deep Neural Networks with Logic Rules**\n\n- arxiv: [http://arxiv.org/abs/1603.06318](http://arxiv.org/abs/1603.06318)\n\n**Degrees of Freedom in Deep Neural Networks**\n\n- arxiv: [http://arxiv.org/abs/1603.09260](http://arxiv.org/abs/1603.09260)\n\n**Deep Networks with Stochastic Depth**\n\n- arxiv: [http://arxiv.org/abs/1603.09382](http://arxiv.org/abs/1603.09382)\n- github: [https://github.com/yueatsprograms/Stochastic_Depth](https://github.com/yueatsprograms/Stochastic_Depth)\n- notes(\"Stochastic Depth Networks will Become the New Normal\"): [http://deliprao.com/archives/134](http://deliprao.com/archives/134)\n- github: [https://github.com/dblN/stochastic_depth_keras](https://github.com/dblN/stochastic_depth_keras)\n- github: [https://github.com/yasunorikudo/chainer-ResDrop](https://github.com/yasunorikudo/chainer-ResDrop)\n- review: [https://medium.com/@tim_nth/review-deep-networks-with-stochastic-depth-51bd53acfe72](https://medium.com/@tim_nth/review-deep-networks-with-stochastic-depth-51bd53acfe72)\n\n**LIFT: Learned Invariant Feature Transform**\n\n- intro: ECCV 2016\n- arxiv: [http://arxiv.org/abs/1603.09114](http://arxiv.org/abs/1603.09114)\n- github(official): [https://github.com/cvlab-epfl/LIFT](https://github.com/cvlab-epfl/LIFT)\n\n**Bridging the Gaps Between Residual Learning, Recurrent Neural Networks and Visual Cortex**\n\n- arxiv: [https://arxiv.org/abs/1604.03640](https://arxiv.org/abs/1604.03640)\n- slides: [http://prlab.tudelft.nl/sites/default/files/rnnResnetCortex.pdf](http://prlab.tudelft.nl/sites/default/files/rnnResnetCortex.pdf)\n\n**Understanding How Image Quality Affects Deep Neural Networks**\n\n- arxiv: [http://arxiv.org/abs/1604.04004](http://arxiv.org/abs/1604.04004)\n- reddit: [https://www.reddit.com/r/MachineLearning/comments/4exk3u/dcnns_are_more_sensitive_to_blur_and_noise_than/](https://www.reddit.com/r/MachineLearning/comments/4exk3u/dcnns_are_more_sensitive_to_blur_and_noise_than/)\n\n**Deep Embedding for Spatial Role Labeling**\n\n- arxiv: [http://arxiv.org/abs/1603.08474](http://arxiv.org/abs/1603.08474)\n- github: [https://github.com/oswaldoludwig/visually-informed-embedding-of-word-VIEW-](https://github.com/oswaldoludwig/visually-informed-embedding-of-word-VIEW-)\n\n**Unreasonable Effectiveness of Learning Neural Nets: Accessible States and Robust Ensembles**\n\n- arxiv: [http://arxiv.org/abs/1605.06444](http://arxiv.org/abs/1605.06444)\n\n**Learning Deep Representation for Imbalanced Classification**\n\n![](http://mmlab.ie.cuhk.edu.hk/projects/LMLE/method.png)\n\n- intro: CVPR 2016\n- keywords: Deep Learning Large Margin Local Embedding (LMLE)\n- project page: [http://mmlab.ie.cuhk.edu.hk/projects/LMLE.html](http://mmlab.ie.cuhk.edu.hk/projects/LMLE.html)\n- paper: [http://personal.ie.cuhk.edu.hk/~ccloy/files/cvpr_2016_imbalanced.pdf](http://personal.ie.cuhk.edu.hk/~ccloy/files/cvpr_2016_imbalanced.pdf)\n- code: [http://mmlab.ie.cuhk.edu.hk/projects/LMLE/lmle_code.zip](http://mmlab.ie.cuhk.edu.hk/projects/LMLE/lmle_code.zip)\n\n**Newtonian Image Understanding: Unfolding the Dynamics of Objects in Static Images**\n\n![](http://allenai.org/images/projects/plato_newton.png?cb=1466683222538)\n\n- homepage: [http://allenai.org/plato/newtonian-understanding/](http://allenai.org/plato/newtonian-understanding/)\n- arxiv: [http://arxiv.org/abs/1511.04048](http://arxiv.org/abs/1511.04048)\n- github: [https://github.com/roozbehm/newtonian](https://github.com/roozbehm/newtonian)\n\n**DeepMath - Deep Sequence Models for Premise Selection**\n\n- arxiv: [https://arxiv.org/abs/1606.04442](https://arxiv.org/abs/1606.04442)\n- github: [https://github.com/tensorflow/deepmath](https://github.com/tensorflow/deepmath)\n\n**Convolutional Neural Networks Analyzed via Convolutional Sparse Coding**\n\n- arxiv: [http://arxiv.org/abs/1607.08194](http://arxiv.org/abs/1607.08194)\n\n**Systematic evaluation of CNN advances on the ImageNet**\n\n- arxiv: [http://arxiv.org/abs/1606.02228](http://arxiv.org/abs/1606.02228)\n- github: [https://github.com/ducha-aiki/caffenet-benchmark](https://github.com/ducha-aiki/caffenet-benchmark)\n\n**Why does deep and cheap learning work so well?**\n\n- intro: Harvard and MIT\n- arxiv: [http://arxiv.org/abs/1608.08225](http://arxiv.org/abs/1608.08225)\n- review: [https://www.technologyreview.com/s/602344/the-extraordinary-link-between-deep-neural-networks-and-the-nature-of-the-universe/](https://www.technologyreview.com/s/602344/the-extraordinary-link-between-deep-neural-networks-and-the-nature-of-the-universe/)\n\n**A scalable convolutional neural network for task-specified scenarios via knowledge distillation**\n\n- arxiv: [http://arxiv.org/abs/1609.05695](http://arxiv.org/abs/1609.05695)\n\n**Alternating Back-Propagation for Generator Network**\n\n- project page(code+data): [http://www.stat.ucla.edu/~ywu/ABP/main.html](http://www.stat.ucla.edu/~ywu/ABP/main.html)\n- paper: [http://www.stat.ucla.edu/~ywu/ABP/doc/arXivABP.pdf](http://www.stat.ucla.edu/~ywu/ABP/doc/arXivABP.pdf)\n\n**A Novel Representation of Neural Networks**\n\n- arxiv: [https://arxiv.org/abs/1610.01549](https://arxiv.org/abs/1610.01549)\n\n**Optimization of Convolutional Neural Network using Microcanonical Annealing Algorithm**\n\n- intro: IEEE ICACSIS 2016\n- arxiv: [https://arxiv.org/abs/1610.02306](https://arxiv.org/abs/1610.02306)\n\n**Uncertainty in Deep Learning**\n\n- intro: PhD Thesis. Cambridge Machine Learning Group\n- blog: [http://mlg.eng.cam.ac.uk/yarin/blog_2248.html](http://mlg.eng.cam.ac.uk/yarin/blog_2248.html)\n- thesis: [http://mlg.eng.cam.ac.uk/yarin/thesis/thesis.pdf](http://mlg.eng.cam.ac.uk/yarin/thesis/thesis.pdf)\n\n**Deep Convolutional Neural Network Design Patterns**\n\n- arxiv: [https://arxiv.org/abs/1611.00847](https://arxiv.org/abs/1611.00847)\n- github: [https://github.com/iPhysicist/CNNDesignPatterns](https://github.com/iPhysicist/CNNDesignPatterns)\n\n**Extensions and Limitations of the Neural GPU**\n\n- arxiv: [https://arxiv.org/abs/1611.00736](https://arxiv.org/abs/1611.00736)\n- github: [https://github.com/openai/ecprice-neural-gpu](https://github.com/openai/ecprice-neural-gpu)\n\n**Neural Functional Programming**\n\n- arxiv: [https://arxiv.org/abs/1611.01988](https://arxiv.org/abs/1611.01988)\n\n**Deep Information Propagation**\n\n- arxiv: [https://arxiv.org/abs/1611.01232](https://arxiv.org/abs/1611.01232)\n\n**Compressed Learning: A Deep Neural Network Approach**\n\n- arxiv: [https://arxiv.org/abs/1610.09615](https://arxiv.org/abs/1610.09615)\n\n**A backward pass through a CNN using a generative model of its activations**\n\n- arxiv: [https://arxiv.org/abs/1611.02767](https://arxiv.org/abs/1611.02767)\n\n**Understanding deep learning requires rethinking generalization**\n\n- intro: ICLR 2017 best paper. MIT & Google Brain & UC Berkeley & Google DeepMind\n- arxiv: [https://arxiv.org/abs/1611.03530](https://arxiv.org/abs/1611.03530)\n- example code: [https://github.com/pluskid/fitting-random-labels](https://github.com/pluskid/fitting-random-labels)\n- notes: [https://theneuralperspective.com/2017/01/24/understanding-deep-learning-requires-rethinking-generalization/](https://theneuralperspective.com/2017/01/24/understanding-deep-learning-requires-rethinking-generalization/)\n\n**Learning the Number of Neurons in Deep Networks**\n\n- intro: NIPS 2016\n- arxiv: [https://arxiv.org/abs/1611.06321](https://arxiv.org/abs/1611.06321)\n\n**Survey of Expressivity in Deep Neural Networks**\n\n- intro: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in Complex Systems\n- intro: Google Brain & Cornell University & Stanford University\n- arxiv: [https://arxiv.org/abs/1611.08083](https://arxiv.org/abs/1611.08083)\n\n**Designing Neural Network Architectures using Reinforcement Learning**\n\n- intro: MIT\n- project page: [https://bowenbaker.github.io/metaqnn/](https://bowenbaker.github.io/metaqnn/)\n- arxiv: [https://arxiv.org/abs/1611.02167](https://arxiv.org/abs/1611.02167)\n\n**Towards Robust Deep Neural Networks with BANG**\n\n- intro: University of Colorado\n- arxiv: [https://arxiv.org/abs/1612.00138](https://arxiv.org/abs/1612.00138)\n\n**Deep Quantization: Encoding Convolutional Activations with Deep Generative Model**\n\n- intro: University of Science and Technology of China & MSR\n- arxiv: [https://arxiv.org/abs/1611.09502](https://arxiv.org/abs/1611.09502)\n\n**A Probabilistic Theory of Deep Learning**\n\n- arxiv: [https://arxiv.org/abs/1504.00641](https://arxiv.org/abs/1504.00641)\n\n**A Probabilistic Framework for Deep Learning**\n\n- intro: Rice University\n- arxiv: [https://arxiv.org/abs/1612.01936](https://arxiv.org/abs/1612.01936)\n\n**Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer**\n\n- arxiv: [https://arxiv.org/abs/1612.03928](https://arxiv.org/abs/1612.03928)\n- github(PyTorch): [https://github.com/szagoruyko/attention-transfer](https://github.com/szagoruyko/attention-transfer)\n\n**Risk versus Uncertainty in Deep Learning: Bayes, Bootstrap and the Dangers of Dropout**\n\n- intro: Google Deepmind\n- paper: [http://bayesiandeeplearning.org/papers/BDL_4.pdf](http://bayesiandeeplearning.org/papers/BDL_4.pdf)\n\n**Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer**\n\n- intro: Google Brain & Jagiellonian University\n- keywords: Sparsely-Gated Mixture-of-Experts layer (MoE), language modeling and machine translation\n- arxiv: [https://arxiv.org/abs/1701.06538](https://arxiv.org/abs/1701.06538)\n- reddit: [https://www.reddit.com/r/MachineLearning/comments/5pud72/research_outrageously_large_neural_networks_the/](https://www.reddit.com/r/MachineLearning/comments/5pud72/research_outrageously_large_neural_networks_the/)\n\n**Deep Network Guided Proof Search**\n\n- intro: Google Research & University of Innsbruck\n- arxiv: [https://arxiv.org/abs/1701.06972](https://arxiv.org/abs/1701.06972)\n\n**PathNet: Evolution Channels Gradient Descent in Super Neural Networks**\n\n- intro: Google DeepMind & Google Brain\n- arxiv: [https://arxiv.org/abs/1701.08734](https://arxiv.org/abs/1701.08734)\n- notes: [https://medium.com/intuitionmachine/pathnet-a-modular-deep-learning-architecture-for-agi-5302fcf53273#.8f0o6w3en](https://medium.com/intuitionmachine/pathnet-a-modular-deep-learning-architecture-for-agi-5302fcf53273#.8f0o6w3en)\n\n**Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks**\n\n- arxiv: [https://arxiv.org/abs/1702.01135](https://arxiv.org/abs/1702.01135)\n\n**The Power of Sparsity in Convolutional Neural Networks**\n\n- arxiv: [https://arxiv.org/abs/1702.06257](https://arxiv.org/abs/1702.06257)\n\n**Learning across scales - A multiscale method for Convolution Neural Networks**\n\n- arxiv: [https://arxiv.org/abs/1703.02009](https://arxiv.org/abs/1703.02009)\n\n**Stacking-based Deep Neural Network: Deep Analytic Network on Convolutional Spectral Histogram Features**\n\n- arxiv: [https://arxiv.org/abs/1703.01396](https://arxiv.org/abs/1703.01396)\n\n**A Compositional Object-Based Approach to Learning Physical Dynamics**\n\n- intro: ICLR 2017. Neural Physics Engine\n- paper: [https://openreview.net/pdf?id=Bkab5dqxe](https://openreview.net/pdf?id=Bkab5dqxe)\n- github: [https://github.com/mbchang/dynamics](https://github.com/mbchang/dynamics)\n\n**Genetic CNN**\n\n- arxiv: [https://arxiv.org/abs/1703.01513](https://arxiv.org/abs/1703.01513)\n- github(Tensorflow): [https://github.com/aqibsaeed/Genetic-CNN](https://github.com/aqibsaeed/Genetic-CNN)\n\n**Deep Sets**\n\n- intro: Amazon Web Services & CMU\n- keywords: statistic estimation, point cloud classification, set expansion, and image tagging\n- arxiv: [https://arxiv.org/abs/1703.06114](https://arxiv.org/abs/1703.06114)\n\n**Multiscale Hierarchical Convolutional Networks**\n\n- arxiv: [https://arxiv.org/abs/1703.04140](https://arxiv.org/abs/1703.04140)\n- github: [https://github.com/jhjacobsen/HierarchicalCNN](https://github.com/jhjacobsen/HierarchicalCNN)\n\n**Deep Neural Networks Do Not Recognize Negative Images**\n\n[https://arxiv.org/abs/1703.06857](https://arxiv.org/abs/1703.06857)\n\n**Failures of Deep Learning**\n\n- arxiv: [https://arxiv.org/abs/1703.07950](https://arxiv.org/abs/1703.07950)\n- github: [https://github.com/shakedshammah/failures_of_DL](https://github.com/shakedshammah/failures_of_DL)\n\n**Multi-Scale Dense Convolutional Networks for Efficient Prediction**\n\n- intro: Cornell University & Tsinghua University & Fudan University & Facebook AI Research\n- arxiv: [https://arxiv.org/abs/1703.09844](https://arxiv.org/abs/1703.09844)\n- github: [https://github.com/gaohuang/MSDNet](https://github.com/gaohuang/MSDNet)\n\n**Scaling the Scattering Transform: Deep Hybrid Networks**\n\n- arxiv: [https://arxiv.org/abs/1703.08961](https://arxiv.org/abs/1703.08961)\n- github: [https://github.com/edouardoyallon/scalingscattering](https://github.com/edouardoyallon/scalingscattering)\n- github(CuPy/PyTorch): [https://github.com/edouardoyallon/pyscatwave](https://github.com/edouardoyallon/pyscatwave)\n\n**Deep Learning is Robust to Massive Label Noise**\n\n[https://arxiv.org/abs/1705.10694](https://arxiv.org/abs/1705.10694)\n\n**Input Fast-Forwarding for Better Deep Learning**\n\n- intro: ICIAR 2017\n- keywords: Fast-Forward Network (FFNet)\n- arxiv: [https://arxiv.org/abs/1705.08479](https://arxiv.org/abs/1705.08479)\n\n**Deep Mutual Learning**\n\n- intro: CVPR 2018\n- keywords: deep mutual learning (DML)\n- arxiv: [https://arxiv.org/abs/1706.00384](https://arxiv.org/abs/1706.00384)\n- github(official, TensorFlow): [https://github.com/YingZhangDUT/Deep-Mutual-Learning](https://github.com/YingZhangDUT/Deep-Mutual-Learning)\n\n**Automated Problem Identification: Regression vs Classification via Evolutionary Deep Networks**\n\n- intro: University of Cape Town\n- arxiv: [https://arxiv.org/abs/1707.00703](https://arxiv.org/abs/1707.00703)\n\n**Revisiting Unreasonable Effectiveness of Data in Deep Learning Era**\n\n- intro: Google Research & CMU\n- arxiv: [https://arxiv.org/abs/1707.02968](https://arxiv.org/abs/1707.02968)\n- blog: [https://research.googleblog.com/2017/07/revisiting-unreasonable-effectiveness.html](https://research.googleblog.com/2017/07/revisiting-unreasonable-effectiveness.html)\n\n**Deep Layer Aggregation**\n\n- intro: UC Berkeley\n- arxiv: [https://arxiv.org/abs/1707.06484](https://arxiv.org/abs/1707.06484)\n\n**Improving Robustness of Feature Representations to Image Deformations using Powered Convolution in CNNs**\n\n[https://arxiv.org/abs/1707.07830](https://arxiv.org/abs/1707.07830)\n\n**Learning uncertainty in regression tasks by deep neural networks**\n\n- intro: Free University of Berlin\n- arxiv: [https://arxiv.org/abs/1707.07287](https://arxiv.org/abs/1707.07287)\n\n**Generalizing the Convolution Operator in Convolutional Neural Networks**\n\n[https://arxiv.org/abs/1707.09864](https://arxiv.org/abs/1707.09864)\n\n**Convolution with Logarithmic Filter Groups for Efficient Shallow CNN**\n\n[https://arxiv.org/abs/1707.09855](https://arxiv.org/abs/1707.09855)\n\n**Deep Multi-View Learning with Stochastic Decorrelation Loss**\n\n[https://arxiv.org/abs/1707.09669](https://arxiv.org/abs/1707.09669)\n\n**Take it in your stride: Do we need striding in CNNs?**\n\n[https://arxiv.org/abs/1712.02502](https://arxiv.org/abs/1712.02502)\n\n**Security Risks in Deep Learning Implementation**\n\n- intro: Qihoo 360 Security Research Lab & University of Georgia & University of Virginia\n- arxiv: [https://arxiv.org/abs/1711.11008](https://arxiv.org/abs/1711.11008)\n\n**Online Learning with Gated Linear Networks**\n\n- intro: DeepMind\n- arxiv: [https://arxiv.org/abs/1712.01897](https://arxiv.org/abs/1712.01897)\n\n**On the Information Bottleneck Theory of Deep Learning**\n\n[https://openreview.net/forum?id=ry_WPG-A-&noteId=ry_WPG-A](https://openreview.net/forum?id=ry_WPG-A-&noteId=ry_WPG-A)\n\n**The Unreasonable Effectiveness of Deep Features as a Perceptual Metric**\n\n- project page: [https://richzhang.github.io/PerceptualSimilarity/](https://richzhang.github.io/PerceptualSimilarity/)\n- arxiv: [https://arxiv.org/abs/1801.03924](https://arxiv.org/abs/1801.03924)\n- github: [https://github.com//richzhang/PerceptualSimilarity](https://github.com//richzhang/PerceptualSimilarity)\n\n**Less is More: Culling the Training Set to Improve Robustness of Deep Neural Networks**\n\n- intro: University of California, Davis\n- arxiv: [https://arxiv.org/abs/1801.02850](https://arxiv.org/abs/1801.02850)\n\n**Towards an Understanding of Neural Networks in Natural-Image Spaces**\n\n[https://arxiv.org/abs/1801.09097](https://arxiv.org/abs/1801.09097)\n\n**Deep Private-Feature Extraction**\n\n[https://arxiv.org/abs/1802.03151](https://arxiv.org/abs/1802.03151)\n\n**Not All Samples Are Created Equal: Deep Learning with Importance Sampling**\n\n- intro: Idiap Research Institute\n- arxiv: [https://arxiv.org/abs/1803.00942](https://arxiv.org/abs/1803.00942)\n\n**Label Refinery: Improving ImageNet Classification through Label Progression**\n\n- intro: Using a Label Refinery improves the state-of-the-art top-1 accuracy of (1) AlexNet from 59.3 to 67.2, \n(2) MobileNet from 70.6 to 73.39, (3) MobileNet-0.25 from 50.6 to 55.59, \n(4) VGG19 from 72.7 to 75.46, and (5) Darknet19 from 72.9 to 74.47.\n- intro: XNOR AI, University of Washington, Allen AI\n- arxiv: [https://arxiv.org/abs/1805.02641](https://arxiv.org/abs/1805.02641)\n- github: [https://github.com/hessamb/label-refinery](https://github.com/hessamb/label-refinery)\n\n**How Many Samples are Needed to Learn a Convolutional Neural Network?**\n\n[https://arxiv.org/abs/1805.07883](https://arxiv.org/abs/1805.07883)\n\n**VisualBackProp for learning using privileged information with CNNs**\n\n[https://arxiv.org/abs/1805.09474](https://arxiv.org/abs/1805.09474)\n\n**BAM: Bottleneck Attention Module**\n\n- intro: BMVC 2018 (oral). Lunit Inc. & Adobe Research\n- arxiv: [https://arxiv.org/abs/1807.06514](https://arxiv.org/abs/1807.06514)\n\n**CBAM: Convolutional Block Attention Module**\n\n- intro: ECCV 2018. Lunit Inc. & Adobe Research\n- arxiv: [https://arxiv.org/abs/1807.06521](https://arxiv.org/abs/1807.06521)\n\n**Scale equivariance in CNNs with vector fields**\n\n- intro: ICML/FAIM 2018 workshop on Towards learning with limited labels: Equivariance, Invariance, and Beyond (oral presentation)\n- arxiv: [https://arxiv.org/abs/1807.11783](https://arxiv.org/abs/1807.11783)\n\n**Downsampling leads to Image Memorization in Convolutional Autoencoders**\n\n[https://arxiv.org/abs/1810.10333](https://arxiv.org/abs/1810.10333)\n\n**Do Normalization Layers in a Deep ConvNet Really Need to Be Distinct?**\n\n[https://arxiv.org/abs/1811.07727](https://arxiv.org/abs/1811.07727)\n\n**Are All Training Examples Created Equal? An Empirical Study**\n\n[https://arxiv.org/abs/1811.12569](https://arxiv.org/abs/1811.12569)\n\n**ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness**\n\n[https://arxiv.org/abs/1811.12231](https://arxiv.org/abs/1811.12231)\n\n**DeepFashion2: A Versatile Benchmark for Detection, Pose Estimation, Segmentation and Re-Identification of Clothing Images**\n\n- intro: The Chinese University of Hong Kong & SenseTime Research\n- keywords: Match R-CNN\n- arxiv: [https://arxiv.org/abs/1901.07973](https://arxiv.org/abs/1901.07973)\n\n**A Comprehensive Overhaul of Feature Distillation**\n\n[https://arxiv.org/abs/1904.01866](https://arxiv.org/abs/1904.01866)\n\n**Mesh R-CNN**\n\n- intro: Facebook AI Research (FAIR)\n- arxiv: [https://arxiv.org/abs/1906.02739](https://arxiv.org/abs/1906.02739)\n\n**ViP: Virtual Pooling for Accelerating CNN-based Image Classification and Object Detection**\n\n[https://arxiv.org/abs/1906.07912](https://arxiv.org/abs/1906.07912)\n\n**VarGNet: Variable Group Convolutional Neural Network for Efficient Embedded Computing**\n\n- intro: Horizon Robotics\n- arxiv: [https://arxiv.org/abs/1907.05653](https://arxiv.org/abs/1907.05653)\n\n**Anchor Loss: Modulating Loss Scale based on Prediction Difficulty**\n\n- intro: ICCV 2019 oral\n- arxiv: [https://arxiv.org/abs/1909.11155](https://arxiv.org/abs/1909.11155)\n\n**Why ReLU networks yield high-confidence predictions far away from the training data and how to mitigate the problem**\n\n- intro: CVPR 2019 oral\n- arxiv: [https://arxiv.org/abs/1812.05720](https://arxiv.org/abs/1812.05720)\n- github: [https://github.com/max-andr/relu_networks_overconfident](https://github.com/max-andr/relu_networks_overconfident)\n\n**Feature Space Augmentation for Long-Tailed Data**\n\n- intro: ECCV 2020\n- arxiv: [https://arxiv.org/abs/2008.03673](https://arxiv.org/abs/2008.03673)\n\n## Tutorials and Surveys\n\n**A Survey: Time Travel in Deep Learning Space: An Introduction to Deep Learning Models and How Deep Learning Models Evolved from the Initial Ideas**\n\n- arxiv: [http://arxiv.org/abs/1510.04781](http://arxiv.org/abs/1510.04781)\n\n**On the Origin of Deep Learning**\n\n- intro: CMU. 70 pages, 200 references\n- arxiv: [https://arxiv.org/abs/1702.07800](https://arxiv.org/abs/1702.07800)\n\n**Efficient Processing of Deep Neural Networks: A Tutorial and Survey**\n\n- intro: MIT\n- arxiv: [https://arxiv.org/abs/1703.09039](https://arxiv.org/abs/1703.09039)\n\n**The History Began from AlexNet: A Comprehensive Survey on Deep Learning Approaches**\n\n{https://arxiv.org/abs/1803.01164}(https://arxiv.org/abs/1803.01164)\n\n## Mathematics of Deep Learning\n\n**A Mathematical Theory of Deep Convolutional Neural Networks for Feature Extraction**\n\n- arxiv: [http://arxiv.org/abs/1512.06293](http://arxiv.org/abs/1512.06293)\n\n**Mathematics of Deep Learning**\n\n- intro: Johns Hopkins University & New York University & Tel-Aviv University & University of California, Los Angeles\n- arxiv: [https://arxiv.org/abs/1712.04741](https://arxiv.org/abs/1712.04741)\n\n## Local Minima\n\n**Local minima in training of deep networks**\n\n- intro: DeepMind\n- arxiv: [https://arxiv.org/abs/1611.06310](https://arxiv.org/abs/1611.06310)\n\n**Deep linear neural networks with arbitrary loss: All local minima are global**\n\n- intro: CMU & University of Southern California & Facebook Artificial Intelligence Research\n- arxiv: [https://arxiv.org/abs/1712.00779](https://arxiv.org/abs/1712.00779)\n\n**Gradient Descent Learns One-hidden-layer CNN: Don't be Afraid of Spurious Local Minima**\n\n- intro: Loyola Marymount University & California State University\n- arxiv: [https://arxiv.org/abs/1712.01473](https://arxiv.org/abs/1712.01473)\n\n**CNNs are Globally Optimal Given Multi-Layer Support**\n\n- intro: CMU\n- arxiv: [https://arxiv.org/abs/1712.02501](https://arxiv.org/abs/1712.02501)\n\n**Spurious Local Minima are Common in Two-Layer ReLU Neural Networks**\n\n[https://arxiv.org/abs/1712.08968](https://arxiv.org/abs/1712.08968)\n\n## Dive Into CNN\n\n**Structured Receptive Fields in CNNs**\n\n- arxiv: [https://arxiv.org/abs/1605.02971](https://arxiv.org/abs/1605.02971)\n- github: [https://github.com/jhjacobsen/RFNN](https://github.com/jhjacobsen/RFNN)\n\n**How ConvNets model Non-linear Transformations**\n\n- arxiv: [https://arxiv.org/abs/1702.07664](https://arxiv.org/abs/1702.07664)\n\n## Separable Convolutions / Grouped Convolutions\n\n**Factorized Convolutional Neural Networks**\n\n**Design of Efficient Convolutional Layers using Single Intra-channel Convolution, Topological Subdivisioning and Spatial \"Bottleneck\" Structure**\n\n- arxiv: [http://arxiv.org/abs/1608.04337](http://arxiv.org/abs/1608.04337)\n\n**XSepConv: Extremely Separated Convolution**\n\n- intro: Tsinghua University & University College London\n- arxiv: [https://arxiv.org/abs/2002.12046](https://arxiv.org/abs/2002.12046)\n\n## STDP\n\n**A biological gradient descent for prediction through a combination of STDP and homeostatic plasticity**\n\n- arxiv: [http://arxiv.org/abs/1206.4812](http://arxiv.org/abs/1206.4812)\n\n**An objective function for STDP**\n\n- arxiv: [http://arxiv.org/abs/1509.05936](http://arxiv.org/abs/1509.05936)\n\n**Towards a Biologically Plausible Backprop**\n\n- arxiv: [http://arxiv.org/abs/1602.05179](http://arxiv.org/abs/1602.05179)\n\n## Target Propagation\n\n**How Auto-Encoders Could Provide Credit Assignment in Deep Networks via Target Propagation**\n\n- arxiv: [http://arxiv.org/abs/1407.7906](http://arxiv.org/abs/1407.7906)\n\n**Difference Target Propagation**\n\n- arxiv: [http://arxiv.org/abs/1412.7525](http://arxiv.org/abs/1412.7525)\n- github: [https://github.com/donghyunlee/dtp](https://github.com/donghyunlee/dtp)\n\n## Zero Shot Learning\n\n**Learning a Deep Embedding Model for Zero-Shot Learning**\n\n- arxiv: [https://arxiv.org/abs/1611.05088](https://arxiv.org/abs/1611.05088)\n\n**Zero-Shot (Deep) Learning**\n\n[https://amundtveit.com/2016/11/18/zero-shot-deep-learning/](https://amundtveit.com/2016/11/18/zero-shot-deep-learning/)\n\n**Zero-shot learning experiments by deep learning.**\n\n[https://github.com/Elyorcv/zsl-deep-learning](https://github.com/Elyorcv/zsl-deep-learning)\n\n**Zero-Shot Learning - The Good, the Bad and the Ugly**\n\n- intro: CVPR 2017\n- arxiv: [https://arxiv.org/abs/1703.04394](https://arxiv.org/abs/1703.04394)\n\n**Semantic Autoencoder for Zero-Shot Learning**\n\n- intro: CVPR 2017\n- project page: [https://elyorcv.github.io/projects/sae](https://elyorcv.github.io/projects/sae)\n- arxiv: [https://arxiv.org/abs/1704.08345](https://arxiv.org/abs/1704.08345)\n- github: [https://github.com/Elyorcv/SAE](https://github.com/Elyorcv/SAE)\n\n**Zero-Shot Learning via Category-Specific Visual-Semantic Mapping**\n\n[https://arxiv.org/abs/1711.06167](https://arxiv.org/abs/1711.06167)\n\n**Zero-Shot Learning via Class-Conditioned Deep Generative Models**\n\n- intro: AAAI 2018\n- arxiv: [https://arxiv.org/abs/1711.05820](https://arxiv.org/abs/1711.05820)\n\n**Feature Generating Networks for Zero-Shot Learning**\n\n[https://arxiv.org/abs/1712.00981](https://arxiv.org/abs/1712.00981)\n\n**Zero-Shot Visual Recognition using Semantics-Preserving Adversarial Embedding Network**\n\n[https://arxiv.org/abs/1712.01928](https://arxiv.org/abs/1712.01928)\n\n**Combining Deep Universal Features, Semantic Attributes, and Hierarchical Classification for Zero-Shot Learning**\n\n- intro: extension to work published in conference proceedings of 2017 IAPR MVA Conference\n- arxiv: [https://arxiv.org/abs/1712.03151](https://arxiv.org/abs/1712.03151)\n\n**Multi-Context Label Embedding**\n\n- keywords: Multi-Context Label Embedding (MCLE) \n- arxiv: [https://arxiv.org/abs/1805.01199](https://arxiv.org/abs/1805.01199)\n\n## Incremental Learning\n\n**iCaRL: Incremental Classifier and Representation Learning**\n\n- arxiv: [https://arxiv.org/abs/1611.07725](https://arxiv.org/abs/1611.07725)\n\n**FearNet: Brain-Inspired Model for Incremental Learning**\n\n[https://arxiv.org/abs/1711.10563](https://arxiv.org/abs/1711.10563)\n\n**Incremental Learning in Deep Convolutional Neural Networks Using Partial Network Sharing**\n\n- intro: Purdue University\n- arxiv: [https://arxiv.org/abs/1712.02719](https://arxiv.org/abs/1712.02719)\n\n**Incremental Classifier Learning with Generative Adversarial Networks**\n\n[https://arxiv.org/abs/1802.00853](https://arxiv.org/abs/1802.00853)\n\n**Learn the new, keep the old: Extending pretrained models with new anatomy and images**\n\n- intro: MICCAI 2018\n- arxiv: [https://arxiv.org/abs/1806.00265](https://arxiv.org/abs/1806.00265)\n\n## Ensemble Deep Learning\n\n**Convolutional Neural Fabrics**\n\n- intro: NIPS 2016\n- arxiv: [http://arxiv.org/abs/1606.02492](http://arxiv.org/abs/1606.02492)\n- github: [https://github.com/shreyassaxena/convolutional-neural-fabrics](https://github.com/shreyassaxena/convolutional-neural-fabrics)\n\n**Stochastic Multiple Choice Learning for Training Diverse Deep Ensembles**\n\n- arxiv: [https://arxiv.org/abs/1606.07839](https://arxiv.org/abs/1606.07839)\n- youtube: [https://www.youtube.com/watch?v=KjUfMtZjyfg&feature=youtu.be](https://www.youtube.com/watch?v=KjUfMtZjyfg&feature=youtu.be)\n\n**Snapshot Ensembles: Train 1, Get M for Free**\n\n- paper: [http://openreview.net/pdf?id=BJYwwY9ll](http://openreview.net/pdf?id=BJYwwY9ll)\n- github(Torch): [https://github.com/gaohuang/SnapshotEnsemble](https://github.com/gaohuang/SnapshotEnsemble)\n- github: [https://github.com/titu1994/Snapshot-Ensembles](https://github.com/titu1994/Snapshot-Ensembles)\n\n**Ensemble Deep Learning**\n\n- blog: [https://amundtveit.com/2016/12/02/ensemble-deep-learning/](https://amundtveit.com/2016/12/02/ensemble-deep-learning/)\n\n## Domain Adaptation\n\n**Adversarial Discriminative Domain Adaptation**\n\n- intro: UC Berkeley & Stanford University & Boston University\n- arxiv: [https://arxiv.org/abs/1702.05464](https://arxiv.org/abs/1702.05464)\n- github: [https://github.com//corenel/pytorch-adda](https://github.com//corenel/pytorch-adda)\n\n**Parameter Reference Loss for Unsupervised Domain Adaptation**\n\n[https://arxiv.org/abs/1711.07170](https://arxiv.org/abs/1711.07170)\n\n**Residual Parameter Transfer for Deep Domain Adaptation**\n\n[https://arxiv.org/abs/1711.07714](https://arxiv.org/abs/1711.07714)\n\n**Adversarial Feature Augmentation for Unsupervised Domain Adaptation**\n\n[https://arxiv.org/abs/1711.08561](https://arxiv.org/abs/1711.08561)\n\n**Image to Image Translation for Domain Adaptation**\n\n[https://arxiv.org/abs/1712.00479](https://arxiv.org/abs/1712.00479)\n\n**Incremental Adversarial Domain Adaptation**\n\n[https://arxiv.org/abs/1712.07436](https://arxiv.org/abs/1712.07436)\n\n**Deep Visual Domain Adaptation: A Survey**\n\n[https://arxiv.org/abs/1802.03601](https://arxiv.org/abs/1802.03601)\n\n**Unsupervised Domain Adaptation: A Multi-task Learning-based Method**\n\n[https://arxiv.org/abs/1803.09208](https://arxiv.org/abs/1803.09208)\n\n**Importance Weighted Adversarial Nets for Partial Domain Adaptation**\n\n[https://arxiv.org/abs/1803.09210](https://arxiv.org/abs/1803.09210)\n\n**Open Set Domain Adaptation by Backpropagation**\n\n[https://arxiv.org/abs/1804.10427](https://arxiv.org/abs/1804.10427)\n\n**Learning Sampling Policies for Domain Adaptation**\n\n- intro: CMU\n- arxiv: [https://arxiv.org/abs/1805.07641](https://arxiv.org/abs/1805.07641)\n\n**Multi-Adversarial Domain Adaptation**\n\n- intro: AAAI 2018 Oral.\n- arxiv: [https://arxiv.org/abs/1809.02176](https://arxiv.org/abs/1809.02176)\n\n**Unsupervised Domain Adaptation: An Adaptive Feature Norm Approach**\n\n- intro: Sun Yat-sen University\n- arxiv: [https://arxiv.org/abs/1811.07456](https://arxiv.org/abs/1811.07456)\n- github: [https://github.com/jihanyang/AFN/](https://github.com/jihanyang/AFN/)\n\n**Multi-source Distilling Domain Adaptation**\n\n- intro: AAAI 2020\n- arxiv: [https://arxiv.org/abs/1911.11554](https://arxiv.org/abs/1911.11554)\n- github: [https://github.com/daoyuan98/MDDA](https://github.com/daoyuan98/MDDA)\n\n**awsome-domain-adaptation**\n\n[https://github.com/zhaoxin94/awsome-domain-adaptation](https://github.com/zhaoxin94/awsome-domain-adaptation)\n\n## Embedding\n\n**Learning Deep Embeddings with Histogram Loss**\n\n- intro: NIPS 2016\n- arxiv: [https://arxiv.org/abs/1611.00822](https://arxiv.org/abs/1611.00822)\n\n**Full-Network Embedding in a Multimodal Embedding Pipeline**\n\n[https://arxiv.org/abs/1707.09872](https://arxiv.org/abs/1707.09872)\n\n**Clustering-driven Deep Embedding with Pairwise Constraints**\n\n[https://arxiv.org/abs/1803.08457](https://arxiv.org/abs/1803.08457)\n\n**Deep Mixture of Experts via Shallow Embedding**\n\n[https://arxiv.org/abs/1806.01531](https://arxiv.org/abs/1806.01531)\n\n**Learning to Learn from Web Data through Deep Semantic Embeddings**\n\n- intro: ECCV MULA Workshop 2018\n- arxiv: [https://arxiv.org/abs/1808.06368](https://arxiv.org/abs/1808.06368)\n\n**Heated-Up Softmax Embedding**\n\n[https://arxiv.org/abs/1809.04157](https://arxiv.org/abs/1809.04157)\n\n**Virtual Class Enhanced Discriminative Embedding Learning**\n\n- intro: NeurIPS 2018\n- arxiv: [https://arxiv.org/abs/1811.12611](https://arxiv.org/abs/1811.12611)\n\n## Regression\n\n**A Comprehensive Analysis of Deep Regression**\n\n[https://arxiv.org/abs/1803.08450](https://arxiv.org/abs/1803.08450)\n\n**Neural Motifs: Scene Graph Parsing with Global Context**\n\n- intro: CVPR 2018. University of Washington\n- project page: [http://rowanzellers.com/neuralmotifs/](http://rowanzellers.com/neuralmotifs/)\n- arxiv: [https://arxiv.org/abs/1711.06640](https://arxiv.org/abs/1711.06640)\n- github: [https://github.com/rowanz/neural-motifs](https://github.com/rowanz/neural-motifs)\n- demo: [https://rowanzellers.com/scenegraph2/](https://rowanzellers.com/scenegraph2/)\n\n## CapsNets\n\n**Dynamic Routing Between Capsules**\n\n- intro: Sara Sabour, Nicholas Frosst, Geoffrey E Hinton\n- intro: Google Brain, Toronto\n- arxiv: [https://arxiv.org/abs/1710.09829](https://arxiv.org/abs/1710.09829)\n- github(official, Tensorflow): [https://github.com/Sarasra/models/tree/master/research/capsules](https://github.com/Sarasra/models/tree/master/research/capsules)\n\n**Capsule Networks (CapsNets)  Tutorial**\n\n- youtube: [https://www.youtube.com/watch?v=pPN8d0E3900](https://www.youtube.com/watch?v=pPN8d0E3900)\n- mirror: [http://www.bilibili.com/video/av16594836/](http://www.bilibili.com/video/av16594836/)\n\n**Improved Explainability of Capsule Networks: Relevance Path by Agreement**\n\n- intro: Concordia University & University of Toronto\n- arxiv: [https://arxiv.org/abs/1802.10204](https://arxiv.org/abs/1802.10204)\n\n## Low Light\n\n**Exploring Image Enhancement for Salient Object Detection in Low Light Images**\n\n- intro: ACM Transactions on Multimedia Computing, Communications, and Applications\n- arxiv: [https://arxiv.org/abs/2007.16124](https://arxiv.org/abs/2007.16124)\n\n**NOD: Taking a Closer Look at Detection under Extreme Low-Light Conditions with Night Object Detection Dataset**\n\n- intro: BMVC 2021\n- arxiv: [https://arxiv.org/abs/2110.10364](https://arxiv.org/abs/2110.10364)\n\n## Computer Vision\n\n**A Taxonomy of Deep Convolutional Neural Nets for Computer Vision**\n\n- arxiv: [http://arxiv.org/abs/1601.06615](http://arxiv.org/abs/1601.06615)\n\n**On the usability of deep networks for object-based image analysis**\n\n- intro: GEOBIA 2016\n- arxiv: [http://arxiv.org/abs/1609.06845](http://arxiv.org/abs/1609.06845)\n\n**Learning Recursive Filters for Low-Level Vision via a Hybrid Neural Network**\n\n- intro: ECCV 2016\n- project page: [http://www.sifeiliu.net/linear-rnn](http://www.sifeiliu.net/linear-rnn)\n- paper: [http://faculty.ucmerced.edu/mhyang/papers/eccv16_rnn_filter.pdf](http://faculty.ucmerced.edu/mhyang/papers/eccv16_rnn_filter.pdf)\n- poster: [http://www.eccv2016.org/files/posters/O-3A-03.pdf](http://www.eccv2016.org/files/posters/O-3A-03.pdf)\n- github: [https://github.com/Liusifei/caffe-lowlevel](https://github.com/Liusifei/caffe-lowlevel)\n\n**Toward Geometric Deep SLAM**\n\n- intro: Magic Leap, Inc\n- arxiv: [https://arxiv.org/abs/1707.07410](https://arxiv.org/abs/1707.07410)\n\n**Learning Dual Convolutional Neural Networks for Low-Level Vision**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1805.05020](https://arxiv.org/abs/1805.05020)\n\n**Not just a matter of semantics: the relationship between visual similarity and semantic similarity**\n\n[https://arxiv.org/abs/1811.07120](https://arxiv.org/abs/1811.07120)\n\n**DF-SLAM: A Deep-Learning Enhanced Visual SLAM System based on Deep Local Features**\n\n- intro: BUPT & Megvii\n- arxiv: [https://arxiv.org/abs/1901.07223](https://arxiv.org/abs/1901.07223)\n\n**GN-Net: The Gauss-Newton Loss for Deep Direct SLAM**\n\n- intro: Technical University of Munich & Artisense\n- arxiv: [https://arxiv.org/abs/1904.11932](https://arxiv.org/abs/1904.11932)\n\n### All-In-One Network\n\n**HyperFace: A Deep Multi-task Learning Framework for Face Detection, Landmark Localization, Pose Estimation, and Gender Recognition**\n\n- arxiv: [https://arxiv.org/abs/1603.01249](https://arxiv.org/abs/1603.01249)\n- summary: [https://github.com/aleju/papers/blob/master/neural-nets/HyperFace.md](https://github.com/aleju/papers/blob/master/neural-nets/HyperFace.md)\n\n**UberNet: Training a `Universal' Convolutional Neural Network for Low-, Mid-, and High-Level Vision using Diverse Datasets and Limited Memory**\n\n- arxiv: [http://arxiv.org/abs/1609.02132](http://arxiv.org/abs/1609.02132)\n- demo: [http://cvn.ecp.fr/ubernet/](http://cvn.ecp.fr/ubernet/)\n\n**An All-In-One Convolutional Neural Network for Face Analysis**\n\n- intro: simultaneous face detection, face alignment, pose estimation, gender recognition, smile detection, age estimation and face recognition \n- arxiv: [https://arxiv.org/abs/1611.00851](https://arxiv.org/abs/1611.00851)\n\n**MultiNet: Real-time Joint Semantic Reasoning for Autonomous Driving**\n\n- intro: first place on Kitti Road Segmentation. \njoint classification, detection and semantic segmentation via a unified architecture, less than 100 ms to perform all tasks\n- arxiv: [https://arxiv.org/abs/1612.07695](https://arxiv.org/abs/1612.07695)\n- github: [https://github.com/MarvinTeichmann/MultiNet](https://github.com/MarvinTeichmann/MultiNet)\n\n**Adversarial Collaboration: Joint Unsupervised Learning of Depth, Camera Motion, Optical Flow and Motion Segmentation**\n\n[https://arxiv.org/abs/1805.09806](https://arxiv.org/abs/1805.09806)\n\n**Visual Person Understanding through Multi-Task and Multi-Dataset Learning**\n\n- intro: RWTH Aachen University\n- arxiv: [https://arxiv.org/abs/1906.03019](https://arxiv.org/abs/1906.03019)\n\n### Deep Learning for Data Structures\n\n**The Case for Learned Index Structures**\n\n- intro: MIT & Google\n- keywords: B-Tree-Index, Hash-Index, BitMap-Index\n- arxiv: [https://arxiv.org/abs/1712.01208](https://arxiv.org/abs/1712.01208)\n\n# Projects\n\n**Top Deep Learning Projects**\n\n- github: [https://github.com/aymericdamien/TopDeepLearning](https://github.com/aymericdamien/TopDeepLearning)\n\n**deepnet: Implementation of some deep learning algorithms**\n\n- github: [https://github.com/nitishsrivastava/deepnet](https://github.com/nitishsrivastava/deepnet)\n\n**DeepNeuralClassifier(Julia): Deep neural network using rectified linear units to classify hand written digits from the MNIST dataset**\n\n- github: [https://github.com/jostmey/DeepNeuralClassifier](https://github.com/jostmey/DeepNeuralClassifier)\n\n**Clarifai Node.js Demo**\n\n- github: [https://github.com/patcat/Clarifai-Node-Demo](https://github.com/patcat/Clarifai-Node-Demo)\n- blog(\"How to Make Your Web App Smarter with Image Recognition\"): [http://www.sitepoint.com/how-to-make-your-web-app-smarter-with-image-recognition/](http://www.sitepoint.com/how-to-make-your-web-app-smarter-with-image-recognition/)\n\n**Deep Learning in Rust**\n\n- blog(\"baby steps\"): [https://medium.com/@tedsta/deep-learning-in-rust-7e228107cccc#.t0pskuwkm](https://medium.com/@tedsta/deep-learning-in-rust-7e228107cccc#.t0pskuwkm)\n- blog(\"a walk in the park\"): [https://medium.com/@tedsta/deep-learning-in-rust-a-walk-in-the-park-fed6c87165ea#.pucj1l5yx](https://medium.com/@tedsta/deep-learning-in-rust-a-walk-in-the-park-fed6c87165ea#.pucj1l5yx)\n- github: [https://github.com/tedsta/deeplearn-rs](https://github.com/tedsta/deeplearn-rs)\n\n**Implementation of state-of-art models in Torch**\n\n- github: [https://github.com/aciditeam/torch-models](https://github.com/aciditeam/torch-models)\n\n**Deep Learning (Python, C, C++, Java, Scala, Go)**\n\n- github: [https://github.com/yusugomori/DeepLearning](https://github.com/yusugomori/DeepLearning)\n\n**deepmark: THE Deep Learning Benchmarks**\n\n- github: [https://github.com/DeepMark/deepmark](https://github.com/DeepMark/deepmark)\n\n**Siamese Net**\n\n- intro: \"This package shows how to train a siamese network using Lasagne and Theano and includes network definitions \nfor state-of-the-art networks including: DeepID, DeepID2, Chopra et. al, and Hani et. al. \nWe also include one pre-trained model using a custom convolutional network.\"\n- github: [https://github.com/Kadenze/siamese_net](https://github.com/Kadenze/siamese_net)\n\n**PRE-TRAINED CONVNETS AND OBJECT LOCALISATION IN KERAS**\n\n- blog: [https://blog.heuritech.com/2016/04/26/pre-trained-convnets-and-object-localisation-in-keras/](https://blog.heuritech.com/2016/04/26/pre-trained-convnets-and-object-localisation-in-keras/)\n- github: [https://github.com/heuritech/convnets-keras](https://github.com/heuritech/convnets-keras)\n\n**Deep Learning algorithms with TensorFlow: Ready to use implementations of various Deep Learning algorithms using TensorFlow**\n\n- homepage: [http://www.gabrieleangeletti.com/](http://www.gabrieleangeletti.com/)\n- github: [https://github.com/blackecho/Deep-Learning-TensorFlow](https://github.com/blackecho/Deep-Learning-TensorFlow)\n\n**Fast Multi-threaded VGG 19 Feature Extractor**\n\n- github: [https://github.com/coreylynch/vgg-19-feature-extractor](https://github.com/coreylynch/vgg-19-feature-extractor)\n\n**Live demo of neural network classifying images**\n\n![](/assets/cnn-materials/nn_classify_images_live_demo.jpg)\n\n[http://ml4a.github.io/dev/demos/cifar_confusion.html#](http://ml4a.github.io/dev/demos/cifar_confusion.html#)\n\n**mojo cnn: c++ convolutional neural network**\n\n- intro: the fast and easy header only c++ convolutional neural network package\n- github: [https://github.com/gnawice/mojo-cnn](https://github.com/gnawice/mojo-cnn)\n\n**DeepHeart: Neural networks for monitoring cardiac data**\n\n- github: [https://github.com/jisaacso/DeepHeart](https://github.com/jisaacso/DeepHeart)\n\n**Deep Water: Deep Learning in H2O using Native GPU Backends**\n\n- intro: Native implementation of Deep Learning models for GPU backends (mxnet, Caffe, TensorFlow, etc.)\n- github: [https://github.com/h2oai/deepwater](https://github.com/h2oai/deepwater)\n\n**Greentea LibDNN: Greentea LibDNN - a universal convolution implementation supporting CUDA and OpenCL**\n\n- github: [https://github.com/naibaf7/libdnn](https://github.com/naibaf7/libdnn)\n\n**Dracula: A spookily good Part of Speech Tagger optimized for Twitter**\n\n- intro: A deep, LSTM-based part of speech tagger and sentiment analyser using character embeddings instead of words. \nCompatible with Theano and TensorFlow. Optimized for Twitter.\n- homepage: [http://dracula.sentimentron.co.uk/](http://dracula.sentimentron.co.uk/)\n- speech tagging demo: [http://dracula.sentimentron.co.uk/pos-demo/](http://dracula.sentimentron.co.uk/pos-demo/)\n- sentiment demo: [http://dracula.sentimentron.co.uk/sentiment-demo/](http://dracula.sentimentron.co.uk/sentiment-demo/)\n- github: [https://github.com/Sentimentron/Dracula](https://github.com/Sentimentron/Dracula)\n\n**Trained image classification models for Keras**\n\n- intro: Keras code and weights files for popular deep learning models.\n- intro: VGG16, VGG19, ResNet50, Inception v3\n- github: [https://github.com/fchollet/deep-learning-models](https://github.com/fchollet/deep-learning-models)\n\n**PyCNN: Cellular Neural Networks Image Processing Python Library**\n\n![](https://camo.githubusercontent.com/0c5fd234a144b3d2145a133466766b2ecd9d3f3c/687474703a2f2f7777772e6973697765622e65652e6574687a2e63682f6861656e6767692f434e4e5f7765622f434e4e5f666967757265732f626c6f636b6469616772616d2e676966)\n\n- blog: [http://blog.ankitaggarwal.me/PyCNN/](http://blog.ankitaggarwal.me/PyCNN/)\n- github: [https://github.com/ankitaggarwal011/PyCNN](https://github.com/ankitaggarwal011/PyCNN)\n\n**regl-cnn: Digit recognition with Convolutional Neural Networks in WebGL**\n\n- intro: TensorFlow, WebGL, [regl](https://github.com/mikolalysenko/regl)\n- github: [https://github.com/Erkaman/regl-cnn/](https://github.com/Erkaman/regl-cnn/)\n- demo: [https://erkaman.github.io/regl-cnn/src/demo.html](https://erkaman.github.io/regl-cnn/src/demo.html)\n\n**dagstudio: Directed Acyclic Graph Studio with Javascript D3**\n\n![](https://raw.githubusercontent.com/TimZaman/dagstudio/master/misc/20160907_dagstudio_ex.gif)\n\n- github: [https://github.com/TimZaman/dagstudio](https://github.com/TimZaman/dagstudio)\n\n**NEUGO: Neural Networks in Go**\n\n- github: [https://github.com/wh1t3w01f/neugo](https://github.com/wh1t3w01f/neugo)\n\n**gvnn: Neural Network Library for Geometric Computer Vision**\n\n- arxiv: [http://arxiv.org/abs/1607.07405](http://arxiv.org/abs/1607.07405)\n- github: [https://github.com/ankurhanda/gvnn](https://github.com/ankurhanda/gvnn)\n\n**DeepForge: A development environment for deep learning**\n\n- github: [https://github.com/dfst/deepforge](https://github.com/dfst/deepforge)\n\n**Implementation of recent Deep Learning papers**\n\n- intro: DenseNet / DeconvNet / DenseRecNet\n- github: [https://github.com/tdeboissiere/DeepLearningImplementations](https://github.com/tdeboissiere/DeepLearningImplementations)\n\n**GPU-accelerated Theano & Keras on Windows 10 native**\n\n- github: [https://github.com/philferriere/dlwin](https://github.com/philferriere/dlwin)\n\n**Head Pose and Gaze Direction Estimation Using Convolutional Neural Networks**\n\n- github: [https://github.com/mpatacchiola/deepgaze](https://github.com/mpatacchiola/deepgaze)\n\n**Intel(R) Math Kernel Library for Deep Neural Networks (Intel(R) MKL-DNN)**\n\n- homepage: [https://01.org/mkl-dnn](https://01.org/mkl-dnn)\n- github: [https://github.com/01org/mkl-dnn](https://github.com/01org/mkl-dnn)\n\n**Deep CNN and RNN - Deep convolution/recurrent neural network project with TensorFlow**\n\n- github: [https://github.com/tobegit3hub/deep_cnn](https://github.com/tobegit3hub/deep_cnn)\n\n**Experimental implementation of novel neural network structures**\n\n- intro: binarynet / ternarynet / qrnn / vae / gcnn\n- github: [https://github.com/DingKe/nn_playground](https://github.com/DingKe/nn_playground)\n\n**WaterNet: A convolutional neural network that identifies water in satellite images**\n\n- github: [https://github.com/treigerm/WaterNet](https://github.com/treigerm/WaterNet)\n\n**Kur: Descriptive Deep Learning**\n\n- github: [https://github.com/deepgram/kur](https://github.com/deepgram/kur)\n- docs: [http://kur.deepgram.com/](http://kur.deepgram.com/)\n\n**Development of JavaScript-based deep learning platform and application to distributed training**\n\n- intro: Workshop paper for ICLR2017\n- arxiv: [https://arxiv.org/abs/1702.01846](https://arxiv.org/abs/1702.01846)\n- github: [https://github.com/mil-tokyo](https://github.com/mil-tokyo)\n\n**NewralNet**\n\n- intro: A lightweight, easy to use and open source Java library for experimenting with\nfeed-forward neural nets and deep learning.\n- gitlab: [https://gitlab.com/flimmerkiste/NewralNet](https://gitlab.com/flimmerkiste/NewralNet)\n\n**FeatherCNN**\n\n- intro: FeatherCNN is a high performance inference engine for convolutional neural networks\n- github: [https://github.com/Tencent/FeatherCNN](https://github.com/Tencent/FeatherCNN)\n\n# Readings and Questions\n\n**What you wanted to know about AI**\n\n[http://fastml.com/what-you-wanted-to-know-about-ai/](http://fastml.com/what-you-wanted-to-know-about-ai/)\n\n**Epoch vs iteration when training neural networks**\n\n- stackoverflow: [http://stackoverflow.com/questions/4752626/epoch-vs-iteration-when-training-neural-networks](http://stackoverflow.com/questions/4752626/epoch-vs-iteration-when-training-neural-networks)\n\n**Questions to Ask When Applying Deep Learning**\n\n[http://deeplearning4j.org/questions.html](http://deeplearning4j.org/questions.html)\n\n**How can I know if Deep Learning works better for a specific problem than SVM or random forest?**\n\n- github: [https://github.com/rasbt/python-machine-learning-book/blob/master/faq/deeplearn-vs-svm-randomforest.md](https://github.com/rasbt/python-machine-learning-book/blob/master/faq/deeplearn-vs-svm-randomforest.md)\n\n**What is the difference between deep learning and usual machine learning?**\n\n- note: [https://github.com/rasbt/python-machine-learning-book/blob/master/faq/difference-deep-and-normal-learning.md](https://github.com/rasbt/python-machine-learning-book/blob/master/faq/difference-deep-and-normal-learning.md)\n\n# Resources\n\n**Awesome Deep Learning**\n\n- github: [https://github.com/ChristosChristofidis/awesome-deep-learning](https://github.com/ChristosChristofidis/awesome-deep-learning)\n\n**Awesome-deep-vision: A curated list of deep learning resources for computer vision**\n\n- website: [http://jiwonkim.org/awesome-deep-vision/](http://jiwonkim.org/awesome-deep-vision/)\n- github: [https://github.com/kjw0612/awesome-deep-vision](https://github.com/kjw0612/awesome-deep-vision)\n\n**Applied Deep Learning Resources: A collection of research articles, blog posts, slides and code snippets about deep learning in applied settings.**\n\n- github: [https://github.com/kristjankorjus/applied-deep-learning-resources](https://github.com/kristjankorjus/applied-deep-learning-resources)\n\n**Deep Learning Libraries by Language**\n\n- website: [http://www.teglor.com/b/deep-learning-libraries-language-cm569/](http://www.teglor.com/b/deep-learning-libraries-language-cm569/)\n\n**Deep Learning Resources**\n\n[http://yanirseroussi.com/deep-learning-resources/](http://yanirseroussi.com/deep-learning-resources/)\n\n**Deep Learning Resources**\n\n[https://omtcyfz.github.io/2016/08/29/Deep-Learning-Resources.html](https://omtcyfz.github.io/2016/08/29/Deep-Learning-Resources.html)\n\n**Turing Machine: musings on theory & code(DEEP LEARNING REVOLUTION, summer 2015, state of the art & topnotch links)**\n\n[https://vzn1.wordpress.com/2015/09/01/deep-learning-revolution-summer-2015-state-of-the-art-topnotch-links/](https://vzn1.wordpress.com/2015/09/01/deep-learning-revolution-summer-2015-state-of-the-art-topnotch-links/)\n\n**BICV Group: Biologically Inspired Computer Vision research group**\n\n[http://www.bicv.org/deep-learning/](http://www.bicv.org/deep-learning/)\n\n**Learning Deep Learning**\n\n[http://rt.dgyblog.com/ref/ref-learning-deep-learning.html](http://rt.dgyblog.com/ref/ref-learning-deep-learning.html)\n\n**Summaries and notes on Deep Learning research papers**\n\n- github: [https://github.com/dennybritz/deeplearning-papernotes](https://github.com/dennybritz/deeplearning-papernotes)\n\n**Deep Learning Glossary**\n\n- intro: \"Simple, opinionated explanations of various things encountered in Deep Learning / AI / ML.\"\n- author: Ryan Dahl, author of NodeJS. \n- github: [https://github.com/ry/deep_learning_glossary](https://github.com/ry/deep_learning_glossary)\n\n**The Deep Learning Playbook**\n\n[https://medium.com/@jiefeng/deep-learning-playbook-c5ebe34f8a1a#.eg9cdz5ak](https://medium.com/@jiefeng/deep-learning-playbook-c5ebe34f8a1a#.eg9cdz5ak)\n\n**Deep Learning Study: Study of HeXA@UNIST in Preparation for Submission**\n\n- github: [https://github.com/carpedm20/deep-learning-study](https://github.com/carpedm20/deep-learning-study)\n\n**Deep Learning Books**\n\n- blog: [http://machinelearningmastery.com/deep-learning-books/](http://machinelearningmastery.com/deep-learning-books/)\n\n**awesome-very-deep-learning: A curated list of papers and code about very deep neural networks (50+ layers)**\n\n- github: [https://github.com/daviddao/awesome-very-deep-learning](https://github.com/daviddao/awesome-very-deep-learning)\n\n**Deep Learning Resources and Tutorials using Keras and Lasagne**\n\n- github: [https://github.com/Vict0rSch/deep_learning](https://github.com/Vict0rSch/deep_learning)\n\n**Deep Learning: Definition, Resources, Comparison with Machine Learning**\n\n- blog: [http://www.datasciencecentral.com/profiles/blogs/deep-learning-definition-resources-comparison-with-machine-learni](http://www.datasciencecentral.com/profiles/blogs/deep-learning-definition-resources-comparison-with-machine-learni)\n\n**Awesome - Most Cited Deep Learning Papers**\n\n- github: [https://github.com/terryum/awesome-deep-learning-papers](https://github.com/terryum/awesome-deep-learning-papers)\n\n**The most cited papers in computer vision and deep learning**\n\n- blog: [https://computervisionblog.wordpress.com/2016/06/19/the-most-cited-papers-in-computer-vision-and-deep-learning/](https://computervisionblog.wordpress.com/2016/06/19/the-most-cited-papers-in-computer-vision-and-deep-learning/)\n\n**deep learning papers: A place to collect papers that are related to deep learning and computational biology**\n\n- github: [https://github.com/pimentel/deep_learning_papers](https://github.com/pimentel/deep_learning_papers)\n\n**papers-I-read**\n\n- intro: \"I am trying a new initiative - a-paper-a-week. This repository will hold all those papers and related summaries and notes.\"\n- github: [https://github.com/shagunsodhani/papers-I-read](https://github.com/shagunsodhani/papers-I-read)\n\n**LEARNING DEEP LEARNING - MY TOP-FIVE LIST**\n\n- blog: [http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/](http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/)\n\n**awesome-free-deep-learning-papers**\n\n- github: [https://github.com/HFTrader/awesome-free-deep-learning-papers](https://github.com/HFTrader/awesome-free-deep-learning-papers)\n\n**DeepLearningBibliography: Bibliography for Publications about Deep Learning using GPU**\n\n- homepage: [http://memkite.com/deep-learning-bibliography/](http://memkite.com/deep-learning-bibliography/)\n- github: [https://github.com/memkite/DeepLearningBibliography](https://github.com/memkite/DeepLearningBibliography)\n\n**Deep Learning Papers Reading Roadmap**\n\n- github: [https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap](https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap)\n\n**deep-learning-papers**\n\n- intro: Papers about deep learning ordered by task, date. Current state-of-the-art papers are labelled.\n- github: [https://github.com/sbrugman/deep-learning-papers/blob/master/README.md](https://github.com/sbrugman/deep-learning-papers/blob/master/README.md)\n\n**Deep Learning and applications in Startups, CV, Text Mining, NLP**\n\n- github: [https://github.com/lipiji/app-dl](https://github.com/lipiji/app-dl)\n\n**ml4a-guides - a collection of practical resources for working with machine learning software, including code and tutorials**\n\n[http://ml4a.github.io/guides/](http://ml4a.github.io/guides/)\n\n**deep-learning-resources**\n\n- intro: A Collection of resources I have found useful on my journey finding my way through the world of Deep Learning.\n- github: [https://github.com/chasingbob/deep-learning-resources](https://github.com/chasingbob/deep-learning-resources)\n\n**21 Deep Learning Videos, Tutorials & Courses on Youtube from 2016**\n\n[https://www.analyticsvidhya.com/blog/2016/12/21-deep-learning-videos-tutorials-courses-on-youtube-from-2016/](https://www.analyticsvidhya.com/blog/2016/12/21-deep-learning-videos-tutorials-courses-on-youtube-from-2016/)\n\n**Awesome Deep learning papers and other resources**\n\n- github: [https://github.com/endymecy/awesome-deeplearning-resources](https://github.com/endymecy/awesome-deeplearning-resources)\n\n**awesome-deep-vision-web-demo**\n\n- intro: A curated list of awesome deep vision web demo\n- github: [https://github.com/hwalsuklee/awesome-deep-vision-web-demo](https://github.com/hwalsuklee/awesome-deep-vision-web-demo)\n\n**Summaries of machine learning papers**\n\n[https://github.com/aleju/papers](https://github.com/aleju/papers)\n\n**Awesome Deep Learning Resources**\n\n[https://github.com/guillaume-chevalier/awesome-deep-learning-resources](https://github.com/guillaume-chevalier/awesome-deep-learning-resources)\n\n**Virginia Tech Vision and Learning Reading Group**\n\n[https://github.com//vt-vl-lab/reading_group](https://github.com//vt-vl-lab/reading_group)\n\n**MEGALODON: ML/DL Resources At One Place**\n\n- intro: Various ML/DL Resources organised at a single place.\n- arxiv: [https://github.com//vyraun/Megalodon](https://github.com//vyraun/Megalodon)\n\n## Arxiv Pages\n\n**Neural and Evolutionary Computing**\n\n[https://arxiv.org/list/cs.NE/recent](https://arxiv.org/list/cs.NE/recent)\n\n**Learning**\n\n[https://arxiv.org/list/cs.LG/recent](https://arxiv.org/list/cs.LG/recent)\n\n**Computer Vision and Pattern Recognition**\n\n[https://arxiv.org/list/cs.CV/recent](https://arxiv.org/list/cs.CV/recent)\n\n## Arxiv Sanity Preserver\n\n- intro: Built by @karpathy to accelerate research.\n- page: [http://www.arxiv-sanity.com/](http://www.arxiv-sanity.com/)\n\n**Today's Deep Learning**\n\n[http://todaysdeeplearning.com/](http://todaysdeeplearning.com/)\n\n**arXiv Analytics**\n\n[http://arxitics.com/](http://arxitics.com/)\n\n## Papers with Code\n\n**Papers with Code**\n\n[https://paperswithcode.com/](https://paperswithcode.com/)\n\n# Tools\n\n**DNNGraph - A deep neural network model generation DSL in Haskell**\n\n- homepage: [http://ajtulloch.github.io/dnngraph/](http://ajtulloch.github.io/dnngraph/)\n\n**Deep playground: an interactive visualization of neural networks, written in typescript using d3.js**\n\n- homepage: [http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.23990&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification](http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.23990&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification)\n- github: [https://github.com/tensorflow/playground](https://github.com/tensorflow/playground)\n\n**Neural Network Package**\n\n- intro: This package provides an easy and modular way to build and train simple or complex neural networks using Torch\n- github: [https://github.com/torch/nn](https://github.com/torch/nn)\n\n**deepdish: Deep learning and data science tools from the University of Chicago**\n**deepdish: Serving Up Chicago-Style Deep Learning**\n\n- homepage: [http://deepdish.io/](http://deepdish.io/)\n- github: [https://github.com/uchicago-cs/deepdish](https://github.com/uchicago-cs/deepdish)\n\n**AETROS CLI: Console application to manage deep neural network training in AETROS Trainer**\n\n- intro: Create, train and monitor deep neural networks using a model designer.\n- homepage: [http://aetros.com/](http://aetros.com/)\n- github: [https://github.com/aetros/aetros-cli](https://github.com/aetros/aetros-cli)\n\n**Deep Learning Studio: Cloud platform for designing Deep Learning AI without programming**\n\n[http://deepcognition.ai/](http://deepcognition.ai/)\n\n**cuda-on-cl: Build NVIDIA CUDA code for OpenCL 1.2 devices**\n\n- github: [https://github.com/hughperkins/cuda-on-cl](https://github.com/hughperkins/cuda-on-cl)\n\n**Receptive Field Calculator**\n\n- homepage: [http://fomoro.com/tools/receptive-fields/](http://fomoro.com/tools/receptive-fields/)\n- example: [http://fomoro.com/tools/receptive-fields/#3,1,1,VALID;3,1,1,VALID;3,1,1,VALID](http://fomoro.com/tools/receptive-fields/#3,1,1,VALID;3,1,1,VALID;3,1,1,VALID)\n\n**receptivefield**\n\n- intro: (PyTorch/Keras/TensorFlow)Gradient based receptive field estimation for Convolutional Neural Networks\n- github: [https://github.com//fornaxai/receptivefield](https://github.com//fornaxai/receptivefield)\n\n# Challenges / Hackathons\n\n**Open Images Challenge 2018**\n\n[https://storage.googleapis.com/openimages/web/challenge.html](https://storage.googleapis.com/openimages/web/challenge.html)\n\n**VisionHack 2017**\n\n- intro: 10 - 14 Sep 2017, Moscow, Russia\n- intro: a full-fledged hackathon that will last three full days\n- homepage: [http://visionhack.misis.ru/](http://visionhack.misis.ru/)\n\n**NVIDIA AI City Challenge Workshop at CVPR 2018**\n\n[http://www.aicitychallenge.org/](http://www.aicitychallenge.org/)\n\n# Books\n\n**Deep Learning**\n\n- author: Ian Goodfellow, Aaron Courville and Yoshua Bengio\n- homepage: [http://www.deeplearningbook.org/](http://www.deeplearningbook.org/)\n- website: [http://goodfeli.github.io/dlbook/](http://goodfeli.github.io/dlbook/)\n- github: [https://github.com/HFTrader/DeepLearningBook](https://github.com/HFTrader/DeepLearningBook)\n- notes(\"Deep Learning for Beginners\"): [http://randomekek.github.io/deep/deeplearning.html](http://randomekek.github.io/deep/deeplearning.html)\n\n**Fundamentals of Deep Learning: Designing Next-Generation Artificial Intelligence Algorithms**\n\n- author: Nikhil Buduma\n- book review: [http://www.opengardensblog.futuretext.com/archives/2015/08/book-review-fundamentals-of-deep-learning-designing-next-generation-artificial-intelligence-algorithms-by-nikhil-buduma.html](http://www.opengardensblog.futuretext.com/archives/2015/08/book-review-fundamentals-of-deep-learning-designing-next-generation-artificial-intelligence-algorithms-by-nikhil-buduma.html)\n- github: [https://github.com/darksigma/Fundamentals-of-Deep-Learning-Book](https://github.com/darksigma/Fundamentals-of-Deep-Learning-Book)\n\n**FIRST CONTACT WITH TENSORFLOW: Get started with with Deep Learning programming**\n\n- author: Jordi Torres\n- book: [http://www.jorditorres.org/first-contact-with-tensorflow/](http://www.jorditorres.org/first-contact-with-tensorflow/)\n\n****\n\n- intro: by Xiu-Shen WEI\n- homepage: [http://lamda.nju.edu.cn/weixs/book/CNN_book.html](http://lamda.nju.edu.cn/weixs/book/CNN_book.html)\n\n**Make Your Own Neural Network: IPython Neural Networks on a Raspberry Pi Zero**\n\n- book: [http://makeyourownneuralnetwork.blogspot.jp/2016/03/ipython-neural-networks-on-raspberry-pi.html](http://makeyourownneuralnetwork.blogspot.jp/2016/03/ipython-neural-networks-on-raspberry-pi.html)\n- github: [https://github.com/makeyourownneuralnetwork/makeyourownneuralnetwork](https://github.com/makeyourownneuralnetwork/makeyourownneuralnetwork)\n\n# Blogs\n\n**Neural Networks and Deep Learning**\n\n[http://neuralnetworksanddeeplearning.com](http://neuralnetworksanddeeplearning.com)\n\n**Deep Learning Reading List**\n\n[http://deeplearning.net/reading-list/](http://deeplearning.net/reading-list/)\n\n**WILDML: A BLOG ABOUT MACHINE LEARNING, DEEP LEARNING AND NLP.**\n\n[http://www.wildml.com/](http://www.wildml.com/)\n\n**Andrej Karpathy blog**\n\n[http://karpathy.github.io/](http://karpathy.github.io/)\n\n**Rodrigob's github page**\n\n[http://rodrigob.github.io/](http://rodrigob.github.io/)\n\n**colah's blog**\n\n[http://colah.github.io/](http://colah.github.io/)\n\n**What My Deep Model Doesn't Know...**\n\n[http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html](http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html)\n\n**Christoph Feichtenhofer**\n\n- intro: PhD Student, Graz University of Technology\n- homepage: [http://feichtenhofer.github.io/](http://feichtenhofer.github.io/)\n\n**Image recognition is not enough: As with language, photos need contextual intelligence**\n\n[https://medium.com/@ken_getquik/image-recognition-is-not-enough-293cd7d58004#.dex817l2z](https://medium.com/@ken_getquik/image-recognition-is-not-enough-293cd7d58004#.dex817l2z)\n\n**ResNets, HighwayNets, and DenseNets, Oh My!**\n\n- blog: [https://medium.com/@awjuliani/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32#.pgltg8pro](https://medium.com/@awjuliani/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32#.pgltg8pro)\n- github: [https://github.com/awjuliani/TF-Tutorials/blob/master/Deep%20Network%20Comparison.ipynb](https://github.com/awjuliani/TF-Tutorials/blob/master/Deep%20Network%20Comparison.ipynb)\n\n**The Frontiers of Memory and Attention in Deep Learning**\n\n- sldies: [http://slides.com/smerity/quora-frontiers-of-memory-and-attention#/](http://slides.com/smerity/quora-frontiers-of-memory-and-attention#/)\n\n**Design Patterns for Deep Learning Architectures**\n\n[http://www.deeplearningpatterns.com/doku.php](http://www.deeplearningpatterns.com/doku.php)\n\n**Building a Deep Learning Powered GIF Search Engine**\n\n- blog: [https://medium.com/@zan2434/building-a-deep-learning-powered-gif-search-engine-a3eb309d7525](https://medium.com/@zan2434/building-a-deep-learning-powered-gif-search-engine-a3eb309d7525)\n\n**850k Images in 24 hours: Automating Deep Learning Dataset Creation**\n\n[https://gab41.lab41.org/850k-images-in-24-hours-automating-deep-learning-dataset-creation-60bdced04275#.xhq9feuxx](https://gab41.lab41.org/850k-images-in-24-hours-automating-deep-learning-dataset-creation-60bdced04275#.xhq9feuxx)\n\n**How six lines of code + SQL Server can bring Deep Learning to ANY App**\n\n- blog: [https://blogs.technet.microsoft.com/dataplatforminsider/2017/01/05/how-six-lines-of-code-sql-server-can-bring-deep-learning-to-any-app/](https://blogs.technet.microsoft.com/dataplatforminsider/2017/01/05/how-six-lines-of-code-sql-server-can-bring-deep-learning-to-any-app/)\n- github: [https://github.com/Microsoft/SQL-Server-R-Services-Samples/tree/master/Galaxies](https://github.com/Microsoft/SQL-Server-R-Services-Samples/tree/master/Galaxies)\n\n**Neural Network Architectures**\n\n![](https://culurciello.github.io/assets/nets/acc_vs_net_vs_ops.svg)\n\n- blog: [https://medium.com/towards-data-science/neural-network-architectures-156e5bad51ba#.m8y39oih6](https://medium.com/towards-data-science/neural-network-architectures-156e5bad51ba#.m8y39oih6)\n- blog: [https://culurciello.github.io/tech/2016/06/04/nets.html](https://culurciello.github.io/tech/2016/06/04/nets.html)\n","excerpt":"ImageNet Single-model on 224x224 Method top1 top5 Model Size Speed ResNet-101 78.0% 94.0% ResNet-200 78.3% 94.2% Inception-v3 Inception-v4 ","outboundReferences":[],"inboundReferences":[]},"tagsOutbound":{"nodes":[]}},"pageContext":{"tags":[],"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-resources/","sidebarItems":[{"title":"Categories","items":[{"title":"Commercial","url":"","items":[{"title":"Commercial Structure","url":"/Commercial/Commercial Structure/","items":[]},{"title":"Community of Practice","url":"/Commercial/Community of Practice/","items":[]},{"title":"Domains","url":"/Commercial/Domains/","items":[]},{"title":"Webizen Alliance","url":"/Commercial/Webizen Alliance/","items":[]}]},{"title":"Core Services","url":"","items":[{"title":"Decentralised Ontologies","url":"/Core Services/Decentralised Ontologies/","items":[]},{"title":"Permissive Commons","url":"/Core Services/Permissive Commons/","items":[]},{"title":"Safety Protocols","url":"","items":[{"title":"Safety Protocols","url":"/Core Services/Safety Protocols/Safety Protocols/","items":[]},{"title":"Social Factors","url":"","items":[{"title":"Best Efforts","url":"/Core Services/Safety Protocols/Social Factors/Best Efforts/","items":[]},{"title":"Ending Digital Slavery","url":"/Core Services/Safety Protocols/Social Factors/Ending Digital Slavery/","items":[]},{"title":"Freedom of Thought","url":"/Core Services/Safety Protocols/Social Factors/Freedom of Thought/","items":[]},{"title":"No Golden Handcuffs","url":"/Core Services/Safety Protocols/Social Factors/No Golden Handcuffs/","items":[]},{"title":"Relationships (Social)","url":"/Core Services/Safety Protocols/Social Factors/Relationships (Social)/","items":[]},{"title":"Social Attack Vectors","url":"/Core Services/Safety Protocols/Social Factors/Social Attack Vectors/","items":[]},{"title":"The Webizen Charter","url":"/Core Services/Safety Protocols/Social Factors/The Webizen Charter/","items":[]}]},{"title":"Values Credentials","url":"/Core Services/Safety Protocols/Values Credentials/","items":[]}]},{"title":"Temporal Semantics","url":"/Core Services/Temporal Semantics/","items":[]},{"title":"Verifiable Claims & Credentials","url":"/Core Services/Verifiable Claims & Credentials/","items":[]},{"title":"Webizen Socio-Economics","url":"","items":[{"title":"Biosphere Ontologies","url":"/Core Services/Webizen Socio-Economics/Biosphere Ontologies/","items":[]},{"title":"Centricity","url":"/Core Services/Webizen Socio-Economics/Centricity/","items":[]},{"title":"Currencies","url":"/Core Services/Webizen Socio-Economics/Currencies/","items":[]},{"title":"SocioSphere Ontologies","url":"/Core Services/Webizen Socio-Economics/SocioSphere Ontologies/","items":[]},{"title":"Sustainable Development Goals (ESG)","url":"/Core Services/Webizen Socio-Economics/Sustainable Development Goals (ESG)/","items":[]}]}]},{"title":"Core Technologies","url":"","items":[{"title":"AUTH","url":"","items":[{"title":"Authentication Fabric","url":"/Core Technologies/AUTH/Authentication Fabric/","items":[]}]},{"title":"Webizen App Spec","url":"","items":[{"title":"SemWebSpecs","url":"","items":[{"title":"Core Ontologies","url":"","items":[{"title":"FOAF","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/FOAF/","items":[]},{"title":"General Ontology Information","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/General Ontology Information/","items":[]},{"title":"Human Rights Ontologies","url":"","items":[{"title":"UDHR","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/Human Rights Ontologies/UDHR/","items":[]}]},{"title":"MD-RDF Ontologies","url":"","items":[{"title":"DataTypesOntology (DTO) Core","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/MD-RDF Ontologies/DataTypes Ontology/","items":[]},{"title":"Friend of a Friend (FOAF) Core","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/MD-RDF Ontologies/FOAF/","items":[]}]},{"title":"OWL","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/OWL/","items":[]},{"title":"RDF Schema 1.1","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/RDFS/","items":[]},{"title":"Sitemap","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/Sitemap/","items":[]},{"title":"SKOS","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/SKOS/","items":[]},{"title":"SOIC","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/SOIC/","items":[]}]},{"title":"Semantic Web - An Introduction","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Semantic Web - An Introduction/","items":[]},{"title":"SemWeb-AUTH","url":"","items":[{"title":"WebID-OIDC","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-OIDC/","items":[]},{"title":"WebID-RSA","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-RSA/","items":[]},{"title":"WebID-TLS","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-TLS/","items":[]}]},{"title":"Sparql","url":"","items":[{"title":"Sparql Family","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Sparql/Sparql Family/","items":[]}]},{"title":"W3C Specifications","url":"","items":[{"title":"Linked Data Fragments","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Fragments/","items":[]},{"title":"Linked Data Notifications","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Notifications/","items":[]},{"title":"Linked Data Platform","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Platform/","items":[]},{"title":"Linked Media Fragments","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Media Fragments/","items":[]},{"title":"RDF","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/RDF/","items":[]},{"title":"Web Access Control (WAC)","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Web Access Control (WAC)/","items":[]},{"title":"Web Of Things","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Web Of Things/","items":[]},{"title":"WebID","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/WebID/","items":[]}]}]},{"title":"Webizen App Spec 1.0","url":"/Core Technologies/Webizen App Spec/Webizen App Spec 1.0/","items":[]},{"title":"WebSpec","url":"","items":[{"title":"HTML SPECS","url":"/Core Technologies/Webizen App Spec/WebSpec/HTML SPECS/","items":[]},{"title":"Query Interfaces","url":"","items":[{"title":"GraphQL","url":"/Core Technologies/Webizen App Spec/WebSpec/Query Interfaces/GraphQL/","items":[]}]},{"title":"WebPlatformTools","url":"","items":[{"title":"WebAuthn","url":"/Core Technologies/Webizen App Spec/WebSpec/WebPlatformTools/WebAuthn/","items":[]},{"title":"WebDav","url":"/Core Technologies/Webizen App Spec/WebSpec/WebPlatformTools/WebDav/","items":[]}]}]}]}]},{"title":"Database Requirements","url":"","items":[{"title":"Database Alternatives","url":"","items":[{"title":"Akutan","url":"/Database requirements/Database Alternatives/akutan/","items":[]},{"title":"CayleyGraph","url":"/Database requirements/Database Alternatives/CayleyGraph/","items":[]}]},{"title":"Database Methods","url":"","items":[{"title":"GraphQL","url":"/Database requirements/Database methods/GraphQL/","items":[]},{"title":"Sparql","url":"/Database requirements/Database methods/Sparql/","items":[]}]}]},{"title":"Host Service Requirements","url":"","items":[{"title":"Domain Hosting","url":"/Host Service Requirements/Domain Hosting/","items":[]},{"title":"Email Services","url":"/Host Service Requirements/Email Services/","items":[]},{"title":"LD_PostOffice_SemanticMGR","url":"/Host Service Requirements/LD_PostOffice_SemanticMGR/","items":[]},{"title":"Media Processing","url":"/Host Service Requirements/Media Processing/","items":[{"title":"Ffmpeg","url":"/Host Service Requirements/Media Processing/ffmpeg/","items":[]},{"title":"Opencv","url":"/Host Service Requirements/Media Processing/opencv/","items":[]}]},{"title":"Website Host","url":"/Host Service Requirements/Website Host/","items":[]}]},{"title":"ICT Stack","url":"","items":[{"title":"General References","url":"","items":[{"title":"List of Protocols ISO Model","url":"/ICT Stack/General References/List of Protocols ISO model/","items":[]}]},{"title":"Internet","url":"","items":[{"title":"Internet Stack","url":"/ICT Stack/Internet/Internet Stack/","items":[]}]}]},{"title":"Implementation V1","url":"","items":[{"title":"App-Design-Sdk-V1","url":"","items":[{"title":"Core Apps","url":"","items":[{"title":"Agent Directory","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Agent Directory/","items":[]},{"title":"Credentials & Contracts Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Credentials & Contracts Manager/","items":[]},{"title":"File (Package) Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/File (package) Manager/","items":[]},{"title":"Temporal Apps","url":"","items":[{"title":"Calendar","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Temporal Apps/Calendar/","items":[]},{"title":"Timeline Interface","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Temporal Apps/Timeline Interface/","items":[]}]},{"title":"Webizen Apps (V1)","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Webizen Apps (v1)/","items":[]},{"title":"Webizen Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Webizen Manager/","items":[]}]},{"title":"Data Applications","url":"/Implementation V1/App-design-sdk-v1/Data Applications/","items":[]},{"title":"Design Goals","url":"","items":[{"title":"Design Goals Overview","url":"/Implementation V1/App-design-sdk-v1/Design Goals/Design Goals Overview/","items":[]}]}]},{"title":"Edge","url":"","items":[{"title":"Webizen Local App Functionality","url":"/Implementation V1/edge/Webizen Local App Functionality/","items":[]}]},{"title":"GoLang Libraries","url":"/Implementation V1/GoLang Libraries/","items":[]},{"title":"Implementation V1 Summary","url":"/Implementation V1/Implementation V1 Summary/","items":[]},{"title":"Vps","url":"","items":[{"title":"Server Functionality Summary (VPS)","url":"/Implementation V1/vps/Server Functionality Summary (VPS)/","items":[]}]},{"title":"Webizen 1.0","url":"/Implementation V1/Webizen 1.0/","items":[]},{"title":"Webizen-Connect","url":"","items":[{"title":"Social Media APIs","url":"/Implementation V1/Webizen-Connect/Social Media APIs/","items":[]},{"title":"Webizen-Connect (Summary)","url":"/Implementation V1/Webizen-Connect/Webizen-Connect (summary)/","items":[]}]}]},{"title":"Non-HTTP(s) Protocols","url":"","items":[{"title":"DAT","url":"/Non-HTTP(s) Protocols/DAT/","items":[]},{"title":"GIT","url":"/Non-HTTP(s) Protocols/GIT/","items":[]},{"title":"GUNECO","url":"/Non-HTTP(s) Protocols/GUNECO/","items":[]},{"title":"IPFS","url":"/Non-HTTP(s) Protocols/IPFS/","items":[]},{"title":"Lightning Network","url":"/Non-HTTP(s) Protocols/Lightning Network/","items":[]},{"title":"Non-HTTP(s) Protocols (& DLTs)","url":"/Non-HTTP(s) Protocols/Non-HTTP(s) Protocols (& DLTs)/","items":[]},{"title":"WebRTC","url":"/Non-HTTP(s) Protocols/WebRTC/","items":[]},{"title":"WebSockets","url":"/Non-HTTP(s) Protocols/WebSockets/","items":[]},{"title":"WebTorrent","url":"/Non-HTTP(s) Protocols/WebTorrent/","items":[]}]},{"title":"Old-Work-Archives","url":"","items":[{"title":"2018-Webizen-Net-Au","url":"","items":[{"title":"_Link_library_links","url":"","items":[{"title":"Link Library","url":"/old-work-archives/2018-webizen-net-au/_link_library_links/2018-09-23-wp-linked-data/","items":[]}]},{"title":"_Posts","url":"","items":[{"title":"About W3C","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-27-about-w3c/","items":[]},{"title":"Advanced Functions &#8211; Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-16-advanced-functions-facebook-pages/","items":[]},{"title":"Advanced Search &#038; Discovery Tips","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-advanced-search-discovery-tips/","items":[]},{"title":"An introduction to Virtual Machines.","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-an-introduction-to-virtual-machines/","items":[]},{"title":"Basic Media Analysis &#8211; Part 1 (Audio)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-30-media-analysis-part-1-audio/","items":[]},{"title":"Basic Media Analysis &#8211; Part 2 (visual)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-31-media-analysis-part-2-visual/","items":[]},{"title":"Basic Media Analysis &#8211; Part 3 (Text &#038; Metadata)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-01-01-basic-media-analysis-part-3-text-metadata/","items":[]},{"title":"Building an Economy based upon Knowledge Equity.","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-25-building-an-economy-based-upon-knowledge-equity/","items":[]},{"title":"Choice of Law","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-26-choice-of-law/","items":[]},{"title":"Contemplation of the ITU Dubai Meeting and the Future of the Internet","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-19-contemplation-of-the-itu-dubai-meeting-and-the-future-of-the-internet/","items":[]},{"title":"Creating a Presence &#8211; Online","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-creating-a-presence-online/","items":[]},{"title":"Credentials and Payments by Manu Sporny","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-credentials-and-payments-by-manu-sporny/","items":[]},{"title":"Data Recovery &#038; Collection: Mobile Devices","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-28-mobile-devices-data-recovery-collection/","items":[]},{"title":"Data Recovery: Laptop &#038; Computers","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-28-data-recovery-laptop-computers/","items":[]},{"title":"Decentralized Web Conference 2016","url":"/old-work-archives/2018-webizen-net-au/_posts/2016-06-09-decentralized-web-2016/","items":[]},{"title":"Decentralized Web Summit 2018","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-decentralized-web-summit-2018/","items":[]},{"title":"Does Anonymity exist?","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-does-anonymity-exist/","items":[]},{"title":"Downloading My Data from Social Networks","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-downloading-my-data-from-social-networks/","items":[]},{"title":"Events","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-events/","items":[]},{"title":"Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-16-facebook-pages/","items":[]},{"title":"Google Tracking Data (geolocation)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-google-tracking/","items":[]},{"title":"Human Consciousness","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-human-consciousness/","items":[]},{"title":"Image Recgonition Video Playlist","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-image-recgonition-video-playlist/","items":[]},{"title":"Inferencing (introduction)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-inferencing-introduction/","items":[]},{"title":"Introduction to AI","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-introduction-to-ai/","items":[]},{"title":"Introduction to Linked Data","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-introduction-to-linked-data/","items":[]},{"title":"Introduction to Maltego","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-introduction-to-maltego/","items":[]},{"title":"Introduction to Ontologies","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-ontologies-intro/","items":[]},{"title":"Introduction to Semantic Web","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-introduction-to-semantic-web/","items":[]},{"title":"Knowledge Capital","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-10-17-knowledge-capital/","items":[]},{"title":"Logo&#8217;s, Style Guides and Artwork","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-logos-style-guides-and-artwork/","items":[]},{"title":"MindMapping &#8211; Setting-up a business &#8211; Identity","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-mindmapping-setting-up-a-business-identity/","items":[]},{"title":"Openlink Virtuoso","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-openlink-virtuoso/","items":[]},{"title":"OpenRefine","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-74-2/","items":[]},{"title":"Projects, Customers and Invoicing &#8211; Web-Services for Startups","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-projects-customers-and-invoicing-web-services-for-startups/","items":[]},{"title":"RWW &#038; some Solid history","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-rww-some-solid-history/","items":[]},{"title":"Semantic Web (An Intro)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-semantic-web-an-intro/","items":[]},{"title":"Setting-up Twitter","url":"/old-work-archives/2018-webizen-net-au/_posts/2013-06-07-setting-up-twitter/","items":[]},{"title":"Social Encryption: An Introduction","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-25-social-encryption-an-introduction/","items":[]},{"title":"Stock Content","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-stock-content/","items":[]},{"title":"The WayBack Machine","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-27-the-wayback-machine/","items":[]},{"title":"Tim Berners Lee &#8211; Turing Lecture","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-05-29-tim-berners-lee-turing-lecture/","items":[]},{"title":"Tools of Trade","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-tools-of-trade/","items":[]},{"title":"Trust Factory 2017","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-trust-factory-2017/","items":[]},{"title":"Verifiable Claims (An Introduction)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-vc-intro/","items":[]},{"title":"Web of Things &#8211; an Introduction","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-web-of-things-an-introduction/","items":[]},{"title":"Web-Persistence","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-web-persistence/","items":[]},{"title":"Web-Services &#8211; Marketing Tools","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-web-services-marketing-tools/","items":[]},{"title":"Website Templates","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-templates/","items":[]},{"title":"What is Linked Data?","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-what-is-linked-data/","items":[]},{"title":"What is Open Source Intelligence?","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-what-is-osint/","items":[]},{"title":"WiX","url":"/old-work-archives/2018-webizen-net-au/_posts/2013-01-01-wix/","items":[]}]},{"title":"about","url":"/old-work-archives/2018-webizen-net-au/about/","items":[{"title":"About The Author","url":"/old-work-archives/2018-webizen-net-au/about/about-the-author/","items":[]},{"title":"Applied Theory: Applications for a Human Centric Web","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/","items":[{"title":"Digital Receipts","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/digital-receipts/","items":[]},{"title":"Fake News: Considerations  Principles  The Institution of Socio &#8211; Economic Values","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations/","items":[]},{"title":"Healthy Living Economy","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/healthy-living-economy/","items":[]},{"title":"HyperMedia Solutions &#8211; Adapting HbbTV V2","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/","items":[{"title":"HYPERMEDIA PACKAGES","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/hypermedia-packages/","items":[]},{"title":"USER STORIES: INTERACTIVE VIEWING EXPERIENCE","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/user-stories-interactive-viewing-experience/","items":[]}]},{"title":"Measurements App","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/measurements-app/","items":[]},{"title":"Re:Animation","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/reanimation/","items":[]},{"title":"Solutions to FakeNews: Linked-Data, Ontologies and Verifiable Claims","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/ld-solutions-to-fakenews/","items":[]}]},{"title":"Executive Summary","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/","items":[{"title":"Assisting those who Enforce the Law","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/assisting-those-who-enforce-the-law/","items":[]},{"title":"Consumer Protections","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/consumer-protections/","items":[]},{"title":"Knowledge Banking: Legal Structures","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-banking-legal-structures/","items":[]},{"title":"Knowledge Economics &#8211; Services","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-economics-services/","items":[]},{"title":"Preserving The Freedom to Think","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/preserving-the-freedom-to-think/","items":[]}]},{"title":"History","url":"/old-work-archives/2018-webizen-net-au/about/history/","items":[{"title":"History: Global Governance and ICT.","url":"/old-work-archives/2018-webizen-net-au/about/history/history-global-governance-ict-1/","items":[]}]},{"title":"Knowledge Banking: A Technical Architecture Summary","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/","items":[{"title":"An introduction to Credentials.","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/","items":[{"title":"credentials and custodianship","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/credentials-and-custodianship/","items":[]},{"title":"DIDs and MultiSig","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/dids-and-multisig/","items":[]}]},{"title":"Personal Augmentation of AI","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/personal-augmentation-of-ai/","items":[]},{"title":"Semantic Inferencing","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/semantic-inferencing/","items":[]},{"title":"Web of Things (IoT+LD)","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/web-of-things-iotld/","items":[]}]},{"title":"References","url":"/old-work-archives/2018-webizen-net-au/about/references/","items":[{"title":"Making the distinction between privacy and dignity.","url":"/old-work-archives/2018-webizen-net-au/about/references/privacy-vs-dignity/","items":[]},{"title":"Roles &#8211; Entity Analysis","url":"/old-work-archives/2018-webizen-net-au/about/references/roles-entity-analysis/","items":[]},{"title":"Social Informatics Design Considerations","url":"/old-work-archives/2018-webizen-net-au/about/references/social-informatics-design-concept-and-principles/","items":[]},{"title":"Socio-economic relations | A conceptual model","url":"/old-work-archives/2018-webizen-net-au/about/references/socioeconomic-relations-p1/","items":[]},{"title":"The need for decentralised Open (Linked) Data","url":"/old-work-archives/2018-webizen-net-au/about/references/the-need-for-decentralised-open-linked-data/","items":[]}]},{"title":"The design of new medium","url":"/old-work-archives/2018-webizen-net-au/about/the-design-of-new-medium/","items":[]},{"title":"The need to modernise socioeconomic infrastructure","url":"/old-work-archives/2018-webizen-net-au/about/the-modernisation-of-socioeconomics/","items":[]},{"title":"The Vision","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/","items":[{"title":"Domesticating Pervasive Surveillance","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/a-technical-vision/","items":[]}]}]},{"title":"An Overview","url":"/old-work-archives/2018-webizen-net-au/the-human-centric-infosphere/","items":[]},{"title":"Resource Library","url":"/old-work-archives/2018-webizen-net-au/resource-library/","items":[{"title":"Handong1587","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/","items":[{"title":"_Posts","url":"","items":[{"title":"Computer_science","url":"","items":[{"title":"Algorithm and Data Structure Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-algo-resourses/","items":[]},{"title":"Artificial Intelligence Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-ai-resources/","items":[]},{"title":"Big Data Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-09-22-big-data-resources/","items":[]},{"title":"Computer Science Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-cs-resources/","items":[]},{"title":"Data Mining Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-data-mining-resources/","items":[]},{"title":"Data Science Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-data-science-resources/","items":[]},{"title":"Database Systems Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-database-resources/","items":[]},{"title":"Discrete Optimization Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-discrete-optimization/","items":[]},{"title":"Distribued System Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-12-12-ditributed-system-resources/","items":[]},{"title":"Funny Stuffs Of Computer Science","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-11-18-funny-stuffs-of-cs/","items":[]},{"title":"Robotics","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-09-26-robotics-resources/","items":[]},{"title":"Writting CS Papers","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-11-30-writing-papers/","items":[]}]},{"title":"Computer_vision","url":"","items":[{"title":"Computer Vision Datasets","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-24-datasets/","items":[]},{"title":"Computer Vision Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-12-cv-resources/","items":[]},{"title":"Features","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-10-09-features/","items":[]},{"title":"Recognition, Detection, Segmentation and Tracking","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-10-09-recognition-detection-segmentation-tracking/","items":[]},{"title":"Use FFmpeg to Capture I Frames of Video","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2016-03-03-ffmpeg-i-frame/","items":[]},{"title":"Working on OpenCV","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-12-25-working-on-opencv/","items":[]}]},{"title":"Deep_learning","url":"","items":[{"title":"3D","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2021-07-28-3d/","items":[]},{"title":"Acceleration and Model Compression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-cnn-compression-acceleration/","items":[]},{"title":"Acceleration and Model Compression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-knowledge-distillation/","items":[]},{"title":"Adversarial Attacks and Defences","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-adversarial-attacks-and-defences/","items":[]},{"title":"Audio / Image / Video Generation","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-audio-image-video-generation/","items":[]},{"title":"BEV","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2022-06-27-bev/","items":[]},{"title":"Classification / Recognition","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recognition/","items":[]},{"title":"Deep Learning and Autonomous Driving","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-autonomous-driving/","items":[]},{"title":"Deep Learning Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-pose-estimation/","items":[]},{"title":"Deep Learning Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-applications/","items":[]},{"title":"Deep learning Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-courses/","items":[]},{"title":"Deep Learning Frameworks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-frameworks/","items":[]},{"title":"Deep Learning Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-resources/","items":[]},{"title":"Deep Learning Software and Hardware","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-software-hardware/","items":[]},{"title":"Deep Learning Tricks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tricks/","items":[]},{"title":"Deep Learning Tutorials","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tutorials/","items":[]},{"title":"Deep Learning with Machine Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-with-ml/","items":[]},{"title":"Face Recognition","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-face-recognition/","items":[]},{"title":"Fun With Deep Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-fun-with-deep-learning/","items":[]},{"title":"Generative Adversarial Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gan/","items":[]},{"title":"Graph Convolutional Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gcn/","items":[]},{"title":"Image / Video Captioning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-captioning/","items":[]},{"title":"Image Retrieval","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-retrieval/","items":[]},{"title":"Keep Up With New Trends","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2018-09-03-keep-up-with-new-trends/","items":[]},{"title":"LiDAR 3D Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-lidar-3d-detection/","items":[]},{"title":"Natural Language Processing","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nlp/","items":[]},{"title":"Neural Architecture Search","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nas/","items":[]},{"title":"Object Counting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-counting/","items":[]},{"title":"Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-detection/","items":[]},{"title":"OCR","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-ocr/","items":[]},{"title":"Optical Flow","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-optical-flow/","items":[]},{"title":"Re-ID","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-re-id/","items":[]},{"title":"Recommendation System","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recommendation-system/","items":[]},{"title":"Reinforcement Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rl/","items":[]},{"title":"RNN and LSTM","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rnn-and-lstm/","items":[]},{"title":"Segmentation","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-segmentation/","items":[]},{"title":"Style Transfer","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-style-transfer/","items":[]},{"title":"Super-Resolution","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-super-resolution/","items":[]},{"title":"Tracking","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-tracking/","items":[]},{"title":"Training Deep Neural Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-training-dnn/","items":[]},{"title":"Transfer Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-transfer-learning/","items":[]},{"title":"Unsupervised Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-unsupervised-learning/","items":[]},{"title":"Video Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-video-applications/","items":[]},{"title":"Visual Question Answering","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-vqa/","items":[]},{"title":"Visualizing and Interpreting Convolutional Neural Network","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-visulizing-interpreting-cnn/","items":[]}]},{"title":"Leisure","url":"","items":[{"title":"All About Enya","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-all-about-enya/","items":[]},{"title":"Coldplay","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-coldplay/","items":[]},{"title":"Coldplay","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-nightwish/","items":[]},{"title":"Games","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-13-games/","items":[]},{"title":"Green Day","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-greenday/","items":[]},{"title":"Muse! Muse!","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-muse-muse/","items":[]},{"title":"Oasis","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-oasis/","items":[]},{"title":"Paintings By J.M.","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2016-03-08-paintings-by-jm/","items":[]},{"title":"Papers, Blogs and Websites","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-09-27-papers-blogs-and-websites/","items":[]},{"title":"Welcome To The Black Parade","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-welcome-to-the-black-parade/","items":[]}]},{"title":"Machine_learning","url":"","items":[{"title":"Bayesian Methods","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-bayesian-methods/","items":[]},{"title":"Clustering Algorithms Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-clustering/","items":[]},{"title":"Competitions","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-competitions/","items":[]},{"title":"Dimensionality Reduction Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-dimensionality-reduction/","items":[]},{"title":"Fun With Machine Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-fun-with-ml/","items":[]},{"title":"Graphical Models Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-graphical-models/","items":[]},{"title":"Machine Learning Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-ml-courses/","items":[]},{"title":"Machine Learning Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-ml-resources/","items":[]},{"title":"Natural Language Processing","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-nlp/","items":[]},{"title":"Neural Network","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-neural-network/","items":[]},{"title":"Random Field","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-random-field/","items":[]},{"title":"Random Forests","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-random-forests/","items":[]},{"title":"Regression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-regression/","items":[]},{"title":"Support Vector Machine","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-svm/","items":[]},{"title":"Topic Model","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-topic-model/","items":[]}]},{"title":"Mathematics","url":"","items":[{"title":"Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/mathematics/2016-02-24-resources/","items":[]}]},{"title":"Programming_study","url":"","items":[{"title":"Add Lunr Search Plugin For Blog","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-31-add-lunr-search-plugin-for-blog/","items":[]},{"title":"Android Development Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-05-23-android-resources/","items":[]},{"title":"C++ Programming Solutions","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-09-07-cpp-programming-solutions/","items":[]},{"title":"Commands To Suppress Some Building Errors With Visual Studio","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-24-cmds-to-suppress-some-vs-building-Errors/","items":[]},{"title":"Embedding Python In C/C++","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-10-embedding-python-in-cpp/","items":[]},{"title":"Enable Large Addresses On VS2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-12-14-enable-large-addresses/","items":[]},{"title":"Fix min/max Error In VS2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-02-17-min-max-error-in-vs2015/","items":[]},{"title":"Gflags Build Problems on Windows X86 and Visual Studio 2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-23-gflags-build-problems-winx86-vs2015/","items":[]},{"title":"Glog Build Problems on Windows X86 and Visual Studio 2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-23-glog-build-problems-winx86/","items":[]},{"title":"Horrible Wired Errors Come From Simple Stupid Mistake","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-16-horrible-wired-errors-come-from-simple-stupid-mistake/","items":[]},{"title":"Install Jekyll To Fix Some Local Github-pages Defects","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-11-21-install-jekyll/","items":[]},{"title":"Install Therubyracer Failure","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-03-install-therubyracer/","items":[]},{"title":"Notes On Valgrind and Others","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-05-30-notes-on-valgrind/","items":[]},{"title":"PHP Hello World","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-04-php-hello-world/","items":[]},{"title":"Programming Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-07-01-programming-resources/","items":[]},{"title":"PyInstsaller and Others","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-12-24-pyinstaller-and-others/","items":[]},{"title":"Web Development Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-06-21-web-dev-resources/","items":[]},{"title":"Working on Visual Studio","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-04-03-working-on-vs/","items":[]}]},{"title":"Reading_and_thoughts","url":"","items":[{"title":"Book Reading List","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2015-12-04-book-reading-list/","items":[]},{"title":"Funny Papers","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2015-12-04-funny-papers/","items":[]},{"title":"Reading Materials","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2016-01-18-reading-materials/","items":[]}]},{"title":"Study","url":"","items":[{"title":"Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2017-11-28-courses/","items":[]},{"title":"Essay Writting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2016-01-11-essay-writting/","items":[]},{"title":"Job Hunting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2016-06-02-job-hunting/","items":[]},{"title":"Study Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2018-04-18-resources/","items":[]}]},{"title":"Working_on_linux","url":"","items":[{"title":"Create Multiple Forks of a GitHub Repo","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-12-18-create-multi-forks/","items":[]},{"title":"Linux Git Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-08-02-linux-git/","items":[]},{"title":"Linux Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-07-24-linux-resources/","items":[]},{"title":"Linux SVN Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-08-03-linux-svn/","items":[]},{"title":"Setup vsftpd on Ubuntu 14.10","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2016-07-27-setup-vsftpd/","items":[]},{"title":"Useful Linux Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-07-25-useful-linux-commands/","items":[]},{"title":"vsftpd Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2016-07-28-vsftpd-cmd/","items":[]}]},{"title":"Working_on_mac","url":"","items":[{"title":"Mac Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_mac/2015-07-25-mac-resources/","items":[]}]},{"title":"Working_on_windows","url":"","items":[{"title":"FFmpeg Collection of Utility Methods","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2016-06-05-ffmpeg-utilities/","items":[]},{"title":"Windows Commands and Utilities","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2015-10-27-windows-cmds-utils/","items":[]},{"title":"Windows Dev Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2015-10-27-resources/","items":[]}]}]},{"title":"Drafts","url":"","items":[{"title":"2016-12-30-Setup-Opengrok","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-12-30-setup-opengrok/","items":[]},{"title":"2017-01-20-Packing-C++-Project-to-Single-Executable","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2017-01-20-packing-c++-project-to-single-executable/","items":[]},{"title":"Notes On Caffe Development","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-10-notes-on-caffe-dev/","items":[]},{"title":"Notes On Deep Learning Training","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-12-notes-on-dl-training/","items":[]},{"title":"Notes On Discrete Optimization","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-13-notes-on-discrete-optimization/","items":[]},{"title":"Notes On Gecode","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-13-notes-on-gecode/","items":[]},{"title":"Notes On Inside-Outside Net","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-28-notes-on-ion/","items":[]},{"title":"Notes On K-Means","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-06-notes-on-kmeans/","items":[]},{"title":"Notes On L-BFGS","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-07-notes-on-l-bfgs/","items":[]},{"title":"Notes On Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-04-notes-on-object-detection/","items":[]},{"title":"Notes On Perceptrons","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-10-07-notes-on-perceptrons/","items":[]},{"title":"Notes On Quantized Convolutional Neural Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-07-notes-on-quantized-cnn/","items":[]},{"title":"Notes On Stanford CS2321n","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-02-21-notes-on-cs231n/","items":[]},{"title":"Notes on Suffix Array and Manacher Algorithm","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-08-27-notes-on-suffix-array-and-manacher-algorithm/","items":[]},{"title":"Notes On Tensorflow Development","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2017-04-13-notes-on-tensorflow-dev/","items":[]},{"title":"Notes On YOLO","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-14-notes-on-yolo/","items":[]},{"title":"PASCAL VOC (20) / COCO (80) / ImageNet (200) Detection Categories","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-12-23-imagenet-det-cat/","items":[]},{"title":"Softmax Vs Logistic Vs Sigmoid","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-10-softmax-logistic-sigmoid/","items":[]},{"title":"Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognititon","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-08-31-model-ensemble-of-deteciton/","items":[]}]}]}]}]}]},{"title":"Webizen 2.0","url":"","items":[{"title":"AI Capabilities","url":"","items":[{"title":"AI Capabilities Objectives","url":"/Webizen 2.0/AI Capabilities/AI Capabilities Objectives/","items":[]},{"title":"Audio & Video Analysis","url":"/Webizen 2.0/AI Capabilities/Audio & Video Analysis/","items":[]},{"title":"Image Analysis","url":"/Webizen 2.0/AI Capabilities/Image Analysis/","items":[]},{"title":"Text Analysis","url":"/Webizen 2.0/AI Capabilities/Text Analysis/","items":[]}]},{"title":"LOD-a-lot","url":"/Webizen 2.0/AI Related Links & Notes/","items":[]},{"title":"Mobile Apps","url":"","items":[{"title":"Android","url":"/Webizen 2.0/Mobile Apps/Android/","items":[]},{"title":"General Mobile Architecture","url":"/Webizen 2.0/Mobile Apps/General Mobile Architecture/","items":[]},{"title":"iOS","url":"/Webizen 2.0/Mobile Apps/iOS/","items":[]}]},{"title":"Web Of Things (IoT)","url":"","items":[{"title":"Web Of Things (IoT)","url":"/Webizen 2.0/Web Of Things (IoT)/Web Of Things (IoT)/","items":[]}]},{"title":"Webizen 2.0","url":"/Webizen 2.0/Webizen 2.0/","items":[]},{"title":"Webizen AI OS Platform","url":"/Webizen 2.0/Webizen AI OS Platform/","items":[]},{"title":"Webizen Pro Summary","url":"/Webizen 2.0/Webizen Pro Summary/","items":[]}]},{"title":"Webizen V1 Project Documentation","url":"/","items":[]}]}],"tagsGroups":[],"latestPosts":[{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/the-human-centric-infosphere/","title":"An Overview","lastUpdatedAt":"2022-12-28T19:39:53.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/about-the-author/","title":"About The Author","lastUpdatedAt":"2022-12-28T19:39:53.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/ld-solutions-to-fakenews/","title":"Solutions to FakeNews: Linked-Data, Ontologies and Verifiable Claims","lastUpdatedAt":"2022-12-28T19:34:43.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations/","title":"Fake News: Considerations  Principles  The Institution of Socio &#8211; Economic Values","lastUpdatedAt":"2022-12-28T19:29:53.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/","title":"Handong1587","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-08-27-notes-on-suffix-array-and-manacher-algorithm/","title":"Notes on Suffix Array and Manacher Algorithm","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-10-07-notes-on-perceptrons/","title":"Notes On Perceptrons","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-04-notes-on-object-detection/","title":"Notes On Object Detection","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-10-notes-on-caffe-dev/","title":"Notes On Caffe Development","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-07-notes-on-l-bfgs/","title":"Notes On L-BFGS","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}