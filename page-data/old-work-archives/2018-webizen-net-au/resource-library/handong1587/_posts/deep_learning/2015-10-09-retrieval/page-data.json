{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-retrieval/",
    "result": {"data":{"mdx":{"id":"db25b10a-f46c-591d-9653-9ede0fed66ca","tableOfContents":{"items":[{"url":"#papers","title":"Papers"},{"url":"#hashing","title":"Hashing"},{"url":"#cross-modal-retrieval","title":"Cross Modal Retrieval","items":[{"url":"#projects","title":"Projects"}]},{"url":"#video-indexing--retrieval","title":"Video Indexing / Retrieval"},{"url":"#learning-to-rank","title":"Learning to Rank"},{"url":"#deep-metric-learning","title":"Deep Metric Learning"},{"url":"#talks--slides","title":"Talks / Slides"},{"url":"#projects-1","title":"Projects"},{"url":"#blogs","title":"Blogs"},{"url":"#tutorials","title":"Tutorials"}]},"fields":{"title":"Image Retrieval","slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-retrieval/","url":"https://devdocs.webizen.org/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-retrieval/","editUrl":"https://github.com/webizenai/devdocs/tree/main/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-retrieval.md","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022","gitCreatedAt":"2022-12-28T19:22:29.000Z","shouldShowTitle":true},"frontmatter":{"title":"Image Retrieval","description":null,"imageAlt":null,"tags":[],"date":"2015-10-09T00:00:00.000Z","dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"layout\": \"post\",\n  \"category\": \"deep_learning\",\n  \"title\": \"Image Retrieval\",\n  \"date\": \"2015-10-09T00:00:00.000Z\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"papers\"\n  }, \"Papers\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Using Very Deep Autoencoders for Content-Based Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ESANN 2011. Alex Krizhevsky, and Geoffrey E. Hinton\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.cs.toronto.edu/~hinton/absps/esann-deep-final.pdf\"\n  }, \"https://www.cs.toronto.edu/~hinton/absps/esann-deep-final.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.toronto.edu/~fritz/absps/esann-deep-final.pdf\"\n  }, \"http://www.cs.toronto.edu/~fritz/absps/esann-deep-final.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning High-level Image Representation for Image Retrieval via Multi-Task DNN using Clickthrough Data\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1312.4740\"\n  }, \"http://arxiv.org/abs/1312.4740\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://legacy.openreview.net/document/90fc8dad-ad02-4ddc-ab06-e7b55706869d#90fc8dad-ad02-4ddc-ab06-e7b55706869d\"\n  }, \"http://legacy.openreview.net/document/90fc8dad-ad02-4ddc-ab06-e7b55706869d#90fc8dad-ad02-4ddc-ab06-e7b55706869d\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Neural Codes for Image Retrieval\")), mdx(\"img\", {\n    \"src\": \"http://sites.skoltech.ru/app/data/uploads/sites/25/2014/11/example-e1404721339557.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2014\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://sites.skoltech.ru/compvision/projects/neuralcodes/\"\n  }, \"http://sites.skoltech.ru/compvision/projects/neuralcodes/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1404.1777\"\n  }, \"http://arxiv.org/abs/1404.1777\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/arbabenko/Spoc\"\n  }, \"https://github.com/arbabenko/Spoc\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Efficient On-the-fly Category Retrieval using ConvNets and GPUs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1407.4764\"\n  }, \"http://arxiv.org/abs/1407.4764\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning visual similarity for product design with convolutional neural networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SIGGRAPH 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.cornell.edu/~kb/publications/SIG15ProductNet.pdf\"\n  }, \"http://www.cs.cornell.edu/~kb/publications/SIG15ProductNet.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://dl.acm.org.sci-hub.cc/citation.cfm?doid=2809654.2766959\"\n  }, \"http://dl.acm.org.sci-hub.cc/citation.cfm?doid=2809654.2766959\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Exploiting Local Features from Deep Networks for Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR DeepVision Workshop 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1504.05133\"\n  }, \"https://arxiv.org/abs/1504.05133\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Visual Search at Pinterest\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: in Proceedings of the 21th ACM SIGKDD International Conference on Knowledge and Discovery and Data Mining, 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1505.07647\"\n  }, \"http://arxiv.org/abs/1505.07647\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://engineering.pinterest.com/blog/introducing-new-way-visually-search-pinterest\"\n  }, \"https://engineering.pinterest.com/blog/introducing-new-way-visually-search-pinterest\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Aggregating Deep Convolutional Features for Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Sum pooing\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1510.07493\"\n  }, \"http://arxiv.org/abs/1510.07493\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Particular object retrieval with integral max-pooling of CNN activations\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: use max-pooling to aggregate the deep descriptors, R-MAC (regional maximum activation of convolutions)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1511.05879\"\n  }, \"https://arxiv.org/abs/1511.05879\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Group Invariant Deep Representations for Image Instance Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1601.02093\"\n  }, \"http://arxiv.org/abs/1601.02093\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Where to Buy It: Matching Street Clothing Photos in Online Shops\")), mdx(\"img\", {\n    \"src\": \"http://www.tamaraberg.com/street2shop/header.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"hmepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.tamaraberg.com/street2shop/\"\n  }, \"http://www.tamaraberg.com/street2shop/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.tamaraberg.com/papers/street2shop.pdf\"\n  }, \"http://www.tamaraberg.com/papers/street2shop.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Kiapour_Where_to_Buy_ICCV_2015_paper.html\"\n  }, \"http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Kiapour_Where_to_Buy_ICCV_2015_paper.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Natural Language Object Retrieval\")), mdx(\"img\", {\n    \"src\": \"http://ronghanghu.com/wp-content/uploads/method-900x353.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://ronghanghu.com/text_obj_retrieval/\"\n  }, \"http://ronghanghu.com/text_obj_retrieval/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1511.04164\"\n  }, \"http://arxiv.org/abs/1511.04164\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://ronghanghu.com/slides/cvpr16_text_obj_retrieval_slides.pdf\"\n  }, \"http://ronghanghu.com/slides/cvpr16_text_obj_retrieval_slides.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ronghanghu/natural-language-object-retrieval\"\n  }, \"https://github.com/ronghanghu/natural-language-object-retrieval\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/andrewliao11/Natural-Language-Object-Retrieval-tensorflow\"\n  }, \"https://github.com/andrewliao11/Natural-Language-Object-Retrieval-tensorflow\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Image Retrieval: Learning global representations for image search\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.xrce.xerox.com/Research-Development/Computer-Vision/Learning-Visual-Representations/Deep-Image-Retrieval\"\n  }, \"http://www.xrce.xerox.com/Research-Development/Computer-Vision/Learning-Visual-Representations/Deep-Image-Retrieval\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1604.01325\"\n  }, \"https://arxiv.org/abs/1604.01325\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.slideshare.net/xavigiro/deep-image-retrieval-learning-global-representations-for-image-search\"\n  }, \"http://www.slideshare.net/xavigiro/deep-image-retrieval-learning-global-representations-for-image-search\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End-to-end Learning of Deep Visual Representations for Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IJCV 2017. Extended version of our ECCV2016 paper \\\"Deep Image Retrieval: Learning global representations for image search\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.xrce.xerox.com/Research-Development/Computer-Vision/Learning-Visual-Representations/Deep-Image-Retrieval\"\n  }, \"http://www.xrce.xerox.com/Research-Development/Computer-Vision/Learning-Visual-Representations/Deep-Image-Retrieval\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.07940\"\n  }, \"https://arxiv.org/abs/1610.07940\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bags of Local Convolutional Features for Scalable Instance Search\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICMR 2016. Best Poster Award at ICMR 2016.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://imatge-upc.github.io/retrieval-2016-icmr/\"\n  }, \"https://imatge-upc.github.io/retrieval-2016-icmr/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1604.04653\"\n  }, \"https://arxiv.org/abs/1604.04653\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/imatge-upc/retrieval-2016-icmr\"\n  }, \"https://github.com/imatge-upc/retrieval-2016-icmr\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.slideshare.net/xavigiro/convolutional-features-for-instance-search\"\n  }, \"http://www.slideshare.net/xavigiro/convolutional-features-for-instance-search\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Faster R-CNN Features for Instance Search\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: DeepVision Workshop in CVPR 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://imatge-upc.github.io/retrieval-2016-deepvision/\"\n  }, \"http://imatge-upc.github.io/retrieval-2016-deepvision/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1604.08893\"\n  }, \"http://arxiv.org/abs/1604.08893\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/imatge-upc/retrieval-2016-deepvision\"\n  }, \"https://github.com/imatge-upc/retrieval-2016-deepvision\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Where to Focus: Query Adaptive Matching for Instance Retrieval Using Convolutional Feature Maps\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: query adaptive matching (QAM), Feature Map Pooling, Overlapped Spatial Pyramid Pooling (OSPP)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1606.06811\"\n  }, \"https://arxiv.org/abs/1606.06811\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Adversarial Training For Sketch Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1607.02748\"\n  }, \"http://arxiv.org/abs/1607.02748\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Compact Binary Descriptors with Unsupervised Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016. DeepBit\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Lin_Learning_Compact_Binary_CVPR_2016_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Lin_Learning_Compact_Binary_CVPR_2016_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kevinlin311tw/cvpr16-deepbit\"\n  }, \"https://github.com/kevinlin311tw/cvpr16-deepbit\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast Training of Triplet-based Deep Binary Embedding Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1603.02844\"\n  }, \"https://arxiv.org/abs/1603.02844\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhuang_Fast_Training_of_CVPR_2016_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhuang_Fast_Training_of_CVPR_2016_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"bitbucket(official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://bitbucket.org/jingruixiaozhuang/fast-training-of-triplet-based-deep-binary-embedding-networks\"\n  }, \"https://bitbucket.org/jingruixiaozhuang/fast-training-of-triplet-based-deep-binary-embedding-networks\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Relative Distance Learning: Tell the Difference Between Similar Vehicles\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: vehicle re-identification, vehicle retrieval. coupled clusters loss\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_Deep_Relative_Distance_CVPR_2016_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_Deep_Relative_Distance_CVPR_2016_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepFashion: Powering Robust Clothes Recognition and Retrieval with Rich Annotations\")), mdx(\"img\", {\n    \"src\": \"http://personal.ie.cuhk.edu.hk/~lz013/projects/deepfashion/intro.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016. FashionNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://personal.ie.cuhk.edu.hk/~lz013/projects/DeepFashion.html\"\n  }, \"http://personal.ie.cuhk.edu.hk/~lz013/projects/DeepFashion.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_DeepFashion_Powering_Robust_CVPR_2016_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_DeepFashion_Powering_Robust_CVPR_2016_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CNN Image Retrieval Learns from BoW: Unsupervised Fine-Tuning with Hard Examples\")), mdx(\"img\", {\n    \"src\": \"http://ptak.felk.cvut.cz/personal/radenfil/siamac/siamac.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page(paper+code+data): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cmp.felk.cvut.cz/~radenfil/projects/siamac.html\"\n  }, \"http://cmp.felk.cvut.cz/~radenfil/projects/siamac.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1604.02426\"\n  }, \"https://arxiv.org/abs/1604.02426\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cmp.felk.cvut.cz/~radenfil/publications/Radenovic-ECCV16.pdf\"\n  }, \"http://cmp.felk.cvut.cz/~radenfil/publications/Radenovic-ECCV16.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code(Matlab): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://ptak.felk.cvut.cz/personal/radenfil/siamac/siaMAC_code.tar.gz\"\n  }, \"http://ptak.felk.cvut.cz/personal/radenfil/siamac/siaMAC_code.tar.gz\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PicHunt: Social Media Image Retrieval for Improved Law Enforcement\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.00905\"\n  }, \"http://arxiv.org/abs/1608.00905\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SIFT Meets CNN: A Decade Survey of Instance Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.01807\"\n  }, \"http://arxiv.org/abs/1608.01807\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Sketchy Database: Learning to Retrieve Badly Drawn Bunnies\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://sketchy.eye.gatech.edu/\"\n  }, \"http://sketchy.eye.gatech.edu/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cc.gatech.edu/~hays/tmp/sketchy-database.pdf\"\n  }, \"http://www.cc.gatech.edu/~hays/tmp/sketchy-database.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/janesjanes/sketchy\"\n  }, \"https://github.com/janesjanes/sketchy\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"What Is the Best Practice for CNNs Applied to Visual Instance Retrieval?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.01640\"\n  }, \"https://arxiv.org/abs/1611.01640\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Image Retrieval with Deep Local Features and Attention-based Keypoints\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.05478\"\n  }, \"https://arxiv.org/abs/1612.05478\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Internet-Based Image Retrieval Using End-to-End Trained Deep Distributions\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.07697\"\n  }, \"https://arxiv.org/abs/1612.07697\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Compression of Deep Neural Networks for Image Instance Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: DCC 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.04923\"\n  }, \"https://arxiv.org/abs/1701.04923\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Effective Multi-Query Expansions: Collaborative Deep Networks for Robust Landmark Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.05003\"\n  }, \"https://arxiv.org/abs/1701.05003\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Siamese Network of Deep Fisher-Vector Descriptors for Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.00338\"\n  }, \"https://arxiv.org/abs/1702.00338\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Geometric Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.06383\"\n  }, \"https://arxiv.org/abs/1702.06383\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Context Aware Query Image Representation for Particular Object Retrieval\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.arxiv.org/abs/1703.01226\"\n  }, \"https://www.arxiv.org/abs/1703.01226\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An End-to-End Approach to Natural Language Object Retrieval via Context-Aware Deep Reinforcement Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1703.07579\"\n  }, \"https://arxiv.org/abs/1703.07579\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AMC: Attention guided Multi-modal Correlation Learning for Image Search\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.00763\"\n  }, \"https://arxiv.org/abs/1704.00763\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kanchen-usc/amc_att\"\n  }, \"https://github.com/kanchen-usc/amc_att\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video2Shop: Exactly Matching Clothes in Videos to Online Shopping Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywrods: AsymNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.05287\"\n  }, \"https://arxiv.org/abs/1804.05287\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep image representations using caption generators\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICME 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1705.09142\"\n  }, \"https://arxiv.org/abs/1705.09142\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Visual Search at eBay\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: 23rd SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.03154\"\n  }, \"https://arxiv.org/abs/1706.03154\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sampling Matters in Deep Embedding Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: UT Austin & A9/Amazon\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: distance weighted sampling\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.07567\"\n  }, \"https://arxiv.org/abs/1706.07567\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"One-Shot Fine-Grained Instance Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM MM 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.00811\"\n  }, \"https://arxiv.org/abs/1707.00811\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Selective Deep Convolutional Features for Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM MM 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.00809\"\n  }, \"https://arxiv.org/abs/1707.00809\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Class-Weighted Convolutional Features for Visual Instance Search\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2017. Universitat Politecnica de Catalunya Barcelona & CSIRO\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://imatge-upc.github.io/retrieval-2017-cam/\"\n  }, \"http://imatge-upc.github.io/retrieval-2017-cam/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.02581\"\n  }, \"https://arxiv.org/abs/1707.02581\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/imatge-upc/retrieval-2017-cam\"\n  }, \"https://github.com/imatge-upc/retrieval-2017-cam\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning a Repression Network for Precise Vehicle Search\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1708.02386\"\n  }, \"https://arxiv.org/abs/1708.02386\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SUBIC: A supervised, structured binary code for image search\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017 (Spotlight). Technicolor & INRIA Rennes & Amazon\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.02932\"\n  }, \"https://arxiv.org/abs/1708.02932\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pruning Convolutional Neural Networks for Image Instance Retrieval\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1707.05455\"\n  }, \"https://arxiv.org/abs/1707.05455\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Image2song: Song Retrieval via Bridging Image Content and Lyric Words\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017. Chinese Academy of Sciences & Northwestern Polytechnical University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.05851\"\n  }, \"https://arxiv.org/abs/1708.05851\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Region-Based Image Retrieval Revisited\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM Multimedia 2017 (Oral)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1709.09106\"\n  }, \"https://arxiv.org/abs/1709.09106\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Beyond Part Models: Person Retrieval with Refined Part Pooling\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.09349\"\n  }, \"https://arxiv.org/abs/1711.09349\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Query-Adaptive R-CNN for Open-Vocabulary Object Detection and Retrieval\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.09509\"\n  }, \"https://arxiv.org/abs/1711.09509\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Saliency Weighted Convolutional Features for Instance Search\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Dublin City University & Universitat Politecnica de Catalunya\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: local convolutional features (BLCF), human visual attention models (saliency)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://imatge-upc.github.io/salbow/\"\n  }, \"https://imatge-upc.github.io/salbow/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.10795\"\n  }, \"https://arxiv.org/abs/1711.10795\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.10795\"\n  }, \"https://arxiv.org/abs/1711.10795\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepStyle: Multimodal Search Engine for Fashion and Interior Design\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1801.03002\"\n  }, \"https://arxiv.org/abs/1801.03002\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"From Selective Deep Convolutional Features to Compact Binary Representations for Image Retrieval\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1802.02899\"\n  }, \"https://arxiv.org/abs/1802.02899\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Web-Scale Responsive Visual Search at Bing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Microsoft\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1802.04914\"\n  }, \"https://arxiv.org/abs/1802.04914\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Approximate Query Matching for Image Retrieval\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.05401\"\n  }, \"https://arxiv.org/abs/1803.05401\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Captioning and Retrieval with Natural Language\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.06152\"\n  }, \"https://arxiv.org/abs/1803.06152\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Triplet-Center Loss for Multi-View 3D Object Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.06189\"\n  }, \"https://arxiv.org/abs/1803.06189\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Collaborative Multi-modal deep learning for the personalized product retrieval in Facebook Marketplace\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Facebook\\n= arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.12312\"\n  }, \"https://arxiv.org/abs/1805.12312\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepFirearm: Learning Discriminative Feature Representation for Fine-grained Firearm Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1806.02984\"\n  }, \"https://arxiv.org/abs/1806.02984\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jdhao/deep_firearm\"\n  }, \"https://github.com/jdhao/deep_firearm\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Instance Search via Instance Level Segmentation and Feature Representation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1806.03576\"\n  }, \"https://arxiv.org/abs/1806.03576\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Feature Aggregation with Heat Diffusion for Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.08587\"\n  }, \"https://arxiv.org/abs/1805.08587\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/pangsm0415/HeW\"\n  }, \"https://github.com/pangsm0415/HeW\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Single Shot Scene Text Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.09044\"\n  }, \"https://arxiv.org/abs/1808.09044\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Embeddings for Product Visual Search with Triplet Loss and Online Sampling\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Yahoo Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1810.04652\"\n  }, \"https://arxiv.org/abs/1810.04652\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attention-aware Generalized Mean Pooling for Image Retrieval\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.00202\"\n  }, \"https://arxiv.org/abs/1811.00202\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hierarchy-based Image Embeddings for Semantic Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: WACV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1809.09924\"\n  }, \"https://arxiv.org/abs/1809.09924\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/cvjena/semantic-embeddings\"\n  }, \"https://github.com/cvjena/semantic-embeddings\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mean Local Group Average Precision (mLGAP): A New Performance Metric for Hashing-based Retrieval\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.09763\"\n  }, \"https://arxiv.org/abs/1811.09763\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Instance-level Sketch-based Retrieval by Deep Triplet Classification Siamese Network\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.11375\"\n  }, \"https://arxiv.org/abs/1811.11375\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Detect-to-Retrieve: Efficient Regional Aggregation for Image Search\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Cambridge & Google AI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1812.01584\"\n  }, \"https://arxiv.org/abs/1812.01584\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning with Average Precision: Training Image Retrieval with a Listwise Loss\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NAVER LABS Europe\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1906.07589\"\n  }, \"https://arxiv.org/abs/1906.07589\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Benchmark on Tricks for Large-scale Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.11854\"\n  }, \"https://arxiv.org/abs/1907.11854\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Smooth-AP: Smoothing the Path Towards Large-Scale Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.12163\"\n  }, \"https://arxiv.org/abs/2007.12163\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Keypoint-Aligned Embeddings for Image Retrieval and Re-identification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: WACV 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2008.11368\"\n  }, \"https://arxiv.org/abs/2008.11368\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Tasks Integrated Networks: Joint Detection and Retrieval for Image Search\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2009.01438\"\n  }, \"https://arxiv.org/abs/2009.01438\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Instance-level Image Retrieval using Reranking Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Virginia & eBay Computer Vision\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.12236\"\n  }, \"https://arxiv.org/abs/2103.12236\"))), mdx(\"h1\", {\n    \"id\": \"hashing\"\n  }, \"Hashing\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Supervised Hashing for Image Retrieval via Image Representation Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2014. Sun Yat-Sen University & National University of Singapore\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: CNNH (Convolutional Neural Network Hashing)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/download/8137/8861/\"\n  }, \"www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/download/8137/8861\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://pdfs.semanticscholar.org/f633/8f23860f9c4808586bbc7e8907d33836147f.pdf\"\n  }, \"https://pdfs.semanticscholar.org/f633/8f23860f9c4808586bbc7e8907d33836147f.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Simultaneous Feature Learning and Hash Coding with Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2015. Sun Yat-Sen University & National University of Singapore\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: NINH (NIN Hashing), DNNH (Deep Neural Network Hashing)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1504.03410\"\n  }, \"https://arxiv.org/abs/1504.03410\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Lai_Simultaneous_Feature_Learning_2015_CVPR_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Lai_Simultaneous_Feature_Learning_2015_CVPR_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hashing by Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IBM T. J. Watson Research Center\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.ee.columbia.edu/~wliu/WeiLiu_DLHash.pdf\"\n  }, \"http://www.ee.columbia.edu/~wliu/WeiLiu_DLHash.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Semantic Ranking Based Hashing for Multi-Label Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2015. DSRH (Deep Semantic Ranking Hashing)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1501.06272\"\n  }, \"http://arxiv.org/abs/1501.06272\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning of Binary Hash Codes for Fast Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR Workshop 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: MNIST, CIFAR-10, Yahoo-1M. DLBHC (Deep Learning of Binary Hash Codes)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.iis.sinica.edu.tw/~kevinlin311.tw/cvprw15.pdf\"\n  }, \"http://www.iis.sinica.edu.tw/~kevinlin311.tw/cvprw15.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kevinlin311tw/caffe-cvprw15\"\n  }, \"https://github.com/kevinlin311tw/caffe-cvprw15\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Supervised Learning of Semantics-Preserving Hashing via Deep Neural Networks for Large-Scale Image Search\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SSDH\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1507.00101\"\n  }, \"http://arxiv.org/abs/1507.00101\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kevinlin311tw/Caffe-DeepBinaryCode\"\n  }, \"https://github.com/kevinlin311tw/Caffe-DeepBinaryCode\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bit-Scalable Deep Hashing with Regularized Similarity Learning for Image Retrieval and Person Re-identification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IEEE Transactions on Image Processing 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: DRSCH (Deep Regularized Similarity Comparison Hashing)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://vision.sysu.edu.cn/projects/deephashing/\"\n  }, \"http://vision.sysu.edu.cn/projects/deephashing/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1508.04535\"\n  }, \"https://arxiv.org/abs/1508.04535\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ruixuejianfei/BitScalableDeepHash\"\n  }, \"https://github.com/ruixuejianfei/BitScalableDeepHash\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Supervised Hashing for Fast Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: DSH (Deep Supervised Hashing)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_Deep_Supervised_Hashing_CVPR_2016_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_Deep_Supervised_Hashing_CVPR_2016_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.jdl.ac.cn/doc/2011/201711214443668218_deep%20supervised%20hashing%20for%20fast%20image%20retrieval_cvpr2016.pdf\"\n  }, \"http://www.jdl.ac.cn/doc/2011/201711214443668218_deep%20supervised%20hashing%20for%20fast%20image%20retrieval_cvpr2016.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lhmRyan/deep-supervised-hashing-DSH\"\n  }, \"https://github.com/lhmRyan/deep-supervised-hashing-DSH\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Hashing Network for Efficient Similarity Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12039\"\n  }, \"http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12039\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Feature Learning based Deep Supervised Hashing with Pairwise Labels\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IJCAI 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1511.03855\"\n  }, \"https://arxiv.org/abs/1511.03855\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.ijcai.org/Proceedings/16/Papers/245.pdf\"\n  }, \"https://www.ijcai.org/Proceedings/16/Papers/245.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://cs.nju.edu.cn/lwj/paper/IJCAI16_DPSH.pdf\"\n  }, \"https://cs.nju.edu.cn/lwj/paper/IJCAI16_DPSH.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cs.nju.edu.cn/lwj/code/DPSH_code.rar\"\n  }, \"http://cs.nju.edu.cn/lwj/code/DPSH_code.rar\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Cross-Modal Hashing\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1602.02255\"\n  }, \"https://arxiv.org/abs/1602.02255\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cycle-Consistent Deep Generative Hashing for Cross-Modal Retrieval\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1804.11013\"\n  }, \"https://arxiv.org/abs/1804.11013\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SSDH: Semi-supervised Deep Hashing for Large Scale Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1607.08477\"\n  }, \"http://arxiv.org/abs/1607.08477\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Semantic-Preserving and Ranking-Based Hashing for Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Microsoft\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.microsoft.com/en-us/research/wp-content/uploads/2016/08/Deep-Semantic-Preserving-and-Ranking-Based-Hashing-for-Image-Retrieval.pdf\"\n  }, \"http://www.microsoft.com/en-us/research/wp-content/uploads/2016/08/Deep-Semantic-Preserving-and-Ranking-Based-Hashing-for-Image-Retrieval.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Hashing: A Joint Approach for Image Signature Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.03658\"\n  }, \"http://arxiv.org/abs/1608.03658\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Transitive Hashing Network for Heterogeneous Multimedia Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: state of the art on NUS-WIDE, ImageNet-YahooQA\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.04307\"\n  }, \"http://arxiv.org/abs/1608.04307\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Residual Hashing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.05400\"\n  }, \"https://arxiv.org/abs/1612.05400\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Region Hashing for Efficient Large-scale Instance Search from Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Columbia University & University of Electronic Science and Technology of China\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.07901\"\n  }, \"https://arxiv.org/abs/1701.07901\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"HashNet: Deep Learning to Hash by Continuation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017. Tsinghua University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.00758\"\n  }, \"https://arxiv.org/abs/1702.00758\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/thuml/HashNet\"\n  }, \"https://github.com/thuml/HashNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unsupervised Triplet Hashing for Fast Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.arxiv.org/abs/1702.08798\"\n  }, \"https://www.arxiv.org/abs/1702.08798\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Sketch Hashing: Fast Free-hand Sketch-Based Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017 spotlight paper\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.05605\"\n  }, \"https://arxiv.org/abs/1703.05605\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Robust Hash Codes for Multiple Instance Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.05724\"\n  }, \"https://arxiv.org/abs/1703.05724\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Simultaneous Feature Aggregating and Hashing for Large-scale Image Search\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.00860\"\n  }, \"https://arxiv.org/abs/1704.00860\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning to Hash\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://cs.nju.edu.cn/lwj/L2H.html\"\n  }, \"https://cs.nju.edu.cn/lwj/L2H.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hashing as Tie-Aware Learning to Rank\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1705.08562\"\n  }, \"https://arxiv.org/abs/1705.08562\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Hashing Network for Unsupervised Domain Adaptation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.07522\"\n  }, \"https://arxiv.org/abs/1706.07522\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(MatConvNet): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hemanthdv/da-hash\"\n  }, \"https://github.com/hemanthdv/da-hash\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Binary Reconstruction for Cross-modal Hashing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM Multimedia 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.05127\"\n  }, \"https://arxiv.org/abs/1708.05127\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Revisit on Deep Hashings for Large-scale Content Based Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Zhejiang University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arixv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.06016\"\n  }, \"https://arxiv.org/abs/1711.06016\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Devil is in the Middle: Exploiting Mid-level Representations for Cross-Domain Instance Matching\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: finegrained sketch-based image retrieval (FG-SBIR) and Person Re-identification (person ReID)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.08106\"\n  }, \"https://arxiv.org/abs/1711.08106\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ForestHash: Semantic Hashing With Shallow Random Forests and Tiny Convolutional Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.08364\"\n  }, \"https://arxiv.org/abs/1711.08364\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Supervised Hashing with End-to-End Binary Deep Neural Network\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.08901\"\n  }, \"https://arxiv.org/abs/1711.08901\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Transfer Adversarial Hashing for Hamming Space Retrieval\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.04616\"\n  }, \"https://arxiv.org/abs/1712.04616\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dual Asymmetric Deep Hashing Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1801.08360\"\n  }, \"https://arxiv.org/abs/1801.08360\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attribute-Guided Network for Cross-Modal Zero-Shot Hashing\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1802.01943\"\n  }, \"https://arxiv.org/abs/1802.01943\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Reinforcement Learning for Image Hashing\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1802.02904\"\n  }, \"https://arxiv.org/abs/1802.02904\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hashing with Mutual Information\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.00974\"\n  }, \"https://arxiv.org/abs/1803.00974\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Zero-Shot Sketch-Image Hashing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018 spotlight\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.02284\"\n  }, \"https://arxiv.org/abs/1803.02284\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Instance Similarity Deep Hashing for Multi-Label Image Retrieval\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.02987\"\n  }, \"https://arxiv.org/abs/1803.02987\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Class-Wise Hashing: Semantics-Preserving Hashing via Class-wise Loss\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: City University of Hong Kong\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.04137\"\n  }, \"https://arxiv.org/abs/1803.04137\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unsupervised Semantic Deep Hashing\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.06911\"\n  }, \"https://arxiv.org/abs/1803.06911\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SketchMate: Deep Hashing for Million-Scale Human Sketch Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.01401\"\n  }, \"https://arxiv.org/abs/1804.01401\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improving Deep Binary Embedding Networks by Order-aware Reweighting of Triplets\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Sun Yat-sen University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.06061\"\n  }, \"https://arxiv.org/abs/1804.06061\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Semantic Hashing with Generative Adversarial Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SIGIR 2017 Oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.08275\"\n  }, \"https://arxiv.org/abs/1804.08275\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Ordinal Hashing with Spatial Attention\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.02459\"\n  }, \"https://arxiv.org/abs/1805.02459\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Efficient end-to-end learning for quantizable representations\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICML 2018. Seoul National University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.05809\"\n  }, \"https://arxiv.org/abs/1805.05809\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/maestrojeong/Deep-Hash-Table-ICML18\"\n  }, \"https://github.com/maestrojeong/Deep-Hash-Table-ICML18\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unsupervised Deep Image Hashing through Tag Embeddings\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1806.05804\"\n  }, \"https://arxiv.org/abs/1806.05804\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Adversarial Learning for Fine-grained Image Search\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1807.02247\"\n  }, \"https://arxiv.org/abs/1807.02247\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Error Correction Maximization for Deep Image Hashing\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1808.01942\"\n  }, \"https://arxiv.org/abs/1808.01942\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Priority Hashing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM MM 2018 Poster\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1809.01238\"\n  }, \"https://arxiv.org/abs/1809.01238\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Neurons Merging Layer: Towards Progressive Redundancy Reduction for Deep Supervised Hashing\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1809.02302\"\n  }, \"https://arxiv.org/abs/1809.02302\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep LDA Hashing\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1810.03402\"\n  }, \"https://arxiv.org/abs/1810.03402\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Triplet Quantization\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM Multimedia 2018 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1902.00153\"\n  }, \"https://arxiv.org/abs/1902.00153\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SADIH: Semantic-Aware DIscrete Hashing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.01739\"\n  }, \"https://arxiv.org/abs/1904.01739\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Feature Pyramid Hashing\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1904.02325\"\n  }, \"https://arxiv.org/abs/1904.02325\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Global Hashing System for Fast Image Search\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1904.08685\"\n  }, \"https://arxiv.org/abs/1904.08685\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Self-Distilled Hashing for Deep Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Seoul National University & NAVER/LINE Vision\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2112.08816\"\n  }, \"https://arxiv.org/abs/2112.08816\"))), mdx(\"h1\", {\n    \"id\": \"cross-modal-retrieval\"\n  }, \"Cross Modal Retrieval\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cross-domain Image Retrieval with a Dual Attribute-aware Ranking Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: DARN, cross-entropy loss, triplet loss\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1505.07922\"\n  }, \"http://arxiv.org/abs/1505.07922\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning for Content-Based, Cross-Modal Retrieval of Videos and Music\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.06761\"\n  }, \"https://arxiv.org/abs/1704.06761\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"supplementary: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://youtu.be/ZyINqDMo3Fg\"\n  }, \"https://youtu.be/ZyINqDMo3Fg\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Binaries: Encoding Semantic-Rich Cues for Efficient Textual-Visual Cross Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.02531\"\n  }, \"https://arxiv.org/abs/1708.02531\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MHTN: Modal-adversarial Hybrid Transfer Network for Cross-modal Retrieval\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1708.04308\"\n  }, \"https://arxiv.org/abs/1708.04308\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cross-Domain Image Retrieval with Attention Modeling\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.01784\"\n  }, \"https://arxiv.org/abs/1709.01784\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Look, Imagine and Match: Improving Textual-Visual Cross-Modal Retrieval with Generative Models\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.06420\"\n  }, \"https://arxiv.org/abs/1711.06420\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"HashGAN:Attention-aware Deep Adversarial Hashing for Cross Modal Retrieval\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.09347\"\n  }, \"https://arxiv.org/abs/1711.09347\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Objects that Sound\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: DeepMind, VGG\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.06651\"\n  }, \"https://arxiv.org/abs/1712.06651\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cross-modal Embeddings for Video and Audio Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.02200\"\n  }, \"https://arxiv.org/abs/1801.02200\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/surisdi/youtube-8m\"\n  }, \"https://github.com/surisdi/youtube-8m\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learnable PINs: Cross-Modal Embeddings for Person Identity\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: VGG\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.00833\"\n  }, \"https://arxiv.org/abs/1805.00833\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Revisiting Cross Modal Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCVW (MULA 2018)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.07364\"\n  }, \"https://arxiv.org/abs/1807.07364\"))), mdx(\"h2\", {\n    \"id\": \"projects\"\n  }, \"Projects\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"HABIR\\u54C8\\u5E0C\\u56FE\\u50CF\\u68C0\\u7D22\\u5DE5\\u5177\\u7BB1\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Various hashing methods for image retrieval and serves as the baselines\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://yongyuan.name/habir/\"\n  }, \"http://yongyuan.name/habir/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/willard-yuan/hashing-baseline-for-image-retrieval\"\n  }, \"https://github.com/willard-yuan/hashing-baseline-for-image-retrieval\"))), mdx(\"h1\", {\n    \"id\": \"video-indexing--retrieval\"\n  }, \"Video Indexing / Retrieval\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Face Video Retrieval via Deep Learning of Binary Hash Representations\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11893/12117\"\n  }, \"https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11893/12117\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning Based Semantic Video Indexing and Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1601.07754\"\n  }, \"https://arxiv.org/abs/1601.07754\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Joint Representations of Videos and Sentences with Web Image Search\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: 4th Workshop on Web-scale Vision and Social Media (VSM), ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.02367\"\n  }, \"http://arxiv.org/abs/1608.02367\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-View Product Image Search Using ConvNets Features\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.03462\"\n  }, \"http://arxiv.org/abs/1608.03462\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generalisation and Sharing in Triplet Convnets for Sketch based Visual Search\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.05301\"\n  }, \"https://arxiv.org/abs/1611.05301\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Binary Subspace Coding for Query-by-Image Video Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.01657\"\n  }, \"https://arxiv.org/abs/1612.01657\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Action Search: Learning to Search for Human Activities in Untrimmed Videos\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1706.04269\"\n  }, \"https://arxiv.org/abs/1706.04269\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Supervised Hashing with Triplet Labels\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.03900\"\n  }, \"https://arxiv.org/abs/1612.03900\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Supervised Deep Hashing for Hierarchical Labeled Data\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.02088\"\n  }, \"https://arxiv.org/abs/1704.02088\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Localizing Moments in Video with Natural Language\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.01641\"\n  }, \"https://arxiv.org/abs/1708.01641\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dress like a Star: Retrieving Fashion Products from Videos\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Aston University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1710.07198\"\n  }, \"https://arxiv.org/abs/1710.07198\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Hashing with Category Mask for Fast Video Retrieval\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.08315\"\n  }, \"https://arxiv.org/abs/1712.08315\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Focus: Querying Large Video Datasets with Low Latency and Low Cost\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1801.03493\"\n  }, \"https://arxiv.org/abs/1801.03493\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Text-to-Clip Video Retrieval with Early Fusion and Re-Captioning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Boston University, University of British Columbia\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.05113\"\n  }, \"https://arxiv.org/abs/1804.05113\"))), mdx(\"h1\", {\n    \"id\": \"learning-to-rank\"\n  }, \"Learning to Rank\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Simple to Complex Cross-modal Learning to Rank\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Xi\\u2019an Jiaotong University & University of Technology Sydney & National University of Singapore & CMU\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.01229\"\n  }, \"https://arxiv.org/abs/1702.01229\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SoDeep: a Sorting Deep net to learn ranking loss surrogates\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.04272\"\n  }, \"https://arxiv.org/abs/1904.04272\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/technicolor-research/sodeep\"\n  }, \"https://github.com/technicolor-research/sodeep\"))), mdx(\"h1\", {\n    \"id\": \"deep-metric-learning\"\n  }, \"Deep Metric Learning\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep metric learning using Triplet network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1412.6622\"\n  }, \"https://arxiv.org/abs/1412.6622\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://tce.technion.ac.il/wp-content/uploads/sites/8/2016/01/Elad-Hofer.pdf\"\n  }, \"http://tce.technion.ac.il/wp-content/uploads/sites/8/2016/01/Elad-Hofer.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/eladhoffer/TripletNet\"\n  }, \"https://github.com/eladhoffer/TripletNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improved Deep Metric Learning with Multi-class N-pair Loss Objective\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.nec-labs.com/uploads/images/Department-Images/MediaAnalytics/papers/nips16_npairmetriclearning.pdf\"\n  }, \"http://www.nec-labs.com/uploads/images/Department-Images/MediaAnalytics/papers/nips16_npairmetriclearning.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Metric Learning with Adaptive Density Discrimination\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR 2016. Facebook AI Research & UC Berkeley\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1511.05939\"\n  }, \"https://arxiv.org/abs/1511.05939\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/pumpikano/tf-magnet-loss\"\n  }, \"https://github.com/pumpikano/tf-magnet-loss\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/vithursant/MagnetLoss-PyTorch/\"\n  }, \"https://github.com/vithursant/MagnetLoss-PyTorch/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hard-Aware Deeply Cascaded Embedding\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.05720\"\n  }, \"https://arxiv.org/abs/1611.05720\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_ICCV_2017/papers/Yuan_Hard-Aware_Deeply_Cascaded_ICCV_2017_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_ICCV_2017/papers/Yuan_Hard-Aware_Deeply_Cascaded_ICCV_2017_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/PkuRainBow/Hard-Aware-Deeply-Cascaded-Embedding_release\"\n  }, \"https://github.com/PkuRainBow/Hard-Aware-Deeply-Cascaded-Embedding_release\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/PkuRainBow/Hard-Aware-Deeply-Cascaed-Embedding\"\n  }, \"https://github.com/PkuRainBow/Hard-Aware-Deeply-Cascaed-Embedding\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learnable Structured Clustering Framework for Deep Metric Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.01213\"\n  }, \"https://arxiv.org/abs/1612.01213\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Metric Learning via Lifted Structured Feature Embedding\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page(code+data): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cvgl.stanford.edu/projects/lifted_struct/\"\n  }, \"http://cvgl.stanford.edu/projects/lifted_struct/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Song_Deep_Metric_Learning_CVPR_2016_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Song_Deep_Metric_Learning_CVPR_2016_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cvgl.stanford.edu/papers/song_cvpr16.pdf\"\n  }, \"http://cvgl.stanford.edu/papers/song_cvpr16.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/rksltnl/Deep-Metric-Learning-CVPR16\"\n  }, \"https://github.com/rksltnl/Deep-Metric-Learning-CVPR16\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/rksltnl/Caffe-Deep-Metric-Learning-CVPR16\"\n  }, \"https://github.com/rksltnl/Caffe-Deep-Metric-Learning-CVPR16\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"dataset: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"ftp://cs.stanford.edu/cs/cvgl/Stanford_Online_Products.zip\"\n  }, \"ftp://cs.stanford.edu/cs/cvgl/Stanford_Online_Products.zip\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cross-modal Deep Metric Learning with Multi-task Regularization\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICME 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.07026\"\n  }, \"https://arxiv.org/abs/1703.07026\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Smart Mining for Deep Metric Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1704.01285\"\n  }, \"https://arxiv.org/abs/1704.01285\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DarkRank: Accelerating Deep Metric Learning via Cross Sample Similarities Transfer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: TuSimple\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: pedestrian re-identification\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.01220\"\n  }, \"https://arxiv.org/abs/1707.01220\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Metric Learning with Angular Loss\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.01682\"\n  }, \"https://arxiv.org/abs/1708.01682\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Metric Learning with BIER: Boosting Independent Embeddings Robustly\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1801.04815\"\n  }, \"https://arxiv.org/abs/1801.04815\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Directional Statistics-based Deep Metric Learning for Image Classification and Retrieval\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1802.09662\"\n  }, \"https://arxiv.org/abs/1802.09662\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generalization in Metric Learning: Should the Embedding Layer be the Embedding Layer?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Georgia Tech\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Cars-196, CUB-200-2011 and Stanford Online Product\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.03310\"\n  }, \"https://arxiv.org/abs/1803.03310\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Metric Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(PyTorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bnulihaixia/Deep_metric\"\n  }, \"https://github.com/bnulihaixia/Deep_metric\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attention-based Ensemble for Deep Metric Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1804.00382\"\n  }, \"https://arxiv.org/abs/1804.00382\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Online Deep Metric Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.05510\"\n  }, \"https://arxiv.org/abs/1805.05510\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Randomized Ensembles for Metric Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.04469\"\n  }, \"https://arxiv.org/abs/1808.04469\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/littleredxh/DREML\"\n  }, \"https://github.com/littleredxh/DREML\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Metric Learning with Hierarchical Triplet Loss\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1810.06951\"\n  }, \"https://arxiv.org/abs/1810.06951\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Ranked List Loss for Deep Metric Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.03238\"\n  }, \"https://arxiv.org/abs/1903.03238\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hardness-Aware Deep Metric Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019 Oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.05503\"\n  }, \"https://arxiv.org/abs/1903.05503\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, Tensorflow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/wzzheng/HDML\"\n  }, \"https://github.com/wzzheng/HDML\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Signal-to-Noise Ratio: A Robust Distance Metric for Deep Metric Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.02616\"\n  }, \"https://arxiv.org/abs/1904.02616\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Similarity Loss with General Pair Weighting for Deep Metric Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.06627\"\n  }, \"https://arxiv.org/abs/1904.06627\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MalongTech/research-ms-loss\"\n  }, \"https://github.com/MalongTech/research-ms-loss\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Metric Learning Beyond Binary Supervision\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.09626\"\n  }, \"https://arxiv.org/abs/1904.09626\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SoftTriple Loss: Deep Metric Learning Without Triplet Sampling\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.05235\"\n  }, \"https://arxiv.org/abs/1909.05235\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Group Loss for Deep Metric Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1912.00385\"\n  }, \"https://arxiv.org/abs/1912.00385\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Embedding Expansion: Augmentation in Embedding Space for Deep Metric Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NAVER Corp.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.02546\"\n  }, \"https://arxiv.org/abs/2003.02546\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Proxy Anchor Loss for Deep Metric Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.13911\"\n  }, \"https://arxiv.org/abs/2003.13911\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, Pytorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tjddus9597/Proxy-Anchor-CVPR2020\"\n  }, \"https://github.com/tjddus9597/Proxy-Anchor-CVPR2020\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spherical Feature Transform for Deep Metric Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2008.01469\"\n  }, \"https://arxiv.org/abs/2008.01469\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Diversified Mutual Learning for Deep Metric Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV Workshop 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2009.04170\"\n  }, \"https://arxiv.org/abs/2009.04170\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Metric Learning with Spherical Embedding\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.02785\"\n  }, \"https://arxiv.org/abs/2011.02785\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Pytorch):\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Dyfine/SphericalEmbedding\"\n  }, \"https://github.com/Dyfine/SphericalEmbedding\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Intra-Batch Connections for Deep Metric Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2102.07753\"\n  }, \"https://arxiv.org/abs/2102.07753\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"LoOp: Looking for Optimal Hard Negative Embeddings for Deep Metric Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2108.09335\"\n  }, \"https://arxiv.org/abs/2108.09335\"))), mdx(\"h1\", {\n    \"id\": \"talks--slides\"\n  }, \"Talks / Slides\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TiefVision: end-to-end image similarity search engine\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: It covers image classification, image location ( OverFeat ) and image similarity ( Deep Ranking).\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://docs.google.com/presentation/d/16hrXJhOzkbmla9AL7JCreCuBsa5L80gm71Pfrjo7F9Y/edit#slide=id.p\"\n  }, \"https://docs.google.com/presentation/d/16hrXJhOzkbmla9AL7JCreCuBsa5L80gm71Pfrjo7F9Y/edit#slide=id.p\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/paucarre/tiefvision\"\n  }, \"https://github.com/paucarre/tiefvision\"))), mdx(\"h1\", {\n    \"id\": \"projects-1\"\n  }, \"Projects\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PyRetri: A PyTorch-based Library for Unsupervised Image Retrieval by Deep Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Open source deep learning based image retrieval toolbox based on PyTorch\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2005.02154\"\n  }, \"https://arxiv.org/abs/2005.02154\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/PyRetri/PyRetri\"\n  }, \"https://github.com/PyRetri/PyRetri\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"\\u56FE\\u50CF\\u68C0\\u7D22\\uFF1ACNN\\u5377\\u79EF\\u795E\\u7ECF\\u7F51\\u7EDC\\u4E0E\\u5B9E\\u6218\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CNN for Image Retrieval\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://yongyuan.name/blog/CBIR-CNN-and-practice.html\"\n  }, \"http://yongyuan.name/blog/CBIR-CNN-and-practice.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/willard-yuan/CNN-for-Image-Retrieval\"\n  }, \"https://github.com/willard-yuan/CNN-for-Image-Retrieval\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://yongyuan.name/pic/\"\n  }, \"http://yongyuan.name/pic/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Visual Search Server\")), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/AKSHAYUBHAT/VisualSearchServer/master/appcode/static/alpha3.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: A simple implementation of Visual Search using features extracted from Tensorflow inception model and Approximate Nearest Neighbors \"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/AKSHAYUBHAT/VisualSearchServer\"\n  }, \"https://github.com/AKSHAYUBHAT/VisualSearchServer\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Vehicle Retrieval: vehicle image retrieval using k CNNs ensemble method\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ranked 1st and won the special prize in the final of\\nthe 3rd National Gradute Contest on Smart-CIty Technology and Creative Design, China\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.pkuml.org/resources/pku-vehicleid.html\"\n  }, \"https://www.pkuml.org/resources/pku-vehicleid.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/iamhankai/vehicle-retrieval-kCNNs\"\n  }, \"https://github.com/iamhankai/vehicle-retrieval-kCNNs\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A visual search engine based on Elasticsearch and Tensorflow\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: faster r-cnn\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tuan3w/visual_search\"\n  }, \"https://github.com/tuan3w/visual_search\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Siamese and triplet networks with online pair/triplet mining in PyTorch\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/adambielski/siamese-triplet\"\n  }, \"https://github.com/adambielski/siamese-triplet\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Triplet Loss and Online Triplet Mining in TensorFlow\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://omoindrot.github.io/triplet-loss\"\n  }, \"https://omoindrot.github.io/triplet-loss\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gtihub: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/omoindrot/tensorflow-triplet-loss\"\n  }, \"https://github.com/omoindrot/tensorflow-triplet-loss\"))), mdx(\"h1\", {\n    \"id\": \"blogs\"\n  }, \"Blogs\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Where can I buy a chair like that? \\u2013 This app will tell you\")), mdx(\"img\", {\n    \"src\": \"http://www.news.cornell.edu/sites/chronicle.cornell/files/GrokStyleApp.png?itok=3jd_S2R7\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.news.cornell.edu/stories/2016/08/where-can-i-buy-chair-app-will-tell-you\"\n  }, \"http://www.news.cornell.edu/stories/2016/08/where-can-i-buy-chair-app-will-tell-you\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Using Sketches to Search for Products Online\")), mdx(\"img\", {\n    \"src\": \"http://sketchx.eecs.qmul.ac.uk/wp-content/uploads/sites/27/2016/04/slider_template_cvpr4-1.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://sketchx.eecs.qmul.ac.uk/\"\n  }, \"http://sketchx.eecs.qmul.ac.uk/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://news.developer.nvidia.com/using-sketches-to-search-for-products-online/\"\n  }, \"https://news.developer.nvidia.com/using-sketches-to-search-for-products-online/\"))), mdx(\"h1\", {\n    \"id\": \"tutorials\"\n  }, \"Tutorials\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Image Retrieval: Learning global representations for image search\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"youtube: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=yT52xDML6ys\"\n  }, \"https://www.youtube.com/watch?v=yT52xDML6ys\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Image Instance Retrieval: Overview of state-of-the-art\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"youtube: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=EYq-rpaZn1o\"\n  }, \"https://www.youtube.com/watch?v=EYq-rpaZn1o\"))));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"---\nlayout: post\ncategory: deep_learning\ntitle: Image Retrieval\ndate: 2015-10-09\n---\n\n# Papers\n\n**Using Very Deep Autoencoders for Content-Based Image Retrieval**\n\n- intro: ESANN 2011. Alex Krizhevsky, and Geoffrey E. Hinton\n- paper: [https://www.cs.toronto.edu/~hinton/absps/esann-deep-final.pdf](https://www.cs.toronto.edu/~hinton/absps/esann-deep-final.pdf)\n- paper: [http://www.cs.toronto.edu/~fritz/absps/esann-deep-final.pdf](http://www.cs.toronto.edu/~fritz/absps/esann-deep-final.pdf)\n\n**Learning High-level Image Representation for Image Retrieval via Multi-Task DNN using Clickthrough Data**\n\n- arxiv: [http://arxiv.org/abs/1312.4740](http://arxiv.org/abs/1312.4740)\n- paper: [http://legacy.openreview.net/document/90fc8dad-ad02-4ddc-ab06-e7b55706869d#90fc8dad-ad02-4ddc-ab06-e7b55706869d](http://legacy.openreview.net/document/90fc8dad-ad02-4ddc-ab06-e7b55706869d#90fc8dad-ad02-4ddc-ab06-e7b55706869d)\n\n**Neural Codes for Image Retrieval**\n\n![](http://sites.skoltech.ru/app/data/uploads/sites/25/2014/11/example-e1404721339557.png)\n\n- intro: ECCV 2014\n- project page: [http://sites.skoltech.ru/compvision/projects/neuralcodes/](http://sites.skoltech.ru/compvision/projects/neuralcodes/)\n- arxiv: [http://arxiv.org/abs/1404.1777](http://arxiv.org/abs/1404.1777)\n- github: [https://github.com/arbabenko/Spoc](https://github.com/arbabenko/Spoc)\n\n**Efficient On-the-fly Category Retrieval using ConvNets and GPUs**\n\n- arxiv: [http://arxiv.org/abs/1407.4764](http://arxiv.org/abs/1407.4764)\n\n**Learning visual similarity for product design with convolutional neural networks**\n\n- intro: SIGGRAPH 2015\n- paper: [http://www.cs.cornell.edu/~kb/publications/SIG15ProductNet.pdf](http://www.cs.cornell.edu/~kb/publications/SIG15ProductNet.pdf)\n- paper: [http://dl.acm.org.sci-hub.cc/citation.cfm?doid=2809654.2766959](http://dl.acm.org.sci-hub.cc/citation.cfm?doid=2809654.2766959)\n\n**Exploiting Local Features from Deep Networks for Image Retrieval**\n\n- intro: CVPR DeepVision Workshop 2015\n- arxiv: [https://arxiv.org/abs/1504.05133](https://arxiv.org/abs/1504.05133)\n\n**Visual Search at Pinterest**\n\n- intro: in Proceedings of the 21th ACM SIGKDD International Conference on Knowledge and Discovery and Data Mining, 2015\n- arxiv: [http://arxiv.org/abs/1505.07647](http://arxiv.org/abs/1505.07647)\n- blog: [https://engineering.pinterest.com/blog/introducing-new-way-visually-search-pinterest](https://engineering.pinterest.com/blog/introducing-new-way-visually-search-pinterest)\n\n**Aggregating Deep Convolutional Features for Image Retrieval**\n\n- intro: ICCV 2015\n- intro: Sum pooing\n- arxiv: [http://arxiv.org/abs/1510.07493](http://arxiv.org/abs/1510.07493)\n\n**Particular object retrieval with integral max-pooling of CNN activations**\n\n- intro: use max-pooling to aggregate the deep descriptors, R-MAC (regional maximum activation of convolutions)\n- arxiv: [https://arxiv.org/abs/1511.05879](https://arxiv.org/abs/1511.05879)\n\n**Group Invariant Deep Representations for Image Instance Retrieval**\n\n- arxiv: [http://arxiv.org/abs/1601.02093](http://arxiv.org/abs/1601.02093)\n\n**Where to Buy It: Matching Street Clothing Photos in Online Shops**\n\n![](http://www.tamaraberg.com/street2shop/header.jpg)\n\n- intro: ICCV 2015\n- hmepage: [http://www.tamaraberg.com/street2shop/](http://www.tamaraberg.com/street2shop/)\n- paper: [http://www.tamaraberg.com/papers/street2shop.pdf](http://www.tamaraberg.com/papers/street2shop.pdf)\n- paper: [http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Kiapour_Where_to_Buy_ICCV_2015_paper.html](http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Kiapour_Where_to_Buy_ICCV_2015_paper.html)\n\n**Natural Language Object Retrieval**\n\n![](http://ronghanghu.com/wp-content/uploads/method-900x353.png)\n\n- intro: CVPR 2015\n- homepage: [http://ronghanghu.com/text_obj_retrieval/](http://ronghanghu.com/text_obj_retrieval/)\n- arxiv: [http://arxiv.org/abs/1511.04164](http://arxiv.org/abs/1511.04164)\n- slides: [http://ronghanghu.com/slides/cvpr16_text_obj_retrieval_slides.pdf](http://ronghanghu.com/slides/cvpr16_text_obj_retrieval_slides.pdf)\n- github: [https://github.com/ronghanghu/natural-language-object-retrieval](https://github.com/ronghanghu/natural-language-object-retrieval)\n- github: [https://github.com/andrewliao11/Natural-Language-Object-Retrieval-tensorflow](https://github.com/andrewliao11/Natural-Language-Object-Retrieval-tensorflow)\n\n**Deep Image Retrieval: Learning global representations for image search**\n\n- intro: ECCV 2016\n- project page: [http://www.xrce.xerox.com/Research-Development/Computer-Vision/Learning-Visual-Representations/Deep-Image-Retrieval](http://www.xrce.xerox.com/Research-Development/Computer-Vision/Learning-Visual-Representations/Deep-Image-Retrieval)\n- arxiv: [https://arxiv.org/abs/1604.01325](https://arxiv.org/abs/1604.01325)\n- slides: [http://www.slideshare.net/xavigiro/deep-image-retrieval-learning-global-representations-for-image-search](http://www.slideshare.net/xavigiro/deep-image-retrieval-learning-global-representations-for-image-search)\n\n**End-to-end Learning of Deep Visual Representations for Image Retrieval**\n\n- intro: IJCV 2017. Extended version of our ECCV2016 paper \"Deep Image Retrieval: Learning global representations for image search\"\n- project page: [http://www.xrce.xerox.com/Research-Development/Computer-Vision/Learning-Visual-Representations/Deep-Image-Retrieval](http://www.xrce.xerox.com/Research-Development/Computer-Vision/Learning-Visual-Representations/Deep-Image-Retrieval)\n- arxiv: [https://arxiv.org/abs/1610.07940](https://arxiv.org/abs/1610.07940)\n\n**Bags of Local Convolutional Features for Scalable Instance Search**\n\n- intro: ICMR 2016. Best Poster Award at ICMR 2016.\n- project page: [https://imatge-upc.github.io/retrieval-2016-icmr/](https://imatge-upc.github.io/retrieval-2016-icmr/)\n- arxiv: [https://arxiv.org/abs/1604.04653](https://arxiv.org/abs/1604.04653)\n- github: [https://github.com/imatge-upc/retrieval-2016-icmr](https://github.com/imatge-upc/retrieval-2016-icmr)\n- slides: [http://www.slideshare.net/xavigiro/convolutional-features-for-instance-search](http://www.slideshare.net/xavigiro/convolutional-features-for-instance-search)\n\n**Faster R-CNN Features for Instance Search**\n\n- intro: DeepVision Workshop in CVPR 2016\n- homepage: [http://imatge-upc.github.io/retrieval-2016-deepvision/](http://imatge-upc.github.io/retrieval-2016-deepvision/)\n- arxiv: [http://arxiv.org/abs/1604.08893](http://arxiv.org/abs/1604.08893)\n- github: [https://github.com/imatge-upc/retrieval-2016-deepvision](https://github.com/imatge-upc/retrieval-2016-deepvision)\n\n**Where to Focus: Query Adaptive Matching for Instance Retrieval Using Convolutional Feature Maps**\n\n- intro: query adaptive matching (QAM), Feature Map Pooling, Overlapped Spatial Pyramid Pooling (OSPP)\n- arxiv: [https://arxiv.org/abs/1606.06811](https://arxiv.org/abs/1606.06811)\n\n**Adversarial Training For Sketch Retrieval**\n\n- arxiv: [http://arxiv.org/abs/1607.02748](http://arxiv.org/abs/1607.02748)\n\n**Learning Compact Binary Descriptors with Unsupervised Deep Neural Networks**\n\n- intro: CVPR 2016. DeepBit\n- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Lin_Learning_Compact_Binary_CVPR_2016_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Lin_Learning_Compact_Binary_CVPR_2016_paper.pdf)\n- github: [https://github.com/kevinlin311tw/cvpr16-deepbit](https://github.com/kevinlin311tw/cvpr16-deepbit)\n\n**Fast Training of Triplet-based Deep Binary Embedding Networks**\n\n- intro: CVPR 2016\n- arxiv: [https://arxiv.org/abs/1603.02844](https://arxiv.org/abs/1603.02844)\n- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhuang_Fast_Training_of_CVPR_2016_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhuang_Fast_Training_of_CVPR_2016_paper.pdf)\n- bitbucket(official): [https://bitbucket.org/jingruixiaozhuang/fast-training-of-triplet-based-deep-binary-embedding-networks](https://bitbucket.org/jingruixiaozhuang/fast-training-of-triplet-based-deep-binary-embedding-networks)\n\n**Deep Relative Distance Learning: Tell the Difference Between Similar Vehicles**\n\n- intro: CVPR 2016\n- intro: vehicle re-identification, vehicle retrieval. coupled clusters loss\n- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_Deep_Relative_Distance_CVPR_2016_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_Deep_Relative_Distance_CVPR_2016_paper.pdf)\n\n**DeepFashion: Powering Robust Clothes Recognition and Retrieval with Rich Annotations**\n\n![](http://personal.ie.cuhk.edu.hk/~lz013/projects/deepfashion/intro.png)\n\n- intro: CVPR 2016. FashionNet\n- project page: [http://personal.ie.cuhk.edu.hk/~lz013/projects/DeepFashion.html](http://personal.ie.cuhk.edu.hk/~lz013/projects/DeepFashion.html)\n- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_DeepFashion_Powering_Robust_CVPR_2016_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_DeepFashion_Powering_Robust_CVPR_2016_paper.pdf)\n\n**CNN Image Retrieval Learns from BoW: Unsupervised Fine-Tuning with Hard Examples**\n\n![](http://ptak.felk.cvut.cz/personal/radenfil/siamac/siamac.png)\n\n- intro: ECCV 2016\n- project page(paper+code+data): [http://cmp.felk.cvut.cz/~radenfil/projects/siamac.html](http://cmp.felk.cvut.cz/~radenfil/projects/siamac.html)\n- arxiv: [https://arxiv.org/abs/1604.02426](https://arxiv.org/abs/1604.02426)\n- paper: [http://cmp.felk.cvut.cz/~radenfil/publications/Radenovic-ECCV16.pdf](http://cmp.felk.cvut.cz/~radenfil/publications/Radenovic-ECCV16.pdf)\n- code(Matlab): [http://ptak.felk.cvut.cz/personal/radenfil/siamac/siaMAC_code.tar.gz](http://ptak.felk.cvut.cz/personal/radenfil/siamac/siaMAC_code.tar.gz)\n\n**PicHunt: Social Media Image Retrieval for Improved Law Enforcement**\n\n- arxiv: [http://arxiv.org/abs/1608.00905](http://arxiv.org/abs/1608.00905)\n\n**SIFT Meets CNN: A Decade Survey of Instance Retrieval**\n\n- arxiv: [http://arxiv.org/abs/1608.01807](http://arxiv.org/abs/1608.01807)\n\n**The Sketchy Database: Learning to Retrieve Badly Drawn Bunnies**\n\n- project page: [http://sketchy.eye.gatech.edu/](http://sketchy.eye.gatech.edu/)\n- paper: [http://www.cc.gatech.edu/~hays/tmp/sketchy-database.pdf](http://www.cc.gatech.edu/~hays/tmp/sketchy-database.pdf)\n- github: [https://github.com/janesjanes/sketchy](https://github.com/janesjanes/sketchy)\n\n**What Is the Best Practice for CNNs Applied to Visual Instance Retrieval?**\n\n- arxiv: [https://arxiv.org/abs/1611.01640](https://arxiv.org/abs/1611.01640)\n\n**Image Retrieval with Deep Local Features and Attention-based Keypoints**\n\n- arxiv: [https://arxiv.org/abs/1612.05478](https://arxiv.org/abs/1612.05478)\n\n**Internet-Based Image Retrieval Using End-to-End Trained Deep Distributions**\n\n- arxiv: [https://arxiv.org/abs/1612.07697](https://arxiv.org/abs/1612.07697)\n\n**Compression of Deep Neural Networks for Image Instance Retrieval**\n\n- intro: DCC 2017\n- arxiv: [https://arxiv.org/abs/1701.04923](https://arxiv.org/abs/1701.04923)\n\n**Effective Multi-Query Expansions: Collaborative Deep Networks for Robust Landmark Retrieval**\n\n- arxiv: [https://arxiv.org/abs/1701.05003](https://arxiv.org/abs/1701.05003)\n\n**Siamese Network of Deep Fisher-Vector Descriptors for Image Retrieval**\n\n- arxiv: [https://arxiv.org/abs/1702.00338](https://arxiv.org/abs/1702.00338)\n\n**Deep Geometric Retrieval**\n\n- arxiv: [https://arxiv.org/abs/1702.06383](https://arxiv.org/abs/1702.06383)\n\n**Context Aware Query Image Representation for Particular Object Retrieval**\n\n[https://www.arxiv.org/abs/1703.01226](https://www.arxiv.org/abs/1703.01226)\n\n**An End-to-End Approach to Natural Language Object Retrieval via Context-Aware Deep Reinforcement Learning**\n\n[https://arxiv.org/abs/1703.07579](https://arxiv.org/abs/1703.07579)\n\n**AMC: Attention guided Multi-modal Correlation Learning for Image Search**\n\n- intro: CVPR 2017\n- arxiv: [https://arxiv.org/abs/1704.00763](https://arxiv.org/abs/1704.00763)\n- github: [https://github.com/kanchen-usc/amc_att](https://github.com/kanchen-usc/amc_att)\n\n**Video2Shop: Exactly Matching Clothes in Videos to Online Shopping Images**\n\n- intro: CVPR 2017\n- keywrods: AsymNet\n- arxiv: [https://arxiv.org/abs/1804.05287](https://arxiv.org/abs/1804.05287)\n\n**Deep image representations using caption generators**\n\n- intro: ICME 2017\n- arxiv: [https://arxiv.org/abs/1705.09142](https://arxiv.org/abs/1705.09142)\n\n**Visual Search at eBay**\n\n- intro: 23rd SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2017\n- arxiv: [https://arxiv.org/abs/1706.03154](https://arxiv.org/abs/1706.03154)\n\n**Sampling Matters in Deep Embedding Learning**\n\n- intro: UT Austin & A9/Amazon\n- keywords: distance weighted sampling\n- arxiv: [https://arxiv.org/abs/1706.07567](https://arxiv.org/abs/1706.07567)\n\n**One-Shot Fine-Grained Instance Retrieval**\n\n- intro: ACM MM 2017\n- arxiv: [https://arxiv.org/abs/1707.00811](https://arxiv.org/abs/1707.00811)\n\n**Selective Deep Convolutional Features for Image Retrieval**\n\n- intro: ACM MM 2017\n- arxiv: [https://arxiv.org/abs/1707.00809](https://arxiv.org/abs/1707.00809)\n\n**Class-Weighted Convolutional Features for Visual Instance Search**\n\n- intro: BMVC 2017. Universitat Politecnica de Catalunya Barcelona & CSIRO\n- project page: [http://imatge-upc.github.io/retrieval-2017-cam/](http://imatge-upc.github.io/retrieval-2017-cam/)\n- arxiv: [https://arxiv.org/abs/1707.02581](https://arxiv.org/abs/1707.02581)\n- github: [https://github.com/imatge-upc/retrieval-2017-cam](https://github.com/imatge-upc/retrieval-2017-cam)\n\n**Learning a Repression Network for Precise Vehicle Search**\n\n[https://arxiv.org/abs/1708.02386](https://arxiv.org/abs/1708.02386)\n\n**SUBIC: A supervised, structured binary code for image search**\n\n- intro: ICCV 2017 (Spotlight). Technicolor & INRIA Rennes & Amazon\n- arxiv: [https://arxiv.org/abs/1708.02932](https://arxiv.org/abs/1708.02932)\n\n**Pruning Convolutional Neural Networks for Image Instance Retrieval**\n\n[https://arxiv.org/abs/1707.05455](https://arxiv.org/abs/1707.05455)\n\n**Image2song: Song Retrieval via Bridging Image Content and Lyric Words**\n\n- intro: ICCV 2017. Chinese Academy of Sciences & Northwestern Polytechnical University\n- arxiv: [https://arxiv.org/abs/1708.05851](https://arxiv.org/abs/1708.05851)\n\n**Region-Based Image Retrieval Revisited**\n\n- intro: ACM Multimedia 2017 (Oral)\n- arxiv: [https://arxiv.org/abs/1709.09106](https://arxiv.org/abs/1709.09106)\n\n**Beyond Part Models: Person Retrieval with Refined Part Pooling**\n\n[https://arxiv.org/abs/1711.09349](https://arxiv.org/abs/1711.09349)\n\n**Query-Adaptive R-CNN for Open-Vocabulary Object Detection and Retrieval**\n\n[https://arxiv.org/abs/1711.09509](https://arxiv.org/abs/1711.09509)\n\n**Saliency Weighted Convolutional Features for Instance Search**\n\n- intro: Dublin City University & Universitat Politecnica de Catalunya\n- keywords: local convolutional features (BLCF), human visual attention models (saliency)\n- project page: [https://imatge-upc.github.io/salbow/](https://imatge-upc.github.io/salbow/)\n- arxiv: [https://arxiv.org/abs/1711.10795](https://arxiv.org/abs/1711.10795)\n- github: [https://arxiv.org/abs/1711.10795](https://arxiv.org/abs/1711.10795)\n\n**DeepStyle: Multimodal Search Engine for Fashion and Interior Design**\n\n[https://arxiv.org/abs/1801.03002](https://arxiv.org/abs/1801.03002)\n\n**From Selective Deep Convolutional Features to Compact Binary Representations for Image Retrieval**\n\n[https://arxiv.org/abs/1802.02899](https://arxiv.org/abs/1802.02899)\n\n**Web-Scale Responsive Visual Search at Bing**\n\n- intro: Microsoft\n- arxiv: [https://arxiv.org/abs/1802.04914](https://arxiv.org/abs/1802.04914)\n\n**Approximate Query Matching for Image Retrieval**\n\n[https://arxiv.org/abs/1803.05401](https://arxiv.org/abs/1803.05401)\n\n**Object Captioning and Retrieval with Natural Language**\n\n[https://arxiv.org/abs/1803.06152](https://arxiv.org/abs/1803.06152)\n\n**Triplet-Center Loss for Multi-View 3D Object Retrieval**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1803.06189](https://arxiv.org/abs/1803.06189)\n\n**Collaborative Multi-modal deep learning for the personalized product retrieval in Facebook Marketplace**\n\n- intro: Facebook\n= arxiv: [https://arxiv.org/abs/1805.12312](https://arxiv.org/abs/1805.12312)\n\n**DeepFirearm: Learning Discriminative Feature Representation for Fine-grained Firearm Retrieval**\n\n- intro: ICPR 2018\n- arxiv: [https://arxiv.org/abs/1806.02984](https://arxiv.org/abs/1806.02984)\n- github: [https://github.com/jdhao/deep_firearm](https://github.com/jdhao/deep_firearm)\n\n**Instance Search via Instance Level Segmentation and Feature Representation**\n\n[https://arxiv.org/abs/1806.03576](https://arxiv.org/abs/1806.03576)\n\n**Deep Feature Aggregation with Heat Diffusion for Image Retrieval**\n\n- arxiv: [https://arxiv.org/abs/1805.08587](https://arxiv.org/abs/1805.08587)\n- github: [https://github.com/pangsm0415/HeW](https://github.com/pangsm0415/HeW)\n\n**Single Shot Scene Text Retrieval**\n\n- intro: ECCV 2018\n- arxiv: [https://arxiv.org/abs/1808.09044](https://arxiv.org/abs/1808.09044)\n\n**Learning Embeddings for Product Visual Search with Triplet Loss and Online Sampling**\n\n- intro: Yahoo Research\n- arxiv: [https://arxiv.org/abs/1810.04652](https://arxiv.org/abs/1810.04652)\n\n**Attention-aware Generalized Mean Pooling for Image Retrieval**\n\n[https://arxiv.org/abs/1811.00202](https://arxiv.org/abs/1811.00202)\n\n**Hierarchy-based Image Embeddings for Semantic Image Retrieval**\n\n- intro: WACV 2019\n- arxiv: [https://arxiv.org/abs/1809.09924](https://arxiv.org/abs/1809.09924)\n- github: [https://github.com/cvjena/semantic-embeddings](https://github.com/cvjena/semantic-embeddings)\n\n**Mean Local Group Average Precision (mLGAP): A New Performance Metric for Hashing-based Retrieval**\n\n[https://arxiv.org/abs/1811.09763](https://arxiv.org/abs/1811.09763)\n\n**Instance-level Sketch-based Retrieval by Deep Triplet Classification Siamese Network**\n\n[https://arxiv.org/abs/1811.11375](https://arxiv.org/abs/1811.11375)\n\n**Detect-to-Retrieve: Efficient Regional Aggregation for Image Search**\n\n- intro: University of Cambridge & Google AI\n- arxiv: [https://arxiv.org/abs/1812.01584](https://arxiv.org/abs/1812.01584)\n\n**Learning with Average Precision: Training Image Retrieval with a Listwise Loss**\n\n- intro: NAVER LABS Europe\n- arxiv: [https://arxiv.org/abs/1906.07589](https://arxiv.org/abs/1906.07589)\n\n**A Benchmark on Tricks for Large-scale Image Retrieval**\n\n- arxiv: [https://arxiv.org/abs/1907.11854](https://arxiv.org/abs/1907.11854)\n\n**Smooth-AP: Smoothing the Path Towards Large-Scale Image Retrieval**\n\n- intro: ECCV 2020\n- arxiv: [https://arxiv.org/abs/2007.12163](https://arxiv.org/abs/2007.12163)\n\n**Keypoint-Aligned Embeddings for Image Retrieval and Re-identification**\n\n- intro: WACV 2021\n- arxiv: [https://arxiv.org/abs/2008.11368](https://arxiv.org/abs/2008.11368)\n\n**Tasks Integrated Networks: Joint Detection and Retrieval for Image Search**\n\n[https://arxiv.org/abs/2009.01438](https://arxiv.org/abs/2009.01438)\n\n**Instance-level Image Retrieval using Reranking Transformers**\n\n- intro: University of Virginia & eBay Computer Vision\n- arxiv: [https://arxiv.org/abs/2103.12236](https://arxiv.org/abs/2103.12236)\n\n# Hashing\n\n**Supervised Hashing for Image Retrieval via Image Representation Learning**\n\n- intro: AAAI 2014. Sun Yat-Sen University & National University of Singapore\n- keywords: CNNH (Convolutional Neural Network Hashing)\n- paper: [www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/download/8137/8861](www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/download/8137/8861)\n- slides: [https://pdfs.semanticscholar.org/f633/8f23860f9c4808586bbc7e8907d33836147f.pdf](https://pdfs.semanticscholar.org/f633/8f23860f9c4808586bbc7e8907d33836147f.pdf)\n\n**Simultaneous Feature Learning and Hash Coding with Deep Neural Networks**\n\n- intro: CVPR 2015. Sun Yat-Sen University & National University of Singapore\n- keywords: NINH (NIN Hashing), DNNH (Deep Neural Network Hashing)\n- arxiv: [https://arxiv.org/abs/1504.03410](https://arxiv.org/abs/1504.03410)\n- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Lai_Simultaneous_Feature_Learning_2015_CVPR_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Lai_Simultaneous_Feature_Learning_2015_CVPR_paper.pdf)\n\n**Hashing by Deep Learning**\n\n- intro: IBM T. J. Watson Research Center\n- paper: [http://www.ee.columbia.edu/~wliu/WeiLiu_DLHash.pdf](http://www.ee.columbia.edu/~wliu/WeiLiu_DLHash.pdf)\n\n**Deep Semantic Ranking Based Hashing for Multi-Label Image Retrieval**\n\n- intro: CVPR 2015. DSRH (Deep Semantic Ranking Hashing)\n- arxiv: [http://arxiv.org/abs/1501.06272](http://arxiv.org/abs/1501.06272)\n\n**Deep Learning of Binary Hash Codes for Fast Image Retrieval**\n\n- intro: CVPR Workshop 2015\n- keywords: MNIST, CIFAR-10, Yahoo-1M. DLBHC (Deep Learning of Binary Hash Codes)\n- paper: [http://www.iis.sinica.edu.tw/~kevinlin311.tw/cvprw15.pdf](http://www.iis.sinica.edu.tw/~kevinlin311.tw/cvprw15.pdf)\n- github: [https://github.com/kevinlin311tw/caffe-cvprw15](https://github.com/kevinlin311tw/caffe-cvprw15)\n\n**Supervised Learning of Semantics-Preserving Hashing via Deep Neural Networks for Large-Scale Image Search**\n\n- intro: SSDH\n- arxiv: [http://arxiv.org/abs/1507.00101](http://arxiv.org/abs/1507.00101)\n- github: [https://github.com/kevinlin311tw/Caffe-DeepBinaryCode](https://github.com/kevinlin311tw/Caffe-DeepBinaryCode)\n\n**Bit-Scalable Deep Hashing with Regularized Similarity Learning for Image Retrieval and Person Re-identification**\n\n- intro: IEEE Transactions on Image Processing 2015\n- keywords: DRSCH (Deep Regularized Similarity Comparison Hashing)\n- project page: [http://vision.sysu.edu.cn/projects/deephashing/](http://vision.sysu.edu.cn/projects/deephashing/)\n- arxiv: [https://arxiv.org/abs/1508.04535](https://arxiv.org/abs/1508.04535)\n- github: [https://github.com/ruixuejianfei/BitScalableDeepHash](https://github.com/ruixuejianfei/BitScalableDeepHash)\n\n**Deep Supervised Hashing for Fast Image Retrieval**\n\n- intro: CVPR 2016\n- keywords: DSH (Deep Supervised Hashing)\n- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_Deep_Supervised_Hashing_CVPR_2016_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_Deep_Supervised_Hashing_CVPR_2016_paper.pdf)\n- paper: [http://www.jdl.ac.cn/doc/2011/201711214443668218_deep%20supervised%20hashing%20for%20fast%20image%20retrieval_cvpr2016.pdf](http://www.jdl.ac.cn/doc/2011/201711214443668218_deep%20supervised%20hashing%20for%20fast%20image%20retrieval_cvpr2016.pdf)\n- github: [https://github.com/lhmRyan/deep-supervised-hashing-DSH](https://github.com/lhmRyan/deep-supervised-hashing-DSH)\n\n**Deep Hashing Network for Efficient Similarity Retrieval**\n\n- intro: AAAI 2016\n- paper: [http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12039](http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12039)\n\n**Feature Learning based Deep Supervised Hashing with Pairwise Labels**\n\n- intro: IJCAI 2016\n- arxiv: [https://arxiv.org/abs/1511.03855](https://arxiv.org/abs/1511.03855)\n- paper: [https://www.ijcai.org/Proceedings/16/Papers/245.pdf](https://www.ijcai.org/Proceedings/16/Papers/245.pdf)\n- paper: [https://cs.nju.edu.cn/lwj/paper/IJCAI16_DPSH.pdf](https://cs.nju.edu.cn/lwj/paper/IJCAI16_DPSH.pdf)\n- code: [http://cs.nju.edu.cn/lwj/code/DPSH_code.rar](http://cs.nju.edu.cn/lwj/code/DPSH_code.rar)\n\n**Deep Cross-Modal Hashing**\n\n[https://arxiv.org/abs/1602.02255](https://arxiv.org/abs/1602.02255)\n\n**Cycle-Consistent Deep Generative Hashing for Cross-Modal Retrieval**\n\n[https://arxiv.org/abs/1804.11013](https://arxiv.org/abs/1804.11013)\n\n**SSDH: Semi-supervised Deep Hashing for Large Scale Image Retrieval**\n\n- arxiv: [http://arxiv.org/abs/1607.08477](http://arxiv.org/abs/1607.08477)\n\n**Deep Semantic-Preserving and Ranking-Based Hashing for Image Retrieval**\n\n- intro: Microsoft\n- paper: [http://www.microsoft.com/en-us/research/wp-content/uploads/2016/08/Deep-Semantic-Preserving-and-Ranking-Based-Hashing-for-Image-Retrieval.pdf](http://www.microsoft.com/en-us/research/wp-content/uploads/2016/08/Deep-Semantic-Preserving-and-Ranking-Based-Hashing-for-Image-Retrieval.pdf)\n\n**Deep Hashing: A Joint Approach for Image Signature Learning**\n\n- arxiv: [http://arxiv.org/abs/1608.03658](http://arxiv.org/abs/1608.03658)\n\n**Transitive Hashing Network for Heterogeneous Multimedia Retrieval**\n\n- intro: state of the art on NUS-WIDE, ImageNet-YahooQA\n- arxiv: [http://arxiv.org/abs/1608.04307](http://arxiv.org/abs/1608.04307)\n\n**Deep Residual Hashing**\n\n- arxiv: [https://arxiv.org/abs/1612.05400](https://arxiv.org/abs/1612.05400)\n\n**Deep Region Hashing for Efficient Large-scale Instance Search from Images**\n\n- intro: Columbia University & University of Electronic Science and Technology of China\n- arxiv: [https://arxiv.org/abs/1701.07901](https://arxiv.org/abs/1701.07901)\n\n**HashNet: Deep Learning to Hash by Continuation**\n\n- intro: ICCV 2017. Tsinghua University\n- arxiv: [https://arxiv.org/abs/1702.00758](https://arxiv.org/abs/1702.00758)\n- github: [https://github.com/thuml/HashNet](https://github.com/thuml/HashNet)\n\n**Unsupervised Triplet Hashing for Fast Image Retrieval**\n\n- arxiv: [https://www.arxiv.org/abs/1702.08798](https://www.arxiv.org/abs/1702.08798)\n\n**Deep Sketch Hashing: Fast Free-hand Sketch-Based Image Retrieval**\n\n- intro: CVPR 2017 spotlight paper\n- arxiv: [https://arxiv.org/abs/1703.05605](https://arxiv.org/abs/1703.05605)\n\n**Learning Robust Hash Codes for Multiple Instance Image Retrieval**\n\n- arxiv: [https://arxiv.org/abs/1703.05724](https://arxiv.org/abs/1703.05724)\n\n**Simultaneous Feature Aggregating and Hashing for Large-scale Image Search**\n\n- intro: CVPR 2017\n- arxiv: [https://arxiv.org/abs/1704.00860](https://arxiv.org/abs/1704.00860)\n\n**Learning to Hash**\n\n- blog: [https://cs.nju.edu.cn/lwj/L2H.html](https://cs.nju.edu.cn/lwj/L2H.html)\n\n**Hashing as Tie-Aware Learning to Rank**\n\n[https://arxiv.org/abs/1705.08562](https://arxiv.org/abs/1705.08562)\n\n**Deep Hashing Network for Unsupervised Domain Adaptation**\n\n- intro: CVPR 2017\n- arxiv: [https://arxiv.org/abs/1706.07522](https://arxiv.org/abs/1706.07522)\n- github(MatConvNet): [https://github.com/hemanthdv/da-hash](https://github.com/hemanthdv/da-hash)\n\n**Deep Binary Reconstruction for Cross-modal Hashing**\n\n- intro: ACM Multimedia 2017\n- arxiv: [https://arxiv.org/abs/1708.05127](https://arxiv.org/abs/1708.05127)\n\n**A Revisit on Deep Hashings for Large-scale Content Based Image Retrieval**\n\n- intro: Zhejiang University\n- arixv: [https://arxiv.org/abs/1711.06016](https://arxiv.org/abs/1711.06016)\n\n**The Devil is in the Middle: Exploiting Mid-level Representations for Cross-Domain Instance Matching**\n\n- keywords: finegrained sketch-based image retrieval (FG-SBIR) and Person Re-identification (person ReID)\n- arxiv: [https://arxiv.org/abs/1711.08106](https://arxiv.org/abs/1711.08106)\n\n**ForestHash: Semantic Hashing With Shallow Random Forests and Tiny Convolutional Networks**\n\n[https://arxiv.org/abs/1711.08364](https://arxiv.org/abs/1711.08364)\n\n**Supervised Hashing with End-to-End Binary Deep Neural Network**\n\n[https://arxiv.org/abs/1711.08901](https://arxiv.org/abs/1711.08901)\n\n**Transfer Adversarial Hashing for Hamming Space Retrieval**\n\n[https://arxiv.org/abs/1712.04616](https://arxiv.org/abs/1712.04616)\n\n**Dual Asymmetric Deep Hashing Learning**\n\n[https://arxiv.org/abs/1801.08360](https://arxiv.org/abs/1801.08360)\n\n**Attribute-Guided Network for Cross-Modal Zero-Shot Hashing**\n\n[https://arxiv.org/abs/1802.01943](https://arxiv.org/abs/1802.01943)\n\n**Deep Reinforcement Learning for Image Hashing**\n\n[https://arxiv.org/abs/1802.02904](https://arxiv.org/abs/1802.02904)\n\n**Hashing with Mutual Information**\n\n[https://arxiv.org/abs/1803.00974](https://arxiv.org/abs/1803.00974)\n\n**Zero-Shot Sketch-Image Hashing**\n\n- intro: CVPR 2018 spotlight\n- arxiv: [https://arxiv.org/abs/1803.02284](https://arxiv.org/abs/1803.02284)\n\n**Instance Similarity Deep Hashing for Multi-Label Image Retrieval**\n\n[https://arxiv.org/abs/1803.02987](https://arxiv.org/abs/1803.02987)\n\n**Deep Class-Wise Hashing: Semantics-Preserving Hashing via Class-wise Loss**\n\n- intro: City University of Hong Kong\n- arxiv: [https://arxiv.org/abs/1803.04137](https://arxiv.org/abs/1803.04137)\n\n**Unsupervised Semantic Deep Hashing**\n\n[https://arxiv.org/abs/1803.06911](https://arxiv.org/abs/1803.06911)\n\n**SketchMate: Deep Hashing for Million-Scale Human Sketch Retrieval**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1804.01401](https://arxiv.org/abs/1804.01401)\n\n**Improving Deep Binary Embedding Networks by Order-aware Reweighting of Triplets**\n\n- intro: Sun Yat-sen University\n- arxiv: [https://arxiv.org/abs/1804.06061](https://arxiv.org/abs/1804.06061)\n\n**Deep Semantic Hashing with Generative Adversarial Networks**\n\n- intro: SIGIR 2017 Oral\n- arxiv: [https://arxiv.org/abs/1804.08275](https://arxiv.org/abs/1804.08275)\n\n**Deep Ordinal Hashing with Spatial Attention**\n\n[https://arxiv.org/abs/1805.02459](https://arxiv.org/abs/1805.02459)\n\n**Efficient end-to-end learning for quantizable representations**\n\n- intro: ICML 2018. Seoul National University\n- arxiv: [https://arxiv.org/abs/1805.05809](https://arxiv.org/abs/1805.05809)\n- github: [https://github.com/maestrojeong/Deep-Hash-Table-ICML18](https://github.com/maestrojeong/Deep-Hash-Table-ICML18)\n\n**Unsupervised Deep Image Hashing through Tag Embeddings**\n\n[https://arxiv.org/abs/1806.05804](https://arxiv.org/abs/1806.05804)\n\n**Adversarial Learning for Fine-grained Image Search**\n\n[https://arxiv.org/abs/1807.02247](https://arxiv.org/abs/1807.02247)\n\n**Error Correction Maximization for Deep Image Hashing**\n\n[https://arxiv.org/abs/1808.01942](https://arxiv.org/abs/1808.01942)\n\n**Deep Priority Hashing**\n\n- intro: ACM MM 2018 Poster\n- arxiv: [https://arxiv.org/abs/1809.01238](https://arxiv.org/abs/1809.01238)\n\n**Neurons Merging Layer: Towards Progressive Redundancy Reduction for Deep Supervised Hashing**\n\n[https://arxiv.org/abs/1809.02302](https://arxiv.org/abs/1809.02302)\n\n**Deep LDA Hashing**\n\n[https://arxiv.org/abs/1810.03402](https://arxiv.org/abs/1810.03402)\n\n**Deep Triplet Quantization**\n\n- intro: ACM Multimedia 2018 oral\n- arxiv: [https://arxiv.org/abs/1902.00153](https://arxiv.org/abs/1902.00153)\n\n**SADIH: Semantic-Aware DIscrete Hashing**\n\n- intro: AAAI 2019\n- arxiv: [https://arxiv.org/abs/1904.01739](https://arxiv.org/abs/1904.01739)\n\n**Feature Pyramid Hashing**\n\n[https://arxiv.org/abs/1904.02325](https://arxiv.org/abs/1904.02325)\n\n**Global Hashing System for Fast Image Search**\n\n[https://arxiv.org/abs/1904.08685](https://arxiv.org/abs/1904.08685)\n\n**Self-Distilled Hashing for Deep Image Retrieval**\n\n- intro: Seoul National University & NAVER/LINE Vision\n- arxiv: [https://arxiv.org/abs/2112.08816](https://arxiv.org/abs/2112.08816)\n\n# Cross Modal Retrieval\n\n**Cross-domain Image Retrieval with a Dual Attribute-aware Ranking Network**\n\n- intro: ICCV 2015\n- intro: DARN, cross-entropy loss, triplet loss\n- arxiv: [http://arxiv.org/abs/1505.07922](http://arxiv.org/abs/1505.07922)\n\n**Deep Learning for Content-Based, Cross-Modal Retrieval of Videos and Music**\n\n- arxiv: [https://arxiv.org/abs/1704.06761](https://arxiv.org/abs/1704.06761)\n- supplementary: [https://youtu.be/ZyINqDMo3Fg](https://youtu.be/ZyINqDMo3Fg)\n\n**Deep Binaries: Encoding Semantic-Rich Cues for Efficient Textual-Visual Cross Retrieval**\n\n- intro: ICCV 2017\n- arxiv: [https://arxiv.org/abs/1708.02531](https://arxiv.org/abs/1708.02531)\n\n**MHTN: Modal-adversarial Hybrid Transfer Network for Cross-modal Retrieval**\n\n[https://arxiv.org/abs/1708.04308](https://arxiv.org/abs/1708.04308)\n\n**Cross-Domain Image Retrieval with Attention Modeling**\n\n[https://arxiv.org/abs/1709.01784](https://arxiv.org/abs/1709.01784)\n\n**Look, Imagine and Match: Improving Textual-Visual Cross-Modal Retrieval with Generative Models**\n\n[https://arxiv.org/abs/1711.06420](https://arxiv.org/abs/1711.06420)\n\n**HashGAN:Attention-aware Deep Adversarial Hashing for Cross Modal Retrieval**\n\n[https://arxiv.org/abs/1711.09347](https://arxiv.org/abs/1711.09347)\n\n**Objects that Sound**\n\n- intro: DeepMind, VGG\n- arxiv: [https://arxiv.org/abs/1712.06651](https://arxiv.org/abs/1712.06651)\n\n**Cross-modal Embeddings for Video and Audio Retrieval**\n\n- arxiv: [https://arxiv.org/abs/1801.02200](https://arxiv.org/abs/1801.02200)\n- github: [https://github.com/surisdi/youtube-8m](https://github.com/surisdi/youtube-8m)\n\n**Learnable PINs: Cross-Modal Embeddings for Person Identity**\n\n- intro: VGG\n- arxiv: [https://arxiv.org/abs/1805.00833](https://arxiv.org/abs/1805.00833)\n\n**Revisiting Cross Modal Retrieval**\n\n- intro: ECCVW (MULA 2018)\n- arxiv: [https://arxiv.org/abs/1807.07364](https://arxiv.org/abs/1807.07364)\n\n## Projects\n\n**HABIR哈希图像检索工具箱**\n\n- intro: Various hashing methods for image retrieval and serves as the baselines\n- blog: [http://yongyuan.name/habir/](http://yongyuan.name/habir/)\n- github: [https://github.com/willard-yuan/hashing-baseline-for-image-retrieval](https://github.com/willard-yuan/hashing-baseline-for-image-retrieval)\n\n# Video Indexing / Retrieval\n\n**Face Video Retrieval via Deep Learning of Binary Hash Representations**\n\n- paper: [https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11893/12117](https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11893/12117)\n\n**Deep Learning Based Semantic Video Indexing and Retrieval**\n\n- arxiv: [https://arxiv.org/abs/1601.07754](https://arxiv.org/abs/1601.07754)\n\n**Learning Joint Representations of Videos and Sentences with Web Image Search**\n\n- intro: 4th Workshop on Web-scale Vision and Social Media (VSM), ECCV 2016\n- arxiv: [http://arxiv.org/abs/1608.02367](http://arxiv.org/abs/1608.02367)\n\n**Multi-View Product Image Search Using ConvNets Features**\n\n- arxiv: [http://arxiv.org/abs/1608.03462](http://arxiv.org/abs/1608.03462)\n\n**Generalisation and Sharing in Triplet Convnets for Sketch based Visual Search**\n\n- arxiv: [https://arxiv.org/abs/1611.05301](https://arxiv.org/abs/1611.05301)\n\n**Binary Subspace Coding for Query-by-Image Video Retrieval**\n\n- arxiv: [https://arxiv.org/abs/1612.01657](https://arxiv.org/abs/1612.01657)\n\n**Action Search: Learning to Search for Human Activities in Untrimmed Videos**\n\n[https://arxiv.org/abs/1706.04269](https://arxiv.org/abs/1706.04269)\n\n**Deep Supervised Hashing with Triplet Labels**\n\n- intro: ACCV 2016\n- arxiv: [https://arxiv.org/abs/1612.03900](https://arxiv.org/abs/1612.03900)\n\n**Supervised Deep Hashing for Hierarchical Labeled Data**\n\n- arxiv: [https://arxiv.org/abs/1704.02088](https://arxiv.org/abs/1704.02088)\n\n**Localizing Moments in Video with Natural Language**\n\n- intro: ICCV 2017\n- arxiv: [https://arxiv.org/abs/1708.01641](https://arxiv.org/abs/1708.01641)\n\n**Dress like a Star: Retrieving Fashion Products from Videos**\n\n- intro: Aston University\n- arxiv: [https://arxiv.org/abs/1710.07198](https://arxiv.org/abs/1710.07198)\n\n**Deep Hashing with Category Mask for Fast Video Retrieval**\n\n[https://arxiv.org/abs/1712.08315](https://arxiv.org/abs/1712.08315)\n\n**Focus: Querying Large Video Datasets with Low Latency and Low Cost**\n\n[https://arxiv.org/abs/1801.03493](https://arxiv.org/abs/1801.03493)\n\n**Text-to-Clip Video Retrieval with Early Fusion and Re-Captioning**\n\n- intro: Boston University, University of British Columbia\n- arxiv: [https://arxiv.org/abs/1804.05113](https://arxiv.org/abs/1804.05113)\n\n# Learning to Rank\n\n**Simple to Complex Cross-modal Learning to Rank**\n\n- intro: Xi’an Jiaotong University & University of Technology Sydney & National University of Singapore & CMU\n- arxiv: [https://arxiv.org/abs/1702.01229](https://arxiv.org/abs/1702.01229)\n\n**SoDeep: a Sorting Deep net to learn ranking loss surrogates**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1904.04272](https://arxiv.org/abs/1904.04272)\n- github: [https://github.com/technicolor-research/sodeep](https://github.com/technicolor-research/sodeep)\n\n# Deep Metric Learning\n\n**Deep metric learning using Triplet network**\n\n- arxiv: [https://arxiv.org/abs/1412.6622](https://arxiv.org/abs/1412.6622)\n- slides: [http://tce.technion.ac.il/wp-content/uploads/sites/8/2016/01/Elad-Hofer.pdf](http://tce.technion.ac.il/wp-content/uploads/sites/8/2016/01/Elad-Hofer.pdf)\n- github: [https://github.com/eladhoffer/TripletNet](https://github.com/eladhoffer/TripletNet)\n\n**Improved Deep Metric Learning with Multi-class N-pair Loss Objective**\n\n- intro: NIPS 2016\n- arxiv: [http://www.nec-labs.com/uploads/images/Department-Images/MediaAnalytics/papers/nips16_npairmetriclearning.pdf](http://www.nec-labs.com/uploads/images/Department-Images/MediaAnalytics/papers/nips16_npairmetriclearning.pdf)\n\n**Metric Learning with Adaptive Density Discrimination**\n\n- intro: ICLR 2016. Facebook AI Research & UC Berkeley\n- arxiv: [https://arxiv.org/abs/1511.05939](https://arxiv.org/abs/1511.05939)\n- github: [https://github.com/pumpikano/tf-magnet-loss](https://github.com/pumpikano/tf-magnet-loss)\n- github: [https://github.com/vithursant/MagnetLoss-PyTorch/](https://github.com/vithursant/MagnetLoss-PyTorch/)\n\n**Hard-Aware Deeply Cascaded Embedding**\n\n- intro: ICCV 2017\n- arxiv: [https://arxiv.org/abs/1611.05720](https://arxiv.org/abs/1611.05720)\n- paper: [http://openaccess.thecvf.com/content_ICCV_2017/papers/Yuan_Hard-Aware_Deeply_Cascaded_ICCV_2017_paper.pdf](http://openaccess.thecvf.com/content_ICCV_2017/papers/Yuan_Hard-Aware_Deeply_Cascaded_ICCV_2017_paper.pdf)\n- github: [https://github.com/PkuRainBow/Hard-Aware-Deeply-Cascaded-Embedding_release](https://github.com/PkuRainBow/Hard-Aware-Deeply-Cascaded-Embedding_release)\n- github: [https://github.com/PkuRainBow/Hard-Aware-Deeply-Cascaed-Embedding](https://github.com/PkuRainBow/Hard-Aware-Deeply-Cascaed-Embedding)\n\n**Learnable Structured Clustering Framework for Deep Metric Learning**\n\n- arxiv: [https://arxiv.org/abs/1612.01213](https://arxiv.org/abs/1612.01213)\n\n**Deep Metric Learning via Lifted Structured Feature Embedding**\n\n- intro: CVPR 2016\n- project page(code+data): [http://cvgl.stanford.edu/projects/lifted_struct/](http://cvgl.stanford.edu/projects/lifted_struct/)\n- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Song_Deep_Metric_Learning_CVPR_2016_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Song_Deep_Metric_Learning_CVPR_2016_paper.pdf)\n- paper: [http://cvgl.stanford.edu/papers/song_cvpr16.pdf](http://cvgl.stanford.edu/papers/song_cvpr16.pdf)\n- github: [https://github.com/rksltnl/Deep-Metric-Learning-CVPR16](https://github.com/rksltnl/Deep-Metric-Learning-CVPR16)\n- github: [https://github.com/rksltnl/Caffe-Deep-Metric-Learning-CVPR16](https://github.com/rksltnl/Caffe-Deep-Metric-Learning-CVPR16)\n- dataset: [ftp://cs.stanford.edu/cs/cvgl/Stanford_Online_Products.zip](ftp://cs.stanford.edu/cs/cvgl/Stanford_Online_Products.zip)\n\n**Cross-modal Deep Metric Learning with Multi-task Regularization**\n\n- intro: ICME 2017\n- arxiv: [https://arxiv.org/abs/1703.07026](https://arxiv.org/abs/1703.07026)\n\n**Smart Mining for Deep Metric Learning**\n\n[https://arxiv.org/abs/1704.01285](https://arxiv.org/abs/1704.01285)\n\n**DarkRank: Accelerating Deep Metric Learning via Cross Sample Similarities Transfer**\n\n- intro: TuSimple\n- keywords: pedestrian re-identification\n- arxiv: [https://arxiv.org/abs/1707.01220](https://arxiv.org/abs/1707.01220)\n\n**Deep Metric Learning with Angular Loss**\n\n- intro: ICCV 2017\n- arxiv: [https://arxiv.org/abs/1708.01682](https://arxiv.org/abs/1708.01682)\n\n**Deep Metric Learning with BIER: Boosting Independent Embeddings Robustly**\n\n[https://arxiv.org/abs/1801.04815](https://arxiv.org/abs/1801.04815)\n\n**Directional Statistics-based Deep Metric Learning for Image Classification and Retrieval**\n\n[https://arxiv.org/abs/1802.09662](https://arxiv.org/abs/1802.09662)\n\n**Generalization in Metric Learning: Should the Embedding Layer be the Embedding Layer?**\n\n- intro: Georgia Tech\n- keywords: Cars-196, CUB-200-2011 and Stanford Online Product\n- arxiv: [https://arxiv.org/abs/1803.03310](https://arxiv.org/abs/1803.03310)\n\n**Deep Metric Learning**\n\n- github(PyTorch): [https://github.com/bnulihaixia/Deep_metric](https://github.com/bnulihaixia/Deep_metric)\n\n**Attention-based Ensemble for Deep Metric Learning**\n\n[https://arxiv.org/abs/1804.00382](https://arxiv.org/abs/1804.00382)\n\n**Online Deep Metric Learning**\n\n[https://arxiv.org/abs/1805.05510](https://arxiv.org/abs/1805.05510)\n\n**Deep Randomized Ensembles for Metric Learning**\n\n- arxiv: [https://arxiv.org/abs/1808.04469](https://arxiv.org/abs/1808.04469)\n- github: [https://github.com/littleredxh/DREML](https://github.com/littleredxh/DREML)\n\n**Deep Metric Learning with Hierarchical Triplet Loss**\n\n- intro: ECCV 2018\n- arxiv: [https://arxiv.org/abs/1810.06951](https://arxiv.org/abs/1810.06951)\n\n**Ranked List Loss for Deep Metric Learning**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1903.03238](https://arxiv.org/abs/1903.03238)\n\n**Hardness-Aware Deep Metric Learning**\n\n- intro: CVPR 2019 Oral\n- arxiv: [https://arxiv.org/abs/1903.05503](https://arxiv.org/abs/1903.05503)\n- github(official, Tensorflow): [https://github.com/wzzheng/HDML](https://github.com/wzzheng/HDML)\n\n**Signal-to-Noise Ratio: A Robust Distance Metric for Deep Metric Learning**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1904.02616](https://arxiv.org/abs/1904.02616)\n\n**Multi-Similarity Loss with General Pair Weighting for Deep Metric Learning**\n\n- arxiv: [https://arxiv.org/abs/1904.06627](https://arxiv.org/abs/1904.06627)\n- github: [https://github.com/MalongTech/research-ms-loss](https://github.com/MalongTech/research-ms-loss)\n\n**Deep Metric Learning Beyond Binary Supervision**\n\n- intro: CVPR 2019 oral\n- arxiv: [https://arxiv.org/abs/1904.09626](https://arxiv.org/abs/1904.09626)\n\n**SoftTriple Loss: Deep Metric Learning Without Triplet Sampling**\n\n- intro: ICCV 2019\n- arxiv: [https://arxiv.org/abs/1909.05235](https://arxiv.org/abs/1909.05235)\n\n**The Group Loss for Deep Metric Learning**\n\n[https://arxiv.org/abs/1912.00385](https://arxiv.org/abs/1912.00385)\n\n**Embedding Expansion: Augmentation in Embedding Space for Deep Metric Learning**\n\n- intro: CVPR 2020\n- intro: NAVER Corp.\n- arxiv: [https://arxiv.org/abs/2003.02546](https://arxiv.org/abs/2003.02546)\n\n**Proxy Anchor Loss for Deep Metric Learning**\n\n- intro: CVPR 2020\n- arxiv: [https://arxiv.org/abs/2003.13911](https://arxiv.org/abs/2003.13911)\n- github(official, Pytorch): [https://github.com/tjddus9597/Proxy-Anchor-CVPR2020](https://github.com/tjddus9597/Proxy-Anchor-CVPR2020)\n\n**Spherical Feature Transform for Deep Metric Learning**\n\n- intro: ECCV 2020\n- arxiv: [https://arxiv.org/abs/2008.01469](https://arxiv.org/abs/2008.01469)\n\n**Diversified Mutual Learning for Deep Metric Learning**\n\n- intro: ECCV Workshop 2020\n- arxiv: [https://arxiv.org/abs/2009.04170](https://arxiv.org/abs/2009.04170)\n\n**Deep Metric Learning with Spherical Embedding**\n\n- intro: NeurIPS 2020\n- arxiv: [https://arxiv.org/abs/2011.02785](https://arxiv.org/abs/2011.02785)\n- github(Pytorch):[https://github.com/Dyfine/SphericalEmbedding](https://github.com/Dyfine/SphericalEmbedding)\n\n**Learning Intra-Batch Connections for Deep Metric Learning**\n\n[https://arxiv.org/abs/2102.07753](https://arxiv.org/abs/2102.07753)\n\n**LoOp: Looking for Optimal Hard Negative Embeddings for Deep Metric Learning**\n\n- intro: ICCV 2021\n- arxiv: [https://arxiv.org/abs/2108.09335](https://arxiv.org/abs/2108.09335)\n\n# Talks / Slides\n\n**TiefVision: end-to-end image similarity search engine**\n\n- intro: It covers image classification, image location ( OverFeat ) and image similarity ( Deep Ranking).\n- slides: [https://docs.google.com/presentation/d/16hrXJhOzkbmla9AL7JCreCuBsa5L80gm71Pfrjo7F9Y/edit#slide=id.p](https://docs.google.com/presentation/d/16hrXJhOzkbmla9AL7JCreCuBsa5L80gm71Pfrjo7F9Y/edit#slide=id.p)\n- github: [https://github.com/paucarre/tiefvision](https://github.com/paucarre/tiefvision)\n\n# Projects\n\n**PyRetri: A PyTorch-based Library for Unsupervised Image Retrieval by Deep Convolutional Neural Networks**\n\n- intro: Open source deep learning based image retrieval toolbox based on PyTorch\n- arxiv: [https://arxiv.org/abs/2005.02154](https://arxiv.org/abs/2005.02154)\n- github: [https://github.com/PyRetri/PyRetri](https://github.com/PyRetri/PyRetri)\n\n**图像检索：CNN卷积神经网络与实战**\n\n**CNN for Image Retrieval**\n\n- blog: [http://yongyuan.name/blog/CBIR-CNN-and-practice.html](http://yongyuan.name/blog/CBIR-CNN-and-practice.html)\n- github: [https://github.com/willard-yuan/CNN-for-Image-Retrieval](https://github.com/willard-yuan/CNN-for-Image-Retrieval)\n- demo: [http://yongyuan.name/pic/](http://yongyuan.name/pic/)\n\n**Visual Search Server**\n\n![](https://raw.githubusercontent.com/AKSHAYUBHAT/VisualSearchServer/master/appcode/static/alpha3.png)\n\n- intro: A simple implementation of Visual Search using features extracted from Tensorflow inception model and Approximate Nearest Neighbors \n- github: [https://github.com/AKSHAYUBHAT/VisualSearchServer](https://github.com/AKSHAYUBHAT/VisualSearchServer)\n\n**Vehicle Retrieval: vehicle image retrieval using k CNNs ensemble method**\n\n- intro: ranked 1st and won the special prize in the final of \nthe 3rd National Gradute Contest on Smart-CIty Technology and Creative Design, China\n- project page: [https://www.pkuml.org/resources/pku-vehicleid.html](https://www.pkuml.org/resources/pku-vehicleid.html)\n- github: [https://github.com/iamhankai/vehicle-retrieval-kCNNs](https://github.com/iamhankai/vehicle-retrieval-kCNNs)\n\n**A visual search engine based on Elasticsearch and Tensorflow**\n\n- keywords: faster r-cnn\n- github: [https://github.com/tuan3w/visual_search](https://github.com/tuan3w/visual_search)\n\n**Siamese and triplet networks with online pair/triplet mining in PyTorch**\n\n[https://github.com/adambielski/siamese-triplet](https://github.com/adambielski/siamese-triplet)\n\n**Triplet Loss and Online Triplet Mining in TensorFlow**\n\n- blog: [https://omoindrot.github.io/triplet-loss](https://omoindrot.github.io/triplet-loss)\n- gtihub: [https://github.com/omoindrot/tensorflow-triplet-loss](https://github.com/omoindrot/tensorflow-triplet-loss)\n\n# Blogs\n\n**Where can I buy a chair like that? – This app will tell you**\n\n![](http://www.news.cornell.edu/sites/chronicle.cornell/files/GrokStyleApp.png?itok=3jd_S2R7)\n\n- blog: [http://www.news.cornell.edu/stories/2016/08/where-can-i-buy-chair-app-will-tell-you](http://www.news.cornell.edu/stories/2016/08/where-can-i-buy-chair-app-will-tell-you)\n\n**Using Sketches to Search for Products Online**\n\n![](http://sketchx.eecs.qmul.ac.uk/wp-content/uploads/sites/27/2016/04/slider_template_cvpr4-1.jpg)\n\n- homepage: [http://sketchx.eecs.qmul.ac.uk/](http://sketchx.eecs.qmul.ac.uk/)\n- blog: [https://news.developer.nvidia.com/using-sketches-to-search-for-products-online/](https://news.developer.nvidia.com/using-sketches-to-search-for-products-online/)\n\n# Tutorials\n\n**Deep Image Retrieval: Learning global representations for image search**\n\n- youtube: [https://www.youtube.com/watch?v=yT52xDML6ys](https://www.youtube.com/watch?v=yT52xDML6ys)\n\n**Image Instance Retrieval: Overview of state-of-the-art**\n\n- youtube: [https://www.youtube.com/watch?v=EYq-rpaZn1o](https://www.youtube.com/watch?v=EYq-rpaZn1o)\n","excerpt":"Papers Using Very Deep Autoencoders for Content-Based Image Retrieval intro: ESANN 2011. Alex Krizhevsky, and Geoffrey E. Hinton paper:  ht…","outboundReferences":[],"inboundReferences":[]},"tagsOutbound":{"nodes":[]}},"pageContext":{"tags":[],"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-retrieval/","sidebarItems":[{"title":"Categories","items":[{"title":"Commercial","url":"","items":[{"title":"Commercial Structure","url":"/Commercial/Commercial Structure/","items":[]},{"title":"Community of Practice","url":"/Commercial/Community of Practice/","items":[]},{"title":"Domains","url":"/Commercial/Domains/","items":[]},{"title":"Webizen Alliance","url":"/Commercial/Webizen Alliance/","items":[]}]},{"title":"Core Services","url":"","items":[{"title":"Decentralised Ontologies","url":"/Core Services/Decentralised Ontologies/","items":[]},{"title":"Permissive Commons","url":"/Core Services/Permissive Commons/","items":[]},{"title":"Safety Protocols","url":"","items":[{"title":"Safety Protocols","url":"/Core Services/Safety Protocols/Safety Protocols/","items":[]},{"title":"Social Factors","url":"","items":[{"title":"Best Efforts","url":"/Core Services/Safety Protocols/Social Factors/Best Efforts/","items":[]},{"title":"Ending Digital Slavery","url":"/Core Services/Safety Protocols/Social Factors/Ending Digital Slavery/","items":[]},{"title":"Freedom of Thought","url":"/Core Services/Safety Protocols/Social Factors/Freedom of Thought/","items":[]},{"title":"No Golden Handcuffs","url":"/Core Services/Safety Protocols/Social Factors/No Golden Handcuffs/","items":[]},{"title":"Relationships (Social)","url":"/Core Services/Safety Protocols/Social Factors/Relationships (Social)/","items":[]},{"title":"Social Attack Vectors","url":"/Core Services/Safety Protocols/Social Factors/Social Attack Vectors/","items":[]},{"title":"The Webizen Charter","url":"/Core Services/Safety Protocols/Social Factors/The Webizen Charter/","items":[]}]},{"title":"Values Credentials","url":"/Core Services/Safety Protocols/Values Credentials/","items":[]}]},{"title":"Temporal Semantics","url":"/Core Services/Temporal Semantics/","items":[]},{"title":"Verifiable Claims & Credentials","url":"/Core Services/Verifiable Claims & Credentials/","items":[]},{"title":"Webizen Socio-Economics","url":"","items":[{"title":"Biosphere Ontologies","url":"/Core Services/Webizen Socio-Economics/Biosphere Ontologies/","items":[]},{"title":"Centricity","url":"/Core Services/Webizen Socio-Economics/Centricity/","items":[]},{"title":"Currencies","url":"/Core Services/Webizen Socio-Economics/Currencies/","items":[]},{"title":"SocioSphere Ontologies","url":"/Core Services/Webizen Socio-Economics/SocioSphere Ontologies/","items":[]},{"title":"Sustainable Development Goals (ESG)","url":"/Core Services/Webizen Socio-Economics/Sustainable Development Goals (ESG)/","items":[]}]}]},{"title":"Core Technologies","url":"","items":[{"title":"AUTH","url":"","items":[{"title":"Authentication Fabric","url":"/Core Technologies/AUTH/Authentication Fabric/","items":[]}]},{"title":"Webizen App Spec","url":"","items":[{"title":"SemWebSpecs","url":"","items":[{"title":"Core Ontologies","url":"","items":[{"title":"FOAF","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/FOAF/","items":[]},{"title":"General Ontology Information","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/General Ontology Information/","items":[]},{"title":"Human Rights Ontologies","url":"","items":[{"title":"UDHR","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/Human Rights Ontologies/UDHR/","items":[]}]},{"title":"MD-RDF Ontologies","url":"","items":[{"title":"DataTypesOntology (DTO) Core","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/MD-RDF Ontologies/DataTypes Ontology/","items":[]},{"title":"Friend of a Friend (FOAF) Core","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/MD-RDF Ontologies/FOAF/","items":[]}]},{"title":"OWL","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/OWL/","items":[]},{"title":"RDF Schema 1.1","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/RDFS/","items":[]},{"title":"Sitemap","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/Sitemap/","items":[]},{"title":"SKOS","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/SKOS/","items":[]},{"title":"SOIC","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/SOIC/","items":[]}]},{"title":"Semantic Web - An Introduction","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Semantic Web - An Introduction/","items":[]},{"title":"SemWeb-AUTH","url":"","items":[{"title":"WebID-OIDC","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-OIDC/","items":[]},{"title":"WebID-RSA","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-RSA/","items":[]},{"title":"WebID-TLS","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-TLS/","items":[]}]},{"title":"Sparql","url":"","items":[{"title":"Sparql Family","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Sparql/Sparql Family/","items":[]}]},{"title":"W3C Specifications","url":"","items":[{"title":"Linked Data Fragments","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Fragments/","items":[]},{"title":"Linked Data Notifications","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Notifications/","items":[]},{"title":"Linked Data Platform","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Platform/","items":[]},{"title":"Linked Media Fragments","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Media Fragments/","items":[]},{"title":"RDF","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/RDF/","items":[]},{"title":"Web Access Control (WAC)","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Web Access Control (WAC)/","items":[]},{"title":"Web Of Things","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Web Of Things/","items":[]},{"title":"WebID","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/WebID/","items":[]}]}]},{"title":"Webizen App Spec 1.0","url":"/Core Technologies/Webizen App Spec/Webizen App Spec 1.0/","items":[]},{"title":"WebSpec","url":"","items":[{"title":"HTML SPECS","url":"/Core Technologies/Webizen App Spec/WebSpec/HTML SPECS/","items":[]},{"title":"Query Interfaces","url":"","items":[{"title":"GraphQL","url":"/Core Technologies/Webizen App Spec/WebSpec/Query Interfaces/GraphQL/","items":[]}]},{"title":"WebPlatformTools","url":"","items":[{"title":"WebAuthn","url":"/Core Technologies/Webizen App Spec/WebSpec/WebPlatformTools/WebAuthn/","items":[]},{"title":"WebDav","url":"/Core Technologies/Webizen App Spec/WebSpec/WebPlatformTools/WebDav/","items":[]}]}]}]}]},{"title":"Database Requirements","url":"","items":[{"title":"Database Alternatives","url":"","items":[{"title":"Akutan","url":"/Database requirements/Database Alternatives/akutan/","items":[]},{"title":"CayleyGraph","url":"/Database requirements/Database Alternatives/CayleyGraph/","items":[]}]},{"title":"Database Methods","url":"","items":[{"title":"GraphQL","url":"/Database requirements/Database methods/GraphQL/","items":[]},{"title":"Sparql","url":"/Database requirements/Database methods/Sparql/","items":[]}]}]},{"title":"Host Service Requirements","url":"","items":[{"title":"Domain Hosting","url":"/Host Service Requirements/Domain Hosting/","items":[]},{"title":"Email Services","url":"/Host Service Requirements/Email Services/","items":[]},{"title":"LD_PostOffice_SemanticMGR","url":"/Host Service Requirements/LD_PostOffice_SemanticMGR/","items":[]},{"title":"Media Processing","url":"/Host Service Requirements/Media Processing/","items":[{"title":"Ffmpeg","url":"/Host Service Requirements/Media Processing/ffmpeg/","items":[]},{"title":"Opencv","url":"/Host Service Requirements/Media Processing/opencv/","items":[]}]},{"title":"Website Host","url":"/Host Service Requirements/Website Host/","items":[]}]},{"title":"ICT Stack","url":"","items":[{"title":"General References","url":"","items":[{"title":"List of Protocols ISO Model","url":"/ICT Stack/General References/List of Protocols ISO model/","items":[]}]},{"title":"Internet","url":"","items":[{"title":"Internet Stack","url":"/ICT Stack/Internet/Internet Stack/","items":[]}]}]},{"title":"Implementation V1","url":"","items":[{"title":"App-Design-Sdk-V1","url":"","items":[{"title":"Core Apps","url":"","items":[{"title":"Agent Directory","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Agent Directory/","items":[]},{"title":"Credentials & Contracts Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Credentials & Contracts Manager/","items":[]},{"title":"File (Package) Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/File (package) Manager/","items":[]},{"title":"Temporal Apps","url":"","items":[{"title":"Calendar","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Temporal Apps/Calendar/","items":[]},{"title":"Timeline Interface","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Temporal Apps/Timeline Interface/","items":[]}]},{"title":"Webizen Apps (V1)","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Webizen Apps (v1)/","items":[]},{"title":"Webizen Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Webizen Manager/","items":[]}]},{"title":"Data Applications","url":"/Implementation V1/App-design-sdk-v1/Data Applications/","items":[]},{"title":"Design Goals","url":"","items":[{"title":"Design Goals Overview","url":"/Implementation V1/App-design-sdk-v1/Design Goals/Design Goals Overview/","items":[]}]}]},{"title":"Edge","url":"","items":[{"title":"Webizen Local App Functionality","url":"/Implementation V1/edge/Webizen Local App Functionality/","items":[]}]},{"title":"GoLang Libraries","url":"/Implementation V1/GoLang Libraries/","items":[]},{"title":"Implementation V1 Summary","url":"/Implementation V1/Implementation V1 Summary/","items":[]},{"title":"Vps","url":"","items":[{"title":"Server Functionality Summary (VPS)","url":"/Implementation V1/vps/Server Functionality Summary (VPS)/","items":[]}]},{"title":"Webizen 1.0","url":"/Implementation V1/Webizen 1.0/","items":[]},{"title":"Webizen-Connect","url":"","items":[{"title":"Social Media APIs","url":"/Implementation V1/Webizen-Connect/Social Media APIs/","items":[]},{"title":"Webizen-Connect (Summary)","url":"/Implementation V1/Webizen-Connect/Webizen-Connect (summary)/","items":[]}]}]},{"title":"Non-HTTP(s) Protocols","url":"","items":[{"title":"DAT","url":"/Non-HTTP(s) Protocols/DAT/","items":[]},{"title":"GIT","url":"/Non-HTTP(s) Protocols/GIT/","items":[]},{"title":"GUNECO","url":"/Non-HTTP(s) Protocols/GUNECO/","items":[]},{"title":"IPFS","url":"/Non-HTTP(s) Protocols/IPFS/","items":[]},{"title":"Lightning Network","url":"/Non-HTTP(s) Protocols/Lightning Network/","items":[]},{"title":"Non-HTTP(s) Protocols (& DLTs)","url":"/Non-HTTP(s) Protocols/Non-HTTP(s) Protocols (& DLTs)/","items":[]},{"title":"WebRTC","url":"/Non-HTTP(s) Protocols/WebRTC/","items":[]},{"title":"WebSockets","url":"/Non-HTTP(s) Protocols/WebSockets/","items":[]},{"title":"WebTorrent","url":"/Non-HTTP(s) Protocols/WebTorrent/","items":[]}]},{"title":"Old-Work-Archives","url":"","items":[{"title":"2018-Webizen-Net-Au","url":"","items":[{"title":"_Link_library_links","url":"","items":[{"title":"Link Library","url":"/old-work-archives/2018-webizen-net-au/_link_library_links/2018-09-23-wp-linked-data/","items":[]}]},{"title":"_Posts","url":"","items":[{"title":"About W3C","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-27-about-w3c/","items":[]},{"title":"Advanced Functions &#8211; Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-16-advanced-functions-facebook-pages/","items":[]},{"title":"Advanced Search &#038; Discovery Tips","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-advanced-search-discovery-tips/","items":[]},{"title":"An introduction to Virtual Machines.","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-an-introduction-to-virtual-machines/","items":[]},{"title":"Basic Media Analysis &#8211; Part 1 (Audio)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-30-media-analysis-part-1-audio/","items":[]},{"title":"Basic Media Analysis &#8211; Part 2 (visual)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-31-media-analysis-part-2-visual/","items":[]},{"title":"Basic Media Analysis &#8211; Part 3 (Text &#038; Metadata)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-01-01-basic-media-analysis-part-3-text-metadata/","items":[]},{"title":"Building an Economy based upon Knowledge Equity.","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-25-building-an-economy-based-upon-knowledge-equity/","items":[]},{"title":"Choice of Law","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-26-choice-of-law/","items":[]},{"title":"Contemplation of the ITU Dubai Meeting and the Future of the Internet","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-19-contemplation-of-the-itu-dubai-meeting-and-the-future-of-the-internet/","items":[]},{"title":"Creating a Presence &#8211; Online","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-creating-a-presence-online/","items":[]},{"title":"Credentials and Payments by Manu Sporny","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-credentials-and-payments-by-manu-sporny/","items":[]},{"title":"Data Recovery &#038; Collection: Mobile Devices","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-28-mobile-devices-data-recovery-collection/","items":[]},{"title":"Data Recovery: Laptop &#038; Computers","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-28-data-recovery-laptop-computers/","items":[]},{"title":"Decentralized Web Conference 2016","url":"/old-work-archives/2018-webizen-net-au/_posts/2016-06-09-decentralized-web-2016/","items":[]},{"title":"Decentralized Web Summit 2018","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-decentralized-web-summit-2018/","items":[]},{"title":"Does Anonymity exist?","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-does-anonymity-exist/","items":[]},{"title":"Downloading My Data from Social Networks","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-downloading-my-data-from-social-networks/","items":[]},{"title":"Events","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-events/","items":[]},{"title":"Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-16-facebook-pages/","items":[]},{"title":"Google Tracking Data (geolocation)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-google-tracking/","items":[]},{"title":"Human Consciousness","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-human-consciousness/","items":[]},{"title":"Image Recgonition Video Playlist","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-image-recgonition-video-playlist/","items":[]},{"title":"Inferencing (introduction)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-inferencing-introduction/","items":[]},{"title":"Introduction to AI","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-introduction-to-ai/","items":[]},{"title":"Introduction to Linked Data","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-introduction-to-linked-data/","items":[]},{"title":"Introduction to Maltego","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-introduction-to-maltego/","items":[]},{"title":"Introduction to Ontologies","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-ontologies-intro/","items":[]},{"title":"Introduction to Semantic Web","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-introduction-to-semantic-web/","items":[]},{"title":"Knowledge Capital","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-10-17-knowledge-capital/","items":[]},{"title":"Logo&#8217;s, Style Guides and Artwork","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-logos-style-guides-and-artwork/","items":[]},{"title":"MindMapping &#8211; Setting-up a business &#8211; Identity","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-mindmapping-setting-up-a-business-identity/","items":[]},{"title":"Openlink Virtuoso","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-openlink-virtuoso/","items":[]},{"title":"OpenRefine","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-74-2/","items":[]},{"title":"Projects, Customers and Invoicing &#8211; Web-Services for Startups","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-projects-customers-and-invoicing-web-services-for-startups/","items":[]},{"title":"RWW &#038; some Solid history","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-rww-some-solid-history/","items":[]},{"title":"Semantic Web (An Intro)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-semantic-web-an-intro/","items":[]},{"title":"Setting-up Twitter","url":"/old-work-archives/2018-webizen-net-au/_posts/2013-06-07-setting-up-twitter/","items":[]},{"title":"Social Encryption: An Introduction","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-25-social-encryption-an-introduction/","items":[]},{"title":"Stock Content","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-stock-content/","items":[]},{"title":"The WayBack Machine","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-27-the-wayback-machine/","items":[]},{"title":"Tim Berners Lee &#8211; Turing Lecture","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-05-29-tim-berners-lee-turing-lecture/","items":[]},{"title":"Tools of Trade","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-tools-of-trade/","items":[]},{"title":"Trust Factory 2017","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-trust-factory-2017/","items":[]},{"title":"Verifiable Claims (An Introduction)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-vc-intro/","items":[]},{"title":"Web of Things &#8211; an Introduction","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-web-of-things-an-introduction/","items":[]},{"title":"Web-Persistence","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-web-persistence/","items":[]},{"title":"Web-Services &#8211; Marketing Tools","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-web-services-marketing-tools/","items":[]},{"title":"Website Templates","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-templates/","items":[]},{"title":"What is Linked Data?","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-what-is-linked-data/","items":[]},{"title":"What is Open Source Intelligence?","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-what-is-osint/","items":[]},{"title":"WiX","url":"/old-work-archives/2018-webizen-net-au/_posts/2013-01-01-wix/","items":[]}]},{"title":"about","url":"/old-work-archives/2018-webizen-net-au/about/","items":[{"title":"About The Author","url":"/old-work-archives/2018-webizen-net-au/about/about-the-author/","items":[]},{"title":"Applied Theory: Applications for a Human Centric Web","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/","items":[{"title":"Digital Receipts","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/digital-receipts/","items":[]},{"title":"Fake News: Considerations → Principles → The Institution of Socio &#8211; Economic Values","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations/","items":[]},{"title":"Healthy Living Economy","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/healthy-living-economy/","items":[]},{"title":"HyperMedia Solutions &#8211; Adapting HbbTV V2","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/","items":[{"title":"HYPERMEDIA PACKAGES","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/hypermedia-packages/","items":[]},{"title":"USER STORIES: INTERACTIVE VIEWING EXPERIENCE","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/user-stories-interactive-viewing-experience/","items":[]}]},{"title":"Measurements App","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/measurements-app/","items":[]},{"title":"Re:Animation","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/reanimation/","items":[]},{"title":"Solutions to FakeNews: Linked-Data, Ontologies and Verifiable Claims","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/ld-solutions-to-fakenews/","items":[]}]},{"title":"Executive Summary","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/","items":[{"title":"Assisting those who Enforce the Law","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/assisting-those-who-enforce-the-law/","items":[]},{"title":"Consumer Protections","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/consumer-protections/","items":[]},{"title":"Knowledge Banking: Legal Structures","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-banking-legal-structures/","items":[]},{"title":"Knowledge Economics &#8211; Services","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-economics-services/","items":[]},{"title":"Preserving The Freedom to Think","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/preserving-the-freedom-to-think/","items":[]}]},{"title":"History","url":"/old-work-archives/2018-webizen-net-au/about/history/","items":[{"title":"History: Global Governance and ICT.","url":"/old-work-archives/2018-webizen-net-au/about/history/history-global-governance-ict-1/","items":[]}]},{"title":"Knowledge Banking: A Technical Architecture Summary","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/","items":[{"title":"An introduction to Credentials.","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/","items":[{"title":"credentials and custodianship","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/credentials-and-custodianship/","items":[]},{"title":"DIDs and MultiSig","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/dids-and-multisig/","items":[]}]},{"title":"Personal Augmentation of AI","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/personal-augmentation-of-ai/","items":[]},{"title":"Semantic Inferencing","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/semantic-inferencing/","items":[]},{"title":"Web of Things (IoT+LD)","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/web-of-things-iotld/","items":[]}]},{"title":"References","url":"/old-work-archives/2018-webizen-net-au/about/references/","items":[{"title":"Making the distinction between ‘privacy’ and ‘dignity’.","url":"/old-work-archives/2018-webizen-net-au/about/references/privacy-vs-dignity/","items":[]},{"title":"Roles &#8211; Entity Analysis","url":"/old-work-archives/2018-webizen-net-au/about/references/roles-entity-analysis/","items":[]},{"title":"Social Informatics Design Considerations","url":"/old-work-archives/2018-webizen-net-au/about/references/social-informatics-design-concept-and-principles/","items":[]},{"title":"Socio-economic relations | A conceptual model","url":"/old-work-archives/2018-webizen-net-au/about/references/socioeconomic-relations-p1/","items":[]},{"title":"The need for decentralised Open (Linked) Data","url":"/old-work-archives/2018-webizen-net-au/about/references/the-need-for-decentralised-open-linked-data/","items":[]}]},{"title":"The design of new medium","url":"/old-work-archives/2018-webizen-net-au/about/the-design-of-new-medium/","items":[]},{"title":"The need to modernise socioeconomic infrastructure","url":"/old-work-archives/2018-webizen-net-au/about/the-modernisation-of-socioeconomics/","items":[]},{"title":"The Vision","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/","items":[{"title":"Domesticating Pervasive Surveillance","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/a-technical-vision/","items":[]}]}]},{"title":"An Overview","url":"/old-work-archives/2018-webizen-net-au/the-human-centric-infosphere/","items":[]},{"title":"Embed Link","url":"/old-work-archives/2018-webizen-net-au/embed-link/","items":[]},{"title":"Posts","url":"/old-work-archives/2018-webizen-net-au/posts/","items":[]},{"title":"Privacy Policy","url":"/old-work-archives/2018-webizen-net-au/privacy-policy/","items":[]},{"title":"Resource Library","url":"/old-work-archives/2018-webizen-net-au/resource-library/","items":[{"title":"Handong1587","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/","items":[{"title":"_Posts","url":"","items":[{"title":"Computer_science","url":"","items":[{"title":"Algorithm and Data Structure Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-algo-resourses/","items":[]},{"title":"Artificial Intelligence Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-ai-resources/","items":[]},{"title":"Big Data Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-09-22-big-data-resources/","items":[]},{"title":"Computer Science Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-cs-resources/","items":[]},{"title":"Data Mining Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-data-mining-resources/","items":[]},{"title":"Data Science Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-data-science-resources/","items":[]},{"title":"Database Systems Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-database-resources/","items":[]},{"title":"Discrete Optimization Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-discrete-optimization/","items":[]},{"title":"Distribued System Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-12-12-ditributed-system-resources/","items":[]},{"title":"Funny Stuffs Of Computer Science","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-11-18-funny-stuffs-of-cs/","items":[]},{"title":"Robotics","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-09-26-robotics-resources/","items":[]},{"title":"Writting CS Papers","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-11-30-writing-papers/","items":[]}]},{"title":"Computer_vision","url":"","items":[{"title":"Computer Vision Datasets","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-24-datasets/","items":[]},{"title":"Computer Vision Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-12-cv-resources/","items":[]},{"title":"Features","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-10-09-features/","items":[]},{"title":"Recognition, Detection, Segmentation and Tracking","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-10-09-recognition-detection-segmentation-tracking/","items":[]},{"title":"Use FFmpeg to Capture I Frames of Video","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2016-03-03-ffmpeg-i-frame/","items":[]},{"title":"Working on OpenCV","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-12-25-working-on-opencv/","items":[]}]},{"title":"Deep_learning","url":"","items":[{"title":"3D","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2021-07-28-3d/","items":[]},{"title":"Acceleration and Model Compression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-cnn-compression-acceleration/","items":[]},{"title":"Acceleration and Model Compression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-knowledge-distillation/","items":[]},{"title":"Adversarial Attacks and Defences","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-adversarial-attacks-and-defences/","items":[]},{"title":"Audio / Image / Video Generation","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-audio-image-video-generation/","items":[]},{"title":"BEV","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2022-06-27-bev/","items":[]},{"title":"Classification / Recognition","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recognition/","items":[]},{"title":"Deep Learning and Autonomous Driving","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-autonomous-driving/","items":[]},{"title":"Deep Learning Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-pose-estimation/","items":[]},{"title":"Deep Learning Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-applications/","items":[]},{"title":"Deep learning Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-courses/","items":[]},{"title":"Deep Learning Frameworks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-frameworks/","items":[]},{"title":"Deep Learning Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-resources/","items":[]},{"title":"Deep Learning Software and Hardware","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-software-hardware/","items":[]},{"title":"Deep Learning Tricks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tricks/","items":[]},{"title":"Deep Learning Tutorials","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tutorials/","items":[]},{"title":"Deep Learning with Machine Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-with-ml/","items":[]},{"title":"Face Recognition","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-face-recognition/","items":[]},{"title":"Fun With Deep Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-fun-with-deep-learning/","items":[]},{"title":"Generative Adversarial Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gan/","items":[]},{"title":"Graph Convolutional Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gcn/","items":[]},{"title":"Image / Video Captioning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-captioning/","items":[]},{"title":"Image Retrieval","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-retrieval/","items":[]},{"title":"Keep Up With New Trends","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2018-09-03-keep-up-with-new-trends/","items":[]},{"title":"LiDAR 3D Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-lidar-3d-detection/","items":[]},{"title":"Natural Language Processing","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nlp/","items":[]},{"title":"Neural Architecture Search","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nas/","items":[]},{"title":"Object Counting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-counting/","items":[]},{"title":"Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-detection/","items":[]},{"title":"OCR","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-ocr/","items":[]},{"title":"Optical Flow","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-optical-flow/","items":[]},{"title":"Re-ID","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-re-id/","items":[]},{"title":"Recommendation System","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recommendation-system/","items":[]},{"title":"Reinforcement Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rl/","items":[]},{"title":"RNN and LSTM","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rnn-and-lstm/","items":[]},{"title":"Segmentation","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-segmentation/","items":[]},{"title":"Style Transfer","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-style-transfer/","items":[]},{"title":"Super-Resolution","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-super-resolution/","items":[]},{"title":"Tracking","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-tracking/","items":[]},{"title":"Training Deep Neural Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-training-dnn/","items":[]},{"title":"Transfer Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-transfer-learning/","items":[]},{"title":"Unsupervised Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-unsupervised-learning/","items":[]},{"title":"Video Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-video-applications/","items":[]},{"title":"Visual Question Answering","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-vqa/","items":[]},{"title":"Visualizing and Interpreting Convolutional Neural Network","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-visulizing-interpreting-cnn/","items":[]}]},{"title":"Leisure","url":"","items":[{"title":"All About Enya","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-all-about-enya/","items":[]},{"title":"Coldplay","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-coldplay/","items":[]},{"title":"Coldplay","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-nightwish/","items":[]},{"title":"Games","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-13-games/","items":[]},{"title":"Green Day","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-greenday/","items":[]},{"title":"Muse! Muse!","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-muse-muse/","items":[]},{"title":"Oasis","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-oasis/","items":[]},{"title":"Paintings By J.M.","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2016-03-08-paintings-by-jm/","items":[]},{"title":"Papers, Blogs and Websites","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-09-27-papers-blogs-and-websites/","items":[]},{"title":"Welcome To The Black Parade","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-welcome-to-the-black-parade/","items":[]}]},{"title":"Machine_learning","url":"","items":[{"title":"Bayesian Methods","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-bayesian-methods/","items":[]},{"title":"Clustering Algorithms Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-clustering/","items":[]},{"title":"Competitions","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-competitions/","items":[]},{"title":"Dimensionality Reduction Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-dimensionality-reduction/","items":[]},{"title":"Fun With Machine Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-fun-with-ml/","items":[]},{"title":"Graphical Models Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-graphical-models/","items":[]},{"title":"Machine Learning Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-ml-courses/","items":[]},{"title":"Machine Learning Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-ml-resources/","items":[]},{"title":"Natural Language Processing","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-nlp/","items":[]},{"title":"Neural Network","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-neural-network/","items":[]},{"title":"Random Field","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-random-field/","items":[]},{"title":"Random Forests","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-random-forests/","items":[]},{"title":"Regression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-regression/","items":[]},{"title":"Support Vector Machine","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-svm/","items":[]},{"title":"Topic Model","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-topic-model/","items":[]}]},{"title":"Mathematics","url":"","items":[{"title":"Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/mathematics/2016-02-24-resources/","items":[]}]},{"title":"Programming_study","url":"","items":[{"title":"Add Lunr Search Plugin For Blog","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-31-add-lunr-search-plugin-for-blog/","items":[]},{"title":"Android Development Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-05-23-android-resources/","items":[]},{"title":"C++ Programming Solutions","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-09-07-cpp-programming-solutions/","items":[]},{"title":"Commands To Suppress Some Building Errors With Visual Studio","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-24-cmds-to-suppress-some-vs-building-Errors/","items":[]},{"title":"Embedding Python In C/C++","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-10-embedding-python-in-cpp/","items":[]},{"title":"Enable Large Addresses On VS2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-12-14-enable-large-addresses/","items":[]},{"title":"Fix min/max Error In VS2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-02-17-min-max-error-in-vs2015/","items":[]},{"title":"Gflags Build Problems on Windows X86 and Visual Studio 2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-23-gflags-build-problems-winx86-vs2015/","items":[]},{"title":"Glog Build Problems on Windows X86 and Visual Studio 2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-23-glog-build-problems-winx86/","items":[]},{"title":"Horrible Wired Errors Come From Simple Stupid Mistake","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-16-horrible-wired-errors-come-from-simple-stupid-mistake/","items":[]},{"title":"Install Jekyll To Fix Some Local Github-pages Defects","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-11-21-install-jekyll/","items":[]},{"title":"Install Therubyracer Failure","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-03-install-therubyracer/","items":[]},{"title":"Notes On Valgrind and Others","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-05-30-notes-on-valgrind/","items":[]},{"title":"PHP Hello World","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-04-php-hello-world/","items":[]},{"title":"Programming Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-07-01-programming-resources/","items":[]},{"title":"PyInstsaller and Others","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-12-24-pyinstaller-and-others/","items":[]},{"title":"Web Development Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-06-21-web-dev-resources/","items":[]},{"title":"Working on Visual Studio","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-04-03-working-on-vs/","items":[]}]},{"title":"Reading_and_thoughts","url":"","items":[{"title":"Book Reading List","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2015-12-04-book-reading-list/","items":[]},{"title":"Funny Papers","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2015-12-04-funny-papers/","items":[]},{"title":"Reading Materials","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2016-01-18-reading-materials/","items":[]}]},{"title":"Study","url":"","items":[{"title":"Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2017-11-28-courses/","items":[]},{"title":"Essay Writting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2016-01-11-essay-writting/","items":[]},{"title":"Job Hunting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2016-06-02-job-hunting/","items":[]},{"title":"Study Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2018-04-18-resources/","items":[]}]},{"title":"Working_on_linux","url":"","items":[{"title":"Create Multiple Forks of a GitHub Repo","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-12-18-create-multi-forks/","items":[]},{"title":"Linux Git Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-08-02-linux-git/","items":[]},{"title":"Linux Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-07-24-linux-resources/","items":[]},{"title":"Linux SVN Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-08-03-linux-svn/","items":[]},{"title":"Setup vsftpd on Ubuntu 14.10","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2016-07-27-setup-vsftpd/","items":[]},{"title":"Useful Linux Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-07-25-useful-linux-commands/","items":[]},{"title":"vsftpd Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2016-07-28-vsftpd-cmd/","items":[]}]},{"title":"Working_on_mac","url":"","items":[{"title":"Mac Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_mac/2015-07-25-mac-resources/","items":[]}]},{"title":"Working_on_windows","url":"","items":[{"title":"FFmpeg Collection of Utility Methods","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2016-06-05-ffmpeg-utilities/","items":[]},{"title":"Windows Commands and Utilities","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2015-10-27-windows-cmds-utils/","items":[]},{"title":"Windows Dev Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2015-10-27-resources/","items":[]}]}]},{"title":"Drafts","url":"","items":[{"title":"2016-12-30-Setup-Opengrok","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-12-30-setup-opengrok/","items":[]},{"title":"2017-01-20-Packing-C++-Project-to-Single-Executable","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2017-01-20-packing-c++-project-to-single-executable/","items":[]},{"title":"Notes On Caffe Development","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-10-notes-on-caffe-dev/","items":[]},{"title":"Notes On Deep Learning Training","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-12-notes-on-dl-training/","items":[]},{"title":"Notes On Discrete Optimization","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-13-notes-on-discrete-optimization/","items":[]},{"title":"Notes On Gecode","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-13-notes-on-gecode/","items":[]},{"title":"Notes On Inside-Outside Net","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-28-notes-on-ion/","items":[]},{"title":"Notes On K-Means","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-06-notes-on-kmeans/","items":[]},{"title":"Notes On L-BFGS","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-07-notes-on-l-bfgs/","items":[]},{"title":"Notes On Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-04-notes-on-object-detection/","items":[]},{"title":"Notes On Perceptrons","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-10-07-notes-on-perceptrons/","items":[]},{"title":"Notes On Quantized Convolutional Neural Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-07-notes-on-quantized-cnn/","items":[]},{"title":"Notes On Stanford CS2321n","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-02-21-notes-on-cs231n/","items":[]},{"title":"Notes on Suffix Array and Manacher Algorithm","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-08-27-notes-on-suffix-array-and-manacher-algorithm/","items":[]},{"title":"Notes On Tensorflow Development","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2017-04-13-notes-on-tensorflow-dev/","items":[]},{"title":"Notes On YOLO","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-14-notes-on-yolo/","items":[]},{"title":"PASCAL VOC (20) / COCO (80) / ImageNet (200) Detection Categories","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-12-23-imagenet-det-cat/","items":[]},{"title":"Softmax Vs Logistic Vs Sigmoid","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-10-softmax-logistic-sigmoid/","items":[]},{"title":"Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognititon","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-08-31-model-ensemble-of-deteciton/","items":[]}]}]}]}]}]},{"title":"Webizen 2.0","url":"","items":[{"title":"AI Capabilities","url":"","items":[{"title":"AI Capabilities Objectives","url":"/Webizen 2.0/AI Capabilities/AI Capabilities Objectives/","items":[]},{"title":"Audio & Video Analysis","url":"/Webizen 2.0/AI Capabilities/Audio & Video Analysis/","items":[]},{"title":"Image Analysis","url":"/Webizen 2.0/AI Capabilities/Image Analysis/","items":[]},{"title":"Text Analysis","url":"/Webizen 2.0/AI Capabilities/Text Analysis/","items":[]}]},{"title":"LOD-a-lot","url":"/Webizen 2.0/AI Related Links & Notes/","items":[]},{"title":"Mobile Apps","url":"","items":[{"title":"Android","url":"/Webizen 2.0/Mobile Apps/Android/","items":[]},{"title":"General Mobile Architecture","url":"/Webizen 2.0/Mobile Apps/General Mobile Architecture/","items":[]},{"title":"iOS","url":"/Webizen 2.0/Mobile Apps/iOS/","items":[]}]},{"title":"Web Of Things (IoT)","url":"","items":[{"title":"Web Of Things (IoT)","url":"/Webizen 2.0/Web Of Things (IoT)/Web Of Things (IoT)/","items":[]}]},{"title":"Webizen 2.0","url":"/Webizen 2.0/Webizen 2.0/","items":[]},{"title":"Webizen AI OS Platform","url":"/Webizen 2.0/Webizen AI OS Platform/","items":[]},{"title":"Webizen Pro Summary","url":"/Webizen 2.0/Webizen Pro Summary/","items":[]}]},{"title":"Webizen V1 Project Documentation","url":"/","items":[]}]}],"tagsGroups":[],"latestPosts":[{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/ld-solutions-to-fakenews/","title":"Solutions to FakeNews: Linked-Data, Ontologies and Verifiable Claims","lastUpdatedAt":"2022-12-28T19:34:43.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations/","title":"Fake News: Considerations → Principles → The Institution of Socio &#8211; Economic Values","lastUpdatedAt":"2022-12-28T19:29:53.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/","title":"Handong1587","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-08-27-notes-on-suffix-array-and-manacher-algorithm/","title":"Notes on Suffix Array and Manacher Algorithm","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-10-07-notes-on-perceptrons/","title":"Notes On Perceptrons","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-04-notes-on-object-detection/","title":"Notes On Object Detection","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-10-notes-on-caffe-dev/","title":"Notes On Caffe Development","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-07-notes-on-l-bfgs/","title":"Notes On L-BFGS","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-10-softmax-logistic-sigmoid/","title":"Softmax Vs Logistic Vs Sigmoid","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-12-notes-on-dl-training/","title":"Notes On Deep Learning Training","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}