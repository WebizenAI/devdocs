{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-detection/",
    "result": {"data":{"mdx":{"id":"e71d7678-79db-5620-88c3-3b0ea37e4677","tableOfContents":{"items":[{"url":"#papers","title":"Papers","items":[{"url":"#densebox","title":"DenseBox"},{"url":"#ohem","title":"OHEM"},{"url":"#r-fcn","title":"R-FCN"},{"url":"#feature-pyramid-network-fpn","title":"Feature Pyramid Network (FPN)"}]},{"url":"#two-stage-object-detection","title":"Two-Stage Object Detection","items":[{"url":"#r-cnn","title":"R-CNN"},{"url":"#fast-r-cnn","title":"Fast R-CNN"},{"url":"#faster-r-cnn","title":"Faster R-CNN"}]},{"url":"#single-shot-object-detection","title":"Single-Shot Object Detection","items":[{"url":"#yolo","title":"YOLO"},{"url":"#yolov2","title":"YOLOv2"},{"url":"#yolov3","title":"YOLOv3"},{"url":"#yolov4","title":"YOLOv4"},{"url":"#yolov7","title":"YOLOv7"},{"url":"#ssd","title":"SSD"},{"url":"#retinanet","title":"RetinaNet"}]},{"url":"#anchor-free","title":"Anchor-free"},{"url":"#transformers","title":"Transformers"},{"url":"#non-maximum-suppression-nms","title":"Non-Maximum Suppression (NMS)"},{"url":"#nms-free","title":"NMS-free"},{"url":"#adversarial-examples","title":"Adversarial Examples"},{"url":"#knowledge-distillation","title":"Knowledge Distillation"},{"url":"#rotated-object-detection","title":"Rotated Object Detection"},{"url":"#long-tailed-object-detection","title":"Long-Tailed Object Detection"},{"url":"#weakly-supervised-object-detection","title":"Weakly Supervised Object Detection"},{"url":"#video-object-detection","title":"Video Object Detection"},{"url":"#object-detection-on-mobile-devices","title":"Object Detection on Mobile Devices"},{"url":"#object-detection-on-rgb-d","title":"Object Detection on RGB-D"},{"url":"#zero-shot-object-detection","title":"Zero-Shot Object Detection"},{"url":"#visual-relationship-detection","title":"Visual Relationship Detection"},{"url":"#face-detection","title":"Face Detection","items":[{"url":"#mtcnn","title":"MTCNN"},{"url":"#detect-small-faces","title":"Detect Small Faces"}]},{"url":"#person-head-detection","title":"Person Head Detection"},{"url":"#pedestrian-detection--people-detection","title":"Pedestrian Detection / People Detection","items":[{"url":"#pedestrian-detection-in-a-crowd","title":"Pedestrian Detection in a Crowd"}]},{"url":"#occluded-pedestrian-detection","title":"Occluded Pedestrian Detection","items":[{"url":"#multispectral-pedestrian-detection","title":"Multispectral Pedestrian Detection"}]},{"url":"#vehicle-detection","title":"Vehicle Detection"},{"url":"#traffic-sign-detection","title":"Traffic-Sign Detection"},{"url":"#skeleton-detection","title":"Skeleton Detection"},{"url":"#fruit-detection","title":"Fruit Detection","items":[{"url":"#shadow-detection","title":"Shadow Detection"}]},{"url":"#others-detection","title":"Others Detection"},{"url":"#object-proposal","title":"Object Proposal"},{"url":"#localization","title":"Localization"},{"url":"#tutorials--talks","title":"Tutorials / Talks"},{"url":"#projects","title":"Projects"},{"url":"#leaderboard","title":"Leaderboard"},{"url":"#tools","title":"Tools"},{"url":"#blogs","title":"Blogs"}]},"fields":{"title":"Object Detection","slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-detection/","url":"https://devdocs.webizen.org/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-detection/","editUrl":"https://github.com/webizenai/devdocs/tree/main/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-detection.md","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022","gitCreatedAt":"2022-12-28T19:22:29.000Z","shouldShowTitle":true},"frontmatter":{"title":"Object Detection","description":null,"imageAlt":null,"tags":[],"date":"2015-10-09T00:00:00.000Z","dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"layout\": \"post\",\n  \"category\": \"deep_learning\",\n  \"title\": \"Object Detection\",\n  \"date\": \"2015-10-09T00:00:00.000Z\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"table\", null, mdx(\"thead\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"thead\"\n  }, mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Method\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"backbone\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"test size\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"VOC2007\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"VOC2010\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"VOC2012\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"ILSVRC 2013\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"MSCOCO 2015\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Speed\"))), mdx(\"tbody\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"OverFeat\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"24.3%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"R-CNN\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"AlexNet\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"58.5%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"53.7%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"53.3%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"31.4%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"R-CNN\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"VGG16\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"66.0%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"SPP_net\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"ZF-5\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"54.2%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"31.84%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"DeepID-Net\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"64.1%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"50.3%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"NoC\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"73.3%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"68.8%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Fast-RCNN\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"VGG16\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"70.0%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"68.8%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"68.4%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"19.7%(@\", \"[0.5-0.95]\", \"), 35.9%(@0.5)\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"MR-CNN\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"78.2%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"73.9%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Faster-RCNN\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"VGG16\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"78.8%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"75.9%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"21.9%(@\", \"[0.5-0.95]\", \"), 42.7%(@0.5)\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"198ms\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Faster-RCNN\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"ResNet101\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"85.6%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"83.8%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"37.4%(@\", \"[0.5-0.95]\", \"), 59.0%(@0.5)\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"YOLO\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"63.4%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"57.9%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"45 fps\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"YOLO VGG-16\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"66.4%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"21 fps\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"YOLOv2\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"448x448\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"78.6%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"73.4%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"21.6%(@\", \"[0.5-0.95]\", \"), 44.0%(@0.5)\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"40 fps\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"SSD\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"VGG16\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"300x300\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"77.2%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"75.8%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"25.1%(@\", \"[0.5-0.95]\", \"), 43.1%(@0.5)\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"46 fps\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"SSD\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"VGG16\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"512x512\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"79.8%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"78.5%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"28.8%(@\", \"[0.5-0.95]\", \"), 48.5%(@0.5)\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"19 fps\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"SSD\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"ResNet101\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"300x300\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"28.0%(@\", \"[0.5-0.95]\", \")\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"16 fps\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"SSD\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"ResNet101\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"512x512\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"31.2%(@\", \"[0.5-0.95]\", \")\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"8 fps\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"DSSD\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"ResNet101\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"300x300\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"28.0%(@\", \"[0.5-0.95]\", \")\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"8 fps\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"DSSD\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"ResNet101\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"500x500\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"33.2%(@\", \"[0.5-0.95]\", \")\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"6 fps\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"ION\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"79.2%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"76.4%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"CRAFT\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"75.7%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"71.3%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"48.5%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"OHEM\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"78.9%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"76.3%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"25.5%(@\", \"[0.5-0.95]\", \"), 45.9%(@0.5)\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"R-FCN\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"ResNet50\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"77.4%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.12sec(K40), 0.09sec(TitianX)\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"R-FCN\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"ResNet101\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"79.5%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.17sec(K40), 0.12sec(TitianX)\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"R-FCN(ms train)\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"ResNet101\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"83.6%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"82.0%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"31.5%(@\", \"[0.5-0.95]\", \"), 53.2%(@0.5)\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"PVANet 9.0\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"84.9%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"84.2%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"750ms(CPU), 46ms(TitianX)\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"RetinaNet\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"ResNet101-FPN\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  })), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Light-Head R-CNN\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Xception\", \"*\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"800/1200\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"31.5%@\", \"[0.5:0.95]\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"95 fps\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Light-Head R-CNN\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Xception\", \"*\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"700/1100\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"30.7%@\", \"[0.5:0.95]\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"102 fps\")))), mdx(\"h1\", {\n    \"id\": \"papers\"\n  }, \"Papers\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Neural Networks for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://papers.nips.cc/paper/5207-deep-neural-networks-for-object-detection.pdf\"\n  }, \"http://papers.nips.cc/paper/5207-deep-neural-networks-for-object-detection.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1312.6229\"\n  }, \"http://arxiv.org/abs/1312.6229\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/sermanet/OverFeat\"\n  }, \"https://github.com/sermanet/OverFeat\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cilvr.nyu.edu/doku.php?id=software:overfeat:start\"\n  }, \"http://cilvr.nyu.edu/doku.php?id=software:overfeat:start\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scalable Object Detection using Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: first MultiBox. Train a CNN to predict Region of Interest.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1312.2249\"\n  }, \"http://arxiv.org/abs/1312.2249\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/google/multibox\"\n  }, \"https://github.com/google/multibox\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://research.googleblog.com/2014/12/high-quality-object-detection-at-scale.html\"\n  }, \"https://research.googleblog.com/2014/12/high-quality-object-detection-at-scale.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scalable, High-Quality Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: second MultiBox\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1412.1441\"\n  }, \"http://arxiv.org/abs/1412.1441\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/google/multibox\"\n  }, \"https://github.com/google/multibox\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2014 / TPAMI 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: SPP-Net\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1406.4729\"\n  }, \"http://arxiv.org/abs/1406.4729\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ShaoqingRen/SPP_net\"\n  }, \"https://github.com/ShaoqingRen/SPP_net\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://zhangliliang.com/2014/09/13/paper-note-sppnet/\"\n  }, \"http://zhangliliang.com/2014/09/13/paper-note-sppnet/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepID-Net: Deformable Deep Convolutional Neural Networks for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: PAMI 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: an extension of R-CNN. box pre-training, cascade on region proposals, deformation layers and context representations\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.ee.cuhk.edu.hk/%CB%9Cwlouyang/projects/imagenetDeepId/index.html\"\n  }, \"http://www.ee.cuhk.edu.hk/%CB%9Cwlouyang/projects/imagenetDeepId/index.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1412.5661\"\n  }, \"http://arxiv.org/abs/1412.5661\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Detectors Emerge in Deep Scene CNNs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1412.6856\"\n  }, \"http://arxiv.org/abs/1412.6856\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.robots.ox.ac.uk/~vgg/rg/papers/zhou_iclr15.pdf\"\n  }, \"https://www.robots.ox.ac.uk/~vgg/rg/papers/zhou_iclr15.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://people.csail.mit.edu/khosla/papers/iclr2015_zhou.pdf\"\n  }, \"https://people.csail.mit.edu/khosla/papers/iclr2015_zhou.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://places.csail.mit.edu/slide_iclr2015.pdf\"\n  }, \"http://places.csail.mit.edu/slide_iclr2015.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"segDeepM: Exploiting Segmentation and Context in Deep Neural Networks for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project(code+data): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.cs.toronto.edu/~yukun/segdeepm.html\"\n  }, \"https://www.cs.toronto.edu/~yukun/segdeepm.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1502.04275\"\n  }, \"https://arxiv.org/abs/1502.04275\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/YknZhu/segDeepM\"\n  }, \"https://github.com/YknZhu/segDeepM\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Detection Networks on Convolutional Feature Maps\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: TPAMI 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: NoC\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1504.06066\"\n  }, \"http://arxiv.org/abs/1504.06066\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improving Object Detection with Deep Convolutional Networks via Bayesian Optimization and Structured Prediction\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1504.03293\"\n  }, \"http://arxiv.org/abs/1504.03293\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.ytzhang.net/files/publications/2015-cvpr-det-slides.pdf\"\n  }, \"http://www.ytzhang.net/files/publications/2015-cvpr-det-slides.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/YutingZhang/fgs-obj\"\n  }, \"https://github.com/YutingZhang/fgs-obj\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepBox: Learning Objectness with Convolutional Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: DeepBox\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1505.02146\"\n  }, \"http://arxiv.org/abs/1505.02146\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/weichengkuo/DeepBox\"\n  }, \"https://github.com/weichengkuo/DeepBox\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object detection via a multi-region & semantic segmentation-aware CNN model\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: MR-CNN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1505.01749\"\n  }, \"http://arxiv.org/abs/1505.01749\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/gidariss/mrcnn-object-detection\"\n  }, \"https://github.com/gidariss/mrcnn-object-detection\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://zhangliliang.com/2015/05/17/paper-note-ms-cnn/\"\n  }, \"http://zhangliliang.com/2015/05/17/paper-note-ms-cnn/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://blog.cvmarcher.com/posts/2015/05/17/multi-region-semantic-segmentation-aware-cnn/\"\n  }, \"http://blog.cvmarcher.com/posts/2015/05/17/multi-region-semantic-segmentation-aware-cnn/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AttentionNet: Aggregating Weak Directions for Accurate Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: state-of-the-art performance of 65% (AP) on PASCAL VOC 2007/2012 human detection task\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1506.07704\"\n  }, \"http://arxiv.org/abs/1506.07704\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.robots.ox.ac.uk/~vgg/rg/slides/AttentionNet.pdf\"\n  }, \"https://www.robots.ox.ac.uk/~vgg/rg/slides/AttentionNet.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://image-net.org/challenges/talks/lunit-kaist-slide.pdf\"\n  }, \"http://image-net.org/challenges/talks/lunit-kaist-slide.pdf\"))), mdx(\"h2\", {\n    \"id\": \"densebox\"\n  }, \"DenseBox\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DenseBox: Unifying Landmark Localization with End to End Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1509.04874\"\n  }, \"http://arxiv.org/abs/1509.04874\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://pan.baidu.com/s/1mgoWWsS\"\n  }, \"http://pan.baidu.com/s/1mgoWWsS\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"KITTI result: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cvlibs.net/datasets/kitti/eval_object.php\"\n  }, \"http://www.cvlibs.net/datasets/kitti/eval_object.php\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Inside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: \\\"0.8s per image on a Titan X GPU (excluding proposal generation) without two-stage bounding-box regression\\nand 1.15s per image with it\\\".\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Inside-Outside Net (ION)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1512.04143\"\n  }, \"http://arxiv.org/abs/1512.04143\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.seanbell.ca/tmp/ion-coco-talk-bell2015.pdf\"\n  }, \"http://www.seanbell.ca/tmp/ion-coco-talk-bell2015.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"coco-leaderboard: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mscoco.org/dataset/#detections-leaderboard\"\n  }, \"http://mscoco.org/dataset/#detections-leaderboard\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Adaptive Object Detection Using Adjacency and Zoom Prediction\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016. AZ-Net\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1512.07711\"\n  }, \"http://arxiv.org/abs/1512.07711\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/luyongxi/az-net\"\n  }, \"https://github.com/luyongxi/az-net\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"youtube: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=YmFtuNwxaNM\"\n  }, \"https://www.youtube.com/watch?v=YmFtuNwxaNM\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"G-CNN: an Iterative Grid Based Object Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1512.07729\"\n  }, \"http://arxiv.org/abs/1512.07729\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"We don't need no bounding-boxes: Training object class detectors using only human verification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1602.08405\"\n  }, \"http://arxiv.org/abs/1602.08405\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"HyperNet: Towards Accurate Region Proposal Generation and Joint Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1604.00600\"\n  }, \"http://arxiv.org/abs/1604.00600\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A MultiPath Network for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2016. Facebook AI Research (FAIR)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1604.02135\"\n  }, \"http://arxiv.org/abs/1604.02135\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/facebookresearch/multipathnet\"\n  }, \"https://github.com/facebookresearch/multipathnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CRAFT Objects from Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016. Cascade Region-proposal-network And FasT-rcnn. an extension of Faster R-CNN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://byangderek.github.io/projects/craft.html\"\n  }, \"http://byangderek.github.io/projects/craft.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1604.03239\"\n  }, \"https://arxiv.org/abs/1604.03239\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Yang_CRAFT_Objects_From_CVPR_2016_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Yang_CRAFT_Objects_From_CVPR_2016_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/byangderek/CRAFT\"\n  }, \"https://github.com/byangderek/CRAFT\"))), mdx(\"h2\", {\n    \"id\": \"ohem\"\n  }, \"OHEM\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Training Region-based Object Detectors with Online Hard Example Mining\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016 Oral. Online hard example mining (OHEM)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1604.03540\"\n  }, \"http://arxiv.org/abs/1604.03540\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Shrivastava_Training_Region-Based_Object_CVPR_2016_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Shrivastava_Training_Region-Based_Object_CVPR_2016_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/abhi2610/ohem\"\n  }, \"https://github.com/abhi2610/ohem\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"author page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://abhinav-shrivastava.info/\"\n  }, \"http://abhinav-shrivastava.info/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"S-OHEM: Stratified Online Hard Example Mining for Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1705.02233\"\n  }, \"https://arxiv.org/abs/1705.02233\")), mdx(\"hr\", null), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Exploit All the Layers: Fast and Accurate CNN Object Detector with Scale Dependent Pooling and Cascaded Rejection Classifiers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: scale-dependent pooling  (SDP), cascaded rejection classifiers (CRC)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www-personal.umich.edu/~wgchoi/SDP-CRC_camready.pdf\"\n  }, \"http://www-personal.umich.edu/~wgchoi/SDP-CRC_camready.pdf\"))), mdx(\"h2\", {\n    \"id\": \"r-fcn\"\n  }, \"R-FCN\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"R-FCN: Object Detection via Region-based Fully Convolutional Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.06409\"\n  }, \"http://arxiv.org/abs/1605.06409\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/daijifeng001/R-FCN\"\n  }, \"https://github.com/daijifeng001/R-FCN\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(MXNet): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/msracver/Deformable-ConvNets/tree/master/rfcn\"\n  }, \"https://github.com/msracver/Deformable-ConvNets/tree/master/rfcn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Orpine/py-R-FCN\"\n  }, \"https://github.com/Orpine/py-R-FCN\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/PureDiors/pytorch_RFCN\"\n  }, \"https://github.com/PureDiors/pytorch_RFCN\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bharatsingh430/py-R-FCN-multiGPU\"\n  }, \"https://github.com/bharatsingh430/py-R-FCN-multiGPU\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xdever/RFCN-tensorflow\"\n  }, \"https://github.com/xdever/RFCN-tensorflow\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"R-FCN-3000 at 30fps: Decoupling Detection and Classification\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.01802\"\n  }, \"https://arxiv.org/abs/1712.01802\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Recycle deep features for better object detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1607.05066\"\n  }, \"http://arxiv.org/abs/1607.05066\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Unified Multi-scale Deep Convolutional Neural Network for Fast Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: 640\\xD7480: 15 fps, 960\\xD7720: 8 fps\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: MS-CNN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1607.07155\"\n  }, \"http://arxiv.org/abs/1607.07155\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zhaoweicai/mscnn\"\n  }, \"https://github.com/zhaoweicai/mscnn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"poster: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.eccv2016.org/files/posters/P-2B-38.pdf\"\n  }, \"http://www.eccv2016.org/files/posters/P-2B-38.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-stage Object Detection with Group Recursive Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: VOC2007: 78.6%, VOC2012: 74.9%\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.05159\"\n  }, \"http://arxiv.org/abs/1608.05159\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Subcategory-aware Convolutional Neural Networks for Object Proposals and Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: WACV 2017. SubCNN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1604.04693\"\n  }, \"http://arxiv.org/abs/1604.04693\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tanshen/SubCNN\"\n  }, \"https://github.com/tanshen/SubCNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PVANet: Lightweight Deep Neural Networks for Real-time Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Presented at NIPS 2016 Workshop on Efficient Methods for Deep Neural Networks (EMDNN).\\nContinuation of \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1608.08021\"\n  }, \"arXiv:1608.08021\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.08588\"\n  }, \"https://arxiv.org/abs/1611.08588\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/sanghoon/pva-faster-rcnn\"\n  }, \"https://github.com/sanghoon/pva-faster-rcnn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"leaderboard(PVANet 9.0): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=4\"\n  }, \"http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=4\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Gated Bi-directional CNN for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The Chinese University of Hong Kong & Sensetime Group Limited\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: GBD-Net\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://link.springer.com/chapter/10.1007/978-3-319-46478-7_22\"\n  }, \"http://link.springer.com/chapter/10.1007/978-3-319-46478-7_22\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"mirror: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://pan.baidu.com/s/1dFohO7v\"\n  }, \"https://pan.baidu.com/s/1dFohO7v\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Crafting GBD-Net for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: winner of the ImageNet object detection challenge of 2016. CUImage and CUVideo\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: gated bi-directional CNN (GBD-Net)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.02579\"\n  }, \"https://arxiv.org/abs/1610.02579\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/craftGBD/craftGBD\"\n  }, \"https://github.com/craftGBD/craftGBD\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"StuffNet: Using 'Stuff' to Improve Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.05861\"\n  }, \"https://arxiv.org/abs/1610.05861\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generalized Haar Filter based Deep Networks for Real-Time Object Detection in Traffic Scene\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.09609\"\n  }, \"https://arxiv.org/abs/1610.09609\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hierarchical Object Detection with Deep Reinforcement Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Deep Reinforcement Learning Workshop (NIPS 2016)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://imatge-upc.github.io/detection-2016-nipsws/\"\n  }, \"https://imatge-upc.github.io/detection-2016-nipsws/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.03718\"\n  }, \"https://arxiv.org/abs/1611.03718\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.slideshare.net/xavigiro/hierarchical-object-detection-with-deep-reinforcement-learning\"\n  }, \"http://www.slideshare.net/xavigiro/hierarchical-object-detection-with-deep-reinforcement-learning\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/imatge-upc/detection-2016-nipsws\"\n  }, \"https://github.com/imatge-upc/detection-2016-nipsws\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://jorditorres.org/nips/\"\n  }, \"http://jorditorres.org/nips/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning to detect and localize many objects from few examples\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.05664\"\n  }, \"https://arxiv.org/abs/1611.05664\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Speed/accuracy trade-offs for modern convolutional object detectors\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017. Google Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.10012\"\n  }, \"https://arxiv.org/abs/1611.10012\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SqueezeDet: Unified, Small, Low Power Fully Convolutional Neural Networks for Real-Time Object Detection for Autonomous Driving\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.01051\"\n  }, \"https://arxiv.org/abs/1612.01051\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/BichenWuUCB/squeezeDet\"\n  }, \"https://github.com/BichenWuUCB/squeezeDet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/fregu856/2D_detection\"\n  }, \"https://github.com/fregu856/2D_detection\"))), mdx(\"h2\", {\n    \"id\": \"feature-pyramid-network-fpn\"\n  }, \"Feature Pyramid Network (FPN)\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Feature Pyramid Networks for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Facebook AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.03144\"\n  }, \"https://arxiv.org/abs/1612.03144\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dynamic Feature Pyramid Networks for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Zhejiang University & Noah\\u2019s Ark Lab & Westlake University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.00779\"\n  }, \"https://arxiv.org/abs/2012.00779\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Implicit Feature Pyramid Network for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MEGVII Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.13563\"\n  }, \"https://arxiv.org/abs/2012.13563\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"You Should Look at All Objects\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The University of Hong Kong & Bytedance & University of Rochester\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2207.07889\"\n  }, \"https://arxiv.org/abs/2207.07889\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/CharlesPikachu/YSLAO\"\n  }, \"https://github.com/CharlesPikachu/YSLAO\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Action-Driven Object Detection with Top-Down Visual Attentions\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.06704\"\n  }, \"https://arxiv.org/abs/1612.06704\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Beyond Skip Connections: Top-Down Modulation for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CMU & UC Berkeley & Google Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.06851\"\n  }, \"https://arxiv.org/abs/1612.06851\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Wide-Residual-Inception Networks for Real-time Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Inha University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.01243\"\n  }, \"https://arxiv.org/abs/1702.01243\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attentional Network for Visual Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Maryland & Mitsubishi Electric Research Laboratories\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.01478\"\n  }, \"https://arxiv.org/abs/1702.01478\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Chained Deep Features and Classifiers for Cascade in Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keykwords: CC-Net\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: chained cascade network (CC-Net). 81.1% mAP on PASCAL VOC 2007\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.07054\"\n  }, \"https://arxiv.org/abs/1702.07054\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeNet: Scalable Real-time Object Detection with Directed Sparse Sampling\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017 (poster)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.10295\"\n  }, \"https://arxiv.org/abs/1703.10295\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Discriminative Bimodal Networks for Visual Localization and Detection with Natural Language Queries\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.03944\"\n  }, \"https://arxiv.org/abs/1704.03944\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spatial Memory for Context Reasoning in Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.04224\"\n  }, \"https://arxiv.org/abs/1704.04224\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Occlusion Reasoning for Multi-Camera Multi-Target Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1704.05775\"\n  }, \"https://arxiv.org/abs/1704.05775\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"LCDet: Low-Complexity Fully-Convolutional Neural Networks for Object Detection in Embedded Systems\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Embedded Vision Workshop in CVPR. UC San Diego & Qualcomm Inc\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1705.05922\"\n  }, \"https://arxiv.org/abs/1705.05922\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Point Linking Network for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Point Linking Network (PLN)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.03646\"\n  }, \"https://arxiv.org/abs/1706.03646\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Perceptual Generative Adversarial Networks for Small Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1706.05274\"\n  }, \"https://arxiv.org/abs/1706.05274\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Few-shot Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1706.08249\"\n  }, \"https://arxiv.org/abs/1706.08249\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Yes-Net: An effective Detector Based on Global Information\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1706.09180\"\n  }, \"https://arxiv.org/abs/1706.09180\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards lightweight convolutional neural networks for object detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1707.01395\"\n  }, \"https://arxiv.org/abs/1707.01395\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RON: Reverse Connection with Objectness Prior Networks for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.01691\"\n  }, \"https://arxiv.org/abs/1707.01691\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/taokong/RON\"\n  }, \"https://github.com/taokong/RON\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deformable Part-based Fully Convolutional Network for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2017 (oral). Sorbonne Universit\\xE9s & CEDRIC\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.06175\"\n  }, \"https://arxiv.org/abs/1707.06175\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Adaptive Feeding: Achieving Fast and Accurate Detections by Adaptively Combining Object Detectors\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.06399\"\n  }, \"https://arxiv.org/abs/1707.06399\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Recurrent Scale Approximation for Object Detection in CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Recurrent Scale Approximation (RSA)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.09531\"\n  }, \"https://arxiv.org/abs/1707.09531\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/sciencefans/RSA-for-object-detection\"\n  }, \"https://github.com/sciencefans/RSA-for-object-detection\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DSOD: Learning Deeply Supervised Object Detectors from Scratch\")), mdx(\"img\", {\n    \"src\": \"https://user-images.githubusercontent.com/3794909/28934967-718c9302-78b5-11e7-89ee-8b514e53e23c.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017. Fudan University & Tsinghua University & Intel Labs China\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.01241\"\n  }, \"https://arxiv.org/abs/1708.01241\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/szq0214/DSOD\"\n  }, \"https://github.com/szq0214/DSOD\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Detection from Scratch with Deep Supervision\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1809.09294\"\n  }, \"https://arxiv.org/abs/1809.09294\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CoupleNet: Coupling Global Structure with Local Parts for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.02863\"\n  }, \"https://arxiv.org/abs/1708.02863\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Incremental Learning of Object Detectors without Catastrophic Forgetting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017. Inria\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.06977\"\n  }, \"https://arxiv.org/abs/1708.06977\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Zoom Out-and-In Network with Map Attention Decision for Region Proposal and Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.04347\"\n  }, \"https://arxiv.org/abs/1709.04347\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"StairNet: Top-Down Semantic Aggregation for Accurate One Shot Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.05788\"\n  }, \"https://arxiv.org/abs/1709.05788\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dynamic Zoom-in Network for Fast Object Detection in Large Images\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.05187\"\n  }, \"https://arxiv.org/abs/1711.05187\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Zero-Annotation Object Detection with Web Knowledge Transfer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NTU, Singapore & Amazon\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: multi-instance multi-label domain adaption learning framework\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.05954\"\n  }, \"https://arxiv.org/abs/1711.05954\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MegDet: A Large Mini-Batch Object Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Peking University & Tsinghua University & Megvii Inc\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.07240\"\n  }, \"https://arxiv.org/abs/1711.07240\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Receptive Field Block Net for Accurate and Fast Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: RFBNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.07767\"\n  }, \"https://arxiv.org/abs/1711.07767\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com//ruinmessi/RFBNet\"\n  }, \"https://github.com//ruinmessi/RFBNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An Analysis of Scale Invariance in Object Detection - SNIP\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.08189\"\n  }, \"https://arxiv.org/abs/1711.08189\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bharatsingh430/snip\"\n  }, \"https://github.com/bharatsingh430/snip\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Feature Selective Networks for Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.08879\"\n  }, \"https://arxiv.org/abs/1711.08879\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning a Rotation Invariant Detector with Rotatable Bounding Box\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.09405\"\n  }, \"https://arxiv.org/abs/1711.09405\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, Caffe): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/liulei01/DRBox\"\n  }, \"https://github.com/liulei01/DRBox\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scalable Object Detection for Stylized Objects\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Microsoft AI & Research Munich\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.09822\"\n  }, \"https://arxiv.org/abs/1711.09822\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Object Detectors from Scratch with Gated Recurrent Feature Pyramids\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.00886\"\n  }, \"https://arxiv.org/abs/1712.00886\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/szq0214/GRP-DSOD\"\n  }, \"https://github.com/szq0214/GRP-DSOD\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Regionlets for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: region selection network, gating network\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.02408\"\n  }, \"https://arxiv.org/abs/1712.02408\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Training and Testing Object Detectors with Virtual Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IEEE/CAA Journal of Automatica Sinica\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.08470\"\n  }, \"https://arxiv.org/abs/1712.08470\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Large-Scale Object Discovery and Detector Adaptation from Unlabeled Video\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: object mining, object tracking, unsupervised object discovery by appearance-based clustering, self-supervised detector adaptation\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.08832\"\n  }, \"https://arxiv.org/abs/1712.08832\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spot the Difference by Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tsinghua University & JD Group\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.01051\"\n  }, \"https://arxiv.org/abs/1801.01051\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Localization-Aware Active Learning for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.05124\"\n  }, \"https://arxiv.org/abs/1801.05124\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Detection with Mask-based Feature Encoding\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1802.03934\"\n  }, \"https://arxiv.org/abs/1802.03934\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"LSTD: A Low-Shot Transfer Detector for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.01529\"\n  }, \"https://arxiv.org/abs/1803.01529\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pseudo Mask Augmented Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.05858\"\n  }, \"https://arxiv.org/abs/1803.05858\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Revisiting RCNN: On Awakening the Classification Power of Faster RCNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: DCR V1\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.06799\"\n  }, \"https://arxiv.org/abs/1803.06799\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, MXNet): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bowenc0221/Decoupled-Classification-Refinement\"\n  }, \"https://github.com/bowenc0221/Decoupled-Classification-Refinement\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Decoupled Classification Refinement: Hard False Positive Suppression for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: DCR V2\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1810.04002\"\n  }, \"https://arxiv.org/abs/1810.04002\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, MXNet): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bowenc0221/Decoupled-Classification-Refinement\"\n  }, \"https://github.com/bowenc0221/Decoupled-Classification-Refinement\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Region Features for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Peking University & MSRA\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.07066\"\n  }, \"https://arxiv.org/abs/1803.07066\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Detection for Comics using Manga109 Annotations\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Tokyo & National Institute of Informatics, Japan\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.08670\"\n  }, \"https://arxiv.org/abs/1803.08670\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Task-Driven Super Resolution: Object Detection in Low-resolution Images\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.11316\"\n  }, \"https://arxiv.org/abs/1803.11316\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Transferring Common-Sense Knowledge for Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1804.01077\"\n  }, \"https://arxiv.org/abs/1804.01077\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-scale Location-aware Kernel Representation for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.00428\"\n  }, \"https://arxiv.org/abs/1804.00428\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Hwang64/MLKP\"\n  }, \"https://github.com/Hwang64/MLKP\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Loss Rank Mining: A General Hard Example Mining Method for Real-time Detectors\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: National University of Defense Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.04606\"\n  }, \"https://arxiv.org/abs/1804.04606\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DetNet: A Backbone network for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tsinghua University & Megvii Inc\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.06215\"\n  }, \"https://arxiv.org/abs/1804.06215\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AdvDetPatch: Attacking Object Detectors with Adversarial Patches\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1806.02299\"\n  }, \"https://arxiv.org/abs/1806.02299\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attacking Object Detectors via Imperceptible Patches on Background\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1809.05966\"\n  }, \"https://arxiv.org/abs/1809.05966\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Physical Adversarial Examples for Object Detectors\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: WOOT 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.07769\"\n  }, \"https://arxiv.org/abs/1807.07769\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object detection at 200 Frames Per Second\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: United Technologies Research Center-Ireland\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.06361\"\n  }, \"https://arxiv.org/abs/1805.06361\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Detection using Domain Randomization and Generative Adversarial Refinement of Synthetic Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018 Deep Vision Workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.11778\"\n  }, \"https://arxiv.org/abs/1805.11778\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SNIPER: Efficient Multi-Scale Training\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Maryland\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: SNIPER (Scale Normalization for Image Pyramid with Efficient Resampling)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.09300\"\n  }, \"https://arxiv.org/abs/1805.09300\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mahyarnajibi/SNIPER\"\n  }, \"https://github.com/mahyarnajibi/SNIPER\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Soft Sampling for Robust Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1806.06986\"\n  }, \"https://arxiv.org/abs/1806.06986\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MetaAnchor: Learning to Detect Objects with Customized Anchors\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Megvii Inc (Face++) & Fudan University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.00980\"\n  }, \"https://arxiv.org/abs/1807.00980\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Localization Recall Precision (LRP): A New Performance Metric for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018. Middle East Technical University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.01696\"\n  }, \"https://arxiv.org/abs/1807.01696\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/cancam/LRP\"\n  }, \"https://github.com/cancam/LRP\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pooling Pyramid Network for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google AI Perception\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.03284\"\n  }, \"https://arxiv.org/abs/1807.03284\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Modeling Visual Context is Key to Augmenting Object Detection Datasets\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.07428\"\n  }, \"https://arxiv.org/abs/1807.07428\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Acquisition of Localization Confidence for Accurate Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.11590\"\n  }, \"https://arxiv.org/abs/1807.11590\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gihtub: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/vacancy/PreciseRoIPooling\"\n  }, \"https://github.com/vacancy/PreciseRoIPooling\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CornerNet: Detecting Objects as Paired Keypoints\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: IoU-Net, PreciseRoIPooling\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.01244\"\n  }, \"https://arxiv.org/abs/1808.01244\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/umich-vl/CornerNet\"\n  }, \"https://github.com/umich-vl/CornerNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unsupervised Hard Example Mining from Videos for Improved Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.04285\"\n  }, \"https://arxiv.org/abs/1808.04285\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SAN: Learning Relationship between Convolutional Features for Multi-Scale Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1808.04974\"\n  }, \"https://arxiv.org/abs/1808.04974\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Survey of Modern Object Detection Literature using Deep Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1808.07256\"\n  }, \"https://arxiv.org/abs/1808.07256\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Tiny-DSOD: Lightweight Object Detection for Resource-Restricted Usages\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.11013\"\n  }, \"https://arxiv.org/abs/1807.11013\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lyxok1/Tiny-DSOD\"\n  }, \"https://github.com/lyxok1/Tiny-DSOD\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Feature Pyramid Reconfiguration for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.07993\"\n  }, \"https://arxiv.org/abs/1808.07993\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MDCN: Multi-Scale, Deep Inception Convolutional Neural Networks for Efficient Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1809.01791\"\n  }, \"https://arxiv.org/abs/1809.01791\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Recent Advances in Object Detection in the Age of Deep Convolutional Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1809.03193\"\n  }, \"https://arxiv.org/abs/1809.03193\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning for Generic Object Detection: A Survey\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1809.02165\"\n  }, \"https://arxiv.org/abs/1809.02165\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Training Confidence-Calibrated Classifier for Detecting Out-of-Distribution Samples\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/alinlab/Confident_classifier\"\n  }, \"https://github.com/alinlab/Confident_classifier\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast and accurate object detection in high resolution 4K and 8K video using GPUs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Best Paper Finalist at IEEE High Performance Extreme Computing Conference (HPEC) 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Carnegie Mellon University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1810.10551\"\n  }, \"https://arxiv.org/abs/1810.10551\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hybrid Knowledge Routed Modules for Large-scale Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1810.12681\"\n  }, \"https://arxiv.org/abs/1810.12681\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, PyTorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/chanyn/HKRM\"\n  }, \"https://github.com/chanyn/HKRM\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BAN: Focusing on Boundary Context for Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.05243\"\n  }, \"https://arxiv.org/abs/1811.05243\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"R2CNN++: Multi-Dimensional Attention Based Rotation Invariant Detector with Robust Anchor Strategy\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.07126\"\n  }, \"https://arxiv.org/abs/1811.07126\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/DetectionTeamUCAS/R2CNN-Plus-Plus_Tensorflow\"\n  }, \"https://github.com/DetectionTeamUCAS/R2CNN-Plus-Plus_Tensorflow\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeRPN: Taking a further step toward more general object detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: South China University of Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"ariv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.06700\"\n  }, \"https://arxiv.org/abs/1811.06700\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/HCIILAB/DeRPN\"\n  }, \"https://github.com/HCIILAB/DeRPN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast Efficient Object Detection Using Selective Attention\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.07502\"\n  }, \"https://arxiv.org/abs/1811.07502\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sampling Techniques for Large-Scale Object Detection from Sparsely Annotated Objects\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.10862\"\n  }, \"https://arxiv.org/abs/1811.10862\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Efficient Coarse-to-Fine Non-Local Module for the Detection of Small Objects\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.12152\"\n  }, \"https://arxiv.org/abs/1811.12152\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Regionlets: Blended Representation and Deep Learning for Generic Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.11318\"\n  }, \"https://arxiv.org/abs/1811.11318\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Transferable Adversarial Attacks for Image and Video Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.12641\"\n  }, \"https://arxiv.org/abs/1811.12641\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Anchor Box Optimization for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Illinois at Urbana-Champaign & Microsoft Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1812.00469\"\n  }, \"https://arxiv.org/abs/1812.00469\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AutoFocus: Efficient Multi-Scale Inference\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Maryland\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1812.01600\"\n  }, \"https://arxiv.org/abs/1812.01600\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Few-shot Object Detection via Feature Reweighting\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1812.01866\"\n  }, \"https://arxiv.org/abs/1812.01866\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Practical Adversarial Attack Against Object Detector\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1812.10217\"\n  }, \"https://arxiv.org/abs/1812.10217\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scale-Aware Trident Networks for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Chinese Academy of Sciences & TuSimple\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.01892\"\n  }, \"https://arxiv.org/abs/1901.01892\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/TuSimple/simpledet\"\n  }, \"https://github.com/TuSimple/simpledet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Region Proposal by Guided Anchoring\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CUHK - SenseTime Joint Lab & Amazon Rekognition & Nanyang Technological University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.03278\"\n  }, \"https://arxiv.org/abs/1901.03278\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bottom-up Object Detection by Grouping Extreme and Center Points\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: ExtremeNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.08043\"\n  }, \"https://arxiv.org/abs/1901.08043\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xingyizhou/ExtremeNet\"\n  }, \"https://github.com/xingyizhou/ExtremeNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bag of Freebies for Training Object Detection Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Amazon Web Services\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1902.04103\"\n  }, \"https://arxiv.org/abs/1902.04103\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Augmentation for small object detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1902.07296\"\n  }, \"https://arxiv.org/abs/1902.07296\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1902.09630\"\n  }, \"https://arxiv.org/abs/1902.09630\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SimpleDet: A Simple and Versatile Distributed Framework for Object Detection and Instance Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: TuSimple\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.05831\"\n  }, \"https://arxiv.org/abs/1903.05831\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tusimple/simpledet\"\n  }, \"https://github.com/tusimple/simpledet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BayesOD: A Bayesian Approach for Uncertainty Estimation in Deep Object Detectors\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Toronto\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.03838\"\n  }, \"https://arxiv.org/abs/1903.03838\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DetNAS: Neural Architecture Search on Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Chinese Academy of Sciences & Megvii Inc\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.10979\"\n  }, \"https://arxiv.org/abs/1903.10979\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ThunderNet: Towards Real-time Generic Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1903.11752\"\n  }, \"https://arxiv.org/abs/1903.11752\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Feature Intertwiner for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CUHK & SenseTime & The University of Sydney\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.11851\"\n  }, \"https://arxiv.org/abs/1903.11851\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improving Object Detection with Inverted Attention\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1903.12255\"\n  }, \"https://arxiv.org/abs/1903.12255\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"What Object Should I Use? - Task Driven Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.03000\"\n  }, \"https://arxiv.org/abs/1904.03000\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards Universal Object Detection by Domain Attention\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.04402\"\n  }, \"https://arxiv.org/abs/1904.04402\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Prime Sample Attention in Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1904.04821\"\n  }, \"https://arxiv.org/abs/1904.04821\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BAOD: Budget-Aware Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1904.05443\"\n  }, \"https://arxiv.org/abs/1904.05443\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An Analysis of Pre-Training on Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Maryland\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.05871\"\n  }, \"https://arxiv.org/abs/1904.05871\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DuBox: No-Prior Box Objection Detection via Residual Dual Scale Detectors\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Baidu Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.06883\"\n  }, \"https://arxiv.org/abs/1904.06883\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"NAS-FPN: Learning Scalable Feature Pyramid Architecture for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Brain\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.07392\"\n  }, \"https://arxiv.org/abs/1904.07392\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Objects as Points\")), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/xingyizhou/CenterNet/master/readme/fig2.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Object detection, 3D detection, and pose estimation using center point detection\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.07850\"\n  }, \"https://arxiv.org/abs/1904.07850\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xingyizhou/CenterNet\"\n  }, \"https://github.com/xingyizhou/CenterNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MultiTask-CenterNet (MCN): Efficient and Diverse Multitask Learning using an Anchor Free Approach\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ZF Friedrichshafen AG, Artificial Intelligence Lab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2108.05060\"\n  }, \"https://arxiv.org/abs/2108.05060\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CenterNet: Object Detection with Keypoint Triplets\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CenterNet: Keypoint Triplets for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.08189\"\n  }, \"https://arxiv.org/abs/1904.08189\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Duankaiwen/CenterNet\"\n  }, \"https://github.com/Duankaiwen/CenterNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CornerNet-Lite: Efficient Keypoint Based Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Princeton University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.08900\"\n  }, \"https://arxiv.org/abs/1904.08900\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/princeton-vl/CornerNet-Lite\"\n  }, \"https://github.com/princeton-vl/CornerNet-Lite\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CenterNet++ for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2204.08394\"\n  }, \"https://arxiv.org/abs/2204.08394\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github; \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Duankaiwen/PyCenterNet\"\n  }, \"https://github.com/Duankaiwen/PyCenterNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Automated Focal Loss for Image based Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1904.09048\"\n  }, \"https://arxiv.org/abs/1904.09048\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Exploring Object Relation in Mean Teacher for Cross-Domain Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.11245\"\n  }, \"https://arxiv.org/abs/1904.11245\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An Energy and GPU-Computation Efficient Backbone Network for Real-Time Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019 CEFRL Workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.09730\"\n  }, \"https://arxiv.org/abs/1904.09730\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RepPoints: Point Set Representation for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Peking University & Tsinghua University & Microsoft Research Asia\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.11490\"\n  }, \"https://arxiv.org/abs/1904.11490\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/microsoft/RepPoints\"\n  }, \"https://github.com/microsoft/RepPoints\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dense RepPoints: Representing Visual Objects with Dense Point Sets\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Peking University & CUHK & Zhejiang University & Shanghai Jiao Tong University & University of Toronto & MSRA\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1912.11473\"\n  }, \"https://arxiv.org/abs/1912.11473\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, mmdetection): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/justimyhxu/Dense-RepPoints\"\n  }, \"https://github.com/justimyhxu/Dense-RepPoints\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RepPoints V2: Verification Meets Regression for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Microsoft Research Asia & Peking University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.08508\"\n  }, \"https://arxiv.org/abs/2007.08508\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, mmdetection): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Scalsol/RepPointsV2\"\n  }, \"https://github.com/Scalsol/RepPointsV2\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Detection in 20 Years: A Survey\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1905.05055\"\n  }, \"https://arxiv.org/abs/1905.05055\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Light-Weight RetinaNet for Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1905.10011\"\n  }, \"https://arxiv.org/abs/1905.10011\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Data Augmentation Strategies for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Research, Brain Team\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1906.11172\"\n  }, \"https://arxiv.org/abs/1906.11172\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tensorflow/tpu/tree/master/models/official/detection\"\n  }, \"https://github.com/tensorflow/tpu/tree/master/models/official/detection\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards Adversarially Robust Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Baidu Research, Sunnyvale USA\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.10310\"\n  }, \"https://arxiv.org/abs/1907.10310\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-adversarial Faster-RCNN for Unrestricted Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.10343\"\n  }, \"https://arxiv.org/abs/1907.10343\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object as Distribution\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MIT\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.12929\"\n  }, \"https://arxiv.org/abs/1907.12929\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Detecting 11K Classes: Large Scale Object Detection without Fine-Grained Bounding Boxes\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1908.05217\"\n  }, \"https://arxiv.org/abs/1908.05217\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"R3Det: Refined Single-Stage Detector with Feature Refinement for Rotating Object\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1908.05612\"\n  }, \"https://arxiv.org/abs/1908.05612\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Thinklab-SJTU/R3Det_Tensorflow\"\n  }, \"https://github.com/Thinklab-SJTU/R3Det_Tensorflow\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SCRDet++: Detecting Small, Cluttered and Rotated Objects via Instance-Level Feature Denoising and Rotation Loss Smoothing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://yangxue0827.github.io/SCRDet++.html\"\n  }, \"https://yangxue0827.github.io/SCRDet++.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2004.13316\"\n  }, \"https://arxiv.org/abs/2004.13316\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Relation Distillation Networks for Video Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1908.09511\"\n  }, \"https://arxiv.org/abs/1908.09511\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Imbalance Problems in Object Detection: A Review\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.00169\"\n  }, \"https://arxiv.org/abs/1909.00169\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kemaloksuz/ObjectDetectionImbalance\"\n  }, \"https://github.com/kemaloksuz/ObjectDetectionImbalance\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FreeAnchor: Learning to Match Anchors for Visual Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.02466\"\n  }, \"https://arxiv.org/abs/1909.02466\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Efficient Neural Architecture Transformation Search in Channel-Level for Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1909.02293\"\n  }, \"https://arxiv.org/abs/1909.02293\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Self-Training and Adversarial Background Regularization for Unsupervised Domain Adaptive One-Stage Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.00597\"\n  }, \"https://arxiv.org/abs/1909.00597\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CBNet: A Novel Composite Backbone Network Architecture for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Composite Backbone Network (CBNet)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.03625\"\n  }, \"https://arxiv.org/abs/1909.03625\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://aaai.org/Papers/AAAI/2020GB/AAAI-LiuY.1833.pdf\"\n  }, \"https://aaai.org/Papers/AAAI/2020GB/AAAI-LiuY.1833.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Caffe2): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/PKUbahuangliuhe/CBNet\"\n  }, \"https://github.com/PKUbahuangliuhe/CBNet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(mmdetection): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/VDIGPKU/CBNet\"\n  }, \"https://github.com/VDIGPKU/CBNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CBNetV2: A Composite Backbone Network Architecture for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2107.00420\"\n  }, \"https://arxiv.org/abs/2107.00420\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/VDIGPKU/CBNetV2\"\n  }, \"https://github.com/VDIGPKU/CBNetV2\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A System-Level Solution for Low-Power Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019 Low-Power Computer Vision Workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.10964\"\n  }, \"https://arxiv.org/abs/1909.10964\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Anchor Loss: Modulating Loss Scale based on Prediction Difficulty\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.11155\"\n  }, \"https://arxiv.org/abs/1909.11155\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Pytorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/slryou41/AnchorLoss\"\n  }, \"https://github.com/slryou41/AnchorLoss\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1911.08287\"\n  }, \"https://arxiv.org/abs/1911.08287\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Zzh-tju/DIoU\"\n  }, \"https://github.com/Zzh-tju/DIoU\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Zzh-tju/CIoU\"\n  }, \"https://github.com/Zzh-tju/CIoU\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Zzh-tju/DIoU-darknet\"\n  }, \"https://github.com/Zzh-tju/DIoU-darknet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Curriculum Self-Paced Learning for Cross-Domain Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1911.06849\"\n  }, \"https://arxiv.org/abs/1911.06849\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multiple Anchor Learning for Visual Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1912.02252\"\n  }, \"https://arxiv.org/abs/1912.02252\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MnasFPN: Learning Latency-aware Pyramid Architecture for Object Detection on Mobile Devices\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google AI & Google Brain\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1912.01106\"\n  }, \"https://arxiv.org/abs/1912.01106\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AugFPN: Improving Multi-scale Feature Learning for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CASIA & Horizon Robotics\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1912.05384\"\n  }, \"https://arxiv.org/abs/1912.05384\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, mmdetection): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Gus-Guo/AugFPN\"\n  }, \"https://github.com/Gus-Guo/AugFPN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Detection as a Positive-Unlabeled Problem\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2002.04672\"\n  }, \"https://arxiv.org/abs/2002.04672\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Universal-RCNN: Universal Object Detector via Transferable Graph R-CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Huawei Noah\\u2019s Ark Lab & South China University of Technology & Sun Yat-Sen University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2002.07417\"\n  }, \"https://arxiv.org/abs/2002.07417\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BiDet: An Efficient Binarized Object Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.03961\"\n  }, \"https://arxiv.org/abs/2003.03961\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ZiweiWangTHU/BiDet\"\n  }, \"https://github.com/ZiweiWangTHU/BiDet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Revisiting the Sibling Head in Object Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020 & Method of Champion of OpenImage Challenge 2019, detection track\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SenseTime X-Lab & CUHK\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: task-aware spatial disentanglement (TSD)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.07540\"\n  }, \"https://arxiv.org/abs/2003.07540\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Sense-X/TSD\"\n  }, \"https://github.com/Sense-X/TSD\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Extended Feature Pyramid Network for Small Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2003.07021\"\n  }, \"https://arxiv.org/abs/2003.07021\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SaccadeNet: A Fast and Accurate Object Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Maryland & Wormpex AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.12125\"\n  }, \"https://arxiv.org/abs/2003.12125\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scale-Equalizing Pyramid Convolution for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SenseTime Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2005.03101\"\n  }, \"https://arxiv.org/abs/2005.03101\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jshilong/SEPC\"\n  }, \"https://github.com/jshilong/SEPC\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dynamic Refinement Network for Oriented and Densely Packed Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: SKU110K-R\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2005.09973\"\n  }, \"https://arxiv.org/abs/2005.09973\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Anymake/DRN_CVPR2020\"\n  }, \"https://github.com/Anymake/DRN_CVPR2020\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Robust Object Detection under Occlusion with Context-Aware CompositionalNets\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Johns Hopkins University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2005.11643\"\n  }, \"https://arxiv.org/abs/2005.11643\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DetectoRS: Detecting Objects with Recursive Feature Pyramid and Switchable Atrous Convolution\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Johns Hopkins University & Google Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: COCO test-dev 54.7% box AP\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2006.02334\"\n  }, \"https://arxiv.org/abs/2006.02334\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, mmdetection): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/joe-siyuan-qiao/DetectoRS\"\n  }, \"https://github.com/joe-siyuan-qiao/DetectoRS\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning a Unified Sample Weighting Network for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2006.06568\"\n  }, \"https://arxiv.org/abs/2006.06568\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/caiqi/sample-weighting-network\"\n  }, \"https://github.com/caiqi/sample-weighting-network\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"2nd Place Solution for Waymo Open Dataset Challenge -- 2D Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Horizon Robotics Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2006.15507\"\n  }, \"https://arxiv.org/abs/2006.15507\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Domain Adaptive Object Detection via Asymmetric Tri-way Faster-RCNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.01571\"\n  }, \"https://arxiv.org/abs/2007.01571\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AQD: Towards Accurate Quantized Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: South China University of Technology & University of Adelaide & Monash University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.06919\"\n  }, \"https://arxiv.org/abs/2007.06919\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/blueardour/model-quantization\"\n  }, \"https://github.com/blueardour/model-quantization\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Probabilistic Anchor Assignment with IoU Prediction for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.08103\"\n  }, \"https://arxiv.org/abs/2007.08103\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kkhoot/PAA\"\n  }, \"https://github.com/kkhoot/PAA\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BorderDet: Border Feature for Dense Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.11056\"\n  }, \"https://arxiv.org/abs/2007.11056\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Megvii-BaseDetection/BorderDet\"\n  }, \"https://github.com/Megvii-BaseDetection/BorderDet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Quantum-soft QUBO Suppression for Accurate Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.13992\"\n  }, \"https://arxiv.org/abs/2007.13992\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"VarifocalNet: An IoU-aware Dense Object Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Queensland University of Technology & University of Queensland\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2008.13367\"\n  }, \"https://arxiv.org/abs/2008.13367\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hyz-xmaster/VarifocalNet\"\n  }, \"https://github.com/hyz-xmaster/VarifocalNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The 1st Tiny Object Detection Challenge:Methods and Results\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV2020 Workshop on Real-world Computer Vision from Inputs with Limited Quality (RLQ) and Tiny Object Detection Challenge\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2009.07506\"\n  }, \"https://arxiv.org/abs/2009.07506\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MimicDet: Bridging the Gap Between One-Stage and Two-Stage Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SenseTime & CUHK\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2009.11528\"\n  }, \"https://arxiv.org/abs/2009.11528\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SEA: Bridging the Gap Between One- and Two-stage Detector Distillation via SEmantic-aware Alignment\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The Chinese University of Hong Kong & SmartMore\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2203.00862\"\n  }, \"https://arxiv.org/abs/2203.00862\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Ranking-based, Balanced Loss Function Unifying Classification and Localisation in Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2020 spotlight\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Middle East Technical University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: average Localization-Recall-Precision (aLRP)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2009.13592\"\n  }, \"https://arxiv.org/abs/2009.13592\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, Pytorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kemaloksuz/aLRPLoss\"\n  }, \"https://github.com/kemaloksuz/aLRPLoss\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Effective Fusion Factor in FPN for Tiny Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: WACV 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.02298\"\n  }, \"https://arxiv.org/abs/2011.02298\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bi-Dimensional Feature Alignment for Cross-Domain Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020 TASK-CV Workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.07205\"\n  }, \"https://arxiv.org/abs/2011.07205\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rethinking Transformer-based Set Prediction for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Carnegie Mellon University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.10881\"\n  }, \"https://arxiv.org/abs/2011.10881\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unsupervised Object Detection with LiDAR Clues\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SenseTime & USTC & CASIA & CAS\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.12953\"\n  }, \"https://arxiv.org/abs/2011.12953\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Self-EMD: Self-Supervised Object Detection without ImageNet\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MEGVII Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.13677\"\n  }, \"https://arxiv.org/abs/2011.13677\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End-to-End Object Detection with Fully Convolutional Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Megvii Technology & Xi\\u2019an Jiaotong University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Prediction-aware One- To-One (POTO) label assignment, 3D Max Filtering (3DMF)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.03544\"\n  }, \"https://arxiv.org/abs/2012.03544\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Megvii-BaseDetection/DeFCN\"\n  }, \"https://github.com/Megvii-BaseDetection/DeFCN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fine-Grained Dynamic Head for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.03519\"\n  }, \"https://arxiv.org/abs/2012.03519\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/StevenGrove/DynamicHead\"\n  }, \"https://github.com/StevenGrove/DynamicHead\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Focal and Efficient IOU Loss for Accurate Bounding Box Regression\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: South China University of Technology & 2Horizon Robotics & Chinese Academy of Sciences\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2101.08158\"\n  }, \"https://arxiv.org/abs/2101.08158\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scale Normalized Image Pyramids with AutoFocus for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: T-PAMI 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2102.05646\"\n  }, \"https://arxiv.org/abs/2102.05646\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mahyarnajibi/SNIPER\"\n  }, \"https://github.com/mahyarnajibi/SNIPER\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DetCo: Unsupervised Contrastive Learning for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The University of Hong Kong & Huawei Noah\\u2019s Ark Lab & Wuhan University & Nanjing University & Chinese University of Hong Kong\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2102.04803\"\n  }, \"https://arxiv.org/abs/2102.04803\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xieenze/DetCo\"\n  }, \"https://github.com/xieenze/DetCo\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/open-mmlab/OpenSelfSup\"\n  }, \"https://github.com/open-mmlab/OpenSelfSup\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RMOPP: Robust Multi-Objective Post-Processing for Effective Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2102.04582\"\n  }, \"https://arxiv.org/abs/2102.04582\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Instance Localization for Self-supervised Detection Pretraining\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Chinese University of Hong Kong & Microsoft Research Asia\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2102.08318\"\n  }, \"https://arxiv.org/abs/2102.08318\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Localization Distillation for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2102.12252\"\n  }, \"https://arxiv.org/abs/2102.12252\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/HikariTJU/LD\"\n  }, \"https://github.com/HikariTJU/LD\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"General Instance Distillation for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.02340\"\n  }, \"https://arxiv.org/abs/2103.02340\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards Open World Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.02603\"\n  }, \"https://arxiv.org/abs/2103.02603\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/JosephKJ/OWOD\"\n  }, \"https://github.com/JosephKJ/OWOD\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Data Augmentation for Object Detection via Differentiable Neural Rendering\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.02852\"\n  }, \"https://arxiv.org/abs/2103.02852\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Guanghan/DANR\"\n  }, \"https://github.com/Guanghan/DANR\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Revisiting the Loss Weight Adjustment in Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Science and Technology of China & University of Michigan\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.09488\"\n  }, \"https://arxiv.org/abs/2103.09488\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ywx-hub/ALWA\"\n  }, \"https://github.com/ywx-hub/ALWA\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"You Only Look One-level Feature\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.09460\"\n  }, \"https://arxiv.org/abs/2103.09460\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/megvii-model/YOLOF\"\n  }, \"https://github.com/megvii-model/YOLOF\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Optimization for Oriented Object Detection via Representation Invariance Loss\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.11636\"\n  }, \"https://arxiv.org/abs/2103.11636\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ming71/RIDet\"\n  }, \"https://github.com/ming71/RIDet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dynamic Anchor Learning for Arbitrary-Oriented Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.04150\"\n  }, \"https://arxiv.org/abs/2012.04150\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ming71/DAL\"\n  }, \"https://github.com/ming71/DAL\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Control Distance IoU and Control Distance IoU Loss Function for Better Bounding Box Regression\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2103.11696\"\n  }, \"https://arxiv.org/abs/2103.11696\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"OTA: Optimal Transport Assignment for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.14259\"\n  }, \"https://arxiv.org/abs/2103.14259\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Megvii-BaseDetection/OTA\"\n  }, \"https://github.com/Megvii-BaseDetection/OTA\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Distilling Object Detectors via Decoupled Features\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.14475\"\n  }, \"https://arxiv.org/abs/2103.14475\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ggjy/DeFeat.pytorch\"\n  }, \"https://github.com/ggjy/DeFeat.pytorch\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Distilling a Powerful Student Model via Online Knowledge Distillation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.14473\"\n  }, \"https://arxiv.org/abs/2103.14473\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/SJLeo/FFSD\"\n  }, \"https://github.com/SJLeo/FFSD\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"IQDet: Instance-wise Quality Distribution Sampling for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Megvii Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.06936\"\n  }, \"https://arxiv.org/abs/2104.06936\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Huazhong University of Science & Technology, Horizon Robotics\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2106.00666\"\n  }, \"https://arxiv.org/abs/2106.00666\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hustvl/YOLOS\"\n  }, \"https://github.com/hustvl/YOLOS\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Augmenting Anchors by the Detector Itself\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2105.14086\"\n  }, \"https://arxiv.org/abs/2105.14086\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rethinking Training from Scratch for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Zhejiang University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2106.03112\"\n  }, \"https://arxiv.org/abs/2106.03112\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dynamic Head: Unifying Object Detection Heads with Attentions\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Microsoft\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2106.08322\"\n  }, \"https://arxiv.org/abs/2106.08322\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/microsoft/DynamicHead\"\n  }, \"https://github.com/microsoft/DynamicHead\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Disentangle Your Dense Object Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM MM 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2107.02963\"\n  }, \"https://arxiv.org/abs/2107.02963\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zehuichen123/DDOD\"\n  }, \"https://github.com/zehuichen123/DDOD\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improving Object Detection by Label Assignment Distillation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2108.10520\"\n  }, \"https://arxiv.org/abs/2108.10520\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/cybercore-co-ltd/CoLAD_paper\"\n  }, \"https://github.com/cybercore-co-ltd/CoLAD_paper\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Progressive Hard-case Mining across Pyramid Levels in Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro:  Baidu Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2109.07217\"\n  }, \"https://arxiv.org/abs/2109.07217\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zimoqingfeng/UMOP\"\n  }, \"https://github.com/zimoqingfeng/UMOP\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Scale Aligned Distillation for Low-Resolution Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The Chinese University of Hong Kong & Adobe Research & SmartMore\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2109.06875\"\n  }, \"https://arxiv.org/abs/2109.06875\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/dvlab-research/MSAD\"\n  }, \"https://github.com/dvlab-research/MSAD\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pix2seq: A Language Modeling Framework for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Research, Brain Team\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2109.10852\"\n  }, \"https://arxiv.org/abs/2109.10852\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mixed Supervised Object Detection by Transferring Mask Prior and Semantic Similarity\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Shanghai Jiao Tong University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2110.14191\"\n  }, \"https://arxiv.org/abs/2110.14191\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bcmi/TraMaS-Weak-Shot-Object-Detection\"\n  }, \"https://github.com/bcmi/TraMaS-Weak-Shot-Object-Detection\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bootstrap Your Object Detector via Mixed Training\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2021 Spotlight\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Huazhong University of Science and Technology & Xi\\u2019an Jiaotong University & Microsoft Research Asia\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: MixTraining\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2111.03056\"\n  }, \"https://arxiv.org/abs/2111.03056\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MendelXu/MixTraining\"\n  }, \"https://github.com/MendelXu/MixTraining\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PP-PicoDet: A Better Real-Time Object Detector on Mobile Devices\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Baidu Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2111.00902\"\n  }, \"https://arxiv.org/abs/2111.00902\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/PaddlePaddle/PaddleDetection\"\n  }, \"https://github.com/PaddlePaddle/PaddleDetection\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Toward Minimal Misalignment at Minimal Cost in One-Stage and Anchor-Free Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2112.08902\"\n  }, \"https://arxiv.org/abs/2112.08902\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"GiraffeDet: A Heavy-Neck Paradigm for Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2202.04256\"\n  }, \"https://arxiv.org/abs/2202.04256\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Dual Weighting Label Assignment Scheme for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2203.09730\"\n  }, \"https://arxiv.org/abs/2203.09730\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/strongwolf/DW\"\n  }, \"https://github.com/strongwolf/DW\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"QueryDet: Cascaded Sparse Query for Accelerating High-Resolution Small Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.09136\"\n  }, \"https://arxiv.org/abs/2103.09136\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ChenhongyiYang/QueryDet-PyTorch\"\n  }, \"https://github.com/ChenhongyiYang/QueryDet-PyTorch\"))), mdx(\"h1\", {\n    \"id\": \"two-stage-object-detection\"\n  }, \"Two-Stage Object Detection\"), mdx(\"h2\", {\n    \"id\": \"r-cnn\"\n  }, \"R-CNN\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rich feature hierarchies for accurate object detection and semantic segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: R-CNN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1311.2524\"\n  }, \"http://arxiv.org/abs/1311.2524\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"supp: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr-supp.pdf\"\n  }, \"http://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr-supp.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.image-net.org/challenges/LSVRC/2013/slides/r-cnn-ilsvrc2013-workshop.pdf\"\n  }, \"http://www.image-net.org/challenges/LSVRC/2013/slides/r-cnn-ilsvrc2013-workshop.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.berkeley.edu/~rbg/slides/rcnn-cvpr14-slides.pdf\"\n  }, \"http://www.cs.berkeley.edu/~rbg/slides/rcnn-cvpr14-slides.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/rbgirshick/rcnn\"\n  }, \"https://github.com/rbgirshick/rcnn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://zhangliliang.com/2014/07/23/paper-note-rcnn/\"\n  }, \"http://zhangliliang.com/2014/07/23/paper-note-rcnn/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"caffe-pr(\\\"Make R-CNN the Caffe detection example\\\"): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/BVLC/caffe/pull/482\"\n  }, \"https://github.com/BVLC/caffe/pull/482\"), \" \")), mdx(\"h2\", {\n    \"id\": \"fast-r-cnn\"\n  }, \"Fast R-CNN\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast R-CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1504.08083\"\n  }, \"http://arxiv.org/abs/1504.08083\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-detection.pdf\"\n  }, \"http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-detection.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/rbgirshick/fast-rcnn\"\n  }, \"https://github.com/rbgirshick/fast-rcnn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(COCO-branch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/rbgirshick/fast-rcnn/tree/coco\"\n  }, \"https://github.com/rbgirshick/fast-rcnn/tree/coco\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"webcam demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/rbgirshick/fast-rcnn/pull/29\"\n  }, \"https://github.com/rbgirshick/fast-rcnn/pull/29\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://zhangliliang.com/2015/05/17/paper-note-fast-rcnn/\"\n  }, \"http://zhangliliang.com/2015/05/17/paper-note-fast-rcnn/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://blog.csdn.net/linj_m/article/details/48930179\"\n  }, \"http://blog.csdn.net/linj_m/article/details/48930179\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(\\\"Fast R-CNN in MXNet\\\"): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/precedenceguo/mx-rcnn\"\n  }, \"https://github.com/precedenceguo/mx-rcnn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mahyarnajibi/fast-rcnn-torch\"\n  }, \"https://github.com/mahyarnajibi/fast-rcnn-torch\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/apple2373/chainer-simple-fast-rnn\"\n  }, \"https://github.com/apple2373/chainer-simple-fast-rnn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zplizzi/tensorflow-fast-rcnn\"\n  }, \"https://github.com/zplizzi/tensorflow-fast-rcnn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A-Fast-RCNN: Hard Positive Generation via Adversary for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.03414\"\n  }, \"https://arxiv.org/abs/1704.03414\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://abhinavsh.info/papers/pdfs/adversarial_object_detection.pdf\"\n  }, \"http://abhinavsh.info/papers/pdfs/adversarial_object_detection.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Caffe): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xiaolonw/adversarial-frcnn\"\n  }, \"https://github.com/xiaolonw/adversarial-frcnn\"))), mdx(\"h2\", {\n    \"id\": \"faster-r-cnn\"\n  }, \"Faster R-CNN\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1506.01497\"\n  }, \"http://arxiv.org/abs/1506.01497\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gitxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.gitxiv.com/posts/8pfpcvefDYn2gSgXk/faster-r-cnn-towards-real-time-object-detection-with-region\"\n  }, \"http://www.gitxiv.com/posts/8pfpcvefDYn2gSgXk/faster-r-cnn-towards-real-time-object-detection-with-region\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2016/bil722/slides/w05-FasterR-CNN.pdf\"\n  }, \"http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2016/bil722/slides/w05-FasterR-CNN.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, Matlab): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ShaoqingRen/faster_rcnn\"\n  }, \"https://github.com/ShaoqingRen/faster_rcnn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/rbgirshick/py-faster-rcnn\"\n  }, \"https://github.com/rbgirshick/py-faster-rcnn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(MXNet): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/msracver/Deformable-ConvNets/tree/master/faster_rcnn\"\n  }, \"https://github.com/msracver/Deformable-ConvNets/tree/master/faster_rcnn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com//jwyang/faster-rcnn.pytorch\"\n  }, \"https://github.com//jwyang/faster-rcnn.pytorch\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mitmul/chainer-faster-rcnn\"\n  }, \"https://github.com/mitmul/chainer-faster-rcnn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/andreaskoepf/faster-rcnn.torch\"\n  }, \"https://github.com/andreaskoepf/faster-rcnn.torch\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ruotianluo/Faster-RCNN-Densecap-torch\"\n  }, \"https://github.com/ruotianluo/Faster-RCNN-Densecap-torch\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/smallcorgi/Faster-RCNN_TF\"\n  }, \"https://github.com/smallcorgi/Faster-RCNN_TF\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/CharlesShang/TFFRCNN\"\n  }, \"https://github.com/CharlesShang/TFFRCNN\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(C++ demo): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/YihangLou/FasterRCNN-Encapsulation-Cplusplus\"\n  }, \"https://github.com/YihangLou/FasterRCNN-Encapsulation-Cplusplus\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yhenon/keras-frcnn\"\n  }, \"https://github.com/yhenon/keras-frcnn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Eniac-Xie/faster-rcnn-resnet\"\n  }, \"https://github.com/Eniac-Xie/faster-rcnn-resnet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(C++): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/D-X-Y/caffe-faster-rcnn/tree/dev\"\n  }, \"https://github.com/D-X-Y/caffe-faster-rcnn/tree/dev\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"R-CNN minus R\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1506.06981\"\n  }, \"http://arxiv.org/abs/1506.06981\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Faster R-CNN in MXNet with distributed implementation and data parallelization\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/dmlc/mxnet/tree/master/example/rcnn\"\n  }, \"https://github.com/dmlc/mxnet/tree/master/example/rcnn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Contextual Priming and Feedback for Faster R-CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016. Carnegie Mellon University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://abhinavsh.info/context_priming_feedback.pdf\"\n  }, \"http://abhinavsh.info/context_priming_feedback.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"poster: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.eccv2016.org/files/posters/P-1A-20.pdf\"\n  }, \"http://www.eccv2016.org/files/posters/P-1A-20.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An Implementation of Faster RCNN with Study for Region Sampling\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Technical Report, 3 pages. CMU\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.02138\"\n  }, \"https://arxiv.org/abs/1702.02138\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/endernewton/tf-faster-rcnn\"\n  }, \"https://github.com/endernewton/tf-faster-rcnn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Interpretable R-CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: North Carolina State University & Alibaba\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: AND-OR Graph (AOG)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.05226\"\n  }, \"https://arxiv.org/abs/1711.05226\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Light-Head R-CNN: In Defense of Two-Stage Object Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tsinghua University & Megvii Inc\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.07264\"\n  }, \"https://arxiv.org/abs/1711.07264\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, Tensorflow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zengarden/light_head_rcnn\"\n  }, \"https://github.com/zengarden/light_head_rcnn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/terrychenism/Deformable-ConvNets/blob/master/rfcn/symbols/resnet_v1_101_rfcn_light.py#L784\"\n  }, \"https://github.com/terrychenism/Deformable-ConvNets/blob/master/rfcn/symbols/resnet_v1_101_rfcn_light.py#L784\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cascade R-CNN: Delving into High Quality Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018. UC San Diego\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.00726\"\n  }, \"https://arxiv.org/abs/1712.00726\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Caffe, official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zhaoweicai/cascade-rcnn\"\n  }, \"https://github.com/zhaoweicai/cascade-rcnn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cascade R-CNN: High Quality Object Detection and Instance Segmentation\")), mdx(\"p\", null, \" -arxiv: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1906.09756\"\n  }, \"https://arxiv.org/abs/1906.09756\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Caffe, official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zhaoweicai/cascade-rcnn\"\n  }, \"https://github.com/zhaoweicai/cascade-rcnn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zhaoweicai/Detectron-Cascade-RCNN\"\n  }, \"https://github.com/zhaoweicai/Detectron-Cascade-RCNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cascade RPN: Delving into High-Quality Region Proposal Network with Adaptive Convolution\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2019 spotlight\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.06720\"\n  }, \"https://arxiv.org/abs/1909.06720\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/thangvubk/Cascade-RPN\"\n  }, \"https://github.com/thangvubk/Cascade-RPN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SMC Faster R-CNN: Toward a scene-specialized multi-object detector\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1706.10217\"\n  }, \"https://arxiv.org/abs/1706.10217\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Domain Adaptive Faster R-CNN for Object Detection in the Wild\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018. ETH Zurich & ESAT/PSI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.03243\"\n  }, \"https://arxiv.org/abs/1803.03243\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official. Caffe): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yuhuayc/da-faster-rcnn\"\n  }, \"https://github.com/yuhuayc/da-faster-rcnn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Robust Physical Adversarial Attack on Faster R-CNN Object Detector\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1804.05810\"\n  }, \"https://arxiv.org/abs/1804.05810\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Auto-Context R-CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Rejected by ECCV18\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.02842\"\n  }, \"https://arxiv.org/abs/1807.02842\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Grid R-CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SenseTime\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.12030\"\n  }, \"https://arxiv.org/abs/1811.12030\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Grid R-CNN Plus: Faster and Better\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SenseTime Research & CUHK & Beihang University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1906.05688\"\n  }, \"https://arxiv.org/abs/1906.05688\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/STVIR/Grid-R-CNN\"\n  }, \"https://github.com/STVIR/Grid-R-CNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Few-shot Adaptive Faster R-CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.09372\"\n  }, \"https://arxiv.org/abs/1903.09372\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Libra R-CNN: Towards Balanced Learning for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.02701\"\n  }, \"https://arxiv.org/abs/1904.02701\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rethinking Classification and Localization in R-CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Northeastern University & Microsoft\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.06493\"\n  }, \"https://arxiv.org/abs/1904.06493\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Reprojection R-CNN: A Fast and Accurate Object Detector for 360\\xB0 Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Peking University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.11830\"\n  }, \"https://arxiv.org/abs/1907.11830\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rethinking Classification and Localization for Cascade R-CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.11914\"\n  }, \"https://arxiv.org/abs/1907.11914\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"IoU-uniform R-CNN: Breaking Through the Limitations of RPN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1912.05190\"\n  }, \"https://arxiv.org/abs/1912.05190\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(mmdetection): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zl1994/IoU-Uniform-R-CNN\"\n  }, \"https://github.com/zl1994/IoU-Uniform-R-CNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dynamic R-CNN: Towards High Quality Object Detection via Dynamic Training\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2004.06002\"\n  }, \"https://arxiv.org/abs/2004.06002\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hkzhang95/DynamicRCNN\"\n  }, \"https://github.com/hkzhang95/DynamicRCNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Delving into the Imbalance of Positive Proposals in Two-stage Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Waseda University & Tencent AI Lab & Nanjing University of Science and Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2005.11472\"\n  }, \"https://arxiv.org/abs/2005.11472\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hierarchical Context Embedding for Region-based Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Nanjing University & Megvii Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2008.01338\"\n  }, \"https://arxiv.org/abs/2008.01338\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sparse R-CNN: End-to-End Object Detection with Learnable Proposals\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The University of Hong Kong & Tongji University & ByteDance AI Lab 4University of California\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.12450\"\n  }, \"https://arxiv.org/abs/2011.12450\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/PeizeSun/SparseR-CNN\"\n  }, \"https://github.com/PeizeSun/SparseR-CNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dynamic Sparse R-CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2205.02101\"\n  }, \"https://arxiv.org/abs/2205.02101\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Featurized Query R-CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Huazhong University of Science & Technology & Horizon Robotics\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2206.06258\"\n  }, \"https://arxiv.org/abs/2206.06258\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hustvl/Featurized-QueryRCNN\"\n  }, \"https://github.com/hustvl/Featurized-QueryRCNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Augmenting Proposals by the Detector Itself\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tsinghua University & Alibaba Group\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2101.11789\"\n  }, \"https://arxiv.org/abs/2101.11789\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Probabilistic two-stage detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: UT Austin & Intel Labs\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.07461\"\n  }, \"https://arxiv.org/abs/2103.07461\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xingyizhou/CenterNet2\"\n  }, \"https://github.com/xingyizhou/CenterNet2\"))), mdx(\"h1\", {\n    \"id\": \"single-shot-object-detection\"\n  }, \"Single-Shot Object Detection\"), mdx(\"h2\", {\n    \"id\": \"yolo\"\n  }, \"YOLO\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"You Only Look Once: Unified, Real-Time Object Detection\")), mdx(\"img\", {\n    \"src\": \"https://camo.githubusercontent.com/e69d4118b20a42de4e23b9549f9a6ec6dbbb0814/687474703a2f2f706a7265646469652e636f6d2f6d656469612f66696c65732f6461726b6e65742d626c61636b2d736d616c6c2e706e67\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1506.02640\"\n  }, \"http://arxiv.org/abs/1506.02640\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://pjreddie.com/darknet/yolo/\"\n  }, \"http://pjreddie.com/darknet/yolo/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/pjreddie/darknet\"\n  }, \"https://github.com/pjreddie/darknet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://pjreddie.com/publications/yolo/\"\n  }, \"https://pjreddie.com/publications/yolo/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&loop=false&delayms=3000&slide=id.p\"\n  }, \"https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&loop=false&delayms=3000&slide=id.p\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"reddit: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.reddit.com/r/MachineLearning/comments/3a3m0o/realtime_object_detection_with_yolo/\"\n  }, \"https://www.reddit.com/r/MachineLearning/comments/3a3m0o/realtime_object_detection_with_yolo/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/gliese581gg/YOLO_tensorflow\"\n  }, \"https://github.com/gliese581gg/YOLO_tensorflow\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xingwangsfu/caffe-yolo\"\n  }, \"https://github.com/xingwangsfu/caffe-yolo\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/frankzhangrui/Darknet-Yolo\"\n  }, \"https://github.com/frankzhangrui/Darknet-Yolo\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/BriSkyHekun/py-darknet-yolo\"\n  }, \"https://github.com/BriSkyHekun/py-darknet-yolo\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tommy-qichang/yolo.torch\"\n  }, \"https://github.com/tommy-qichang/yolo.torch\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/frischzenger/yolo-windows\"\n  }, \"https://github.com/frischzenger/yolo-windows\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/AlexeyAB/yolo-windows\"\n  }, \"https://github.com/AlexeyAB/yolo-windows\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/nilboy/tensorflow-yolo\"\n  }, \"https://github.com/nilboy/tensorflow-yolo\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"darkflow - translate darknet to tensorflow. Load trained weights, retrain/fine-tune them using tensorflow, export constant graph def to C++\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://thtrieu.github.io/notes/yolo-tensorflow-graph-buffer-cpp\"\n  }, \"https://thtrieu.github.io/notes/yolo-tensorflow-graph-buffer-cpp\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/thtrieu/darkflow\"\n  }, \"https://github.com/thtrieu/darkflow\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Start Training YOLO with Our Own Data\")), mdx(\"img\", {\n    \"src\": \"http://guanghan.info/blog/en/wp-content/uploads/2015/12/images-40.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: train with customized data and class numbers/labels. Linux / Windows version for darknet.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://guanghan.info/blog/en/my-works/train-yolo/\"\n  }, \"http://guanghan.info/blog/en/my-works/train-yolo/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Guanghan/darknet\"\n  }, \"https://github.com/Guanghan/darknet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"YOLO: Core ML versus MPSNNGraph\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tiny YOLO for iOS implemented using CoreML but also using the new MPS graph API.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://machinethink.net/blog/yolo-coreml-versus-mps-graph/\"\n  }, \"http://machinethink.net/blog/yolo-coreml-versus-mps-graph/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hollance/YOLO-CoreML-MPSNNGraph\"\n  }, \"https://github.com/hollance/YOLO-CoreML-MPSNNGraph\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TensorFlow YOLO object detection on Android\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Real-time object detection on Android using the YOLO network with TensorFlow\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/natanielruiz/android-yolo\"\n  }, \"https://github.com/natanielruiz/android-yolo\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Computer Vision in iOS \\u2013 Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://sriraghu.com/2017/07/12/computer-vision-in-ios-object-detection/\"\n  }, \"https://sriraghu.com/2017/07/12/computer-vision-in-ios-object-detection/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github:\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/r4ghu/iOS-CoreML-Yolo\"\n  }, \"https://github.com/r4ghu/iOS-CoreML-Yolo\"))), mdx(\"h2\", {\n    \"id\": \"yolov2\"\n  }, \"YOLOv2\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"YOLO9000: Better, Faster, Stronger\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.08242\"\n  }, \"https://arxiv.org/abs/1612.08242\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://pjreddie.com/yolo9000/\"\n  }, \"http://pjreddie.com/yolo9000/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Chainer): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/leetenki/YOLOv2\"\n  }, \"https://github.com/leetenki/YOLOv2\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Keras): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/allanzelener/YAD2K\"\n  }, \"https://github.com/allanzelener/YAD2K\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(PyTorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/longcw/yolo2-pytorch\"\n  }, \"https://github.com/longcw/yolo2-pytorch\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Tensorflow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hizhangp/yolo_tensorflow\"\n  }, \"https://github.com/hizhangp/yolo_tensorflow\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Windows): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/AlexeyAB/darknet\"\n  }, \"https://github.com/AlexeyAB/darknet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/choasUp/caffe-yolo9000\"\n  }, \"https://github.com/choasUp/caffe-yolo9000\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/philipperemy/yolo-9000\"\n  }, \"https://github.com/philipperemy/yolo-9000\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"darknet_scripts\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Auxilary scripts to work with (YOLO) darknet deep learning famework. AKA -> How to generate YOLO anchors?\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Jumabek/darknet_scripts\"\n  }, \"https://github.com/Jumabek/darknet_scripts\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Yolo_mark: GUI for marking bounded boxes of objects in images for training Yolo v2\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/AlexeyAB/Yolo_mark\"\n  }, \"https://github.com/AlexeyAB/Yolo_mark\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"LightNet: Bringing pjreddie's DarkNet out of the shadows\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com//explosion/lightnet\"\n  }, \"https://github.com//explosion/lightnet\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"YOLO v2 Bounding Box Tool\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Bounding box labeler tool to generate the training data in the format YOLO v2 requires.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Cartucho/yolo-boundingbox-labeler-GUI\"\n  }, \"https://github.com/Cartucho/yolo-boundingbox-labeler-GUI\"))), mdx(\"h2\", {\n    \"id\": \"yolov3\"\n  }, \"YOLOv3\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"YOLOv3: An Incremental Improvement\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://pjreddie.com/darknet/yolo/\"\n  }, \"https://pjreddie.com/darknet/yolo/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://pjreddie.com/media/files/papers/YOLOv3.pdf\"\n  }, \"https://pjreddie.com/media/files/papers/YOLOv3.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.02767\"\n  }, \"https://arxiv.org/abs/1804.02767\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"githb: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/DeNA/PyTorch_YOLOv3\"\n  }, \"https://github.com/DeNA/PyTorch_YOLOv3\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/eriklindernoren/PyTorch-YOLOv3\"\n  }, \"https://github.com/eriklindernoren/PyTorch-YOLOv3\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Gaussian YOLOv3: An Accurate and Fast Object Detector Using Localization Uncertainty for Autonomous Driving\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1904.04620\"\n  }, \"https://arxiv.org/abs/1904.04620\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"YOLO-LITE: A Real-Time Object Detection Algorithm Optimized for Non-GPU Computers\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.05588\"\n  }, \"https://arxiv.org/abs/1811.05588\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spiking-YOLO: Spiking Neural Network for Real-time Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1903.06530\"\n  }, \"https://arxiv.org/abs/1903.06530\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"YOLO Nano: a Highly Compact You Only Look Once Convolutional Neural Network for Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1910.01271\"\n  }, \"https://arxiv.org/abs/1910.01271\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"REQ-YOLO: A Resource-Aware, Efficient Quantization Framework for Object Detection on FPGAs\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1909.13396\"\n  }, \"https://arxiv.org/abs/1909.13396\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Poly-YOLO: higher speed, more precise detection and instance segmentation for YOLOv3\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: TPAMI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2005.13243\"\n  }, \"https://arxiv.org/abs/2005.13243\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gitlab: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://gitlab.com/irafm-ai/poly-yolo\"\n  }, \"https://gitlab.com/irafm-ai/poly-yolo\"))), mdx(\"h2\", {\n    \"id\": \"yolov4\"\n  }, \"YOLOv4\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"YOLOv4: Optimal Speed and Accuracy of Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Weighted-Residual-Connections (WRC), Cross-Stage-Partial-connections (CSP), Cross mini-Batch Normalization (CmBN), Self-adversarial-training (SAT), Mish-activation\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2004.10934\"\n  }, \"https://arxiv.org/abs/2004.10934\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/AlexeyAB/darknet\"\n  }, \"https://github.com/AlexeyAB/darknet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/WongKinYiu/PyTorch_YOLOv4\"\n  }, \"https://github.com/WongKinYiu/PyTorch_YOLOv4\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"YOLOX: Exceeding YOLO Series in 2021\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Megvii Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2107.08430\"\n  }, \"https://arxiv.org/abs/2107.08430\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Megvii-BaseDetection/YOLOX\"\n  }, \"https://github.com/Megvii-BaseDetection/YOLOX\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PP-YOLO: An Effective and Efficient Implementation of Object Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Baidu Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.12099\"\n  }, \"https://arxiv.org/abs/2007.12099\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/PaddlePaddle/PaddleDetection\"\n  }, \"https://github.com/PaddlePaddle/PaddleDetection\"))), mdx(\"h2\", {\n    \"id\": \"yolov7\"\n  }, \"YOLOv7\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2207.02696\"\n  }, \"https://arxiv.org/abs/2207.02696\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/WongKinYiu/yolov7\"\n  }, \"https://github.com/WongKinYiu/yolov7\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Real-time Object Detection for Streaming Perception\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2203.12338\"\n  }, \"https://arxiv.org/abs/2203.12338\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yancie-yjr/StreamYOLO\"\n  }, \"https://github.com/yancie-yjr/StreamYOLO\"))), mdx(\"h2\", {\n    \"id\": \"ssd\"\n  }, \"SSD\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SSD: Single Shot MultiBox Detector\")), mdx(\"img\", {\n    \"src\": \"https://camo.githubusercontent.com/ad9b147ed3a5f48ffb7c3540711c15aa04ce49c6/687474703a2f2f7777772e63732e756e632e6564752f7e776c69752f7061706572732f7373642e706e67\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016 Oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1512.02325\"\n  }, \"http://arxiv.org/abs/1512.02325\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.unc.edu/~wliu/papers/ssd.pdf\"\n  }, \"http://www.cs.unc.edu/~wliu/papers/ssd.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.unc.edu/%7Ewliu/papers/ssd_eccv2016_slide.pdf\"\n  }, \"http://www.cs.unc.edu/%7Ewliu/papers/ssd_eccv2016_slide.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/weiliu89/caffe/tree/ssd\"\n  }, \"https://github.com/weiliu89/caffe/tree/ssd\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"video: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://weibo.com/p/2304447a2326da963254c963c97fb05dd3a973\"\n  }, \"http://weibo.com/p/2304447a2326da963254c963c97fb05dd3a973\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zhreshold/mxnet-ssd\"\n  }, \"https://github.com/zhreshold/mxnet-ssd\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zhreshold/mxnet-ssd.cpp\"\n  }, \"https://github.com/zhreshold/mxnet-ssd.cpp\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/rykov8/ssd_keras\"\n  }, \"https://github.com/rykov8/ssd_keras\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/balancap/SSD-Tensorflow\"\n  }, \"https://github.com/balancap/SSD-Tensorflow\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/amdegroot/ssd.pytorch\"\n  }, \"https://github.com/amdegroot/ssd.pytorch\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Caffe): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/chuanqi305/MobileNet-SSD\"\n  }, \"https://github.com/chuanqi305/MobileNet-SSD\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"What's the diffience in performance between this new code you pushed and the previous code? #327\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/weiliu89/caffe/issues/327\"\n  }, \"https://github.com/weiliu89/caffe/issues/327\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DSSD : Deconvolutional Single Shot Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: UNC Chapel Hill & Amazon Inc\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.06659\"\n  }, \"https://arxiv.org/abs/1701.06659\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/chengyangfu/caffe/tree/dssd\"\n  }, \"https://github.com/chengyangfu/caffe/tree/dssd\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MTCloudVision/mxnet-dssd\"\n  }, \"https://github.com/MTCloudVision/mxnet-dssd\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://120.52.72.53/www.cs.unc.edu/c3pr90ntc0td/~cyfu/dssd_lalaland.mp4\"\n  }, \"http://120.52.72.53/www.cs.unc.edu/c3pr90ntc0td/~cyfu/dssd_lalaland.mp4\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Enhancement of SSD by concatenating feature maps for object detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: rainbow SSD (R-SSD)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1705.09587\"\n  }, \"https://arxiv.org/abs/1705.09587\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Context-aware Single-Shot Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: CSSD, DiCSSD, DeCSSD, effective receptive fields (ERFs),  theoretical receptive fields (TRFs)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.08682\"\n  }, \"https://arxiv.org/abs/1707.08682\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Feature-Fused SSD: Fast Detection for Small Objects\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.05054\"\n  }, \"https://arxiv.org/abs/1709.05054\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FSSD: Feature Fusion Single Shot Multibox Detector\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.00960\"\n  }, \"https://arxiv.org/abs/1712.00960\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Weaving Multi-scale Context for Single Shot Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: WeaveNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: fuse multi-scale information\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.03149\"\n  }, \"https://arxiv.org/abs/1712.03149\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Extend the shallow part of Single Shot MultiBox Detector via Convolutional Neural Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: ESSD\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.05918\"\n  }, \"https://arxiv.org/abs/1801.05918\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Tiny SSD: A Tiny Single-shot Detection Deep Convolutional Neural Network for Real-time Embedded Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1802.06488\"\n  }, \"https://arxiv.org/abs/1802.06488\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MDSSD: Multi-scale Deconvolutional Single Shot Detector for small objects\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Zhengzhou University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.07009\"\n  }, \"https://arxiv.org/abs/1805.07009\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Accurate Single Stage Detector Using Recurrent Rolling Convolution\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017. SenseTime\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Recurrent Rolling Convolution (RRC)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.05776\"\n  }, \"https://arxiv.org/abs/1704.05776\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xiaohaoChen/rrc_detection\"\n  }, \"https://github.com/xiaohaoChen/rrc_detection\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Residual Features and Unified Prediction Network for Single Stage Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1707.05031\"\n  }, \"https://arxiv.org/abs/1707.05031\")), mdx(\"h2\", {\n    \"id\": \"retinanet\"\n  }, \"RetinaNet\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Focal Loss for Dense Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017 Best student paper award. Facebook AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: RetinaNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.02002\"\n  }, \"https://arxiv.org/abs/1708.02002\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cascade RetinaNet: Maintaining Consistency for Single-Stage Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Cas-RetinaNet, Feature Consistency Module\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.06881\"\n  }, \"https://arxiv.org/abs/1907.06881\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Focal Loss Dense Detector for Vehicle Surveillance\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.01114\"\n  }, \"https://arxiv.org/abs/1803.01114\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Single-Shot Refinement Neural Network for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.06897\"\n  }, \"https://arxiv.org/abs/1711.06897\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/sfzhang15/RefineDet\"\n  }, \"https://github.com/sfzhang15/RefineDet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MTCloudVision/RefineDet-Mxnet\"\n  }, \"https://github.com/MTCloudVision/RefineDet-Mxnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Single-Shot Bidirectional Pyramid Networks for High-Quality Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Singapore Management University & Zhejiang University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.08208\"\n  }, \"https://arxiv.org/abs/1803.08208\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dual Refinement Network for Single-Shot Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1807.08638\"\n  }, \"https://arxiv.org/abs/1807.08638\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ScratchDet:Exploring to Train Single-Shot Object Detectors from Scratch\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1810.08425\"\n  }, \"https://arxiv.org/abs/1810.08425\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/KimSoybean/ScratchDethttps://github.com/KimSoybean/ScratchDet\"\n  }, \"https://github.com/KimSoybean/ScratchDet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Gradient Harmonized Single-stage Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2019 Oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.05181\"\n  }, \"https://arxiv.org/abs/1811.05181\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gihtub(official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/libuyu/GHM_Detection\"\n  }, \"https://github.com/libuyu/GHM_Detection\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.04533\"\n  }, \"https://arxiv.org/abs/1811.04533\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/qijiezhao/M2Det\"\n  }, \"https://github.com/qijiezhao/M2Det\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-layer Pruning Framework for Compressing Single Shot MultiBox Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: WACV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.08342\"\n  }, \"https://arxiv.org/abs/1811.08342\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Consistent Optimization for Single-Shot Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.06563\"\n  }, \"https://arxiv.org/abs/1901.06563\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://zhuanlan.zhihu.com/p/55416312\"\n  }, \"https://zhuanlan.zhihu.com/p/55416312\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Single-shot Object Detector with Feature Aggragation and Enhancement\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1902.02923\"\n  }, \"https://arxiv.org/abs/1902.02923\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards Accurate One-Stage Object Detection with AP-Loss\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Shanghai Jiao Tong University & Intel Labs & Malaysia Multimedia University & Tencent YouTu Lab & Peking University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Average-Precision loss (AP-loss)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: {\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.06373%7D(https://arxiv.org/abs/1904.06373)\"\n  }, \"https://arxiv.org/abs/1904.06373}(https://arxiv.org/abs/1904.06373)\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AP-Loss for Accurate One-Stage Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IEEE TPAMI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2008.07294\"\n  }, \"https://arxiv.org/abs/2008.07294\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/cccorn/AP-loss\"\n  }, \"https://github.com/cccorn/AP-loss\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Searching Parameterized AP Loss for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: 1Tsinghua University & Zhejiang University & SenseTime Research & Shanghai Jiao Tong University & Beijing Academy of Artificial Intelligence\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2112.05138\"\n  }, \"https://arxiv.org/abs/2112.05138\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/fundamentalvision/Parameterized-AP-Loss\"\n  }, \"https://github.com/fundamentalvision/Parameterized-AP-Loss\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Efficient Featurized Image Pyramid Network for Single Shot Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_CVPR_2019/papers/Pang_Efficient_Featurized_Image_Pyramid_Network_for_Single_Shot_Detector_CVPR_2019_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_CVPR_2019/papers/Pang_Efficient_Featurized_Image_Pyramid_Network_for_Single_Shot_Detector_CVPR_2019_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/vaesl/LFIP\"\n  }, \"https://github.com/vaesl/LFIP\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DR Loss: Improving Object Detection by Distributional Ranking\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Alibaba Group\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.10156\"\n  }, \"https://arxiv.org/abs/1907.10156\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"HAR-Net: Joint Learning of Hybrid Attention for Single-stage Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1904.11141\"\n  }, \"https://arxiv.org/abs/1904.11141\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Propose-and-Attend Single Shot Detector\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1907.12736\"\n  }, \"https://arxiv.org/abs/1907.12736\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Revisiting Feature Alignment for One-stage Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Chinese Academy of Sciences & TuSimple\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: AlignDet, RoIConv\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1908.01570\"\n  }, \"https://arxiv.org/abs/1908.01570\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"IoU-balanced Loss Functions for Single-stage Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: HUST\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1908.05641\"\n  }, \"https://arxiv.org/abs/1908.05641\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PosNeg-Balanced Anchors with Aligned Features for Single-Shot Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Chinese Academy of Sciences & University of Chinese Academy of Sciences\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Anchor Promotion Module (APM), Feature Alignment Module (FAM)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1908.03295\"\n  }, \"https://arxiv.org/abs/1908.03295\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"R3Det: Refined Single-Stage Detector with Feature Refinement for Rotating Object\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1908.05612\"\n  }, \"https://arxiv.org/abs/1908.05612\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hierarchical Shot Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: reg-offset-cls (ROC) module\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_ICCV_2019/papers/Cao_Hierarchical_Shot_Detector_ICCV_2019_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_ICCV_2019/papers/Cao_Hierarchical_Shot_Detector_ICCV_2019_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, Pytorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/JialeCao001/HSD\"\n  }, \"https://github.com/JialeCao001/HSD\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning from Noisy Anchors for One-stage Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1912.05086\"\n  }, \"https://arxiv.org/abs/1912.05086\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Nanjing University of Science and Technology & Momenta & Nanjing University & Microsoft Research & Tsinghua University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2006.04388\"\n  }, \"https://arxiv.org/abs/2006.04388\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/implus/GFocal\"\n  }, \"https://github.com/implus/GFocal\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generalized Focal Loss V2: Learning Reliable Localization Quality Estimation for Dense Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Nanjing University of Science and Technology & Momenta & Nanjing University & Tsinghua University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.12885\"\n  }, \"https://arxiv.org/abs/2011.12885\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/implus/GFocalV2\"\n  }, \"https://github.com/implus/GFocalV2\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Single-Shot Two-Pronged Detector with Rectified IoU Loss\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM MM 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2008.03511\"\n  }, \"https://arxiv.org/abs/2008.03511\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"OneNet: Towards End-to-End One-Stage Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The University of Hong Kong & ByteDance AI Lab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.05780\"\n  }, \"https://arxiv.org/abs/2012.05780\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/PeizeSun/OneNet\"\n  }, \"https://github.com/PeizeSun/OneNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TOOD: Task-aligned One-stage Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021 Oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Intellifusion Inc. & Meituan Inc. & ByteDance Inc. & Malong LLC & Alibaba Group\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2108.07755\"\n  }, \"https://arxiv.org/abs/2108.07755\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/fcjian/TOOD\"\n  }, \"https://github.com/fcjian/TOOD\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rethinking the Aligned and Misaligned Features in One-stage Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2108.12176\"\n  }, \"https://arxiv.org/abs/2108.12176\")), mdx(\"h1\", {\n    \"id\": \"anchor-free\"\n  }, \"Anchor-free\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Feature Selective Anchor-Free Module for Single-Shot Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: feature selective anchor-free (FSAF) module\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.00621\"\n  }, \"https://arxiv.org/abs/1903.00621\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FCOS: Fully Convolutional One-Stage Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The University of Adelaide\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: anchor-free\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.01355\"\n  }, \"https://arxiv.org/abs/1904.01355\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tianzhi0549/FCOS/\"\n  }, \"https://github.com/tianzhi0549/FCOS/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FoveaBox: Beyond Anchor-based Object Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tsinghua University & BNRist & ByteDance AI Lab & University of Pennsylvania\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.03797\"\n  }, \"https://arxiv.org/abs/1904.03797\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, mmdetection): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/taokong/FoveaBox\"\n  }, \"https://github.com/taokong/FoveaBox\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"IMMVP: An Efficient Daytime and Nighttime On-Road Object Detector\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1910.06573\"\n  }, \"https://arxiv.org/abs/1910.06573\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"EfficientDet: Scalable and Efficient Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1911.09070\"\n  }, \"https://arxiv.org/abs/1911.09070\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/google/automl/tree/master/efficientdet\"\n  }, \"https://github.com/google/automl/tree/master/efficientdet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch\"\n  }, \"https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Domain Adaptation for Object Detection via Style Consistency\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1911.10033\"\n  }, \"https://arxiv.org/abs/1911.10033\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Soft Anchor-Point Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Carnegie Mellon University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Soft Anchor-Point Detector (SAPD)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1911.12448\"\n  }, \"https://arxiv.org/abs/1911.12448\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"IPG-Net: Image Pyramid Guidance Network for Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1912.00632\"\n  }, \"https://arxiv.org/abs/1912.00632\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1912.02424\"\n  }, \"https://arxiv.org/abs/1912.02424\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/sfzhang15/ATSS\"\n  }, \"https://github.com/sfzhang15/ATSS\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Localization Uncertainty Estimation for Anchor-Free Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Gaussian-FCOS\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2006.15607\"\n  }, \"https://arxiv.org/abs/2006.15607\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Corner Proposal Network for Anchor-free, Two-stage Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.13816\"\n  }, \"https://arxiv.org/abs/2007.13816\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Duankaiwen/CPNDet\"\n  }, \"https://github.com/Duankaiwen/CPNDet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dive Deeper Into Box for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: DDBNet, anchor free\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.14350\"\n  }, \"https://arxiv.org/abs/2007.14350\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Corner Proposal Network for Anchor-free, Two-stage Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.13816\"\n  }, \"https://arxiv.org/abs/2007.13816\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Duankaiwen/CPNDet\"\n  }, \"https://github.com/Duankaiwen/CPNDet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Reducing Label Noise in Anchor-Free Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2008.01167\"\n  }, \"https://arxiv.org/abs/2008.01167\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/nerminsamet/ppdet\"\n  }, \"https://github.com/nerminsamet/ppdet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Balance-Oriented Focal Loss with Linear Scheduling for Anchor Free Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2012.13763\"\n  }, \"https://arxiv.org/abs/2012.13763\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PAFNet: An Efficient Anchor-Free Object Detector Guidance\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Baidu Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.13534\"\n  }, \"https://arxiv.org/abs/2104.13534\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/PaddlePaddle/PaddleDetection\"\n  }, \"https://github.com/PaddlePaddle/PaddleDetection\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pseudo-IoU: Improving Label Assignment in Anchor-Free Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021 Workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: UIUC & MIT-IBM Watson AI Lab & IBM T.J. Watson Research Center & NVIDIA & University of Oregon & Picsart AI Research (PAIR)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.14082\"\n  }, \"https://arxiv.org/abs/2104.14082\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ObjectBox: From Centers to Boxes for Anchor-Free Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2022 Oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Ingenuity Labs Research Institute & Queen\\u2019s University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2207.06985\"\n  }, \"https://arxiv.org/abs/2207.06985\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MohsenZand/ObjectBox\"\n  }, \"https://github.com/MohsenZand/ObjectBox\"))), mdx(\"h1\", {\n    \"id\": \"transformers\"\n  }, \"Transformers\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End-to-End Object Detection with Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Facebook AI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: DEtection TRansformer (DETR)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2005.12872\"\n  }, \"https://arxiv.org/abs/2005.12872\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/facebookresearch/detr\"\n  }, \"https://github.com/facebookresearch/detr\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deformable DETR: Deformable Transformers for End-to-End Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SenseTime Research & USTC & CUHK\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2010.04159\"\n  }, \"https://arxiv.org/abs/2010.04159\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/fundamentalvision/Deformable-DETR\"\n  }, \"https://github.com/fundamentalvision/Deformable-DETR\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RelationNet++: Bridging Visual Representations for Object Detection via Transformer Decoder\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS2020 Spotlight\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CAS & MSRA\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2010.15831\"\n  }, \"https://arxiv.org/abs/2010.15831\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github:\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/microsoft/RelationNet2\"\n  }, \"https://github.com/microsoft/RelationNet2\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"UP-DETR: Unsupervised Pre-training for Object Detection with Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: South China University of Technology & Tencent Wechat AI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.09094\"\n  }, \"https://arxiv.org/abs/2011.09094\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Conditional DETR for Fast Training Convergence\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Science and Technology of China & Peking University & Microsoft Research Asia\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2108.06152\"\n  }, \"https://arxiv.org/abs/2108.06152\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Atten4Vis/ConditionalDETR\"\n  }, \"https://github.com/Atten4Vis/ConditionalDETR\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End-to-End Object Detection with Adaptive Clustering Transformer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Peking University & The Chinese University of Hong Kong\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.09315\"\n  }, \"https://arxiv.org/abs/2011.09315\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Toward Transformer-Based Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Pinterest\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: ViT-FRCNN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.09958\"\n  }, \"https://arxiv.org/abs/2012.09958\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Efficient DETR: Improving End-to-End Object Detector with Dense Prior\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Megvii Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.01318\"\n  }, \"https://arxiv.org/abs/2104.01318\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Anchor DETR: Query Design for Transformer-Based Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MEGVII Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2109.07107\"\n  }, \"https://arxiv.org/abs/2109.07107\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gihtub: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/megvii-model/AnchorDETR\"\n  }, \"https://github.com/megvii-model/AnchorDETR\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2201.12329\"\n  }, \"https://arxiv.org/abs/2201.12329\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/SlongLiu/DAB-DETR\"\n  }, \"https://github.com/SlongLiu/DAB-DETR\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2203.03605\"\n  }, \"https://arxiv.org/abs/2203.03605\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/IDEACVR/DINO\"\n  }, \"https://github.com/IDEACVR/DINO\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Oriented Object Detection with Transformer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University at Buffalo & Beihang University & Baidu Inc\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2106.03146\"\n  }, \"https://arxiv.org/abs/2106.03146\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ViDT: An Efficient and Effective Fully Transformer-based Object Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NAVER AI Lab & Google Research & University of California at Merced\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2110.03921\"\n  }, \"https://arxiv.org/abs/2110.03921\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/naver-ai/vidt\"\n  }, \"https://github.com/naver-ai/vidt\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An Extendable, Efficient and Effective Transformer-based Object Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2204.07962\"\n  }, \"https://arxiv.org/abs/2204.07962\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/naver-ai/vidt\"\n  }, \"https://github.com/naver-ai/vidt\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Omni-DETR: Omni-Supervised Object Detection with Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2203.16089\"\n  }, \"https://arxiv.org/abs/2203.16089\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Accelerating DETR Convergence via Semantic-Aligned Matching\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2203.06883\"\n  }, \"https://arxiv.org/abs/2203.06883\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ZhangGongjie/SAM-DETR\"\n  }, \"https://github.com/ZhangGongjie/SAM-DETR\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AdaMixer: A Fast-Converging Query-Based Object Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Nanjing University, MYbank Ant Group\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2203.16507\"\n  }, \"https://arxiv.org/abs/2203.16507\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MCG-NJU/AdaMixer\"\n  }, \"https://github.com/MCG-NJU/AdaMixer\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Exploring Plain Vision Transformer Backbones for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Facebook AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2203.16527\"\n  }, \"https://arxiv.org/abs/2203.16527\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Efficient Decoder-free Object Detection with Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro:  Tencent Youtu Lab & Zhejiang University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2206.06829\"\n  }, \"https://arxiv.org/abs/2206.06829\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Pealing/DFFT\"\n  }, \"https://github.com/Pealing/DFFT\"))), mdx(\"h1\", {\n    \"id\": \"non-maximum-suppression-nms\"\n  }, \"Non-Maximum Suppression (NMS)\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End-to-End Integration of a Convolutional Network, Deformable Parts Model and Non-Maximum Suppression\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1411.5309\"\n  }, \"http://arxiv.org/abs/1411.5309\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Wan_End-to-End_Integration_of_2015_CVPR_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Wan_End-to-End_Integration_of_2015_CVPR_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A convnet for non-maximum suppression\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1511.06437\"\n  }, \"http://arxiv.org/abs/1511.06437\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improving Object Detection With One Line of Code\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Soft-NMS -- Improving Object Detection With One Line of Code\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017. University of Maryland\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Soft-NMS\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.04503\"\n  }, \"https://arxiv.org/abs/1704.04503\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bharatsingh430/soft-nms\"\n  }, \"https://github.com/bharatsingh430/soft-nms\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Softer-NMS: Rethinking Bounding Box Regression for Accurate Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CMU & Megvii Inc. (Face++)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1809.08545\"\n  }, \"https://arxiv.org/abs/1809.08545\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yihui-he/softer-NMS\"\n  }, \"https://github.com/yihui-he/softer-NMS\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning non-maximum suppression\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/object-recognition-and-scene-understanding/learning-nms/\"\n  }, \"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/object-recognition-and-scene-understanding/learning-nms/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1705.02950\"\n  }, \"https://arxiv.org/abs/1705.02950\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hosang/gossipnet\"\n  }, \"https://github.com/hosang/gossipnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Relation Networks for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.11575\"\n  }, \"https://arxiv.org/abs/1711.11575\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, MXNet): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/msracver/Relation-Networks-for-Object-Detection\"\n  }, \"https://github.com/msracver/Relation-Networks-for-Object-Detection\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Pairwise Relationship for Multi-object Detection in Crowded Scenes\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Pairwise-NMS\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.03796\"\n  }, \"https://arxiv.org/abs/1901.03796\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Daedalus: Breaking Non-Maximum Suppression in Object Detection via Adversarial Examples\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1902.02067\"\n  }, \"https://arxiv.org/abs/1902.02067\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"NMS by Representative Region: Towards Crowded Pedestrian Detection by Proposal Pairing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Waseda University & Tencent AI Lab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.12729\"\n  }, \"https://arxiv.org/abs/2003.12729\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hashing-based Non-Maximum Suppression for Crowded Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Microsoft\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2005.11426\"\n  }, \"https://arxiv.org/abs/2005.11426\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/microsoft/hnms\"\n  }, \"https://github.com/microsoft/hnms\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Visibility Guided NMS: Efficient Boosting of Amodal Object Detection in Crowded Traffic Scenes\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2019, Machine Learning for Autonomous Driving Workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Mercedes-Benz AG, R&D & University of Jena\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Visibility Guided NMS (vg-NMS)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2006.08547\"\n  }, \"https://arxiv.org/abs/2006.08547\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Determinantal Point Process as an alternative to NMS\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2008.11451\"\n  }, \"https://arxiv.org/abs/2008.11451\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression Grounding\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Zhejiang University & Nanyang Technological University & Tencent AI Lab & Columbia University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2009.01449\"\n  }, \"https://arxiv.org/abs/2009.01449\"))), mdx(\"h1\", {\n    \"id\": \"nms-free\"\n  }, \"NMS-free\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Detection Made Simpler by Eliminating Heuristic NMS\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Alibaba Group & Monash University & The University of Adelaide\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2101.11782\"\n  }, \"https://arxiv.org/abs/2101.11782\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/txdet/FCOSPss\"\n  }, \"https://github.com/txdet/FCOSPss\"))), mdx(\"h1\", {\n    \"id\": \"adversarial-examples\"\n  }, \"Adversarial Examples\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Adversarial Examples that Fool Detectors\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Illinois\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.02494\"\n  }, \"https://arxiv.org/abs/1712.02494\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://nicholas.carlini.com/code/nn_breaking_detection/\"\n  }, \"http://nicholas.carlini.com/code/nn_breaking_detection/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1705.07263\"\n  }, \"https://arxiv.org/abs/1705.07263\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/carlini/nn_breaking_detection\"\n  }, \"https://github.com/carlini/nn_breaking_detection\"))), mdx(\"h1\", {\n    \"id\": \"knowledge-distillation\"\n  }, \"Knowledge Distillation\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mimicking Very Efficient Network for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017. SenseTime & Beihang University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Mimicking_Very_Efficient_CVPR_2017_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Mimicking_Very_Efficient_CVPR_2017_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Quantization Mimic: Towards Very Tiny CNN for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.02152\"\n  }, \"https://arxiv.org/abs/1805.02152\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Efficient Detector with Semi-supervised Adaptive Distillation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SenseTime Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.00366\"\n  }, \"https://arxiv.org/abs/1901.00366\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Tangshitao/Semi-supervised-Adaptive-Distillation\"\n  }, \"https://github.com/Tangshitao/Semi-supervised-Adaptive-Distillation\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Distilling Object Detectors with Fine-grained Feature Imitation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: National University of Singapore & Huawei Noah\\u2019s Ark Lab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: mimic\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1906.03609\"\n  }, \"https://arxiv.org/abs/1906.03609\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/twangnh/Distilling-Object-Detectors\"\n  }, \"https://github.com/twangnh/Distilling-Object-Detectors\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"GAN-Knowledge Distillation for one-stage Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1906.08467\"\n  }, \"https://arxiv.org/abs/1906.08467\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Lightweight Pedestrian Detector with Hierarchical Knowledge Distillation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICIP 2019 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.09325\"\n  }, \"https://arxiv.org/abs/1909.09325\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improve Object Detection with Feature-based Knowledge Distillation: Towards Accurate and Efficient Detectors\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR 2021 poster\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"openreview: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://openreview.net/forum?id=uKhGRvM8QNH\"\n  }, \"https://openreview.net/forum?id=uKhGRvM8QNH\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://openreview.net/pdf?id=uKhGRvM8QNH\"\n  }, \"https://openreview.net/pdf?id=uKhGRvM8QNH\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ArchipLab-LinfengZhang/Object-Detection-Knowledge-Distillation-ICLR2021\"\n  }, \"https://github.com/ArchipLab-LinfengZhang/Object-Detection-Knowledge-Distillation-ICLR2021\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"G-DetKD: Towards General Distillation Framework for Object Detectors via Contrastive and Semantic-guided Feature Imitation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Hong Kong University of Science and Technology & Huawei Noah\\u2019s Ark Lab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2108.07482\"\n  }, \"https://arxiv.org/abs/2108.07482\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"LGD: Label-guided Self-distillation for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MEGVII Technology & Xi\\u2019an Jiaotong University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2109.11496\"\n  }, \"https://arxiv.org/abs/2109.11496\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Structured Instance Graph for Distilling Object Detectors\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The Chinese University of Hong Kong & SmartMore\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2109.12862\"\n  }, \"https://arxiv.org/abs/2109.12862\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/dvlab-research/Dsig\"\n  }, \"https://github.com/dvlab-research/Dsig\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Instance-Conditional Knowledge Distillation for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2021 poster\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Xi\\u2019an Jiaotong University & MEGVII Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2110.12724\"\n  }, \"https://arxiv.org/abs/2110.12724\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Distilling Object Detectors with Feature Richness\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Science and Technology of China & CAS & Cambricon Technologies & University of Chinese Academy of Sciences\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2111.00674\"\n  }, \"https://arxiv.org/abs/2111.00674\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Focal and Global Knowledge Distillation for Detectors\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tsinghua Shenzhen International Graduate School & ByteDance Inc & BeiHang University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2111.11837\"\n  }, \"https://arxiv.org/abs/2111.11837\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yzd-v/FGD\"\n  }, \"https://github.com/yzd-v/FGD\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Prediction-Guided Distillation for Dense Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Edinburgh & Heriot-Watt University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2203.05469\"\n  }, \"https://arxiv.org/abs/2203.05469\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ChenhongyiYang/PGD\"\n  }, \"https://github.com/ChenhongyiYang/PGD\"))), mdx(\"h1\", {\n    \"id\": \"rotated-object-detection\"\n  }, \"Rotated Object Detection\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rethinking Rotated Object Detection with Gaussian Wasserstein Distance Loss\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Shanghai Jiao Tong University & Huawei Inc. & Beijing Institute of Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2101.11952\"\n  }, \"https://arxiv.org/abs/2101.11952\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yangxue0827/RotationDetection\"\n  }, \"https://github.com/yangxue0827/RotationDetection\"))), mdx(\"h1\", {\n    \"id\": \"long-tailed-object-detection\"\n  }, \"Long-Tailed Object Detection\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Factors in Finetuning Deep Model for object detection\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Factors in Finetuning Deep Model for Object Detection with Long-tail Distribution\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016.rank 3rd for provided data and 2nd for external data on ILSVRC 2015 object detection\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.ee.cuhk.edu.hk/~wlouyang/projects/ImageNetFactors/CVPR16.html\"\n  }, \"http://www.ee.cuhk.edu.hk/~wlouyang/projects/ImageNetFactors/CVPR16.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1601.05150\"\n  }, \"http://arxiv.org/abs/1601.05150\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Overcoming Classifier Imbalance for Long-tail Object Detection with Balanced Group Softmax\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2006.10408\"\n  }, \"https://arxiv.org/abs/2006.10408\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/FishYuLi/BalancedGroupSoftmax\"\n  }, \"https://github.com/FishYuLi/BalancedGroupSoftmax\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Equalization Loss v2: A New Gradient Balance Approach for Long-tailed Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tongji University & SenseTime Research & Tsinghua University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.08548\"\n  }, \"https://arxiv.org/abs/2012.08548\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Simple and Effective Use of Object-Centric Images for Long-Tailed Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The Ohio State University & University of Central Florida & University of Southern California & Google Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2102.08884\"\n  }, \"https://arxiv.org/abs/2102.08884\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Adaptive Class Suppression Loss for Long-Tail Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.00885\"\n  }, \"https://arxiv.org/abs/2104.00885\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/CASIA-IVA-Lab/ACSL\"\n  }, \"https://github.com/CASIA-IVA-Lab/ACSL\"))), mdx(\"h1\", {\n    \"id\": \"weakly-supervised-object-detection\"\n  }, \"Weakly Supervised Object Detection\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Track and Transfer: Watching Videos to Simulate Strong Human Supervision for Weakly-Supervised Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1604.05766\"\n  }, \"http://arxiv.org/abs/1604.05766\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Weakly supervised object detection using pseudo-strong labels\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1607.04731\"\n  }, \"http://arxiv.org/abs/1607.04731\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Saliency Guided End-to-End Learning for Weakly Supervised Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IJCAI 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.06768\"\n  }, \"https://arxiv.org/abs/1706.06768\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Visual and Semantic Knowledge Transfer for Large Scale Semi-supervised Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: TPAMI 2017. National Institutes of Health (NIH) Clinical Center\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.03145\"\n  }, \"https://arxiv.org/abs/1801.03145\"))), mdx(\"h1\", {\n    \"id\": \"video-object-detection\"\n  }, \"Video Object Detection\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Object Class Detectors from Weakly Annotated Video\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2012\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.vision.ee.ethz.ch/publications/papers/proceedings/eth_biwi_00905.pdf\"\n  }, \"https://www.vision.ee.ethz.ch/publications/papers/proceedings/eth_biwi_00905.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Analysing domain shift factors between videos and images for object detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1501.01186\"\n  }, \"https://arxiv.org/abs/1501.01186\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video Object Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://vision.princeton.edu/courses/COS598/2015sp/slides/VideoRecog/Video%20Object%20Recognition.pptx\"\n  }, \"http://vision.princeton.edu/courses/COS598/2015sp/slides/VideoRecog/Video%20Object%20Recognition.pptx\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning for Saliency Prediction in Natural Video\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Submitted on 12 Jan 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Deep learning, saliency map, optical flow, convolution network, contrast features\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://hal.archives-ouvertes.fr/hal-01251614/document\"\n  }, \"https://hal.archives-ouvertes.fr/hal-01251614/document\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"T-CNN: Tubelets with Convolutional Neural Networks for Object Detection from Videos\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Winning solution in ILSVRC2015 Object Detection from Video(VID) Task\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1604.02532\"\n  }, \"http://arxiv.org/abs/1604.02532\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/myfavouritekk/T-CNN\"\n  }, \"https://github.com/myfavouritekk/T-CNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Detection from Video Tubelets with Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016 Spotlight paper\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1604.04053\"\n  }, \"https://arxiv.org/abs/1604.04053\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.ee.cuhk.edu.hk/~wlouyang/Papers/KangVideoDet_CVPR16.pdf\"\n  }, \"http://www.ee.cuhk.edu.hk/~wlouyang/Papers/KangVideoDet_CVPR16.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gihtub: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/myfavouritekk/vdetlib\"\n  }, \"https://github.com/myfavouritekk/vdetlib\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Detection in Videos with Tubelets and Multi-context Cues\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SenseTime Group\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.ee.cuhk.edu.hk/~xgwang/CUvideo.pdf\"\n  }, \"http://www.ee.cuhk.edu.hk/~xgwang/CUvideo.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://image-net.org/challenges/talks/Object%20Detection%20in%20Videos%20with%20Tubelets%20and%20Multi-context%20Cues%20-%20Final.pdf\"\n  }, \"http://image-net.org/challenges/talks/Object%20Detection%20in%20Videos%20with%20Tubelets%20and%20Multi-context%20Cues%20-%20Final.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Context Matters: Refining Object Detection in Video with Recurrent Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: pseudo-labeler\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1607.04648\"\n  }, \"http://arxiv.org/abs/1607.04648\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://vision.cornell.edu/se3/wp-content/uploads/2016/07/video_object_detection_BMVC.pdf\"\n  }, \"http://vision.cornell.edu/se3/wp-content/uploads/2016/07/video_object_detection_BMVC.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CNN Based Object Detection in Large Video Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: WangTao @ \\u7231\\u5947\\u827A\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: object retrieval, object detection, scene classification\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://on-demand.gputechconf.com/gtc/2016/presentation/s6362-wang-tao-cnn-based-object-detection-large-video-images.pdf\"\n  }, \"http://on-demand.gputechconf.com/gtc/2016/presentation/s6362-wang-tao-cnn-based-object-detection-large-video-images.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Detection in Videos with Tubelet Proposal Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.06355\"\n  }, \"https://arxiv.org/abs/1702.06355\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Flow-Guided Feature Aggregation for Video Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MSRA\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.10025\"\n  }, \"https://arxiv.org/abs/1703.10025\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video Object Detection using Faster R-CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://andrewliao11.github.io/object_detection/faster_rcnn/\"\n  }, \"http://andrewliao11.github.io/object_detection/faster_rcnn/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/andrewliao11/py-faster-rcnn-imagenet\"\n  }, \"https://github.com/andrewliao11/py-faster-rcnn-imagenet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improving Context Modeling for Video Object Detection and Tracking\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://image-net.org/challenges/talks_2017/ilsvrc2017_short(poster).pdf\"\n  }, \"http://image-net.org/challenges/talks_2017/ilsvrc2017_short(poster).pdf\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Temporal Dynamic Graph LSTM for Action-driven Video Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.00666\"\n  }, \"https://arxiv.org/abs/1708.00666\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mobile Video Object Detection with Temporally-Aware Feature Maps\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.06368\"\n  }, \"https://arxiv.org/abs/1711.06368\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards High Performance Video Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.11577\"\n  }, \"https://arxiv.org/abs/1711.11577\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Impression Network for Video Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.05896\"\n  }, \"https://arxiv.org/abs/1712.05896\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spatial-Temporal Memory Networks for Video Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.06317\"\n  }, \"https://arxiv.org/abs/1712.06317\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"3D-DETNet: a Single Stage Video-Based Vehicle Detector\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1801.01769\"\n  }, \"https://arxiv.org/abs/1801.01769\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Detection in Videos by Short and Long Range Object Linking\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1801.09823\"\n  }, \"https://arxiv.org/abs/1801.09823\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Detection in Video with Spatiotemporal Sampling Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Pennsylvania, 2Dartmouth College\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.05549\"\n  }, \"https://arxiv.org/abs/1803.05549\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards High Performance Video Object Detection for Mobiles\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Microsoft Research Asia\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.05830\"\n  }, \"https://arxiv.org/abs/1804.05830\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Optimizing Video Object Detection via a Scale-Time Lattice\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mmlab.ie.cuhk.edu.hk/projects/ST-Lattice/\"\n  }, \"http://mmlab.ie.cuhk.edu.hk/projects/ST-Lattice/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.05472\"\n  }, \"https://arxiv.org/abs/1804.05472\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hellock/scale-time-lattice\"\n  }, \"https://github.com/hellock/scale-time-lattice\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pack and Detect: Fast Object Detection in Videos Using Region-of-Interest Packing\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1809.01701\"\n  }, \"https://arxiv.org/abs/1809.01701\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast Object Detection in Compressed Video\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.11057\"\n  }, \"https://arxiv.org/abs/1811.11057\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Tube-CNN: Modeling temporal evolution of appearance for object detection in video\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: INRIA/ENS\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1812.02619\"\n  }, \"https://arxiv.org/abs/1812.02619\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AdaScale: Towards Real-time Video Object Detection Using Adaptive Scaling\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SysML 2019 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1902.02910\"\n  }, \"https://arxiv.org/abs/1902.02910\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SCNN: A General Distribution based Statistical Convolutional Neural Network with Application to Video Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.07663\"\n  }, \"https://arxiv.org/abs/1903.07663\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Looking Fast and Slow: Memory-Guided Mobile Video Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Cornell University & Google AI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.10172\"\n  }, \"https://arxiv.org/abs/1903.10172\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Progressive Sparse Local Attention for Video object detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NLPR,CASIA & Horizon Robotics\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.09126\"\n  }, \"https://arxiv.org/abs/1903.09126\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sequence Level Semantics Aggregation for Video Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.06390\"\n  }, \"https://arxiv.org/abs/1907.06390\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(MXNet): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/happywu/Sequence-Level-Semantics-Aggregation\"\n  }, \"https://github.com/happywu/Sequence-Level-Semantics-Aggregation\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Detection in Video with Spatial-temporal Context Aggregation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Huazhong University of Science and Technology & Horizon Robotics Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.04988\"\n  }, \"https://arxiv.org/abs/1907.04988\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Delay Metric for Video Object Detection: What Average Precision Fails to Tell\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1908.06368\"\n  }, \"https://arxiv.org/abs/1908.06368\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Minimum Delay Object Detection From Video\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1908.11092\"\n  }, \"https://arxiv.org/abs/1908.11092\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Motion Priors for Efficient Video Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1911.05253\"\n  }, \"https://arxiv.org/abs/1911.05253\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object-aware Feature Aggregation for Video Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Beihang University & Capital Normal University & The University of Hong Kong & Baidu, Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2010.12573\"\n  }, \"https://arxiv.org/abs/2010.12573\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End-to-End Video Object Detection with Spatial-Temporal Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2105.10920\"\n  }, \"https://arxiv.org/abs/2105.10920\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/SJTU-LuHe/TransVOD\"\n  }, \"https://github.com/SJTU-LuHe/TransVOD\"))), mdx(\"h1\", {\n    \"id\": \"object-detection-on-mobile-devices\"\n  }, \"Object Detection on Mobile Devices\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pelee: A Real-Time Object Detection System on Mobile Devices\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR 2018 workshop track\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: based on the SSD\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.06882\"\n  }, \"https://arxiv.org/abs/1804.06882\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Robert-JunWang/Pelee\"\n  }, \"https://github.com/Robert-JunWang/Pelee\"))), mdx(\"h1\", {\n    \"id\": \"object-detection-on-rgb-d\"\n  }, \"Object Detection on RGB-D\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Rich Features from RGB-D Images for Object Detection and Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1407.5736\"\n  }, \"http://arxiv.org/abs/1407.5736\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Differential Geometry Boosts Convolutional Neural Networks for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2016_workshops/w23/html/Wang_Differential_Geometry_Boosts_CVPR_2016_paper.html\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2016_workshops/w23/html/Wang_Differential_Geometry_Boosts_CVPR_2016_paper.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Self-supervised Learning System for Object Detection using Physics Simulation and Multi-view Pose Estimation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1703.03347\"\n  }, \"https://arxiv.org/abs/1703.03347\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cross-Modal Attentional Context Learning for RGB-D Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IEEE Transactions on Image Processing\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1810.12829\"\n  }, \"https://arxiv.org/abs/1810.12829\"))), mdx(\"h1\", {\n    \"id\": \"zero-shot-object-detection\"\n  }, \"Zero-Shot Object Detection\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Zero-Shot Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Australian National University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: YOLO\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.07113\"\n  }, \"https://arxiv.org/abs/1803.07113\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Zero-Shot Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1804.04340\"\n  }, \"https://arxiv.org/abs/1804.04340\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Zero-Shot Object Detection: Learning to Simultaneously Recognize and Localize Novel Concepts\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Australian National University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.06049\"\n  }, \"https://arxiv.org/abs/1803.06049\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Zero-Shot Object Detection by Hybrid Region Embedding\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Middle East Technical University & Hacettepe University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.06157\"\n  }, \"https://arxiv.org/abs/1805.06157\"))), mdx(\"h1\", {\n    \"id\": \"visual-relationship-detection\"\n  }, \"Visual Relationship Detection\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Visual Relationship Detection with Language Priors\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://cs.stanford.edu/people/ranjaykrishna/vrd/vrd.pdf\"\n  }, \"https://cs.stanford.edu/people/ranjaykrishna/vrd/vrd.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Prof-Lu-Cewu/Visual-Relationship-Detection\"\n  }, \"https://github.com/Prof-Lu-Cewu/Visual-Relationship-Detection\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ViP-CNN: A Visual Phrase Reasoning Convolutional Neural Network for Visual Relationship Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Visual Phrase reasoning Convolutional Neural Network (ViP-CNN), Visual Phrase Reasoning Structure (VPRS)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.07191\"\n  }, \"https://arxiv.org/abs/1702.07191\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Visual Translation Embedding Network for Visual Relation Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.arxiv.org/abs/1702.08319\"\n  }, \"https://www.arxiv.org/abs/1702.08319\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Variation-structured Reinforcement Learning for Visual Relationship and Attribute Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017 spotlight paper\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.03054\"\n  }, \"https://arxiv.org/abs/1703.03054\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Detecting Visual Relationships with Deep Relational Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017 oral. The Chinese University of Hong Kong\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.03114\"\n  }, \"https://arxiv.org/abs/1704.03114\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Identifying Spatial Relations in Images using Convolutional Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1706.04215\"\n  }, \"https://arxiv.org/abs/1706.04215\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PPR-FCN: Weakly Supervised Visual Relation Detection via Parallel Pairwise R-FCN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.01956\"\n  }, \"https://arxiv.org/abs/1708.01956\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Natural Language Guided Visual Relationship Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.06032\"\n  }, \"https://arxiv.org/abs/1711.06032\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Detecting Visual Relationships Using Box Attention\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google AI & IST Austria\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.02136\"\n  }, \"https://arxiv.org/abs/1807.02136\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Google AI Open Images - Visual Relationship Track\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Detect pairs of objects in particular relationships\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"kaggle: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.kaggle.com/c/google-ai-open-images-visual-relationship-track\"\n  }, \"https://www.kaggle.com/c/google-ai-open-images-visual-relationship-track\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Context-Dependent Diffusion Network for Visual Relationship Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: 2018 ACM Multimedia Conference\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1809.06213\"\n  }, \"https://arxiv.org/abs/1809.06213\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Problem Reduction Approach for Visual Relationships Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018 Workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1809.09828\"\n  }, \"https://arxiv.org/abs/1809.09828\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Exploring the Semantics for Visual Relationship Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1904.02104\"\n  }, \"https://arxiv.org/abs/1904.02104\")), mdx(\"h1\", {\n    \"id\": \"face-detection\"\n  }, \"Face Detection\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-view Face Detection Using Deep Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Yahoo\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1502.02766\"\n  }, \"http://arxiv.org/abs/1502.02766\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/guoyilin/FaceDetection_CNN\"\n  }, \"https://github.com/guoyilin/FaceDetection_CNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"From Facial Parts Responses to Face Detection: A Deep Learning Approach\")), mdx(\"img\", {\n    \"src\": \"http://personal.ie.cuhk.edu.hk/~ys014/projects/Faceness/support/index.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2015. CUHK\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://personal.ie.cuhk.edu.hk/~ys014/projects/Faceness/Faceness.html\"\n  }, \"http://personal.ie.cuhk.edu.hk/~ys014/projects/Faceness/Faceness.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1509.06451\"\n  }, \"https://arxiv.org/abs/1509.06451\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Yang_From_Facial_Parts_ICCV_2015_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Yang_From_Facial_Parts_ICCV_2015_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Compact Convolutional Neural Network Cascade for Face Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1508.01292\"\n  }, \"http://arxiv.org/abs/1508.01292\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Bkmz21/FD-Evaluation\"\n  }, \"https://github.com/Bkmz21/FD-Evaluation\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Bkmz21/CompactCNNCascade\"\n  }, \"https://github.com/Bkmz21/CompactCNNCascade\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Face Detection with End-to-End Integration of a ConvNet and a 3D Model\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1606.00850\"\n  }, \"https://arxiv.org/abs/1606.00850\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(MXNet): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tfwu/FaceDetection-ConvNet-3D\"\n  }, \"https://github.com/tfwu/FaceDetection-ConvNet-3D\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CMS-RCNN: Contextual Multi-Scale Region-based CNN for Unconstrained Face Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CMU\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1606.05413\"\n  }, \"https://arxiv.org/abs/1606.05413\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards a Deep Learning Framework for Unconstrained Face Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: overlap with CMS-RCNN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.05322\"\n  }, \"https://arxiv.org/abs/1612.05322\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Supervised Transformer Network for Efficient Face Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1607.05477\"\n  }, \"http://arxiv.org/abs/1607.05477\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"UnitBox: An Advanced Object Detection Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM MM 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Illinois at Urbana\\u2212Champaign & Megvii Inc\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: IOULoss\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.01471\"\n  }, \"http://arxiv.org/abs/1608.01471\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bootstrapping Face Detection with Hard Negative Examples\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"author: \\u4E07\\u97F6\\u534E @ \\u5C0F\\u7C73.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Faster R-CNN, hard negative mining. state-of-the-art on the FDDB dataset\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.02236\"\n  }, \"http://arxiv.org/abs/1608.02236\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Grid Loss: Detecting Occluded Faces\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1609.00129\"\n  }, \"https://arxiv.org/abs/1609.00129\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://lrs.icg.tugraz.at/pubs/opitz_eccv_16.pdf\"\n  }, \"http://lrs.icg.tugraz.at/pubs/opitz_eccv_16.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"poster: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.eccv2016.org/files/posters/P-2A-34.pdf\"\n  }, \"http://www.eccv2016.org/files/posters/P-2A-34.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Multi-Scale Cascade Fully Convolutional Network Face Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICPR 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.03536\"\n  }, \"http://arxiv.org/abs/1609.03536\"))), mdx(\"h2\", {\n    \"id\": \"mtcnn\"\n  }, \"MTCNN\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Neural Networks\")), mdx(\"img\", {\n    \"src\": \"https://kpzhang93.github.io/MTCNN_face_detection_alignment/support/index.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://kpzhang93.github.io/MTCNN_face_detection_alignment/index.html\"\n  }, \"https://kpzhang93.github.io/MTCNN_face_detection_alignment/index.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1604.02878\"\n  }, \"https://arxiv.org/abs/1604.02878\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, Matlab): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kpzhang93/MTCNN_face_detection_alignment\"\n  }, \"https://github.com/kpzhang93/MTCNN_face_detection_alignment\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/pangyupo/mxnet_mtcnn_face_detection\"\n  }, \"https://github.com/pangyupo/mxnet_mtcnn_face_detection\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/DaFuCoding/MTCNN_Caffe\"\n  }, \"https://github.com/DaFuCoding/MTCNN_Caffe\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(MXNet): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Seanlinx/mtcnn\"\n  }, \"https://github.com/Seanlinx/mtcnn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Pi-DeepLearning/RaspberryPi-FaceDetection-MTCNN-Caffe-With-Motion\"\n  }, \"https://github.com/Pi-DeepLearning/RaspberryPi-FaceDetection-MTCNN-Caffe-With-Motion\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Caffe): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/foreverYoungGitHub/MTCNN\"\n  }, \"https://github.com/foreverYoungGitHub/MTCNN\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/CongWeilin/mtcnn-caffe\"\n  }, \"https://github.com/CongWeilin/mtcnn-caffe\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(OpenCV+OpenBlas): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/AlphaQi/MTCNN-light\"\n  }, \"https://github.com/AlphaQi/MTCNN-light\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Tensorflow+golang): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jdeng/goface\"\n  }, \"https://github.com/jdeng/goface\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Face Detection using Deep Learning: An Improved Faster RCNN Approach\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: DeepIR Inc\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.08289\"\n  }, \"https://arxiv.org/abs/1701.08289\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Faceness-Net: Face Detection through Deep Facial Part Responses\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: An extended version of ICCV 2015 paper\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.08393\"\n  }, \"https://arxiv.org/abs/1701.08393\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Path Region-Based Convolutional Neural Network for Accurate Detection of Unconstrained \\\"Hard Faces\\\"\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017. MP-RCNN, MP-RPN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.09145\"\n  }, \"https://arxiv.org/abs/1703.09145\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End-To-End Face Detection and Recognition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1703.10818\"\n  }, \"https://arxiv.org/abs/1703.10818\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Face R-CNN\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1706.01061\"\n  }, \"https://arxiv.org/abs/1706.01061\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Face Detection through Scale-Friendly Deep Convolutional Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1706.02863\"\n  }, \"https://arxiv.org/abs/1706.02863\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scale-Aware Face Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017. SenseTime & Tsinghua University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.09876\"\n  }, \"https://arxiv.org/abs/1706.09876\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Detecting Faces Using Inside Cascaded Contextual CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017. Tencent AI Lab & SenseTime\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://ai.tencent.com/ailab/media/publications/Detecting_Faces_Using_Inside_Cascaded_Contextual_CNN.pdf\"\n  }, \"http://ai.tencent.com/ailab/media/publications/Detecting_Faces_Using_Inside_Cascaded_Contextual_CNN.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Branch Fully Convolutional Network for Face Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1707.06330\"\n  }, \"https://arxiv.org/abs/1707.06330\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SSH: Single Stage Headless Face Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017. University of Maryland\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.03979\"\n  }, \"https://arxiv.org/abs/1708.03979\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, Caffe): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mahyarnajibi/SSH\"\n  }, \"https://github.com/mahyarnajibi/SSH\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dockerface: an easy to install and use Faster R-CNN face detector in a Docker container\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1708.04370\"\n  }, \"https://arxiv.org/abs/1708.04370\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FaceBoxes: A CPU Real-time Face Detector with High Accuracy\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IJCB 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Rapidly Digested Convolutional Layers (RDCL), Multiple Scale Convolutional Layers (MSCL)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: the proposed detector runs at 20 FPS on a single CPU core and 125 FPS using a GPU for VGA-resolution images\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.05234\"\n  }, \"https://arxiv.org/abs/1708.05234\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/sfzhang15/FaceBoxes\"\n  }, \"https://github.com/sfzhang15/FaceBoxes\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Caffe): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zeusees/FaceBoxes\"\n  }, \"https://github.com/zeusees/FaceBoxes\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"S3FD: Single Shot Scale-invariant Face Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017. Chinese Academy of Sciences\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: can run at 36 FPS on a Nvidia Titan X (Pascal) for VGA-resolution images\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.05237\"\n  }, \"https://arxiv.org/abs/1708.05237\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Caffe, official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/sfzhang15/SFD\"\n  }, \"https://github.com/sfzhang15/SFD\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com//clcarwin/SFD_pytorch\"\n  }, \"https://github.com//clcarwin/SFD_pytorch\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Detecting Faces Using Region-based Fully Convolutional Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.05256\"\n  }, \"https://arxiv.org/abs/1709.05256\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AffordanceNet: An End-to-End Deep Learning Approach for Object Affordance Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.07326\"\n  }, \"https://arxiv.org/abs/1709.07326\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Face Attention Network: An effective Face Detector for the Occluded Faces\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.07246\"\n  }, \"https://arxiv.org/abs/1711.07246\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Feature Agglomeration Networks for Single Stage Face Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.00721\"\n  }, \"https://arxiv.org/abs/1712.00721\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Face Detection Using Improved Faster RCNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Huawei Cloud BU\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1802.02142\"\n  }, \"https://arxiv.org/abs/1802.02142\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PyramidBox: A Context-assisted Single Shot Face Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Baidu, Inc\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.07737\"\n  }, \"https://arxiv.org/abs/1803.07737\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PyramidBox++: High Performance Detector for Finding Tiny Face\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Chinese Academy of Sciences & Baidu, Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.00386\"\n  }, \"https://arxiv.org/abs/1904.00386\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Fast Face Detection Method via Convolutional Neural Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Neurocomputing\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.10103\"\n  }, \"https://arxiv.org/abs/1803.10103\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Beyond Trade-off: Accelerate FCN-based Face Detector with Higher Accuracy\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018. Beihang University & CUHK & Sensetime\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.05197\"\n  }, \"https://arxiv.org/abs/1804.05197\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Real-Time Rotation-Invariant Face Detection with Progressive Calibration Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.06039\"\n  }, \"https://arxiv.org/abs/1804.06039\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(binary library): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Jack-CV/PCN\"\n  }, \"https://github.com/Jack-CV/PCN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SFace: An Efficient Network for Face Detection in Large Scale Variations\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Beihang University & Megvii Inc. (Face++)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.06559\"\n  }, \"https://arxiv.org/abs/1804.06559\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Survey of Face Detection on Low-quality Images\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1804.07362\"\n  }, \"https://arxiv.org/abs/1804.07362\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Anchor Cascade for Efficient Face Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The University of Sydney\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.03363\"\n  }, \"https://arxiv.org/abs/1805.03363\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Adversarial Attacks on Face Detectors using Neural Net based Constrained Optimization\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IEEE MMSP\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.12302\"\n  }, \"https://arxiv.org/abs/1805.12302\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Selective Refinement Network for High Performance Face Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1809.02693\"\n  }, \"https://arxiv.org/abs/1809.02693\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DSFD: Dual Shot Face Detector\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1810.10220\"\n  }, \"https://arxiv.org/abs/1810.10220\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Better Features for Face Detection with Feature Fusion and Segmentation Supervision\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.08557\"\n  }, \"https://arxiv.org/abs/1811.08557\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FA-RPN: Floating Region Proposals for Face Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1812.05586\"\n  }, \"https://arxiv.org/abs/1812.05586\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Robust and High Performance Face Detector\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1901.02350\"\n  }, \"https://arxiv.org/abs/1901.02350\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DAFE-FD: Density Aware Feature Enrichment for Face Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1901.05375\"\n  }, \"https://arxiv.org/abs/1901.05375\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improved Selective Refinement Network for Face Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Chinese Academy of Sciences & JD AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.06651\"\n  }, \"https://arxiv.org/abs/1901.06651\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Revisiting a single-stage method for face detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1902.01559\"\n  }, \"https://arxiv.org/abs/1902.01559\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MSFD:Multi-Scale Receptive Field Face Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.04147\"\n  }, \"https://arxiv.org/abs/1903.04147\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"LFFD: A Light and Fast Face Detector for Edge Devices\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.10633\"\n  }, \"https://arxiv.org/abs/1904.10633\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/YonghaoHe/A-Light-and-Fast-Face-Detector-for-Edge-Devices\"\n  }, \"https://github.com/YonghaoHe/A-Light-and-Fast-Face-Detector-for-Edge-Devices\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RetinaFace: Single-stage Dense Face Localisation in the Wild\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1905.00641\"\n  }, \"https://arxiv.org/abs/1905.00641\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gihtub: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/deepinsight/insightface/tree/master/RetinaFace\"\n  }, \"https://github.com/deepinsight/insightface/tree/master/RetinaFace\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BlazeFace: Sub-millisecond Neural Face Detection on Mobile GPUs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR Workshop on Computer Vision for Augmented and Virtual Reality, 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.05047\"\n  }, \"https://arxiv.org/abs/1907.05047\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"HAMBox: Delving into Online High-quality Anchors Mining for Detecting Outer Faces\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Baidu Inc. &  Chinese Academy of Sciences\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1912.09231\"\n  }, \"https://arxiv.org/abs/1912.09231\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"KPNet: Towards Minimal Face Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.07543\"\n  }, \"https://arxiv.org/abs/2003.07543\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ASFD: Automatic and Scalable Face Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Youtu Lab, Tencent & Southeast University & Xiamen University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.11228\"\n  }, \"https://arxiv.org/abs/2003.11228\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TinaFace: Strong but Simple Baseline for Face Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Media Intelligence Technology Co.,Ltd\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.13183\"\n  }, \"https://arxiv.org/abs/2011.13183\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(PyTorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Media-Smart/vedadet\"\n  }, \"https://github.com/Media-Smart/vedadet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MogFace: Rethinking Scale Augmentation on the Face Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Alibaba Group & Imperial College\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.11139\"\n  }, \"https://arxiv.org/abs/2103.11139\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"HLA-Face: Joint High-Low Adaptation for Low Light Face Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Peking University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://daooshee.github.io/HLA-Face-Website/\"\n  }, \"https://daooshee.github.io/HLA-Face-Website/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.01984\"\n  }, \"https://arxiv.org/abs/2104.01984\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/daooshee/HLA-Face-Code\"\n  }, \"https://github.com/daooshee/HLA-Face-Code\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"1st Place Solutions for UG2+ Challenge 2021 -- (Semi-)supervised Face detection in the low light condition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tomorrow Advancing Life (TAL) Education Group\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2107.00818\"\n  }, \"https://arxiv.org/abs/2107.00818\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MOS: A Low Latency and Lightweight Framework for Face Detection, Landmark Localization, and Head Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2110.10953\"\n  }, \"https://arxiv.org/abs/2110.10953\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lyp-deeplearning/MOS-Multi-Task-Face-Detect\"\n  }, \"https://github.com/lyp-deeplearning/MOS-Multi-Task-Face-Detect\"))), mdx(\"h2\", {\n    \"id\": \"detect-small-faces\"\n  }, \"Detect Small Faces\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Finding Tiny Faces\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017. CMU\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.cmu.edu/~peiyunh/tiny/index.html\"\n  }, \"http://www.cs.cmu.edu/~peiyunh/tiny/index.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.04402\"\n  }, \"https://arxiv.org/abs/1612.04402\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, Matlab): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/peiyunh/tiny\"\n  }, \"https://github.com/peiyunh/tiny\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(inference-only): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/chinakook/hr101_mxnet\"\n  }, \"https://github.com/chinakook/hr101_mxnet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/cydonia999/Tiny_Faces_in_Tensorflow\"\n  }, \"https://github.com/cydonia999/Tiny_Faces_in_Tensorflow\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Detecting and counting tiny faces\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ENS Paris-Saclay. ExtendedTinyFaces\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Detecting and counting small objects - Analysis, review and application to counting\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.06504\"\n  }, \"https://arxiv.org/abs/1801.06504\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/alexattia/ExtendedTinyFaces\"\n  }, \"https://github.com/alexattia/ExtendedTinyFaces\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Seeing Small Faces from Robust Anchor's Perspective\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1802.09058\"\n  }, \"https://arxiv.org/abs/1802.09058\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Face-MagNet: Magnifying Feature Maps to Detect Small Faces\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: WACV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Face Magnifier Network (Face-MageNet)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.05258\"\n  }, \"https://arxiv.org/abs/1803.05258\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/po0ya/face-magnet\"\n  }, \"https://github.com/po0ya/face-magnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Robust Face Detection via Learning Small Faces on Hard Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Johns Hopkins University & Stanford University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.11662\"\n  }, \"https://arxiv.org/abs/1811.11662\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bairdzhang/smallhardface\"\n  }, \"https://github.com/bairdzhang/smallhardface\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SFA: Small Faces Attention Face Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Jilin University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1812.08402\"\n  }, \"https://arxiv.org/abs/1812.08402\"))), mdx(\"h1\", {\n    \"id\": \"person-head-detection\"\n  }, \"Person Head Detection\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Context-aware CNNs for person head detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.di.ens.fr/willow/research/headdetection/\"\n  }, \"http://www.di.ens.fr/willow/research/headdetection/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1511.07917\"\n  }, \"http://arxiv.org/abs/1511.07917\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aosokin/cnn_head_detection\"\n  }, \"https://github.com/aosokin/cnn_head_detection\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Detecting Heads using Feature Refine Net and Cascaded Multi-scale Architecture\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.09256\"\n  }, \"https://arxiv.org/abs/1803.09256\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Comparison of CNN-based Face and Head Detectors for Real-Time Video Surveillance Applications\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1809.03336\"\n  }, \"https://arxiv.org/abs/1809.03336\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FCHD: A fast and accurate head detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1809.08766\"\n  }, \"https://arxiv.org/abs/1809.08766\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(PyTorch, official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aditya-vora/FCHD-Fully-Convolutional-Head-Detector\"\n  }, \"https://github.com/aditya-vora/FCHD-Fully-Convolutional-Head-Detector\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Relational Learning for Joint Head and Human Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: JointDet, head-body Relationship Discriminating Module (RDM)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.10674\"\n  }, \"https://arxiv.org/abs/1909.10674\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Body-Face Joint Detection via Embedding and Head Hook\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://openaccess.thecvf.com/content/ICCV2021/papers/Wan_Body-Face_Joint_Detection_via_Embedding_and_Head_Hook_ICCV_2021_paper.pdf\"\n  }, \"https://openaccess.thecvf.com/content/ICCV2021/papers/Wan_Body-Face_Joint_Detection_via_Embedding_and_Head_Hook_ICCV_2021_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gihtub: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/AibeeDetect/BFJDet\"\n  }, \"https://github.com/AibeeDetect/BFJDet\"))), mdx(\"h1\", {\n    \"id\": \"pedestrian-detection--people-detection\"\n  }, \"Pedestrian Detection / People Detection\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pedestrian Detection aided by Deep Learning Semantic Tasks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mmlab.ie.cuhk.edu.hk/projects/TA-CNN/\"\n  }, \"http://mmlab.ie.cuhk.edu.hk/projects/TA-CNN/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1412.0069\"\n  }, \"http://arxiv.org/abs/1412.0069\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning Strong Parts for Pedestrian Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2015. CUHK. DeepParts\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Achieving 11.89% average miss rate on Caltech Pedestrian Dataset\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://personal.ie.cuhk.edu.hk/~pluo/pdf/tianLWTiccv15.pdf\"\n  }, \"http://personal.ie.cuhk.edu.hk/~pluo/pdf/tianLWTiccv15.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Taking a Deeper Look at Pedestrians\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1501.05790\"\n  }, \"https://arxiv.org/abs/1501.05790\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Convolutional Channel Features\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1504.07339\"\n  }, \"https://arxiv.org/abs/1504.07339\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/byangderek/CCF\"\n  }, \"https://github.com/byangderek/CCF\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End-to-end people detection in crowded scenes\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1506.04878\"\n  }, \"http://arxiv.org/abs/1506.04878\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Russell91/reinspect\"\n  }, \"https://github.com/Russell91/reinspect\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"ipn: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://nbviewer.ipython.org/github/Russell91/ReInspect/blob/master/evaluation_reinspect.ipynb\"\n  }, \"http://nbviewer.ipython.org/github/Russell91/ReInspect/blob/master/evaluation_reinspect.ipynb\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"youtube: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=QeWl0h3kQ24\"\n  }, \"https://www.youtube.com/watch?v=QeWl0h3kQ24\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Complexity-Aware Cascades for Deep Pedestrian Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1507.05348\"\n  }, \"https://arxiv.org/abs/1507.05348\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep convolutional neural networks for pedestrian detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1510.03608\"\n  }, \"http://arxiv.org/abs/1510.03608\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/DenisTome/DeepPed\"\n  }, \"https://github.com/DenisTome/DeepPed\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scale-aware Fast R-CNN for Pedestrian Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1510.08160\"\n  }, \"https://arxiv.org/abs/1510.08160\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"New algorithm improves speed and accuracy of pedestrian detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.eurekalert.org/pub_releases/2016-02/uoc--nai020516.php\"\n  }, \"http://www.eurekalert.org/pub_releases/2016-02/uoc--nai020516.php\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pushing the Limits of Deep CNNs for Pedestrian Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: \\\"set a new record on the Caltech pedestrian dataset, lowering the log-average miss rate from 11.7% to 8.9%\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.04525\"\n  }, \"http://arxiv.org/abs/1603.04525\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Real-Time Deep Learning Pedestrian Detector for Robot Navigation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1607.04436\"\n  }, \"http://arxiv.org/abs/1607.04436\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Real-Time Pedestrian Detector using Deep Learning for Human-Aware Navigation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1607.04441\"\n  }, \"http://arxiv.org/abs/1607.04441\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Is Faster R-CNN Doing Well for Pedestrian Detection?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1607.07032\"\n  }, \"http://arxiv.org/abs/1607.07032\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zhangliliang/RPN_BF/tree/RPN-pedestrian\"\n  }, \"https://github.com/zhangliliang/RPN_BF/tree/RPN-pedestrian\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unsupervised Deep Domain Adaptation for Pedestrian Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV Workshop 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1802.03269\"\n  }, \"https://arxiv.org/abs/1802.03269\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Reduced Memory Region Based Deep Convolutional Neural Network Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IEEE 2016 ICCE-Berlin\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.02500\"\n  }, \"http://arxiv.org/abs/1609.02500\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fused DNN: A deep neural network fusion approach to fast and robust pedestrian detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.03466\"\n  }, \"https://arxiv.org/abs/1610.03466\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Detecting People in Artwork with CNNs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016 Workshops\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.08871\"\n  }, \"https://arxiv.org/abs/1610.08871\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Multi-camera People Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.04593\"\n  }, \"https://arxiv.org/abs/1702.04593\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Expecting the Unexpected: Training Detectors for Unusual Pedestrians with Adversarial Imposters\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://ml.cs.tsinghua.edu.cn:5000/publications/synunity/\"\n  }, \"http://ml.cs.tsinghua.edu.cn:5000/publications/synunity/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.06283\"\n  }, \"https://arxiv.org/abs/1703.06283\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Tensorflow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/huangshiyu13/RPNplus\"\n  }, \"https://github.com/huangshiyu13/RPNplus\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"What Can Help Pedestrian Detection?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017. Tsinghua University & Peking University & Megvii Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Faster R-CNN, HyperLearner\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1705.02757\"\n  }, \"https://arxiv.org/abs/1705.02757\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_cvpr_2017/papers/Mao_What_Can_Help_CVPR_2017_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_cvpr_2017/papers/Mao_What_Can_Help_CVPR_2017_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Illuminating Pedestrians via Simultaneous Detection & Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1706.08564\"\n  }, \"https://arxiv.org/abs/1706.08564\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rotational Rectification Network for Robust Pedestrian Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CMU & Volvo Construction\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.08917\"\n  }, \"https://arxiv.org/abs/1706.08917\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"STD-PD: Generating Synthetic Training Data for Pedestrian Detection in Unannotated Videos\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The University of North Carolina at Chapel Hill\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.09100\"\n  }, \"https://arxiv.org/abs/1707.09100\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Too Far to See? Not Really! --- Pedestrian Detection with Scale-aware Localization Policy\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.00235\"\n  }, \"https://arxiv.org/abs/1709.00235\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Aggregated Channels Network for Real-Time Pedestrian Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1801.00476\"\n  }, \"https://arxiv.org/abs/1801.00476\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Exploring Multi-Branch and High-Level Semantic Networks for Improving Pedestrian Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1804.00872\"\n  }, \"https://arxiv.org/abs/1804.00872\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pedestrian-Synthesis-GAN: Generating Pedestrian Data in Real Scene and Beyond\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1804.02047\"\n  }, \"https://arxiv.org/abs/1804.02047\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PCN: Part and Context Information for Pedestrian Detection with CNNs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: British Machine Vision Conference(BMVC) 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.04483\"\n  }, \"https://arxiv.org/abs/1804.04483\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improving Occlusion and Hard Negative Handling for Single-Stage Pedestrian Detectors\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_cvpr_2018/papers/Noh_Improving_Occlusion_and_CVPR_2018_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_cvpr_2018/papers/Noh_Improving_Occlusion_and_CVPR_2018_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Small-scale Pedestrian Detection Based on Somatic Topology Localization and Temporal Feature Aggregation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Hikvision Research Institute\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.01438\"\n  }, \"https://arxiv.org/abs/1807.01438\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bi-box Regression for Pedestrian Detection and Occlusion Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_ECCV_2018/papers/CHUNLUAN_ZHOU_Bi-box_Regression_for_ECCV_2018_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_ECCV_2018/papers/CHUNLUAN_ZHOU_Bi-box_Regression_for_ECCV_2018_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Pytorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/rainofmine/Bi-box_Regression\"\n  }, \"https://github.com/rainofmine/Bi-box_Regression\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pedestrian Detection with Autoregressive Network Phases\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Michigan State University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1812.00440\"\n  }, \"https://arxiv.org/abs/1812.00440\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SSA-CNN: Semantic Self-Attention CNN for Pedestrian Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1902.09080\"\n  }, \"https://arxiv.org/abs/1902.09080\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"High-level Semantic Feature Detection:A New Perspective for Pedestrian Detection\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Center and Scale Prediction: A Box-free Approach for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: National University of Defense Technology & Chinese Academy of Sciences & Inception Institute of Artificial Intelligence (IIAI) & Horizon Robotics Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.02948\"\n  }, \"https://arxiv.org/abs/1904.02948\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, Keras): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/liuwei16/CSP\"\n  }, \"https://github.com/liuwei16/CSP\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Evading Real-Time Person Detectors by Adversarial T-shirt\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1910.11099\"\n  }, \"https://arxiv.org/abs/1910.11099\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Coupled Network for Robust Pedestrian Detection with Gated Multi-Layer Feature Extraction and Deformable Occlusion Handling\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1912.08661\"\n  }, \"https://arxiv.org/abs/1912.08661\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scale Match for Tiny Person Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: WACV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1912.10664\"\n  }, \"https://arxiv.org/abs/1912.10664\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ucas-vg/TinyBenchmark\"\n  }, \"https://github.com/ucas-vg/TinyBenchmark\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SM+: Refined Scale Match for Tiny Person Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2102.03558\"\n  }, \"https://arxiv.org/abs/2102.03558\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Resisting the Distracting-factors in Pedestrian Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Beihang University & Arizona State University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2005.07344\"\n  }, \"https://arxiv.org/abs/2005.07344\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SADet: Learning An Efficient and Accurate Pedestrian Detector\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2007.13119\"\n  }, \"https://arxiv.org/abs/2007.13119\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"NOH-NMS: Improving Pedestrian Detection by Nearby Objects Hallucination\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM MM 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tencent Youtu Lab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.13376\"\n  }, \"https://arxiv.org/abs/2007.13376\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Anchor-free Small-scale Multispectral Pedestrian Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2008.08418\"\n  }, \"https://arxiv.org/abs/2008.08418\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/HensoldtOptronicsCV/MultispectralPedestrianDetection\"\n  }, \"https://github.com/HensoldtOptronicsCV/MultispectralPedestrianDetection\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"LLA: Loss-aware Label Assignment for Dense Pedestrian Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2101.04307\"\n  }, \"https://arxiv.org/abs/2101.04307\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Megvii-BaseDetection/LLA\"\n  }, \"https://github.com/Megvii-BaseDetection/LLA\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DETR for Pedestrian Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2012.06785\"\n  }, \"https://arxiv.org/abs/2012.06785\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"V2F-Net: Explicit Decomposition of Occluded Pedestrian Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MEGVII Technology & Texas A&M University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.03106\"\n  }, \"https://arxiv.org/abs/2104.03106\"))), mdx(\"h2\", {\n    \"id\": \"pedestrian-detection-in-a-crowd\"\n  }, \"Pedestrian Detection in a Crowd\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Repulsion Loss: Detecting Pedestrians in a Crowd\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.07752\"\n  }, \"https://arxiv.org/abs/1711.07752\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Occlusion-aware R-CNN: Detecting Pedestrians in a Crowd\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.08407\"\n  }, \"https://arxiv.org/abs/1807.08407\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Adaptive NMS: Refining Pedestrian Detection in a Crowd\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.03629\"\n  }, \"https://arxiv.org/abs/1904.03629\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PedHunter: Occlusion Robust Pedestrian Detector in Crowded Scenes\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: SUR-PED\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.06826\"\n  }, \"https://arxiv.org/abs/1909.06826\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Double Anchor R-CNN for Human Detection in a Crowd\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Megvii Inc. (Face++) & Tsinghua University & Xi\\u2019an Jiaotong University & Zhejiang University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.09998\"\n  }, \"https://arxiv.org/abs/1909.09998\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CSID: Center, Scale, Identity and Density-aware Pedestrian Detection in a Crowd\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1910.09188\"\n  }, \"https://arxiv.org/abs/1910.09188\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Head Enhanced Pedestrian Detection in a Crowd\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1911.11985\"\n  }, \"https://arxiv.org/abs/1911.11985\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Detection in Crowded Scenes: One Proposal, Multiple Predictions\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020 Oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.09163\"\n  }, \"https://arxiv.org/abs/2003.09163\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Purkialo/CrowdDet\"\n  }, \"https://github.com/Purkialo/CrowdDet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Visible Feature Guidance for Crowd Pedestrian Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020 RLQ Workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2008.09993\"\n  }, \"https://arxiv.org/abs/2008.09993\"))), mdx(\"h1\", {\n    \"id\": \"occluded-pedestrian-detection\"\n  }, \"Occluded Pedestrian Detection\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mask-Guided Attention Network for Occluded Pedestrian Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1910.06160\"\n  }, \"https://arxiv.org/abs/1910.06160\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Leotju/MGAN\"\n  }, \"https://github.com/Leotju/MGAN\"))), mdx(\"h2\", {\n    \"id\": \"multispectral-pedestrian-detection\"\n  }, \"Multispectral Pedestrian Detection\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multispectral Deep Neural Networks for Pedestrian Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2016 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.02644\"\n  }, \"https://arxiv.org/abs/1611.02644\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Illumination-aware Faster R-CNN for Robust Multispectral Pedestrian Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: State Key Lab of CAD&CG, Zhejiang University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.05347\"\n  }, \"https://arxiv.org/abs/1803.05347\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multispectral Pedestrian Detection via Simultaneous Detection and Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.04818\"\n  }, \"https://arxiv.org/abs/1808.04818\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Cross-Modality Disparity Problem in Multispectral Pedestrian Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1901.02645\"\n  }, \"https://arxiv.org/abs/1901.02645\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Box-level Segmentation Supervised Deep Neural Networks for Accurate and Real-time Multispectral Pedestrian Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1902.05291\"\n  }, \"https://arxiv.org/abs/1902.05291\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"GFD-SSD: Gated Fusion Double SSD for Multispectral Pedestrian Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1903.06999\"\n  }, \"https://arxiv.org/abs/1903.06999\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unsupervised Domain Adaptation for Multispectral Pedestrian Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1904.03692\"\n  }, \"https://arxiv.org/abs/1904.03692\")), mdx(\"h1\", {\n    \"id\": \"vehicle-detection\"\n  }, \"Vehicle Detection\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DAVE: A Unified Framework for Fast Vehicle Detection and Annotation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1607.04564\"\n  }, \"http://arxiv.org/abs/1607.04564\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Evolving Boxes for fast Vehicle Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.00254\"\n  }, \"https://arxiv.org/abs/1702.00254\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fine-Grained Car Detection for Visual Census Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1709.02480\"\n  }, \"https://arxiv.org/abs/1709.02480\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SINet: A Scale-insensitive Convolutional Neural Network for Fast Vehicle Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IEEE Transactions on Intelligent Transportation Systems (T-ITS)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.00433\"\n  }, \"https://arxiv.org/abs/1804.00433\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Label and Sample: Efficient Training of Vehicle Object Detector from Sparsely Labeled Data\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: UC Berkeley\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.08603\"\n  }, \"https://arxiv.org/abs/1808.08603\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Domain Randomization for Scene-Specific Car Detection and Pose Estimation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.05939\"\n  }, \"https://arxiv.org/abs/1811.05939\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ShuffleDet: Real-Time Vehicle Detection Network in On-board Embedded UAV Imagery\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018, UAVision 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.06318\"\n  }, \"https://arxiv.org/abs/1811.06318\"))), mdx(\"h1\", {\n    \"id\": \"traffic-sign-detection\"\n  }, \"Traffic-Sign Detection\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Traffic-Sign Detection and Classification in the Wild\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page(code+dataset): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cg.cs.tsinghua.edu.cn/traffic-sign/\"\n  }, \"http://cg.cs.tsinghua.edu.cn/traffic-sign/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhu_Traffic-Sign_Detection_and_CVPR_2016_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhu_Traffic-Sign_Detection_and_CVPR_2016_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code & model: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cg.cs.tsinghua.edu.cn/traffic-sign/data_model_code/newdata0411.zip\"\n  }, \"http://cg.cs.tsinghua.edu.cn/traffic-sign/data_model_code/newdata0411.zip\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Evaluating State-of-the-art Object Detector on Challenging Traffic Light Data\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017 workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_cvpr_2017_workshops/w9/papers/Jensen_Evaluating_State-Of-The-Art_Object_CVPR_2017_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_cvpr_2017_workshops/w9/papers/Jensen_Evaluating_State-Of-The-Art_Object_CVPR_2017_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Detecting Small Signs from Large Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IEEE Conference on Information Reuse and Integration (IRI) 2017 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.08574\"\n  }, \"https://arxiv.org/abs/1706.08574\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Localized Traffic Sign Detection with Multi-scale Deconvolution Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1804.10428\"\n  }, \"https://arxiv.org/abs/1804.10428\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Detecting Traffic Lights by Single Shot Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ITSC 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.02523\"\n  }, \"https://arxiv.org/abs/1805.02523\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Hierarchical Deep Architecture and Mini-Batch Selection Method For Joint Traffic Sign and Light Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IEEE 15th Conference on Computer and Robot Vision\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1806.07987\"\n  }, \"https://arxiv.org/abs/1806.07987\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=_YmogPzBXOw&feature=youtu.be\"\n  }, \"https://www.youtube.com/watch?v=_YmogPzBXOw&feature=youtu.be\"))), mdx(\"h1\", {\n    \"id\": \"skeleton-detection\"\n  }, \"Skeleton Detection\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Skeleton Extraction in Natural Images by Fusing Scale-associated Deep Side Outputs\")), mdx(\"img\", {\n    \"src\": \"https://camo.githubusercontent.com/88a65f132aa4ae4b0477e3ad02c13cdc498377d9/687474703a2f2f37786e37777a2e636f6d312e7a302e676c622e636c6f7564646e2e636f6d2f44656570536b656c65746f6e2e706e673f696d61676556696577322f322f772f353030\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.09446\"\n  }, \"http://arxiv.org/abs/1603.09446\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zeakey/DeepSkeleton\"\n  }, \"https://github.com/zeakey/DeepSkeleton\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepSkeleton: Learning Multi-task Scale-associated Deep Side Outputs for Object Skeleton Extraction in Natural Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.03659\"\n  }, \"http://arxiv.org/abs/1609.03659\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SRN: Side-output Residual Network for Object Symmetry Detection in the Wild\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.02243\"\n  }, \"https://arxiv.org/abs/1703.02243\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/KevinKecc/SRN\"\n  }, \"https://github.com/KevinKecc/SRN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hi-Fi: Hierarchical Feature Integration for Skeleton Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1801.01849\"\n  }, \"https://arxiv.org/abs/1801.01849\")), mdx(\"h1\", {\n    \"id\": \"fruit-detection\"\n  }, \"Fruit Detection\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Fruit Detection in Orchards\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.03677\"\n  }, \"https://arxiv.org/abs/1610.03677\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Image Segmentation for Fruit Detection and Yield Estimation in Apple Orchards\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The Journal of Field Robotics in May 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://confluence.acfr.usyd.edu.au/display/AGPub/\"\n  }, \"http://confluence.acfr.usyd.edu.au/display/AGPub/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.08120\"\n  }, \"https://arxiv.org/abs/1610.08120\"))), mdx(\"h2\", {\n    \"id\": \"shadow-detection\"\n  }, \"Shadow Detection\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast Shadow Detection from a Single Image Using a Patched Convolutional Neural Network\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.09283\"\n  }, \"https://arxiv.org/abs/1709.09283\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A+D-Net: Shadow Detection with Adversarial Shadow Attenuation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.01361\"\n  }, \"https://arxiv.org/abs/1712.01361\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Stacked Conditional Generative Adversarial Networks for Jointly Learning Shadow Detection and Shadow Removal\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.02478\"\n  }, \"https://arxiv.org/abs/1712.02478\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Direction-aware Spatial Context Features for Shadow Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.04142\"\n  }, \"https://arxiv.org/abs/1712.04142\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Direction-aware Spatial Context Features for Shadow Detection and Removal\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The Chinese University of Hong Kong & The Hong Kong Polytechnic University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv:  \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.04635\"\n  }, \"https://arxiv.org/abs/1805.04635\"))), mdx(\"h1\", {\n    \"id\": \"others-detection\"\n  }, \"Others Detection\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Deformation Network for Object Landmark Localization\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.01014\"\n  }, \"http://arxiv.org/abs/1605.01014\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fashion Landmark Detection in the Wild\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://personal.ie.cuhk.edu.hk/~lz013/projects/FashionLandmarks.html\"\n  }, \"http://personal.ie.cuhk.edu.hk/~lz013/projects/FashionLandmarks.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.03049\"\n  }, \"http://arxiv.org/abs/1608.03049\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Caffe): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/liuziwei7/fashion-landmarks\"\n  }, \"https://github.com/liuziwei7/fashion-landmarks\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning for Fast and Accurate Fashion Item Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Kuznech Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MultiBox and Fast R-CNN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://kddfashion2016.mybluemix.net/kddfashion_finalSubmissions/Deep%20Learning%20for%20Fast%20and%20Accurate%20Fashion%20Item%20Detection.pdf\"\n  }, \"https://kddfashion2016.mybluemix.net/kddfashion_finalSubmissions/Deep%20Learning%20for%20Fast%20and%20Accurate%20Fashion%20Item%20Detection.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"OSMDeepOD - OSM and Deep Learning based Object Detection from Aerial Imagery (formerly known as \\\"OSM-Crosswalk-Detection\\\")\")), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/geometalab/OSMDeepOD/master/imgs/process.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/geometalab/OSMDeepOD\"\n  }, \"https://github.com/geometalab/OSMDeepOD\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Selfie Detection by Synergy-Constraint Based Convolutional Neural Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro:  IEEE SITIS 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.04357\"\n  }, \"https://arxiv.org/abs/1611.04357\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Associative Embedding:End-to-End Learning for Joint Detection and Grouping\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.05424\"\n  }, \"https://arxiv.org/abs/1611.05424\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Cuboid Detection: Beyond 2D Bounding Boxes\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CMU & Magic Leap\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.10010\"\n  }, \"https://arxiv.org/abs/1611.10010\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Automatic Model Based Dataset Generation for Fast and Accurate Crop and Weeds Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.03019\"\n  }, \"https://arxiv.org/abs/1612.03019\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning Logo Detection with Data Expansion by Synthesising Context\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.09322\"\n  }, \"https://arxiv.org/abs/1612.09322\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scalable Deep Learning Logo Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.11417\"\n  }, \"https://arxiv.org/abs/1803.11417\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pixel-wise Ear Detection with Convolutional Encoder-Decoder Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.00307\"\n  }, \"https://arxiv.org/abs/1702.00307\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Automatic Handgun Detection Alarm in Videos Using Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.05147\"\n  }, \"https://arxiv.org/abs/1702.05147\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"results: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/SihamTabik/Pistol-Detection-in-Videos\"\n  }, \"https://github.com/SihamTabik/Pistol-Detection-in-Videos\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Objects as context for part detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1703.09529\"\n  }, \"https://arxiv.org/abs/1703.09529\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Using Deep Networks for Drone Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AVSS 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.05726\"\n  }, \"https://arxiv.org/abs/1706.05726\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cut, Paste and Learn: Surprisingly Easy Synthesis for Instance Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.01642\"\n  }, \"https://arxiv.org/abs/1708.01642\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Target Driven Instance Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.04610\"\n  }, \"https://arxiv.org/abs/1803.04610\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepVoting: An Explainable Framework for Semantic Part Detection under Partial Occlusion\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.04577\"\n  }, \"https://arxiv.org/abs/1709.04577\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"VPGNet: Vanishing Point Guided Network for Lane and Road Marking Detection and Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1710.06288\"\n  }, \"https://arxiv.org/abs/1710.06288\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/SeokjuLee/VPGNet\"\n  }, \"https://github.com/SeokjuLee/VPGNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Grab, Pay and Eat: Semantic Food Detection for Smart Restaurants\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.05128\"\n  }, \"https://arxiv.org/abs/1711.05128\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ReMotENet: Efficient Relevant Motion Event Detection for Large-scale Home Surveillance Videos\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: WACV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.02031\"\n  }, \"https://arxiv.org/abs/1801.02031\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning Object Detection Methods for Ecological Camera Trap Data\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Conference of Computer and Robot Vision. University of Guelph\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.10842\"\n  }, \"https://arxiv.org/abs/1803.10842\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"EL-GAN: Embedding Loss Driven Generative Adversarial Networks for Lane Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1806.05525\"\n  }, \"https://arxiv.org/abs/1806.05525\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards End-to-End Lane Detection: an Instance Segmentation Approach\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1802.05591\"\n  }, \"https://arxiv.org/abs/1802.05591\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MaybeShewill-CV/lanenet-lane-detection\"\n  }, \"https://github.com/MaybeShewill-CV/lanenet-lane-detection\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Densely Supervised Grasp Detector (DSGD)\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1810.03962\"\n  }, \"https://arxiv.org/abs/1810.03962\")), mdx(\"h1\", {\n    \"id\": \"object-proposal\"\n  }, \"Object Proposal\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepProposal: Hunting Objects by Cascading Deep Convolutional Layers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1510.04445\"\n  }, \"http://arxiv.org/abs/1510.04445\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aghodrati/deepproposal\"\n  }, \"https://github.com/aghodrati/deepproposal\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scale-aware Pixel-wise Object Proposal Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IEEE Transactions on Image Processing\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1601.04798\"\n  }, \"http://arxiv.org/abs/1601.04798\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attend Refine Repeat: Active Box Proposal Generation via In-Out Localization\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2016. AttractioNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1606.04446\"\n  }, \"https://arxiv.org/abs/1606.04446\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/gidariss/AttractioNet\"\n  }, \"https://github.com/gidariss/AttractioNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning to Segment Object Proposals via Recursive Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.01057\"\n  }, \"https://arxiv.org/abs/1612.01057\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Detection with Diverse Proposals\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: differentiable Determinantal Point Process (DPP) layer, Learning Detection with Diverse Proposals (LDDP)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.03533\"\n  }, \"https://arxiv.org/abs/1704.03533\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ScaleNet: Guiding Object Proposal Generation in Supermarkets and Beyond\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: product detection\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.06752\"\n  }, \"https://arxiv.org/abs/1704.06752\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improving Small Object Proposals for Company Logo Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICMR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.08881\"\n  }, \"https://arxiv.org/abs/1704.08881\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Open Logo Detection Challenge\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: QMUL-OpenLogo\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://qmul-openlogo.github.io/\"\n  }, \"https://qmul-openlogo.github.io/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.01964\"\n  }, \"https://arxiv.org/abs/1807.01964\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AttentionMask: Attentive, Efficient Object Proposal Generation Focusing on Small Objects\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACCV 2018 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.08728\"\n  }, \"https://arxiv.org/abs/1811.08728\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/chwilms/AttentionMask\"\n  }, \"https://github.com/chwilms/AttentionMask\"))), mdx(\"h1\", {\n    \"id\": \"localization\"\n  }, \"Localization\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Beyond Bounding Boxes: Precise Localization of Objects in Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: PhD Thesis\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-193.html\"\n  }, \"http://www.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-193.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"phd-thesis: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-193.pdf\"\n  }, \"http://www.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-193.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(\\\"SDS using hypercolumns\\\"): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bharath272/sds\"\n  }, \"https://github.com/bharath272/sds\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Weakly Supervised Object Localization with Multi-fold Multiple Instance Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1503.00949\"\n  }, \"http://arxiv.org/abs/1503.00949\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Weakly Supervised Object Localization Using Size Estimates\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.04314\"\n  }, \"http://arxiv.org/abs/1608.04314\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Active Object Localization with Deep Reinforcement Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Markov Decision Process\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1511.06015\"\n  }, \"https://arxiv.org/abs/1511.06015\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Localizing objects using referring expressions\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: LSTM, multiple instance learning (MIL)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.umiacs.umd.edu/~varun/files/refexp-ECCV16.pdf\"\n  }, \"http://www.umiacs.umd.edu/~varun/files/refexp-ECCV16.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/varun-nagaraja/referring-expressions\"\n  }, \"https://github.com/varun-nagaraja/referring-expressions\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"LocNet: Improving Localization Accuracy for Object Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1511.07763\"\n  }, \"http://arxiv.org/abs/1511.07763\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/gidariss/LocNet\"\n  }, \"https://github.com/gidariss/LocNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Deep Features for Discriminative Localization\")), mdx(\"img\", {\n    \"src\": \"http://cnnlocalization.csail.mit.edu/framework.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cnnlocalization.csail.mit.edu/\"\n  }, \"http://cnnlocalization.csail.mit.edu/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1512.04150\"\n  }, \"http://arxiv.org/abs/1512.04150\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Tensorflow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jazzsaxmafia/Weakly_detector\"\n  }, \"https://github.com/jazzsaxmafia/Weakly_detector\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/metalbubble/CAM\"\n  }, \"https://github.com/metalbubble/CAM\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tdeboissiere/VGG16CAM-keras\"\n  }, \"https://github.com/tdeboissiere/VGG16CAM-keras\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ContextLocNet: Context-Aware Deep Network Models for Weakly Supervised Localization\")), mdx(\"img\", {\n    \"src\": \"http://www.di.ens.fr/willow/research/contextlocnet/model.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.di.ens.fr/willow/research/contextlocnet/\"\n  }, \"http://www.di.ens.fr/willow/research/contextlocnet/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.04331\"\n  }, \"http://arxiv.org/abs/1609.04331\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/vadimkantorov/contextlocnet\"\n  }, \"https://github.com/vadimkantorov/contextlocnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Ensemble of Part Detectors for Simultaneous Classification and Localization\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1705.10034\"\n  }, \"https://arxiv.org/abs/1705.10034\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"STNet: Selective Tuning of Convolutional Networks for Object Localization\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1708.06418\"\n  }, \"https://arxiv.org/abs/1708.06418\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Soft Proposal Networks for Weakly Supervised Object Localization\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1709.01829\"\n  }, \"https://arxiv.org/abs/1709.01829\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fine-grained Discriminative Localization via Saliency-guided Faster R-CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM MM 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1709.08295\"\n  }, \"https://arxiv.org/abs/1709.08295\"))), mdx(\"h1\", {\n    \"id\": \"tutorials--talks\"\n  }, \"Tutorials / Talks\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Convolutional Feature Maps: Elements of efficient (and accurate) CNN-based object detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://research.microsoft.com/en-us/um/people/kahe/iccv15tutorial/iccv2015_tutorial_convolutional_feature_maps_kaiminghe.pdf\"\n  }, \"http://research.microsoft.com/en-us/um/people/kahe/iccv15tutorial/iccv2015_tutorial_convolutional_feature_maps_kaiminghe.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards Good Practices for Recognition & Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Hikvision Research Institute. Supervised Data Augmentation (SDA)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://image-net.org/challenges/talks/2016/Hikvision_at_ImageNet_2016.pdf\"\n  }, \"http://image-net.org/challenges/talks/2016/Hikvision_at_ImageNet_2016.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Work in progress: Improving object detection and instance segmentation for small objects\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://docs.google.com/presentation/d/1OTfGn6mLe1VWE8D0q6Tu_WwFTSoLGd4OF8WCYnOWcVo/edit#slide=id.g37418adc7a_0_229\"\n  }, \"https://docs.google.com/presentation/d/1OTfGn6mLe1VWE8D0q6Tu_WwFTSoLGd4OF8WCYnOWcVo/edit#slide=id.g37418adc7a_0_229\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Detection with Deep Learning: A Review\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1807.05511\"\n  }, \"https://arxiv.org/abs/1807.05511\")), mdx(\"h1\", {\n    \"id\": \"projects\"\n  }, \"Projects\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Detectron\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: FAIR's research platform for object detection research, implementing popular algorithms like Mask R-CNN and RetinaNet.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/facebookresearch/Detectron\"\n  }, \"https://github.com/facebookresearch/Detectron\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Detectron2\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Detectron2 is FAIR's next-generation platform for object detection and segmentation.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/facebookresearch/detectron2\"\n  }, \"https://github.com/facebookresearch/detectron2\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MMDetection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MMDetection: Open MMLab Detection Toolbox and Benchmark\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1906.07155\"\n  }, \"https://arxiv.org/abs/1906.07155\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/open-mmlab/mmdetection\"\n  }, \"https://github.com/open-mmlab/mmdetection\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"docs: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://mmdetection.readthedocs.io/en/latest/\"\n  }, \"https://mmdetection.readthedocs.io/en/latest/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SimpleDet - A Simple and Versatile Framework for Object Detection and Instance Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: A Simple and Versatile Framework for Object Detection and Instance Recognition\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/TuSimple/simpledet\"\n  }, \"https://github.com/TuSimple/simpledet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AdelaiDet\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AdelaiDet is an open source toolbox for multiple instance-level detection and recognition tasks.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aim-uofa/AdelaiDet/\"\n  }, \"https://github.com/aim-uofa/AdelaiDet/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TensorBox: a simple framework for training neural networks to detect objects in images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: \\\"The basic model implements the simple and robust GoogLeNet-OverFeat algorithm.\\nWe additionally provide an implementation of the \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Russell91/ReInspect/\"\n  }, \"ReInspect\"), \" algorithm\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Russell91/TensorBox\"\n  }, \"https://github.com/Russell91/TensorBox\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"NanoDet\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Super fast and lightweight anchor-free object detection model. Real-time on mobile devices.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/RangiLyu/nanodet\"\n  }, \"https://github.com/RangiLyu/nanodet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object detection in torch: Implementation of some object detection frameworks in torch\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/fmassa/object-detection.torch\"\n  }, \"https://github.com/fmassa/object-detection.torch\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Using DIGITS to train an Object Detection network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/NVIDIA/DIGITS/blob/master/examples/object-detection/README.md\"\n  }, \"https://github.com/NVIDIA/DIGITS/blob/master/examples/object-detection/README.md\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FCN-MultiBox Detector\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Full convolution MultiBox Detector (like SSD) implemented in Torch.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/teaonly/FMD.torch\"\n  }, \"https://github.com/teaonly/FMD.torch\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"KittiBox: A car detection model implemented in Tensorflow.\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: MultiNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: KittiBox is a collection of scripts to train out model FastBox on the Kitti Object Detection Dataset\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MarvinTeichmann/KittiBox\"\n  }, \"https://github.com/MarvinTeichmann/KittiBox\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deformable Convolutional Networks + MST + Soft-NMS\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bharatsingh430/Deformable-ConvNets\"\n  }, \"https://github.com/bharatsingh430/Deformable-ConvNets\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"How to Build a Real-time Hand-Detector using Neural Networks (SSD) on Tensorflow\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://towardsdatascience.com/how-to-build-a-real-time-hand-detector-using-neural-networks-ssd-on-tensorflow-d6bac0e4b2ce\"\n  }, \"https://towardsdatascience.com/how-to-build-a-real-time-hand-detector-using-neural-networks-ssd-on-tensorflow-d6bac0e4b2ce\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com//victordibia/handtracking\"\n  }, \"https://github.com//victordibia/handtracking\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Metrics for object detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Most popular metrics used to evaluate object detection algorithms\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/rafaelpadilla/Object-Detection-Metrics\"\n  }, \"https://github.com/rafaelpadilla/Object-Detection-Metrics\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MobileNetv2-SSDLite\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Caffe implementation of SSD and SSDLite detection on MobileNetv2, converted from tensorflow.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/chuanqi305/MobileNetv2-SSDLite\"\n  }, \"https://github.com/chuanqi305/MobileNetv2-SSDLite\"))), mdx(\"h1\", {\n    \"id\": \"leaderboard\"\n  }, \"Leaderboard\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Detection Results: VOC2012\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Competition \\\"comp4\\\" (train on additional data)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=4\"\n  }, \"http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=4\"))), mdx(\"h1\", {\n    \"id\": \"tools\"\n  }, \"Tools\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BeaverDam: Video annotation tool for deep learning training labels\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/antingshen/BeaverDam\"\n  }, \"https://github.com/antingshen/BeaverDam\")), mdx(\"h1\", {\n    \"id\": \"blogs\"\n  }, \"Blogs\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Convolutional Neural Networks for Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://rnd.azoft.com/convolutional-neural-networks-object-detection/\"\n  }, \"http://rnd.azoft.com/convolutional-neural-networks-object-detection/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Introducing automatic object detection to visual search (Pinterest)\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Faster R-CNN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://engineering.pinterest.com/blog/introducing-automatic-object-detection-visual-search\"\n  }, \"https://engineering.pinterest.com/blog/introducing-automatic-object-detection-visual-search\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://engineering.pinterest.com/sites/engineering/files/Visual%20Search%20V1%20-%20Video.mp4\"\n  }, \"https://engineering.pinterest.com/sites/engineering/files/Visual%20Search%20V1%20-%20Video.mp4\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"review: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://news.developer.nvidia.com/pinterest-introduces-the-future-of-visual-search/?mkt_tok=eyJpIjoiTnpaa01UWXpPRE0xTURFMiIsInQiOiJJRjcybjkwTmtmallORUhLOFFFODBDclFqUlB3SWlRVXJXb1MrQ013TDRIMGxLQWlBczFIeWg0TFRUdnN2UHY2ZWFiXC9QQVwvQzBHM3B0UzBZblpOSmUyU1FcLzNPWXI4cml2VERwTTJsOFwvOEk9In0%3D\"\n  }, \"https://news.developer.nvidia.com/pinterest-introduces-the-future-of-visual-search/?mkt_tok=eyJpIjoiTnpaa01UWXpPRE0xTURFMiIsInQiOiJJRjcybjkwTmtmallORUhLOFFFODBDclFqUlB3SWlRVXJXb1MrQ013TDRIMGxLQWlBczFIeWg0TFRUdnN2UHY2ZWFiXC9QQVwvQzBHM3B0UzBZblpOSmUyU1FcLzNPWXI4cml2VERwTTJsOFwvOEk9In0%3D\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning for Object Detection with DIGITS\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://devblogs.nvidia.com/parallelforall/deep-learning-object-detection-digits/\"\n  }, \"https://devblogs.nvidia.com/parallelforall/deep-learning-object-detection-digits/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Analyzing The Papers Behind Facebook's Computer Vision Approach\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: DeepMask, SharpMask, MultiPathNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://adeshpande3.github.io/adeshpande3.github.io/Analyzing-the-Papers-Behind-Facebook's-Computer-Vision-Approach/\"\n  }, \"https://adeshpande3.github.io/adeshpande3.github.io/Analyzing-the-Papers-Behind-Facebook's-Computer-Vision-Approach/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Easily Create High Quality Object Detectors with Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: dlib v19.2\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://blog.dlib.net/2016/10/easily-create-high-quality-object.html\"\n  }, \"http://blog.dlib.net/2016/10/easily-create-high-quality-object.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"How to Train a Deep-Learned Object Detection Model in the Microsoft Cognitive Toolkit\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://blogs.technet.microsoft.com/machinelearning/2016/10/25/how-to-train-a-deep-learned-object-detection-model-in-cntk/\"\n  }, \"https://blogs.technet.microsoft.com/machinelearning/2016/10/25/how-to-train-a-deep-learned-object-detection-model-in-cntk/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Microsoft/CNTK/tree/master/Examples/Image/Detection/FastRCNN\"\n  }, \"https://github.com/Microsoft/CNTK/tree/master/Examples/Image/Detection/FastRCNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Detection in Satellite Imagery, a Low Overhead Approach\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"part 1: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/the-downlinq/object-detection-in-satellite-imagery-a-low-overhead-approach-part-i-cbd96154a1b7#.2csh4iwx9\"\n  }, \"https://medium.com/the-downlinq/object-detection-in-satellite-imagery-a-low-overhead-approach-part-i-cbd96154a1b7#.2csh4iwx9\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"part 2: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/the-downlinq/object-detection-in-satellite-imagery-a-low-overhead-approach-part-ii-893f40122f92#.f9b7dgf64\"\n  }, \"https://medium.com/the-downlinq/object-detection-in-satellite-imagery-a-low-overhead-approach-part-ii-893f40122f92#.f9b7dgf64\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"You Only Look Twice\\u200A\\u2014\\u200AMulti-Scale Object Detection in Satellite Imagery With Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"part 1: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/the-downlinq/you-only-look-twice-multi-scale-object-detection-in-satellite-imagery-with-convolutional-neural-38dad1cf7571#.fmmi2o3of\"\n  }, \"https://medium.com/the-downlinq/you-only-look-twice-multi-scale-object-detection-in-satellite-imagery-with-convolutional-neural-38dad1cf7571#.fmmi2o3of\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"part 2: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/the-downlinq/you-only-look-twice-multi-scale-object-detection-in-satellite-imagery-with-convolutional-neural-34f72f659588#.nwzarsz1t\"\n  }, \"https://medium.com/the-downlinq/you-only-look-twice-multi-scale-object-detection-in-satellite-imagery-with-convolutional-neural-34f72f659588#.nwzarsz1t\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Faster R-CNN Pedestrian and Car Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://bigsnarf.wordpress.com/2016/11/07/faster-r-cnn-pedestrian-and-car-detection/\"\n  }, \"https://bigsnarf.wordpress.com/2016/11/07/faster-r-cnn-pedestrian-and-car-detection/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"ipn: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://gist.github.com/bigsnarfdude/2f7b2144065f6056892a98495644d3e0#file-demo_faster_rcnn_notebook-ipynb\"\n  }, \"https://gist.github.com/bigsnarfdude/2f7b2144065f6056892a98495644d3e0#file-demo_faster_rcnn_notebook-ipynb\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bigsnarfdude/Faster-RCNN_TF\"\n  }, \"https://github.com/bigsnarfdude/Faster-RCNN_TF\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Small U-Net for vehicle detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/@vivek.yadav/small-u-net-for-vehicle-detection-9eec216f9fd6#.md4u80kad\"\n  }, \"https://medium.com/@vivek.yadav/small-u-net-for-vehicle-detection-9eec216f9fd6#.md4u80kad\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Region of interest pooling explained\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://deepsense.io/region-of-interest-pooling-explained/\"\n  }, \"https://deepsense.io/region-of-interest-pooling-explained/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/deepsense-io/roi-pooling\"\n  }, \"https://github.com/deepsense-io/roi-pooling\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Supercharge your Computer Vision models with the TensorFlow Object Detection API\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://research.googleblog.com/2017/06/supercharge-your-computer-vision-models.html\"\n  }, \"https://research.googleblog.com/2017/06/supercharge-your-computer-vision-models.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tensorflow/models/tree/master/object_detection\"\n  }, \"https://github.com/tensorflow/models/tree/master/object_detection\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Understanding SSD MultiBox\\u200A\\u2014\\u200AReal-Time Object Detection In Deep Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://towardsdatascience.com/understanding-ssd-multibox-real-time-object-detection-in-deep-learning-495ef744fab\"\n  }, \"https://towardsdatascience.com/understanding-ssd-multibox-real-time-object-detection-in-deep-learning-495ef744fab\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"One-shot object detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://machinethink.net/blog/object-detection/\"\n  }, \"http://machinethink.net/blog/object-detection/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An overview of object detection: one-stage methods\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.jeremyjordan.me/object-detection-one-stage/\"\n  }, \"https://www.jeremyjordan.me/object-detection-one-stage/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"deep learning object detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: A paper list of object detection using deep learning.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hoya012/deep_learning_object_detection\"\n  }, \"https://github.com/hoya012/deep_learning_object_detection\"))));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"---\nlayout: post\ncategory: deep_learning\ntitle: Object Detection\ndate: 2015-10-09\n---\n\n| Method           | backbone      | test size | VOC2007 | VOC2010 | VOC2012 | ILSVRC 2013 | MSCOCO 2015                     | Speed                          |\n| :------------:   | :-----:       | :-----:   | :-----: | :-----: | :-----: | :---------: | :---------:                     | :---------:                    |\n| OverFeat         |               |           |         |         |         | 24.3%       |                                 |                                |\n| R-CNN            | AlexNet       |           | 58.5%   | 53.7%   | 53.3%   | 31.4%       |                                 |                                |\n| R-CNN            | VGG16         |           | 66.0%   |         |         |             |                                 |                                |\n| SPP_net          | ZF-5          |           | 54.2%   |         |         | 31.84%      |                                 |                                |\n| DeepID-Net       |               |           | 64.1%   |         |         | 50.3%       |                                 |                                |\n| NoC              | 73.3%         |           | 68.8%   |         |         |             |                                 |                                |\n| Fast-RCNN        | VGG16         |           | 70.0%   | 68.8%   | 68.4%   |             | 19.7%(@[0.5-0.95]), 35.9%(@0.5) |                                |\n| MR-CNN           | 78.2%         |           | 73.9%   |         |         |             |                                 |                                |\n| Faster-RCNN      | VGG16         |           | 78.8%   |         | 75.9%   |             | 21.9%(@[0.5-0.95]), 42.7%(@0.5) | 198ms                          |\n| Faster-RCNN      | ResNet101     |           | 85.6%   |         | 83.8%   |             | 37.4%(@[0.5-0.95]), 59.0%(@0.5) |                                |\n| YOLO             |               |           | 63.4%   |         | 57.9%   |             |                                 | 45 fps                         |\n| YOLO VGG-16      |               |           | 66.4%   |         |         |             |                                 | 21 fps                         |\n| YOLOv2           |               | 448x448   | 78.6%   |         | 73.4%   |             | 21.6%(@[0.5-0.95]), 44.0%(@0.5) | 40 fps                         |\n| SSD              | VGG16         | 300x300   | 77.2%   |         | 75.8%   |             | 25.1%(@[0.5-0.95]), 43.1%(@0.5) | 46 fps                         |\n| SSD              | VGG16         | 512x512   | 79.8%   |         | 78.5%   |             | 28.8%(@[0.5-0.95]), 48.5%(@0.5) | 19 fps                         |\n| SSD              | ResNet101     | 300x300   |         |         |         |             | 28.0%(@[0.5-0.95])              | 16 fps                         |\n| SSD              | ResNet101     | 512x512   |         |         |         |             | 31.2%(@[0.5-0.95])              | 8 fps                          |\n| DSSD             | ResNet101     | 300x300   |         |         |         |             | 28.0%(@[0.5-0.95])              | 8 fps                          |\n| DSSD             | ResNet101     | 500x500   |         |         |         |             | 33.2%(@[0.5-0.95])              | 6 fps                          |\n| ION              |               |           | 79.2%   |         | 76.4%   |             |                                 |                                |\n| CRAFT            |               |           | 75.7%   |         | 71.3%   | 48.5%       |                                 |                                |\n| OHEM             |               |           | 78.9%   |         | 76.3%   |             | 25.5%(@[0.5-0.95]), 45.9%(@0.5) |                                |\n| R-FCN            | ResNet50      |           | 77.4%   |         |         |             |                                 | 0.12sec(K40), 0.09sec(TitianX) |\n| R-FCN            | ResNet101     |           | 79.5%   |         |         |             |                                 | 0.17sec(K40), 0.12sec(TitianX) |\n| R-FCN(ms train)  | ResNet101     |           | 83.6%   |         | 82.0%   |             | 31.5%(@[0.5-0.95]), 53.2%(@0.5) |                                |\n| PVANet 9.0       |               |           | 84.9%   |         | 84.2%   |             |                                 | 750ms(CPU), 46ms(TitianX)      |\n| RetinaNet        | ResNet101-FPN |           |         |         |         |             |                                 |                                |\n| Light-Head R-CNN | Xception\\*    | 800/1200  |         |         |         |             | 31.5%@[0.5:0.95]                | 95 fps                         |\n| Light-Head R-CNN | Xception\\*    | 700/1100  |         |         |         |             | 30.7%@[0.5:0.95]                | 102 fps                        |\n\n# Papers\n\n**Deep Neural Networks for Object Detection**\n\n- paper: [http://papers.nips.cc/paper/5207-deep-neural-networks-for-object-detection.pdf](http://papers.nips.cc/paper/5207-deep-neural-networks-for-object-detection.pdf)\n\n**OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks**\n\n- arxiv: [http://arxiv.org/abs/1312.6229](http://arxiv.org/abs/1312.6229)\n- github: [https://github.com/sermanet/OverFeat](https://github.com/sermanet/OverFeat)\n- code: [http://cilvr.nyu.edu/doku.php?id=software:overfeat:start](http://cilvr.nyu.edu/doku.php?id=software:overfeat:start)\n\n**Scalable Object Detection using Deep Neural Networks**\n\n- intro: first MultiBox. Train a CNN to predict Region of Interest.\n- arxiv: [http://arxiv.org/abs/1312.2249](http://arxiv.org/abs/1312.2249)\n- github: [https://github.com/google/multibox](https://github.com/google/multibox)\n- blog: [https://research.googleblog.com/2014/12/high-quality-object-detection-at-scale.html](https://research.googleblog.com/2014/12/high-quality-object-detection-at-scale.html)\n\n**Scalable, High-Quality Object Detection**\n\n- intro: second MultiBox\n- arxiv: [http://arxiv.org/abs/1412.1441](http://arxiv.org/abs/1412.1441)\n- github: [https://github.com/google/multibox](https://github.com/google/multibox)\n\n**Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition**\n\n- intro: ECCV 2014 / TPAMI 2015\n- keywords: SPP-Net\n- arxiv: [http://arxiv.org/abs/1406.4729](http://arxiv.org/abs/1406.4729)\n- github: [https://github.com/ShaoqingRen/SPP_net](https://github.com/ShaoqingRen/SPP_net)\n- notes: [http://zhangliliang.com/2014/09/13/paper-note-sppnet/](http://zhangliliang.com/2014/09/13/paper-note-sppnet/)\n\n**DeepID-Net: Deformable Deep Convolutional Neural Networks for Object Detection**\n\n- intro: PAMI 2016\n- intro: an extension of R-CNN. box pre-training, cascade on region proposals, deformation layers and context representations\n- project page: [http://www.ee.cuhk.edu.hk/%CB%9Cwlouyang/projects/imagenetDeepId/index.html](http://www.ee.cuhk.edu.hk/%CB%9Cwlouyang/projects/imagenetDeepId/index.html)\n- arxiv: [http://arxiv.org/abs/1412.5661](http://arxiv.org/abs/1412.5661)\n\n**Object Detectors Emerge in Deep Scene CNNs**\n\n- intro: ICLR 2015\n- arxiv: [http://arxiv.org/abs/1412.6856](http://arxiv.org/abs/1412.6856)\n- paper: [https://www.robots.ox.ac.uk/~vgg/rg/papers/zhou_iclr15.pdf](https://www.robots.ox.ac.uk/~vgg/rg/papers/zhou_iclr15.pdf)\n- paper: [https://people.csail.mit.edu/khosla/papers/iclr2015_zhou.pdf](https://people.csail.mit.edu/khosla/papers/iclr2015_zhou.pdf)\n- slides: [http://places.csail.mit.edu/slide_iclr2015.pdf](http://places.csail.mit.edu/slide_iclr2015.pdf)\n\n**segDeepM: Exploiting Segmentation and Context in Deep Neural Networks for Object Detection**\n\n- intro: CVPR 2015\n- project(code+data): [https://www.cs.toronto.edu/~yukun/segdeepm.html](https://www.cs.toronto.edu/~yukun/segdeepm.html)\n- arxiv: [https://arxiv.org/abs/1502.04275](https://arxiv.org/abs/1502.04275)\n- github: [https://github.com/YknZhu/segDeepM](https://github.com/YknZhu/segDeepM)\n\n**Object Detection Networks on Convolutional Feature Maps**\n\n- intro: TPAMI 2015\n- keywords: NoC\n- arxiv: [http://arxiv.org/abs/1504.06066](http://arxiv.org/abs/1504.06066)\n\n**Improving Object Detection with Deep Convolutional Networks via Bayesian Optimization and Structured Prediction**\n\n- arxiv: [http://arxiv.org/abs/1504.03293](http://arxiv.org/abs/1504.03293)\n- slides: [http://www.ytzhang.net/files/publications/2015-cvpr-det-slides.pdf](http://www.ytzhang.net/files/publications/2015-cvpr-det-slides.pdf)\n- github: [https://github.com/YutingZhang/fgs-obj](https://github.com/YutingZhang/fgs-obj)\n\n**DeepBox: Learning Objectness with Convolutional Networks**\n\n- keywords: DeepBox\n- arxiv: [http://arxiv.org/abs/1505.02146](http://arxiv.org/abs/1505.02146)\n- github: [https://github.com/weichengkuo/DeepBox](https://github.com/weichengkuo/DeepBox)\n\n**Object detection via a multi-region & semantic segmentation-aware CNN model**\n\n- intro: ICCV 2015\n- keywords: MR-CNN\n- arxiv: [http://arxiv.org/abs/1505.01749](http://arxiv.org/abs/1505.01749)\n- github: [https://github.com/gidariss/mrcnn-object-detection](https://github.com/gidariss/mrcnn-object-detection)\n- notes: [http://zhangliliang.com/2015/05/17/paper-note-ms-cnn/](http://zhangliliang.com/2015/05/17/paper-note-ms-cnn/)\n- notes: [http://blog.cvmarcher.com/posts/2015/05/17/multi-region-semantic-segmentation-aware-cnn/](http://blog.cvmarcher.com/posts/2015/05/17/multi-region-semantic-segmentation-aware-cnn/)\n\n**AttentionNet: Aggregating Weak Directions for Accurate Object Detection**\n\n- intro: ICCV 2015\n- intro: state-of-the-art performance of 65% (AP) on PASCAL VOC 2007/2012 human detection task\n- arxiv: [http://arxiv.org/abs/1506.07704](http://arxiv.org/abs/1506.07704)\n- slides: [https://www.robots.ox.ac.uk/~vgg/rg/slides/AttentionNet.pdf](https://www.robots.ox.ac.uk/~vgg/rg/slides/AttentionNet.pdf)\n- slides: [http://image-net.org/challenges/talks/lunit-kaist-slide.pdf](http://image-net.org/challenges/talks/lunit-kaist-slide.pdf)\n\n## DenseBox\n\n**DenseBox: Unifying Landmark Localization with End to End Object Detection**\n\n- arxiv: [http://arxiv.org/abs/1509.04874](http://arxiv.org/abs/1509.04874)\n- demo: [http://pan.baidu.com/s/1mgoWWsS](http://pan.baidu.com/s/1mgoWWsS)\n- KITTI result: [http://www.cvlibs.net/datasets/kitti/eval_object.php](http://www.cvlibs.net/datasets/kitti/eval_object.php)\n\n**Inside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks**\n\n- intro: \"0.8s per image on a Titan X GPU (excluding proposal generation) without two-stage bounding-box regression\nand 1.15s per image with it\".\n- keywords: Inside-Outside Net (ION)\n- arxiv: [http://arxiv.org/abs/1512.04143](http://arxiv.org/abs/1512.04143)\n- slides: [http://www.seanbell.ca/tmp/ion-coco-talk-bell2015.pdf](http://www.seanbell.ca/tmp/ion-coco-talk-bell2015.pdf)\n- coco-leaderboard: [http://mscoco.org/dataset/#detections-leaderboard](http://mscoco.org/dataset/#detections-leaderboard)\n\n**Adaptive Object Detection Using Adjacency and Zoom Prediction**\n\n- intro: CVPR 2016. AZ-Net\n- arxiv: [http://arxiv.org/abs/1512.07711](http://arxiv.org/abs/1512.07711)\n- github: [https://github.com/luyongxi/az-net](https://github.com/luyongxi/az-net)\n- youtube: [https://www.youtube.com/watch?v=YmFtuNwxaNM](https://www.youtube.com/watch?v=YmFtuNwxaNM)\n\n**G-CNN: an Iterative Grid Based Object Detector**\n\n- arxiv: [http://arxiv.org/abs/1512.07729](http://arxiv.org/abs/1512.07729)\n\n**We don't need no bounding-boxes: Training object class detectors using only human verification**\n\n- arxiv: [http://arxiv.org/abs/1602.08405](http://arxiv.org/abs/1602.08405)\n\n**HyperNet: Towards Accurate Region Proposal Generation and Joint Object Detection**\n\n- arxiv: [http://arxiv.org/abs/1604.00600](http://arxiv.org/abs/1604.00600)\n\n**A MultiPath Network for Object Detection**\n\n- intro: BMVC 2016. Facebook AI Research (FAIR)\n- arxiv: [http://arxiv.org/abs/1604.02135](http://arxiv.org/abs/1604.02135)\n- github: [https://github.com/facebookresearch/multipathnet](https://github.com/facebookresearch/multipathnet)\n\n**CRAFT Objects from Images**\n\n- intro: CVPR 2016. Cascade Region-proposal-network And FasT-rcnn. an extension of Faster R-CNN\n- project page: [http://byangderek.github.io/projects/craft.html](http://byangderek.github.io/projects/craft.html)\n- arxiv: [https://arxiv.org/abs/1604.03239](https://arxiv.org/abs/1604.03239)\n- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Yang_CRAFT_Objects_From_CVPR_2016_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Yang_CRAFT_Objects_From_CVPR_2016_paper.pdf)\n- github: [https://github.com/byangderek/CRAFT](https://github.com/byangderek/CRAFT)\n\n## OHEM\n\n**Training Region-based Object Detectors with Online Hard Example Mining**\n\n- intro: CVPR 2016 Oral. Online hard example mining (OHEM)\n- arxiv: [http://arxiv.org/abs/1604.03540](http://arxiv.org/abs/1604.03540)\n- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Shrivastava_Training_Region-Based_Object_CVPR_2016_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Shrivastava_Training_Region-Based_Object_CVPR_2016_paper.pdf)\n- github(Official): [https://github.com/abhi2610/ohem](https://github.com/abhi2610/ohem)\n- author page: [http://abhinav-shrivastava.info/](http://abhinav-shrivastava.info/)\n\n**S-OHEM: Stratified Online Hard Example Mining for Object Detection**\n\n[https://arxiv.org/abs/1705.02233](https://arxiv.org/abs/1705.02233)\n\n- - -\n\n**Exploit All the Layers: Fast and Accurate CNN Object Detector with Scale Dependent Pooling and Cascaded Rejection Classifiers**\n\n- intro: CVPR 2016\n- keywords: scale-dependent pooling  (SDP), cascaded rejection classifiers (CRC)\n- paper: [http://www-personal.umich.edu/~wgchoi/SDP-CRC_camready.pdf](http://www-personal.umich.edu/~wgchoi/SDP-CRC_camready.pdf)\n\n## R-FCN\n\n**R-FCN: Object Detection via Region-based Fully Convolutional Networks**\n\n- arxiv: [http://arxiv.org/abs/1605.06409](http://arxiv.org/abs/1605.06409)\n- github: [https://github.com/daijifeng001/R-FCN](https://github.com/daijifeng001/R-FCN)\n- github(MXNet): [https://github.com/msracver/Deformable-ConvNets/tree/master/rfcn](https://github.com/msracver/Deformable-ConvNets/tree/master/rfcn)\n- github: [https://github.com/Orpine/py-R-FCN](https://github.com/Orpine/py-R-FCN)\n- github: [https://github.com/PureDiors/pytorch_RFCN](https://github.com/PureDiors/pytorch_RFCN)\n- github: [https://github.com/bharatsingh430/py-R-FCN-multiGPU](https://github.com/bharatsingh430/py-R-FCN-multiGPU)\n- github: [https://github.com/xdever/RFCN-tensorflow](https://github.com/xdever/RFCN-tensorflow)\n\n**R-FCN-3000 at 30fps: Decoupling Detection and Classification**\n\n[https://arxiv.org/abs/1712.01802](https://arxiv.org/abs/1712.01802)\n\n**Recycle deep features for better object detection**\n\n- arxiv: [http://arxiv.org/abs/1607.05066](http://arxiv.org/abs/1607.05066)\n\n**A Unified Multi-scale Deep Convolutional Neural Network for Fast Object Detection**\n\n- intro: ECCV 2016\n- intro: 640480: 15 fps, 960720: 8 fps\n- keywords: MS-CNN\n- arxiv: [http://arxiv.org/abs/1607.07155](http://arxiv.org/abs/1607.07155)\n- github: [https://github.com/zhaoweicai/mscnn](https://github.com/zhaoweicai/mscnn)\n- poster: [http://www.eccv2016.org/files/posters/P-2B-38.pdf](http://www.eccv2016.org/files/posters/P-2B-38.pdf)\n\n**Multi-stage Object Detection with Group Recursive Learning**\n\n- intro: VOC2007: 78.6%, VOC2012: 74.9%\n- arxiv: [http://arxiv.org/abs/1608.05159](http://arxiv.org/abs/1608.05159)\n\n**Subcategory-aware Convolutional Neural Networks for Object Proposals and Detection**\n\n- intro: WACV 2017. SubCNN\n- arxiv: [http://arxiv.org/abs/1604.04693](http://arxiv.org/abs/1604.04693)\n- github: [https://github.com/tanshen/SubCNN](https://github.com/tanshen/SubCNN)\n\n**PVANet: Lightweight Deep Neural Networks for Real-time Object Detection**\n\n- intro: Presented at NIPS 2016 Workshop on Efficient Methods for Deep Neural Networks (EMDNN). \nContinuation of [arXiv:1608.08021](https://arxiv.org/abs/1608.08021)\n- arxiv: [https://arxiv.org/abs/1611.08588](https://arxiv.org/abs/1611.08588)\n- github: [https://github.com/sanghoon/pva-faster-rcnn](https://github.com/sanghoon/pva-faster-rcnn)\n- leaderboard(PVANet 9.0): [http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=4](http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=4)\n\n**Gated Bi-directional CNN for Object Detection**\n\n- intro: The Chinese University of Hong Kong & Sensetime Group Limited\n- keywords: GBD-Net\n- paper: [http://link.springer.com/chapter/10.1007/978-3-319-46478-7_22](http://link.springer.com/chapter/10.1007/978-3-319-46478-7_22)\n- mirror: [https://pan.baidu.com/s/1dFohO7v](https://pan.baidu.com/s/1dFohO7v)\n\n**Crafting GBD-Net for Object Detection**\n\n- intro: winner of the ImageNet object detection challenge of 2016. CUImage and CUVideo\n- intro: gated bi-directional CNN (GBD-Net)\n- arxiv: [https://arxiv.org/abs/1610.02579](https://arxiv.org/abs/1610.02579)\n- github: [https://github.com/craftGBD/craftGBD](https://github.com/craftGBD/craftGBD)\n\n**StuffNet: Using 'Stuff' to Improve Object Detection**\n\n- arxiv: [https://arxiv.org/abs/1610.05861](https://arxiv.org/abs/1610.05861)\n\n**Generalized Haar Filter based Deep Networks for Real-Time Object Detection in Traffic Scene**\n\n- arxiv: [https://arxiv.org/abs/1610.09609](https://arxiv.org/abs/1610.09609)\n\n**Hierarchical Object Detection with Deep Reinforcement Learning**\n\n- intro: Deep Reinforcement Learning Workshop (NIPS 2016)\n- project page: [https://imatge-upc.github.io/detection-2016-nipsws/](https://imatge-upc.github.io/detection-2016-nipsws/)\n- arxiv: [https://arxiv.org/abs/1611.03718](https://arxiv.org/abs/1611.03718)\n- slides: [http://www.slideshare.net/xavigiro/hierarchical-object-detection-with-deep-reinforcement-learning](http://www.slideshare.net/xavigiro/hierarchical-object-detection-with-deep-reinforcement-learning)\n- github: [https://github.com/imatge-upc/detection-2016-nipsws](https://github.com/imatge-upc/detection-2016-nipsws)\n- blog: [http://jorditorres.org/nips/](http://jorditorres.org/nips/)\n\n**Learning to detect and localize many objects from few examples**\n\n- arxiv: [https://arxiv.org/abs/1611.05664](https://arxiv.org/abs/1611.05664)\n\n**Speed/accuracy trade-offs for modern convolutional object detectors**\n\n- intro: CVPR 2017. Google Research\n- arxiv: [https://arxiv.org/abs/1611.10012](https://arxiv.org/abs/1611.10012)\n\n**SqueezeDet: Unified, Small, Low Power Fully Convolutional Neural Networks for Real-Time Object Detection for Autonomous Driving**\n\n- arxiv: [https://arxiv.org/abs/1612.01051](https://arxiv.org/abs/1612.01051)\n- github: [https://github.com/BichenWuUCB/squeezeDet](https://github.com/BichenWuUCB/squeezeDet)\n- github: [https://github.com/fregu856/2D_detection](https://github.com/fregu856/2D_detection)\n\n## Feature Pyramid Network (FPN)\n\n**Feature Pyramid Networks for Object Detection**\n\n- intro: Facebook AI Research\n- arxiv: [https://arxiv.org/abs/1612.03144](https://arxiv.org/abs/1612.03144)\n\n**Dynamic Feature Pyramid Networks for Object Detection**\n\n- intro: Zhejiang University & Noahs Ark Lab & Westlake University\n- arxiv: [https://arxiv.org/abs/2012.00779](https://arxiv.org/abs/2012.00779)\n\n**Implicit Feature Pyramid Network for Object Detection**\n\n- intro: MEGVII Technology\n- arxiv: [https://arxiv.org/abs/2012.13563](https://arxiv.org/abs/2012.13563)\n\n**You Should Look at All Objects**\n\n- intro: ECCV 2022\n- intro: The University of Hong Kong & Bytedance & University of Rochester\n- arxiv: [https://arxiv.org/abs/2207.07889](https://arxiv.org/abs/2207.07889)\n- github: [https://github.com/CharlesPikachu/YSLAO](https://github.com/CharlesPikachu/YSLAO)\n\n**Action-Driven Object Detection with Top-Down Visual Attentions**\n\n- arxiv: [https://arxiv.org/abs/1612.06704](https://arxiv.org/abs/1612.06704)\n\n**Beyond Skip Connections: Top-Down Modulation for Object Detection**\n\n- intro: CMU & UC Berkeley & Google Research\n- arxiv: [https://arxiv.org/abs/1612.06851](https://arxiv.org/abs/1612.06851)\n\n**Wide-Residual-Inception Networks for Real-time Object Detection**\n\n- intro: Inha University\n- arxiv: [https://arxiv.org/abs/1702.01243](https://arxiv.org/abs/1702.01243)\n\n**Attentional Network for Visual Object Detection**\n\n- intro: University of Maryland & Mitsubishi Electric Research Laboratories\n- arxiv: [https://arxiv.org/abs/1702.01478](https://arxiv.org/abs/1702.01478)\n\n**Learning Chained Deep Features and Classifiers for Cascade in Object Detection**\n\n- keykwords: CC-Net\n- intro: chained cascade network (CC-Net). 81.1% mAP on PASCAL VOC 2007\n- arxiv: [https://arxiv.org/abs/1702.07054](https://arxiv.org/abs/1702.07054)\n\n**DeNet: Scalable Real-time Object Detection with Directed Sparse Sampling**\n\n- intro: ICCV 2017 (poster)\n- arxiv: [https://arxiv.org/abs/1703.10295](https://arxiv.org/abs/1703.10295)\n\n**Discriminative Bimodal Networks for Visual Localization and Detection with Natural Language Queries**\n\n- intro: CVPR 2017\n- arxiv: [https://arxiv.org/abs/1704.03944](https://arxiv.org/abs/1704.03944)\n\n**Spatial Memory for Context Reasoning in Object Detection**\n\n- arxiv: [https://arxiv.org/abs/1704.04224](https://arxiv.org/abs/1704.04224)\n\n**Deep Occlusion Reasoning for Multi-Camera Multi-Target Detection**\n\n[https://arxiv.org/abs/1704.05775](https://arxiv.org/abs/1704.05775)\n\n**LCDet: Low-Complexity Fully-Convolutional Neural Networks for Object Detection in Embedded Systems**\n\n- intro: Embedded Vision Workshop in CVPR. UC San Diego & Qualcomm Inc\n- arxiv: [https://arxiv.org/abs/1705.05922](https://arxiv.org/abs/1705.05922)\n\n**Point Linking Network for Object Detection**\n\n- intro: Point Linking Network (PLN)\n- arxiv: [https://arxiv.org/abs/1706.03646](https://arxiv.org/abs/1706.03646)\n\n**Perceptual Generative Adversarial Networks for Small Object Detection**\n\n[https://arxiv.org/abs/1706.05274](https://arxiv.org/abs/1706.05274)\n\n**Few-shot Object Detection**\n\n[https://arxiv.org/abs/1706.08249](https://arxiv.org/abs/1706.08249)\n\n**Yes-Net: An effective Detector Based on Global Information**\n\n[https://arxiv.org/abs/1706.09180](https://arxiv.org/abs/1706.09180)\n\n**Towards lightweight convolutional neural networks for object detection**\n\n[https://arxiv.org/abs/1707.01395](https://arxiv.org/abs/1707.01395)\n\n**RON: Reverse Connection with Objectness Prior Networks for Object Detection**\n\n- intro: CVPR 2017\n- arxiv: [https://arxiv.org/abs/1707.01691](https://arxiv.org/abs/1707.01691)\n- github: [https://github.com/taokong/RON](https://github.com/taokong/RON)\n\n**Deformable Part-based Fully Convolutional Network for Object Detection**\n\n- intro: BMVC 2017 (oral). Sorbonne Universits & CEDRIC\n- arxiv: [https://arxiv.org/abs/1707.06175](https://arxiv.org/abs/1707.06175)\n\n**Adaptive Feeding: Achieving Fast and Accurate Detections by Adaptively Combining Object Detectors**\n\n- intro: ICCV 2017\n- arxiv: [https://arxiv.org/abs/1707.06399](https://arxiv.org/abs/1707.06399)\n\n**Recurrent Scale Approximation for Object Detection in CNN**\n\n- intro: ICCV 2017\n- keywords: Recurrent Scale Approximation (RSA)\n- arxiv: [https://arxiv.org/abs/1707.09531](https://arxiv.org/abs/1707.09531)\n- github: [https://github.com/sciencefans/RSA-for-object-detection](https://github.com/sciencefans/RSA-for-object-detection)\n\n**DSOD: Learning Deeply Supervised Object Detectors from Scratch**\n\n![](https://user-images.githubusercontent.com/3794909/28934967-718c9302-78b5-11e7-89ee-8b514e53e23c.png)\n\n- intro: ICCV 2017. Fudan University & Tsinghua University & Intel Labs China\n- arxiv: [https://arxiv.org/abs/1708.01241](https://arxiv.org/abs/1708.01241)\n- github: [https://github.com/szq0214/DSOD](https://github.com/szq0214/DSOD)\n\n**Object Detection from Scratch with Deep Supervision**\n\n[https://arxiv.org/abs/1809.09294](https://arxiv.org/abs/1809.09294)\n\n**CoupleNet: Coupling Global Structure with Local Parts for Object Detection**\n\n- intro: ICCV 2017\n- arxiv: [https://arxiv.org/abs/1708.02863](https://arxiv.org/abs/1708.02863)\n\n**Incremental Learning of Object Detectors without Catastrophic Forgetting**\n\n- intro: ICCV 2017. Inria\n- arxiv: [https://arxiv.org/abs/1708.06977](https://arxiv.org/abs/1708.06977)\n\n**Zoom Out-and-In Network with Map Attention Decision for Region Proposal and Object Detection**\n\n[https://arxiv.org/abs/1709.04347](https://arxiv.org/abs/1709.04347)\n\n**StairNet: Top-Down Semantic Aggregation for Accurate One Shot Detection**\n\n[https://arxiv.org/abs/1709.05788](https://arxiv.org/abs/1709.05788)\n\n**Dynamic Zoom-in Network for Fast Object Detection in Large Images**\n\n[https://arxiv.org/abs/1711.05187](https://arxiv.org/abs/1711.05187)\n\n**Zero-Annotation Object Detection with Web Knowledge Transfer**\n\n- intro: NTU, Singapore & Amazon\n- keywords: multi-instance multi-label domain adaption learning framework\n- arxiv: [https://arxiv.org/abs/1711.05954](https://arxiv.org/abs/1711.05954)\n\n**MegDet: A Large Mini-Batch Object Detector**\n\n- intro: Peking University & Tsinghua University & Megvii Inc\n- arxiv: [https://arxiv.org/abs/1711.07240](https://arxiv.org/abs/1711.07240)\n\n**Receptive Field Block Net for Accurate and Fast Object Detection**\n\n- intro: RFBNet\n- arxiv: [https://arxiv.org/abs/1711.07767](https://arxiv.org/abs/1711.07767)\n- github: [https://github.com//ruinmessi/RFBNet](https://github.com//ruinmessi/RFBNet)\n\n**An Analysis of Scale Invariance in Object Detection - SNIP**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1711.08189](https://arxiv.org/abs/1711.08189)\n- github: [https://github.com/bharatsingh430/snip](https://github.com/bharatsingh430/snip)\n\n**Feature Selective Networks for Object Detection**\n\n[https://arxiv.org/abs/1711.08879](https://arxiv.org/abs/1711.08879)\n\n**Learning a Rotation Invariant Detector with Rotatable Bounding Box**\n\n- arxiv: [https://arxiv.org/abs/1711.09405](https://arxiv.org/abs/1711.09405)\n- github(official, Caffe): [https://github.com/liulei01/DRBox](https://github.com/liulei01/DRBox)\n\n**Scalable Object Detection for Stylized Objects**\n\n- intro: Microsoft AI & Research Munich\n- arxiv: [https://arxiv.org/abs/1711.09822](https://arxiv.org/abs/1711.09822)\n\n**Learning Object Detectors from Scratch with Gated Recurrent Feature Pyramids**\n\n- arxiv: [https://arxiv.org/abs/1712.00886](https://arxiv.org/abs/1712.00886)\n- github: [https://github.com/szq0214/GRP-DSOD](https://github.com/szq0214/GRP-DSOD)\n\n**Deep Regionlets for Object Detection**\n\n- keywords: region selection network, gating network\n- arxiv: [https://arxiv.org/abs/1712.02408](https://arxiv.org/abs/1712.02408)\n\n**Training and Testing Object Detectors with Virtual Images**\n\n- intro: IEEE/CAA Journal of Automatica Sinica\n- arxiv: [https://arxiv.org/abs/1712.08470](https://arxiv.org/abs/1712.08470)\n\n**Large-Scale Object Discovery and Detector Adaptation from Unlabeled Video**\n\n- keywords: object mining, object tracking, unsupervised object discovery by appearance-based clustering, self-supervised detector adaptation\n- arxiv: [https://arxiv.org/abs/1712.08832](https://arxiv.org/abs/1712.08832)\n\n**Spot the Difference by Object Detection**\n\n- intro: Tsinghua University & JD Group\n- arxiv: [https://arxiv.org/abs/1801.01051](https://arxiv.org/abs/1801.01051)\n\n**Localization-Aware Active Learning for Object Detection**\n\n- arxiv: [https://arxiv.org/abs/1801.05124](https://arxiv.org/abs/1801.05124)\n\n**Object Detection with Mask-based Feature Encoding**\n\n[https://arxiv.org/abs/1802.03934](https://arxiv.org/abs/1802.03934)\n\n**LSTD: A Low-Shot Transfer Detector for Object Detection**\n\n- intro: AAAI 2018\n- arxiv: [https://arxiv.org/abs/1803.01529](https://arxiv.org/abs/1803.01529)\n\n**Pseudo Mask Augmented Object Detection**\n\n[https://arxiv.org/abs/1803.05858](https://arxiv.org/abs/1803.05858)\n\n**Revisiting RCNN: On Awakening the Classification Power of Faster RCNN**\n\n- intro: ECCV 2018\n- keywords: DCR V1\n- arxiv: [https://arxiv.org/abs/1803.06799](https://arxiv.org/abs/1803.06799)\n- github(official, MXNet): [https://github.com/bowenc0221/Decoupled-Classification-Refinement](https://github.com/bowenc0221/Decoupled-Classification-Refinement)\n\n**Decoupled Classification Refinement: Hard False Positive Suppression for Object Detection**\n\n- keywords: DCR V2\n- arxiv: [https://arxiv.org/abs/1810.04002](https://arxiv.org/abs/1810.04002)\n- github(official, MXNet): [https://github.com/bowenc0221/Decoupled-Classification-Refinement](https://github.com/bowenc0221/Decoupled-Classification-Refinement)\n\n**Learning Region Features for Object Detection**\n\n- intro: Peking University & MSRA\n- arxiv: [https://arxiv.org/abs/1803.07066](https://arxiv.org/abs/1803.07066)\n\n**Object Detection for Comics using Manga109 Annotations**\n\n- intro: University of Tokyo & National Institute of Informatics, Japan\n- arxiv: [https://arxiv.org/abs/1803.08670](https://arxiv.org/abs/1803.08670)\n\n**Task-Driven Super Resolution: Object Detection in Low-resolution Images**\n\n[https://arxiv.org/abs/1803.11316](https://arxiv.org/abs/1803.11316)\n\n**Transferring Common-Sense Knowledge for Object Detection**\n\n[https://arxiv.org/abs/1804.01077](https://arxiv.org/abs/1804.01077)\n\n**Multi-scale Location-aware Kernel Representation for Object Detection**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1804.00428](https://arxiv.org/abs/1804.00428)\n- github: [https://github.com/Hwang64/MLKP](https://github.com/Hwang64/MLKP)\n\n**Loss Rank Mining: A General Hard Example Mining Method for Real-time Detectors**\n\n- intro: National University of Defense Technology\n- arxiv: [https://arxiv.org/abs/1804.04606](https://arxiv.org/abs/1804.04606)\n\n**DetNet: A Backbone network for Object Detection**\n\n- intro: Tsinghua University & Megvii Inc\n- arxiv: [https://arxiv.org/abs/1804.06215](https://arxiv.org/abs/1804.06215)\n\n**AdvDetPatch: Attacking Object Detectors with Adversarial Patches**\n\n[https://arxiv.org/abs/1806.02299](https://arxiv.org/abs/1806.02299)\n\n**Attacking Object Detectors via Imperceptible Patches on Background**\n\n[https://arxiv.org/abs/1809.05966](https://arxiv.org/abs/1809.05966)\n\n**Physical Adversarial Examples for Object Detectors**\n\n- intro: WOOT 2018\n- arxiv: [https://arxiv.org/abs/1807.07769](https://arxiv.org/abs/1807.07769)\n\n**Object detection at 200 Frames Per Second**\n\n- intro: United Technologies Research Center-Ireland\n- arxiv: [https://arxiv.org/abs/1805.06361](https://arxiv.org/abs/1805.06361)\n\n**Object Detection using Domain Randomization and Generative Adversarial Refinement of Synthetic Images**\n\n- intro: CVPR 2018 Deep Vision Workshop\n- arxiv: [https://arxiv.org/abs/1805.11778](https://arxiv.org/abs/1805.11778)\n\n**SNIPER: Efficient Multi-Scale Training**\n\n- intro: University of Maryland\n- keywords: SNIPER (Scale Normalization for Image Pyramid with Efficient Resampling)\n- arxiv: [https://arxiv.org/abs/1805.09300](https://arxiv.org/abs/1805.09300)\n- github: [https://github.com/mahyarnajibi/SNIPER](https://github.com/mahyarnajibi/SNIPER)\n\n**Soft Sampling for Robust Object Detection**\n\n[https://arxiv.org/abs/1806.06986](https://arxiv.org/abs/1806.06986)\n\n**MetaAnchor: Learning to Detect Objects with Customized Anchors**\n\n- intro: Megvii Inc (Face++) & Fudan University\n- arxiv: [https://arxiv.org/abs/1807.00980](https://arxiv.org/abs/1807.00980)\n\n**Localization Recall Precision (LRP): A New Performance Metric for Object Detection**\n\n- intro: ECCV 2018. Middle East Technical University\n- arxiv: [https://arxiv.org/abs/1807.01696](https://arxiv.org/abs/1807.01696)\n- github: [https://github.com/cancam/LRP](https://github.com/cancam/LRP)\n\n**Pooling Pyramid Network for Object Detection**\n\n- intro: Google AI Perception\n- arxiv: [https://arxiv.org/abs/1807.03284](https://arxiv.org/abs/1807.03284)\n\n**Modeling Visual Context is Key to Augmenting Object Detection Datasets**\n\n- intro: ECCV 2018\n- arxiv: [https://arxiv.org/abs/1807.07428](https://arxiv.org/abs/1807.07428)\n\n**Acquisition of Localization Confidence for Accurate Object Detection**\n\n- intro: ECCV 2018\n- arxiv: [https://arxiv.org/abs/1807.11590](https://arxiv.org/abs/1807.11590)\n- gihtub: [https://github.com/vacancy/PreciseRoIPooling](https://github.com/vacancy/PreciseRoIPooling)\n\n**CornerNet: Detecting Objects as Paired Keypoints**\n\n- intro: ECCV 2018\n- keywords: IoU-Net, PreciseRoIPooling\n- arxiv: [https://arxiv.org/abs/1808.01244](https://arxiv.org/abs/1808.01244)\n- github: [https://github.com/umich-vl/CornerNet](https://github.com/umich-vl/CornerNet)\n\n**Unsupervised Hard Example Mining from Videos for Improved Object Detection**\n\n- intro: ECCV 2018\n- arxiv: [https://arxiv.org/abs/1808.04285](https://arxiv.org/abs/1808.04285)\n\n**SAN: Learning Relationship between Convolutional Features for Multi-Scale Object Detection**\n\n[https://arxiv.org/abs/1808.04974](https://arxiv.org/abs/1808.04974)\n\n**A Survey of Modern Object Detection Literature using Deep Learning**\n\n[https://arxiv.org/abs/1808.07256](https://arxiv.org/abs/1808.07256)\n\n**Tiny-DSOD: Lightweight Object Detection for Resource-Restricted Usages**\n\n- intro: BMVC 2018\n- arxiv: [https://arxiv.org/abs/1807.11013](https://arxiv.org/abs/1807.11013)\n- github: [https://github.com/lyxok1/Tiny-DSOD](https://github.com/lyxok1/Tiny-DSOD)\n\n**Deep Feature Pyramid Reconfiguration for Object Detection**\n\n- intro: ECCV 2018\n- arxiv: [https://arxiv.org/abs/1808.07993](https://arxiv.org/abs/1808.07993)\n\n**MDCN: Multi-Scale, Deep Inception Convolutional Neural Networks for Efficient Object Detection**\n\n- intro: ICPR 2018\n- arxiv: [https://arxiv.org/abs/1809.01791](https://arxiv.org/abs/1809.01791)\n\n**Recent Advances in Object Detection in the Age of Deep Convolutional Neural Networks**\n\n[https://arxiv.org/abs/1809.03193](https://arxiv.org/abs/1809.03193)\n\n**Deep Learning for Generic Object Detection: A Survey**\n\n[https://arxiv.org/abs/1809.02165](https://arxiv.org/abs/1809.02165)\n\n**Training Confidence-Calibrated Classifier for Detecting Out-of-Distribution Samples**\n\n- intro: ICLR 2018\n- arxiv: [https://github.com/alinlab/Confident_classifier](https://github.com/alinlab/Confident_classifier)\n\n**Fast and accurate object detection in high resolution 4K and 8K video using GPUs**\n\n- intro: Best Paper Finalist at IEEE High Performance Extreme Computing Conference (HPEC) 2018\n- intro: Carnegie Mellon University\n- arxiv: [https://arxiv.org/abs/1810.10551](https://arxiv.org/abs/1810.10551)\n\n**Hybrid Knowledge Routed Modules for Large-scale Object Detection**\n\n- intro: NIPS 2018\n- arxiv: [https://arxiv.org/abs/1810.12681](https://arxiv.org/abs/1810.12681)\n- github(official, PyTorch): [https://github.com/chanyn/HKRM](https://github.com/chanyn/HKRM)\n\n**BAN: Focusing on Boundary Context for Object Detection**\n\n[https://arxiv.org/abs/1811.05243](https://arxiv.org/abs/1811.05243)\n\n**R2CNN++: Multi-Dimensional Attention Based Rotation Invariant Detector with Robust Anchor Strategy**\n\n- arxiv: [https://arxiv.org/abs/1811.07126](https://arxiv.org/abs/1811.07126)\n- github: [https://github.com/DetectionTeamUCAS/R2CNN-Plus-Plus_Tensorflow](https://github.com/DetectionTeamUCAS/R2CNN-Plus-Plus_Tensorflow)\n\n**DeRPN: Taking a further step toward more general object detection**\n\n- intro: AAAI 2019\n- intro: South China University of Technology\n- ariv: [https://arxiv.org/abs/1811.06700](https://arxiv.org/abs/1811.06700)\n- github: [https://github.com/HCIILAB/DeRPN](https://github.com/HCIILAB/DeRPN)\n\n**Fast Efficient Object Detection Using Selective Attention**\n\n[https://arxiv.org/abs/1811.07502](https://arxiv.org/abs/1811.07502)\n\n**Sampling Techniques for Large-Scale Object Detection from Sparsely Annotated Objects**\n\n[https://arxiv.org/abs/1811.10862](https://arxiv.org/abs/1811.10862)\n\n**Efficient Coarse-to-Fine Non-Local Module for the Detection of Small Objects**\n\n[https://arxiv.org/abs/1811.12152](https://arxiv.org/abs/1811.12152)\n\n**Deep Regionlets: Blended Representation and Deep Learning for Generic Object Detection**\n\n[https://arxiv.org/abs/1811.11318](https://arxiv.org/abs/1811.11318)\n\n**Transferable Adversarial Attacks for Image and Video Object Detection**\n\n[https://arxiv.org/abs/1811.12641](https://arxiv.org/abs/1811.12641)\n\n**Anchor Box Optimization for Object Detection**\n\n- intro: University of Illinois at Urbana-Champaign & Microsoft Research\n- arxiv: [https://arxiv.org/abs/1812.00469](https://arxiv.org/abs/1812.00469)\n\n**AutoFocus: Efficient Multi-Scale Inference**\n\n- intro: University of Maryland\n- arxiv: [https://arxiv.org/abs/1812.01600](https://arxiv.org/abs/1812.01600)\n\n**Few-shot Object Detection via Feature Reweighting**\n\n[https://arxiv.org/abs/1812.01866](https://arxiv.org/abs/1812.01866)\n\n**Practical Adversarial Attack Against Object Detector**\n\n[https://arxiv.org/abs/1812.10217](https://arxiv.org/abs/1812.10217)\n\n**Scale-Aware Trident Networks for Object Detection**\n\n- intro: University of Chinese Academy of Sciences & TuSimple\n- arxiv: [https://arxiv.org/abs/1901.01892](https://arxiv.org/abs/1901.01892)\n- github: [https://github.com/TuSimple/simpledet](https://github.com/TuSimple/simpledet)\n\n**Region Proposal by Guided Anchoring**\n\n- intro: CVPR 2019\n- intro: CUHK - SenseTime Joint Lab & Amazon Rekognition & Nanyang Technological University\n- arxiv: [https://arxiv.org/abs/1901.03278](https://arxiv.org/abs/1901.03278)\n\n**Bottom-up Object Detection by Grouping Extreme and Center Points**\n\n- keywords: ExtremeNet\n- arxiv: [https://arxiv.org/abs/1901.08043](https://arxiv.org/abs/1901.08043)\n- github: [https://github.com/xingyizhou/ExtremeNet](https://github.com/xingyizhou/ExtremeNet)\n\n**Bag of Freebies for Training Object Detection Neural Networks**\n\n- intro: Amazon Web Services\n- arxiv: [https://arxiv.org/abs/1902.04103](https://arxiv.org/abs/1902.04103)\n\n**Augmentation for small object detection**\n\n[https://arxiv.org/abs/1902.07296](https://arxiv.org/abs/1902.07296)\n\n**Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1902.09630](https://arxiv.org/abs/1902.09630)\n\n**SimpleDet: A Simple and Versatile Distributed Framework for Object Detection and Instance Recognition**\n\n- intro: TuSimple\n- arxiv: [https://arxiv.org/abs/1903.05831](https://arxiv.org/abs/1903.05831)\n- github: [https://github.com/tusimple/simpledet](https://github.com/tusimple/simpledet)\n\n**BayesOD: A Bayesian Approach for Uncertainty Estimation in Deep Object Detectors**\n\n- intro: University of Toronto\n- arxiv: [https://arxiv.org/abs/1903.03838](https://arxiv.org/abs/1903.03838)\n\n**DetNAS: Neural Architecture Search on Object Detection**\n\n- intro: Chinese Academy of Sciences & Megvii Inc\n- arxiv: [https://arxiv.org/abs/1903.10979](https://arxiv.org/abs/1903.10979)\n\n**ThunderNet: Towards Real-time Generic Object Detection**\n\n[https://arxiv.org/abs/1903.11752](https://arxiv.org/abs/1903.11752)\n\n**Feature Intertwiner for Object Detection**\n\n- intro: ICLR 2019\n- intro: CUHK & SenseTime & The University of Sydney\n- arxiv: [https://arxiv.org/abs/1903.11851](https://arxiv.org/abs/1903.11851)\n\n**Improving Object Detection with Inverted Attention**\n\n[https://arxiv.org/abs/1903.12255](https://arxiv.org/abs/1903.12255)\n\n**What Object Should I Use? - Task Driven Object Detection**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1904.03000](https://arxiv.org/abs/1904.03000)\n\n**Towards Universal Object Detection by Domain Attention**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1904.04402](https://arxiv.org/abs/1904.04402)\n\n**Prime Sample Attention in Object Detection**\n\n[https://arxiv.org/abs/1904.04821](https://arxiv.org/abs/1904.04821)\n\n**BAOD: Budget-Aware Object Detection**\n\n[https://arxiv.org/abs/1904.05443](https://arxiv.org/abs/1904.05443)\n\n**An Analysis of Pre-Training on Object Detection**\n\n- intro: University of Maryland\n- arxiv: [https://arxiv.org/abs/1904.05871](https://arxiv.org/abs/1904.05871)\n\n**DuBox: No-Prior Box Objection Detection via Residual Dual Scale Detectors**\n\n- intro: Baidu Inc.\n- arxiv: [https://arxiv.org/abs/1904.06883](https://arxiv.org/abs/1904.06883)\n\n**NAS-FPN: Learning Scalable Feature Pyramid Architecture for Object Detection**\n\n- intro: CVPR 2019\n- intro: Google Brain\n- arxiv: [https://arxiv.org/abs/1904.07392](https://arxiv.org/abs/1904.07392)\n\n**Objects as Points**\n\n![](https://raw.githubusercontent.com/xingyizhou/CenterNet/master/readme/fig2.png)\n\n- intro: Object detection, 3D detection, and pose estimation using center point detection\n- arxiv: [https://arxiv.org/abs/1904.07850](https://arxiv.org/abs/1904.07850)\n- github: [https://github.com/xingyizhou/CenterNet](https://github.com/xingyizhou/CenterNet)\n\n**MultiTask-CenterNet (MCN): Efficient and Diverse Multitask Learning using an Anchor Free Approach**\n\n- intro: ICCV 2021\n- intro: ZF Friedrichshafen AG, Artificial Intelligence Lab\n- arxiv: [https://arxiv.org/abs/2108.05060](https://arxiv.org/abs/2108.05060)\n\n**CenterNet: Object Detection with Keypoint Triplets**\n\n**CenterNet: Keypoint Triplets for Object Detection**\n\n- arxiv: [https://arxiv.org/abs/1904.08189](https://arxiv.org/abs/1904.08189)\n- github: [https://github.com/Duankaiwen/CenterNet](https://github.com/Duankaiwen/CenterNet)\n\n**CornerNet-Lite: Efficient Keypoint Based Object Detection**\n\n- intro: Princeton University\n- arxiv: [https://arxiv.org/abs/1904.08900](https://arxiv.org/abs/1904.08900)\n- github: [https://github.com/princeton-vl/CornerNet-Lite](https://github.com/princeton-vl/CornerNet-Lite)\n\n**CenterNet++ for Object Detection**\n\n- arxiv: [https://arxiv.org/abs/2204.08394](https://arxiv.org/abs/2204.08394)\n- github; [https://github.com/Duankaiwen/PyCenterNet](https://github.com/Duankaiwen/PyCenterNet)\n\n**Automated Focal Loss for Image based Object Detection**\n\n[https://arxiv.org/abs/1904.09048](https://arxiv.org/abs/1904.09048)\n\n**Exploring Object Relation in Mean Teacher for Cross-Domain Detection**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1904.11245](https://arxiv.org/abs/1904.11245)\n\n**An Energy and GPU-Computation Efficient Backbone Network for Real-Time Object Detection**\n\n- intro: CVPR 2019 CEFRL Workshop\n- arxiv: [https://arxiv.org/abs/1904.09730](https://arxiv.org/abs/1904.09730)\n\n**RepPoints: Point Set Representation for Object Detection**\n\n- intro: ICCV 2019\n- intro: Peking University & Tsinghua University & Microsoft Research Asia\n- arxiv: [https://arxiv.org/abs/1904.11490](https://arxiv.org/abs/1904.11490)\n- github: [https://github.com/microsoft/RepPoints](https://github.com/microsoft/RepPoints)\n\n**Dense RepPoints: Representing Visual Objects with Dense Point Sets**\n\n- intro: Peking University & CUHK & Zhejiang University & Shanghai Jiao Tong University & University of Toronto & MSRA\n- arxiv: [https://arxiv.org/abs/1912.11473](https://arxiv.org/abs/1912.11473)\n- github(official, mmdetection): [https://github.com/justimyhxu/Dense-RepPoints](https://github.com/justimyhxu/Dense-RepPoints)\n\n**RepPoints V2: Verification Meets Regression for Object Detection**\n\n- intro: Microsoft Research Asia & Peking University\n- arxiv: [https://arxiv.org/abs/2007.08508](https://arxiv.org/abs/2007.08508)\n- github(official, mmdetection): [https://github.com/Scalsol/RepPointsV2](https://github.com/Scalsol/RepPointsV2)\n\n**Object Detection in 20 Years: A Survey**\n\n[https://arxiv.org/abs/1905.05055](https://arxiv.org/abs/1905.05055)\n\n**Light-Weight RetinaNet for Object Detection**\n\n[https://arxiv.org/abs/1905.10011](https://arxiv.org/abs/1905.10011)\n\n**Learning Data Augmentation Strategies for Object Detection**\n\n- intro: Google Research, Brain Team\n- arxiv: [https://arxiv.org/abs/1906.11172](https://arxiv.org/abs/1906.11172)\n- github: [https://github.com/tensorflow/tpu/tree/master/models/official/detection](https://github.com/tensorflow/tpu/tree/master/models/official/detection)\n\n**Towards Adversarially Robust Object Detection**\n\n- intro: ICCV 2019\n- intro: Baidu Research, Sunnyvale USA\n- arxiv: [https://arxiv.org/abs/1907.10310](https://arxiv.org/abs/1907.10310)\n\n**Multi-adversarial Faster-RCNN for Unrestricted Object Detection**\n\n- intro: ICCV 2019\n- arxiv: [https://arxiv.org/abs/1907.10343](https://arxiv.org/abs/1907.10343)\n\n**Object as Distribution**\n\n- intro: NeurIPS 2019\n- intro: MIT\n- arxiv: [https://arxiv.org/abs/1907.12929](https://arxiv.org/abs/1907.12929)\n\n**Detecting 11K Classes: Large Scale Object Detection without Fine-Grained Bounding Boxes**\n\n- intro: ICCV 2019\n- arxiv: [https://arxiv.org/abs/1908.05217](https://arxiv.org/abs/1908.05217)\n\n**R3Det: Refined Single-Stage Detector with Feature Refinement for Rotating Object**\n\n- arxiv: [https://arxiv.org/abs/1908.05612](https://arxiv.org/abs/1908.05612)\n- github: [https://github.com/Thinklab-SJTU/R3Det_Tensorflow](https://github.com/Thinklab-SJTU/R3Det_Tensorflow)\n\n**SCRDet++: Detecting Small, Cluttered and Rotated Objects via Instance-Level Feature Denoising and Rotation Loss Smoothing**\n\n- project page: [https://yangxue0827.github.io/SCRDet++.html](https://yangxue0827.github.io/SCRDet++.html)\n- arxiv: [https://arxiv.org/abs/2004.13316](https://arxiv.org/abs/2004.13316)\n\n**Relation Distillation Networks for Video Object Detection**\n\n- intro: ICCV 2019\n- arxiv: [https://arxiv.org/abs/1908.09511](https://arxiv.org/abs/1908.09511)\n\n**Imbalance Problems in Object Detection: A Review**\n\n- arxiv: [https://arxiv.org/abs/1909.00169](https://arxiv.org/abs/1909.00169)\n- github: [https://github.com/kemaloksuz/ObjectDetectionImbalance](https://github.com/kemaloksuz/ObjectDetectionImbalance)\n\n**FreeAnchor: Learning to Match Anchors for Visual Object Detection**\n\n- intro: NeurIPS 2019\n- arxiv: [https://arxiv.org/abs/1909.02466](https://arxiv.org/abs/1909.02466)\n\n**Efficient Neural Architecture Transformation Search in Channel-Level for Object Detection**\n\n[https://arxiv.org/abs/1909.02293](https://arxiv.org/abs/1909.02293)\n\n**Self-Training and Adversarial Background Regularization for Unsupervised Domain Adaptive One-Stage Object Detection**\n\n- intro: ICCV 2019 oral\n- arxiv: [https://arxiv.org/abs/1909.00597](https://arxiv.org/abs/1909.00597)\n\n**CBNet: A Novel Composite Backbone Network Architecture for Object Detection**\n\n- intro: AAAI 2020\n- keywords: Composite Backbone Network (CBNet)\n- arxiv: [https://arxiv.org/abs/1909.03625](https://arxiv.org/abs/1909.03625)\n- paper: [https://aaai.org/Papers/AAAI/2020GB/AAAI-LiuY.1833.pdf](https://aaai.org/Papers/AAAI/2020GB/AAAI-LiuY.1833.pdf)\n- github(Caffe2): [https://github.com/PKUbahuangliuhe/CBNet](https://github.com/PKUbahuangliuhe/CBNet)\n- github(mmdetection): [https://github.com/VDIGPKU/CBNet](https://github.com/VDIGPKU/CBNet)\n\n**CBNetV2: A Composite Backbone Network Architecture for Object Detection**\n\n- arxiv: [https://arxiv.org/abs/2107.00420](https://arxiv.org/abs/2107.00420)\n- github: [https://github.com/VDIGPKU/CBNetV2](https://github.com/VDIGPKU/CBNetV2)\n\n**A System-Level Solution for Low-Power Object Detection**\n\n- intro: ICCV 2019 Low-Power Computer Vision Workshop\n- arxiv: [https://arxiv.org/abs/1909.10964](https://arxiv.org/abs/1909.10964)\n\n**Anchor Loss: Modulating Loss Scale based on Prediction Difficulty**\n\n- intro: ICCV 2019 oral\n- arxiv: [https://arxiv.org/abs/1909.11155](https://arxiv.org/abs/1909.11155)\n- github(Pytorch): [https://github.com/slryou41/AnchorLoss](https://github.com/slryou41/AnchorLoss)\n\n**Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression**\n\n- intro: AAAI 2020\n- arxiv: [https://arxiv.org/abs/1911.08287](https://arxiv.org/abs/1911.08287)\n- github: [https://github.com/Zzh-tju/DIoU](https://github.com/Zzh-tju/DIoU)\n- github: [https://github.com/Zzh-tju/CIoU](https://github.com/Zzh-tju/CIoU)\n- github: [https://github.com/Zzh-tju/DIoU-darknet](https://github.com/Zzh-tju/DIoU-darknet)\n\n**Curriculum Self-Paced Learning for Cross-Domain Object Detection**\n\n[https://arxiv.org/abs/1911.06849](https://arxiv.org/abs/1911.06849)\n\n**Multiple Anchor Learning for Visual Object Detection**\n\n[https://arxiv.org/abs/1912.02252](https://arxiv.org/abs/1912.02252)\n\n**MnasFPN: Learning Latency-aware Pyramid Architecture for Object Detection on Mobile Devices**\n\n- intro: Google AI & Google Brain\n- arxiv: [https://arxiv.org/abs/1912.01106](https://arxiv.org/abs/1912.01106)\n\n**AugFPN: Improving Multi-scale Feature Learning for Object Detection**\n\n- intro: CVPR 2020\n- intro: CASIA & Horizon Robotics\n- arxiv: [https://arxiv.org/abs/1912.05384](https://arxiv.org/abs/1912.05384)\n- github(official, mmdetection): [https://github.com/Gus-Guo/AugFPN](https://github.com/Gus-Guo/AugFPN)\n\n**Object Detection as a Positive-Unlabeled Problem**\n\n[https://arxiv.org/abs/2002.04672](https://arxiv.org/abs/2002.04672)\n\n**Universal-RCNN: Universal Object Detector via Transferable Graph R-CNN**\n\n- intro: AAAI 2020\n- intro: Huawei Noahs Ark Lab & South China University of Technology & Sun Yat-Sen University\n- arxiv: [https://arxiv.org/abs/2002.07417](https://arxiv.org/abs/2002.07417)\n\n**BiDet: An Efficient Binarized Object Detector**\n\n- intro: CVPR 2020\n- arxiv: [https://arxiv.org/abs/2003.03961](https://arxiv.org/abs/2003.03961)\n- github: [https://github.com/ZiweiWangTHU/BiDet](https://github.com/ZiweiWangTHU/BiDet)\n\n**Revisiting the Sibling Head in Object Detector**\n\n- intro: CVPR 2020 & Method of Champion of OpenImage Challenge 2019, detection track\n- intro: SenseTime X-Lab & CUHK\n- keywords: task-aware spatial disentanglement (TSD)\n- arxiv: [https://arxiv.org/abs/2003.07540](https://arxiv.org/abs/2003.07540)\n- github: [https://github.com/Sense-X/TSD](https://github.com/Sense-X/TSD)\n\n**Extended Feature Pyramid Network for Small Object Detection**\n\n[https://arxiv.org/abs/2003.07021](https://arxiv.org/abs/2003.07021)\n\n**SaccadeNet: A Fast and Accurate Object Detector**\n\n- intro: University of Maryland & Wormpex AI Research\n- arxiv: [https://arxiv.org/abs/2003.12125](https://arxiv.org/abs/2003.12125)\n\n**Scale-Equalizing Pyramid Convolution for Object Detection**\n\n- intro: CVPR 2020\n- intro: SenseTime Research\n- arxiv: [https://arxiv.org/abs/2005.03101](https://arxiv.org/abs/2005.03101)\n- github: [https://github.com/jshilong/SEPC](https://github.com/jshilong/SEPC)\n\n**Dynamic Refinement Network for Oriented and Densely Packed Object Detection**\n\n- intro: CVPR 2020 oral\n- keywords: SKU110K-R\n- arxiv: [https://arxiv.org/abs/2005.09973](https://arxiv.org/abs/2005.09973)\n- github: [https://github.com/Anymake/DRN_CVPR2020](https://github.com/Anymake/DRN_CVPR2020)\n\n**Robust Object Detection under Occlusion with Context-Aware CompositionalNets**\n\n- intro: CVPR 2020\n- intro: Johns Hopkins University\n- arxiv: [https://arxiv.org/abs/2005.11643](https://arxiv.org/abs/2005.11643)\n\n**DetectoRS: Detecting Objects with Recursive Feature Pyramid and Switchable Atrous Convolution**\n\n- intro: Johns Hopkins University & Google Research\n- intro: COCO test-dev 54.7% box AP\n- arxiv: [https://arxiv.org/abs/2006.02334](https://arxiv.org/abs/2006.02334)\n- github(official, mmdetection): [https://github.com/joe-siyuan-qiao/DetectoRS](https://github.com/joe-siyuan-qiao/DetectoRS)\n\n**Learning a Unified Sample Weighting Network for Object Detection**\n\n- intro: CVPR 2020\n- arxiv: [https://arxiv.org/abs/2006.06568](https://arxiv.org/abs/2006.06568)\n- github: [https://github.com/caiqi/sample-weighting-network](https://github.com/caiqi/sample-weighting-network)\n\n**2nd Place Solution for Waymo Open Dataset Challenge -- 2D Object Detection**\n\n- intro: Horizon Robotics Inc.\n- arxiv: [https://arxiv.org/abs/2006.15507](https://arxiv.org/abs/2006.15507)\n\n**Domain Adaptive Object Detection via Asymmetric Tri-way Faster-RCNN**\n\n- intro: ECCV 2020\n- arxiv: [https://arxiv.org/abs/2007.01571](https://arxiv.org/abs/2007.01571)\n\n**AQD: Towards Accurate Quantized Object Detection**\n\n- intro: South China University of Technology & University of Adelaide & Monash University\n- arxiv: [https://arxiv.org/abs/2007.06919](https://arxiv.org/abs/2007.06919)\n- github: [https://github.com/blueardour/model-quantization](https://github.com/blueardour/model-quantization)\n\n**Probabilistic Anchor Assignment with IoU Prediction for Object Detection**\n\n- intro: ECCV 2020\n- arxiv: [https://arxiv.org/abs/2007.08103](https://arxiv.org/abs/2007.08103)\n- github: [https://github.com/kkhoot/PAA](https://github.com/kkhoot/PAA)\n\n**BorderDet: Border Feature for Dense Object Detection**\n\n- intro: ECCV 2020 oral\n- arxiv: [https://arxiv.org/abs/2007.11056](https://arxiv.org/abs/2007.11056)\n- github: [https://github.com/Megvii-BaseDetection/BorderDet](https://github.com/Megvii-BaseDetection/BorderDet)\n\n**Quantum-soft QUBO Suppression for Accurate Object Detection**\n\n- intro: ECCV 2020\n- arxiv: [https://arxiv.org/abs/2007.13992](https://arxiv.org/abs/2007.13992)\n\n**VarifocalNet: An IoU-aware Dense Object Detector**\n\n- intro: Queensland University of Technology & University of Queensland\n- arxiv: [https://arxiv.org/abs/2008.13367](https://arxiv.org/abs/2008.13367)\n- github: [https://github.com/hyz-xmaster/VarifocalNet](https://github.com/hyz-xmaster/VarifocalNet)\n\n**The 1st Tiny Object Detection Challenge:Methods and Results**\n\n- intro: ECCV2020 Workshop on Real-world Computer Vision from Inputs with Limited Quality (RLQ) and Tiny Object Detection Challenge\n- arxiv: [https://arxiv.org/abs/2009.07506](https://arxiv.org/abs/2009.07506)\n\n**MimicDet: Bridging the Gap Between One-Stage and Two-Stage Object Detection**\n\n- intro: ECCV 2020\n- intro: SenseTime & CUHK\n- arxiv: [https://arxiv.org/abs/2009.11528](https://arxiv.org/abs/2009.11528)\n\n**SEA: Bridging the Gap Between One- and Two-stage Detector Distillation via SEmantic-aware Alignment**\n\n- intro: The Chinese University of Hong Kong & SmartMore\n- arxiv: [https://arxiv.org/abs/2203.00862](https://arxiv.org/abs/2203.00862)\n\n**A Ranking-based, Balanced Loss Function Unifying Classification and Localisation in Object Detection**\n\n- intro: NeurIPS 2020 spotlight\n- intro: Middle East Technical University\n- keywords: average Localization-Recall-Precision (aLRP)\n- arxiv: [https://arxiv.org/abs/2009.13592](https://arxiv.org/abs/2009.13592)\n- github(official, Pytorch): [https://github.com/kemaloksuz/aLRPLoss](https://github.com/kemaloksuz/aLRPLoss)\n\n**Effective Fusion Factor in FPN for Tiny Object Detection**\n\n- intro: WACV 2021\n- arxiv: [https://arxiv.org/abs/2011.02298](https://arxiv.org/abs/2011.02298)\n\n**Bi-Dimensional Feature Alignment for Cross-Domain Object Detection**\n\n- intro: ECCV 2020 TASK-CV Workshop\n- arxiv: [https://arxiv.org/abs/2011.07205](https://arxiv.org/abs/2011.07205)\n\n**Rethinking Transformer-based Set Prediction for Object Detection**\n\n- intro: Carnegie Mellon University\n- arxiv: [https://arxiv.org/abs/2011.10881](https://arxiv.org/abs/2011.10881)\n\n**Unsupervised Object Detection with LiDAR Clues**\n\n- intro: SenseTime & USTC & CASIA & CAS\n- arxiv: [https://arxiv.org/abs/2011.12953](https://arxiv.org/abs/2011.12953)\n\n**Self-EMD: Self-Supervised Object Detection without ImageNet**\n\n- intro: MEGVII Technology\n- arxiv: [https://arxiv.org/abs/2011.13677](https://arxiv.org/abs/2011.13677)\n\n**End-to-End Object Detection with Fully Convolutional Network**\n\n- intro: Megvii Technology & Xian Jiaotong University\n- keywords: Prediction-aware One- To-One (POTO) label assignment, 3D Max Filtering (3DMF)\n- arxiv: [https://arxiv.org/abs/2012.03544](https://arxiv.org/abs/2012.03544)\n- github: [https://github.com/Megvii-BaseDetection/DeFCN](https://github.com/Megvii-BaseDetection/DeFCN)\n\n**Fine-Grained Dynamic Head for Object Detection**\n\n- intro: NeurIPS 2020\n- arxiv: [https://arxiv.org/abs/2012.03519](https://arxiv.org/abs/2012.03519)\n- github: [https://github.com/StevenGrove/DynamicHead](https://github.com/StevenGrove/DynamicHead)\n\n**Focal and Efficient IOU Loss for Accurate Bounding Box Regression**\n\n- intro: South China University of Technology & 2Horizon Robotics & Chinese Academy of Sciences\n- arxiv: [https://arxiv.org/abs/2101.08158](https://arxiv.org/abs/2101.08158)\n\n**Scale Normalized Image Pyramids with AutoFocus for Object Detection**\n\n- intro: T-PAMI 2021\n- arxiv: [https://arxiv.org/abs/2102.05646](https://arxiv.org/abs/2102.05646)\n- github: [https://github.com/mahyarnajibi/SNIPER](https://github.com/mahyarnajibi/SNIPER)\n\n**DetCo: Unsupervised Contrastive Learning for Object Detection**\n\n- intro: The University of Hong Kong & Huawei Noahs Ark Lab & Wuhan University & Nanjing University & Chinese University of Hong Kong\n- arxiv: [https://arxiv.org/abs/2102.04803](https://arxiv.org/abs/2102.04803)\n- github: [https://github.com/xieenze/DetCo](https://github.com/xieenze/DetCo)\n- github: [https://github.com/open-mmlab/OpenSelfSup](https://github.com/open-mmlab/OpenSelfSup)\n\n**RMOPP: Robust Multi-Objective Post-Processing for Effective Object Detection**\n\n[https://arxiv.org/abs/2102.04582](https://arxiv.org/abs/2102.04582)\n\n**Instance Localization for Self-supervised Detection Pretraining**\n\n- intro: Chinese University of Hong Kong & Microsoft Research Asia\n- arxiv: [https://arxiv.org/abs/2102.08318](https://arxiv.org/abs/2102.08318)\n\n**Localization Distillation for Object Detection**\n\n- arxiv: [https://arxiv.org/abs/2102.12252](https://arxiv.org/abs/2102.12252)\n- github: [https://github.com/HikariTJU/LD](https://github.com/HikariTJU/LD)\n\n**General Instance Distillation for Object Detection**\n\n- intro: CVPR 2021\n- arxiv: [https://arxiv.org/abs/2103.02340](https://arxiv.org/abs/2103.02340)\n\n**Towards Open World Object Detection**\n\n- intro: CVPR 2021 oral\n- arxiv: [https://arxiv.org/abs/2103.02603](https://arxiv.org/abs/2103.02603)\n- github: [https://github.com/JosephKJ/OWOD](https://github.com/JosephKJ/OWOD)\n\n**Data Augmentation for Object Detection via Differentiable Neural Rendering**\n\n- arxiv: [https://arxiv.org/abs/2103.02852](https://arxiv.org/abs/2103.02852)\n- github: [https://github.com/Guanghan/DANR](https://github.com/Guanghan/DANR)\n\n**Revisiting the Loss Weight Adjustment in Object Detection**\n\n- intro: University of Science and Technology of China & University of Michigan\n- arxiv: [https://arxiv.org/abs/2103.09488](https://arxiv.org/abs/2103.09488)\n- github: [https://github.com/ywx-hub/ALWA](https://github.com/ywx-hub/ALWA)\n\n**You Only Look One-level Feature**\n\n- intro: CVPR 2021\n- arxiv: [https://arxiv.org/abs/2103.09460](https://arxiv.org/abs/2103.09460)\n- github: [https://github.com/megvii-model/YOLOF](https://github.com/megvii-model/YOLOF)\n\n**Optimization for Oriented Object Detection via Representation Invariance Loss**\n\n- arxiv: [https://arxiv.org/abs/2103.11636](https://arxiv.org/abs/2103.11636)\n- github: [https://github.com/ming71/RIDet](https://github.com/ming71/RIDet)\n\n**Dynamic Anchor Learning for Arbitrary-Oriented Object Detection**\n\n- intro: AAAI 2021\n- arxiv: [https://arxiv.org/abs/2012.04150](https://arxiv.org/abs/2012.04150)\n- github: [https://github.com/ming71/DAL](https://github.com/ming71/DAL)\n\n**Control Distance IoU and Control Distance IoU Loss Function for Better Bounding Box Regression**\n\n[https://arxiv.org/abs/2103.11696](https://arxiv.org/abs/2103.11696)\n\n**OTA: Optimal Transport Assignment for Object Detection**\n\n- intro: CVPR 2021\n- arxiv: [https://arxiv.org/abs/2103.14259](https://arxiv.org/abs/2103.14259)\n- github: [https://github.com/Megvii-BaseDetection/OTA](https://github.com/Megvii-BaseDetection/OTA)\n\n**Distilling Object Detectors via Decoupled Features**\n\n- intro: CVPR 2021\n- arxiv: [https://arxiv.org/abs/2103.14475](https://arxiv.org/abs/2103.14475)\n- github: [https://github.com/ggjy/DeFeat.pytorch](https://github.com/ggjy/DeFeat.pytorch)\n\n**Distilling a Powerful Student Model via Online Knowledge Distillation**\n\n- arxiv: [https://arxiv.org/abs/2103.14473](https://arxiv.org/abs/2103.14473)\n- github: [https://github.com/SJLeo/FFSD](https://github.com/SJLeo/FFSD)\n\n**IQDet: Instance-wise Quality Distribution Sampling for Object Detection**\n\n- intro: CVPR 2021\n- intro: Megvii Technology\n- arxiv: [https://arxiv.org/abs/2104.06936](https://arxiv.org/abs/2104.06936)\n\n**You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection**\n\n- intro: Huazhong University of Science & Technology, Horizon Robotics\n- arxiv: [https://arxiv.org/abs/2106.00666](https://arxiv.org/abs/2106.00666)\n- github: [https://github.com/hustvl/YOLOS](https://github.com/hustvl/YOLOS)\n\n**Augmenting Anchors by the Detector Itself**\n\n[https://arxiv.org/abs/2105.14086](https://arxiv.org/abs/2105.14086)\n\n**Rethinking Training from Scratch for Object Detection**\n\n- intro: Zhejiang University\n- arxiv: [https://arxiv.org/abs/2106.03112](https://arxiv.org/abs/2106.03112)\n\n**Dynamic Head: Unifying Object Detection Heads with Attentions**\n\n- intro: CVPR 2021\n- intro: Microsoft\n- arxiv: [https://arxiv.org/abs/2106.08322](https://arxiv.org/abs/2106.08322)\n- github: [https://github.com/microsoft/DynamicHead](https://github.com/microsoft/DynamicHead)\n\n**Disentangle Your Dense Object Detector**\n\n- intro: ACM MM 2021\n- arxiv: [https://arxiv.org/abs/2107.02963](https://arxiv.org/abs/2107.02963)\n- github: [https://github.com/zehuichen123/DDOD](https://github.com/zehuichen123/DDOD)\n\n**Improving Object Detection by Label Assignment Distillation**\n\n- arxiv: [https://arxiv.org/abs/2108.10520](https://arxiv.org/abs/2108.10520)\n- github: [https://github.com/cybercore-co-ltd/CoLAD_paper](https://github.com/cybercore-co-ltd/CoLAD_paper)\n\n**Progressive Hard-case Mining across Pyramid Levels in Object Detection**\n\n- intro:  Baidu Inc.\n- arxiv: [https://arxiv.org/abs/2109.07217](https://arxiv.org/abs/2109.07217)\n- github: [https://github.com/zimoqingfeng/UMOP](https://github.com/zimoqingfeng/UMOP)\n\n**Multi-Scale Aligned Distillation for Low-Resolution Detection**\n\n- intro: CVPR 2021\n- intro: The Chinese University of Hong Kong & Adobe Research & SmartMore\n- arxiv: [https://arxiv.org/abs/2109.06875](https://arxiv.org/abs/2109.06875)\n- github: [https://github.com/dvlab-research/MSAD](https://github.com/dvlab-research/MSAD)\n\n**Pix2seq: A Language Modeling Framework for Object Detection**\n\n- intro: Google Research, Brain Team\n- arxiv: [https://arxiv.org/abs/2109.10852](https://arxiv.org/abs/2109.10852)\n\n**Mixed Supervised Object Detection by Transferring Mask Prior and Semantic Similarity**\n\n- intro: NeurIPS 2021\n- intro: Shanghai Jiao Tong University\n- arxiv: [https://arxiv.org/abs/2110.14191](https://arxiv.org/abs/2110.14191)\n- github: [https://github.com/bcmi/TraMaS-Weak-Shot-Object-Detection](https://github.com/bcmi/TraMaS-Weak-Shot-Object-Detection)\n\n**Bootstrap Your Object Detector via Mixed Training**\n\n- intro: NeurIPS 2021 Spotlight\n- intro: Huazhong University of Science and Technology & Xian Jiaotong University & Microsoft Research Asia\n- keywords: MixTraining\n- arxiv: [https://arxiv.org/abs/2111.03056](https://arxiv.org/abs/2111.03056)\n- github: [https://github.com/MendelXu/MixTraining](https://github.com/MendelXu/MixTraining)\n\n**PP-PicoDet: A Better Real-Time Object Detector on Mobile Devices**\n\n- intro: Baidu Inc.\n- arxiv: [https://arxiv.org/abs/2111.00902](https://arxiv.org/abs/2111.00902)\n- github: [https://github.com/PaddlePaddle/PaddleDetection](https://github.com/PaddlePaddle/PaddleDetection)\n\n**Toward Minimal Misalignment at Minimal Cost in One-Stage and Anchor-Free Object Detection**\n\n[https://arxiv.org/abs/2112.08902](https://arxiv.org/abs/2112.08902)\n\n**GiraffeDet: A Heavy-Neck Paradigm for Object Detection**\n\n[https://arxiv.org/abs/2202.04256](https://arxiv.org/abs/2202.04256)\n\n**A Dual Weighting Label Assignment Scheme for Object Detection**\n\n- intro: CVPR 2022\n- arxiv: [https://arxiv.org/abs/2203.09730](https://arxiv.org/abs/2203.09730)\n- github: [https://github.com/strongwolf/DW](https://github.com/strongwolf/DW)\n\n**QueryDet: Cascaded Sparse Query for Accelerating High-Resolution Small Object Detection**\n\n- intro: CVPR 2022\n- arxiv: [https://arxiv.org/abs/2103.09136](https://arxiv.org/abs/2103.09136)\n- github: [https://github.com/ChenhongyiYang/QueryDet-PyTorch](https://github.com/ChenhongyiYang/QueryDet-PyTorch)\n\n# Two-Stage Object Detection\n\n## R-CNN\n\n**Rich feature hierarchies for accurate object detection and semantic segmentation**\n\n- intro: R-CNN\n- arxiv: [http://arxiv.org/abs/1311.2524](http://arxiv.org/abs/1311.2524)\n- supp: [http://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr-supp.pdf](http://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr-supp.pdf)\n- slides: [http://www.image-net.org/challenges/LSVRC/2013/slides/r-cnn-ilsvrc2013-workshop.pdf](http://www.image-net.org/challenges/LSVRC/2013/slides/r-cnn-ilsvrc2013-workshop.pdf)\n- slides: [http://www.cs.berkeley.edu/~rbg/slides/rcnn-cvpr14-slides.pdf](http://www.cs.berkeley.edu/~rbg/slides/rcnn-cvpr14-slides.pdf)\n- github: [https://github.com/rbgirshick/rcnn](https://github.com/rbgirshick/rcnn)\n- notes: [http://zhangliliang.com/2014/07/23/paper-note-rcnn/](http://zhangliliang.com/2014/07/23/paper-note-rcnn/)\n- caffe-pr(\"Make R-CNN the Caffe detection example\"): [https://github.com/BVLC/caffe/pull/482](https://github.com/BVLC/caffe/pull/482) \n\n## Fast R-CNN\n\n**Fast R-CNN**\n\n- arxiv: [http://arxiv.org/abs/1504.08083](http://arxiv.org/abs/1504.08083)\n- slides: [http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-detection.pdf](http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-detection.pdf)\n- github: [https://github.com/rbgirshick/fast-rcnn](https://github.com/rbgirshick/fast-rcnn)\n- github(COCO-branch): [https://github.com/rbgirshick/fast-rcnn/tree/coco](https://github.com/rbgirshick/fast-rcnn/tree/coco)\n- webcam demo: [https://github.com/rbgirshick/fast-rcnn/pull/29](https://github.com/rbgirshick/fast-rcnn/pull/29)\n- notes: [http://zhangliliang.com/2015/05/17/paper-note-fast-rcnn/](http://zhangliliang.com/2015/05/17/paper-note-fast-rcnn/)\n- notes: [http://blog.csdn.net/linj_m/article/details/48930179](http://blog.csdn.net/linj_m/article/details/48930179)\n- github(\"Fast R-CNN in MXNet\"): [https://github.com/precedenceguo/mx-rcnn](https://github.com/precedenceguo/mx-rcnn)\n- github: [https://github.com/mahyarnajibi/fast-rcnn-torch](https://github.com/mahyarnajibi/fast-rcnn-torch)\n- github: [https://github.com/apple2373/chainer-simple-fast-rnn](https://github.com/apple2373/chainer-simple-fast-rnn)\n- github: [https://github.com/zplizzi/tensorflow-fast-rcnn](https://github.com/zplizzi/tensorflow-fast-rcnn)\n\n**A-Fast-RCNN: Hard Positive Generation via Adversary for Object Detection**\n\n- intro: CVPR 2017\n- arxiv: [https://arxiv.org/abs/1704.03414](https://arxiv.org/abs/1704.03414)\n- paper: [http://abhinavsh.info/papers/pdfs/adversarial_object_detection.pdf](http://abhinavsh.info/papers/pdfs/adversarial_object_detection.pdf)\n- github(Caffe): [https://github.com/xiaolonw/adversarial-frcnn](https://github.com/xiaolonw/adversarial-frcnn)\n\n## Faster R-CNN\n\n**Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks**\n\n- intro: NIPS 2015\n- arxiv: [http://arxiv.org/abs/1506.01497](http://arxiv.org/abs/1506.01497)\n- gitxiv: [http://www.gitxiv.com/posts/8pfpcvefDYn2gSgXk/faster-r-cnn-towards-real-time-object-detection-with-region](http://www.gitxiv.com/posts/8pfpcvefDYn2gSgXk/faster-r-cnn-towards-real-time-object-detection-with-region)\n- slides: [http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2016/bil722/slides/w05-FasterR-CNN.pdf](http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2016/bil722/slides/w05-FasterR-CNN.pdf)\n- github(official, Matlab): [https://github.com/ShaoqingRen/faster_rcnn](https://github.com/ShaoqingRen/faster_rcnn)\n- github: [https://github.com/rbgirshick/py-faster-rcnn](https://github.com/rbgirshick/py-faster-rcnn)\n- github(MXNet): [https://github.com/msracver/Deformable-ConvNets/tree/master/faster_rcnn](https://github.com/msracver/Deformable-ConvNets/tree/master/faster_rcnn)\n- github: [https://github.com//jwyang/faster-rcnn.pytorch](https://github.com//jwyang/faster-rcnn.pytorch)\n- github: [https://github.com/mitmul/chainer-faster-rcnn](https://github.com/mitmul/chainer-faster-rcnn)\n- github: [https://github.com/andreaskoepf/faster-rcnn.torch](https://github.com/andreaskoepf/faster-rcnn.torch)\n- github: [https://github.com/ruotianluo/Faster-RCNN-Densecap-torch](https://github.com/ruotianluo/Faster-RCNN-Densecap-torch)\n- github: [https://github.com/smallcorgi/Faster-RCNN_TF](https://github.com/smallcorgi/Faster-RCNN_TF)\n- github: [https://github.com/CharlesShang/TFFRCNN](https://github.com/CharlesShang/TFFRCNN)\n- github(C++ demo): [https://github.com/YihangLou/FasterRCNN-Encapsulation-Cplusplus](https://github.com/YihangLou/FasterRCNN-Encapsulation-Cplusplus)\n- github: [https://github.com/yhenon/keras-frcnn](https://github.com/yhenon/keras-frcnn)\n- github: [https://github.com/Eniac-Xie/faster-rcnn-resnet](https://github.com/Eniac-Xie/faster-rcnn-resnet)\n- github(C++): [https://github.com/D-X-Y/caffe-faster-rcnn/tree/dev](https://github.com/D-X-Y/caffe-faster-rcnn/tree/dev)\n\n**R-CNN minus R**\n\n- intro: BMVC 2015\n- arxiv: [http://arxiv.org/abs/1506.06981](http://arxiv.org/abs/1506.06981)\n\n**Faster R-CNN in MXNet with distributed implementation and data parallelization**\n\n- github: [https://github.com/dmlc/mxnet/tree/master/example/rcnn](https://github.com/dmlc/mxnet/tree/master/example/rcnn)\n\n**Contextual Priming and Feedback for Faster R-CNN**\n\n- intro: ECCV 2016. Carnegie Mellon University\n- paper: [http://abhinavsh.info/context_priming_feedback.pdf](http://abhinavsh.info/context_priming_feedback.pdf)\n- poster: [http://www.eccv2016.org/files/posters/P-1A-20.pdf](http://www.eccv2016.org/files/posters/P-1A-20.pdf)\n\n**An Implementation of Faster RCNN with Study for Region Sampling**\n\n- intro: Technical Report, 3 pages. CMU\n- arxiv: [https://arxiv.org/abs/1702.02138](https://arxiv.org/abs/1702.02138)\n- github: [https://github.com/endernewton/tf-faster-rcnn](https://github.com/endernewton/tf-faster-rcnn)\n\n**Interpretable R-CNN**\n\n- intro: North Carolina State University & Alibaba\n- keywords: AND-OR Graph (AOG)\n- arxiv: [https://arxiv.org/abs/1711.05226](https://arxiv.org/abs/1711.05226)\n\n**Light-Head R-CNN: In Defense of Two-Stage Object Detector**\n\n- intro: Tsinghua University & Megvii Inc\n- arxiv: [https://arxiv.org/abs/1711.07264](https://arxiv.org/abs/1711.07264)\n- github(official, Tensorflow): [https://github.com/zengarden/light_head_rcnn](https://github.com/zengarden/light_head_rcnn)\n- github: [https://github.com/terrychenism/Deformable-ConvNets/blob/master/rfcn/symbols/resnet_v1_101_rfcn_light.py#L784](https://github.com/terrychenism/Deformable-ConvNets/blob/master/rfcn/symbols/resnet_v1_101_rfcn_light.py#L784)\n\n**Cascade R-CNN: Delving into High Quality Object Detection**\n\n- intro: CVPR 2018. UC San Diego\n- arxiv: [https://arxiv.org/abs/1712.00726](https://arxiv.org/abs/1712.00726)\n- github(Caffe, official): [https://github.com/zhaoweicai/cascade-rcnn](https://github.com/zhaoweicai/cascade-rcnn)\n\n**Cascade R-CNN: High Quality Object Detection and Instance Segmentation**\n\n -arxiv: [https://arxiv.org/abs/1906.09756](https://arxiv.org/abs/1906.09756)\n- github(Caffe, official): [https://github.com/zhaoweicai/cascade-rcnn](https://github.com/zhaoweicai/cascade-rcnn)\n- github(official): [https://github.com/zhaoweicai/Detectron-Cascade-RCNN](https://github.com/zhaoweicai/Detectron-Cascade-RCNN)\n\n**Cascade RPN: Delving into High-Quality Region Proposal Network with Adaptive Convolution**\n\n- intro: NeurIPS 2019 spotlight\n- arxiv: [https://arxiv.org/abs/1909.06720](https://arxiv.org/abs/1909.06720)\n- github: [https://github.com/thangvubk/Cascade-RPN](https://github.com/thangvubk/Cascade-RPN)\n\n**SMC Faster R-CNN: Toward a scene-specialized multi-object detector**\n\n[https://arxiv.org/abs/1706.10217](https://arxiv.org/abs/1706.10217)\n\n**Domain Adaptive Faster R-CNN for Object Detection in the Wild**\n\n- intro: CVPR 2018. ETH Zurich & ESAT/PSI\n- arxiv: [https://arxiv.org/abs/1803.03243](https://arxiv.org/abs/1803.03243)\n- github(official. Caffe): [https://github.com/yuhuayc/da-faster-rcnn](https://github.com/yuhuayc/da-faster-rcnn)\n\n**Robust Physical Adversarial Attack on Faster R-CNN Object Detector**\n\n[https://arxiv.org/abs/1804.05810](https://arxiv.org/abs/1804.05810)\n\n**Auto-Context R-CNN**\n\n- intro: Rejected by ECCV18\n- arxiv: [https://arxiv.org/abs/1807.02842](https://arxiv.org/abs/1807.02842)\n\n**Grid R-CNN**\n\n- intro: CVPR 2019\n- intro: SenseTime\n- arxiv: [https://arxiv.org/abs/1811.12030](https://arxiv.org/abs/1811.12030)\n\n**Grid R-CNN Plus: Faster and Better**\n\n- intro: SenseTime Research & CUHK & Beihang University\n- arxiv: [https://arxiv.org/abs/1906.05688](https://arxiv.org/abs/1906.05688)\n- github: [https://github.com/STVIR/Grid-R-CNN](https://github.com/STVIR/Grid-R-CNN)\n\n**Few-shot Adaptive Faster R-CNN**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1903.09372](https://arxiv.org/abs/1903.09372)\n\n**Libra R-CNN: Towards Balanced Learning for Object Detection**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1904.02701](https://arxiv.org/abs/1904.02701)\n\n**Rethinking Classification and Localization in R-CNN**\n\n- intro: Northeastern University & Microsoft\n- arxiv: [https://arxiv.org/abs/1904.06493](https://arxiv.org/abs/1904.06493)\n\n**Reprojection R-CNN: A Fast and Accurate Object Detector for 360 Images**\n\n- intro: Peking University\n- arxiv: [https://arxiv.org/abs/1907.11830](https://arxiv.org/abs/1907.11830)\n\n**Rethinking Classification and Localization for Cascade R-CNN**\n\n- intro: BMVC 2019\n- arxiv: [https://arxiv.org/abs/1907.11914](https://arxiv.org/abs/1907.11914)\n\n**IoU-uniform R-CNN: Breaking Through the Limitations of RPN**\n\n- arxiv: [https://arxiv.org/abs/1912.05190](https://arxiv.org/abs/1912.05190)\n- github(mmdetection): [https://github.com/zl1994/IoU-Uniform-R-CNN](https://github.com/zl1994/IoU-Uniform-R-CNN)\n\n**Dynamic R-CNN: Towards High Quality Object Detection via Dynamic Training**\n\n- arxiv: [https://arxiv.org/abs/2004.06002](https://arxiv.org/abs/2004.06002)\n- github: [https://github.com/hkzhang95/DynamicRCNN](https://github.com/hkzhang95/DynamicRCNN)\n\n**Delving into the Imbalance of Positive Proposals in Two-stage Object Detection**\n\n- intro: Waseda University & Tencent AI Lab & Nanjing University of Science and Technology\n- arxiv: [https://arxiv.org/abs/2005.11472](https://arxiv.org/abs/2005.11472)\n\n**Hierarchical Context Embedding for Region-based Object Detection**\n\n- intro: ECCV 2020\n- intro: Nanjing University & Megvii Technology\n- arxiv: [https://arxiv.org/abs/2008.01338](https://arxiv.org/abs/2008.01338)\n\n**Sparse R-CNN: End-to-End Object Detection with Learnable Proposals**\n\n- intro: CVPR 2021\n- intro: The University of Hong Kong & Tongji University & ByteDance AI Lab 4University of California\n- arxiv: [https://arxiv.org/abs/2011.12450](https://arxiv.org/abs/2011.12450)\n- github: [https://github.com/PeizeSun/SparseR-CNN](https://github.com/PeizeSun/SparseR-CNN)\n\n**Dynamic Sparse R-CNN**\n\n- intro: CVPR 2022\n- arxiv: [https://arxiv.org/abs/2205.02101](https://arxiv.org/abs/2205.02101)\n\n**Featurized Query R-CNN**\n\n- intro: Huazhong University of Science & Technology & Horizon Robotics\n- arxiv: [https://arxiv.org/abs/2206.06258](https://arxiv.org/abs/2206.06258)\n- github: [https://github.com/hustvl/Featurized-QueryRCNN](https://github.com/hustvl/Featurized-QueryRCNN)\n\n**Augmenting Proposals by the Detector Itself**\n\n- intro: Tsinghua University & Alibaba Group\n- arxiv: [https://arxiv.org/abs/2101.11789](https://arxiv.org/abs/2101.11789)\n\n**Probabilistic two-stage detection**\n\n- intro: UT Austin & Intel Labs\n- arxiv: [https://arxiv.org/abs/2103.07461](https://arxiv.org/abs/2103.07461)\n- github: [https://github.com/xingyizhou/CenterNet2](https://github.com/xingyizhou/CenterNet2)\n\n# Single-Shot Object Detection\n\n## YOLO\n\n**You Only Look Once: Unified, Real-Time Object Detection**\n\n![](https://camo.githubusercontent.com/e69d4118b20a42de4e23b9549f9a6ec6dbbb0814/687474703a2f2f706a7265646469652e636f6d2f6d656469612f66696c65732f6461726b6e65742d626c61636b2d736d616c6c2e706e67)\n\n- arxiv: [http://arxiv.org/abs/1506.02640](http://arxiv.org/abs/1506.02640)\n- code: [http://pjreddie.com/darknet/yolo/](http://pjreddie.com/darknet/yolo/)\n- github: [https://github.com/pjreddie/darknet](https://github.com/pjreddie/darknet)\n- blog: [https://pjreddie.com/publications/yolo/](https://pjreddie.com/publications/yolo/)\n- slides: [https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&loop=false&delayms=3000&slide=id.p](https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&loop=false&delayms=3000&slide=id.p)\n- reddit: [https://www.reddit.com/r/MachineLearning/comments/3a3m0o/realtime_object_detection_with_yolo/](https://www.reddit.com/r/MachineLearning/comments/3a3m0o/realtime_object_detection_with_yolo/)\n- github: [https://github.com/gliese581gg/YOLO_tensorflow](https://github.com/gliese581gg/YOLO_tensorflow)\n- github: [https://github.com/xingwangsfu/caffe-yolo](https://github.com/xingwangsfu/caffe-yolo)\n- github: [https://github.com/frankzhangrui/Darknet-Yolo](https://github.com/frankzhangrui/Darknet-Yolo)\n- github: [https://github.com/BriSkyHekun/py-darknet-yolo](https://github.com/BriSkyHekun/py-darknet-yolo)\n- github: [https://github.com/tommy-qichang/yolo.torch](https://github.com/tommy-qichang/yolo.torch)\n- github: [https://github.com/frischzenger/yolo-windows](https://github.com/frischzenger/yolo-windows)\n- github: [https://github.com/AlexeyAB/yolo-windows](https://github.com/AlexeyAB/yolo-windows)\n- github: [https://github.com/nilboy/tensorflow-yolo](https://github.com/nilboy/tensorflow-yolo)\n\n**darkflow - translate darknet to tensorflow. Load trained weights, retrain/fine-tune them using tensorflow, export constant graph def to C++**\n\n- blog: [https://thtrieu.github.io/notes/yolo-tensorflow-graph-buffer-cpp](https://thtrieu.github.io/notes/yolo-tensorflow-graph-buffer-cpp)\n- github: [https://github.com/thtrieu/darkflow](https://github.com/thtrieu/darkflow)\n\n**Start Training YOLO with Our Own Data**\n\n![](http://guanghan.info/blog/en/wp-content/uploads/2015/12/images-40.jpg)\n\n- intro: train with customized data and class numbers/labels. Linux / Windows version for darknet.\n- blog: [http://guanghan.info/blog/en/my-works/train-yolo/](http://guanghan.info/blog/en/my-works/train-yolo/)\n- github: [https://github.com/Guanghan/darknet](https://github.com/Guanghan/darknet)\n\n**YOLO: Core ML versus MPSNNGraph**\n\n- intro: Tiny YOLO for iOS implemented using CoreML but also using the new MPS graph API.\n- blog: [http://machinethink.net/blog/yolo-coreml-versus-mps-graph/](http://machinethink.net/blog/yolo-coreml-versus-mps-graph/)\n- github: [https://github.com/hollance/YOLO-CoreML-MPSNNGraph](https://github.com/hollance/YOLO-CoreML-MPSNNGraph)\n\n**TensorFlow YOLO object detection on Android**\n\n- intro: Real-time object detection on Android using the YOLO network with TensorFlow\n- github: [https://github.com/natanielruiz/android-yolo](https://github.com/natanielruiz/android-yolo)\n\n**Computer Vision in iOS  Object Detection**\n\n- blog: [https://sriraghu.com/2017/07/12/computer-vision-in-ios-object-detection/](https://sriraghu.com/2017/07/12/computer-vision-in-ios-object-detection/)\n- github:[https://github.com/r4ghu/iOS-CoreML-Yolo](https://github.com/r4ghu/iOS-CoreML-Yolo)\n\n## YOLOv2\n\n**YOLO9000: Better, Faster, Stronger**\n\n- arxiv: [https://arxiv.org/abs/1612.08242](https://arxiv.org/abs/1612.08242)\n- code: [http://pjreddie.com/yolo9000/](http://pjreddie.com/yolo9000/)\n- github(Chainer): [https://github.com/leetenki/YOLOv2](https://github.com/leetenki/YOLOv2)\n- github(Keras): [https://github.com/allanzelener/YAD2K](https://github.com/allanzelener/YAD2K)\n- github(PyTorch): [https://github.com/longcw/yolo2-pytorch](https://github.com/longcw/yolo2-pytorch)\n- github(Tensorflow): [https://github.com/hizhangp/yolo_tensorflow](https://github.com/hizhangp/yolo_tensorflow)\n- github(Windows): [https://github.com/AlexeyAB/darknet](https://github.com/AlexeyAB/darknet)\n- github: [https://github.com/choasUp/caffe-yolo9000](https://github.com/choasUp/caffe-yolo9000)\n- github: [https://github.com/philipperemy/yolo-9000](https://github.com/philipperemy/yolo-9000)\n\n**darknet_scripts**\n\n- intro: Auxilary scripts to work with (YOLO) darknet deep learning famework. AKA -> How to generate YOLO anchors?\n- github: [https://github.com/Jumabek/darknet_scripts](https://github.com/Jumabek/darknet_scripts)\n\n**Yolo_mark: GUI for marking bounded boxes of objects in images for training Yolo v2**\n\n- github: [https://github.com/AlexeyAB/Yolo_mark](https://github.com/AlexeyAB/Yolo_mark)\n\n**LightNet: Bringing pjreddie's DarkNet out of the shadows**\n\n[https://github.com//explosion/lightnet](https://github.com//explosion/lightnet)\n\n**YOLO v2 Bounding Box Tool**\n\n- intro: Bounding box labeler tool to generate the training data in the format YOLO v2 requires.\n- github: [https://github.com/Cartucho/yolo-boundingbox-labeler-GUI](https://github.com/Cartucho/yolo-boundingbox-labeler-GUI)\n\n## YOLOv3\n\n**YOLOv3: An Incremental Improvement**\n\n- project page: [https://pjreddie.com/darknet/yolo/](https://pjreddie.com/darknet/yolo/)\n- paper: [https://pjreddie.com/media/files/papers/YOLOv3.pdf](https://pjreddie.com/media/files/papers/YOLOv3.pdf)\n- arxiv: [https://arxiv.org/abs/1804.02767](https://arxiv.org/abs/1804.02767)\n- githb: [https://github.com/DeNA/PyTorch_YOLOv3](https://github.com/DeNA/PyTorch_YOLOv3)\n- github: [https://github.com/eriklindernoren/PyTorch-YOLOv3](https://github.com/eriklindernoren/PyTorch-YOLOv3)\n\n**Gaussian YOLOv3: An Accurate and Fast Object Detector Using Localization Uncertainty for Autonomous Driving**\n\n[https://arxiv.org/abs/1904.04620](https://arxiv.org/abs/1904.04620)\n\n**YOLO-LITE: A Real-Time Object Detection Algorithm Optimized for Non-GPU Computers**\n\n[https://arxiv.org/abs/1811.05588](https://arxiv.org/abs/1811.05588)\n\n**Spiking-YOLO: Spiking Neural Network for Real-time Object Detection**\n\n[https://arxiv.org/abs/1903.06530](https://arxiv.org/abs/1903.06530)\n\n**YOLO Nano: a Highly Compact You Only Look Once Convolutional Neural Network for Object Detection**\n\n[https://arxiv.org/abs/1910.01271](https://arxiv.org/abs/1910.01271)\n\n**REQ-YOLO: A Resource-Aware, Efficient Quantization Framework for Object Detection on FPGAs**\n\n[https://arxiv.org/abs/1909.13396](https://arxiv.org/abs/1909.13396)\n\n**Poly-YOLO: higher speed, more precise detection and instance segmentation for YOLOv3**\n\n- intro: TPAMI\n- arxiv: [https://arxiv.org/abs/2005.13243](https://arxiv.org/abs/2005.13243)\n- gitlab: [https://gitlab.com/irafm-ai/poly-yolo](https://gitlab.com/irafm-ai/poly-yolo)\n\n## YOLOv4\n\n**YOLOv4: Optimal Speed and Accuracy of Object Detection**\n\n- keywords: Weighted-Residual-Connections (WRC), Cross-Stage-Partial-connections (CSP), Cross mini-Batch Normalization (CmBN), Self-adversarial-training (SAT), Mish-activation\n- arxiv: [https://arxiv.org/abs/2004.10934](https://arxiv.org/abs/2004.10934)\n- github: [https://github.com/AlexeyAB/darknet](https://github.com/AlexeyAB/darknet)\n- github: [https://github.com/WongKinYiu/PyTorch_YOLOv4](https://github.com/WongKinYiu/PyTorch_YOLOv4)\n\n**YOLOX: Exceeding YOLO Series in 2021**\n\n- intro: Megvii Technology\n- arxiv: [https://arxiv.org/abs/2107.08430](https://arxiv.org/abs/2107.08430)\n- github: [https://github.com/Megvii-BaseDetection/YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)\n\n**PP-YOLO: An Effective and Efficient Implementation of Object Detector**\n\n- intro: Baidu Inc.\n- arxiv: [https://arxiv.org/abs/2007.12099](https://arxiv.org/abs/2007.12099)\n- github: [https://github.com/PaddlePaddle/PaddleDetection](https://github.com/PaddlePaddle/PaddleDetection)\n\n## YOLOv7\n\n**YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors**\n\n- arxiv: [https://arxiv.org/abs/2207.02696](https://arxiv.org/abs/2207.02696)\n- github: [https://github.com/WongKinYiu/yolov7](https://github.com/WongKinYiu/yolov7)\n\n**Real-time Object Detection for Streaming Perception**\n\n- intro: CVPR 2022 oral\n- arxiv: [https://arxiv.org/abs/2203.12338](https://arxiv.org/abs/2203.12338)\n- github: [https://github.com/yancie-yjr/StreamYOLO](https://github.com/yancie-yjr/StreamYOLO)\n\n## SSD\n\n**SSD: Single Shot MultiBox Detector**\n\n![](https://camo.githubusercontent.com/ad9b147ed3a5f48ffb7c3540711c15aa04ce49c6/687474703a2f2f7777772e63732e756e632e6564752f7e776c69752f7061706572732f7373642e706e67)\n\n- intro: ECCV 2016 Oral\n- arxiv: [http://arxiv.org/abs/1512.02325](http://arxiv.org/abs/1512.02325)\n- paper: [http://www.cs.unc.edu/~wliu/papers/ssd.pdf](http://www.cs.unc.edu/~wliu/papers/ssd.pdf)\n- slides: [http://www.cs.unc.edu/%7Ewliu/papers/ssd_eccv2016_slide.pdf](http://www.cs.unc.edu/%7Ewliu/papers/ssd_eccv2016_slide.pdf)\n- github(Official): [https://github.com/weiliu89/caffe/tree/ssd](https://github.com/weiliu89/caffe/tree/ssd)\n- video: [http://weibo.com/p/2304447a2326da963254c963c97fb05dd3a973](http://weibo.com/p/2304447a2326da963254c963c97fb05dd3a973)\n- github: [https://github.com/zhreshold/mxnet-ssd](https://github.com/zhreshold/mxnet-ssd)\n- github: [https://github.com/zhreshold/mxnet-ssd.cpp](https://github.com/zhreshold/mxnet-ssd.cpp)\n- github: [https://github.com/rykov8/ssd_keras](https://github.com/rykov8/ssd_keras)\n- github: [https://github.com/balancap/SSD-Tensorflow](https://github.com/balancap/SSD-Tensorflow)\n- github: [https://github.com/amdegroot/ssd.pytorch](https://github.com/amdegroot/ssd.pytorch)\n- github(Caffe): [https://github.com/chuanqi305/MobileNet-SSD](https://github.com/chuanqi305/MobileNet-SSD)\n\n**What's the diffience in performance between this new code you pushed and the previous code? #327**\n\n[https://github.com/weiliu89/caffe/issues/327](https://github.com/weiliu89/caffe/issues/327)\n\n**DSSD : Deconvolutional Single Shot Detector**\n\n- intro: UNC Chapel Hill & Amazon Inc\n- arxiv: [https://arxiv.org/abs/1701.06659](https://arxiv.org/abs/1701.06659)\n- github: [https://github.com/chengyangfu/caffe/tree/dssd](https://github.com/chengyangfu/caffe/tree/dssd)\n- github: [https://github.com/MTCloudVision/mxnet-dssd](https://github.com/MTCloudVision/mxnet-dssd)\n- demo: [http://120.52.72.53/www.cs.unc.edu/c3pr90ntc0td/~cyfu/dssd_lalaland.mp4](http://120.52.72.53/www.cs.unc.edu/c3pr90ntc0td/~cyfu/dssd_lalaland.mp4)\n\n**Enhancement of SSD by concatenating feature maps for object detection**\n\n- intro: rainbow SSD (R-SSD)\n- arxiv: [https://arxiv.org/abs/1705.09587](https://arxiv.org/abs/1705.09587)\n\n**Context-aware Single-Shot Detector**\n\n- keywords: CSSD, DiCSSD, DeCSSD, effective receptive fields (ERFs),  theoretical receptive fields (TRFs)\n- arxiv: [https://arxiv.org/abs/1707.08682](https://arxiv.org/abs/1707.08682)\n\n**Feature-Fused SSD: Fast Detection for Small Objects**\n\n[https://arxiv.org/abs/1709.05054](https://arxiv.org/abs/1709.05054)\n\n**FSSD: Feature Fusion Single Shot Multibox Detector**\n\n[https://arxiv.org/abs/1712.00960](https://arxiv.org/abs/1712.00960)\n\n**Weaving Multi-scale Context for Single Shot Detector**\n\n- intro: WeaveNet\n- keywords: fuse multi-scale information\n- arxiv: [https://arxiv.org/abs/1712.03149](https://arxiv.org/abs/1712.03149)\n\n**Extend the shallow part of Single Shot MultiBox Detector via Convolutional Neural Network**\n\n- keywords: ESSD\n- arxiv: [https://arxiv.org/abs/1801.05918](https://arxiv.org/abs/1801.05918)\n\n**Tiny SSD: A Tiny Single-shot Detection Deep Convolutional Neural Network for Real-time Embedded Object Detection**\n\n[https://arxiv.org/abs/1802.06488](https://arxiv.org/abs/1802.06488)\n\n**MDSSD: Multi-scale Deconvolutional Single Shot Detector for small objects**\n\n- intro: Zhengzhou University\n- arxiv: [https://arxiv.org/abs/1805.07009](https://arxiv.org/abs/1805.07009)\n\n**Accurate Single Stage Detector Using Recurrent Rolling Convolution**\n\n- intro: CVPR 2017. SenseTime\n- keywords: Recurrent Rolling Convolution (RRC)\n- arxiv: [https://arxiv.org/abs/1704.05776](https://arxiv.org/abs/1704.05776)\n- github: [https://github.com/xiaohaoChen/rrc_detection](https://github.com/xiaohaoChen/rrc_detection)\n\n**Residual Features and Unified Prediction Network for Single Stage Detection**\n\n[https://arxiv.org/abs/1707.05031](https://arxiv.org/abs/1707.05031)\n\n## RetinaNet\n\n**Focal Loss for Dense Object Detection**\n\n- intro: ICCV 2017 Best student paper award. Facebook AI Research\n- keywords: RetinaNet\n- arxiv: [https://arxiv.org/abs/1708.02002](https://arxiv.org/abs/1708.02002)\n\n**Cascade RetinaNet: Maintaining Consistency for Single-Stage Object Detection**\n\n- intro: BMVC 2019\n- keywords: Cas-RetinaNet, Feature Consistency Module\n- arxiv: [https://arxiv.org/abs/1907.06881](https://arxiv.org/abs/1907.06881)\n\n**Focal Loss Dense Detector for Vehicle Surveillance**\n\n[https://arxiv.org/abs/1803.01114](https://arxiv.org/abs/1803.01114)\n\n**Single-Shot Refinement Neural Network for Object Detection**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1711.06897](https://arxiv.org/abs/1711.06897)\n- github: [https://github.com/sfzhang15/RefineDet](https://github.com/sfzhang15/RefineDet)\n- github: [https://github.com/MTCloudVision/RefineDet-Mxnet](https://github.com/MTCloudVision/RefineDet-Mxnet)\n\n**Single-Shot Bidirectional Pyramid Networks for High-Quality Object Detection**\n\n- intro: Singapore Management University & Zhejiang University\n- arxiv: [https://arxiv.org/abs/1803.08208](https://arxiv.org/abs/1803.08208)\n\n**Dual Refinement Network for Single-Shot Object Detection**\n\n[https://arxiv.org/abs/1807.08638](https://arxiv.org/abs/1807.08638)\n\n**ScratchDet:Exploring to Train Single-Shot Object Detectors from Scratch**\n\n- arxiv: [https://arxiv.org/abs/1810.08425](https://arxiv.org/abs/1810.08425)\n- github: [https://github.com/KimSoybean/ScratchDet](https://github.com/KimSoybean/ScratchDethttps://github.com/KimSoybean/ScratchDet)\n\n**Gradient Harmonized Single-stage Detector**\n\n- intro: AAAI 2019 Oral\n- arxiv: [https://arxiv.org/abs/1811.05181](https://arxiv.org/abs/1811.05181)\n- gihtub(official): [https://github.com/libuyu/GHM_Detection](https://github.com/libuyu/GHM_Detection)\n\n**M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network**\n\n- intro: AAAI 2019\n- arxiv: [https://arxiv.org/abs/1811.04533](https://arxiv.org/abs/1811.04533)\n- github: [https://github.com/qijiezhao/M2Det](https://github.com/qijiezhao/M2Det)\n\n**Multi-layer Pruning Framework for Compressing Single Shot MultiBox Detector**\n\n- intro: WACV 2019\n- arxiv: [https://arxiv.org/abs/1811.08342](https://arxiv.org/abs/1811.08342)\n\n**Consistent Optimization for Single-Shot Object Detection**\n\n- arxiv: [https://arxiv.org/abs/1901.06563](https://arxiv.org/abs/1901.06563)\n- blog: [https://zhuanlan.zhihu.com/p/55416312](https://zhuanlan.zhihu.com/p/55416312)\n\n**A Single-shot Object Detector with Feature Aggragation and Enhancement**\n\n[https://arxiv.org/abs/1902.02923](https://arxiv.org/abs/1902.02923)\n\n**Towards Accurate One-Stage Object Detection with AP-Loss**\n\n- intro: CVPR 2019\n- intro: Shanghai Jiao Tong University & Intel Labs & Malaysia Multimedia University & Tencent YouTu Lab & Peking University\n- keywords: Average-Precision loss (AP-loss)\n- arxiv: {https://arxiv.org/abs/1904.06373}(https://arxiv.org/abs/1904.06373)\n\n**AP-Loss for Accurate One-Stage Object Detection**\n\n- intro: IEEE TPAMI\n- arxiv: [https://arxiv.org/abs/2008.07294](https://arxiv.org/abs/2008.07294)\n- github: [https://github.com/cccorn/AP-loss](https://github.com/cccorn/AP-loss)\n\n**Searching Parameterized AP Loss for Object Detection**\n\n- intro: NeurIPS 2021\n- intro: 1Tsinghua University & Zhejiang University & SenseTime Research & Shanghai Jiao Tong University & Beijing Academy of Artificial Intelligence\n- arxiv: [https://arxiv.org/abs/2112.05138](https://arxiv.org/abs/2112.05138)\n- github: [https://github.com/fundamentalvision/Parameterized-AP-Loss](https://github.com/fundamentalvision/Parameterized-AP-Loss)\n\n**Efficient Featurized Image Pyramid Network for Single Shot Detector**\n\n- intro: CVPR 2019\n- paper: [http://openaccess.thecvf.com/content_CVPR_2019/papers/Pang_Efficient_Featurized_Image_Pyramid_Network_for_Single_Shot_Detector_CVPR_2019_paper.pdf](http://openaccess.thecvf.com/content_CVPR_2019/papers/Pang_Efficient_Featurized_Image_Pyramid_Network_for_Single_Shot_Detector_CVPR_2019_paper.pdf)\n- github: [https://github.com/vaesl/LFIP](https://github.com/vaesl/LFIP)\n\n**DR Loss: Improving Object Detection by Distributional Ranking**\n\n- intro: Alibaba Group\n- arxiv: [https://arxiv.org/abs/1907.10156](https://arxiv.org/abs/1907.10156)\n\n**HAR-Net: Joint Learning of Hybrid Attention for Single-stage Object Detection**\n\n[https://arxiv.org/abs/1904.11141](https://arxiv.org/abs/1904.11141)\n\n**Propose-and-Attend Single Shot Detector**\n\n[https://arxiv.org/abs/1907.12736](https://arxiv.org/abs/1907.12736)\n\n**Revisiting Feature Alignment for One-stage Object Detection**\n\n- intro: University of Chinese Academy of Sciences & TuSimple\n- keywords: AlignDet, RoIConv\n- arxiv: [https://arxiv.org/abs/1908.01570](https://arxiv.org/abs/1908.01570)\n\n**IoU-balanced Loss Functions for Single-stage Object Detection**\n\n- intro: HUST\n- arxiv: [https://arxiv.org/abs/1908.05641](https://arxiv.org/abs/1908.05641)\n\n**PosNeg-Balanced Anchors with Aligned Features for Single-Shot Object Detection**\n\n- intro: Chinese Academy of Sciences & University of Chinese Academy of Sciences\n- keywords: Anchor Promotion Module (APM), Feature Alignment Module (FAM)\n- arxiv: [https://arxiv.org/abs/1908.03295](https://arxiv.org/abs/1908.03295)\n\n**R3Det: Refined Single-Stage Detector with Feature Refinement for Rotating Object**\n\n[https://arxiv.org/abs/1908.05612](https://arxiv.org/abs/1908.05612)\n\n**Hierarchical Shot Detector**\n\n- intro: ICCV 2019\n- keywords: reg-offset-cls (ROC) module\n- paper: [http://openaccess.thecvf.com/content_ICCV_2019/papers/Cao_Hierarchical_Shot_Detector_ICCV_2019_paper.pdf](http://openaccess.thecvf.com/content_ICCV_2019/papers/Cao_Hierarchical_Shot_Detector_ICCV_2019_paper.pdf)\n- github(official, Pytorch): [https://github.com/JialeCao001/HSD](https://github.com/JialeCao001/HSD)\n\n**Learning from Noisy Anchors for One-stage Object Detection**\n\n[https://arxiv.org/abs/1912.05086](https://arxiv.org/abs/1912.05086)\n\n**Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection**\n\n- intro: Nanjing University of Science and Technology & Momenta & Nanjing University & Microsoft Research & Tsinghua University\n- arxiv: [https://arxiv.org/abs/2006.04388](https://arxiv.org/abs/2006.04388)\n- github: [https://github.com/implus/GFocal](https://github.com/implus/GFocal)\n\n**Generalized Focal Loss V2: Learning Reliable Localization Quality Estimation for Dense Object Detection**\n\n- intro: Nanjing University of Science and Technology & Momenta & Nanjing University & Tsinghua University\n- arxiv: [https://arxiv.org/abs/2011.12885](https://arxiv.org/abs/2011.12885)\n- github: [https://github.com/implus/GFocalV2](https://github.com/implus/GFocalV2)\n\n**Single-Shot Two-Pronged Detector with Rectified IoU Loss**\n\n- intro: ACM MM 2020\n- arxiv: [https://arxiv.org/abs/2008.03511](https://arxiv.org/abs/2008.03511)\n\n**OneNet: Towards End-to-End One-Stage Object Detection**\n\n- intro: The University of Hong Kong & ByteDance AI Lab\n- arxiv: [https://arxiv.org/abs/2012.05780](https://arxiv.org/abs/2012.05780)\n- github: [https://github.com/PeizeSun/OneNet](https://github.com/PeizeSun/OneNet)\n\n**TOOD: Task-aligned One-stage Object Detection**\n\n- intro: ICCV 2021 Oral\n- intro: Intellifusion Inc. & Meituan Inc. & ByteDance Inc. & Malong LLC & Alibaba Group\n- arxiv: [https://arxiv.org/abs/2108.07755](https://arxiv.org/abs/2108.07755)\n- github: [https://github.com/fcjian/TOOD](https://github.com/fcjian/TOOD)\n\n**Rethinking the Aligned and Misaligned Features in One-stage Object Detection**\n\n[https://arxiv.org/abs/2108.12176](https://arxiv.org/abs/2108.12176)\n\n# Anchor-free\n\n**Feature Selective Anchor-Free Module for Single-Shot Object Detection**\n\n- intro: CVPR 2019\n- keywords: feature selective anchor-free (FSAF) module\n- arxiv: [https://arxiv.org/abs/1903.00621](https://arxiv.org/abs/1903.00621)\n\n**FCOS: Fully Convolutional One-Stage Object Detection**\n\n- intro: The University of Adelaide\n- keywords: anchor-free\n- arxiv: [https://arxiv.org/abs/1904.01355](https://arxiv.org/abs/1904.01355)\n- github: [https://github.com/tianzhi0549/FCOS/](https://github.com/tianzhi0549/FCOS/)\n\n**FoveaBox: Beyond Anchor-based Object Detector**\n\n- intro: Tsinghua University & BNRist & ByteDance AI Lab & University of Pennsylvania\n- arxiv: [https://arxiv.org/abs/1904.03797](https://arxiv.org/abs/1904.03797)\n- github(official, mmdetection): [https://github.com/taokong/FoveaBox](https://github.com/taokong/FoveaBox)\n\n**IMMVP: An Efficient Daytime and Nighttime On-Road Object Detector**\n\n[https://arxiv.org/abs/1910.06573](https://arxiv.org/abs/1910.06573)\n\n**EfficientDet: Scalable and Efficient Object Detection**\n\n- intro: CVPR 2020\n- arxiv: [https://arxiv.org/abs/1911.09070](https://arxiv.org/abs/1911.09070)\n- github: [https://github.com/google/automl/tree/master/efficientdet](https://github.com/google/automl/tree/master/efficientdet)\n- github: [https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch](https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch)\n\n**Domain Adaptation for Object Detection via Style Consistency**\n\n- intro: BMVC 2019\n- arxiv: [https://arxiv.org/abs/1911.10033](https://arxiv.org/abs/1911.10033)\n\n**Soft Anchor-Point Object Detection**\n\n- intro: ECCV 2020\n- intro: Carnegie Mellon University\n- keywords: Soft Anchor-Point Detector (SAPD)\n- arxiv: [https://arxiv.org/abs/1911.12448](https://arxiv.org/abs/1911.12448)\n\n**IPG-Net: Image Pyramid Guidance Network for Object Detection**\n\n[https://arxiv.org/abs/1912.00632](https://arxiv.org/abs/1912.00632)\n\n**Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection**\n\n- arxiv: [https://arxiv.org/abs/1912.02424](https://arxiv.org/abs/1912.02424)\n- github: [https://github.com/sfzhang15/ATSS](https://github.com/sfzhang15/ATSS)\n\n**Localization Uncertainty Estimation for Anchor-Free Object Detection**\n\n- keywords: Gaussian-FCOS\n- arxiv: [https://arxiv.org/abs/2006.15607](https://arxiv.org/abs/2006.15607)\n\n**Corner Proposal Network for Anchor-free, Two-stage Object Detection**\n\n- intro: ECCV 2020\n- arxiv: [https://arxiv.org/abs/2007.13816](https://arxiv.org/abs/2007.13816)\n- github: [https://github.com/Duankaiwen/CPNDet](https://github.com/Duankaiwen/CPNDet)\n\n**Dive Deeper Into Box for Object Detection**\n\n- intro: ECCV 2020\n- keywords: DDBNet, anchor free\n- arxiv: [https://arxiv.org/abs/2007.14350](https://arxiv.org/abs/2007.14350)\n\n**Corner Proposal Network for Anchor-free, Two-stage Object Detection**\n\n- intro: ECCV 2020\n- arxiv: [https://arxiv.org/abs/2007.13816](https://arxiv.org/abs/2007.13816)\n- github: [https://github.com/Duankaiwen/CPNDet](https://github.com/Duankaiwen/CPNDet)\n\n**Reducing Label Noise in Anchor-Free Object Detection**\n\n- intro: BMVC 2020\n- arxiv: [https://arxiv.org/abs/2008.01167](https://arxiv.org/abs/2008.01167)\n- github: [https://github.com/nerminsamet/ppdet](https://github.com/nerminsamet/ppdet)\n\n**Balance-Oriented Focal Loss with Linear Scheduling for Anchor Free Object Detection**\n\n[https://arxiv.org/abs/2012.13763](https://arxiv.org/abs/2012.13763)\n\n**PAFNet: An Efficient Anchor-Free Object Detector Guidance**\n\n- intro: Baidu Inc.\n- github: [https://arxiv.org/abs/2104.13534](https://arxiv.org/abs/2104.13534)\n- arxiv: [https://github.com/PaddlePaddle/PaddleDetection](https://github.com/PaddlePaddle/PaddleDetection)\n\n**Pseudo-IoU: Improving Label Assignment in Anchor-Free Object Detection**\n\n- intro: CVPR 2021 Workshop\n- intro: UIUC & MIT-IBM Watson AI Lab & IBM T.J. Watson Research Center & NVIDIA & University of Oregon & Picsart AI Research (PAIR)\n- arxiv: [https://arxiv.org/abs/2104.14082](https://arxiv.org/abs/2104.14082)\n\n**ObjectBox: From Centers to Boxes for Anchor-Free Object Detection**\n\n- intro: ECCV 2022 Oral\n- intro: Ingenuity Labs Research Institute & Queens University\n- arxiv: [https://arxiv.org/abs/2207.06985](https://arxiv.org/abs/2207.06985)\n- github: [https://github.com/MohsenZand/ObjectBox](https://github.com/MohsenZand/ObjectBox)\n\n# Transformers\n\n**End-to-End Object Detection with Transformers**\n\n- intro: Facebook AI\n- keywords: DEtection TRansformer (DETR)\n- arxiv: [https://arxiv.org/abs/2005.12872](https://arxiv.org/abs/2005.12872)\n- github: [https://github.com/facebookresearch/detr](https://github.com/facebookresearch/detr)\n\n**Deformable DETR: Deformable Transformers for End-to-End Object Detection**\n\n- intro: SenseTime Research & USTC & CUHK\n- arxiv: [https://arxiv.org/abs/2010.04159](https://arxiv.org/abs/2010.04159)\n- github: [https://github.com/fundamentalvision/Deformable-DETR](https://github.com/fundamentalvision/Deformable-DETR)\n\n**RelationNet++: Bridging Visual Representations for Object Detection via Transformer Decoder**\n\n- intro: NeurIPS2020 Spotlight\n- intro: CAS & MSRA\n- arxiv: [https://arxiv.org/abs/2010.15831](https://arxiv.org/abs/2010.15831)\n- github:[https://github.com/microsoft/RelationNet2](https://github.com/microsoft/RelationNet2)\n\n**UP-DETR: Unsupervised Pre-training for Object Detection with Transformers**\n\n- intro: South China University of Technology & Tencent Wechat AI\n- arxiv: [https://arxiv.org/abs/2011.09094](https://arxiv.org/abs/2011.09094)\n\n**Conditional DETR for Fast Training Convergence**\n\n- intro: ICCV 2021\n- intro: University of Science and Technology of China & Peking University & Microsoft Research Asia\n- arxiv: [https://arxiv.org/abs/2108.06152](https://arxiv.org/abs/2108.06152)\n- github: [https://github.com/Atten4Vis/ConditionalDETR](https://github.com/Atten4Vis/ConditionalDETR)\n\n**End-to-End Object Detection with Adaptive Clustering Transformer**\n\n- intro: Peking University & The Chinese University of Hong Kong\n- arxiv: [https://arxiv.org/abs/2011.09315](https://arxiv.org/abs/2011.09315)\n\n**Toward Transformer-Based Object Detection**\n\n- intro: Pinterest\n- keywords: ViT-FRCNN\n- arxiv: [https://arxiv.org/abs/2012.09958](https://arxiv.org/abs/2012.09958)\n\n**Efficient DETR: Improving End-to-End Object Detector with Dense Prior**\n\n- intro: Megvii Technology\n- arxiv: [https://arxiv.org/abs/2104.01318](https://arxiv.org/abs/2104.01318)\n\n**Anchor DETR: Query Design for Transformer-Based Detector**\n\n- intro: MEGVII Technology\n- arxiv: [https://arxiv.org/abs/2109.07107](https://arxiv.org/abs/2109.07107)\n- gihtub: [https://github.com/megvii-model/AnchorDETR](https://github.com/megvii-model/AnchorDETR)\n\n**DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR**\n\n- arxiv: [https://arxiv.org/abs/2201.12329](https://arxiv.org/abs/2201.12329)\n- github: [https://github.com/SlongLiu/DAB-DETR](https://github.com/SlongLiu/DAB-DETR)\n\n**DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection**\n\n- arxiv: [https://arxiv.org/abs/2203.03605](https://arxiv.org/abs/2203.03605)\n- github: [https://github.com/IDEACVR/DINO](https://github.com/IDEACVR/DINO)\n\n**Oriented Object Detection with Transformer**\n\n- intro: University at Buffalo & Beihang University & Baidu Inc\n- arxiv: [https://arxiv.org/abs/2106.03146](https://arxiv.org/abs/2106.03146)\n\n**ViDT: An Efficient and Effective Fully Transformer-based Object Detector**\n\n- intro: NAVER AI Lab & Google Research & University of California at Merced\n- arxiv: [https://arxiv.org/abs/2110.03921](https://arxiv.org/abs/2110.03921)\n- github: [https://github.com/naver-ai/vidt](https://github.com/naver-ai/vidt)\n\n**An Extendable, Efficient and Effective Transformer-based Object Detector**\n\n- arxiv: [https://arxiv.org/abs/2204.07962](https://arxiv.org/abs/2204.07962)\n- github: [https://github.com/naver-ai/vidt](https://github.com/naver-ai/vidt)\n\n**Omni-DETR: Omni-Supervised Object Detection with Transformers**\n\n- intro: CVPR 2022\n- arxiv: [https://arxiv.org/abs/2203.16089](https://arxiv.org/abs/2203.16089)\n\n**Accelerating DETR Convergence via Semantic-Aligned Matching**\n\n- intro: CVPR 2022\n- arxiv: [https://arxiv.org/abs/2203.06883](https://arxiv.org/abs/2203.06883)\n- github: [https://github.com/ZhangGongjie/SAM-DETR](https://github.com/ZhangGongjie/SAM-DETR)\n\n**AdaMixer: A Fast-Converging Query-Based Object Detector**\n\n- intro: CVPR 2022 oral\n- intro: Nanjing University, MYbank Ant Group\n- arxiv: [https://arxiv.org/abs/2203.16507](https://arxiv.org/abs/2203.16507)\n- github: [https://github.com/MCG-NJU/AdaMixer](https://github.com/MCG-NJU/AdaMixer)\n\n**Exploring Plain Vision Transformer Backbones for Object Detection**\n\n- intro: Facebook AI Research\n- arxiv: [https://arxiv.org/abs/2203.16527](https://arxiv.org/abs/2203.16527)\n\n**Efficient Decoder-free Object Detection with Transformers**\n\n- intro:  Tencent Youtu Lab & Zhejiang University\n- arxiv: [https://arxiv.org/abs/2206.06829](https://arxiv.org/abs/2206.06829)\n- github: [https://github.com/Pealing/DFFT](https://github.com/Pealing/DFFT)\n\n# Non-Maximum Suppression (NMS)\n\n**End-to-End Integration of a Convolutional Network, Deformable Parts Model and Non-Maximum Suppression**\n\n- intro: CVPR 2015\n- arxiv: [http://arxiv.org/abs/1411.5309](http://arxiv.org/abs/1411.5309)\n- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Wan_End-to-End_Integration_of_2015_CVPR_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Wan_End-to-End_Integration_of_2015_CVPR_paper.pdf)\n\n**A convnet for non-maximum suppression**\n\n- arxiv: [http://arxiv.org/abs/1511.06437](http://arxiv.org/abs/1511.06437)\n\n**Improving Object Detection With One Line of Code**\n\n**Soft-NMS -- Improving Object Detection With One Line of Code**\n\n- intro: ICCV 2017. University of Maryland\n- keywords: Soft-NMS\n- arxiv: [https://arxiv.org/abs/1704.04503](https://arxiv.org/abs/1704.04503)\n- github: [https://github.com/bharatsingh430/soft-nms](https://github.com/bharatsingh430/soft-nms)\n\n**Softer-NMS: Rethinking Bounding Box Regression for Accurate Object Detection**\n\n- intro: CMU & Megvii Inc. (Face++)\n- arxiv: [https://arxiv.org/abs/1809.08545](https://arxiv.org/abs/1809.08545)\n- github: [https://github.com/yihui-he/softer-NMS](https://github.com/yihui-he/softer-NMS)\n\n**Learning non-maximum suppression**\n\n- intro: CVPR 2017\n- project page: [https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/object-recognition-and-scene-understanding/learning-nms/](https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/object-recognition-and-scene-understanding/learning-nms/)\n- arxiv: [https://arxiv.org/abs/1705.02950](https://arxiv.org/abs/1705.02950)\n- github: [https://github.com/hosang/gossipnet](https://github.com/hosang/gossipnet)\n\n**Relation Networks for Object Detection**\n\n- intro: CVPR 2018 oral\n- arxiv: [https://arxiv.org/abs/1711.11575](https://arxiv.org/abs/1711.11575)\n- github(official, MXNet): [https://github.com/msracver/Relation-Networks-for-Object-Detection](https://github.com/msracver/Relation-Networks-for-Object-Detection)\n\n**Learning Pairwise Relationship for Multi-object Detection in Crowded Scenes**\n\n- keywords: Pairwise-NMS\n- arxiv: [https://arxiv.org/abs/1901.03796](https://arxiv.org/abs/1901.03796)\n\n**Daedalus: Breaking Non-Maximum Suppression in Object Detection via Adversarial Examples**\n\n[https://arxiv.org/abs/1902.02067](https://arxiv.org/abs/1902.02067)\n\n**NMS by Representative Region: Towards Crowded Pedestrian Detection by Proposal Pairing**\n\n- intro: CVPR 2020\n- intro: Waseda University & Tencent AI Lab\n- arxiv: [https://arxiv.org/abs/2003.12729](https://arxiv.org/abs/2003.12729)\n\n**Hashing-based Non-Maximum Suppression for Crowded Object Detection**\n\n- intro: Microsoft\n- arxiv: [https://arxiv.org/abs/2005.11426](https://arxiv.org/abs/2005.11426)\n- github: [https://github.com/microsoft/hnms](https://github.com/microsoft/hnms)\n\n**Visibility Guided NMS: Efficient Boosting of Amodal Object Detection in Crowded Traffic Scenes**\n\n- intro: NeurIPS 2019, Machine Learning for Autonomous Driving Workshop\n- intro: Mercedes-Benz AG, R&D & University of Jena\n- keywords: Visibility Guided NMS (vg-NMS)\n- arxiv: [https://arxiv.org/abs/2006.08547](https://arxiv.org/abs/2006.08547)\n\n**Determinantal Point Process as an alternative to NMS**\n\n[https://arxiv.org/abs/2008.11451](https://arxiv.org/abs/2008.11451)\n\n**Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression Grounding**\n\n- intro: Zhejiang University & Nanyang Technological University & Tencent AI Lab & Columbia University\n- arxiv: [https://arxiv.org/abs/2009.01449](https://arxiv.org/abs/2009.01449)\n\n# NMS-free\n\n**Object Detection Made Simpler by Eliminating Heuristic NMS**\n\n- intro: Alibaba Group & Monash University & The University of Adelaide\n- arxiv: [https://arxiv.org/abs/2101.11782](https://arxiv.org/abs/2101.11782)\n- github: [https://github.com/txdet/FCOSPss](https://github.com/txdet/FCOSPss)\n\n# Adversarial Examples\n\n**Adversarial Examples that Fool Detectors**\n\n- intro: University of Illinois\n- arxiv: [https://arxiv.org/abs/1712.02494](https://arxiv.org/abs/1712.02494)\n\n**Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods**\n\n- project page: [http://nicholas.carlini.com/code/nn_breaking_detection/](http://nicholas.carlini.com/code/nn_breaking_detection/)\n- arxiv: [https://arxiv.org/abs/1705.07263](https://arxiv.org/abs/1705.07263)\n- github: [https://github.com/carlini/nn_breaking_detection](https://github.com/carlini/nn_breaking_detection)\n\n# Knowledge Distillation\n\n**Mimicking Very Efficient Network for Object Detection**\n\n- intro: CVPR 2017. SenseTime & Beihang University\n- paper: [http://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Mimicking_Very_Efficient_CVPR_2017_paper.pdf](http://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Mimicking_Very_Efficient_CVPR_2017_paper.pdf)\n\n**Quantization Mimic: Towards Very Tiny CNN for Object Detection**\n\n- intro: ECCV 2018\n- arxiv: [https://arxiv.org/abs/1805.02152](https://arxiv.org/abs/1805.02152)\n\n**Learning Efficient Detector with Semi-supervised Adaptive Distillation**\n\n- intro: SenseTime Research\n- arxiv: [https://arxiv.org/abs/1901.00366](https://arxiv.org/abs/1901.00366)\n- github: [https://github.com/Tangshitao/Semi-supervised-Adaptive-Distillation](https://github.com/Tangshitao/Semi-supervised-Adaptive-Distillation)\n\n**Distilling Object Detectors with Fine-grained Feature Imitation**\n\n- intro: CVPR 2019\n- intro: National University of Singapore & Huawei Noahs Ark Lab\n- keywords: mimic\n- arxiv: [https://arxiv.org/abs/1906.03609](https://arxiv.org/abs/1906.03609)\n- github: [https://github.com/twangnh/Distilling-Object-Detectors](https://github.com/twangnh/Distilling-Object-Detectors)\n\n**GAN-Knowledge Distillation for one-stage Object Detection**\n\n[https://arxiv.org/abs/1906.08467](https://arxiv.org/abs/1906.08467)\n\n**Learning Lightweight Pedestrian Detector with Hierarchical Knowledge Distillation**\n\n- intro: ICIP 2019 oral\n- arxiv: [https://arxiv.org/abs/1909.09325](https://arxiv.org/abs/1909.09325)\n\n**Improve Object Detection with Feature-based Knowledge Distillation: Towards Accurate and Efficient Detectors**\n\n- intro: ICLR 2021 poster\n- openreview: [https://openreview.net/forum?id=uKhGRvM8QNH](https://openreview.net/forum?id=uKhGRvM8QNH)\n- paper: [https://openreview.net/pdf?id=uKhGRvM8QNH](https://openreview.net/pdf?id=uKhGRvM8QNH)\n- github: [https://github.com/ArchipLab-LinfengZhang/Object-Detection-Knowledge-Distillation-ICLR2021](https://github.com/ArchipLab-LinfengZhang/Object-Detection-Knowledge-Distillation-ICLR2021)\n\n**G-DetKD: Towards General Distillation Framework for Object Detectors via Contrastive and Semantic-guided Feature Imitation**\n\n- intro: Hong Kong University of Science and Technology & Huawei Noahs Ark Lab\n- intro: ICCV 2021\n- arxiv: [https://arxiv.org/abs/2108.07482](https://arxiv.org/abs/2108.07482)\n\n**LGD: Label-guided Self-distillation for Object Detection**\n\n- intro: MEGVII Technology & Xian Jiaotong University\n- arxiv: [https://arxiv.org/abs/2109.11496](https://arxiv.org/abs/2109.11496)\n\n**Deep Structured Instance Graph for Distilling Object Detectors**\n\n- intro: ICCV 2021\n- intro: The Chinese University of Hong Kong & SmartMore\n- arxiv: [https://arxiv.org/abs/2109.12862](https://arxiv.org/abs/2109.12862)\n- github: [https://github.com/dvlab-research/Dsig](https://github.com/dvlab-research/Dsig)\n\n**Instance-Conditional Knowledge Distillation for Object Detection**\n\n- intro: NeurIPS 2021 poster\n- intro: Xian Jiaotong University & MEGVII Technology\n- arxiv: [https://arxiv.org/abs/2110.12724](https://arxiv.org/abs/2110.12724)\n\n**Distilling Object Detectors with Feature Richness**\n\n- intro: University of Science and Technology of China & CAS & Cambricon Technologies & University of Chinese Academy of Sciences\n- arxiv: [https://arxiv.org/abs/2111.00674](https://arxiv.org/abs/2111.00674)\n\n**Focal and Global Knowledge Distillation for Detectors**\n\n- intro: Tsinghua Shenzhen International Graduate School & ByteDance Inc & BeiHang University\n- arxiv: [https://arxiv.org/abs/2111.11837](https://arxiv.org/abs/2111.11837)\n- github: [https://github.com/yzd-v/FGD](https://github.com/yzd-v/FGD)\n\n**Prediction-Guided Distillation for Dense Object Detection**\n\n- intro: University of Edinburgh & Heriot-Watt University\n- arxiv: [https://arxiv.org/abs/2203.05469](https://arxiv.org/abs/2203.05469)\n- github: [https://github.com/ChenhongyiYang/PGD](https://github.com/ChenhongyiYang/PGD)\n\n# Rotated Object Detection\n\n**Rethinking Rotated Object Detection with Gaussian Wasserstein Distance Loss**\n\n- intro: Shanghai Jiao Tong University & Huawei Inc. & Beijing Institute of Technology\n- arxiv: [https://arxiv.org/abs/2101.11952](https://arxiv.org/abs/2101.11952)\n- github: [https://github.com/yangxue0827/RotationDetection](https://github.com/yangxue0827/RotationDetection)\n\n# Long-Tailed Object Detection\n\n**Factors in Finetuning Deep Model for object detection**\n\n**Factors in Finetuning Deep Model for Object Detection with Long-tail Distribution**\n\n- intro: CVPR 2016.rank 3rd for provided data and 2nd for external data on ILSVRC 2015 object detection\n- project page: [http://www.ee.cuhk.edu.hk/~wlouyang/projects/ImageNetFactors/CVPR16.html](http://www.ee.cuhk.edu.hk/~wlouyang/projects/ImageNetFactors/CVPR16.html)\n- arxiv: [http://arxiv.org/abs/1601.05150](http://arxiv.org/abs/1601.05150)\n\n**Overcoming Classifier Imbalance for Long-tail Object Detection with Balanced Group Softmax**\n\n- intro: CVPR 2020 oral\n- arxiv: [https://arxiv.org/abs/2006.10408](https://arxiv.org/abs/2006.10408)\n- github: [https://github.com/FishYuLi/BalancedGroupSoftmax](https://github.com/FishYuLi/BalancedGroupSoftmax)\n\n**Equalization Loss v2: A New Gradient Balance Approach for Long-tailed Object Detection**\n\n- intro: Tongji University & SenseTime Research & Tsinghua University\n- arxiv: [https://arxiv.org/abs/2012.08548](https://arxiv.org/abs/2012.08548)\n\n**A Simple and Effective Use of Object-Centric Images for Long-Tailed Object Detection**\n\n- intro: The Ohio State University & University of Central Florida & University of Southern California & Google Research\n- arxiv: [https://arxiv.org/abs/2102.08884](https://arxiv.org/abs/2102.08884)\n\n**Adaptive Class Suppression Loss for Long-Tail Object Detection**\n\n- intro: CVPR 2021\n- arxiv: [https://arxiv.org/abs/2104.00885](https://arxiv.org/abs/2104.00885)\n- github: [https://github.com/CASIA-IVA-Lab/ACSL](https://github.com/CASIA-IVA-Lab/ACSL)\n\n# Weakly Supervised Object Detection\n\n**Track and Transfer: Watching Videos to Simulate Strong Human Supervision for Weakly-Supervised Object Detection**\n\n- intro: CVPR 2016\n- arxiv: [http://arxiv.org/abs/1604.05766](http://arxiv.org/abs/1604.05766)\n\n**Weakly supervised object detection using pseudo-strong labels**\n\n- arxiv: [http://arxiv.org/abs/1607.04731](http://arxiv.org/abs/1607.04731)\n\n**Saliency Guided End-to-End Learning for Weakly Supervised Object Detection**\n\n- intro: IJCAI 2017\n- arxiv: [https://arxiv.org/abs/1706.06768](https://arxiv.org/abs/1706.06768)\n\n**Visual and Semantic Knowledge Transfer for Large Scale Semi-supervised Object Detection**\n\n- intro: TPAMI 2017. National Institutes of Health (NIH) Clinical Center\n- arxiv: [https://arxiv.org/abs/1801.03145](https://arxiv.org/abs/1801.03145)\n\n# Video Object Detection\n\n**Learning Object Class Detectors from Weakly Annotated Video**\n\n- intro: CVPR 2012\n- paper: [https://www.vision.ee.ethz.ch/publications/papers/proceedings/eth_biwi_00905.pdf](https://www.vision.ee.ethz.ch/publications/papers/proceedings/eth_biwi_00905.pdf)\n\n**Analysing domain shift factors between videos and images for object detection**\n\n- arxiv: [https://arxiv.org/abs/1501.01186](https://arxiv.org/abs/1501.01186)\n\n**Video Object Recognition**\n\n- slides: [http://vision.princeton.edu/courses/COS598/2015sp/slides/VideoRecog/Video%20Object%20Recognition.pptx](http://vision.princeton.edu/courses/COS598/2015sp/slides/VideoRecog/Video%20Object%20Recognition.pptx)\n\n**Deep Learning for Saliency Prediction in Natural Video**\n\n- intro: Submitted on 12 Jan 2016\n- keywords: Deep learning, saliency map, optical flow, convolution network, contrast features\n- paper: [https://hal.archives-ouvertes.fr/hal-01251614/document](https://hal.archives-ouvertes.fr/hal-01251614/document)\n\n**T-CNN: Tubelets with Convolutional Neural Networks for Object Detection from Videos**\n\n- intro: Winning solution in ILSVRC2015 Object Detection from Video(VID) Task\n- arxiv: [http://arxiv.org/abs/1604.02532](http://arxiv.org/abs/1604.02532)\n- github: [https://github.com/myfavouritekk/T-CNN](https://github.com/myfavouritekk/T-CNN)\n\n**Object Detection from Video Tubelets with Convolutional Neural Networks**\n\n- intro: CVPR 2016 Spotlight paper\n- arxiv: [https://arxiv.org/abs/1604.04053](https://arxiv.org/abs/1604.04053)\n- paper: [http://www.ee.cuhk.edu.hk/~wlouyang/Papers/KangVideoDet_CVPR16.pdf](http://www.ee.cuhk.edu.hk/~wlouyang/Papers/KangVideoDet_CVPR16.pdf)\n- gihtub: [https://github.com/myfavouritekk/vdetlib](https://github.com/myfavouritekk/vdetlib)\n\n**Object Detection in Videos with Tubelets and Multi-context Cues**\n\n- intro: SenseTime Group\n- slides: [http://www.ee.cuhk.edu.hk/~xgwang/CUvideo.pdf](http://www.ee.cuhk.edu.hk/~xgwang/CUvideo.pdf)\n- slides: [http://image-net.org/challenges/talks/Object%20Detection%20in%20Videos%20with%20Tubelets%20and%20Multi-context%20Cues%20-%20Final.pdf](http://image-net.org/challenges/talks/Object%20Detection%20in%20Videos%20with%20Tubelets%20and%20Multi-context%20Cues%20-%20Final.pdf)\n\n**Context Matters: Refining Object Detection in Video with Recurrent Neural Networks**\n\n- intro: BMVC 2016\n- keywords: pseudo-labeler\n- arxiv: [http://arxiv.org/abs/1607.04648](http://arxiv.org/abs/1607.04648)\n- paper: [http://vision.cornell.edu/se3/wp-content/uploads/2016/07/video_object_detection_BMVC.pdf](http://vision.cornell.edu/se3/wp-content/uploads/2016/07/video_object_detection_BMVC.pdf)\n\n**CNN Based Object Detection in Large Video Images**\n\n- intro: WangTao @ \n- keywords: object retrieval, object detection, scene classification\n- slides: [http://on-demand.gputechconf.com/gtc/2016/presentation/s6362-wang-tao-cnn-based-object-detection-large-video-images.pdf](http://on-demand.gputechconf.com/gtc/2016/presentation/s6362-wang-tao-cnn-based-object-detection-large-video-images.pdf)\n\n**Object Detection in Videos with Tubelet Proposal Networks**\n\n- arxiv: [https://arxiv.org/abs/1702.06355](https://arxiv.org/abs/1702.06355)\n\n**Flow-Guided Feature Aggregation for Video Object Detection**\n\n- intro: MSRA\n- arxiv: [https://arxiv.org/abs/1703.10025](https://arxiv.org/abs/1703.10025)\n\n**Video Object Detection using Faster R-CNN**\n\n- blog: [http://andrewliao11.github.io/object_detection/faster_rcnn/](http://andrewliao11.github.io/object_detection/faster_rcnn/)\n- github: [https://github.com/andrewliao11/py-faster-rcnn-imagenet](https://github.com/andrewliao11/py-faster-rcnn-imagenet)\n\n**Improving Context Modeling for Video Object Detection and Tracking**\n\n[http://image-net.org/challenges/talks_2017/ilsvrc2017_short(poster).pdf](http://image-net.org/challenges/talks_2017/ilsvrc2017_short(poster).pdf)\n\n**Temporal Dynamic Graph LSTM for Action-driven Video Object Detection**\n\n- intro: ICCV 2017\n- arxiv: [https://arxiv.org/abs/1708.00666](https://arxiv.org/abs/1708.00666)\n\n**Mobile Video Object Detection with Temporally-Aware Feature Maps**\n\n[https://arxiv.org/abs/1711.06368](https://arxiv.org/abs/1711.06368)\n\n**Towards High Performance Video Object Detection**\n\n[https://arxiv.org/abs/1711.11577](https://arxiv.org/abs/1711.11577)\n\n**Impression Network for Video Object Detection**\n\n[https://arxiv.org/abs/1712.05896](https://arxiv.org/abs/1712.05896)\n\n**Spatial-Temporal Memory Networks for Video Object Detection**\n\n[https://arxiv.org/abs/1712.06317](https://arxiv.org/abs/1712.06317)\n\n**3D-DETNet: a Single Stage Video-Based Vehicle Detector**\n\n[https://arxiv.org/abs/1801.01769](https://arxiv.org/abs/1801.01769)\n\n**Object Detection in Videos by Short and Long Range Object Linking**\n\n[https://arxiv.org/abs/1801.09823](https://arxiv.org/abs/1801.09823)\n\n**Object Detection in Video with Spatiotemporal Sampling Networks**\n\n- intro: University of Pennsylvania, 2Dartmouth College\n- arxiv: [https://arxiv.org/abs/1803.05549](https://arxiv.org/abs/1803.05549)\n\n**Towards High Performance Video Object Detection for Mobiles**\n\n- intro: Microsoft Research Asia\n- arxiv: [https://arxiv.org/abs/1804.05830](https://arxiv.org/abs/1804.05830)\n\n**Optimizing Video Object Detection via a Scale-Time Lattice**\n\n- intro: CVPR 2018\n- project page: [http://mmlab.ie.cuhk.edu.hk/projects/ST-Lattice/](http://mmlab.ie.cuhk.edu.hk/projects/ST-Lattice/)\n- arxiv: [https://arxiv.org/abs/1804.05472](https://arxiv.org/abs/1804.05472)\n- github: [https://github.com/hellock/scale-time-lattice](https://github.com/hellock/scale-time-lattice)\n\n**Pack and Detect: Fast Object Detection in Videos Using Region-of-Interest Packing**\n\n[https://arxiv.org/abs/1809.01701](https://arxiv.org/abs/1809.01701)\n\n**Fast Object Detection in Compressed Video**\n\n[https://arxiv.org/abs/1811.11057](https://arxiv.org/abs/1811.11057)\n\n**Tube-CNN: Modeling temporal evolution of appearance for object detection in video**\n\n- intro: INRIA/ENS\n- arxiv: [https://arxiv.org/abs/1812.02619](https://arxiv.org/abs/1812.02619)\n\n**AdaScale: Towards Real-time Video Object Detection Using Adaptive Scaling**\n\n- intro: SysML 2019 oral\n- arxiv: [https://arxiv.org/abs/1902.02910](https://arxiv.org/abs/1902.02910)\n\n**SCNN: A General Distribution based Statistical Convolutional Neural Network with Application to Video Object Detection**\n\n- intro: AAAI 2019\n- arxiv: [https://arxiv.org/abs/1903.07663](https://arxiv.org/abs/1903.07663)\n\n**Looking Fast and Slow: Memory-Guided Mobile Video Object Detection**\n\n- intro: Cornell University & Google AI\n- arxiv: [https://arxiv.org/abs/1903.10172](https://arxiv.org/abs/1903.10172)\n\n**Progressive Sparse Local Attention for Video object detection**\n\n- intro: NLPR,CASIA & Horizon Robotics\n- arxiv: [https://arxiv.org/abs/1903.09126](https://arxiv.org/abs/1903.09126)\n\n**Sequence Level Semantics Aggregation for Video Object Detection**\n\n- intro: ICCV 2019 oral\n- arxiv: [https://arxiv.org/abs/1907.06390](https://arxiv.org/abs/1907.06390)\n- github(MXNet): [https://github.com/happywu/Sequence-Level-Semantics-Aggregation](https://github.com/happywu/Sequence-Level-Semantics-Aggregation)\n\n**Object Detection in Video with Spatial-temporal Context Aggregation**\n\n- intro: Huazhong University of Science and Technology & Horizon Robotics Inc.\n- arxiv: [https://arxiv.org/abs/1907.04988](https://arxiv.org/abs/1907.04988)\n\n**A Delay Metric for Video Object Detection: What Average Precision Fails to Tell**\n\n- intro: ICCV 2019\n- arxiv: [https://arxiv.org/abs/1908.06368](https://arxiv.org/abs/1908.06368)\n\n**Minimum Delay Object Detection From Video**\n\n- intro: ICCV 2019\n- arxiv: [https://arxiv.org/abs/1908.11092](https://arxiv.org/abs/1908.11092)\n\n**Learning Motion Priors for Efficient Video Object Detection**\n\n[https://arxiv.org/abs/1911.05253](https://arxiv.org/abs/1911.05253)\n\n**Object-aware Feature Aggregation for Video Object Detection**\n\n- intro: Beihang University & Capital Normal University & The University of Hong Kong & Baidu, Inc.\n- arxiv: [https://arxiv.org/abs/2010.12573](https://arxiv.org/abs/2010.12573)\n\n**End-to-End Video Object Detection with Spatial-Temporal Transformers**\n\n- arxiv: [https://arxiv.org/abs/2105.10920](https://arxiv.org/abs/2105.10920)\n- github: [https://github.com/SJTU-LuHe/TransVOD](https://github.com/SJTU-LuHe/TransVOD)\n\n# Object Detection on Mobile Devices\n\n**Pelee: A Real-Time Object Detection System on Mobile Devices**\n\n- intro: ICLR 2018 workshop track\n- intro: based on the SSD\n- arxiv: [https://arxiv.org/abs/1804.06882](https://arxiv.org/abs/1804.06882)\n- github: [https://github.com/Robert-JunWang/Pelee](https://github.com/Robert-JunWang/Pelee)\n\n# Object Detection on RGB-D\n\n**Learning Rich Features from RGB-D Images for Object Detection and Segmentation**\n\n- arxiv: [http://arxiv.org/abs/1407.5736](http://arxiv.org/abs/1407.5736)\n\n**Differential Geometry Boosts Convolutional Neural Networks for Object Detection**\n\n- intro: CVPR 2016\n- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2016_workshops/w23/html/Wang_Differential_Geometry_Boosts_CVPR_2016_paper.html](http://www.cv-foundation.org/openaccess/content_cvpr_2016_workshops/w23/html/Wang_Differential_Geometry_Boosts_CVPR_2016_paper.html)\n\n**A Self-supervised Learning System for Object Detection using Physics Simulation and Multi-view Pose Estimation**\n\n[https://arxiv.org/abs/1703.03347](https://arxiv.org/abs/1703.03347)\n\n**Cross-Modal Attentional Context Learning for RGB-D Object Detection**\n\n- intro: IEEE Transactions on Image Processing\n- arxiv: [https://arxiv.org/abs/1810.12829](https://arxiv.org/abs/1810.12829)\n\n# Zero-Shot Object Detection\n\n**Zero-Shot Detection**\n\n- intro: Australian National University\n- keywords: YOLO\n- arxiv: [https://arxiv.org/abs/1803.07113](https://arxiv.org/abs/1803.07113)\n\n**Zero-Shot Object Detection**\n\n[https://arxiv.org/abs/1804.04340](https://arxiv.org/abs/1804.04340)\n\n**Zero-Shot Object Detection: Learning to Simultaneously Recognize and Localize Novel Concepts**\n\n- intro: Australian National University\n- arxiv: [https://arxiv.org/abs/1803.06049](https://arxiv.org/abs/1803.06049)\n\n**Zero-Shot Object Detection by Hybrid Region Embedding**\n\n- intro: Middle East Technical University & Hacettepe University\n- arxiv: [https://arxiv.org/abs/1805.06157](https://arxiv.org/abs/1805.06157)\n\n# Visual Relationship Detection\n\n**Visual Relationship Detection with Language Priors**\n\n- intro: ECCV 2016 oral\n- paper: [https://cs.stanford.edu/people/ranjaykrishna/vrd/vrd.pdf](https://cs.stanford.edu/people/ranjaykrishna/vrd/vrd.pdf)\n- github: [https://github.com/Prof-Lu-Cewu/Visual-Relationship-Detection](https://github.com/Prof-Lu-Cewu/Visual-Relationship-Detection)\n\n**ViP-CNN: A Visual Phrase Reasoning Convolutional Neural Network for Visual Relationship Detection**\n\n- intro: Visual Phrase reasoning Convolutional Neural Network (ViP-CNN), Visual Phrase Reasoning Structure (VPRS)\n- arxiv: [https://arxiv.org/abs/1702.07191](https://arxiv.org/abs/1702.07191)\n\n**Visual Translation Embedding Network for Visual Relation Detection**\n\n- arxiv: [https://www.arxiv.org/abs/1702.08319](https://www.arxiv.org/abs/1702.08319)\n\n**Deep Variation-structured Reinforcement Learning for Visual Relationship and Attribute Detection**\n\n- intro: CVPR 2017 spotlight paper\n- arxiv: [https://arxiv.org/abs/1703.03054](https://arxiv.org/abs/1703.03054)\n\n**Detecting Visual Relationships with Deep Relational Networks**\n\n- intro: CVPR 2017 oral. The Chinese University of Hong Kong\n- arxiv: [https://arxiv.org/abs/1704.03114](https://arxiv.org/abs/1704.03114)\n\n**Identifying Spatial Relations in Images using Convolutional Neural Networks**\n\n[https://arxiv.org/abs/1706.04215](https://arxiv.org/abs/1706.04215)\n\n**PPR-FCN: Weakly Supervised Visual Relation Detection via Parallel Pairwise R-FCN**\n\n- intro: ICCV\n- arxiv: [https://arxiv.org/abs/1708.01956](https://arxiv.org/abs/1708.01956)\n\n**Natural Language Guided Visual Relationship Detection**\n\n[https://arxiv.org/abs/1711.06032](https://arxiv.org/abs/1711.06032)\n\n**Detecting Visual Relationships Using Box Attention**\n\n- intro: Google AI & IST Austria\n- arxiv: [https://arxiv.org/abs/1807.02136](https://arxiv.org/abs/1807.02136)\n\n**Google AI Open Images - Visual Relationship Track**\n\n- intro: Detect pairs of objects in particular relationships\n- kaggle: [https://www.kaggle.com/c/google-ai-open-images-visual-relationship-track](https://www.kaggle.com/c/google-ai-open-images-visual-relationship-track)\n\n**Context-Dependent Diffusion Network for Visual Relationship Detection**\n\n- intro: 2018 ACM Multimedia Conference\n- arxiv: [https://arxiv.org/abs/1809.06213](https://arxiv.org/abs/1809.06213)\n\n**A Problem Reduction Approach for Visual Relationships Detection**\n\n- intro: ECCV 2018 Workshop\n- arxiv: [https://arxiv.org/abs/1809.09828](https://arxiv.org/abs/1809.09828)\n\n**Exploring the Semantics for Visual Relationship Detection**\n\n[https://arxiv.org/abs/1904.02104](https://arxiv.org/abs/1904.02104)\n\n# Face Detection\n\n**Multi-view Face Detection Using Deep Convolutional Neural Networks**\n\n- intro: Yahoo\n- arxiv: [http://arxiv.org/abs/1502.02766](http://arxiv.org/abs/1502.02766)\n- github: [https://github.com/guoyilin/FaceDetection_CNN](https://github.com/guoyilin/FaceDetection_CNN)\n\n**From Facial Parts Responses to Face Detection: A Deep Learning Approach**\n\n![](http://personal.ie.cuhk.edu.hk/~ys014/projects/Faceness/support/index.png)\n\n- intro: ICCV 2015. CUHK\n- project page: [http://personal.ie.cuhk.edu.hk/~ys014/projects/Faceness/Faceness.html](http://personal.ie.cuhk.edu.hk/~ys014/projects/Faceness/Faceness.html)\n- arxiv: [https://arxiv.org/abs/1509.06451](https://arxiv.org/abs/1509.06451)\n- paper: [http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Yang_From_Facial_Parts_ICCV_2015_paper.pdf](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Yang_From_Facial_Parts_ICCV_2015_paper.pdf)\n\n**Compact Convolutional Neural Network Cascade for Face Detection**\n\n- arxiv: [http://arxiv.org/abs/1508.01292](http://arxiv.org/abs/1508.01292)\n- github: [https://github.com/Bkmz21/FD-Evaluation](https://github.com/Bkmz21/FD-Evaluation)\n- github: [https://github.com/Bkmz21/CompactCNNCascade](https://github.com/Bkmz21/CompactCNNCascade)\n\n**Face Detection with End-to-End Integration of a ConvNet and a 3D Model**\n\n- intro: ECCV 2016\n- arxiv: [https://arxiv.org/abs/1606.00850](https://arxiv.org/abs/1606.00850)\n- github(MXNet): [https://github.com/tfwu/FaceDetection-ConvNet-3D](https://github.com/tfwu/FaceDetection-ConvNet-3D)\n\n**CMS-RCNN: Contextual Multi-Scale Region-based CNN for Unconstrained Face Detection**\n\n- intro: CMU\n- arxiv: [https://arxiv.org/abs/1606.05413](https://arxiv.org/abs/1606.05413)\n\n**Towards a Deep Learning Framework for Unconstrained Face Detection**\n\n- intro: overlap with CMS-RCNN\n- arxiv: [https://arxiv.org/abs/1612.05322](https://arxiv.org/abs/1612.05322)\n\n**Supervised Transformer Network for Efficient Face Detection**\n\n- arxiv: [http://arxiv.org/abs/1607.05477](http://arxiv.org/abs/1607.05477)\n\n**UnitBox: An Advanced Object Detection Network**\n\n- intro: ACM MM 2016\n- intro: University of Illinois at UrbanaChampaign & Megvii Inc\n- keywords: IOULoss\n- arxiv: [http://arxiv.org/abs/1608.01471](http://arxiv.org/abs/1608.01471)\n\n**Bootstrapping Face Detection with Hard Negative Examples**\n\n- author:  @ .\n- intro: Faster R-CNN, hard negative mining. state-of-the-art on the FDDB dataset\n- arxiv: [http://arxiv.org/abs/1608.02236](http://arxiv.org/abs/1608.02236)\n\n**Grid Loss: Detecting Occluded Faces**\n\n- intro: ECCV 2016\n- arxiv: [https://arxiv.org/abs/1609.00129](https://arxiv.org/abs/1609.00129)\n- paper: [http://lrs.icg.tugraz.at/pubs/opitz_eccv_16.pdf](http://lrs.icg.tugraz.at/pubs/opitz_eccv_16.pdf)\n- poster: [http://www.eccv2016.org/files/posters/P-2A-34.pdf](http://www.eccv2016.org/files/posters/P-2A-34.pdf)\n\n**A Multi-Scale Cascade Fully Convolutional Network Face Detector**\n\n- intro: ICPR 2016\n- arxiv: [http://arxiv.org/abs/1609.03536](http://arxiv.org/abs/1609.03536)\n\n## MTCNN\n\n**Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks**\n\n**Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Neural Networks**\n\n![](https://kpzhang93.github.io/MTCNN_face_detection_alignment/support/index.png)\n\n- project page: [https://kpzhang93.github.io/MTCNN_face_detection_alignment/index.html](https://kpzhang93.github.io/MTCNN_face_detection_alignment/index.html)\n- arxiv: [https://arxiv.org/abs/1604.02878](https://arxiv.org/abs/1604.02878)\n- github(official, Matlab): [https://github.com/kpzhang93/MTCNN_face_detection_alignment](https://github.com/kpzhang93/MTCNN_face_detection_alignment)\n- github: [https://github.com/pangyupo/mxnet_mtcnn_face_detection](https://github.com/pangyupo/mxnet_mtcnn_face_detection)\n- github: [https://github.com/DaFuCoding/MTCNN_Caffe](https://github.com/DaFuCoding/MTCNN_Caffe)\n- github(MXNet): [https://github.com/Seanlinx/mtcnn](https://github.com/Seanlinx/mtcnn)\n- github: [https://github.com/Pi-DeepLearning/RaspberryPi-FaceDetection-MTCNN-Caffe-With-Motion](https://github.com/Pi-DeepLearning/RaspberryPi-FaceDetection-MTCNN-Caffe-With-Motion)\n- github(Caffe): [https://github.com/foreverYoungGitHub/MTCNN](https://github.com/foreverYoungGitHub/MTCNN)\n- github: [https://github.com/CongWeilin/mtcnn-caffe](https://github.com/CongWeilin/mtcnn-caffe)\n- github(OpenCV+OpenBlas): [https://github.com/AlphaQi/MTCNN-light](https://github.com/AlphaQi/MTCNN-light)\n- github(Tensorflow+golang): [https://github.com/jdeng/goface](https://github.com/jdeng/goface)\n\n**Face Detection using Deep Learning: An Improved Faster RCNN Approach**\n\n- intro: DeepIR Inc\n- arxiv: [https://arxiv.org/abs/1701.08289](https://arxiv.org/abs/1701.08289)\n\n**Faceness-Net: Face Detection through Deep Facial Part Responses**\n\n- intro: An extended version of ICCV 2015 paper\n- arxiv: [https://arxiv.org/abs/1701.08393](https://arxiv.org/abs/1701.08393)\n\n**Multi-Path Region-Based Convolutional Neural Network for Accurate Detection of Unconstrained \"Hard Faces\"**\n\n- intro: CVPR 2017. MP-RCNN, MP-RPN\n- arxiv: [https://arxiv.org/abs/1703.09145](https://arxiv.org/abs/1703.09145)\n\n**End-To-End Face Detection and Recognition**\n\n[https://arxiv.org/abs/1703.10818](https://arxiv.org/abs/1703.10818)\n\n**Face R-CNN**\n\n[https://arxiv.org/abs/1706.01061](https://arxiv.org/abs/1706.01061)\n\n**Face Detection through Scale-Friendly Deep Convolutional Networks**\n\n[https://arxiv.org/abs/1706.02863](https://arxiv.org/abs/1706.02863)\n\n**Scale-Aware Face Detection**\n\n- intro: CVPR 2017. SenseTime & Tsinghua University\n- arxiv: [https://arxiv.org/abs/1706.09876](https://arxiv.org/abs/1706.09876)\n\n**Detecting Faces Using Inside Cascaded Contextual CNN**\n\n- intro: CVPR 2017. Tencent AI Lab & SenseTime\n- paper: [http://ai.tencent.com/ailab/media/publications/Detecting_Faces_Using_Inside_Cascaded_Contextual_CNN.pdf](http://ai.tencent.com/ailab/media/publications/Detecting_Faces_Using_Inside_Cascaded_Contextual_CNN.pdf)\n\n**Multi-Branch Fully Convolutional Network for Face Detection**\n\n[https://arxiv.org/abs/1707.06330](https://arxiv.org/abs/1707.06330)\n\n**SSH: Single Stage Headless Face Detector**\n\n- intro: ICCV 2017. University of Maryland\n- arxiv: [https://arxiv.org/abs/1708.03979](https://arxiv.org/abs/1708.03979)\n- github(official, Caffe): [https://github.com/mahyarnajibi/SSH](https://github.com/mahyarnajibi/SSH)\n\n**Dockerface: an easy to install and use Faster R-CNN face detector in a Docker container**\n\n[https://arxiv.org/abs/1708.04370](https://arxiv.org/abs/1708.04370)\n\n**FaceBoxes: A CPU Real-time Face Detector with High Accuracy**\n\n- intro: IJCB 2017\n- keywords: Rapidly Digested Convolutional Layers (RDCL), Multiple Scale Convolutional Layers (MSCL)\n- intro: the proposed detector runs at 20 FPS on a single CPU core and 125 FPS using a GPU for VGA-resolution images\n- arxiv: [https://arxiv.org/abs/1708.05234](https://arxiv.org/abs/1708.05234)\n- github(official): [https://github.com/sfzhang15/FaceBoxes](https://github.com/sfzhang15/FaceBoxes)\n- github(Caffe): [https://github.com/zeusees/FaceBoxes](https://github.com/zeusees/FaceBoxes)\n\n**S3FD: Single Shot Scale-invariant Face Detector**\n\n- intro: ICCV 2017. Chinese Academy of Sciences\n- intro: can run at 36 FPS on a Nvidia Titan X (Pascal) for VGA-resolution images\n- arxiv: [https://arxiv.org/abs/1708.05237](https://arxiv.org/abs/1708.05237)\n- github(Caffe, official): [https://github.com/sfzhang15/SFD](https://github.com/sfzhang15/SFD)\n- github: [https://github.com//clcarwin/SFD_pytorch](https://github.com//clcarwin/SFD_pytorch)\n\n**Detecting Faces Using Region-based Fully Convolutional Networks**\n\n[https://arxiv.org/abs/1709.05256](https://arxiv.org/abs/1709.05256)\n\n**AffordanceNet: An End-to-End Deep Learning Approach for Object Affordance Detection**\n\n[https://arxiv.org/abs/1709.07326](https://arxiv.org/abs/1709.07326)\n\n**Face Attention Network: An effective Face Detector for the Occluded Faces**\n\n[https://arxiv.org/abs/1711.07246](https://arxiv.org/abs/1711.07246)\n\n**Feature Agglomeration Networks for Single Stage Face Detection**\n\n[https://arxiv.org/abs/1712.00721](https://arxiv.org/abs/1712.00721)\n\n**Face Detection Using Improved Faster RCNN**\n\n- intro: Huawei Cloud BU\n- arxiv: [https://arxiv.org/abs/1802.02142](https://arxiv.org/abs/1802.02142)\n\n**PyramidBox: A Context-assisted Single Shot Face Detector**\n\n- intro: Baidu, Inc\n- arxiv: [https://arxiv.org/abs/1803.07737](https://arxiv.org/abs/1803.07737)\n\n**PyramidBox++: High Performance Detector for Finding Tiny Face**\n\n- intro: Chinese Academy of Sciences & Baidu, Inc.\n- arxiv: [https://arxiv.org/abs/1904.00386](https://arxiv.org/abs/1904.00386)\n\n**A Fast Face Detection Method via Convolutional Neural Network**\n\n- intro: Neurocomputing\n- arxiv: [https://arxiv.org/abs/1803.10103](https://arxiv.org/abs/1803.10103)\n\n**Beyond Trade-off: Accelerate FCN-based Face Detector with Higher Accuracy**\n\n- intro: CVPR 2018. Beihang University & CUHK & Sensetime\n- arxiv: [https://arxiv.org/abs/1804.05197](https://arxiv.org/abs/1804.05197)\n\n**Real-Time Rotation-Invariant Face Detection with Progressive Calibration Networks**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1804.06039](https://arxiv.org/abs/1804.06039)\n- github(binary library): [https://github.com/Jack-CV/PCN](https://github.com/Jack-CV/PCN)\n\n**SFace: An Efficient Network for Face Detection in Large Scale Variations**\n\n- intro: Beihang University & Megvii Inc. (Face++)\n- arxiv: [https://arxiv.org/abs/1804.06559](https://arxiv.org/abs/1804.06559)\n\n**Survey of Face Detection on Low-quality Images**\n\n[https://arxiv.org/abs/1804.07362](https://arxiv.org/abs/1804.07362)\n\n**Anchor Cascade for Efficient Face Detection**\n\n- intro: The University of Sydney\n- arxiv: [https://arxiv.org/abs/1805.03363](https://arxiv.org/abs/1805.03363)\n\n**Adversarial Attacks on Face Detectors using Neural Net based Constrained Optimization**\n\n- intro: IEEE MMSP\n- arxiv: [https://arxiv.org/abs/1805.12302](https://arxiv.org/abs/1805.12302)\n\n**Selective Refinement Network for High Performance Face Detection**\n\n[https://arxiv.org/abs/1809.02693](https://arxiv.org/abs/1809.02693)\n\n**DSFD: Dual Shot Face Detector**\n\n[https://arxiv.org/abs/1810.10220](https://arxiv.org/abs/1810.10220)\n\n**Learning Better Features for Face Detection with Feature Fusion and Segmentation Supervision**\n\n[https://arxiv.org/abs/1811.08557](https://arxiv.org/abs/1811.08557)\n\n**FA-RPN: Floating Region Proposals for Face Detection**\n\n[https://arxiv.org/abs/1812.05586](https://arxiv.org/abs/1812.05586)\n\n**Robust and High Performance Face Detector**\n\n[https://arxiv.org/abs/1901.02350](https://arxiv.org/abs/1901.02350)\n\n**DAFE-FD: Density Aware Feature Enrichment for Face Detection**\n\n[https://arxiv.org/abs/1901.05375](https://arxiv.org/abs/1901.05375)\n\n**Improved Selective Refinement Network for Face Detection**\n\n- intro: Chinese Academy of Sciences & JD AI Research\n- arxiv: [https://arxiv.org/abs/1901.06651](https://arxiv.org/abs/1901.06651)\n\n**Revisiting a single-stage method for face detection**\n\n[https://arxiv.org/abs/1902.01559](https://arxiv.org/abs/1902.01559)\n\n**MSFD:Multi-Scale Receptive Field Face Detector**\n\n- intro: ICPR 2018\n- arxiv: [https://arxiv.org/abs/1903.04147](https://arxiv.org/abs/1903.04147)\n\n**LFFD: A Light and Fast Face Detector for Edge Devices**\n\n- arxiv: [https://arxiv.org/abs/1904.10633](https://arxiv.org/abs/1904.10633)\n- github: [https://github.com/YonghaoHe/A-Light-and-Fast-Face-Detector-for-Edge-Devices](https://github.com/YonghaoHe/A-Light-and-Fast-Face-Detector-for-Edge-Devices)\n\n**RetinaFace: Single-stage Dense Face Localisation in the Wild**\n\n- intro: CVPR 2020\n- arxiv: [https://arxiv.org/abs/1905.00641](https://arxiv.org/abs/1905.00641)\n- gihtub: [https://github.com/deepinsight/insightface/tree/master/RetinaFace](https://github.com/deepinsight/insightface/tree/master/RetinaFace)\n\n**BlazeFace: Sub-millisecond Neural Face Detection on Mobile GPUs**\n\n- intro: CVPR Workshop on Computer Vision for Augmented and Virtual Reality, 2019\n- arxiv: [https://arxiv.org/abs/1907.05047](https://arxiv.org/abs/1907.05047)\n\n**HAMBox: Delving into Online High-quality Anchors Mining for Detecting Outer Faces**\n\n- intro: Baidu Inc. &  Chinese Academy of Sciences\n- arxiv: [https://arxiv.org/abs/1912.09231](https://arxiv.org/abs/1912.09231)\n\n**KPNet: Towards Minimal Face Detector**\n\n- intro: AAAI 2020\n- arxiv: [https://arxiv.org/abs/2003.07543](https://arxiv.org/abs/2003.07543)\n\n**ASFD: Automatic and Scalable Face Detector**\n\n- intro: Youtu Lab, Tencent & Southeast University & Xiamen University\n- arxiv: [https://arxiv.org/abs/2003.11228](https://arxiv.org/abs/2003.11228)\n\n**TinaFace: Strong but Simple Baseline for Face Detection**\n\n- intro: Media Intelligence Technology Co.,Ltd\n- arxiv: [https://arxiv.org/abs/2011.13183](https://arxiv.org/abs/2011.13183)\n- github(PyTorch): [https://github.com/Media-Smart/vedadet](https://github.com/Media-Smart/vedadet)\n\n**MogFace: Rethinking Scale Augmentation on the Face Detector**\n\n- intro: Alibaba Group & Imperial College\n- arxiv: [https://arxiv.org/abs/2103.11139](https://arxiv.org/abs/2103.11139)\n\n**HLA-Face: Joint High-Low Adaptation for Low Light Face Detection**\n\n- intro: CVPR 2021\n- intro: Peking University\n- project page: [https://daooshee.github.io/HLA-Face-Website/](https://daooshee.github.io/HLA-Face-Website/)\n- arxiv: [https://arxiv.org/abs/2104.01984](https://arxiv.org/abs/2104.01984)\n- github: [https://github.com/daooshee/HLA-Face-Code](https://github.com/daooshee/HLA-Face-Code)\n\n**1st Place Solutions for UG2+ Challenge 2021 -- (Semi-)supervised Face detection in the low light condition**\n\n- intro: Tomorrow Advancing Life (TAL) Education Group\n- arxiv: [https://arxiv.org/abs/2107.00818](https://arxiv.org/abs/2107.00818)\n\n**MOS: A Low Latency and Lightweight Framework for Face Detection, Landmark Localization, and Head Pose Estimation**\n\n- intro: BMVC 2021\n- arxiv: [https://arxiv.org/abs/2110.10953](https://arxiv.org/abs/2110.10953)\n- github: [https://github.com/lyp-deeplearning/MOS-Multi-Task-Face-Detect](https://github.com/lyp-deeplearning/MOS-Multi-Task-Face-Detect)\n\n## Detect Small Faces\n\n**Finding Tiny Faces**\n\n- intro: CVPR 2017. CMU\n- project page: [http://www.cs.cmu.edu/~peiyunh/tiny/index.html](http://www.cs.cmu.edu/~peiyunh/tiny/index.html)\n- arxiv: [https://arxiv.org/abs/1612.04402](https://arxiv.org/abs/1612.04402)\n- github(official, Matlab): [https://github.com/peiyunh/tiny](https://github.com/peiyunh/tiny)\n- github(inference-only): [https://github.com/chinakook/hr101_mxnet](https://github.com/chinakook/hr101_mxnet)\n- github: [https://github.com/cydonia999/Tiny_Faces_in_Tensorflow](https://github.com/cydonia999/Tiny_Faces_in_Tensorflow)\n\n**Detecting and counting tiny faces**\n\n- intro: ENS Paris-Saclay. ExtendedTinyFaces\n- intro: Detecting and counting small objects - Analysis, review and application to counting\n- arxiv: [https://arxiv.org/abs/1801.06504](https://arxiv.org/abs/1801.06504)\n- github: [https://github.com/alexattia/ExtendedTinyFaces](https://github.com/alexattia/ExtendedTinyFaces)\n\n**Seeing Small Faces from Robust Anchor's Perspective**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1802.09058](https://arxiv.org/abs/1802.09058)\n\n**Face-MagNet: Magnifying Feature Maps to Detect Small Faces**\n\n- intro: WACV 2018\n- keywords: Face Magnifier Network (Face-MageNet)\n- arxiv: [https://arxiv.org/abs/1803.05258](https://arxiv.org/abs/1803.05258)\n- github: [https://github.com/po0ya/face-magnet](https://github.com/po0ya/face-magnet)\n\n**Robust Face Detection via Learning Small Faces on Hard Images**\n\n- intro: Johns Hopkins University & Stanford University\n- arxiv: [https://arxiv.org/abs/1811.11662](https://arxiv.org/abs/1811.11662)\n- github: [https://github.com/bairdzhang/smallhardface](https://github.com/bairdzhang/smallhardface)\n\n**SFA: Small Faces Attention Face Detector**\n\n- intro: Jilin University\n- arxiv: [https://arxiv.org/abs/1812.08402](https://arxiv.org/abs/1812.08402)\n\n# Person Head Detection\n\n**Context-aware CNNs for person head detection**\n\n- intro: ICCV 2015\n- project page: [http://www.di.ens.fr/willow/research/headdetection/](http://www.di.ens.fr/willow/research/headdetection/)\n- arxiv: [http://arxiv.org/abs/1511.07917](http://arxiv.org/abs/1511.07917)\n- github: [https://github.com/aosokin/cnn_head_detection](https://github.com/aosokin/cnn_head_detection)\n\n**Detecting Heads using Feature Refine Net and Cascaded Multi-scale Architecture**\n\n[https://arxiv.org/abs/1803.09256](https://arxiv.org/abs/1803.09256)\n\n**A Comparison of CNN-based Face and Head Detectors for Real-Time Video Surveillance Applications**\n\n[https://arxiv.org/abs/1809.03336](https://arxiv.org/abs/1809.03336)\n\n**FCHD: A fast and accurate head detector**\n\n- arxiv: [https://arxiv.org/abs/1809.08766](https://arxiv.org/abs/1809.08766)\n- github(PyTorch, official): [https://github.com/aditya-vora/FCHD-Fully-Convolutional-Head-Detector](https://github.com/aditya-vora/FCHD-Fully-Convolutional-Head-Detector)\n\n**Relational Learning for Joint Head and Human Detection**\n\n- keywords: JointDet, head-body Relationship Discriminating Module (RDM)\n- arxiv: [https://arxiv.org/abs/1909.10674](https://arxiv.org/abs/1909.10674)\n\n**Body-Face Joint Detection via Embedding and Head Hook**\n\n- intro: ICCV 2021\n- paper: [https://openaccess.thecvf.com/content/ICCV2021/papers/Wan_Body-Face_Joint_Detection_via_Embedding_and_Head_Hook_ICCV_2021_paper.pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Wan_Body-Face_Joint_Detection_via_Embedding_and_Head_Hook_ICCV_2021_paper.pdf)\n- gihtub: [https://github.com/AibeeDetect/BFJDet](https://github.com/AibeeDetect/BFJDet)\n\n# Pedestrian Detection / People Detection\n\n**Pedestrian Detection aided by Deep Learning Semantic Tasks**\n\n- intro: CVPR 2015\n- project page: [http://mmlab.ie.cuhk.edu.hk/projects/TA-CNN/](http://mmlab.ie.cuhk.edu.hk/projects/TA-CNN/)\n- arxiv: [http://arxiv.org/abs/1412.0069](http://arxiv.org/abs/1412.0069)\n\n**Deep Learning Strong Parts for Pedestrian Detection**\n\n- intro: ICCV 2015. CUHK. DeepParts\n- intro: Achieving 11.89% average miss rate on Caltech Pedestrian Dataset\n- paper: [http://personal.ie.cuhk.edu.hk/~pluo/pdf/tianLWTiccv15.pdf](http://personal.ie.cuhk.edu.hk/~pluo/pdf/tianLWTiccv15.pdf)\n\n**Taking a Deeper Look at Pedestrians**\n\n- intro: CVPR 2015\n- arxiv: [https://arxiv.org/abs/1501.05790](https://arxiv.org/abs/1501.05790)\n\n**Convolutional Channel Features**\n\n- intro: ICCV 2015\n- arxiv: [https://arxiv.org/abs/1504.07339](https://arxiv.org/abs/1504.07339)\n- github: [https://github.com/byangderek/CCF](https://github.com/byangderek/CCF)\n\n**End-to-end people detection in crowded scenes**\n\n- arxiv: [http://arxiv.org/abs/1506.04878](http://arxiv.org/abs/1506.04878)\n- github: [https://github.com/Russell91/reinspect](https://github.com/Russell91/reinspect)\n- ipn: [http://nbviewer.ipython.org/github/Russell91/ReInspect/blob/master/evaluation_reinspect.ipynb](http://nbviewer.ipython.org/github/Russell91/ReInspect/blob/master/evaluation_reinspect.ipynb)\n- youtube: [https://www.youtube.com/watch?v=QeWl0h3kQ24](https://www.youtube.com/watch?v=QeWl0h3kQ24)\n\n**Learning Complexity-Aware Cascades for Deep Pedestrian Detection**\n\n- intro: ICCV 2015\n- arxiv: [https://arxiv.org/abs/1507.05348](https://arxiv.org/abs/1507.05348)\n\n**Deep convolutional neural networks for pedestrian detection**\n\n- arxiv: [http://arxiv.org/abs/1510.03608](http://arxiv.org/abs/1510.03608)\n- github: [https://github.com/DenisTome/DeepPed](https://github.com/DenisTome/DeepPed)\n\n**Scale-aware Fast R-CNN for Pedestrian Detection**\n\n- arxiv: [https://arxiv.org/abs/1510.08160](https://arxiv.org/abs/1510.08160)\n\n**New algorithm improves speed and accuracy of pedestrian detection**\n\n- blog: [http://www.eurekalert.org/pub_releases/2016-02/uoc--nai020516.php](http://www.eurekalert.org/pub_releases/2016-02/uoc--nai020516.php)\n\n**Pushing the Limits of Deep CNNs for Pedestrian Detection**\n\n- intro: \"set a new record on the Caltech pedestrian dataset, lowering the log-average miss rate from 11.7% to 8.9%\"\n- arxiv: [http://arxiv.org/abs/1603.04525](http://arxiv.org/abs/1603.04525)\n\n**A Real-Time Deep Learning Pedestrian Detector for Robot Navigation**\n\n- arxiv: [http://arxiv.org/abs/1607.04436](http://arxiv.org/abs/1607.04436)\n\n**A Real-Time Pedestrian Detector using Deep Learning for Human-Aware Navigation**\n\n- arxiv: [http://arxiv.org/abs/1607.04441](http://arxiv.org/abs/1607.04441)\n\n**Is Faster R-CNN Doing Well for Pedestrian Detection?**\n\n- intro: ECCV 2016\n- arxiv: [http://arxiv.org/abs/1607.07032](http://arxiv.org/abs/1607.07032)\n- github: [https://github.com/zhangliliang/RPN_BF/tree/RPN-pedestrian](https://github.com/zhangliliang/RPN_BF/tree/RPN-pedestrian)\n\n**Unsupervised Deep Domain Adaptation for Pedestrian Detection**\n\n- intro: ECCV Workshop 2016\n- arxiv: [https://arxiv.org/abs/1802.03269](https://arxiv.org/abs/1802.03269)\n\n**Reduced Memory Region Based Deep Convolutional Neural Network Detection**\n\n- intro: IEEE 2016 ICCE-Berlin\n- arxiv: [http://arxiv.org/abs/1609.02500](http://arxiv.org/abs/1609.02500)\n\n**Fused DNN: A deep neural network fusion approach to fast and robust pedestrian detection**\n\n- arxiv: [https://arxiv.org/abs/1610.03466](https://arxiv.org/abs/1610.03466)\n\n**Detecting People in Artwork with CNNs**\n\n- intro: ECCV 2016 Workshops\n- arxiv: [https://arxiv.org/abs/1610.08871](https://arxiv.org/abs/1610.08871)\n\n**Deep Multi-camera People Detection**\n\n- arxiv: [https://arxiv.org/abs/1702.04593](https://arxiv.org/abs/1702.04593)\n\n**Expecting the Unexpected: Training Detectors for Unusual Pedestrians with Adversarial Imposters**\n\n- intro: CVPR 2017\n- project page: [http://ml.cs.tsinghua.edu.cn:5000/publications/synunity/](http://ml.cs.tsinghua.edu.cn:5000/publications/synunity/)\n- arxiv: [https://arxiv.org/abs/1703.06283](https://arxiv.org/abs/1703.06283)\n- github(Tensorflow): [https://github.com/huangshiyu13/RPNplus](https://github.com/huangshiyu13/RPNplus)\n\n**What Can Help Pedestrian Detection?**\n\n- intro: CVPR 2017. Tsinghua University & Peking University & Megvii Inc.\n- keywords: Faster R-CNN, HyperLearner\n- arxiv: [https://arxiv.org/abs/1705.02757](https://arxiv.org/abs/1705.02757)\n- paper: [http://openaccess.thecvf.com/content_cvpr_2017/papers/Mao_What_Can_Help_CVPR_2017_paper.pdf](http://openaccess.thecvf.com/content_cvpr_2017/papers/Mao_What_Can_Help_CVPR_2017_paper.pdf)\n\n**Illuminating Pedestrians via Simultaneous Detection & Segmentation**\n\n[https://arxiv.org/abs/1706.08564](https://arxiv.org/abs/1706.08564)\n\n**Rotational Rectification Network for Robust Pedestrian Detection**\n\n- intro: CMU & Volvo Construction\n- arxiv: [https://arxiv.org/abs/1706.08917](https://arxiv.org/abs/1706.08917)\n\n**STD-PD: Generating Synthetic Training Data for Pedestrian Detection in Unannotated Videos**\n\n- intro: The University of North Carolina at Chapel Hill\n- arxiv: [https://arxiv.org/abs/1707.09100](https://arxiv.org/abs/1707.09100)\n\n**Too Far to See? Not Really! --- Pedestrian Detection with Scale-aware Localization Policy**\n\n[https://arxiv.org/abs/1709.00235](https://arxiv.org/abs/1709.00235)\n\n**Aggregated Channels Network for Real-Time Pedestrian Detection**\n\n[https://arxiv.org/abs/1801.00476](https://arxiv.org/abs/1801.00476)\n\n**Exploring Multi-Branch and High-Level Semantic Networks for Improving Pedestrian Detection**\n\n[https://arxiv.org/abs/1804.00872](https://arxiv.org/abs/1804.00872)\n\n**Pedestrian-Synthesis-GAN: Generating Pedestrian Data in Real Scene and Beyond**\n\n[https://arxiv.org/abs/1804.02047](https://arxiv.org/abs/1804.02047)\n\n**PCN: Part and Context Information for Pedestrian Detection with CNNs**\n\n- intro: British Machine Vision Conference(BMVC) 2017\n- arxiv: [https://arxiv.org/abs/1804.04483](https://arxiv.org/abs/1804.04483)\n\n**Improving Occlusion and Hard Negative Handling for Single-Stage Pedestrian Detectors**\n\n- intro: CVPR 2018\n- paper: [http://openaccess.thecvf.com/content_cvpr_2018/papers/Noh_Improving_Occlusion_and_CVPR_2018_paper.pdf](http://openaccess.thecvf.com/content_cvpr_2018/papers/Noh_Improving_Occlusion_and_CVPR_2018_paper.pdf)\n\n**Small-scale Pedestrian Detection Based on Somatic Topology Localization and Temporal Feature Aggregation**\n\n- intro: ECCV 2018\n- intro: Hikvision Research Institute\n- arxiv: [https://arxiv.org/abs/1807.01438](https://arxiv.org/abs/1807.01438)\n\n**Bi-box Regression for Pedestrian Detection and Occlusion Estimation**\n\n- intro: ECCV 2018\n- paper: [http://openaccess.thecvf.com/content_ECCV_2018/papers/CHUNLUAN_ZHOU_Bi-box_Regression_for_ECCV_2018_paper.pdf](http://openaccess.thecvf.com/content_ECCV_2018/papers/CHUNLUAN_ZHOU_Bi-box_Regression_for_ECCV_2018_paper.pdf)\n- github(Pytorch): [https://github.com/rainofmine/Bi-box_Regression](https://github.com/rainofmine/Bi-box_Regression)\n\n**Pedestrian Detection with Autoregressive Network Phases**\n\n- intro: Michigan State University\n- arxiv: [https://arxiv.org/abs/1812.00440](https://arxiv.org/abs/1812.00440)\n\n**SSA-CNN: Semantic Self-Attention CNN for Pedestrian Detection**\n\n[https://arxiv.org/abs/1902.09080](https://arxiv.org/abs/1902.09080)\n\n**High-level Semantic Feature Detection:A New Perspective for Pedestrian Detection**\n\n**Center and Scale Prediction: A Box-free Approach for Object Detection**\n\n- intro: CVPR 2019\n- intro: National University of Defense Technology & Chinese Academy of Sciences & Inception Institute of Artificial Intelligence (IIAI) & Horizon Robotics Inc.\n- arxiv: [https://arxiv.org/abs/1904.02948](https://arxiv.org/abs/1904.02948)\n- github(official, Keras): [https://github.com/liuwei16/CSP](https://github.com/liuwei16/CSP)\n\n**Evading Real-Time Person Detectors by Adversarial T-shirt**\n\n[https://arxiv.org/abs/1910.11099](https://arxiv.org/abs/1910.11099)\n\n**Coupled Network for Robust Pedestrian Detection with Gated Multi-Layer Feature Extraction and Deformable Occlusion Handling**\n\n[https://arxiv.org/abs/1912.08661](https://arxiv.org/abs/1912.08661)\n\n**Scale Match for Tiny Person Detection**\n\n- intro: WACV 2020\n- arxiv: [https://arxiv.org/abs/1912.10664](https://arxiv.org/abs/1912.10664)\n- github: [https://github.com/ucas-vg/TinyBenchmark](https://github.com/ucas-vg/TinyBenchmark)\n\n**SM+: Refined Scale Match for Tiny Person Detection**\n\n[https://arxiv.org/abs/2102.03558](https://arxiv.org/abs/2102.03558)\n\n**Resisting the Distracting-factors in Pedestrian Detection**\n\n- intro: Beihang University & Arizona State University\n- arxiv: [https://arxiv.org/abs/2005.07344](https://arxiv.org/abs/2005.07344)\n\n**SADet: Learning An Efficient and Accurate Pedestrian Detector**\n\n[https://arxiv.org/abs/2007.13119](https://arxiv.org/abs/2007.13119)\n\n**NOH-NMS: Improving Pedestrian Detection by Nearby Objects Hallucination**\n\n- intro: ACM MM 2020\n- intro: Tencent Youtu Lab\n- arxiv: [https://arxiv.org/abs/2007.13376](https://arxiv.org/abs/2007.13376)\n\n**Anchor-free Small-scale Multispectral Pedestrian Detection**\n\n- intro: BMVC 2020\n- arxiv: [https://arxiv.org/abs/2008.08418](https://arxiv.org/abs/2008.08418)\n- github: [https://github.com/HensoldtOptronicsCV/MultispectralPedestrianDetection](https://github.com/HensoldtOptronicsCV/MultispectralPedestrianDetection)\n\n**LLA: Loss-aware Label Assignment for Dense Pedestrian Detection**\n\n- arxiv: [https://arxiv.org/abs/2101.04307](https://arxiv.org/abs/2101.04307)\n- github: [https://github.com/Megvii-BaseDetection/LLA](https://github.com/Megvii-BaseDetection/LLA)\n\n**DETR for Pedestrian Detection**\n\n[https://arxiv.org/abs/2012.06785](https://arxiv.org/abs/2012.06785)\n\n**V2F-Net: Explicit Decomposition of Occluded Pedestrian Detection**\n\n- intro: MEGVII Technology & Texas A&M University\n- arxiv: [https://arxiv.org/abs/2104.03106](https://arxiv.org/abs/2104.03106)\n\n## Pedestrian Detection in a Crowd\n\n**Repulsion Loss: Detecting Pedestrians in a Crowd**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1711.07752](https://arxiv.org/abs/1711.07752)\n\n**Occlusion-aware R-CNN: Detecting Pedestrians in a Crowd**\n\n- intro: ECCV 2018\n- arxiv: [https://arxiv.org/abs/1807.08407](https://arxiv.org/abs/1807.08407)\n\n**Adaptive NMS: Refining Pedestrian Detection in a Crowd**\n\n- intro: CVPR 2019 oral\n- arxiv: [https://arxiv.org/abs/1904.03629](https://arxiv.org/abs/1904.03629)\n\n**PedHunter: Occlusion Robust Pedestrian Detector in Crowded Scenes**\n\n- keywords: SUR-PED\n- arxiv: [https://arxiv.org/abs/1909.06826](https://arxiv.org/abs/1909.06826)\n\n**Double Anchor R-CNN for Human Detection in a Crowd**\n\n- intro: Megvii Inc. (Face++) & Tsinghua University & Xian Jiaotong University & Zhejiang University\n- arxiv: [https://arxiv.org/abs/1909.09998](https://arxiv.org/abs/1909.09998)\n\n**CSID: Center, Scale, Identity and Density-aware Pedestrian Detection in a Crowd**\n\n[https://arxiv.org/abs/1910.09188](https://arxiv.org/abs/1910.09188)\n\n**Semantic Head Enhanced Pedestrian Detection in a Crowd**\n\n[https://arxiv.org/abs/1911.11985](https://arxiv.org/abs/1911.11985)\n\n**Detection in Crowded Scenes: One Proposal, Multiple Predictions**\n\n- intro: CVPR 2020 Oral\n- arxiv: [https://arxiv.org/abs/2003.09163](https://arxiv.org/abs/2003.09163)\n- github: [https://github.com/Purkialo/CrowdDet](https://github.com/Purkialo/CrowdDet)\n\n**Visible Feature Guidance for Crowd Pedestrian Detection**\n\n- intro: ECCV 2020 RLQ Workshop\n- arxiv: [https://arxiv.org/abs/2008.09993](https://arxiv.org/abs/2008.09993)\n\n# Occluded Pedestrian Detection\n\n**Mask-Guided Attention Network for Occluded Pedestrian Detection**\n\n- intro: ICCV 2019\n- arxiv: [https://arxiv.org/abs/1910.06160](https://arxiv.org/abs/1910.06160)\n- github: [https://github.com/Leotju/MGAN](https://github.com/Leotju/MGAN)\n\n## Multispectral Pedestrian Detection\n\n**Multispectral Deep Neural Networks for Pedestrian Detection**\n\n- intro: BMVC 2016 oral\n- arxiv: [https://arxiv.org/abs/1611.02644](https://arxiv.org/abs/1611.02644)\n\n**Illumination-aware Faster R-CNN for Robust Multispectral Pedestrian Detection**\n\n- intro: State Key Lab of CAD&CG, Zhejiang University\n- arxiv: [https://arxiv.org/abs/1803.05347](https://arxiv.org/abs/1803.05347)\n\n**Multispectral Pedestrian Detection via Simultaneous Detection and Segmentation**\n\n- intro: BMVC 2018\n- arxiv: [https://arxiv.org/abs/1808.04818](https://arxiv.org/abs/1808.04818)\n\n**The Cross-Modality Disparity Problem in Multispectral Pedestrian Detection**\n\n[https://arxiv.org/abs/1901.02645](https://arxiv.org/abs/1901.02645)\n\n**Box-level Segmentation Supervised Deep Neural Networks for Accurate and Real-time Multispectral Pedestrian Detection**\n\n[https://arxiv.org/abs/1902.05291](https://arxiv.org/abs/1902.05291)\n\n**GFD-SSD: Gated Fusion Double SSD for Multispectral Pedestrian Detection**\n\n[https://arxiv.org/abs/1903.06999](https://arxiv.org/abs/1903.06999)\n\n**Unsupervised Domain Adaptation for Multispectral Pedestrian Detection**\n\n[https://arxiv.org/abs/1904.03692](https://arxiv.org/abs/1904.03692)\n\n# Vehicle Detection\n\n**DAVE: A Unified Framework for Fast Vehicle Detection and Annotation**\n\n- intro: ECCV 2016\n- arxiv: [http://arxiv.org/abs/1607.04564](http://arxiv.org/abs/1607.04564)\n\n**Evolving Boxes for fast Vehicle Detection**\n\n- arxiv: [https://arxiv.org/abs/1702.00254](https://arxiv.org/abs/1702.00254)\n\n**Fine-Grained Car Detection for Visual Census Estimation**\n\n- intro: AAAI 2016\n- arxiv: [https://arxiv.org/abs/1709.02480](https://arxiv.org/abs/1709.02480)\n\n**SINet: A Scale-insensitive Convolutional Neural Network for Fast Vehicle Detection**\n\n- intro: IEEE Transactions on Intelligent Transportation Systems (T-ITS)\n- arxiv: [https://arxiv.org/abs/1804.00433](https://arxiv.org/abs/1804.00433)\n\n**Label and Sample: Efficient Training of Vehicle Object Detector from Sparsely Labeled Data**\n\n- intro: UC Berkeley\n- arxiv: [https://arxiv.org/abs/1808.08603](https://arxiv.org/abs/1808.08603)\n\n**Domain Randomization for Scene-Specific Car Detection and Pose Estimation**\n\n[https://arxiv.org/abs/1811.05939](https://arxiv.org/abs/1811.05939)\n\n**ShuffleDet: Real-Time Vehicle Detection Network in On-board Embedded UAV Imagery**\n\n- intro: ECCV 2018, UAVision 2018\n- arxiv: [https://arxiv.org/abs/1811.06318](https://arxiv.org/abs/1811.06318)\n\n# Traffic-Sign Detection\n\n**Traffic-Sign Detection and Classification in the Wild**\n\n- intro: CVPR 2016\n- project page(code+dataset): [http://cg.cs.tsinghua.edu.cn/traffic-sign/](http://cg.cs.tsinghua.edu.cn/traffic-sign/)\n- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhu_Traffic-Sign_Detection_and_CVPR_2016_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhu_Traffic-Sign_Detection_and_CVPR_2016_paper.pdf)\n- code & model: [http://cg.cs.tsinghua.edu.cn/traffic-sign/data_model_code/newdata0411.zip](http://cg.cs.tsinghua.edu.cn/traffic-sign/data_model_code/newdata0411.zip)\n\n**Evaluating State-of-the-art Object Detector on Challenging Traffic Light Data**\n\n- intro: CVPR 2017 workshop\n- paper: [http://openaccess.thecvf.com/content_cvpr_2017_workshops/w9/papers/Jensen_Evaluating_State-Of-The-Art_Object_CVPR_2017_paper.pdf](http://openaccess.thecvf.com/content_cvpr_2017_workshops/w9/papers/Jensen_Evaluating_State-Of-The-Art_Object_CVPR_2017_paper.pdf)\n\n**Detecting Small Signs from Large Images**\n\n- intro: IEEE Conference on Information Reuse and Integration (IRI) 2017 oral\n- arxiv: [https://arxiv.org/abs/1706.08574](https://arxiv.org/abs/1706.08574)\n\n**Localized Traffic Sign Detection with Multi-scale Deconvolution Networks**\n\n[https://arxiv.org/abs/1804.10428](https://arxiv.org/abs/1804.10428)\n\n**Detecting Traffic Lights by Single Shot Detection**\n\n- intro: ITSC 2018\n- arxiv: [https://arxiv.org/abs/1805.02523](https://arxiv.org/abs/1805.02523)\n\n**A Hierarchical Deep Architecture and Mini-Batch Selection Method For Joint Traffic Sign and Light Detection**\n\n- intro: IEEE 15th Conference on Computer and Robot Vision\n- arxiv: [https://arxiv.org/abs/1806.07987](https://arxiv.org/abs/1806.07987)\n- demo: [https://www.youtube.com/watch?v=_YmogPzBXOw&feature=youtu.be](https://www.youtube.com/watch?v=_YmogPzBXOw&feature=youtu.be)\n\n# Skeleton Detection\n\n**Object Skeleton Extraction in Natural Images by Fusing Scale-associated Deep Side Outputs**\n\n![](https://camo.githubusercontent.com/88a65f132aa4ae4b0477e3ad02c13cdc498377d9/687474703a2f2f37786e37777a2e636f6d312e7a302e676c622e636c6f7564646e2e636f6d2f44656570536b656c65746f6e2e706e673f696d61676556696577322f322f772f353030)\n\n- arxiv: [http://arxiv.org/abs/1603.09446](http://arxiv.org/abs/1603.09446)\n- github: [https://github.com/zeakey/DeepSkeleton](https://github.com/zeakey/DeepSkeleton)\n\n**DeepSkeleton: Learning Multi-task Scale-associated Deep Side Outputs for Object Skeleton Extraction in Natural Images**\n\n- arxiv: [http://arxiv.org/abs/1609.03659](http://arxiv.org/abs/1609.03659)\n\n**SRN: Side-output Residual Network for Object Symmetry Detection in the Wild**\n\n- intro: CVPR 2017\n- arxiv: [https://arxiv.org/abs/1703.02243](https://arxiv.org/abs/1703.02243)\n- github: [https://github.com/KevinKecc/SRN](https://github.com/KevinKecc/SRN)\n\n**Hi-Fi: Hierarchical Feature Integration for Skeleton Detection**\n\n[https://arxiv.org/abs/1801.01849](https://arxiv.org/abs/1801.01849)\n\n# Fruit Detection\n\n**Deep Fruit Detection in Orchards**\n\n- arxiv: [https://arxiv.org/abs/1610.03677](https://arxiv.org/abs/1610.03677)\n\n**Image Segmentation for Fruit Detection and Yield Estimation in Apple Orchards**\n\n- intro: The Journal of Field Robotics in May 2016\n- project page: [http://confluence.acfr.usyd.edu.au/display/AGPub/](http://confluence.acfr.usyd.edu.au/display/AGPub/)\n- arxiv: [https://arxiv.org/abs/1610.08120](https://arxiv.org/abs/1610.08120)\n\n## Shadow Detection\n\n**Fast Shadow Detection from a Single Image Using a Patched Convolutional Neural Network**\n\n[https://arxiv.org/abs/1709.09283](https://arxiv.org/abs/1709.09283)\n\n**A+D-Net: Shadow Detection with Adversarial Shadow Attenuation**\n\n[https://arxiv.org/abs/1712.01361](https://arxiv.org/abs/1712.01361)\n\n**Stacked Conditional Generative Adversarial Networks for Jointly Learning Shadow Detection and Shadow Removal**\n\n[https://arxiv.org/abs/1712.02478](https://arxiv.org/abs/1712.02478)\n\n**Direction-aware Spatial Context Features for Shadow Detection**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1712.04142](https://arxiv.org/abs/1712.04142)\n\n**Direction-aware Spatial Context Features for Shadow Detection and Removal**\n\n- intro: The Chinese University of Hong Kong & The Hong Kong Polytechnic University\n- arxiv:  [https://arxiv.org/abs/1805.04635](https://arxiv.org/abs/1805.04635)\n\n# Others Detection\n\n**Deep Deformation Network for Object Landmark Localization**\n\n- arxiv: [http://arxiv.org/abs/1605.01014](http://arxiv.org/abs/1605.01014)\n\n**Fashion Landmark Detection in the Wild**\n\n- intro: ECCV 2016\n- project page: [http://personal.ie.cuhk.edu.hk/~lz013/projects/FashionLandmarks.html](http://personal.ie.cuhk.edu.hk/~lz013/projects/FashionLandmarks.html)\n- arxiv: [http://arxiv.org/abs/1608.03049](http://arxiv.org/abs/1608.03049)\n- github(Caffe): [https://github.com/liuziwei7/fashion-landmarks](https://github.com/liuziwei7/fashion-landmarks)\n\n**Deep Learning for Fast and Accurate Fashion Item Detection**\n\n- intro: Kuznech Inc.\n- intro: MultiBox and Fast R-CNN\n- paper: [https://kddfashion2016.mybluemix.net/kddfashion_finalSubmissions/Deep%20Learning%20for%20Fast%20and%20Accurate%20Fashion%20Item%20Detection.pdf](https://kddfashion2016.mybluemix.net/kddfashion_finalSubmissions/Deep%20Learning%20for%20Fast%20and%20Accurate%20Fashion%20Item%20Detection.pdf)\n\n**OSMDeepOD - OSM and Deep Learning based Object Detection from Aerial Imagery (formerly known as \"OSM-Crosswalk-Detection\")**\n\n![](https://raw.githubusercontent.com/geometalab/OSMDeepOD/master/imgs/process.png)\n\n- github: [https://github.com/geometalab/OSMDeepOD](https://github.com/geometalab/OSMDeepOD)\n\n**Selfie Detection by Synergy-Constraint Based Convolutional Neural Network**\n\n- intro:  IEEE SITIS 2016\n- arxiv: [https://arxiv.org/abs/1611.04357](https://arxiv.org/abs/1611.04357)\n\n**Associative Embedding:End-to-End Learning for Joint Detection and Grouping**\n\n- arxiv: [https://arxiv.org/abs/1611.05424](https://arxiv.org/abs/1611.05424)\n\n**Deep Cuboid Detection: Beyond 2D Bounding Boxes**\n\n- intro: CMU & Magic Leap\n- arxiv: [https://arxiv.org/abs/1611.10010](https://arxiv.org/abs/1611.10010)\n\n**Automatic Model Based Dataset Generation for Fast and Accurate Crop and Weeds Detection**\n\n- arxiv: [https://arxiv.org/abs/1612.03019](https://arxiv.org/abs/1612.03019)\n\n**Deep Learning Logo Detection with Data Expansion by Synthesising Context**\n\n- arxiv: [https://arxiv.org/abs/1612.09322](https://arxiv.org/abs/1612.09322)\n\n**Scalable Deep Learning Logo Detection**\n\n[https://arxiv.org/abs/1803.11417](https://arxiv.org/abs/1803.11417)\n\n**Pixel-wise Ear Detection with Convolutional Encoder-Decoder Networks**\n\n- arxiv: [https://arxiv.org/abs/1702.00307](https://arxiv.org/abs/1702.00307)\n\n**Automatic Handgun Detection Alarm in Videos Using Deep Learning**\n\n- arxiv: [https://arxiv.org/abs/1702.05147](https://arxiv.org/abs/1702.05147)\n- results: [https://github.com/SihamTabik/Pistol-Detection-in-Videos](https://github.com/SihamTabik/Pistol-Detection-in-Videos)\n\n**Objects as context for part detection**\n\n[https://arxiv.org/abs/1703.09529](https://arxiv.org/abs/1703.09529)\n\n**Using Deep Networks for Drone Detection**\n\n- intro: AVSS 2017\n- arxiv: [https://arxiv.org/abs/1706.05726](https://arxiv.org/abs/1706.05726)\n\n**Cut, Paste and Learn: Surprisingly Easy Synthesis for Instance Detection**\n\n- intro: ICCV 2017\n- arxiv: [https://arxiv.org/abs/1708.01642](https://arxiv.org/abs/1708.01642)\n\n**Target Driven Instance Detection**\n\n[https://arxiv.org/abs/1803.04610](https://arxiv.org/abs/1803.04610)\n\n**DeepVoting: An Explainable Framework for Semantic Part Detection under Partial Occlusion**\n\n[https://arxiv.org/abs/1709.04577](https://arxiv.org/abs/1709.04577)\n\n**VPGNet: Vanishing Point Guided Network for Lane and Road Marking Detection and Recognition**\n\n- intro: ICCV 2017\n- arxiv: [https://arxiv.org/abs/1710.06288](https://arxiv.org/abs/1710.06288)\n- github: [https://github.com/SeokjuLee/VPGNet](https://github.com/SeokjuLee/VPGNet)\n\n**Grab, Pay and Eat: Semantic Food Detection for Smart Restaurants**\n\n[https://arxiv.org/abs/1711.05128](https://arxiv.org/abs/1711.05128)\n\n**ReMotENet: Efficient Relevant Motion Event Detection for Large-scale Home Surveillance Videos**\n\n- intro: WACV 2018\n- arxiv: [https://arxiv.org/abs/1801.02031](https://arxiv.org/abs/1801.02031)\n\n**Deep Learning Object Detection Methods for Ecological Camera Trap Data**\n\n- intro: Conference of Computer and Robot Vision. University of Guelph\n- arxiv: [https://arxiv.org/abs/1803.10842](https://arxiv.org/abs/1803.10842)\n\n**EL-GAN: Embedding Loss Driven Generative Adversarial Networks for Lane Detection**\n\n[https://arxiv.org/abs/1806.05525](https://arxiv.org/abs/1806.05525)\n\n**Towards End-to-End Lane Detection: an Instance Segmentation Approach**\n\n- arxiv: [https://arxiv.org/abs/1802.05591](https://arxiv.org/abs/1802.05591)\n- github: [https://github.com/MaybeShewill-CV/lanenet-lane-detection](https://github.com/MaybeShewill-CV/lanenet-lane-detection)\n\n**Densely Supervised Grasp Detector (DSGD)**\n\n[https://arxiv.org/abs/1810.03962](https://arxiv.org/abs/1810.03962)\n\n# Object Proposal\n\n**DeepProposal: Hunting Objects by Cascading Deep Convolutional Layers**\n\n- arxiv: [http://arxiv.org/abs/1510.04445](http://arxiv.org/abs/1510.04445)\n- github: [https://github.com/aghodrati/deepproposal](https://github.com/aghodrati/deepproposal)\n\n**Scale-aware Pixel-wise Object Proposal Networks**\n\n- intro: IEEE Transactions on Image Processing\n- arxiv: [http://arxiv.org/abs/1601.04798](http://arxiv.org/abs/1601.04798)\n\n**Attend Refine Repeat: Active Box Proposal Generation via In-Out Localization**\n\n- intro: BMVC 2016. AttractioNet\n- arxiv: [https://arxiv.org/abs/1606.04446](https://arxiv.org/abs/1606.04446)\n- github: [https://github.com/gidariss/AttractioNet](https://github.com/gidariss/AttractioNet)\n\n**Learning to Segment Object Proposals via Recursive Neural Networks**\n\n- arxiv: [https://arxiv.org/abs/1612.01057](https://arxiv.org/abs/1612.01057)\n\n**Learning Detection with Diverse Proposals**\n\n- intro: CVPR 2017\n- keywords: differentiable Determinantal Point Process (DPP) layer, Learning Detection with Diverse Proposals (LDDP)\n- arxiv: [https://arxiv.org/abs/1704.03533](https://arxiv.org/abs/1704.03533)\n\n**ScaleNet: Guiding Object Proposal Generation in Supermarkets and Beyond**\n\n- keywords: product detection\n- arxiv: [https://arxiv.org/abs/1704.06752](https://arxiv.org/abs/1704.06752)\n\n**Improving Small Object Proposals for Company Logo Detection**\n\n- intro: ICMR 2017\n- arxiv: [https://arxiv.org/abs/1704.08881](https://arxiv.org/abs/1704.08881)\n\n**Open Logo Detection Challenge**\n\n- intro: BMVC 2018\n- keywords: QMUL-OpenLogo\n- project page: [https://qmul-openlogo.github.io/](https://qmul-openlogo.github.io/)\n- arxiv: [https://arxiv.org/abs/1807.01964](https://arxiv.org/abs/1807.01964)\n\n**AttentionMask: Attentive, Efficient Object Proposal Generation Focusing on Small Objects**\n\n- intro: ACCV 2018 oral\n- arxiv: [https://arxiv.org/abs/1811.08728](https://arxiv.org/abs/1811.08728)\n- github: [https://github.com/chwilms/AttentionMask](https://github.com/chwilms/AttentionMask)\n\n# Localization\n\n**Beyond Bounding Boxes: Precise Localization of Objects in Images**\n\n- intro: PhD Thesis\n- homepage: [http://www.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-193.html](http://www.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-193.html)\n- phd-thesis: [http://www.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-193.pdf](http://www.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-193.pdf)\n- github(\"SDS using hypercolumns\"): [https://github.com/bharath272/sds](https://github.com/bharath272/sds)\n\n**Weakly Supervised Object Localization with Multi-fold Multiple Instance Learning**\n\n- arxiv: [http://arxiv.org/abs/1503.00949](http://arxiv.org/abs/1503.00949)\n\n**Weakly Supervised Object Localization Using Size Estimates**\n\n- arxiv: [http://arxiv.org/abs/1608.04314](http://arxiv.org/abs/1608.04314)\n\n**Active Object Localization with Deep Reinforcement Learning**\n\n- intro: ICCV 2015\n- keywords: Markov Decision Process\n- arxiv: [https://arxiv.org/abs/1511.06015](https://arxiv.org/abs/1511.06015)\n\n**Localizing objects using referring expressions**\n\n- intro: ECCV 2016\n- keywords: LSTM, multiple instance learning (MIL)\n- paper: [http://www.umiacs.umd.edu/~varun/files/refexp-ECCV16.pdf](http://www.umiacs.umd.edu/~varun/files/refexp-ECCV16.pdf)\n- github: [https://github.com/varun-nagaraja/referring-expressions](https://github.com/varun-nagaraja/referring-expressions)\n\n**LocNet: Improving Localization Accuracy for Object Detection**\n\n- intro: CVPR 2016 oral\n- arxiv: [http://arxiv.org/abs/1511.07763](http://arxiv.org/abs/1511.07763)\n- github: [https://github.com/gidariss/LocNet](https://github.com/gidariss/LocNet)\n\n**Learning Deep Features for Discriminative Localization**\n\n![](http://cnnlocalization.csail.mit.edu/framework.jpg)\n\n- homepage: [http://cnnlocalization.csail.mit.edu/](http://cnnlocalization.csail.mit.edu/)\n- arxiv: [http://arxiv.org/abs/1512.04150](http://arxiv.org/abs/1512.04150)\n- github(Tensorflow): [https://github.com/jazzsaxmafia/Weakly_detector](https://github.com/jazzsaxmafia/Weakly_detector)\n- github: [https://github.com/metalbubble/CAM](https://github.com/metalbubble/CAM)\n- github: [https://github.com/tdeboissiere/VGG16CAM-keras](https://github.com/tdeboissiere/VGG16CAM-keras)\n\n**ContextLocNet: Context-Aware Deep Network Models for Weakly Supervised Localization**\n\n![](http://www.di.ens.fr/willow/research/contextlocnet/model.png)\n\n- intro: ECCV 2016\n- project page: [http://www.di.ens.fr/willow/research/contextlocnet/](http://www.di.ens.fr/willow/research/contextlocnet/)\n- arxiv: [http://arxiv.org/abs/1609.04331](http://arxiv.org/abs/1609.04331)\n- github: [https://github.com/vadimkantorov/contextlocnet](https://github.com/vadimkantorov/contextlocnet)\n\n**Ensemble of Part Detectors for Simultaneous Classification and Localization**\n\n[https://arxiv.org/abs/1705.10034](https://arxiv.org/abs/1705.10034)\n\n**STNet: Selective Tuning of Convolutional Networks for Object Localization**\n\n[https://arxiv.org/abs/1708.06418](https://arxiv.org/abs/1708.06418)\n\n**Soft Proposal Networks for Weakly Supervised Object Localization**\n\n- intro: ICCV 2017\n- arxiv: [https://arxiv.org/abs/1709.01829](https://arxiv.org/abs/1709.01829)\n\n**Fine-grained Discriminative Localization via Saliency-guided Faster R-CNN**\n\n- intro: ACM MM 2017\n- arxiv: [https://arxiv.org/abs/1709.08295](https://arxiv.org/abs/1709.08295)\n\n# Tutorials / Talks\n\n**Convolutional Feature Maps: Elements of efficient (and accurate) CNN-based object detection**\n\n- slides: [http://research.microsoft.com/en-us/um/people/kahe/iccv15tutorial/iccv2015_tutorial_convolutional_feature_maps_kaiminghe.pdf](http://research.microsoft.com/en-us/um/people/kahe/iccv15tutorial/iccv2015_tutorial_convolutional_feature_maps_kaiminghe.pdf)\n\n**Towards Good Practices for Recognition & Detection**\n\n- intro: Hikvision Research Institute. Supervised Data Augmentation (SDA)\n- slides: [http://image-net.org/challenges/talks/2016/Hikvision_at_ImageNet_2016.pdf](http://image-net.org/challenges/talks/2016/Hikvision_at_ImageNet_2016.pdf)\n\n**Work in progress: Improving object detection and instance segmentation for small objects**\n\n[https://docs.google.com/presentation/d/1OTfGn6mLe1VWE8D0q6Tu_WwFTSoLGd4OF8WCYnOWcVo/edit#slide=id.g37418adc7a_0_229](https://docs.google.com/presentation/d/1OTfGn6mLe1VWE8D0q6Tu_WwFTSoLGd4OF8WCYnOWcVo/edit#slide=id.g37418adc7a_0_229)\n\n**Object Detection with Deep Learning: A Review**\n\n[https://arxiv.org/abs/1807.05511](https://arxiv.org/abs/1807.05511)\n\n# Projects\n\n**Detectron**\n\n- intro: FAIR's research platform for object detection research, implementing popular algorithms like Mask R-CNN and RetinaNet.\n- github: [https://github.com/facebookresearch/Detectron](https://github.com/facebookresearch/Detectron)\n\n**Detectron2**\n\n- intro: Detectron2 is FAIR's next-generation platform for object detection and segmentation.\n- github: [https://github.com/facebookresearch/detectron2](https://github.com/facebookresearch/detectron2)\n\n**MMDetection**\n\n- intro: MMDetection: Open MMLab Detection Toolbox and Benchmark\n- arxiv: [https://arxiv.org/abs/1906.07155](https://arxiv.org/abs/1906.07155)\n- github: [https://github.com/open-mmlab/mmdetection](https://github.com/open-mmlab/mmdetection)\n- docs: [https://mmdetection.readthedocs.io/en/latest/](https://mmdetection.readthedocs.io/en/latest/)\n\n**SimpleDet - A Simple and Versatile Framework for Object Detection and Instance Recognition**\n\n- intro: A Simple and Versatile Framework for Object Detection and Instance Recognition\n- github: [https://github.com/TuSimple/simpledet](https://github.com/TuSimple/simpledet)\n\n**AdelaiDet**\n\n- intro: AdelaiDet is an open source toolbox for multiple instance-level detection and recognition tasks.\n- github: [https://github.com/aim-uofa/AdelaiDet/](https://github.com/aim-uofa/AdelaiDet/)\n\n**TensorBox: a simple framework for training neural networks to detect objects in images**\n\n- intro: \"The basic model implements the simple and robust GoogLeNet-OverFeat algorithm. \nWe additionally provide an implementation of the [ReInspect](https://github.com/Russell91/ReInspect/) algorithm\"\n- github: [https://github.com/Russell91/TensorBox](https://github.com/Russell91/TensorBox)\n\n**NanoDet**\n\n- intro: Super fast and lightweight anchor-free object detection model. Real-time on mobile devices.\n- arxiv: [https://github.com/RangiLyu/nanodet](https://github.com/RangiLyu/nanodet)\n\n**Object detection in torch: Implementation of some object detection frameworks in torch**\n\n- github: [https://github.com/fmassa/object-detection.torch](https://github.com/fmassa/object-detection.torch)\n\n**Using DIGITS to train an Object Detection network**\n\n- github: [https://github.com/NVIDIA/DIGITS/blob/master/examples/object-detection/README.md](https://github.com/NVIDIA/DIGITS/blob/master/examples/object-detection/README.md)\n\n**FCN-MultiBox Detector**\n\n- intro: Full convolution MultiBox Detector (like SSD) implemented in Torch.\n- github: [https://github.com/teaonly/FMD.torch](https://github.com/teaonly/FMD.torch)\n\n**KittiBox: A car detection model implemented in Tensorflow.**\n\n- keywords: MultiNet\n- intro: KittiBox is a collection of scripts to train out model FastBox on the Kitti Object Detection Dataset\n- github: [https://github.com/MarvinTeichmann/KittiBox](https://github.com/MarvinTeichmann/KittiBox)\n\n**Deformable Convolutional Networks + MST + Soft-NMS**\n\n- github: [https://github.com/bharatsingh430/Deformable-ConvNets](https://github.com/bharatsingh430/Deformable-ConvNets)\n\n**How to Build a Real-time Hand-Detector using Neural Networks (SSD) on Tensorflow**\n\n- blog: [https://towardsdatascience.com/how-to-build-a-real-time-hand-detector-using-neural-networks-ssd-on-tensorflow-d6bac0e4b2ce](https://towardsdatascience.com/how-to-build-a-real-time-hand-detector-using-neural-networks-ssd-on-tensorflow-d6bac0e4b2ce)\n- github: [https://github.com//victordibia/handtracking](https://github.com//victordibia/handtracking)\n\n**Metrics for object detection**\n\n- intro: Most popular metrics used to evaluate object detection algorithms\n- github: [https://github.com/rafaelpadilla/Object-Detection-Metrics](https://github.com/rafaelpadilla/Object-Detection-Metrics)\n\n**MobileNetv2-SSDLite**\n\n- intro: Caffe implementation of SSD and SSDLite detection on MobileNetv2, converted from tensorflow.\n- github: [https://github.com/chuanqi305/MobileNetv2-SSDLite](https://github.com/chuanqi305/MobileNetv2-SSDLite)\n\n# Leaderboard\n\n**Detection Results: VOC2012**\n\n- intro: Competition \"comp4\" (train on additional data)\n- homepage: [http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=4](http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=4)\n\n# Tools\n\n**BeaverDam: Video annotation tool for deep learning training labels**\n\n[https://github.com/antingshen/BeaverDam](https://github.com/antingshen/BeaverDam)\n\n# Blogs\n\n**Convolutional Neural Networks for Object Detection**\n\n[http://rnd.azoft.com/convolutional-neural-networks-object-detection/](http://rnd.azoft.com/convolutional-neural-networks-object-detection/)\n\n**Introducing automatic object detection to visual search (Pinterest)**\n\n- keywords: Faster R-CNN\n- blog: [https://engineering.pinterest.com/blog/introducing-automatic-object-detection-visual-search](https://engineering.pinterest.com/blog/introducing-automatic-object-detection-visual-search)\n- demo: [https://engineering.pinterest.com/sites/engineering/files/Visual%20Search%20V1%20-%20Video.mp4](https://engineering.pinterest.com/sites/engineering/files/Visual%20Search%20V1%20-%20Video.mp4)\n- review: [https://news.developer.nvidia.com/pinterest-introduces-the-future-of-visual-search/?mkt_tok=eyJpIjoiTnpaa01UWXpPRE0xTURFMiIsInQiOiJJRjcybjkwTmtmallORUhLOFFFODBDclFqUlB3SWlRVXJXb1MrQ013TDRIMGxLQWlBczFIeWg0TFRUdnN2UHY2ZWFiXC9QQVwvQzBHM3B0UzBZblpOSmUyU1FcLzNPWXI4cml2VERwTTJsOFwvOEk9In0%3D](https://news.developer.nvidia.com/pinterest-introduces-the-future-of-visual-search/?mkt_tok=eyJpIjoiTnpaa01UWXpPRE0xTURFMiIsInQiOiJJRjcybjkwTmtmallORUhLOFFFODBDclFqUlB3SWlRVXJXb1MrQ013TDRIMGxLQWlBczFIeWg0TFRUdnN2UHY2ZWFiXC9QQVwvQzBHM3B0UzBZblpOSmUyU1FcLzNPWXI4cml2VERwTTJsOFwvOEk9In0%3D)\n\n**Deep Learning for Object Detection with DIGITS**\n\n- blog: [https://devblogs.nvidia.com/parallelforall/deep-learning-object-detection-digits/](https://devblogs.nvidia.com/parallelforall/deep-learning-object-detection-digits/)\n\n**Analyzing The Papers Behind Facebook's Computer Vision Approach**\n\n- keywords: DeepMask, SharpMask, MultiPathNet\n- blog: [https://adeshpande3.github.io/adeshpande3.github.io/Analyzing-the-Papers-Behind-Facebook's-Computer-Vision-Approach/](https://adeshpande3.github.io/adeshpande3.github.io/Analyzing-the-Papers-Behind-Facebook's-Computer-Vision-Approach/)\n\n**Easily Create High Quality Object Detectors with Deep Learning**\n\n- intro: dlib v19.2\n- blog: [http://blog.dlib.net/2016/10/easily-create-high-quality-object.html](http://blog.dlib.net/2016/10/easily-create-high-quality-object.html)\n\n**How to Train a Deep-Learned Object Detection Model in the Microsoft Cognitive Toolkit**\n\n- blog: [https://blogs.technet.microsoft.com/machinelearning/2016/10/25/how-to-train-a-deep-learned-object-detection-model-in-cntk/](https://blogs.technet.microsoft.com/machinelearning/2016/10/25/how-to-train-a-deep-learned-object-detection-model-in-cntk/)\n- github: [https://github.com/Microsoft/CNTK/tree/master/Examples/Image/Detection/FastRCNN](https://github.com/Microsoft/CNTK/tree/master/Examples/Image/Detection/FastRCNN)\n\n**Object Detection in Satellite Imagery, a Low Overhead Approach**\n\n- part 1: [https://medium.com/the-downlinq/object-detection-in-satellite-imagery-a-low-overhead-approach-part-i-cbd96154a1b7#.2csh4iwx9](https://medium.com/the-downlinq/object-detection-in-satellite-imagery-a-low-overhead-approach-part-i-cbd96154a1b7#.2csh4iwx9)\n- part 2: [https://medium.com/the-downlinq/object-detection-in-satellite-imagery-a-low-overhead-approach-part-ii-893f40122f92#.f9b7dgf64](https://medium.com/the-downlinq/object-detection-in-satellite-imagery-a-low-overhead-approach-part-ii-893f40122f92#.f9b7dgf64)\n\n**You Only Look TwiceMulti-Scale Object Detection in Satellite Imagery With Convolutional Neural Networks**\n\n- part 1: [https://medium.com/the-downlinq/you-only-look-twice-multi-scale-object-detection-in-satellite-imagery-with-convolutional-neural-38dad1cf7571#.fmmi2o3of](https://medium.com/the-downlinq/you-only-look-twice-multi-scale-object-detection-in-satellite-imagery-with-convolutional-neural-38dad1cf7571#.fmmi2o3of)\n- part 2: [https://medium.com/the-downlinq/you-only-look-twice-multi-scale-object-detection-in-satellite-imagery-with-convolutional-neural-34f72f659588#.nwzarsz1t](https://medium.com/the-downlinq/you-only-look-twice-multi-scale-object-detection-in-satellite-imagery-with-convolutional-neural-34f72f659588#.nwzarsz1t)\n\n**Faster R-CNN Pedestrian and Car Detection**\n\n- blog: [https://bigsnarf.wordpress.com/2016/11/07/faster-r-cnn-pedestrian-and-car-detection/](https://bigsnarf.wordpress.com/2016/11/07/faster-r-cnn-pedestrian-and-car-detection/)\n- ipn: [https://gist.github.com/bigsnarfdude/2f7b2144065f6056892a98495644d3e0#file-demo_faster_rcnn_notebook-ipynb](https://gist.github.com/bigsnarfdude/2f7b2144065f6056892a98495644d3e0#file-demo_faster_rcnn_notebook-ipynb)\n- github: [https://github.com/bigsnarfdude/Faster-RCNN_TF](https://github.com/bigsnarfdude/Faster-RCNN_TF)\n\n**Small U-Net for vehicle detection**\n\n- blog: [https://medium.com/@vivek.yadav/small-u-net-for-vehicle-detection-9eec216f9fd6#.md4u80kad](https://medium.com/@vivek.yadav/small-u-net-for-vehicle-detection-9eec216f9fd6#.md4u80kad)\n\n**Region of interest pooling explained**\n\n- blog: [https://deepsense.io/region-of-interest-pooling-explained/](https://deepsense.io/region-of-interest-pooling-explained/)\n- github: [https://github.com/deepsense-io/roi-pooling](https://github.com/deepsense-io/roi-pooling)\n\n**Supercharge your Computer Vision models with the TensorFlow Object Detection API**\n\n- blog: [https://research.googleblog.com/2017/06/supercharge-your-computer-vision-models.html](https://research.googleblog.com/2017/06/supercharge-your-computer-vision-models.html)\n- github: [https://github.com/tensorflow/models/tree/master/object_detection](https://github.com/tensorflow/models/tree/master/object_detection)\n\n**Understanding SSD MultiBoxReal-Time Object Detection In Deep Learning**\n\n[https://towardsdatascience.com/understanding-ssd-multibox-real-time-object-detection-in-deep-learning-495ef744fab](https://towardsdatascience.com/understanding-ssd-multibox-real-time-object-detection-in-deep-learning-495ef744fab)\n\n**One-shot object detection**\n\n[http://machinethink.net/blog/object-detection/](http://machinethink.net/blog/object-detection/)\n\n**An overview of object detection: one-stage methods**\n\n[https://www.jeremyjordan.me/object-detection-one-stage/](https://www.jeremyjordan.me/object-detection-one-stage/)\n\n**deep learning object detection**\n\n- intro: A paper list of object detection using deep learning.\n- arxiv: [https://github.com/hoya012/deep_learning_object_detection](https://github.com/hoya012/deep_learning_object_detection)\n","excerpt":"Method backbone test size VOC2007 VOC2010 VOC2012 ILSVRC 2013 MSCOCO 2015 Speed OverFeat 24.3% R-CNN AlexNet 58.5% 53.7% 53.3% 31.4% R-CNN ","outboundReferences":[],"inboundReferences":[]},"tagsOutbound":{"nodes":[]}},"pageContext":{"tags":[],"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-detection/","sidebarItems":[{"title":"Categories","items":[{"title":"Commercial","url":"","items":[{"title":"Commercial Structure","url":"/Commercial/Commercial Structure/","items":[]},{"title":"Community of Practice","url":"/Commercial/Community of Practice/","items":[]},{"title":"Domains","url":"/Commercial/Domains/","items":[]},{"title":"Webizen Alliance","url":"/Commercial/Webizen Alliance/","items":[]}]},{"title":"Core Services","url":"","items":[{"title":"Decentralised Ontologies","url":"/Core Services/Decentralised Ontologies/","items":[]},{"title":"Permissive Commons","url":"/Core Services/Permissive Commons/","items":[]},{"title":"Safety Protocols","url":"","items":[{"title":"Safety Protocols","url":"/Core Services/Safety Protocols/Safety Protocols/","items":[]},{"title":"Social Factors","url":"","items":[{"title":"Best Efforts","url":"/Core Services/Safety Protocols/Social Factors/Best Efforts/","items":[]},{"title":"Ending Digital Slavery","url":"/Core Services/Safety Protocols/Social Factors/Ending Digital Slavery/","items":[]},{"title":"Freedom of Thought","url":"/Core Services/Safety Protocols/Social Factors/Freedom of Thought/","items":[]},{"title":"No Golden Handcuffs","url":"/Core Services/Safety Protocols/Social Factors/No Golden Handcuffs/","items":[]},{"title":"Relationships (Social)","url":"/Core Services/Safety Protocols/Social Factors/Relationships (Social)/","items":[]},{"title":"Social Attack Vectors","url":"/Core Services/Safety Protocols/Social Factors/Social Attack Vectors/","items":[]},{"title":"The Webizen Charter","url":"/Core Services/Safety Protocols/Social Factors/The Webizen Charter/","items":[]}]},{"title":"Values Credentials","url":"/Core Services/Safety Protocols/Values Credentials/","items":[]}]},{"title":"Temporal Semantics","url":"/Core Services/Temporal Semantics/","items":[]},{"title":"Verifiable Claims & Credentials","url":"/Core Services/Verifiable Claims & Credentials/","items":[]},{"title":"Webizen Socio-Economics","url":"","items":[{"title":"Biosphere Ontologies","url":"/Core Services/Webizen Socio-Economics/Biosphere Ontologies/","items":[]},{"title":"Centricity","url":"/Core Services/Webizen Socio-Economics/Centricity/","items":[]},{"title":"Currencies","url":"/Core Services/Webizen Socio-Economics/Currencies/","items":[]},{"title":"SocioSphere Ontologies","url":"/Core Services/Webizen Socio-Economics/SocioSphere Ontologies/","items":[]},{"title":"Sustainable Development Goals (ESG)","url":"/Core Services/Webizen Socio-Economics/Sustainable Development Goals (ESG)/","items":[]}]}]},{"title":"Core Technologies","url":"","items":[{"title":"AUTH","url":"","items":[{"title":"Authentication Fabric","url":"/Core Technologies/AUTH/Authentication Fabric/","items":[]}]},{"title":"Webizen App Spec","url":"","items":[{"title":"SemWebSpecs","url":"","items":[{"title":"Core Ontologies","url":"","items":[{"title":"FOAF","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/FOAF/","items":[]},{"title":"General Ontology Information","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/General Ontology Information/","items":[]},{"title":"Human Rights Ontologies","url":"","items":[{"title":"UDHR","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/Human Rights Ontologies/UDHR/","items":[]}]},{"title":"MD-RDF Ontologies","url":"","items":[{"title":"DataTypesOntology (DTO) Core","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/MD-RDF Ontologies/DataTypes Ontology/","items":[]},{"title":"Friend of a Friend (FOAF) Core","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/MD-RDF Ontologies/FOAF/","items":[]}]},{"title":"OWL","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/OWL/","items":[]},{"title":"RDF Schema 1.1","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/RDFS/","items":[]},{"title":"Sitemap","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/Sitemap/","items":[]},{"title":"SKOS","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/SKOS/","items":[]},{"title":"SOIC","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/SOIC/","items":[]}]},{"title":"Semantic Web - An Introduction","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Semantic Web - An Introduction/","items":[]},{"title":"SemWeb-AUTH","url":"","items":[{"title":"WebID-OIDC","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-OIDC/","items":[]},{"title":"WebID-RSA","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-RSA/","items":[]},{"title":"WebID-TLS","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-TLS/","items":[]}]},{"title":"Sparql","url":"","items":[{"title":"Sparql Family","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Sparql/Sparql Family/","items":[]}]},{"title":"W3C Specifications","url":"","items":[{"title":"Linked Data Fragments","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Fragments/","items":[]},{"title":"Linked Data Notifications","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Notifications/","items":[]},{"title":"Linked Data Platform","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Platform/","items":[]},{"title":"Linked Media Fragments","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Media Fragments/","items":[]},{"title":"RDF","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/RDF/","items":[]},{"title":"Web Access Control (WAC)","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Web Access Control (WAC)/","items":[]},{"title":"Web Of Things","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Web Of Things/","items":[]},{"title":"WebID","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/WebID/","items":[]}]}]},{"title":"Webizen App Spec 1.0","url":"/Core Technologies/Webizen App Spec/Webizen App Spec 1.0/","items":[]},{"title":"WebSpec","url":"","items":[{"title":"HTML SPECS","url":"/Core Technologies/Webizen App Spec/WebSpec/HTML SPECS/","items":[]},{"title":"Query Interfaces","url":"","items":[{"title":"GraphQL","url":"/Core Technologies/Webizen App Spec/WebSpec/Query Interfaces/GraphQL/","items":[]}]},{"title":"WebPlatformTools","url":"","items":[{"title":"WebAuthn","url":"/Core Technologies/Webizen App Spec/WebSpec/WebPlatformTools/WebAuthn/","items":[]},{"title":"WebDav","url":"/Core Technologies/Webizen App Spec/WebSpec/WebPlatformTools/WebDav/","items":[]}]}]}]}]},{"title":"Database Requirements","url":"","items":[{"title":"Database Alternatives","url":"","items":[{"title":"Akutan","url":"/Database requirements/Database Alternatives/akutan/","items":[]},{"title":"CayleyGraph","url":"/Database requirements/Database Alternatives/CayleyGraph/","items":[]}]},{"title":"Database Methods","url":"","items":[{"title":"GraphQL","url":"/Database requirements/Database methods/GraphQL/","items":[]},{"title":"Sparql","url":"/Database requirements/Database methods/Sparql/","items":[]}]}]},{"title":"Host Service Requirements","url":"","items":[{"title":"Domain Hosting","url":"/Host Service Requirements/Domain Hosting/","items":[]},{"title":"Email Services","url":"/Host Service Requirements/Email Services/","items":[]},{"title":"LD_PostOffice_SemanticMGR","url":"/Host Service Requirements/LD_PostOffice_SemanticMGR/","items":[]},{"title":"Media Processing","url":"/Host Service Requirements/Media Processing/","items":[{"title":"Ffmpeg","url":"/Host Service Requirements/Media Processing/ffmpeg/","items":[]},{"title":"Opencv","url":"/Host Service Requirements/Media Processing/opencv/","items":[]}]},{"title":"Website Host","url":"/Host Service Requirements/Website Host/","items":[]}]},{"title":"ICT Stack","url":"","items":[{"title":"General References","url":"","items":[{"title":"List of Protocols ISO Model","url":"/ICT Stack/General References/List of Protocols ISO model/","items":[]}]},{"title":"Internet","url":"","items":[{"title":"Internet Stack","url":"/ICT Stack/Internet/Internet Stack/","items":[]}]}]},{"title":"Implementation V1","url":"","items":[{"title":"App-Design-Sdk-V1","url":"","items":[{"title":"Core Apps","url":"","items":[{"title":"Agent Directory","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Agent Directory/","items":[]},{"title":"Credentials & Contracts Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Credentials & Contracts Manager/","items":[]},{"title":"File (Package) Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/File (package) Manager/","items":[]},{"title":"Temporal Apps","url":"","items":[{"title":"Calendar","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Temporal Apps/Calendar/","items":[]},{"title":"Timeline Interface","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Temporal Apps/Timeline Interface/","items":[]}]},{"title":"Webizen Apps (V1)","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Webizen Apps (v1)/","items":[]},{"title":"Webizen Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Webizen Manager/","items":[]}]},{"title":"Data Applications","url":"/Implementation V1/App-design-sdk-v1/Data Applications/","items":[]},{"title":"Design Goals","url":"","items":[{"title":"Design Goals Overview","url":"/Implementation V1/App-design-sdk-v1/Design Goals/Design Goals Overview/","items":[]}]}]},{"title":"Edge","url":"","items":[{"title":"Webizen Local App Functionality","url":"/Implementation V1/edge/Webizen Local App Functionality/","items":[]}]},{"title":"GoLang Libraries","url":"/Implementation V1/GoLang Libraries/","items":[]},{"title":"Implementation V1 Summary","url":"/Implementation V1/Implementation V1 Summary/","items":[]},{"title":"Vps","url":"","items":[{"title":"Server Functionality Summary (VPS)","url":"/Implementation V1/vps/Server Functionality Summary (VPS)/","items":[]}]},{"title":"Webizen 1.0","url":"/Implementation V1/Webizen 1.0/","items":[]},{"title":"Webizen-Connect","url":"","items":[{"title":"Social Media APIs","url":"/Implementation V1/Webizen-Connect/Social Media APIs/","items":[]},{"title":"Webizen-Connect (Summary)","url":"/Implementation V1/Webizen-Connect/Webizen-Connect (summary)/","items":[]}]}]},{"title":"Non-HTTP(s) Protocols","url":"","items":[{"title":"DAT","url":"/Non-HTTP(s) Protocols/DAT/","items":[]},{"title":"GIT","url":"/Non-HTTP(s) Protocols/GIT/","items":[]},{"title":"GUNECO","url":"/Non-HTTP(s) Protocols/GUNECO/","items":[]},{"title":"IPFS","url":"/Non-HTTP(s) Protocols/IPFS/","items":[]},{"title":"Lightning Network","url":"/Non-HTTP(s) Protocols/Lightning Network/","items":[]},{"title":"Non-HTTP(s) Protocols (& DLTs)","url":"/Non-HTTP(s) Protocols/Non-HTTP(s) Protocols (& DLTs)/","items":[]},{"title":"WebRTC","url":"/Non-HTTP(s) Protocols/WebRTC/","items":[]},{"title":"WebSockets","url":"/Non-HTTP(s) Protocols/WebSockets/","items":[]},{"title":"WebTorrent","url":"/Non-HTTP(s) Protocols/WebTorrent/","items":[]}]},{"title":"Old-Work-Archives","url":"","items":[{"title":"2018-Webizen-Net-Au","url":"","items":[{"title":"_Link_library_links","url":"","items":[{"title":"Link Library","url":"/old-work-archives/2018-webizen-net-au/_link_library_links/2018-09-23-wp-linked-data/","items":[]}]},{"title":"_Posts","url":"","items":[{"title":"About W3C","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-27-about-w3c/","items":[]},{"title":"Advanced Functions &#8211; Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-16-advanced-functions-facebook-pages/","items":[]},{"title":"Advanced Search &#038; Discovery Tips","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-advanced-search-discovery-tips/","items":[]},{"title":"An introduction to Virtual Machines.","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-an-introduction-to-virtual-machines/","items":[]},{"title":"Basic Media Analysis &#8211; Part 1 (Audio)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-30-media-analysis-part-1-audio/","items":[]},{"title":"Basic Media Analysis &#8211; Part 2 (visual)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-31-media-analysis-part-2-visual/","items":[]},{"title":"Basic Media Analysis &#8211; Part 3 (Text &#038; Metadata)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-01-01-basic-media-analysis-part-3-text-metadata/","items":[]},{"title":"Building an Economy based upon Knowledge Equity.","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-25-building-an-economy-based-upon-knowledge-equity/","items":[]},{"title":"Choice of Law","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-26-choice-of-law/","items":[]},{"title":"Contemplation of the ITU Dubai Meeting and the Future of the Internet","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-19-contemplation-of-the-itu-dubai-meeting-and-the-future-of-the-internet/","items":[]},{"title":"Creating a Presence &#8211; Online","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-creating-a-presence-online/","items":[]},{"title":"Credentials and Payments by Manu Sporny","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-credentials-and-payments-by-manu-sporny/","items":[]},{"title":"Data Recovery &#038; Collection: Mobile Devices","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-28-mobile-devices-data-recovery-collection/","items":[]},{"title":"Data Recovery: Laptop &#038; Computers","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-28-data-recovery-laptop-computers/","items":[]},{"title":"Decentralized Web Conference 2016","url":"/old-work-archives/2018-webizen-net-au/_posts/2016-06-09-decentralized-web-2016/","items":[]},{"title":"Decentralized Web Summit 2018","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-decentralized-web-summit-2018/","items":[]},{"title":"Does Anonymity exist?","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-does-anonymity-exist/","items":[]},{"title":"Downloading My Data from Social Networks","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-downloading-my-data-from-social-networks/","items":[]},{"title":"Events","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-events/","items":[]},{"title":"Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-16-facebook-pages/","items":[]},{"title":"Google Tracking Data (geolocation)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-google-tracking/","items":[]},{"title":"Human Consciousness","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-human-consciousness/","items":[]},{"title":"Image Recgonition Video Playlist","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-image-recgonition-video-playlist/","items":[]},{"title":"Inferencing (introduction)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-inferencing-introduction/","items":[]},{"title":"Introduction to AI","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-introduction-to-ai/","items":[]},{"title":"Introduction to Linked Data","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-introduction-to-linked-data/","items":[]},{"title":"Introduction to Maltego","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-introduction-to-maltego/","items":[]},{"title":"Introduction to Ontologies","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-ontologies-intro/","items":[]},{"title":"Introduction to Semantic Web","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-introduction-to-semantic-web/","items":[]},{"title":"Knowledge Capital","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-10-17-knowledge-capital/","items":[]},{"title":"Logo&#8217;s, Style Guides and Artwork","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-logos-style-guides-and-artwork/","items":[]},{"title":"MindMapping &#8211; Setting-up a business &#8211; Identity","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-mindmapping-setting-up-a-business-identity/","items":[]},{"title":"Openlink Virtuoso","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-openlink-virtuoso/","items":[]},{"title":"OpenRefine","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-74-2/","items":[]},{"title":"Projects, Customers and Invoicing &#8211; Web-Services for Startups","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-projects-customers-and-invoicing-web-services-for-startups/","items":[]},{"title":"RWW &#038; some Solid history","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-rww-some-solid-history/","items":[]},{"title":"Semantic Web (An Intro)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-semantic-web-an-intro/","items":[]},{"title":"Setting-up Twitter","url":"/old-work-archives/2018-webizen-net-au/_posts/2013-06-07-setting-up-twitter/","items":[]},{"title":"Social Encryption: An Introduction","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-25-social-encryption-an-introduction/","items":[]},{"title":"Stock Content","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-stock-content/","items":[]},{"title":"The WayBack Machine","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-27-the-wayback-machine/","items":[]},{"title":"Tim Berners Lee &#8211; Turing Lecture","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-05-29-tim-berners-lee-turing-lecture/","items":[]},{"title":"Tools of Trade","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-tools-of-trade/","items":[]},{"title":"Trust Factory 2017","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-trust-factory-2017/","items":[]},{"title":"Verifiable Claims (An Introduction)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-vc-intro/","items":[]},{"title":"Web of Things &#8211; an Introduction","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-web-of-things-an-introduction/","items":[]},{"title":"Web-Persistence","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-web-persistence/","items":[]},{"title":"Web-Services &#8211; Marketing Tools","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-web-services-marketing-tools/","items":[]},{"title":"Website Templates","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-templates/","items":[]},{"title":"What is Linked Data?","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-what-is-linked-data/","items":[]},{"title":"What is Open Source Intelligence?","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-what-is-osint/","items":[]},{"title":"WiX","url":"/old-work-archives/2018-webizen-net-au/_posts/2013-01-01-wix/","items":[]}]},{"title":"about","url":"/old-work-archives/2018-webizen-net-au/about/","items":[{"title":"About The Author","url":"/old-work-archives/2018-webizen-net-au/about/about-the-author/","items":[]},{"title":"Applied Theory: Applications for a Human Centric Web","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/","items":[{"title":"Digital Receipts","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/digital-receipts/","items":[]},{"title":"Fake News: Considerations  Principles  The Institution of Socio &#8211; Economic Values","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations/","items":[]},{"title":"Fake-News-Considerations-%E2%86%92-Principles-%E2%86%92-the-Institution-of-Socio-Economic-Values","url":"","items":[{"title":"Solutions to FakeNews: Linked-Data, Ontologies and Verifiable Claims","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations-%e2%86%92-principles-%e2%86%92-the-institution-of-socio-economic-values/solutions-to-fakenews-linked-data-ontologies-and-verifiable-claims/","items":[]}]},{"title":"Healthy Living Economy","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/healthy-living-economy/","items":[]},{"title":"HyperMedia Solutions &#8211; Adapting HbbTV V2","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/","items":[{"title":"HYPERMEDIA PACKAGES","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/hypermedia-packages/","items":[]},{"title":"USER STORIES: INTERACTIVE VIEWING EXPERIENCE","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/user-stories-interactive-viewing-experience/","items":[]}]},{"title":"Measurements App","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/measurements-app/","items":[]},{"title":"Re:Animation","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/reanimation/","items":[]}]},{"title":"Executive Summary","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/","items":[{"title":"Assisting those who Enforce the Law","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/assisting-those-who-enforce-the-law/","items":[]},{"title":"Consumer Protections","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/consumer-protections/","items":[]},{"title":"Knowledge Banking: Legal Structures","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-banking-legal-structures/","items":[]},{"title":"Knowledge Economics &#8211; Services","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-economics-services/","items":[]},{"title":"Preserving The Freedom to Think","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/preserving-the-freedom-to-think/","items":[]}]},{"title":"History","url":"/old-work-archives/2018-webizen-net-au/about/history/","items":[{"title":"History: Global Governance and ICT.","url":"/old-work-archives/2018-webizen-net-au/about/history/history-global-governance-ict-1/","items":[]}]},{"title":"Knowledge Banking: A Technical Architecture Summary","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/","items":[{"title":"An introduction to Credentials.","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/","items":[{"title":"credentials and custodianship","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/credentials-and-custodianship/","items":[]},{"title":"DIDs and MultiSig","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/dids-and-multisig/","items":[]}]},{"title":"Personal Augmentation of AI","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/personal-augmentation-of-ai/","items":[]},{"title":"Semantic Inferencing","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/semantic-inferencing/","items":[]},{"title":"Web of Things (IoT+LD)","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/web-of-things-iotld/","items":[]}]},{"title":"References","url":"/old-work-archives/2018-webizen-net-au/about/references/","items":[{"title":"Making the distinction between privacy and dignity.","url":"/old-work-archives/2018-webizen-net-au/about/references/privacy-vs-dignity/","items":[]},{"title":"Roles &#8211; Entity Analysis","url":"/old-work-archives/2018-webizen-net-au/about/references/roles-entity-analysis/","items":[]},{"title":"Social Informatics Design Considerations","url":"/old-work-archives/2018-webizen-net-au/about/references/social-informatics-design-concept-and-principles/","items":[]},{"title":"Socio-economic relations | A conceptual model","url":"/old-work-archives/2018-webizen-net-au/about/references/socioeconomic-relations-p1/","items":[]},{"title":"The need for decentralised Open (Linked) Data","url":"/old-work-archives/2018-webizen-net-au/about/references/the-need-for-decentralised-open-linked-data/","items":[]}]},{"title":"The design of new medium","url":"/old-work-archives/2018-webizen-net-au/about/the-design-of-new-medium/","items":[]},{"title":"The need to modernise socioeconomic infrastructure","url":"/old-work-archives/2018-webizen-net-au/about/the-modernisation-of-socioeconomics/","items":[]},{"title":"The Vision","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/","items":[{"title":"Domesticating Pervasive Surveillance","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/a-technical-vision/","items":[]}]}]},{"title":"An Overview","url":"/old-work-archives/2018-webizen-net-au/the-human-centric-infosphere/","items":[]},{"title":"Embed Link","url":"/old-work-archives/2018-webizen-net-au/embed-link/","items":[]},{"title":"Posts","url":"/old-work-archives/2018-webizen-net-au/posts/","items":[]},{"title":"Privacy Policy","url":"/old-work-archives/2018-webizen-net-au/privacy-policy/","items":[]},{"title":"Resource Library","url":"/old-work-archives/2018-webizen-net-au/resource-library/","items":[{"title":"Handong1587","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/","items":[{"title":"_Posts","url":"","items":[{"title":"Computer_science","url":"","items":[{"title":"Algorithm and Data Structure Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-algo-resourses/","items":[]},{"title":"Artificial Intelligence Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-ai-resources/","items":[]},{"title":"Big Data Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-09-22-big-data-resources/","items":[]},{"title":"Computer Science Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-cs-resources/","items":[]},{"title":"Data Mining Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-data-mining-resources/","items":[]},{"title":"Data Science Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-data-science-resources/","items":[]},{"title":"Database Systems Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-database-resources/","items":[]},{"title":"Discrete Optimization Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-discrete-optimization/","items":[]},{"title":"Distribued System Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-12-12-ditributed-system-resources/","items":[]},{"title":"Funny Stuffs Of Computer Science","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-11-18-funny-stuffs-of-cs/","items":[]},{"title":"Robotics","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-09-26-robotics-resources/","items":[]},{"title":"Writting CS Papers","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-11-30-writing-papers/","items":[]}]},{"title":"Computer_vision","url":"","items":[{"title":"Computer Vision Datasets","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-24-datasets/","items":[]},{"title":"Computer Vision Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-12-cv-resources/","items":[]},{"title":"Features","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-10-09-features/","items":[]},{"title":"Recognition, Detection, Segmentation and Tracking","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-10-09-recognition-detection-segmentation-tracking/","items":[]},{"title":"Use FFmpeg to Capture I Frames of Video","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2016-03-03-ffmpeg-i-frame/","items":[]},{"title":"Working on OpenCV","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-12-25-working-on-opencv/","items":[]}]},{"title":"Deep_learning","url":"","items":[{"title":"3D","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2021-07-28-3d/","items":[]},{"title":"Acceleration and Model Compression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-cnn-compression-acceleration/","items":[]},{"title":"Acceleration and Model Compression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-knowledge-distillation/","items":[]},{"title":"Adversarial Attacks and Defences","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-adversarial-attacks-and-defences/","items":[]},{"title":"Audio / Image / Video Generation","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-audio-image-video-generation/","items":[]},{"title":"BEV","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2022-06-27-bev/","items":[]},{"title":"Classification / Recognition","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recognition/","items":[]},{"title":"Deep Learning and Autonomous Driving","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-autonomous-driving/","items":[]},{"title":"Deep Learning Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-pose-estimation/","items":[]},{"title":"Deep Learning Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-applications/","items":[]},{"title":"Deep learning Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-courses/","items":[]},{"title":"Deep Learning Frameworks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-frameworks/","items":[]},{"title":"Deep Learning Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-resources/","items":[]},{"title":"Deep Learning Software and Hardware","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-software-hardware/","items":[]},{"title":"Deep Learning Tricks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tricks/","items":[]},{"title":"Deep Learning Tutorials","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tutorials/","items":[]},{"title":"Deep Learning with Machine Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-with-ml/","items":[]},{"title":"Face Recognition","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-face-recognition/","items":[]},{"title":"Fun With Deep Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-fun-with-deep-learning/","items":[]},{"title":"Generative Adversarial Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gan/","items":[]},{"title":"Graph Convolutional Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gcn/","items":[]},{"title":"Image / Video Captioning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-captioning/","items":[]},{"title":"Image Retrieval","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-retrieval/","items":[]},{"title":"Keep Up With New Trends","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2018-09-03-keep-up-with-new-trends/","items":[]},{"title":"LiDAR 3D Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-lidar-3d-detection/","items":[]},{"title":"Natural Language Processing","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nlp/","items":[]},{"title":"Neural Architecture Search","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nas/","items":[]},{"title":"Object Counting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-counting/","items":[]},{"title":"Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-detection/","items":[]},{"title":"OCR","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-ocr/","items":[]},{"title":"Optical Flow","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-optical-flow/","items":[]},{"title":"Re-ID","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-re-id/","items":[]},{"title":"Recommendation System","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recommendation-system/","items":[]},{"title":"Reinforcement Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rl/","items":[]},{"title":"RNN and LSTM","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rnn-and-lstm/","items":[]},{"title":"Segmentation","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-segmentation/","items":[]},{"title":"Style Transfer","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-style-transfer/","items":[]},{"title":"Super-Resolution","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-super-resolution/","items":[]},{"title":"Tracking","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-tracking/","items":[]},{"title":"Training Deep Neural Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-training-dnn/","items":[]},{"title":"Transfer Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-transfer-learning/","items":[]},{"title":"Unsupervised Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-unsupervised-learning/","items":[]},{"title":"Video Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-video-applications/","items":[]},{"title":"Visual Question Answering","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-vqa/","items":[]},{"title":"Visualizing and Interpreting Convolutional Neural Network","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-visulizing-interpreting-cnn/","items":[]}]},{"title":"Leisure","url":"","items":[{"title":"All About Enya","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-all-about-enya/","items":[]},{"title":"Coldplay","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-coldplay/","items":[]},{"title":"Coldplay","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-nightwish/","items":[]},{"title":"Games","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-13-games/","items":[]},{"title":"Green Day","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-greenday/","items":[]},{"title":"Muse! Muse!","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-muse-muse/","items":[]},{"title":"Oasis","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-oasis/","items":[]},{"title":"Paintings By J.M.","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2016-03-08-paintings-by-jm/","items":[]},{"title":"Papers, Blogs and Websites","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-09-27-papers-blogs-and-websites/","items":[]},{"title":"Welcome To The Black Parade","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-welcome-to-the-black-parade/","items":[]}]},{"title":"Machine_learning","url":"","items":[{"title":"Bayesian Methods","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-bayesian-methods/","items":[]},{"title":"Clustering Algorithms Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-clustering/","items":[]},{"title":"Competitions","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-competitions/","items":[]},{"title":"Dimensionality Reduction Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-dimensionality-reduction/","items":[]},{"title":"Fun With Machine Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-fun-with-ml/","items":[]},{"title":"Graphical Models Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-graphical-models/","items":[]},{"title":"Machine Learning Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-ml-courses/","items":[]},{"title":"Machine Learning Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-ml-resources/","items":[]},{"title":"Natural Language Processing","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-nlp/","items":[]},{"title":"Neural Network","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-neural-network/","items":[]},{"title":"Random Field","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-random-field/","items":[]},{"title":"Random Forests","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-random-forests/","items":[]},{"title":"Regression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-regression/","items":[]},{"title":"Support Vector Machine","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-svm/","items":[]},{"title":"Topic Model","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-topic-model/","items":[]}]},{"title":"Mathematics","url":"","items":[{"title":"Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/mathematics/2016-02-24-resources/","items":[]}]},{"title":"Programming_study","url":"","items":[{"title":"Add Lunr Search Plugin For Blog","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-31-add-lunr-search-plugin-for-blog/","items":[]},{"title":"Android Development Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-05-23-android-resources/","items":[]},{"title":"C++ Programming Solutions","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-09-07-cpp-programming-solutions/","items":[]},{"title":"Commands To Suppress Some Building Errors With Visual Studio","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-24-cmds-to-suppress-some-vs-building-Errors/","items":[]},{"title":"Embedding Python In C/C++","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-10-embedding-python-in-cpp/","items":[]},{"title":"Enable Large Addresses On VS2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-12-14-enable-large-addresses/","items":[]},{"title":"Fix min/max Error In VS2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-02-17-min-max-error-in-vs2015/","items":[]},{"title":"Gflags Build Problems on Windows X86 and Visual Studio 2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-23-gflags-build-problems-winx86-vs2015/","items":[]},{"title":"Glog Build Problems on Windows X86 and Visual Studio 2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-23-glog-build-problems-winx86/","items":[]},{"title":"Horrible Wired Errors Come From Simple Stupid Mistake","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-16-horrible-wired-errors-come-from-simple-stupid-mistake/","items":[]},{"title":"Install Jekyll To Fix Some Local Github-pages Defects","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-11-21-install-jekyll/","items":[]},{"title":"Install Therubyracer Failure","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-03-install-therubyracer/","items":[]},{"title":"Notes On Valgrind and Others","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-05-30-notes-on-valgrind/","items":[]},{"title":"PHP Hello World","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-04-php-hello-world/","items":[]},{"title":"Programming Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-07-01-programming-resources/","items":[]},{"title":"PyInstsaller and Others","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-12-24-pyinstaller-and-others/","items":[]},{"title":"Web Development Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-06-21-web-dev-resources/","items":[]},{"title":"Working on Visual Studio","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-04-03-working-on-vs/","items":[]}]},{"title":"Reading_and_thoughts","url":"","items":[{"title":"Book Reading List","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2015-12-04-book-reading-list/","items":[]},{"title":"Funny Papers","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2015-12-04-funny-papers/","items":[]},{"title":"Reading Materials","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2016-01-18-reading-materials/","items":[]}]},{"title":"Study","url":"","items":[{"title":"Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2017-11-28-courses/","items":[]},{"title":"Essay Writting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2016-01-11-essay-writting/","items":[]},{"title":"Job Hunting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2016-06-02-job-hunting/","items":[]},{"title":"Study Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2018-04-18-resources/","items":[]}]},{"title":"Working_on_linux","url":"","items":[{"title":"Create Multiple Forks of a GitHub Repo","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-12-18-create-multi-forks/","items":[]},{"title":"Linux Git Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-08-02-linux-git/","items":[]},{"title":"Linux Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-07-24-linux-resources/","items":[]},{"title":"Linux SVN Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-08-03-linux-svn/","items":[]},{"title":"Setup vsftpd on Ubuntu 14.10","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2016-07-27-setup-vsftpd/","items":[]},{"title":"Useful Linux Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-07-25-useful-linux-commands/","items":[]},{"title":"vsftpd Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2016-07-28-vsftpd-cmd/","items":[]}]},{"title":"Working_on_mac","url":"","items":[{"title":"Mac Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_mac/2015-07-25-mac-resources/","items":[]}]},{"title":"Working_on_windows","url":"","items":[{"title":"FFmpeg Collection of Utility Methods","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2016-06-05-ffmpeg-utilities/","items":[]},{"title":"Windows Commands and Utilities","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2015-10-27-windows-cmds-utils/","items":[]},{"title":"Windows Dev Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2015-10-27-resources/","items":[]}]}]},{"title":"Drafts","url":"","items":[{"title":"2016-12-30-Setup-Opengrok","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-12-30-setup-opengrok/","items":[]},{"title":"2017-01-20-Packing-C++-Project-to-Single-Executable","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2017-01-20-packing-c++-project-to-single-executable/","items":[]},{"title":"Notes On Caffe Development","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-10-notes-on-caffe-dev/","items":[]},{"title":"Notes On Deep Learning Training","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-12-notes-on-dl-training/","items":[]},{"title":"Notes On Discrete Optimization","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-13-notes-on-discrete-optimization/","items":[]},{"title":"Notes On Gecode","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-13-notes-on-gecode/","items":[]},{"title":"Notes On Inside-Outside Net","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-28-notes-on-ion/","items":[]},{"title":"Notes On K-Means","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-06-notes-on-kmeans/","items":[]},{"title":"Notes On L-BFGS","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-07-notes-on-l-bfgs/","items":[]},{"title":"Notes On Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-04-notes-on-object-detection/","items":[]},{"title":"Notes On Perceptrons","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-10-07-notes-on-perceptrons/","items":[]},{"title":"Notes On Quantized Convolutional Neural Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-07-notes-on-quantized-cnn/","items":[]},{"title":"Notes On Stanford CS2321n","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-02-21-notes-on-cs231n/","items":[]},{"title":"Notes on Suffix Array and Manacher Algorithm","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-08-27-notes-on-suffix-array-and-manacher-algorithm/","items":[]},{"title":"Notes On Tensorflow Development","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2017-04-13-notes-on-tensorflow-dev/","items":[]},{"title":"Notes On YOLO","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-14-notes-on-yolo/","items":[]},{"title":"PASCAL VOC (20) / COCO (80) / ImageNet (200) Detection Categories","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-12-23-imagenet-det-cat/","items":[]},{"title":"Softmax Vs Logistic Vs Sigmoid","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-10-softmax-logistic-sigmoid/","items":[]},{"title":"Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognititon","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-08-31-model-ensemble-of-deteciton/","items":[]}]}]}]}]}]},{"title":"Webizen 2.0","url":"","items":[{"title":"AI Capabilities","url":"","items":[{"title":"AI Capabilities Objectives","url":"/Webizen 2.0/AI Capabilities/AI Capabilities Objectives/","items":[]},{"title":"Audio & Video Analysis","url":"/Webizen 2.0/AI Capabilities/Audio & Video Analysis/","items":[]},{"title":"Image Analysis","url":"/Webizen 2.0/AI Capabilities/Image Analysis/","items":[]},{"title":"Text Analysis","url":"/Webizen 2.0/AI Capabilities/Text Analysis/","items":[]}]},{"title":"LOD-a-lot","url":"/Webizen 2.0/AI Related Links & Notes/","items":[]},{"title":"Mobile Apps","url":"","items":[{"title":"Android","url":"/Webizen 2.0/Mobile Apps/Android/","items":[]},{"title":"General Mobile Architecture","url":"/Webizen 2.0/Mobile Apps/General Mobile Architecture/","items":[]},{"title":"iOS","url":"/Webizen 2.0/Mobile Apps/iOS/","items":[]}]},{"title":"Web Of Things (IoT)","url":"","items":[{"title":"Web Of Things (IoT)","url":"/Webizen 2.0/Web Of Things (IoT)/Web Of Things (IoT)/","items":[]}]},{"title":"Webizen 2.0","url":"/Webizen 2.0/Webizen 2.0/","items":[]},{"title":"Webizen AI OS Platform","url":"/Webizen 2.0/Webizen AI OS Platform/","items":[]},{"title":"Webizen Pro Summary","url":"/Webizen 2.0/Webizen Pro Summary/","items":[]}]},{"title":"Webizen V1 Project Documentation","url":"/","items":[]}]}],"tagsGroups":[],"latestPosts":[{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations/","title":"Fake News: Considerations  Principles  The Institution of Socio &#8211; Economic Values","lastUpdatedAt":"2022-12-28T19:29:53.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/","title":"Handong1587","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-08-27-notes-on-suffix-array-and-manacher-algorithm/","title":"Notes on Suffix Array and Manacher Algorithm","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-10-07-notes-on-perceptrons/","title":"Notes On Perceptrons","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-04-notes-on-object-detection/","title":"Notes On Object Detection","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-10-notes-on-caffe-dev/","title":"Notes On Caffe Development","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-07-notes-on-l-bfgs/","title":"Notes On L-BFGS","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-10-softmax-logistic-sigmoid/","title":"Softmax Vs Logistic Vs Sigmoid","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-12-notes-on-dl-training/","title":"Notes On Deep Learning Training","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-14-notes-on-yolo/","title":"Notes On YOLO","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}