{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recognition/",
    "result": {"data":{"mdx":{"id":"4014d114-99ed-578d-8340-031d3c75b470","tableOfContents":{"items":[{"url":"#papers","title":"Papers"},{"url":"#massive-classification","title":"Massive Classification"},{"url":"#multi-object-recognition","title":"Multi-object Recognition"},{"url":"#multi-label-classification","title":"Multi-Label Classification"},{"url":"#person-recognition","title":"Person Recognition","items":[{"url":"#coco_v1","title":"COCO_v1"},{"url":"#coco_v2","title":"COCO_v2"}]},{"url":"#fine-grained-recognition","title":"Fine-grained Recognition"},{"url":"#food-recognition","title":"Food Recognition"},{"url":"#attribute-recognition","title":"Attribute Recognition"},{"url":"#pedestrian-attribute-recognition--person-attribute-recognition","title":"Pedestrian Attribute Recognition / Person Attribute Recognition"},{"url":"#clothes-recognition","title":"Clothes Recognition"},{"url":"#star-galaxy-classification","title":"Star-galaxy Classification"},{"url":"#logo-recognition","title":"Logo Recognition"},{"url":"#plant-classification","title":"Plant Classification"},{"url":"#scene-recognition--scene-classification","title":"Scene Recognition / Scene Classification","items":[{"url":"#leaderboard","title":"Leaderboard"}]},{"url":"#blogs","title":"Blogs"}]},"fields":{"title":"Classification / Recognition","slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recognition/","url":"https://devdocs.webizen.org/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recognition/","editUrl":"https://github.com/webizenai/devdocs/tree/main/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recognition.md","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022","gitCreatedAt":"2022-12-28T19:22:29.000Z","shouldShowTitle":true},"frontmatter":{"title":"Classification / Recognition","description":null,"imageAlt":null,"tags":[],"date":"2015-10-09T00:00:00.000Z","dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"layout\": \"post\",\n  \"category\": \"deep_learning\",\n  \"title\": \"Classification / Recognition\",\n  \"date\": \"2015-10-09T00:00:00.000Z\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"papers\"\n  }, \"Papers\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"auothor: Jeff Donahue, Yangqing Jia, Oriol Vinyals, Judy Hoffman, Ning Zhang, Eric Tzeng, Trevor Darrell\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1310.1531\"\n  }, \"http://arxiv.org/abs/1310.1531\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CNN Features off-the-shelf: an Astounding Baseline for Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2014\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1403.6382\"\n  }, \"http://arxiv.org/abs/1403.6382\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"HD-CNN: Hierarchical Deep Convolutional Neural Network for Image Classification\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"HD-CNN: Hierarchical Deep Convolutional Neural Network for Large Scale Visual Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: introduce hierarchical deep CNNs (HD-CNNs) by embedding deep CNNs into a category hierarchy\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://sites.google.com/site/homepagezhichengyan/home/hdcnn\"\n  }, \"https://sites.google.com/site/homepagezhichengyan/home/hdcnn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1410.0736\"\n  }, \"https://arxiv.org/abs/1410.0736\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://sites.google.com/site/homepagezhichengyan/home/hdcnn/code\"\n  }, \"https://sites.google.com/site/homepagezhichengyan/home/hdcnn/code\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/stephenyan1231/caffe-public/tree/hdcnn\"\n  }, \"https://github.com/stephenyan1231/caffe-public/tree/hdcnn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ImageNet top-5 error: 4.94%\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1502.01852\"\n  }, \"http://arxiv.org/abs/1502.01852\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://blog.csdn.net/happynear/article/details/45440811\"\n  }, \"http://blog.csdn.net/happynear/article/details/45440811\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Automatic Instrument Recognition in Polyphonic Music Using Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1511.05520\"\n  }, \"http://arxiv.org/abs/1511.05520\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/glennq/instrument-recognition\"\n  }, \"https://github.com/glennq/instrument-recognition\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Convolutional Networks on the Pitch Spiral for Musical Instrument Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lostanlen/ismir2016/blob/master/paper/lostanlen_ismir2016.pdf\"\n  }, \"https://github.com/lostanlen/ismir2016/blob/master/paper/lostanlen_ismir2016.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lostanlen/ismir2016\"\n  }, \"https://github.com/lostanlen/ismir2016\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Humans and deep networks largely agree on which kinds of variation make object recognition harder\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1604.06486\"\n  }, \"http://arxiv.org/abs/1604.06486\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"review: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.technologyreview.com/s/601387/why-machine-vision-is-flawed-in-the-same-way-as-human-vision/\"\n  }, \"https://www.technologyreview.com/s/601387/why-machine-vision-is-flawed-in-the-same-way-as-human-vision/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FusionNet: 3D Object Classification Using Multiple Data Representations\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1607.05695\"\n  }, \"https://arxiv.org/abs/1607.05695\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"From image recognition to object recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.oreilly.com/ideas/from-image-recognition-to-object-recognition\"\n  }, \"https://www.oreilly.com/ideas/from-image-recognition-to-object-recognition\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep FisherNet for Object Classification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.00182\"\n  }, \"http://arxiv.org/abs/1608.00182\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Factorized Bilinear Models for Image Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: TuSimple\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.05709\"\n  }, \"https://arxiv.org/abs/1611.05709\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(MXNet): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lyttonhao/Factorized-Bilinear-Network\"\n  }, \"https://github.com/lyttonhao/Factorized-Bilinear-Network\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hyperspectral CNN Classification with Limited Training Samples\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.09007\"\n  }, \"https://arxiv.org/abs/1611.09007\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The More You Know: Using Knowledge Graphs for Image Classification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CMU. GSNN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.04844\"\n  }, \"https://arxiv.org/abs/1612.04844\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MaxMin Convolutional Neural Networks for Image Classification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://webia.lip6.fr/~thomen/papers/Blot_ICIP_2016.pdf\"\n  }, \"http://webia.lip6.fr/~thomen/papers/Blot_ICIP_2016.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/karandesai-96/maxmin-cnn\"\n  }, \"https://github.com/karandesai-96/maxmin-cnn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cost-Effective Active Learning for Deep Image Classification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: TCSVT 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Sun Yat-sen University & Guangzhou University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.03551\"\n  }, \"https://arxiv.org/abs/1701.03551\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Collaborative Learning for Visual Recognition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.arxiv.org/abs/1703.01229\"\n  }, \"https://www.arxiv.org/abs/1703.01229\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Convolutional Low-Resolution Fine-Grained Classification\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1703.05393\"\n  }, \"https://arxiv.org/abs/1703.05393\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Scale Dense Networks for Resource Efficient Image Classification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Cornell University & Fudan University & Tsinghua University & Facebook AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.09844\"\n  }, \"https://arxiv.org/abs/1703.09844\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com//gaohuang/MSDNet\"\n  }, \"https://github.com//gaohuang/MSDNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Mixture of Diverse Experts for Large-Scale Visual Recognition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1706.07901\"\n  }, \"https://arxiv.org/abs/1706.07901\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sunrise or Sunset: Selective Comparison Learning for Subtle Attribute Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.06335\"\n  }, \"https://arxiv.org/abs/1707.06335\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Why Do Deep Neural Networks Still Not Recognize These Images?: A Qualitative Analysis on Failure Cases of ImageNet Classification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Poster presented at CVPR 2017 Scene Understanding Workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1709.03439\"\n  }, \"https://arxiv.org/abs/1709.03439\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"B-CNN: Branch Convolutional Neural Network for Hierarchical Classification\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.09890\"\n  }, \"https://arxiv.org/abs/1709.09890\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Transferable Architectures for Scalable Image Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Brain\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Neural Architecture Search\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.07012\"\n  }, \"https://arxiv.org/abs/1707.07012\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AOGNets: Deep AND-OR Grammar Networks for Visual Recognition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.05847\"\n  }, \"https://arxiv.org/abs/1711.05847\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Knowledge Concentration: Learning 100K Object Classifiers in a Single CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Southern California & Google Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.07607\"\n  }, \"https://arxiv.org/abs/1711.07607\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Between-class Learning for Image Classification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The University of Tokyo & RIKEN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.10284\"\n  }, \"https://arxiv.org/abs/1711.10284\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Efficient Traffic-Sign Recognition with Scale-aware CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.12289\"\n  }, \"https://arxiv.org/abs/1805.12289\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Co-domain Embedding using Deep Quadruplet Networks for Unseen Traffic Sign Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arix:v\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.01907\"\n  }, \"https://arxiv.org/abs/1712.01907\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"\\xB5Net: A Highly Compact Deep Convolutional Neural Network Architecture for Real-time Embedded Traffic Sign Classification\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1804.00497\"\n  }, \"https://arxiv.org/abs/1804.00497\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Predictive Coding Network for Object Recognition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1802.04762\"\n  }, \"https://arxiv.org/abs/1802.04762\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018. The Robotics Institute, Carnegie Mellon University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.08035\"\n  }, \"https://arxiv.org/abs/1803.08035\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attention-based Pyramid Aggregation Network for Visual Place Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM MM 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.00288\"\n  }, \"https://arxiv.org/abs/1808.00288\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"How do Convolutional Neural Networks Learn Design?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.08402\"\n  }, \"https://arxiv.org/abs/1808.08402\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Making Classification Competitive for Deep Metric Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.12649\"\n  }, \"https://arxiv.org/abs/1811.12649\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"In Defense of the Triplet Loss for Visual Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Maryland & Honda Research Institute\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.08616\"\n  }, \"https://arxiv.org/abs/1901.08616\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"All You Need is a Few Shifts: Designing Efficient Convolutional Neural Networks for Image Classification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.05285\"\n  }, \"https://arxiv.org/abs/1903.05285\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep CNN-based Multi-task Learning for Open-Set Recognition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1903.03161\"\n  }, \"https://arxiv.org/abs/1903.03161\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Squared Earth Mover's Distance-based Loss for Training Deep Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1611.05916\"\n  }, \"https://arxiv.org/abs/1611.05916\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Large-Scale Long-Tailed Recognition in an Open World\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CUHK & UC Berkeley / ICSI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://liuziwei7.github.io/projects/LongTail.html\"\n  }, \"https://liuziwei7.github.io/projects/LongTail.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.05160\"\n  }, \"https://arxiv.org/abs/1904.05160\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Research, Brain Team\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2010.11929\"\n  }, \"https://arxiv.org/abs/2010.11929\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/google-research/vision_transformer\"\n  }, \"https://github.com/google-research/vision_transformer\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"High-Performance Large-Scale Image Recognition Without Normalization\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NFNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2102.06171\"\n  }, \"https://arxiv.org/abs/2102.06171\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/deepmind/deepmind-research/tree/master/nfnets\"\n  }, \"https://github.com/deepmind/deepmind-research/tree/master/nfnets\"))), mdx(\"h1\", {\n    \"id\": \"massive-classification\"\n  }, \"Massive Classification\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Accelerated Training for Massive Classification via Dynamic Class Selection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2018. CUHK & SenseTime\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: HF-Softmax\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.01687\"\n  }, \"https://arxiv.org/abs/1801.01687\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yl-1993/hfsoftmax\"\n  }, \"https://github.com/yl-1993/hfsoftmax\"))), mdx(\"h1\", {\n    \"id\": \"multi-object-recognition\"\n  }, \"Multi-object Recognition\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multiple Object Recognition with Visual Attention\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keyword: deep recurrent neural network, reinforcement learning\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1412.7755\"\n  }, \"https://arxiv.org/abs/1412.7755\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jrbtaylor/visual-attention\"\n  }, \"https://github.com/jrbtaylor/visual-attention\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multiple Instance Learning Convolutional Neural Networks for Object Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICPR 2016 Oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.03155\"\n  }, \"https://arxiv.org/abs/1610.03155\"))), mdx(\"h1\", {\n    \"id\": \"multi-label-classification\"\n  }, \"Multi-Label Classification\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Spatial Regularization with Image-level Supervisions for Multi-label Image Classification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Science and Technology of China & CUHK\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.05891\"\n  }, \"https://arxiv.org/abs/1702.05891\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official. Caffe): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zhufengx/SRN_multilabel/\"\n  }, \"https://github.com/zhufengx/SRN_multilabel/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Order-Free RNN with Visual Attention for Multi-Label Classification\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1707.05495\"\n  }, \"https://arxiv.org/abs/1707.05495\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Social Image Embedding with Deep Multimodal Attention Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Beihang University & Microsoft Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1710.06582\"\n  }, \"https://arxiv.org/abs/1710.06582\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-label Image Recognition by Recurrently Discovering Attentional Regions\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.02816\"\n  }, \"https://arxiv.org/abs/1711.02816\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Recurrent Attentional Reinforcement Learning for Multi-label Image Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.07465\"\n  }, \"https://arxiv.org/abs/1712.07465\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Baseline for Multi-Label Image Classification Using Ensemble Deep CNN\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.08412\"\n  }, \"https://arxiv.org/abs/1811.08412\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-class Classification without Multi-class Labels\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.00544\"\n  }, \"https://arxiv.org/abs/1901.00544\"))), mdx(\"p\", null, \"L\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"earning a Deep ConvNet for Multi-label Classification with Partial Labels\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1902.09720\"\n  }, \"https://arxiv.org/abs/1902.09720\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Label Image Recognition with Graph Convolutional Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.03582\"\n  }, \"https://arxiv.org/abs/1904.03582\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/chenzhaomin123/ML_GCN\"\n  }, \"https://github.com/chenzhaomin123/ML_GCN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"General Multi-label Image Classification with Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Virginia\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.14027\"\n  }, \"https://arxiv.org/abs/2011.14027\"))), mdx(\"h1\", {\n    \"id\": \"person-recognition\"\n  }, \"Person Recognition\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Beyond Frontal Faces: Improving Person Recognition Using Multiple Cues\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: UC Berkeley & Facebook AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: People In Photo Albums (PIPA) dataset, Pose Invariant PErson Recognition (PIPER)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://people.eecs.berkeley.edu/~nzhang/piper.html\"\n  }, \"https://people.eecs.berkeley.edu/~nzhang/piper.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1501.05703\"\n  }, \"https://arxiv.org/abs/1501.05703\"))), mdx(\"h2\", {\n    \"id\": \"coco_v1\"\n  }, \"COCO_v1\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Deep Features via Congenerous Cosine Loss for Person Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: COCO loss\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.06890\"\n  }, \"https://arxiv.org/abs/1702.06890\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/sciencefans/coco_loss\"\n  }, \"https://github.com/sciencefans/coco_loss\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pose-Aware Person Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVIT & Facebook AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1705.10120\"\n  }, \"https://arxiv.org/abs/1705.10120\"))), mdx(\"h2\", {\n    \"id\": \"coco_v2\"\n  }, \"COCO_v2\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rethinking Feature Discrimination and Polymerization for Large-scale Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2017 Deep Learning Workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: COCO loss\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1710.00870\"\n  }, \"https://arxiv.org/abs/1710.00870\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/sciencefans/coco_loss\"\n  }, \"https://github.com/sciencefans/coco_loss\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Person Recognition in Social Media Photos\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1710.03224\"\n  }, \"https://arxiv.org/abs/1710.03224\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unifying Identification and Context Learning for Person Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_cvpr_2018/papers/Huang_Unifying_Identification_and_CVPR_2018_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_cvpr_2018/papers/Huang_Unifying_Identification_and_CVPR_2018_paper.pdf\"))), mdx(\"h1\", {\n    \"id\": \"fine-grained-recognition\"\n  }, \"Fine-grained Recognition\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bilinear CNN Models for Fine-grained Visual Recognition\")), mdx(\"img\", {\n    \"src\": \"http://people.cs.umass.edu/~smaji/picon/bcnn.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://vis-www.cs.umass.edu/bcnn/\"\n  }, \"http://vis-www.cs.umass.edu/bcnn/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://vis-www.cs.umass.edu/bcnn/docs/bcnn_iccv15.pdf\"\n  }, \"http://vis-www.cs.umass.edu/bcnn/docs/bcnn_iccv15.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1504.07889\"\n  }, \"http://arxiv.org/abs/1504.07889\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"bitbucket: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://bitbucket.org/tsungyu/bcnn.git\"\n  }, \"https://bitbucket.org/tsungyu/bcnn.git\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fine-grained Image Classification by Exploring Bipartite-Graph Labels\")), mdx(\"img\", {\n    \"src\": \"http://www.f-zhou.com/fg/over.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.f-zhou.com/fg.html\"\n  }, \"http://www.f-zhou.com/fg.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1512.02665\"\n  }, \"http://arxiv.org/abs/1512.02665\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.f-zhou.com/fg_demo/\"\n  }, \"http://www.f-zhou.com/fg_demo/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Embedding Label Structures for Fine-Grained Feature Representation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1512.02895\"\n  }, \"http://arxiv.org/abs/1512.02895\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://webpages.uncc.edu/~szhang16/paper/CVPR16_structured_labels.pdf\"\n  }, \"http://webpages.uncc.edu/~szhang16/paper/CVPR16_structured_labels.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fine-grained Categorization and Dataset Bootstrapping using Deep Metric Learning with Humans in the Loop\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1512.05227\"\n  }, \"http://arxiv.org/abs/1512.05227\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fully Convolutional Attention Localization Networks: Efficient Attention Localization for Fine-Grained Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.06765\"\n  }, \"http://arxiv.org/abs/1603.06765\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Localizing by Describing: Attribute-Guided Attention Localization for Fine-Grained Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1605.06217\"\n  }, \"https://arxiv.org/abs/1605.06217\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Deep Representations of Fine-grained Visual Descriptions\")), mdx(\"img\", {\n    \"src\": \"https://raw.githubusercontent.com/reedscot/cvpr2016/master/images/description_embedding.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.05395\"\n  }, \"http://arxiv.org/abs/1605.05395\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/reedscot/cvpr2016\"\n  }, \"https://github.com/reedscot/cvpr2016\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"IDNet: Smartphone-based Gait Recognition with Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1606.03238\"\n  }, \"http://arxiv.org/abs/1606.03238\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Picking Deep Filter Responses for Fine-grained Image Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SPDA-CNN: Unifying Semantic Part Detection and Abstraction for Fine-grained Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Part-Stacked CNN for Fine-Grained Visual Categorization\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fine-grained Recognition in the Noisy Wild: Sensitivity Analysis of Convolutional Neural Networks Approaches\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.06756\"\n  }, \"https://arxiv.org/abs/1610.06756\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Low-rank Bilinear Pooling for Fine-Grained Classification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.ics.uci.edu/~skong2/lr_bilinear.html\"\n  }, \"http://www.ics.uci.edu/~skong2/lr_bilinear.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.05109\"\n  }, \"https://arxiv.org/abs/1611.05109\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aimerykong/Low-Rank-Bilinear-Pooling\"\n  }, \"https://github.com/aimerykong/Low-Rank-Bilinear-Pooling\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"\\u7EC6\\u7C92\\u5EA6\\u56FE\\u50CF\\u5206\\u6790\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: by \\u5434\\u5EFA\\u946B, NJU. VALSE 2017 Annual Progress Review Series\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mac.xmu.edu.cn/valse2017/ppt/APR/wjx_APR.pdf\"\n  }, \"http://mac.xmu.edu.cn/valse2017/ppt/APR/wjx_APR.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Look Closer to See Better: Recurrent Attention Convolutional Neural Network for Fine-grained Image Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_cvpr_2017/papers/Fu_Look_Closer_to_CVPR_2017_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_cvpr_2017/papers/Fu_Look_Closer_to_CVPR_2017_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fine-grained Recognition in the Wild: A Multi-Task Domain Adaptation Approach\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1709.02476\"\n  }, \"https://arxiv.org/abs/1709.02476\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Where to Focus: Deep Attention-based Spatially Recurrent Bilinear Networks for Fine-Grained Visual Recognition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.05769\"\n  }, \"https://arxiv.org/abs/1709.05769\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Multi-Attention Convolutional Neural Network for Fine-Grained Image Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"introL ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: MA-CNN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Science and Technology of China & Microsoft Research & University of Rochester\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_ICCV_2017/papers/Zheng_Learning_Multi-Attention_Convolutional_ICCV_2017_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_ICCV_2017/papers/Zheng_Learning_Multi-Attention_Convolutional_ICCV_2017_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TransFG: A Transformer Architecture for Fine-grained Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Johns Hopkins University & ByteDance Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.07976\"\n  }, \"https://arxiv.org/abs/2103.07976\"))), mdx(\"h1\", {\n    \"id\": \"food-recognition\"\n  }, \"Food Recognition\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepFood: Deep Learning-Based Food Image Recognition for Computer-Aided Dietary Assessment\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1606.05675\"\n  }, \"http://arxiv.org/abs/1606.05675\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/deercoder/DeepFood\"\n  }, \"https://github.com/deercoder/DeepFood\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Im2Calories: towards an automated mobile vision food diary\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: recognize the contents of your meal from a single image, then predict its nutritional contents, such as calories\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.ubc.ca/~murphyk/Papers/im2calories_iccv15.pdf\"\n  }, \"http://www.cs.ubc.ca/~murphyk/Papers/im2calories_iccv15.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Food Image Recognition by Using Convolutional Neural Networks (CNNs)\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.00983\"\n  }, \"https://arxiv.org/abs/1612.00983\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Wide-Slice Residual Networks for Food Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.06543\"\n  }, \"https://arxiv.org/abs/1612.06543\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Food Classification with Deep Learning in Keras / Tensorflow\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://blog.stratospark.com/deep-learning-applied-food-classification-deep-learning-keras.html\"\n  }, \"http://blog.stratospark.com/deep-learning-applied-food-classification-deep-learning-keras.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/stratospark/food-101-keras\"\n  }, \"https://github.com/stratospark/food-101-keras\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ChineseFoodNet: A large-scale Image Dataset for Chinese Food Recognition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1705.02743\"\n  }, \"https://arxiv.org/abs/1705.02743\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Computer vision-based food calorie estimation: dataset, method, and experiment\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1705.07632\"\n  }, \"https://arxiv.org/abs/1705.07632\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning-Based Food Calorie Estimation Method in Dietary Assessment\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1706.04062\"\n  }, \"https://arxiv.org/abs/1706.04062\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Food Ingredients Recognition through Multi-label Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1707.08816\"\n  }, \"https://arxiv.org/abs/1707.08816\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FoodNet: Recognizing Foods Using Ensemble of Deep Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IEEE Signal Processing Letters\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1709.09429\"\n  }, \"https://arxiv.org/abs/1709.09429\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Food recognition and recipe analysis: integrating visual content, context and external knowledge\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1801.07230\"\n  }, \"https://arxiv.org/abs/1801.07230\")), mdx(\"h1\", {\n    \"id\": \"attribute-recognition\"\n  }, \"Attribute Recognition\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-task CNN Model for Attribute Prediction\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ieee transaction paper\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1601.00400\"\n  }, \"https://arxiv.org/abs/1601.00400\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attributes for Improved Attributes: A Multi-Task Network for Attribute Classification\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1604.07360\"\n  }, \"https://arxiv.org/abs/1604.07360\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generative Adversarial Models for People Attribute Recognition in Surveillance\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AVSS 2017 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.02240\"\n  }, \"https://arxiv.org/abs/1707.02240\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attribute Recognition by Joint Recurrent Learning of Context and Correlation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1709.08553\"\n  }, \"https://arxiv.org/abs/1709.08553\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-label Object Attribute Classification using a Convolutional Neural Network\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.04309\"\n  }, \"https://arxiv.org/abs/1811.04309\")), mdx(\"h1\", {\n    \"id\": \"pedestrian-attribute-recognition--person-attribute-recognition\"\n  }, \"Pedestrian Attribute Recognition / Person Attribute Recognition\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-attribute Learning for Pedestrian Attribute Recognition in Surveillance Scenarios\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACPR 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: DeepSAR / DeepMAR\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://or.nsfc.gov.cn/bitstream/00001903-5/417802/1/1000014103914.pdf\"\n  }, \"http://or.nsfc.gov.cn/bitstream/00001903-5/417802/1/1000014103914.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kyu-sz/DeepMAR_deploy\"\n  }, \"https://github.com/kyu-sz/DeepMAR_deploy\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/dangweili/pedestrian-attribute-recognition-pytorch\"\n  }, \"https://github.com/dangweili/pedestrian-attribute-recognition-pytorch\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pedestrian Attribute Recognition At Far Distance\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM MM 2014\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://personal.ie.cuhk.edu.hk/~pluo/pdf/mm14.pdf\"\n  }, \"http://personal.ie.cuhk.edu.hk/~pluo/pdf/mm14.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Person Attribute Recognition with a Jointly-trained Holistic CNN Model\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Parse27k\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.vision.rwth-aachen.de/media/papers/sudowe_spitzer_leibe_ICCV_LaP_2015.pdf\"\n  }, \"https://www.vision.rwth-aachen.de/media/papers/sudowe_spitzer_leibe_ICCV_LaP_2015.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Human Attribute Recognition by Deep Hierarchical Contexts\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://personal.ie.cuhk.edu.hk/~ccloy/files/eccv_2016_human.pdf\"\n  }, \"http://personal.ie.cuhk.edu.hk/~ccloy/files/eccv_2016_human.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Robust Pedestrian Attribute Recognition for an Unbalanced Dataset using Mini-batch Training with Rarity Rate\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Intelligent Vehicles Symposium 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Chubu University & Nagoya University, Japan\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.vision.cs.chubu.ac.jp/MPRG/C_group/C081_fukui2016.pdf\"\n  }, \"http://www.vision.cs.chubu.ac.jp/MPRG/C_group/C081_fukui2016.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Weakly-supervised Learning of Mid-level Features for Pedestrian Attribute Recognition and Localization\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.05603\"\n  }, \"https://arxiv.org/abs/1611.05603\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kyu-sz/WPAL-network\"\n  }, \"https://github.com/kyu-sz/WPAL-network\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep View-Sensitive Pedestrian Attribute Inference in an end-to-end Model\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: PETA, RAP and WIDER\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.06089\"\n  }, \"https://arxiv.org/abs/1707.06089\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/asc-kit/vespa\"\n  }, \"https://github.com/asc-kit/vespa\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"HydraPlus-Net: Attentive Deep Features for Pedestrian Analysis\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CUHK & SenseTime\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: multi-directional attention (MDA)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1709.09930\"\n  }, \"https://arxiv.org/abs/1709.09930\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_ICCV_2017/papers/Liu_HydraPlus-Net_Attentive_Deep_ICCV_2017_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_ICCV_2017/papers/Liu_HydraPlus-Net_Attentive_Deep_ICCV_2017_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xh-liu/HydraPlus-Net\"\n  }, \"https://github.com/xh-liu/HydraPlus-Net\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Imbalanced Attribute Classification using Visual Attention Aggregation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Houston\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.03903\"\n  }, \"https://arxiv.org/abs/1807.03903\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Localization Guided Learning for Pedestrian Attribute Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.09102\"\n  }, \"https://arxiv.org/abs/1808.09102\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Grouping Attribute Recognition for Pedestrian with Joint Recurrent Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IJCAI 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.ijcai.org/proceedings/2018/0441.pdf\"\n  }, \"https://www.ijcai.org/proceedings/2018/0441.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sequence-based Person Attribute Recognition with Joint CTC-Attention Model\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: joint CTC-Attention model (JCM), s connectionist temporal classification (CTC)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.08115\"\n  }, \"https://arxiv.org/abs/1811.08115\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Deeper, the Better: Analysis of Person Attributes Recognition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1901.03756\"\n  }, \"https://arxiv.org/abs/1901.03756\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video-Based Pedestrian Attribute Recognition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1901.05742\"\n  }, \"https://arxiv.org/abs/1901.05742\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pedestrian Attribute Recognition: A Survey\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Anhui University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://sites.google.com/view/ahu-pedestrianattributes/\"\n  }, \"https://sites.google.com/view/ahu-pedestrianattributes/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.07474\"\n  }, \"https://arxiv.org/abs/1901.07474\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Papers with code: Pedestrian Attribute Recognition\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://paperswithcode.com/task/pedestrian-attribute-recognition/codeless\"\n  }, \"https://paperswithcode.com/task/pedestrian-attribute-recognition/codeless\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pedestrian-Attribute-Recognition-Paper-List\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/wangxiao5791509/Pedestrian-Attribute-Recognition-Paper-List\"\n  }, \"https://github.com/wangxiao5791509/Pedestrian-Attribute-Recognition-Paper-List\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attribute Aware Pooling for Pedestrian Attribute Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IJCAI 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Huawei Noah\\u2019s Ark Lab & University of Sydney\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.11837\"\n  }, \"https://arxiv.org/abs/1907.11837\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Distraction-Aware Feature Learning for Human Attribute Recognition via Coarse-to-Fine Attention Mechanism\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2020 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1911.11351\"\n  }, \"https://arxiv.org/abs/1911.11351\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rethinking of Pedestrian Attribute Recognition: Realistic Datasets with Efficient Method\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Chinese Academy of Sciences & Chinese Academy of Sciences\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2005.11909\"\n  }, \"https://arxiv.org/abs/2005.11909\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, Pytorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/valencebond/Strong_Baseline_of_Pedestrian_Attribute_Recognition\"\n  }, \"https://github.com/valencebond/Strong_Baseline_of_Pedestrian_Attribute_Recognition\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hierarchical Feature Embedding for Attribute Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SenseTime Group Limited & Tsinghua University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2005.11576\"\n  }, \"https://arxiv.org/abs/2005.11576\"))), mdx(\"h1\", {\n    \"id\": \"clothes-recognition\"\n  }, \"Clothes Recognition\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepFashion: Powering Robust Clothes Recognition and Retrieval with Rich Annotations\")), mdx(\"img\", {\n    \"src\": \"http://personal.ie.cuhk.edu.hk/~lz013/projects/deepfashion/intro.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: FashionNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://personal.ie.cuhk.edu.hk/~lz013/projects/DeepFashion.html\"\n  }, \"http://personal.ie.cuhk.edu.hk/~lz013/projects/DeepFashion.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_DeepFashion_Powering_Robust_CVPR_2016_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_DeepFashion_Powering_Robust_CVPR_2016_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Task Curriculum Transfer Deep Learning of Clothing Attributes\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.03670\"\n  }, \"https://arxiv.org/abs/1610.03670\"))), mdx(\"h1\", {\n    \"id\": \"star-galaxy-classification\"\n  }, \"Star-galaxy Classification\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Star-galaxy Classification Using Deep Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MNRAS\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.04369\"\n  }, \"http://arxiv.org/abs/1608.04369\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/EdwardJKim/dl4astro\"\n  }, \"https://github.com/EdwardJKim/dl4astro\"))), mdx(\"h1\", {\n    \"id\": \"logo-recognition\"\n  }, \"Logo Recognition\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning for Logo Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.02620\"\n  }, \"https://arxiv.org/abs/1701.02620\"))), mdx(\"h1\", {\n    \"id\": \"plant-classification\"\n  }, \"Plant Classification\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Large-Scale Plant Classification with Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Published at Proocedings of ACM Computing Frontiers Conference 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.03736\"\n  }, \"https://arxiv.org/abs/1706.03736\"))), mdx(\"h1\", {\n    \"id\": \"scene-recognition--scene-classification\"\n  }, \"Scene Recognition / Scene Classification\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Deep Features for Scene Recognition using Places Database\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://places.csail.mit.edu/places_NIPS14.pdf\"\n  }, \"http://places.csail.mit.edu/places_NIPS14.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gihtub: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/metalbubble/places365\"\n  }, \"https://github.com/metalbubble/places365\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Using neon for Scene Recognition: Mini-Places2\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: This is an implementation of the deep residual network used for\\n\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://6.869.csail.mit.edu/fa15/project.html\"\n  }, \"Mini-Places2\"), \" as described in\\n\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1512.03385\"\n  }, \"He et. al., \\\"Deep Residual Learning for Image Recognition\\\"\"), \".\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.nervanasys.com/using-neon-for-scene-recognition-mini-places2/\"\n  }, \"http://www.nervanasys.com/using-neon-for-scene-recognition-mini-places2/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hunterlang/mpmz\"\n  }, \"https://github.com/hunterlang/mpmz\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scene Classification with Inception-7\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://lsun.cs.princeton.edu/slides/Christian.pdf\"\n  }, \"http://lsun.cs.princeton.edu/slides/Christian.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Clustering for Robust Fine-Grained Scene Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1607.07614\"\n  }, \"http://arxiv.org/abs/1607.07614\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scene recognition with CNNs: objects, scales and dataset bias\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.06867\"\n  }, \"https://arxiv.org/abs/1801.06867\"))), mdx(\"h2\", {\n    \"id\": \"leaderboard\"\n  }, \"Leaderboard\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Leaderboard of Places Database\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: currently rank1: Qian Zhang(Beijing Samsung Telecom R&D Center), 0.6410@top1, 0.9065@top5\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://places.csail.mit.edu/user/leaderboard.php\"\n  }, \"http://places.csail.mit.edu/user/leaderboard.php\"))), mdx(\"h1\", {\n    \"id\": \"blogs\"\n  }, \"Blogs\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"What is the class of this image ? - Discover the current state of the art in objects classification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: \\\"Discover the current state of the art in objects classification.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MNIST, CIFAR-10, CIFAR-100, STL-10, SVHN, ILSVRC2012 task 1\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\"\n  }, \"http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Recognition with Convolutional Neural Networks in the Keras Deep Learning Library\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://machinelearningmastery.com/object-recognition-convolutional-neural-networks-keras-deep-learning-library/\"\n  }, \"http://machinelearningmastery.com/object-recognition-convolutional-neural-networks-keras-deep-learning-library/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Effect of Resolution on Deep Neural Network Image Classification Accuracy\")), mdx(\"img\", {\n    \"src\": \"https://cdn-images-1.medium.com/max/800/1*0SBEYOChCOMbqnGG34xSxw.png\",\n    \"alt\": null\n  }), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://medium.com/the-downlinq/the-effect-of-resolution-on-deep-neural-network-image-classification-accuracy-d1338e2782c5#.em5rk991r\"\n  }, \"https://medium.com/the-downlinq/the-effect-of-resolution-on-deep-neural-network-image-classification-accuracy-d1338e2782c5#.em5rk991r\")));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"---\nlayout: post\ncategory: deep_learning\ntitle: Classification / Recognition\ndate: 2015-10-09\n---\n\n# Papers\n\n**DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition**\n\n- auothor: Jeff Donahue, Yangqing Jia, Oriol Vinyals, Judy Hoffman, Ning Zhang, Eric Tzeng, Trevor Darrell\n- arxiv: [http://arxiv.org/abs/1310.1531](http://arxiv.org/abs/1310.1531)\n\n**CNN Features off-the-shelf: an Astounding Baseline for Recognition**\n\n- intro: CVPR 2014\n- arxiv: [http://arxiv.org/abs/1403.6382](http://arxiv.org/abs/1403.6382)\n\n**HD-CNN: Hierarchical Deep Convolutional Neural Network for Image Classification**\n\n**HD-CNN: Hierarchical Deep Convolutional Neural Network for Large Scale Visual Recognition**\n\n- intro: ICCV 2015\n- intro: introduce hierarchical deep CNNs (HD-CNNs) by embedding deep CNNs into a category hierarchy\n- project page: [https://sites.google.com/site/homepagezhichengyan/home/hdcnn](https://sites.google.com/site/homepagezhichengyan/home/hdcnn)\n- arxiv: [https://arxiv.org/abs/1410.0736](https://arxiv.org/abs/1410.0736)\n- code: [https://sites.google.com/site/homepagezhichengyan/home/hdcnn/code](https://sites.google.com/site/homepagezhichengyan/home/hdcnn/code)\n- github: [https://github.com/stephenyan1231/caffe-public/tree/hdcnn](https://github.com/stephenyan1231/caffe-public/tree/hdcnn)\n\n**Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification**\n\n- intro: ImageNet top-5 error: 4.94%\n- arxiv: [http://arxiv.org/abs/1502.01852](http://arxiv.org/abs/1502.01852)\n- notes: [http://blog.csdn.net/happynear/article/details/45440811](http://blog.csdn.net/happynear/article/details/45440811)\n\n**Automatic Instrument Recognition in Polyphonic Music Using Convolutional Neural Networks**\n\n- arxiv: [http://arxiv.org/abs/1511.05520](http://arxiv.org/abs/1511.05520)\n- github: [https://github.com/glennq/instrument-recognition](https://github.com/glennq/instrument-recognition)\n\n**Deep Convolutional Networks on the Pitch Spiral for Musical Instrument Recognition**\n\n- paper: [https://github.com/lostanlen/ismir2016/blob/master/paper/lostanlen_ismir2016.pdf](https://github.com/lostanlen/ismir2016/blob/master/paper/lostanlen_ismir2016.pdf)\n- github: [https://github.com/lostanlen/ismir2016](https://github.com/lostanlen/ismir2016)\n\n**Humans and deep networks largely agree on which kinds of variation make object recognition harder**\n\n- arxiv: [http://arxiv.org/abs/1604.06486](http://arxiv.org/abs/1604.06486)\n- review: [https://www.technologyreview.com/s/601387/why-machine-vision-is-flawed-in-the-same-way-as-human-vision/](https://www.technologyreview.com/s/601387/why-machine-vision-is-flawed-in-the-same-way-as-human-vision/)\n\n**FusionNet: 3D Object Classification Using Multiple Data Representations**\n\n- arxiv: [https://arxiv.org/abs/1607.05695](https://arxiv.org/abs/1607.05695)\n\n**From image recognition to object recognition**\n\n- blog: [https://www.oreilly.com/ideas/from-image-recognition-to-object-recognition](https://www.oreilly.com/ideas/from-image-recognition-to-object-recognition)\n\n**Deep FisherNet for Object Classification**\n\n- arxiv: [http://arxiv.org/abs/1608.00182](http://arxiv.org/abs/1608.00182)\n\n**Factorized Bilinear Models for Image Recognition**\n\n- intro: TuSimple\n- arxiv: [https://arxiv.org/abs/1611.05709](https://arxiv.org/abs/1611.05709)\n- github(MXNet): [https://github.com/lyttonhao/Factorized-Bilinear-Network](https://github.com/lyttonhao/Factorized-Bilinear-Network)\n\n**Hyperspectral CNN Classification with Limited Training Samples**\n\n- arxiv: [https://arxiv.org/abs/1611.09007](https://arxiv.org/abs/1611.09007)\n\n**The More You Know: Using Knowledge Graphs for Image Classification**\n\n- intro: CMU. GSNN\n- arxiv: [https://arxiv.org/abs/1612.04844](https://arxiv.org/abs/1612.04844)\n\n**MaxMin Convolutional Neural Networks for Image Classification**\n\n- paper: [http://webia.lip6.fr/~thomen/papers/Blot_ICIP_2016.pdf](http://webia.lip6.fr/~thomen/papers/Blot_ICIP_2016.pdf)\n- github: [https://github.com/karandesai-96/maxmin-cnn](https://github.com/karandesai-96/maxmin-cnn)\n\n**Cost-Effective Active Learning for Deep Image Classification**\n\n- intro: TCSVT 2016\n- intro: Sun Yat-sen University & Guangzhou University\n- arxiv: [https://arxiv.org/abs/1701.03551](https://arxiv.org/abs/1701.03551)\n\n**Deep Collaborative Learning for Visual Recognition**\n\n[https://www.arxiv.org/abs/1703.01229](https://www.arxiv.org/abs/1703.01229)\n\n**Convolutional Low-Resolution Fine-Grained Classification**\n\n[https://arxiv.org/abs/1703.05393](https://arxiv.org/abs/1703.05393)\n\n**Multi-Scale Dense Networks for Resource Efficient Image Classification**\n\n- intro: Cornell University & Fudan University & Tsinghua University & Facebook AI Research\n- arxiv: [https://arxiv.org/abs/1703.09844](https://arxiv.org/abs/1703.09844)\n- github: [https://github.com//gaohuang/MSDNet](https://github.com//gaohuang/MSDNet)\n\n**Deep Mixture of Diverse Experts for Large-Scale Visual Recognition**\n\n[https://arxiv.org/abs/1706.07901](https://arxiv.org/abs/1706.07901)\n\n**Sunrise or Sunset: Selective Comparison Learning for Subtle Attribute Recognition**\n\n- intro: BMVC 2017\n- arxiv: [https://arxiv.org/abs/1707.06335](https://arxiv.org/abs/1707.06335)\n\n**Why Do Deep Neural Networks Still Not Recognize These Images?: A Qualitative Analysis on Failure Cases of ImageNet Classification**\n\n- intro: Poster presented at CVPR 2017 Scene Understanding Workshop\n- arxiv: [https://arxiv.org/abs/1709.03439](https://arxiv.org/abs/1709.03439)\n\n**B-CNN: Branch Convolutional Neural Network for Hierarchical Classification**\n\n[https://arxiv.org/abs/1709.09890](https://arxiv.org/abs/1709.09890)\n\n**Learning Transferable Architectures for Scalable Image Recognition**\n\n- intro: Google Brain\n- keywords: Neural Architecture Search\n- arxiv: [https://arxiv.org/abs/1707.07012](https://arxiv.org/abs/1707.07012)\n\n**AOGNets: Deep AND-OR Grammar Networks for Visual Recognition**\n\n[https://arxiv.org/abs/1711.05847](https://arxiv.org/abs/1711.05847)\n\n**Knowledge Concentration: Learning 100K Object Classifiers in a Single CNN**\n\n- intro: University of Southern California & Google Research\n- arxiv: [https://arxiv.org/abs/1711.07607](https://arxiv.org/abs/1711.07607)\n\n**Between-class Learning for Image Classification**\n\n- intro: The University of Tokyo & RIKEN\n- arxiv: [https://arxiv.org/abs/1711.10284](https://arxiv.org/abs/1711.10284)\n\n**Efficient Traffic-Sign Recognition with Scale-aware CNN**\n\n- intro: BMVC 2017\n- arxiv: [https://arxiv.org/abs/1805.12289](https://arxiv.org/abs/1805.12289)\n\n**Co-domain Embedding using Deep Quadruplet Networks for Unseen Traffic Sign Recognition**\n\n- intro: AAAI 2018\n- arix:v[https://arxiv.org/abs/1712.01907](https://arxiv.org/abs/1712.01907)\n\n**µNet: A Highly Compact Deep Convolutional Neural Network Architecture for Real-time Embedded Traffic Sign Classification**\n\n[https://arxiv.org/abs/1804.00497](https://arxiv.org/abs/1804.00497)\n\n**Deep Predictive Coding Network for Object Recognition**\n\n[https://arxiv.org/abs/1802.04762](https://arxiv.org/abs/1802.04762)\n\n**Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs**\n\n- intro: CVPR 2018. The Robotics Institute, Carnegie Mellon University\n- arxiv: [https://arxiv.org/abs/1803.08035](https://arxiv.org/abs/1803.08035)\n\n**Attention-based Pyramid Aggregation Network for Visual Place Recognition**\n\n- intro: ACM MM 2018\n- arxiv: [https://arxiv.org/abs/1808.00288](https://arxiv.org/abs/1808.00288)\n\n**How do Convolutional Neural Networks Learn Design?**\n\n- intro: ICPR 2018\n- arxiv: [https://arxiv.org/abs/1808.08402](https://arxiv.org/abs/1808.08402)\n\n**Making Classification Competitive for Deep Metric Learning**\n\n[https://arxiv.org/abs/1811.12649](https://arxiv.org/abs/1811.12649)\n\n**In Defense of the Triplet Loss for Visual Recognition**\n\n- intro: University of Maryland & Honda Research Institute\n- arxiv: [https://arxiv.org/abs/1901.08616](https://arxiv.org/abs/1901.08616)\n\n**All You Need is a Few Shifts: Designing Efficient Convolutional Neural Networks for Image Classification**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1903.05285](https://arxiv.org/abs/1903.05285)\n\n**Deep CNN-based Multi-task Learning for Open-Set Recognition**\n\n[https://arxiv.org/abs/1903.03161](https://arxiv.org/abs/1903.03161)\n\n**Squared Earth Mover's Distance-based Loss for Training Deep Neural Networks**\n\n[https://arxiv.org/abs/1611.05916](https://arxiv.org/abs/1611.05916)\n\n**Large-Scale Long-Tailed Recognition in an Open World**\n\n- intro: CVPR 2019 oral\n- intro: CUHK & UC Berkeley / ICSI\n- project page: [https://liuziwei7.github.io/projects/LongTail.html](https://liuziwei7.github.io/projects/LongTail.html)\n- arxiv: [https://arxiv.org/abs/1904.05160](https://arxiv.org/abs/1904.05160)\n\n**An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale**\n\n- intro: Google Research, Brain Team\n- arxiv: [https://arxiv.org/abs/2010.11929](https://arxiv.org/abs/2010.11929)\n- github: [https://github.com/google-research/vision_transformer](https://github.com/google-research/vision_transformer)\n\n**High-Performance Large-Scale Image Recognition Without Normalization**\n\n- intro: NFNet\n- arxiv: [https://arxiv.org/abs/2102.06171](https://arxiv.org/abs/2102.06171)\n- github: [https://github.com/deepmind/deepmind-research/tree/master/nfnets](https://github.com/deepmind/deepmind-research/tree/master/nfnets)\n\n# Massive Classification\n\n**Accelerated Training for Massive Classification via Dynamic Class Selection**\n\n- intro: AAAI 2018. CUHK & SenseTime\n- keywords: HF-Softmax\n- arxiv: [https://arxiv.org/abs/1801.01687](https://arxiv.org/abs/1801.01687)\n- github: [https://github.com/yl-1993/hfsoftmax](https://github.com/yl-1993/hfsoftmax)\n\n# Multi-object Recognition\n\n**Multiple Object Recognition with Visual Attention**\n\n- keyword: deep recurrent neural network, reinforcement learning\n- arxiv: [https://arxiv.org/abs/1412.7755](https://arxiv.org/abs/1412.7755)\n- github: [https://github.com/jrbtaylor/visual-attention](https://github.com/jrbtaylor/visual-attention)\n\n**Multiple Instance Learning Convolutional Neural Networks for Object Recognition**\n\n- intro: ICPR 2016 Oral\n- arxiv: [https://arxiv.org/abs/1610.03155](https://arxiv.org/abs/1610.03155)\n\n# Multi-Label Classification\n\n**Learning Spatial Regularization with Image-level Supervisions for Multi-label Image Classification**\n\n- intro: CVPR 2017\n- intro: University of Science and Technology of China & CUHK\n- arxiv: [https://arxiv.org/abs/1702.05891](https://arxiv.org/abs/1702.05891)\n- github(official. Caffe): [https://github.com/zhufengx/SRN_multilabel/](https://github.com/zhufengx/SRN_multilabel/)\n\n**Order-Free RNN with Visual Attention for Multi-Label Classification**\n\n[https://arxiv.org/abs/1707.05495](https://arxiv.org/abs/1707.05495)\n\n**Learning Social Image Embedding with Deep Multimodal Attention Networks**\n\n- intro: Beihang University & Microsoft Research\n- arxiv: [https://arxiv.org/abs/1710.06582](https://arxiv.org/abs/1710.06582)\n\n**Multi-label Image Recognition by Recurrently Discovering Attentional Regions**\n\n- intro: ICCV 2017\n- arxiv: [https://arxiv.org/abs/1711.02816](https://arxiv.org/abs/1711.02816)\n\n**Recurrent Attentional Reinforcement Learning for Multi-label Image Recognition**\n\n- intro: AAAI 2018\n- arxiv: [https://arxiv.org/abs/1712.07465](https://arxiv.org/abs/1712.07465)\n\n**A Baseline for Multi-Label Image Classification Using Ensemble Deep CNN**\n\n[https://arxiv.org/abs/1811.08412](https://arxiv.org/abs/1811.08412)\n\n**Multi-class Classification without Multi-class Labels**\n\n- intro: ICLR 2019\n- arxiv: [https://arxiv.org/abs/1901.00544](https://arxiv.org/abs/1901.00544)\n\nL**earning a Deep ConvNet for Multi-label Classification with Partial Labels**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1902.09720](https://arxiv.org/abs/1902.09720)\n\n**Multi-Label Image Recognition with Graph Convolutional Networks**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1904.03582](https://arxiv.org/abs/1904.03582)\n- github: [https://github.com/chenzhaomin123/ML_GCN](https://github.com/chenzhaomin123/ML_GCN)\n\n**General Multi-label Image Classification with Transformers**\n\n- intro: University of Virginia\n- arxiv: [https://arxiv.org/abs/2011.14027](https://arxiv.org/abs/2011.14027)\n\n# Person Recognition\n\n**Beyond Frontal Faces: Improving Person Recognition Using Multiple Cues**\n\n- intro: UC Berkeley & Facebook AI Research\n- keywords: People In Photo Albums (PIPA) dataset, Pose Invariant PErson Recognition (PIPER)\n- project page: [https://people.eecs.berkeley.edu/~nzhang/piper.html](https://people.eecs.berkeley.edu/~nzhang/piper.html)\n- arxiv: [https://arxiv.org/abs/1501.05703](https://arxiv.org/abs/1501.05703)\n\n## COCO_v1\n\n**Learning Deep Features via Congenerous Cosine Loss for Person Recognition**\n\n- keywords: COCO loss\n- arxiv: [https://arxiv.org/abs/1702.06890](https://arxiv.org/abs/1702.06890)\n- github: [https://github.com/sciencefans/coco_loss](https://github.com/sciencefans/coco_loss)\n\n**Pose-Aware Person Recognition**\n\n- intro: CVIT & Facebook AI Research\n- arxiv: [https://arxiv.org/abs/1705.10120](https://arxiv.org/abs/1705.10120)\n\n## COCO_v2\n\n**Rethinking Feature Discrimination and Polymerization for Large-scale Recognition**\n\n- intro: NIPS 2017 Deep Learning Workshop\n- keywords: COCO loss\n- arxiv: [https://arxiv.org/abs/1710.00870](https://arxiv.org/abs/1710.00870)\n- github: [https://github.com/sciencefans/coco_loss](https://github.com/sciencefans/coco_loss)\n\n**Person Recognition in Social Media Photos**\n\n[https://arxiv.org/abs/1710.03224](https://arxiv.org/abs/1710.03224)\n\n**Unifying Identification and Context Learning for Person Recognition**\n\n- intro: CVPR 2018\n- paper: [http://openaccess.thecvf.com/content_cvpr_2018/papers/Huang_Unifying_Identification_and_CVPR_2018_paper.pdf](http://openaccess.thecvf.com/content_cvpr_2018/papers/Huang_Unifying_Identification_and_CVPR_2018_paper.pdf)\n\n# Fine-grained Recognition\n\n**Bilinear CNN Models for Fine-grained Visual Recognition**\n\n![](http://people.cs.umass.edu/~smaji/picon/bcnn.png)\n\n- intro: ICCV 2015\n- homepage: [http://vis-www.cs.umass.edu/bcnn/](http://vis-www.cs.umass.edu/bcnn/)\n- paper: [http://vis-www.cs.umass.edu/bcnn/docs/bcnn_iccv15.pdf](http://vis-www.cs.umass.edu/bcnn/docs/bcnn_iccv15.pdf)\n- arxiv: [http://arxiv.org/abs/1504.07889](http://arxiv.org/abs/1504.07889)\n- bitbucket: [https://bitbucket.org/tsungyu/bcnn.git](https://bitbucket.org/tsungyu/bcnn.git)\n\n**Fine-grained Image Classification by Exploring Bipartite-Graph Labels**\n\n![](http://www.f-zhou.com/fg/over.png)\n\n- intro: CVPR 2016\n- project page: [http://www.f-zhou.com/fg.html](http://www.f-zhou.com/fg.html)\n- arxiv: [http://arxiv.org/abs/1512.02665](http://arxiv.org/abs/1512.02665)\n- demo: [http://www.f-zhou.com/fg_demo/](http://www.f-zhou.com/fg_demo/)\n\n**Embedding Label Structures for Fine-Grained Feature Representation**\n\n- intro: CVPR 2016\n- arxiv: [http://arxiv.org/abs/1512.02895](http://arxiv.org/abs/1512.02895)\n- paper: [http://webpages.uncc.edu/~szhang16/paper/CVPR16_structured_labels.pdf](http://webpages.uncc.edu/~szhang16/paper/CVPR16_structured_labels.pdf)\n\n**Fine-grained Categorization and Dataset Bootstrapping using Deep Metric Learning with Humans in the Loop**\n\n- arxiv: [http://arxiv.org/abs/1512.05227](http://arxiv.org/abs/1512.05227)\n\n**Fully Convolutional Attention Localization Networks: Efficient Attention Localization for Fine-Grained Recognition**\n\n- arxiv: [http://arxiv.org/abs/1603.06765](http://arxiv.org/abs/1603.06765)\n\n**Localizing by Describing: Attribute-Guided Attention Localization for Fine-Grained Recognition**\n\n- arxiv: [https://arxiv.org/abs/1605.06217](https://arxiv.org/abs/1605.06217)\n\n**Learning Deep Representations of Fine-grained Visual Descriptions**\n\n![](https://raw.githubusercontent.com/reedscot/cvpr2016/master/images/description_embedding.jpg)\n\n- intro: CVPR 2016\n- arxiv: [http://arxiv.org/abs/1605.05395](http://arxiv.org/abs/1605.05395)\n- github: [https://github.com/reedscot/cvpr2016](https://github.com/reedscot/cvpr2016)\n\n**IDNet: Smartphone-based Gait Recognition with Convolutional Neural Networks**\n\n- arxiv: [http://arxiv.org/abs/1606.03238](http://arxiv.org/abs/1606.03238)\n\n**Picking Deep Filter Responses for Fine-grained Image Recognition**\n\n- intro: CVPR 2016\n\n**SPDA-CNN: Unifying Semantic Part Detection and Abstraction for Fine-grained Recognition**\n\n- intro: CVPR 2016\n\n**Part-Stacked CNN for Fine-Grained Visual Categorization**\n\n- intro: CVPR 2016\n\n**Fine-grained Recognition in the Noisy Wild: Sensitivity Analysis of Convolutional Neural Networks Approaches**\n\n- intro: BMVC 2016\n- arxiv: [https://arxiv.org/abs/1610.06756](https://arxiv.org/abs/1610.06756)\n\n**Low-rank Bilinear Pooling for Fine-Grained Classification**\n\n- intro: CVPR 2017\n- project page: [http://www.ics.uci.edu/~skong2/lr_bilinear.html](http://www.ics.uci.edu/~skong2/lr_bilinear.html)\n- arxiv: [https://arxiv.org/abs/1611.05109](https://arxiv.org/abs/1611.05109)\n- github: [https://github.com/aimerykong/Low-Rank-Bilinear-Pooling](https://github.com/aimerykong/Low-Rank-Bilinear-Pooling)\n\n**细粒度图像分析**\n\n- intro: by 吴建鑫, NJU. VALSE 2017 Annual Progress Review Series\n- slides: [http://mac.xmu.edu.cn/valse2017/ppt/APR/wjx_APR.pdf](http://mac.xmu.edu.cn/valse2017/ppt/APR/wjx_APR.pdf)\n\n**Look Closer to See Better: Recurrent Attention Convolutional Neural Network for Fine-grained Image Recognition**\n\n- intro: CVPR 2017\n- paper: [http://openaccess.thecvf.com/content_cvpr_2017/papers/Fu_Look_Closer_to_CVPR_2017_paper.pdf](http://openaccess.thecvf.com/content_cvpr_2017/papers/Fu_Look_Closer_to_CVPR_2017_paper.pdf)\n\n**Fine-grained Recognition in the Wild: A Multi-Task Domain Adaptation Approach**\n\n- intro: ICCV 2017\n- arxiv: [https://arxiv.org/abs/1709.02476](https://arxiv.org/abs/1709.02476)\n\n**Where to Focus: Deep Attention-based Spatially Recurrent Bilinear Networks for Fine-Grained Visual Recognition**\n\n[https://arxiv.org/abs/1709.05769](https://arxiv.org/abs/1709.05769)\n\n**Learning Multi-Attention Convolutional Neural Network for Fine-Grained Image Recognition**\n\n- introL ICCV 2017\n- keywords: MA-CNN\n- intro: University of Science and Technology of China & Microsoft Research & University of Rochester\n- paper: [http://openaccess.thecvf.com/content_ICCV_2017/papers/Zheng_Learning_Multi-Attention_Convolutional_ICCV_2017_paper.pdf](http://openaccess.thecvf.com/content_ICCV_2017/papers/Zheng_Learning_Multi-Attention_Convolutional_ICCV_2017_paper.pdf)\n\n**TransFG: A Transformer Architecture for Fine-grained Recognition**\n\n- intro: Johns Hopkins University & ByteDance Inc.\n- arxiv: [https://arxiv.org/abs/2103.07976](https://arxiv.org/abs/2103.07976)\n\n# Food Recognition\n\n**DeepFood: Deep Learning-Based Food Image Recognition for Computer-Aided Dietary Assessment**\n\n- arxiv: [http://arxiv.org/abs/1606.05675](http://arxiv.org/abs/1606.05675)\n- github: [https://github.com/deercoder/DeepFood](https://github.com/deercoder/DeepFood)\n\n**Im2Calories: towards an automated mobile vision food diary**\n\n- intro: recognize the contents of your meal from a single image, then predict its nutritional contents, such as calories\n- paper: [http://www.cs.ubc.ca/~murphyk/Papers/im2calories_iccv15.pdf](http://www.cs.ubc.ca/~murphyk/Papers/im2calories_iccv15.pdf)\n\n**Food Image Recognition by Using Convolutional Neural Networks (CNNs)**\n\n- arxiv: [https://arxiv.org/abs/1612.00983](https://arxiv.org/abs/1612.00983)\n\n**Wide-Slice Residual Networks for Food Recognition**\n\n- arxiv: [https://arxiv.org/abs/1612.06543](https://arxiv.org/abs/1612.06543)\n\n**Food Classification with Deep Learning in Keras / Tensorflow**\n\n- blog: [http://blog.stratospark.com/deep-learning-applied-food-classification-deep-learning-keras.html](http://blog.stratospark.com/deep-learning-applied-food-classification-deep-learning-keras.html)\n- github: [https://github.com/stratospark/food-101-keras](https://github.com/stratospark/food-101-keras)\n\n**ChineseFoodNet: A large-scale Image Dataset for Chinese Food Recognition**\n\n[https://arxiv.org/abs/1705.02743](https://arxiv.org/abs/1705.02743)\n\n**Computer vision-based food calorie estimation: dataset, method, and experiment**\n\n[https://arxiv.org/abs/1705.07632](https://arxiv.org/abs/1705.07632)\n\n**Deep Learning-Based Food Calorie Estimation Method in Dietary Assessment**\n\n[https://arxiv.org/abs/1706.04062](https://arxiv.org/abs/1706.04062)\n\n**Food Ingredients Recognition through Multi-label Learning**\n\n[https://arxiv.org/abs/1707.08816](https://arxiv.org/abs/1707.08816)\n\n**FoodNet: Recognizing Foods Using Ensemble of Deep Networks**\n\n- intro: IEEE Signal Processing Letters\n- arxiv: [https://arxiv.org/abs/1709.09429](https://arxiv.org/abs/1709.09429)\n\n**Food recognition and recipe analysis: integrating visual content, context and external knowledge**\n\n[https://arxiv.org/abs/1801.07230](https://arxiv.org/abs/1801.07230)\n\n# Attribute Recognition\n\n**Multi-task CNN Model for Attribute Prediction**\n\n- intro: ieee transaction paper\n- arxiv: [https://arxiv.org/abs/1601.00400](https://arxiv.org/abs/1601.00400)\n\n**Attributes for Improved Attributes: A Multi-Task Network for Attribute Classification**\n\n[https://arxiv.org/abs/1604.07360](https://arxiv.org/abs/1604.07360)\n\n**Generative Adversarial Models for People Attribute Recognition in Surveillance**\n\n- intro: AVSS 2017 oral\n- arxiv: [https://arxiv.org/abs/1707.02240](https://arxiv.org/abs/1707.02240)\n\n**Attribute Recognition by Joint Recurrent Learning of Context and Correlation**\n\n- intro: ICCV 2017\n- arxiv: [https://arxiv.org/abs/1709.08553](https://arxiv.org/abs/1709.08553)\n\n**Multi-label Object Attribute Classification using a Convolutional Neural Network**\n\n[https://arxiv.org/abs/1811.04309](https://arxiv.org/abs/1811.04309)\n\n# Pedestrian Attribute Recognition / Person Attribute Recognition\n\n**Multi-attribute Learning for Pedestrian Attribute Recognition in Surveillance Scenarios**\n\n- intro: ACPR 2015\n- keywords: DeepSAR / DeepMAR\n- paper: [http://or.nsfc.gov.cn/bitstream/00001903-5/417802/1/1000014103914.pdf](http://or.nsfc.gov.cn/bitstream/00001903-5/417802/1/1000014103914.pdf)\n- github: [https://github.com/kyu-sz/DeepMAR_deploy](https://github.com/kyu-sz/DeepMAR_deploy)\n- github: [https://github.com/dangweili/pedestrian-attribute-recognition-pytorch](https://github.com/dangweili/pedestrian-attribute-recognition-pytorch)\n\n**Pedestrian Attribute Recognition At Far Distance**\n\n- intro: ACM MM 2014\n- paper: [http://personal.ie.cuhk.edu.hk/~pluo/pdf/mm14.pdf](http://personal.ie.cuhk.edu.hk/~pluo/pdf/mm14.pdf)\n\n**Person Attribute Recognition with a Jointly-trained Holistic CNN Model**\n\n- intro: ICCV 2015\n- keywords: Parse27k\n- arxiv: [https://www.vision.rwth-aachen.de/media/papers/sudowe_spitzer_leibe_ICCV_LaP_2015.pdf](https://www.vision.rwth-aachen.de/media/papers/sudowe_spitzer_leibe_ICCV_LaP_2015.pdf)\n\n**Human Attribute Recognition by Deep Hierarchical Contexts**\n\n- intro: ECCV 2016\n- paper: [http://personal.ie.cuhk.edu.hk/~ccloy/files/eccv_2016_human.pdf](http://personal.ie.cuhk.edu.hk/~ccloy/files/eccv_2016_human.pdf)\n\n**Robust Pedestrian Attribute Recognition for an Unbalanced Dataset using Mini-batch Training with Rarity Rate**\n\n- intro: Intelligent Vehicles Symposium 2016\n- intro: Chubu University & Nagoya University, Japan\n- paper: [http://www.vision.cs.chubu.ac.jp/MPRG/C_group/C081_fukui2016.pdf](http://www.vision.cs.chubu.ac.jp/MPRG/C_group/C081_fukui2016.pdf)\n\n**Weakly-supervised Learning of Mid-level Features for Pedestrian Attribute Recognition and Localization**\n\n- arxiv: [https://arxiv.org/abs/1611.05603](https://arxiv.org/abs/1611.05603)\n- github: [https://github.com/kyu-sz/WPAL-network](https://github.com/kyu-sz/WPAL-network)\n\n**Deep View-Sensitive Pedestrian Attribute Inference in an end-to-end Model**\n\n- intro: BMVC 2017\n- keywords: PETA, RAP and WIDER\n- arxiv: [https://arxiv.org/abs/1707.06089](https://arxiv.org/abs/1707.06089)\n- github: [https://github.com/asc-kit/vespa](https://github.com/asc-kit/vespa)\n\n**HydraPlus-Net: Attentive Deep Features for Pedestrian Analysis**\n\n- intro: ICCV 2017\n- intro: CUHK & SenseTime\n- keywords: multi-directional attention (MDA)\n- arxiv: [https://arxiv.org/abs/1709.09930](https://arxiv.org/abs/1709.09930)\n- paper: [http://openaccess.thecvf.com/content_ICCV_2017/papers/Liu_HydraPlus-Net_Attentive_Deep_ICCV_2017_paper.pdf](http://openaccess.thecvf.com/content_ICCV_2017/papers/Liu_HydraPlus-Net_Attentive_Deep_ICCV_2017_paper.pdf)\n- github: [https://github.com/xh-liu/HydraPlus-Net](https://github.com/xh-liu/HydraPlus-Net)\n\n**Deep Imbalanced Attribute Classification using Visual Attention Aggregation**\n\n- intro: ECCV 2018\n- intro: University of Houston\n- arxiv: [https://arxiv.org/abs/1807.03903](https://arxiv.org/abs/1807.03903)\n\n**Localization Guided Learning for Pedestrian Attribute Recognition**\n\n- intro: BMVC 2018\n- arxiv: [https://arxiv.org/abs/1808.09102](https://arxiv.org/abs/1808.09102)\n\n**Grouping Attribute Recognition for Pedestrian with Joint Recurrent Learning**\n\n- intro: IJCAI 2018\n- paper: [https://www.ijcai.org/proceedings/2018/0441.pdf](https://www.ijcai.org/proceedings/2018/0441.pdf)\n\n**Sequence-based Person Attribute Recognition with Joint CTC-Attention Model**\n\n- keywords: joint CTC-Attention model (JCM), s connectionist temporal classification (CTC)\n- arxiv: [https://arxiv.org/abs/1811.08115](https://arxiv.org/abs/1811.08115)\n\n**The Deeper, the Better: Analysis of Person Attributes Recognition**\n\n[https://arxiv.org/abs/1901.03756](https://arxiv.org/abs/1901.03756)\n\n**Video-Based Pedestrian Attribute Recognition**\n\n[https://arxiv.org/abs/1901.05742](https://arxiv.org/abs/1901.05742)\n\n**Pedestrian Attribute Recognition: A Survey**\n\n- intro: Anhui University\n- project page: [https://sites.google.com/view/ahu-pedestrianattributes/](https://sites.google.com/view/ahu-pedestrianattributes/)\n- arxiv: [https://arxiv.org/abs/1901.07474](https://arxiv.org/abs/1901.07474)\n\n**Papers with code: Pedestrian Attribute Recognition**\n\n[https://paperswithcode.com/task/pedestrian-attribute-recognition/codeless](https://paperswithcode.com/task/pedestrian-attribute-recognition/codeless)\n\n**Pedestrian-Attribute-Recognition-Paper-List**\n\n[https://github.com/wangxiao5791509/Pedestrian-Attribute-Recognition-Paper-List](https://github.com/wangxiao5791509/Pedestrian-Attribute-Recognition-Paper-List)\n\n**Attribute Aware Pooling for Pedestrian Attribute Recognition**\n\n- intro: IJCAI 2019\n- intro: Huawei Noah’s Ark Lab & University of Sydney\n- arxiv: [https://arxiv.org/abs/1907.11837](https://arxiv.org/abs/1907.11837)\n\n**Distraction-Aware Feature Learning for Human Attribute Recognition via Coarse-to-Fine Attention Mechanism**\n\n- intro: AAAI 2020 oral\n- arxiv: [https://arxiv.org/abs/1911.11351](https://arxiv.org/abs/1911.11351)\n\n**Rethinking of Pedestrian Attribute Recognition: Realistic Datasets with Efficient Method**\n\n- intro: University of Chinese Academy of Sciences & Chinese Academy of Sciences\n- arxiv: [https://arxiv.org/abs/2005.11909](https://arxiv.org/abs/2005.11909)\n- github(official, Pytorch): [https://github.com/valencebond/Strong_Baseline_of_Pedestrian_Attribute_Recognition](https://github.com/valencebond/Strong_Baseline_of_Pedestrian_Attribute_Recognition)\n\n**Hierarchical Feature Embedding for Attribute Recognition**\n\n- intro: SenseTime Group Limited & Tsinghua University\n- arxiv: [https://arxiv.org/abs/2005.11576](https://arxiv.org/abs/2005.11576)\n\n# Clothes Recognition\n\n**DeepFashion: Powering Robust Clothes Recognition and Retrieval with Rich Annotations**\n\n![](http://personal.ie.cuhk.edu.hk/~lz013/projects/deepfashion/intro.png)\n\n- intro: CVPR 2016\n- keywords: FashionNet\n- project page: [http://personal.ie.cuhk.edu.hk/~lz013/projects/DeepFashion.html](http://personal.ie.cuhk.edu.hk/~lz013/projects/DeepFashion.html)\n- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_DeepFashion_Powering_Robust_CVPR_2016_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_DeepFashion_Powering_Robust_CVPR_2016_paper.pdf)\n\n**Multi-Task Curriculum Transfer Deep Learning of Clothing Attributes**\n\n- arxiv: [https://arxiv.org/abs/1610.03670](https://arxiv.org/abs/1610.03670)\n\n# Star-galaxy Classification\n\n**Star-galaxy Classification Using Deep Convolutional Neural Networks**\n\n- intro: MNRAS\n- arxiv: [http://arxiv.org/abs/1608.04369](http://arxiv.org/abs/1608.04369)\n- github: [https://github.com/EdwardJKim/dl4astro](https://github.com/EdwardJKim/dl4astro)\n\n# Logo Recognition\n\n**Deep Learning for Logo Recognition**\n\n- arxiv: [https://arxiv.org/abs/1701.02620](https://arxiv.org/abs/1701.02620)\n\n# Plant Classification\n\n**Large-Scale Plant Classification with Deep Neural Networks**\n\n- intro: Published at Proocedings of ACM Computing Frontiers Conference 2017\n- arxiv: [https://arxiv.org/abs/1706.03736](https://arxiv.org/abs/1706.03736)\n\n# Scene Recognition / Scene Classification\n\n**Learning Deep Features for Scene Recognition using Places Database**\n\n- paper: [http://places.csail.mit.edu/places_NIPS14.pdf](http://places.csail.mit.edu/places_NIPS14.pdf)\n- gihtub: [https://github.com/metalbubble/places365](https://github.com/metalbubble/places365)\n\n**Using neon for Scene Recognition: Mini-Places2**\n\n- intro: This is an implementation of the deep residual network used for \n[Mini-Places2](http://6.869.csail.mit.edu/fa15/project.html) as described in \n[He et. al., \"Deep Residual Learning for Image Recognition\"](http://arxiv.org/abs/1512.03385).\n- blog: [http://www.nervanasys.com/using-neon-for-scene-recognition-mini-places2/](http://www.nervanasys.com/using-neon-for-scene-recognition-mini-places2/)\n- github: [https://github.com/hunterlang/mpmz](https://github.com/hunterlang/mpmz)\n\n**Scene Classification with Inception-7**\n\n- slides: [http://lsun.cs.princeton.edu/slides/Christian.pdf](http://lsun.cs.princeton.edu/slides/Christian.pdf)\n\n**Semantic Clustering for Robust Fine-Grained Scene Recognition**\n\n- arxiv: [http://arxiv.org/abs/1607.07614](http://arxiv.org/abs/1607.07614)\n\n**Scene recognition with CNNs: objects, scales and dataset bias**\n\n- intro: CVPR 2016\n- arxiv: [https://arxiv.org/abs/1801.06867](https://arxiv.org/abs/1801.06867)\n\n## Leaderboard\n\n**Leaderboard of Places Database**\n\n- intro: currently rank1: Qian Zhang(Beijing Samsung Telecom R&D Center), 0.6410@top1, 0.9065@top5\n- homepage: [http://places.csail.mit.edu/user/leaderboard.php](http://places.csail.mit.edu/user/leaderboard.php)\n\n# Blogs\n\n**What is the class of this image ? - Discover the current state of the art in objects classification**\n\n- intro: \"Discover the current state of the art in objects classification.\"\n- intro: MNIST, CIFAR-10, CIFAR-100, STL-10, SVHN, ILSVRC2012 task 1\n- blog: [http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html)\n\n**Object Recognition with Convolutional Neural Networks in the Keras Deep Learning Library**\n\n[http://machinelearningmastery.com/object-recognition-convolutional-neural-networks-keras-deep-learning-library/](http://machinelearningmastery.com/object-recognition-convolutional-neural-networks-keras-deep-learning-library/)\n\n**The Effect of Resolution on Deep Neural Network Image Classification Accuracy**\n\n![](https://cdn-images-1.medium.com/max/800/1*0SBEYOChCOMbqnGG34xSxw.png)\n\n[https://medium.com/the-downlinq/the-effect-of-resolution-on-deep-neural-network-image-classification-accuracy-d1338e2782c5#.em5rk991r](https://medium.com/the-downlinq/the-effect-of-resolution-on-deep-neural-network-image-classification-accuracy-d1338e2782c5#.em5rk991r)\n","excerpt":"Papers DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition auothor: Jeff Donahue, Yangqing Jia, Oriol Vinyals, Ju…","outboundReferences":[],"inboundReferences":[]},"tagsOutbound":{"nodes":[]}},"pageContext":{"tags":[],"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recognition/","sidebarItems":[{"title":"Categories","items":[{"title":"Commercial","url":"","items":[{"title":"Commercial Structure","url":"/Commercial/Commercial Structure/","items":[]},{"title":"Community of Practice","url":"/Commercial/Community of Practice/","items":[]},{"title":"Domains","url":"/Commercial/Domains/","items":[]},{"title":"Webizen Alliance","url":"/Commercial/Webizen Alliance/","items":[]}]},{"title":"Core Services","url":"","items":[{"title":"Decentralised Ontologies","url":"/Core Services/Decentralised Ontologies/","items":[]},{"title":"Permissive Commons","url":"/Core Services/Permissive Commons/","items":[]},{"title":"Safety Protocols","url":"","items":[{"title":"Safety Protocols","url":"/Core Services/Safety Protocols/Safety Protocols/","items":[]},{"title":"Social Factors","url":"","items":[{"title":"Best Efforts","url":"/Core Services/Safety Protocols/Social Factors/Best Efforts/","items":[]},{"title":"Ending Digital Slavery","url":"/Core Services/Safety Protocols/Social Factors/Ending Digital Slavery/","items":[]},{"title":"Freedom of Thought","url":"/Core Services/Safety Protocols/Social Factors/Freedom of Thought/","items":[]},{"title":"No Golden Handcuffs","url":"/Core Services/Safety Protocols/Social Factors/No Golden Handcuffs/","items":[]},{"title":"Relationships (Social)","url":"/Core Services/Safety Protocols/Social Factors/Relationships (Social)/","items":[]},{"title":"Social Attack Vectors","url":"/Core Services/Safety Protocols/Social Factors/Social Attack Vectors/","items":[]},{"title":"The Webizen Charter","url":"/Core Services/Safety Protocols/Social Factors/The Webizen Charter/","items":[]}]},{"title":"Values Credentials","url":"/Core Services/Safety Protocols/Values Credentials/","items":[]}]},{"title":"Temporal Semantics","url":"/Core Services/Temporal Semantics/","items":[]},{"title":"Verifiable Claims & Credentials","url":"/Core Services/Verifiable Claims & Credentials/","items":[]},{"title":"Webizen Socio-Economics","url":"","items":[{"title":"Biosphere Ontologies","url":"/Core Services/Webizen Socio-Economics/Biosphere Ontologies/","items":[]},{"title":"Centricity","url":"/Core Services/Webizen Socio-Economics/Centricity/","items":[]},{"title":"Currencies","url":"/Core Services/Webizen Socio-Economics/Currencies/","items":[]},{"title":"SocioSphere Ontologies","url":"/Core Services/Webizen Socio-Economics/SocioSphere Ontologies/","items":[]},{"title":"Sustainable Development Goals (ESG)","url":"/Core Services/Webizen Socio-Economics/Sustainable Development Goals (ESG)/","items":[]}]}]},{"title":"Core Technologies","url":"","items":[{"title":"AUTH","url":"","items":[{"title":"Authentication Fabric","url":"/Core Technologies/AUTH/Authentication Fabric/","items":[]}]},{"title":"Webizen App Spec","url":"","items":[{"title":"SemWebSpecs","url":"","items":[{"title":"Core Ontologies","url":"","items":[{"title":"FOAF","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/FOAF/","items":[]},{"title":"General Ontology Information","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/General Ontology Information/","items":[]},{"title":"Human Rights Ontologies","url":"","items":[{"title":"UDHR","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/Human Rights Ontologies/UDHR/","items":[]}]},{"title":"MD-RDF Ontologies","url":"","items":[{"title":"DataTypesOntology (DTO) Core","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/MD-RDF Ontologies/DataTypes Ontology/","items":[]},{"title":"Friend of a Friend (FOAF) Core","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/MD-RDF Ontologies/FOAF/","items":[]}]},{"title":"OWL","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/OWL/","items":[]},{"title":"RDF Schema 1.1","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/RDFS/","items":[]},{"title":"Sitemap","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/Sitemap/","items":[]},{"title":"SKOS","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/SKOS/","items":[]},{"title":"SOIC","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/SOIC/","items":[]}]},{"title":"Semantic Web - An Introduction","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Semantic Web - An Introduction/","items":[]},{"title":"SemWeb-AUTH","url":"","items":[{"title":"WebID-OIDC","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-OIDC/","items":[]},{"title":"WebID-RSA","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-RSA/","items":[]},{"title":"WebID-TLS","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-TLS/","items":[]}]},{"title":"Sparql","url":"","items":[{"title":"Sparql Family","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Sparql/Sparql Family/","items":[]}]},{"title":"W3C Specifications","url":"","items":[{"title":"Linked Data Fragments","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Fragments/","items":[]},{"title":"Linked Data Notifications","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Notifications/","items":[]},{"title":"Linked Data Platform","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Platform/","items":[]},{"title":"Linked Media Fragments","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Media Fragments/","items":[]},{"title":"RDF","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/RDF/","items":[]},{"title":"Web Access Control (WAC)","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Web Access Control (WAC)/","items":[]},{"title":"Web Of Things","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Web Of Things/","items":[]},{"title":"WebID","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/WebID/","items":[]}]}]},{"title":"Webizen App Spec 1.0","url":"/Core Technologies/Webizen App Spec/Webizen App Spec 1.0/","items":[]},{"title":"WebSpec","url":"","items":[{"title":"HTML SPECS","url":"/Core Technologies/Webizen App Spec/WebSpec/HTML SPECS/","items":[]},{"title":"Query Interfaces","url":"","items":[{"title":"GraphQL","url":"/Core Technologies/Webizen App Spec/WebSpec/Query Interfaces/GraphQL/","items":[]}]},{"title":"WebPlatformTools","url":"","items":[{"title":"WebAuthn","url":"/Core Technologies/Webizen App Spec/WebSpec/WebPlatformTools/WebAuthn/","items":[]},{"title":"WebDav","url":"/Core Technologies/Webizen App Spec/WebSpec/WebPlatformTools/WebDav/","items":[]}]}]}]}]},{"title":"Database Requirements","url":"","items":[{"title":"Database Alternatives","url":"","items":[{"title":"Akutan","url":"/Database requirements/Database Alternatives/akutan/","items":[]},{"title":"CayleyGraph","url":"/Database requirements/Database Alternatives/CayleyGraph/","items":[]}]},{"title":"Database Methods","url":"","items":[{"title":"GraphQL","url":"/Database requirements/Database methods/GraphQL/","items":[]},{"title":"Sparql","url":"/Database requirements/Database methods/Sparql/","items":[]}]}]},{"title":"Host Service Requirements","url":"","items":[{"title":"Domain Hosting","url":"/Host Service Requirements/Domain Hosting/","items":[]},{"title":"Email Services","url":"/Host Service Requirements/Email Services/","items":[]},{"title":"LD_PostOffice_SemanticMGR","url":"/Host Service Requirements/LD_PostOffice_SemanticMGR/","items":[]},{"title":"Media Processing","url":"/Host Service Requirements/Media Processing/","items":[{"title":"Ffmpeg","url":"/Host Service Requirements/Media Processing/ffmpeg/","items":[]},{"title":"Opencv","url":"/Host Service Requirements/Media Processing/opencv/","items":[]}]},{"title":"Website Host","url":"/Host Service Requirements/Website Host/","items":[]}]},{"title":"ICT Stack","url":"","items":[{"title":"General References","url":"","items":[{"title":"List of Protocols ISO Model","url":"/ICT Stack/General References/List of Protocols ISO model/","items":[]}]},{"title":"Internet","url":"","items":[{"title":"Internet Stack","url":"/ICT Stack/Internet/Internet Stack/","items":[]}]}]},{"title":"Implementation V1","url":"","items":[{"title":"App-Design-Sdk-V1","url":"","items":[{"title":"Core Apps","url":"","items":[{"title":"Agent Directory","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Agent Directory/","items":[]},{"title":"Credentials & Contracts Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Credentials & Contracts Manager/","items":[]},{"title":"File (Package) Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/File (package) Manager/","items":[]},{"title":"Temporal Apps","url":"","items":[{"title":"Calendar","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Temporal Apps/Calendar/","items":[]},{"title":"Timeline Interface","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Temporal Apps/Timeline Interface/","items":[]}]},{"title":"Webizen Apps (V1)","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Webizen Apps (v1)/","items":[]},{"title":"Webizen Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Webizen Manager/","items":[]}]},{"title":"Data Applications","url":"/Implementation V1/App-design-sdk-v1/Data Applications/","items":[]},{"title":"Design Goals","url":"","items":[{"title":"Design Goals Overview","url":"/Implementation V1/App-design-sdk-v1/Design Goals/Design Goals Overview/","items":[]}]}]},{"title":"Edge","url":"","items":[{"title":"Webizen Local App Functionality","url":"/Implementation V1/edge/Webizen Local App Functionality/","items":[]}]},{"title":"GoLang Libraries","url":"/Implementation V1/GoLang Libraries/","items":[]},{"title":"Implementation V1 Summary","url":"/Implementation V1/Implementation V1 Summary/","items":[]},{"title":"Vps","url":"","items":[{"title":"Server Functionality Summary (VPS)","url":"/Implementation V1/vps/Server Functionality Summary (VPS)/","items":[]}]},{"title":"Webizen 1.0","url":"/Implementation V1/Webizen 1.0/","items":[]},{"title":"Webizen-Connect","url":"","items":[{"title":"Social Media APIs","url":"/Implementation V1/Webizen-Connect/Social Media APIs/","items":[]},{"title":"Webizen-Connect (Summary)","url":"/Implementation V1/Webizen-Connect/Webizen-Connect (summary)/","items":[]}]}]},{"title":"Non-HTTP(s) Protocols","url":"","items":[{"title":"DAT","url":"/Non-HTTP(s) Protocols/DAT/","items":[]},{"title":"GIT","url":"/Non-HTTP(s) Protocols/GIT/","items":[]},{"title":"GUNECO","url":"/Non-HTTP(s) Protocols/GUNECO/","items":[]},{"title":"IPFS","url":"/Non-HTTP(s) Protocols/IPFS/","items":[]},{"title":"Lightning Network","url":"/Non-HTTP(s) Protocols/Lightning Network/","items":[]},{"title":"Non-HTTP(s) Protocols (& DLTs)","url":"/Non-HTTP(s) Protocols/Non-HTTP(s) Protocols (& DLTs)/","items":[]},{"title":"WebRTC","url":"/Non-HTTP(s) Protocols/WebRTC/","items":[]},{"title":"WebSockets","url":"/Non-HTTP(s) Protocols/WebSockets/","items":[]},{"title":"WebTorrent","url":"/Non-HTTP(s) Protocols/WebTorrent/","items":[]}]},{"title":"Old-Work-Archives","url":"","items":[{"title":"2018-Webizen-Net-Au","url":"","items":[{"title":"_Link_library_links","url":"","items":[{"title":"Link Library","url":"/old-work-archives/2018-webizen-net-au/_link_library_links/2018-09-23-wp-linked-data/","items":[]}]},{"title":"_Posts","url":"","items":[{"title":"About W3C","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-27-about-w3c/","items":[]},{"title":"Advanced Functions &#8211; Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-16-advanced-functions-facebook-pages/","items":[]},{"title":"Advanced Search &#038; Discovery Tips","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-advanced-search-discovery-tips/","items":[]},{"title":"An introduction to Virtual Machines.","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-an-introduction-to-virtual-machines/","items":[]},{"title":"Basic Media Analysis &#8211; Part 1 (Audio)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-30-media-analysis-part-1-audio/","items":[]},{"title":"Basic Media Analysis &#8211; Part 2 (visual)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-31-media-analysis-part-2-visual/","items":[]},{"title":"Basic Media Analysis &#8211; Part 3 (Text &#038; Metadata)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-01-01-basic-media-analysis-part-3-text-metadata/","items":[]},{"title":"Building an Economy based upon Knowledge Equity.","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-25-building-an-economy-based-upon-knowledge-equity/","items":[]},{"title":"Choice of Law","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-26-choice-of-law/","items":[]},{"title":"Contemplation of the ITU Dubai Meeting and the Future of the Internet","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-19-contemplation-of-the-itu-dubai-meeting-and-the-future-of-the-internet/","items":[]},{"title":"Creating a Presence &#8211; Online","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-creating-a-presence-online/","items":[]},{"title":"Credentials and Payments by Manu Sporny","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-credentials-and-payments-by-manu-sporny/","items":[]},{"title":"Data Recovery &#038; Collection: Mobile Devices","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-28-mobile-devices-data-recovery-collection/","items":[]},{"title":"Data Recovery: Laptop &#038; Computers","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-28-data-recovery-laptop-computers/","items":[]},{"title":"Decentralized Web Conference 2016","url":"/old-work-archives/2018-webizen-net-au/_posts/2016-06-09-decentralized-web-2016/","items":[]},{"title":"Decentralized Web Summit 2018","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-decentralized-web-summit-2018/","items":[]},{"title":"Does Anonymity exist?","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-does-anonymity-exist/","items":[]},{"title":"Downloading My Data from Social Networks","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-downloading-my-data-from-social-networks/","items":[]},{"title":"Events","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-events/","items":[]},{"title":"Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-16-facebook-pages/","items":[]},{"title":"Google Tracking Data (geolocation)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-google-tracking/","items":[]},{"title":"Human Consciousness","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-human-consciousness/","items":[]},{"title":"Image Recgonition Video Playlist","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-image-recgonition-video-playlist/","items":[]},{"title":"Inferencing (introduction)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-inferencing-introduction/","items":[]},{"title":"Introduction to AI","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-introduction-to-ai/","items":[]},{"title":"Introduction to Linked Data","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-introduction-to-linked-data/","items":[]},{"title":"Introduction to Maltego","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-introduction-to-maltego/","items":[]},{"title":"Introduction to Ontologies","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-ontologies-intro/","items":[]},{"title":"Introduction to Semantic Web","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-introduction-to-semantic-web/","items":[]},{"title":"Knowledge Capital","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-10-17-knowledge-capital/","items":[]},{"title":"Logo&#8217;s, Style Guides and Artwork","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-logos-style-guides-and-artwork/","items":[]},{"title":"MindMapping &#8211; Setting-up a business &#8211; Identity","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-mindmapping-setting-up-a-business-identity/","items":[]},{"title":"Openlink Virtuoso","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-openlink-virtuoso/","items":[]},{"title":"OpenRefine","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-74-2/","items":[]},{"title":"Projects, Customers and Invoicing &#8211; Web-Services for Startups","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-projects-customers-and-invoicing-web-services-for-startups/","items":[]},{"title":"RWW &#038; some Solid history","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-rww-some-solid-history/","items":[]},{"title":"Semantic Web (An Intro)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-semantic-web-an-intro/","items":[]},{"title":"Setting-up Twitter","url":"/old-work-archives/2018-webizen-net-au/_posts/2013-06-07-setting-up-twitter/","items":[]},{"title":"Social Encryption: An Introduction","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-25-social-encryption-an-introduction/","items":[]},{"title":"Stock Content","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-stock-content/","items":[]},{"title":"The WayBack Machine","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-27-the-wayback-machine/","items":[]},{"title":"Tim Berners Lee &#8211; Turing Lecture","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-05-29-tim-berners-lee-turing-lecture/","items":[]},{"title":"Tools of Trade","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-tools-of-trade/","items":[]},{"title":"Trust Factory 2017","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-trust-factory-2017/","items":[]},{"title":"Verifiable Claims (An Introduction)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-vc-intro/","items":[]},{"title":"Web of Things &#8211; an Introduction","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-web-of-things-an-introduction/","items":[]},{"title":"Web-Persistence","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-web-persistence/","items":[]},{"title":"Web-Services &#8211; Marketing Tools","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-web-services-marketing-tools/","items":[]},{"title":"Website Templates","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-templates/","items":[]},{"title":"What is Linked Data?","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-what-is-linked-data/","items":[]},{"title":"What is Open Source Intelligence?","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-what-is-osint/","items":[]},{"title":"WiX","url":"/old-work-archives/2018-webizen-net-au/_posts/2013-01-01-wix/","items":[]}]},{"title":"about","url":"/old-work-archives/2018-webizen-net-au/about/","items":[{"title":"About The Author","url":"/old-work-archives/2018-webizen-net-au/about/about-the-author/","items":[]},{"title":"Applied Theory: Applications for a Human Centric Web","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/","items":[{"title":"Digital Receipts","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/digital-receipts/","items":[]},{"title":"Fake News: Considerations → Principles → The Institution of Socio &#8211; Economic Values","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations/","items":[]},{"title":"Healthy Living Economy","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/healthy-living-economy/","items":[]},{"title":"HyperMedia Solutions &#8211; Adapting HbbTV V2","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/","items":[{"title":"HYPERMEDIA PACKAGES","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/hypermedia-packages/","items":[]},{"title":"USER STORIES: INTERACTIVE VIEWING EXPERIENCE","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/user-stories-interactive-viewing-experience/","items":[]}]},{"title":"Measurements App","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/measurements-app/","items":[]},{"title":"Re:Animation","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/reanimation/","items":[]},{"title":"Solutions to FakeNews: Linked-Data, Ontologies and Verifiable Claims","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/ld-solutions-to-fakenews/","items":[]}]},{"title":"Executive Summary","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/","items":[{"title":"Assisting those who Enforce the Law","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/assisting-those-who-enforce-the-law/","items":[]},{"title":"Consumer Protections","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/consumer-protections/","items":[]},{"title":"Knowledge Banking: Legal Structures","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-banking-legal-structures/","items":[]},{"title":"Knowledge Economics &#8211; Services","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-economics-services/","items":[]},{"title":"Preserving The Freedom to Think","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/preserving-the-freedom-to-think/","items":[]}]},{"title":"History","url":"/old-work-archives/2018-webizen-net-au/about/history/","items":[{"title":"History: Global Governance and ICT.","url":"/old-work-archives/2018-webizen-net-au/about/history/history-global-governance-ict-1/","items":[]}]},{"title":"Knowledge Banking: A Technical Architecture Summary","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/","items":[{"title":"An introduction to Credentials.","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/","items":[{"title":"credentials and custodianship","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/credentials-and-custodianship/","items":[]},{"title":"DIDs and MultiSig","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/dids-and-multisig/","items":[]}]},{"title":"Personal Augmentation of AI","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/personal-augmentation-of-ai/","items":[]},{"title":"Semantic Inferencing","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/semantic-inferencing/","items":[]},{"title":"Web of Things (IoT+LD)","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/web-of-things-iotld/","items":[]}]},{"title":"References","url":"/old-work-archives/2018-webizen-net-au/about/references/","items":[{"title":"Making the distinction between ‘privacy’ and ‘dignity’.","url":"/old-work-archives/2018-webizen-net-au/about/references/privacy-vs-dignity/","items":[]},{"title":"Roles &#8211; Entity Analysis","url":"/old-work-archives/2018-webizen-net-au/about/references/roles-entity-analysis/","items":[]},{"title":"Social Informatics Design Considerations","url":"/old-work-archives/2018-webizen-net-au/about/references/social-informatics-design-concept-and-principles/","items":[]},{"title":"Socio-economic relations | A conceptual model","url":"/old-work-archives/2018-webizen-net-au/about/references/socioeconomic-relations-p1/","items":[]},{"title":"The need for decentralised Open (Linked) Data","url":"/old-work-archives/2018-webizen-net-au/about/references/the-need-for-decentralised-open-linked-data/","items":[]}]},{"title":"The design of new medium","url":"/old-work-archives/2018-webizen-net-au/about/the-design-of-new-medium/","items":[]},{"title":"The need to modernise socioeconomic infrastructure","url":"/old-work-archives/2018-webizen-net-au/about/the-modernisation-of-socioeconomics/","items":[]},{"title":"The Vision","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/","items":[{"title":"Domesticating Pervasive Surveillance","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/a-technical-vision/","items":[]}]}]},{"title":"An Overview","url":"/old-work-archives/2018-webizen-net-au/the-human-centric-infosphere/","items":[]},{"title":"Embed Link","url":"/old-work-archives/2018-webizen-net-au/embed-link/","items":[]},{"title":"Posts","url":"/old-work-archives/2018-webizen-net-au/posts/","items":[]},{"title":"Privacy Policy","url":"/old-work-archives/2018-webizen-net-au/privacy-policy/","items":[]},{"title":"Resource Library","url":"/old-work-archives/2018-webizen-net-au/resource-library/","items":[{"title":"Handong1587","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/","items":[{"title":"_Posts","url":"","items":[{"title":"Computer_science","url":"","items":[{"title":"Algorithm and Data Structure Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-algo-resourses/","items":[]},{"title":"Artificial Intelligence Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-ai-resources/","items":[]},{"title":"Big Data Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-09-22-big-data-resources/","items":[]},{"title":"Computer Science Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-cs-resources/","items":[]},{"title":"Data Mining Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-data-mining-resources/","items":[]},{"title":"Data Science Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-data-science-resources/","items":[]},{"title":"Database Systems Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-database-resources/","items":[]},{"title":"Discrete Optimization Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-discrete-optimization/","items":[]},{"title":"Distribued System Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-12-12-ditributed-system-resources/","items":[]},{"title":"Funny Stuffs Of Computer Science","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-11-18-funny-stuffs-of-cs/","items":[]},{"title":"Robotics","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-09-26-robotics-resources/","items":[]},{"title":"Writting CS Papers","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-11-30-writing-papers/","items":[]}]},{"title":"Computer_vision","url":"","items":[{"title":"Computer Vision Datasets","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-24-datasets/","items":[]},{"title":"Computer Vision Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-12-cv-resources/","items":[]},{"title":"Features","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-10-09-features/","items":[]},{"title":"Recognition, Detection, Segmentation and Tracking","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-10-09-recognition-detection-segmentation-tracking/","items":[]},{"title":"Use FFmpeg to Capture I Frames of Video","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2016-03-03-ffmpeg-i-frame/","items":[]},{"title":"Working on OpenCV","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-12-25-working-on-opencv/","items":[]}]},{"title":"Deep_learning","url":"","items":[{"title":"3D","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2021-07-28-3d/","items":[]},{"title":"Acceleration and Model Compression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-cnn-compression-acceleration/","items":[]},{"title":"Acceleration and Model Compression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-knowledge-distillation/","items":[]},{"title":"Adversarial Attacks and Defences","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-adversarial-attacks-and-defences/","items":[]},{"title":"Audio / Image / Video Generation","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-audio-image-video-generation/","items":[]},{"title":"BEV","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2022-06-27-bev/","items":[]},{"title":"Classification / Recognition","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recognition/","items":[]},{"title":"Deep Learning and Autonomous Driving","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-autonomous-driving/","items":[]},{"title":"Deep Learning Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-pose-estimation/","items":[]},{"title":"Deep Learning Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-applications/","items":[]},{"title":"Deep learning Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-courses/","items":[]},{"title":"Deep Learning Frameworks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-frameworks/","items":[]},{"title":"Deep Learning Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-resources/","items":[]},{"title":"Deep Learning Software and Hardware","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-software-hardware/","items":[]},{"title":"Deep Learning Tricks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tricks/","items":[]},{"title":"Deep Learning Tutorials","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tutorials/","items":[]},{"title":"Deep Learning with Machine Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-with-ml/","items":[]},{"title":"Face Recognition","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-face-recognition/","items":[]},{"title":"Fun With Deep Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-fun-with-deep-learning/","items":[]},{"title":"Generative Adversarial Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gan/","items":[]},{"title":"Graph Convolutional Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gcn/","items":[]},{"title":"Image / Video Captioning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-captioning/","items":[]},{"title":"Image Retrieval","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-retrieval/","items":[]},{"title":"Keep Up With New Trends","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2018-09-03-keep-up-with-new-trends/","items":[]},{"title":"LiDAR 3D Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-lidar-3d-detection/","items":[]},{"title":"Natural Language Processing","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nlp/","items":[]},{"title":"Neural Architecture Search","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nas/","items":[]},{"title":"Object Counting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-counting/","items":[]},{"title":"Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-detection/","items":[]},{"title":"OCR","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-ocr/","items":[]},{"title":"Optical Flow","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-optical-flow/","items":[]},{"title":"Re-ID","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-re-id/","items":[]},{"title":"Recommendation System","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recommendation-system/","items":[]},{"title":"Reinforcement Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rl/","items":[]},{"title":"RNN and LSTM","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rnn-and-lstm/","items":[]},{"title":"Segmentation","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-segmentation/","items":[]},{"title":"Style Transfer","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-style-transfer/","items":[]},{"title":"Super-Resolution","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-super-resolution/","items":[]},{"title":"Tracking","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-tracking/","items":[]},{"title":"Training Deep Neural Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-training-dnn/","items":[]},{"title":"Transfer Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-transfer-learning/","items":[]},{"title":"Unsupervised Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-unsupervised-learning/","items":[]},{"title":"Video Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-video-applications/","items":[]},{"title":"Visual Question Answering","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-vqa/","items":[]},{"title":"Visualizing and Interpreting Convolutional Neural Network","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-visulizing-interpreting-cnn/","items":[]}]},{"title":"Leisure","url":"","items":[{"title":"All About Enya","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-all-about-enya/","items":[]},{"title":"Coldplay","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-coldplay/","items":[]},{"title":"Coldplay","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-nightwish/","items":[]},{"title":"Games","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-13-games/","items":[]},{"title":"Green Day","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-greenday/","items":[]},{"title":"Muse! Muse!","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-muse-muse/","items":[]},{"title":"Oasis","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-oasis/","items":[]},{"title":"Paintings By J.M.","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2016-03-08-paintings-by-jm/","items":[]},{"title":"Papers, Blogs and Websites","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-09-27-papers-blogs-and-websites/","items":[]},{"title":"Welcome To The Black Parade","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-welcome-to-the-black-parade/","items":[]}]},{"title":"Machine_learning","url":"","items":[{"title":"Bayesian Methods","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-bayesian-methods/","items":[]},{"title":"Clustering Algorithms Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-clustering/","items":[]},{"title":"Competitions","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-competitions/","items":[]},{"title":"Dimensionality Reduction Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-dimensionality-reduction/","items":[]},{"title":"Fun With Machine Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-fun-with-ml/","items":[]},{"title":"Graphical Models Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-graphical-models/","items":[]},{"title":"Machine Learning Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-ml-courses/","items":[]},{"title":"Machine Learning Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-ml-resources/","items":[]},{"title":"Natural Language Processing","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-nlp/","items":[]},{"title":"Neural Network","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-neural-network/","items":[]},{"title":"Random Field","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-random-field/","items":[]},{"title":"Random Forests","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-random-forests/","items":[]},{"title":"Regression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-regression/","items":[]},{"title":"Support Vector Machine","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-svm/","items":[]},{"title":"Topic Model","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-topic-model/","items":[]}]},{"title":"Mathematics","url":"","items":[{"title":"Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/mathematics/2016-02-24-resources/","items":[]}]},{"title":"Programming_study","url":"","items":[{"title":"Add Lunr Search Plugin For Blog","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-31-add-lunr-search-plugin-for-blog/","items":[]},{"title":"Android Development Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-05-23-android-resources/","items":[]},{"title":"C++ Programming Solutions","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-09-07-cpp-programming-solutions/","items":[]},{"title":"Commands To Suppress Some Building Errors With Visual Studio","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-24-cmds-to-suppress-some-vs-building-Errors/","items":[]},{"title":"Embedding Python In C/C++","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-10-embedding-python-in-cpp/","items":[]},{"title":"Enable Large Addresses On VS2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-12-14-enable-large-addresses/","items":[]},{"title":"Fix min/max Error In VS2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-02-17-min-max-error-in-vs2015/","items":[]},{"title":"Gflags Build Problems on Windows X86 and Visual Studio 2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-23-gflags-build-problems-winx86-vs2015/","items":[]},{"title":"Glog Build Problems on Windows X86 and Visual Studio 2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-23-glog-build-problems-winx86/","items":[]},{"title":"Horrible Wired Errors Come From Simple Stupid Mistake","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-16-horrible-wired-errors-come-from-simple-stupid-mistake/","items":[]},{"title":"Install Jekyll To Fix Some Local Github-pages Defects","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-11-21-install-jekyll/","items":[]},{"title":"Install Therubyracer Failure","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-03-install-therubyracer/","items":[]},{"title":"Notes On Valgrind and Others","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-05-30-notes-on-valgrind/","items":[]},{"title":"PHP Hello World","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-04-php-hello-world/","items":[]},{"title":"Programming Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-07-01-programming-resources/","items":[]},{"title":"PyInstsaller and Others","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-12-24-pyinstaller-and-others/","items":[]},{"title":"Web Development Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-06-21-web-dev-resources/","items":[]},{"title":"Working on Visual Studio","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-04-03-working-on-vs/","items":[]}]},{"title":"Reading_and_thoughts","url":"","items":[{"title":"Book Reading List","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2015-12-04-book-reading-list/","items":[]},{"title":"Funny Papers","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2015-12-04-funny-papers/","items":[]},{"title":"Reading Materials","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2016-01-18-reading-materials/","items":[]}]},{"title":"Study","url":"","items":[{"title":"Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2017-11-28-courses/","items":[]},{"title":"Essay Writting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2016-01-11-essay-writting/","items":[]},{"title":"Job Hunting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2016-06-02-job-hunting/","items":[]},{"title":"Study Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2018-04-18-resources/","items":[]}]},{"title":"Working_on_linux","url":"","items":[{"title":"Create Multiple Forks of a GitHub Repo","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-12-18-create-multi-forks/","items":[]},{"title":"Linux Git Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-08-02-linux-git/","items":[]},{"title":"Linux Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-07-24-linux-resources/","items":[]},{"title":"Linux SVN Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-08-03-linux-svn/","items":[]},{"title":"Setup vsftpd on Ubuntu 14.10","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2016-07-27-setup-vsftpd/","items":[]},{"title":"Useful Linux Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-07-25-useful-linux-commands/","items":[]},{"title":"vsftpd Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2016-07-28-vsftpd-cmd/","items":[]}]},{"title":"Working_on_mac","url":"","items":[{"title":"Mac Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_mac/2015-07-25-mac-resources/","items":[]}]},{"title":"Working_on_windows","url":"","items":[{"title":"FFmpeg Collection of Utility Methods","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2016-06-05-ffmpeg-utilities/","items":[]},{"title":"Windows Commands and Utilities","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2015-10-27-windows-cmds-utils/","items":[]},{"title":"Windows Dev Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2015-10-27-resources/","items":[]}]}]},{"title":"Drafts","url":"","items":[{"title":"2016-12-30-Setup-Opengrok","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-12-30-setup-opengrok/","items":[]},{"title":"2017-01-20-Packing-C++-Project-to-Single-Executable","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2017-01-20-packing-c++-project-to-single-executable/","items":[]},{"title":"Notes On Caffe Development","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-10-notes-on-caffe-dev/","items":[]},{"title":"Notes On Deep Learning Training","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-12-notes-on-dl-training/","items":[]},{"title":"Notes On Discrete Optimization","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-13-notes-on-discrete-optimization/","items":[]},{"title":"Notes On Gecode","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-13-notes-on-gecode/","items":[]},{"title":"Notes On Inside-Outside Net","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-28-notes-on-ion/","items":[]},{"title":"Notes On K-Means","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-06-notes-on-kmeans/","items":[]},{"title":"Notes On L-BFGS","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-07-notes-on-l-bfgs/","items":[]},{"title":"Notes On Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-04-notes-on-object-detection/","items":[]},{"title":"Notes On Perceptrons","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-10-07-notes-on-perceptrons/","items":[]},{"title":"Notes On Quantized Convolutional Neural Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-07-notes-on-quantized-cnn/","items":[]},{"title":"Notes On Stanford CS2321n","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-02-21-notes-on-cs231n/","items":[]},{"title":"Notes on Suffix Array and Manacher Algorithm","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-08-27-notes-on-suffix-array-and-manacher-algorithm/","items":[]},{"title":"Notes On Tensorflow Development","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2017-04-13-notes-on-tensorflow-dev/","items":[]},{"title":"Notes On YOLO","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-14-notes-on-yolo/","items":[]},{"title":"PASCAL VOC (20) / COCO (80) / ImageNet (200) Detection Categories","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-12-23-imagenet-det-cat/","items":[]},{"title":"Softmax Vs Logistic Vs Sigmoid","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-10-softmax-logistic-sigmoid/","items":[]},{"title":"Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognititon","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-08-31-model-ensemble-of-deteciton/","items":[]}]}]}]}]}]},{"title":"Webizen 2.0","url":"","items":[{"title":"AI Capabilities","url":"","items":[{"title":"AI Capabilities Objectives","url":"/Webizen 2.0/AI Capabilities/AI Capabilities Objectives/","items":[]},{"title":"Audio & Video Analysis","url":"/Webizen 2.0/AI Capabilities/Audio & Video Analysis/","items":[]},{"title":"Image Analysis","url":"/Webizen 2.0/AI Capabilities/Image Analysis/","items":[]},{"title":"Text Analysis","url":"/Webizen 2.0/AI Capabilities/Text Analysis/","items":[]}]},{"title":"LOD-a-lot","url":"/Webizen 2.0/AI Related Links & Notes/","items":[]},{"title":"Mobile Apps","url":"","items":[{"title":"Android","url":"/Webizen 2.0/Mobile Apps/Android/","items":[]},{"title":"General Mobile Architecture","url":"/Webizen 2.0/Mobile Apps/General Mobile Architecture/","items":[]},{"title":"iOS","url":"/Webizen 2.0/Mobile Apps/iOS/","items":[]}]},{"title":"Web Of Things (IoT)","url":"","items":[{"title":"Web Of Things (IoT)","url":"/Webizen 2.0/Web Of Things (IoT)/Web Of Things (IoT)/","items":[]}]},{"title":"Webizen 2.0","url":"/Webizen 2.0/Webizen 2.0/","items":[]},{"title":"Webizen AI OS Platform","url":"/Webizen 2.0/Webizen AI OS Platform/","items":[]},{"title":"Webizen Pro Summary","url":"/Webizen 2.0/Webizen Pro Summary/","items":[]}]},{"title":"Webizen V1 Project Documentation","url":"/","items":[]}]}],"tagsGroups":[],"latestPosts":[{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/ld-solutions-to-fakenews/","title":"Solutions to FakeNews: Linked-Data, Ontologies and Verifiable Claims","lastUpdatedAt":"2022-12-28T19:34:43.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations/","title":"Fake News: Considerations → Principles → The Institution of Socio &#8211; Economic Values","lastUpdatedAt":"2022-12-28T19:29:53.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/","title":"Handong1587","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-08-27-notes-on-suffix-array-and-manacher-algorithm/","title":"Notes on Suffix Array and Manacher Algorithm","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-10-07-notes-on-perceptrons/","title":"Notes On Perceptrons","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-04-notes-on-object-detection/","title":"Notes On Object Detection","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-10-notes-on-caffe-dev/","title":"Notes On Caffe Development","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-07-notes-on-l-bfgs/","title":"Notes On L-BFGS","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-10-softmax-logistic-sigmoid/","title":"Softmax Vs Logistic Vs Sigmoid","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-12-notes-on-dl-training/","title":"Notes On Deep Learning Training","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}