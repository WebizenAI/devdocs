{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-pose-estimation/",
    "result": {"data":{"mdx":{"id":"84b76199-35fb-5d1d-a371-3ffb1bb45f17","tableOfContents":{"items":[{"url":"#papers","title":"Papers","items":[{"url":"#cpm","title":"CPM"},{"url":"#alphapose","title":"AlphaPose"}]},{"url":"#regression-based-method","title":"Regression-based Method"},{"url":"#top-down","title":"Top-Down"},{"url":"#bottom-up","title":"Bottom-Up"},{"url":"#hand-pose","title":"Hand Pose"},{"url":"#3d-pose","title":"3D Pose"},{"url":"#3d-car-keypoints-detection","title":"3D Car keypoints Detection"},{"url":"#pose-estimation-and-action-recognition","title":"Pose Estimation and Action Recognition"},{"url":"#pose-tracking","title":"Pose Tracking"},{"url":"#object-pose-estimation","title":"Object Pose Estimation"},{"url":"#projects","title":"Projects"},{"url":"#challenge","title":"Challenge"}]},"fields":{"title":"Deep Learning Applications","slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-pose-estimation/","url":"https://devdocs.webizen.org/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-pose-estimation/","editUrl":"https://github.com/webizenai/devdocs/tree/main/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-pose-estimation.md","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022","gitCreatedAt":"2022-12-28T19:22:29.000Z","shouldShowTitle":true},"frontmatter":{"title":"Deep Learning Applications","description":null,"imageAlt":null,"tags":[],"date":"2015-10-09T00:00:00.000Z","dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"layout\": \"post\",\n  \"category\": \"deep_learning\",\n  \"title\": \"Deep Learning Applications\",\n  \"date\": \"2015-10-09T00:00:00.000Z\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"papers\"\n  }, \"Papers\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepPose: Human Pose Estimation via Deep Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2014\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1312.4659\"\n  }, \"http://arxiv.org/abs/1312.4659\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://140.122.184.143/paperlinks/Slides/DeepPose_HumanPose_Estimation_via_Deep_Neural_Networks.pptx\"\n  }, \"http://140.122.184.143/paperlinks/Slides/DeepPose_HumanPose_Estimation_via_Deep_Neural_Networks.pptx\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/asanakoy/deeppose_tf\"\n  }, \"https://github.com/asanakoy/deeppose_tf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Heterogeneous multi-task learning for human pose estimation with deep convolutional neural network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/www.cv-foundation.org/openaccess/content_cvpr_workshops_2014/W15/papers/LI_Heterogeneous_Multi-task_Learning_2014_CVPR_paper.pdf/\"\n  }, \"www.cv-foundation.org/openaccess/content_cvpr_workshops_2014/W15/papers/LI_Heterogeneous_Multi-task_Learning_2014_CVPR_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Flowing ConvNets for Human Pose Estimation in Videos\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1506.02897\"\n  }, \"http://arxiv.org/abs/1506.02897\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.robots.ox.ac.uk/~vgg/software/cnn_heatmap/\"\n  }, \"http://www.robots.ox.ac.uk/~vgg/software/cnn_heatmap/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tpfister/caffe-heatmap\"\n  }, \"https://github.com/tpfister/caffe-heatmap\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sparseness Meets Deepness: 3D Human Pose Estimation from Monocular Video\")), mdx(\"img\", {\n    \"src\": \"https://fling.seas.upenn.edu/~xiaowz/dynamic/wordpress/wp-content/uploads/2016/01/overview.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1511.09439\"\n  }, \"http://arxiv.org/abs/1511.09439\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://fling.seas.upenn.edu/~xiaowz/dynamic/wordpress/monocular-human-pose/\"\n  }, \"https://fling.seas.upenn.edu/~xiaowz/dynamic/wordpress/monocular-human-pose/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"video: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://weibo.com/p/230444264a8772b7fff71cd23e40b8a88dcaad\"\n  }, \"http://weibo.com/p/230444264a8772b7fff71cd23e40b8a88dcaad\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Structured Feature Learning for Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.09065\"\n  }, \"http://arxiv.org/abs/1603.09065\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.ee.cuhk.edu.hk/~xgwang/projectpage_structured_feature_pose.html\"\n  }, \"http://www.ee.cuhk.edu.hk/~xgwang/projectpage_structured_feature_pose.html\"))), mdx(\"h2\", {\n    \"id\": \"cpm\"\n  }, \"CPM\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Convolutional Pose Machines\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Convolutional Pose Machines(CPMs)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1602.00134\"\n  }, \"http://arxiv.org/abs/1602.00134\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/shihenw/convolutional-pose-machines-release\"\n  }, \"https://github.com/shihenw/convolutional-pose-machines-release\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(PyTorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation\"\n  }, \"https://github.com/tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/timctho/convolutional-pose-machines-tensorflow\"\n  }, \"https://github.com/timctho/convolutional-pose-machines-tensorflow\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Stacked Hourglass Networks for Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www-personal.umich.edu/~alnewell/pose/\"\n  }, \"http://www-personal.umich.edu/~alnewell/pose/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.06937\"\n  }, \"http://arxiv.org/abs/1603.06937\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/anewell/pose-hg-train\"\n  }, \"https://github.com/anewell/pose-hg-train\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/anewell/pose-hg-demo\"\n  }, \"https://github.com/anewell/pose-hg-demo\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Chained Predictions Using Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: EECV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: CNN, structured prediction, RNN, human pose estimation\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.02346\"\n  }, \"http://arxiv.org/abs/1605.02346\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeeperCut: A Deeper, Stronger, and Faster Multi-Person Pose Estimation Model\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.03170\"\n  }, \"http://arxiv.org/abs/1605.03170\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/eldar/deepcut-cnn\"\n  }, \"https://github.com/eldar/deepcut-cnn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Real-time Human Pose Estimation from Video with Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.07420\"\n  }, \"http://arxiv.org/abs/1609.07420\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017 Oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Part Confidence Maps, Part Affinity Fields & Bipartite Matching & Part Association\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.08050\"\n  }, \"https://arxiv.org/abs/1611.08050\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"video: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=pW6nZXeWlGM&feature=youtu.be\"\n  }, \"https://www.youtube.com/watch?v=pW6nZXeWlGM&feature=youtu.be\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://image-net.org/challenges/talks/2016/Multi-person%20pose%20estimation-CMU.pdf\"\n  }, \"http://image-net.org/challenges/talks/2016/Multi-person%20pose%20estimation-CMU.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ZheC/Realtime_Multi-Person_Pose_Estimation\"\n  }, \"https://github.com/ZheC/Realtime_Multi-Person_Pose_Estimation\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Journal version\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1812.08008\"\n  }, \"https://arxiv.org/abs/1812.08008\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards Accurate Multi-person Pose Estimation in the Wild\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.01779\"\n  }, \"https://arxiv.org/abs/1701.01779\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Binarized Convolutional Landmark Localizers for Human Pose Estimation and Face Alignment with Limited Resources\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017 Oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.adrianbulat.com/binary-cnn-landmarks\"\n  }, \"https://www.adrianbulat.com/binary-cnn-landmarks\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.arxiv.org/abs/1703.00862\"\n  }, \"https://www.arxiv.org/abs/1703.00862\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Adversarial PoseNet: A Structure-aware Convolutional Network for Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1705.00389\"\n  }, \"https://arxiv.org/abs/1705.00389\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"video: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://v.qq.com/x/page/c039862eira.html\"\n  }, \"http://v.qq.com/x/page/c039862eira.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"video: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://v.qq.com/x/page/f0398zcvkl5.html\"\n  }, \"http://v.qq.com/x/page/f0398zcvkl5.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"video: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://v.qq.com/x/page/w0398ei9m1r.html\"\n  }, \"http://v.qq.com/x/page/w0398ei9m1r.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A simple yet effective baseline for 3d human pose estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1705.03098\"\n  }, \"https://arxiv.org/abs/1705.03098\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/una-dinosauria/3d-pose-baseline\"\n  }, \"https://github.com/una-dinosauria/3d-pose-baseline\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Human Pose Detection Mining Body Language from Videos\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/@samim/human-pose-detection-51268e95ddc2\"\n  }, \"https://medium.com/@samim/human-pose-detection-51268e95ddc2\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"OpenPose: A Real-Time Multi-Person Keypoint Detection And Multi-Threading C++ Library\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: OpenPose is a library for real-time multi-person keypoint detection and multi-threading written in C++ using OpenCV and Caffe\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/CMU-Perceptual-Computing-Lab/openpose\"\n  }, \"https://github.com/CMU-Perceptual-Computing-Lab/openpose\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Feature Pyramids for Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.01101\"\n  }, \"https://arxiv.org/abs/1708.01101\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bearpaw/PyraNet\"\n  }, \"https://github.com/bearpaw/PyraNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Context Attention for Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.07432\"\n  }, \"https://arxiv.org/abs/1702.07432\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Torch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bearpaw/pose-attention\"\n  }, \"https://github.com/bearpaw/pose-attention\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Human Pose Estimation with TensorFlow\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/eldar/pose-tensorflow\"\n  }, \"https://github.com/eldar/pose-tensorflow\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cascaded Pyramid Network for Multi-Person Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018. Tsinghua University & HuaZhong Univerisity of Science and Technology & Megvii Inc\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.07319\"\n  }, \"https://arxiv.org/abs/1711.07319\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/chenyilun95/tf-cpn\"\n  }, \"https://github.com/chenyilun95/tf-cpn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/GengDavid/pytorch-cpn\"\n  }, \"https://github.com/GengDavid/pytorch-cpn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"LSTM Pose Machines\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018. SenseTime Research & Sun Yat-sen University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.06316\"\n  }, \"https://arxiv.org/abs/1712.06316\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Caffe, officical): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lawy623/LSTM_Pose_Machines\"\n  }, \"https://github.com/lawy623/LSTM_Pose_Machines\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DenseReg: Fully Convolutional Dense Shape Regression In-the-Wild\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://alpguler.com/DenseReg.html\"\n  }, \"http://alpguler.com/DenseReg.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.01202\"\n  }, \"https://arxiv.org/abs/1612.01202\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ralpguler/DenseReg\"\n  }, \"https://github.com/ralpguler/DenseReg\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DenseReg: Fully Convolutional Dense Shape Regression In-the-Wild\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.02188\"\n  }, \"https://arxiv.org/abs/1803.02188\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DensePose: Dense Human Pose Estimation In The Wild\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018. INRIA & Facebook AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://densepose.org/\"\n  }, \"http://densepose.org/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1802.00434\"\n  }, \"https://arxiv.org/abs/1802.00434\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(CaffeO2): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/facebookresearch/DensePose\"\n  }, \"https://github.com/facebookresearch/DensePose\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"LCR-Net++: Multi-person 2D and 3D Pose Detection in Natural Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: journal version of the CVPR 2017 paper\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.00455\"\n  }, \"https://arxiv.org/abs/1803.00455\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Pose Consensus Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.08190\"\n  }, \"https://arxiv.org/abs/1803.08190\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"3D Human Pose Estimation in the Wild by Adversarial Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.09722\"\n  }, \"https://arxiv.org/abs/1803.09722\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Scale Structure-Aware Network for Human Pose Estimation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.09894\"\n  }, \"https://arxiv.org/abs/1803.09894\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Co-occurrence Feature Learning from Skeleton Data for Action Recognition and Detection with Hierarchical Aggregation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IJCAI 2018 oral. Hikvision Research Institute\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.06055\"\n  }, \"https://arxiv.org/abs/1804.06055\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning to Refine Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPRW (2018). Workshop: Visual Understanding of Humans in Crowd Scene and the 2nd Look Into Person Challenge (VUHCS-LIP)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.07909\"\n  }, \"https://arxiv.org/abs/1804.07909\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"3D Human Pose Estimation with Relational Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.08961\"\n  }, \"https://arxiv.org/abs/1805.08961\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Jointly Optimize Data Augmentation and Network Training: Adversarial Data Augmentation in Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.09707\"\n  }, \"https://arxiv.org/abs/1805.09707\"))), mdx(\"h2\", {\n    \"id\": \"alphapose\"\n  }, \"AlphaPose\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RMPE: Regional Multi-person Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://fang-haoshu.github.io/publications/rmpe/\"\n  }, \"https://fang-haoshu.github.io/publications/rmpe/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.00137\"\n  }, \"https://arxiv.org/abs/1612.00137\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_ICCV_2017/papers/Fang_RMPE_Regional_Multi-Person_ICCV_2017_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_ICCV_2017/papers/Fang_RMPE_Regional_Multi-Person_ICCV_2017_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Caffe, official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MVIG-SJTU/RMPE\"\n  }, \"https://github.com/MVIG-SJTU/RMPE\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Fang-Haoshu/RMPE\"\n  }, \"https://github.com/Fang-Haoshu/RMPE\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pose Flow: Efficient Online Pose Tracking\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1802.00977\"\n  }, \"https://arxiv.org/abs/1802.00977\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AlphaPose: Multi-Person Pose Estimation System\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: an accurate multi-person pose estimation system\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.mvig.org/research/alphapose.html\"\n  }, \"http://www.mvig.org/research/alphapose.html\"))), mdx(\"hr\", null), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Computing CNN Loss and Gradients for Pose Estimation with Riemannian Geometry\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.01026\"\n  }, \"https://arxiv.org/abs/1805.01026\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bi-directional Graph Structure Information Model for Multi-Person Pose Estimation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.00603\"\n  }, \"https://arxiv.org/abs/1805.00603\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MultiPoseNet: Fast Multi-Person Pose Estimation using Pose Residual Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018. Middle East Technical University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Pose Residual Network (PRN), person detection, keypoint detection, person segmentation and pose estimation\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.04067\"\n  }, \"https://arxiv.org/abs/1807.04067\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mkocabas/pose-residual-network\"\n  }, \"https://github.com/mkocabas/pose-residual-network\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Autoencoder for Combined Human Pose Estimation and body Model Upscaling\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1807.01511\"\n  }, \"https://arxiv.org/abs/1807.01511\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Human Poses from Actions\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.09075\"\n  }, \"https://arxiv.org/abs/1807.09075\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Scale Supervised Network for Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICIP 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.01623\"\n  }, \"https://arxiv.org/abs/1808.01623\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CU-Net: Coupled U-Nets\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2018 (Oral)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.06521\"\n  }, \"https://arxiv.org/abs/1808.06521\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Domain Pose Network for Multi-Person Pose Estimation and Tracking\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1810.08338\"\n  }, \"https://arxiv.org/abs/1810.08338\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Benchmarking and Error Diagnosis in Multi-Instance Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.vision.caltech.edu/~mronchi/projects/PoseErrorDiagnosis/\"\n  }, \"http://www.vision.caltech.edu/~mronchi/projects/PoseErrorDiagnosis/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.05388\"\n  }, \"https://arxiv.org/abs/1707.05388\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/matteorr/coco-analyze\"\n  }, \"https://github.com/matteorr/coco-analyze\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improving Multi-Person Pose Estimation using Label Correction\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.03331\"\n  }, \"https://arxiv.org/abs/1811.03331\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Fast Pose Distillation (FPD)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.05419\"\n  }, \"https://arxiv.org/abs/1811.05419\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PoseFix: Model-agnostic General Human Pose Refinement Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1812.03595\"\n  }, \"https://arxiv.org/abs/1812.03595\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(TensorFlow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mks0601/PoseFix_RELEASE\"\n  }, \"https://github.com/mks0601/PoseFix_RELEASE\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rethinking on Multi-Stage Networks for Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Megvii Inc. (Face++) & Shanghai Jiao Tong University & Beihang University & Beijing University of Posts and Telecommunications\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.00148\"\n  }, \"https://arxiv.org/abs/1901.00148\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/fenglinglwb/MSPN\"\n  }, \"https://github.com/fenglinglwb/MSPN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep High-Resolution Representation Learning for Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Science and Technology of China & Microsoft Research Asia\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: HRNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1902.09212\"\n  }, \"https://arxiv.org/abs/1902.09212\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://jingdongwang2017.github.io/Projects/HRNet/PoseEstimation.html\"\n  }, \"https://jingdongwang2017.github.io/Projects/HRNet/PoseEstimation.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/leoxiaobin/deep-high-resolution-net.pytorch\"\n  }, \"https://github.com/leoxiaobin/deep-high-resolution-net.pytorch\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Context-and-Spatial Aware Network for Multi-Person Pose Estimation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1905.05355\"\n  }, \"https://arxiv.org/abs/1905.05355\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FastPose: Towards Real-time Pose Estimation and Tracking via Scale-normalized Multi-task Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Chinese Academy of Sciences & BUPT & Horizon Robotics\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1908.06290\"\n  }, \"https://arxiv.org/abs/1908.06290\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Single-Stage Multi-Person Pose Machines\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Yitu Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1908.09220\"\n  }, \"https://arxiv.org/abs/1908.09220\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Single-Network Whole-Body Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/CMU-Perceptual-Computing-Lab/openpose_train\"\n  }, \"https://github.com/CMU-Perceptual-Computing-Lab/openpose_train\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.13423\"\n  }, \"https://arxiv.org/abs/1909.13423\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"NADS-Net: A Nimble Architecture for Driver and Seat Belt Detection via Convolutional Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1910.03695\"\n  }, \"https://arxiv.org/abs/1910.03695\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Distribution-Aware Coordinate Representation for Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Distribution-Aware coordinate Representation of Keypoint (DARK)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Results on the COCO keypoint detection challenge: 78.9% AP on the test-dev set (Top-1 in the leaderbord by 12 Oct 2019) and 76.4% AP on the test-challenge set.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://ilovepose.github.io/coco/\"\n  }, \"https://ilovepose.github.io/coco/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1910.06278\"\n  }, \"https://arxiv.org/abs/1910.06278\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ilovepose/DarkPose\"\n  }, \"https://github.com/ilovepose/DarkPose\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TRB: A Novel Triplet Representation for Understanding 2D Human Body\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1910.11535\"\n  }, \"https://arxiv.org/abs/1910.11535\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Chirality Nets for Human Pose Regression\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1911.00029\"\n  }, \"https://arxiv.org/abs/1911.00029\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Conservative Wasserstein Training for Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1911.00962\"\n  }, \"https://arxiv.org/abs/1911.00962\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DirectPose: Direct End-to-End Multi-Person Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The University of Adelaide\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Keypoint Alignment (KPAlign)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1911.07451\"\n  }, \"https://arxiv.org/abs/1911.07451\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Devil is in the Details: Delving into Unbiased Data Processing for Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: XForwardAI Technology Co.,Ltd & Tsinghua University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1911.07524\"\n  }, \"https://arxiv.org/abs/1911.07524\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/HuangJunJie2017/UDP-Pose\"\n  }, \"https://github.com/HuangJunJie2017/UDP-Pose\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Simple Pose: Rethinking and Improving a Bottom-up Approach for Multi-Person Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1911.10529\"\n  }, \"https://arxiv.org/abs/1911.10529\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hellojialee/Improved-Body-Parts\"\n  }, \"https://github.com/hellojialee/Improved-Body-Parts\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"HintPose\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Joint COCO and Mapillary Workshop at ICCV 2019: Keypoint Detection Challenge Track\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.02170\"\n  }, \"https://arxiv.org/abs/2003.02170\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"How to Train Your Robust Human Pose Estimator: Pay Attention to the Constraint Cue\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: XForwardAI Technology Co.,Ltd & Tsinghua University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2008.07139\"\n  }, \"https://arxiv.org/abs/2008.07139\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CoKe: Localized Contrastive Learning for Robust Keypoint Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Johns Hopkins University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2009.14115\"\n  }, \"https://arxiv.org/abs/2009.14115\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"View-Invariant, Occlusion-Robust Probabilistic Embedding for Human Pose\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Research & California Institute of Technology & Rutgers University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2010.13321\"\n  }, \"https://arxiv.org/abs/2010.13321\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gtihub: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/google-research/google-research/tree/master/poem\"\n  }, \"https://github.com/google-research/google-research/tree/master/poem\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An Empirical Study of the Collapsing Problem in Semi-Supervised 2D Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Peking University & Microsoft Research Asia\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.12498\"\n  }, \"https://arxiv.org/abs/2011.12498\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"EfficientPose: Efficient Human Pose Estimation with Neural Architecture Search\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2012.07086\"\n  }, \"https://arxiv.org/abs/2012.07086\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TransPose: Towards Explainable Human Pose Estimation by Transformer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Southeast University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.14214\"\n  }, \"https://arxiv.org/abs/2012.14214\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yangsenius/TransPose\"\n  }, \"https://github.com/yangsenius/TransPose\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rethinking the Heatmap Regression for Bottom-up Human Pose Estimation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2012.15175\"\n  }, \"https://arxiv.org/abs/2012.15175\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Hypothesis Pose Networks: Rethinking Top-Down Pose Estimation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2101.11223\"\n  }, \"https://arxiv.org/abs/2101.11223\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"OmniPose: A Multi-Scale Framework for Multi-Person Pose Estimation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2103.10180\"\n  }, \"https://arxiv.org/abs/2103.10180\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End-to-End Trainable Multi-Instance Pose Estimation with Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Swiss Federal Institute of Technology (EPFL)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.12115\"\n  }, \"https://arxiv.org/abs/2103.12115\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TFPose: Direct Human Pose Estimation with Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The University of Adelaide & Alibaba Group\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.15320\"\n  }, \"https://arxiv.org/abs/2103.15320\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TokenPose: Learning Keypoint Tokens for Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MEGVII Technology & Tsinghua University & Southeast University & Peng Cheng Laboratory\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.03516\"\n  }, \"https://arxiv.org/abs/2104.03516\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pose Recognition with Cascade Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.06976\"\n  }, \"https://arxiv.org/abs/2104.06976\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mlpc-ucsd/PRTR\"\n  }, \"https://github.com/mlpc-ucsd/PRTR\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Is 2D Heatmap Representation Even Necessary for Human Pose Estimation?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tsinghua University & MEGVII Technology & Southeast University & Peng Cheng Laboratory\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2107.03332\"\n  }, \"https://arxiv.org/abs/2107.03332\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/leeyegy/SimDR\"\n  }, \"https://github.com/leeyegy/SimDR\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"InsPose: Instance-Aware Networks for Single-Stage Multi-Person Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM MM 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2107.08982\"\n  }, \"https://arxiv.org/abs/2107.08982\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Adaptive Dilated Convolution For Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Megvii & UCAS & CRIPAC & NLPR & CASIA\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2107.10477\"\n  }, \"https://arxiv.org/abs/2107.10477\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PoseDet: Fast Multi-Person Pose Estimation Using Pose Embedding\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tsinghua University & Northwestern University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2107.10466\"\n  }, \"https://arxiv.org/abs/2107.10466\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Online Knowledge Distillation for Efficient Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2108.02092\"\n  }, \"https://arxiv.org/abs/2108.02092\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SmoothNet: A Plug-and-Play Network for Refining Human Poses in Videos\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The Chinese University of Hong Kong & Sensetime Group Ltd. &Shanghai Jiao Tong University & Nanyang Technological University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://ailingzeng.site/smoothnet\"\n  }, \"https://ailingzeng.site/smoothnet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2112.13715\"\n  }, \"https://arxiv.org/abs/2112.13715\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AdaptivePose: Human Parts as Adaptive Points\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Beijing University of Posts and Telecommunications & ByteDance Inc. & Tsinghua University &  Horizon Robotics\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2112.13635\"\n  }, \"https://arxiv.org/abs/2112.13635\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Quality-aware Representation for Multi-person Pose Regression\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Beijing University of Posts and Telecommunications & ByteDance Inc. & Tsinghua University &  Horizon Robotics\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2201.01087\"\n  }, \"https://arxiv.org/abs/2201.01087\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Recognition of Freely Selected Keypoints on Human Limbs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022 Workshops\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2204.06326\"\n  }, \"https://arxiv.org/abs/2204.06326\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"YOLO-Pose: Enhancing YOLO for Multi Person Pose Estimation Using Object Keypoint Similarity Loss\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Texas Instruments Inc\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2204.06806\"\n  }, \"https://arxiv.org/abs/2204.06806\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/TexasInstruments/edgeai-yolov5\"\n  }, \"https://github.com/TexasInstruments/edgeai-yolov5\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/TexasInstruments/edgeai-yolox\"\n  }, \"https://github.com/TexasInstruments/edgeai-yolox\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Lite Pose: Efficient Architecture Design for 2D Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tsinghua University & CMU & MIT\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2205.01271\"\n  }, \"https://arxiv.org/abs/2205.01271\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mit-han-lab/litepose\"\n  }, \"https://github.com/mit-han-lab/litepose\"))), mdx(\"h1\", {\n    \"id\": \"regression-based-method\"\n  }, \"Regression-based Method\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Integral Human Pose Regression\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.08229\"\n  }, \"https://arxiv.org/abs/1711.08229\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://jimmysuen.github.io/slides/xiaosun_integral_human_pose_regression.pptx\"\n  }, \"https://jimmysuen.github.io/slides/xiaosun_integral_human_pose_regression.pptx\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/JimmySuen/integral-human-pose\"\n  }, \"https://github.com/JimmySuen/integral-human-pose\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Human Pose Regression with Residual Log-likelihood Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021 Oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Shanghai Jiao Tong University & The Chinese University of Hong Kong & SenseTime Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2107.11291\"\n  }, \"https://arxiv.org/abs/2107.11291\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Jeff-sjtu/res-loglikelihood-regression\"\n  }, \"https://github.com/Jeff-sjtu/res-loglikelihood-regression\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Poseur: Direct Human Pose Regression with Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The University of Adelaide & Alibaba Damo Academy & Zhejiang University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2201.07412\"\n  }, \"https://arxiv.org/abs/2201.07412\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Location-free Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Beijing Jiaotong University & Tencent Youtu Lab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2205.12619\"\n  }, \"https://arxiv.org/abs/2205.12619\"))), mdx(\"h1\", {\n    \"id\": \"top-down\"\n  }, \"Top-Down\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Point-Set Anchors for Object Detection, Instance Segmentation and Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MSRA & Peking University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.02846\"\n  }, \"https://arxiv.org/abs/2007.02846\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/FangyunWei/PointSetAnchor\"\n  }, \"https://github.com/FangyunWei/PointSetAnchor\"))), mdx(\"h1\", {\n    \"id\": \"bottom-up\"\n  }, \"Bottom-Up\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PifPaf: Composite Fields for Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: EPFL VITA lab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Part Intensity Field (PIF), Part Association Field (PAF)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.06593\"\n  }, \"https://arxiv.org/abs/1903.06593\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"OpenPifPaf: Composite Fields for Semantic Keypoint Detection and Spatio-Temporal Association\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://openpifpaf.github.io/intro.html\"\n  }, \"https://openpifpaf.github.io/intro.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.02440\"\n  }, \"https://arxiv.org/abs/2103.02440\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/openpifpaf/openpifpaf\"\n  }, \"https://github.com/openpifpaf/openpifpaf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bottom-Up Human Pose Estimation Via Disentangled Keypoint Regression\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: DEKR\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Science and Technology of China & University of Chinese Academy of Sciences & Microsof\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.02300\"\n  }, \"https://arxiv.org/abs/2104.02300\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/HRNet/DEKR\"\n  }, \"https://github.com/HRNet/DEKR\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepSportLab: a Unified Framework for Ball Detection, Player Instance Segmentation and Pose Estimation in Team Sports Scenes\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2112.00627\"\n  }, \"https://arxiv.org/abs/2112.00627\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ispgroupucl/DeepSportLab\"\n  }, \"https://github.com/ispgroupucl/DeepSportLab\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Local-Global Contextual Adaptation for Fully End-to-End Bottom-Up Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Wuhan University & North Carolina State University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2109.03622\"\n  }, \"https://arxiv.org/abs/2109.03622\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Keypoint Communities\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2110.00988\"\n  }, \"https://arxiv.org/abs/2110.00988\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Center of Attention: Center-Keypoint Grouping via Attention for Multi-Person Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Technical University of Munich\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2110.05132\"\n  }, \"https://arxiv.org/abs/2110.05132\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Self-Supervision and Spatial-Sequential Attention Based Loss for Multi-Person Pose Estimation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2110.10734\"\n  }, \"https://arxiv.org/abs/2110.10734\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Local-Global Contextual Adaptation for Multi-Person Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Wuhan University, NC State University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2109.03622\"\n  }, \"https://arxiv.org/abs/2109.03622\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"I^2R-Net: Intra- and Inter-Human Relation Network for Multi-Person Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Xiamen University & Microsoft Research Asia\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2206.10892\"\n  }, \"https://arxiv.org/abs/2206.10892\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End-to-End Multi-Person Pose Estimation with Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022 Oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_End-to-End_Multi-Person_Pose_Estimation_With_Transformers_CVPR_2022_paper.pdf\"\n  }, \"https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_End-to-End_Multi-Person_Pose_Estimation_With_Transformers_CVPR_2022_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hikvision-research/opera/tree/main/configs/petr\"\n  }, \"https://github.com/hikvision-research/opera/tree/main/configs/petr\"))), mdx(\"h1\", {\n    \"id\": \"hand-pose\"\n  }, \"Hand Pose\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Model-based Deep Hand Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://xingyizhou.xyz/zhou2016model.pdf\"\n  }, \"http://xingyizhou.xyz/zhou2016model.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tenstep/DeepModel\"\n  }, \"https://github.com/tenstep/DeepModel\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Region Ensemble Network: Improving Convolutional Network for Hand Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.02447\"\n  }, \"https://arxiv.org/abs/1702.02447\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Crossing Nets: Combining GANs and VAEs with a Shared Latent Space for Hand Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.03431\"\n  }, \"https://arxiv.org/abs/1702.03431\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning to Disambiguate Strongly Interacting Hands via Probabilistic Per-pixel Part Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: 3DV 2021 Oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2107.00434\"\n  }, \"https://arxiv.org/abs/2107.00434\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zc-alexfan/digit-interacting\"\n  }, \"https://github.com/zc-alexfan/digit-interacting\"))), mdx(\"h1\", {\n    \"id\": \"3d-pose\"\n  }, \"3D Pose\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Can 3D Pose be Learned from 2D Projections Alone?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018 workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.07182\"\n  }, \"https://arxiv.org/abs/1808.07182\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast and Robust Multi-Person 3D Pose Estimation from Multiple Views\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://zju-3dv.github.io/mvpose/\"\n  }, \"https://zju-3dv.github.io/mvpose/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.04111\"\n  }, \"https://arxiv.org/abs/1901.04111\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zju-3dv/mvpose\"\n  }, \"https://github.com/zju-3dv/mvpose\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"3D Human Pose Machines with Self-supervised Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: T-PAMI 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.sysu-hcp.net/3d_pose_ssl/\"\n  }, \"http://www.sysu-hcp.net/3d_pose_ssl/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.03798\"\n  }, \"https://arxiv.org/abs/1901.03798\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/chanyn/3Dpose_ssl\"\n  }, \"https://github.com/chanyn/3Dpose_ssl\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Feature Boosting Network For 3D Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Nanyang Technological University & Chalmers University of Technology & Peking University & Alibaba Group\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.04877\"\n  }, \"https://arxiv.org/abs/1901.04877\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"View Invariant 3D Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MSRA & USTC\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.10841\"\n  }, \"https://arxiv.org/abs/1901.10841\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"3D Human Pose Estimation from Deep Multi-View 2D Pose\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1902.02841\"\n  }, \"https://arxiv.org/abs/1902.02841\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RepNet: Weakly Supervised Training of an Adversarial Reprojection Network for 3D Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1902.09868\"\n  }, \"https://arxiv.org/abs/1902.09868\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DenseBody: Directly Regressing Dense 3D Human Pose and Shape From a Single Color Image\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Cloudwalk & Shanghai Jiao Tong University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.10153\"\n  }, \"https://arxiv.org/abs/1903.10153\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Camera Distance-aware Top-down Approach for 3D Multi-person Pose Estimation from a Single RGB Image\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.11346\"\n  }, \"https://arxiv.org/abs/1907.11346\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mks0601/3DMPPE_ROOTNET_RELEASE\"\n  }, \"https://github.com/mks0601/3DMPPE_ROOTNET_RELEASE\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Lightweight 3D Human Pose Estimation Network Training Using Teacher-Student Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2001.05097\"\n  }, \"https://arxiv.org/abs/2001.05097\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cross-View Tracking for Multi-Human 3D Pose Estimation at over 100 FPS\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tsinghua University & AiFi Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.03972\"\n  }, \"https://arxiv.org/abs/2003.03972\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Skeletor: Skeletal Transformers for Robust Body-Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Surrey\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.11712\"\n  }, \"https://arxiv.org/abs/2104.11712\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"UltraPose: Synthesizing Dense Pose with 1 Billion Points by Human-body Decoupling 3D Model\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Beijing Momo Technology Co., Ltd. & Sun Yat-sen University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2110.15267\"\n  }, \"https://arxiv.org/abs/2110.15267\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MomoAILab/ultrapose\"\n  }, \"https://github.com/MomoAILab/ultrapose\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Distribution-Aware Single-Stage Models for Multi-Person 3D Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Beihang University & Meitu Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2203.07697\"\n  }, \"https://arxiv.org/abs/2203.07697\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeciWatch: A Simple Baseline for 10x Efficient 2D and 3D Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The Chinese University of Hong Kong & Sensetime Group Ltd. &  Shanghai Artificial Intelligence Laboratory\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://ailingzeng.site/deciwatch\"\n  }, \"https://ailingzeng.site/deciwatch\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2203.08713\"\n  }, \"https://arxiv.org/abs/2203.08713\"))), mdx(\"h1\", {\n    \"id\": \"3d-car-keypoints-detection\"\n  }, \"3D Car keypoints Detection\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Occlusion-Net: 2D/3D Occluded Keypoint Localization Using Graph Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_CVPR_2019/papers/Reddy_Occlusion-Net_2D3D_Occluded_Keypoint_Localization_Using_Graph_Networks_CVPR_2019_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_CVPR_2019/papers/Reddy_Occlusion-Net_2D3D_Occluded_Keypoint_Localization_Using_Graph_Networks_CVPR_2019_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/dineshreddy91/Occlusion_Net\"\n  }, \"https://github.com/dineshreddy91/Occlusion_Net\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RTM3D: Real-time Monocular 3D Detection from Object Keypoints for Autonomous Driving\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Chinese Academy of Sciences & University of Chinese Academy of Sciences\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2001.03343\"\n  }, \"https://arxiv.org/abs/2001.03343\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Banconxuan/RTM3D\"\n  }, \"https://github.com/Banconxuan/RTM3D\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SMOKE: Single-Stage Monocular 3D Object Detection via Keypoint Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: 1ZongMu Tech & TU/e\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2002.10111\"\n  }, \"https://arxiv.org/abs/2002.10111\"))), mdx(\"h1\", {\n    \"id\": \"pose-estimation-and-action-recognition\"\n  }, \"Pose Estimation and Action Recognition\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"2D/3D Pose Estimation and Action Recognition using Multitask Deep Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1802.09232\"\n  }, \"https://arxiv.org/abs/1802.09232\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-task Deep Learning for Real-Time 3D Human Pose Estimation and Action Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1912.08077\"\n  }, \"https://arxiv.org/abs/1912.08077\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/dluvizon/deephar\"\n  }, \"https://github.com/dluvizon/deephar\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video Pose Distillation for Few-Shot, Fine-Grained Sports Action Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021 poster\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Stanford University & Adobe Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2109.01305\"\n  }, \"https://arxiv.org/abs/2109.01305\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Skeleton Sequence and RGB Frame Based Multi-Modality Feature Fusion Network for Action Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2202.11374\"\n  }, \"https://arxiv.org/abs/2202.11374\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Revisiting Skeleton-based Action Recognition\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022 Oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: PoseConv3D\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.13586\"\n  }, \"https://arxiv.org/abs/2104.13586\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kennymckormick/pyskl\"\n  }, \"https://github.com/kennymckormick/pyskl\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/open-mmlab/mmaction2/blob/master/configs/skeleton/posec3d/README.md\"\n  }, \"https://github.com/open-mmlab/mmaction2/blob/master/configs/skeleton/posec3d/README.md\"))), mdx(\"h1\", {\n    \"id\": \"pose-tracking\"\n  }, \"Pose Tracking\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Detect-and-Track: Efficient Pose Estimation in Videos\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018. CMU & Facebook & Dartmouth\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Ranked first in ICCV 2017 PoseTrack challenge (keypoint tracking in videos)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://rohitgirdhar.github.io/DetectAndTrack/\"\n  }, \"https://rohitgirdhar.github.io/DetectAndTrack/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.09184\"\n  }, \"https://arxiv.org/abs/1712.09184\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_cvpr_2018/papers/Girdhar_Detect-and-Track_Efficient_Pose_CVPR_2018_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_cvpr_2018/papers/Girdhar_Detect-and-Track_Efficient_Pose_CVPR_2018_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/facebookresearch/DetectAndTrack/\"\n  }, \"https://github.com/facebookresearch/DetectAndTrack/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Simple Baselines for Human Pose Estimation and Tracking\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MSRA\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: optical flow based pose propagation and similarity measurement\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.06208\"\n  }, \"https://arxiv.org/abs/1804.06208\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Microsoft/human-pose-estimation.pytorch\"\n  }, \"https://github.com/Microsoft/human-pose-estimation.pytorch\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Top-down Approach to Articulated Human Pose Estimation and Tracking\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: JD.com Silicon Valley Research Center\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCVW 2018. Workshop: 2nd PoseTrack Challenge\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.07680\"\n  }, \"https://arxiv.org/abs/1901.07680\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"15 Keypoints Is All You Need\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Brown University & NEC Labs America\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1912.02323\"\n  }, \"https://arxiv.org/abs/1912.02323\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Dynamics via Graph Neural Networks for Human Pose Estimation and Tracking\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Stevens Institute of Technology & Wormpex AI Research & National University of Singapore\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2106.03772\"\n  }, \"https://arxiv.org/abs/2106.03772\"))), mdx(\"h1\", {\n    \"id\": \"object-pose-estimation\"\n  }, \"Object Pose Estimation\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Real-Time Object Pose Estimation with Pose Interpreter Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2018)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.01099\"\n  }, \"https://arxiv.org/abs/1808.01099\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jimmyyhwu/pose-interpreter-networks\"\n  }, \"https://github.com/jimmyyhwu/pose-interpreter-networks\"))), mdx(\"h1\", {\n    \"id\": \"projects\"\n  }, \"Projects\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MobilePose: Single Person Pose Estimation for Mobile Device\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: a Tiny PyTorch implementation of single person 2D pose estimation framework\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/YuliangXiu/MobilePose-pytorch\"\n  }, \"https://github.com/YuliangXiu/MobilePose-pytorch\"), \"\\ngithub: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MVIG-SJTU/AlphaPose\"\n  }, \"https://github.com/MVIG-SJTU/AlphaPose\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PyTorch-Pose: A PyTorch toolkit for 2D Human Pose Estimation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: a PyTorch implementation of the general pipeline for 2D single human pose estimation.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bearpaw/pytorch-pose\"\n  }, \"https://github.com/bearpaw/pytorch-pose\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hourglass, DHN and CPN model in TensorFlow for 2018-FashionAI Key Points Detection of Apparel at TianChi\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Full pipeline for TianChi FashionAI clothes keypoints detection compitetion in TensorFlow\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/HiKapok/tf.fashionAI\"\n  }, \"https://github.com/HiKapok/tf.fashionAI\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FashionAI: KeyPoint Detection Challenge in Keras\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Code for TianChi 2018 FashionAI Cloth KeyPoint Detection Challenge\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yuanyuanli85/FashionAI_KeyPoint_Detection_Challenge_Keras\"\n  }, \"https://github.com/yuanyuanli85/FashionAI_KeyPoint_Detection_Challenge_Keras\"))), mdx(\"h1\", {\n    \"id\": \"challenge\"\n  }, \"Challenge\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"POSETRACK CHALLENGE: ARTICULATED PEOPLE TRACKING IN THE WILD\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://posetrack.net/workshops/eccv2018/#challenges\"\n  }, \"https://posetrack.net/workshops/eccv2018/#challenges\")));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"---\nlayout: post\ncategory: deep_learning\ntitle: Deep Learning Applications\ndate: 2015-10-09\n---\n\n# Papers\n\n**DeepPose: Human Pose Estimation via Deep Neural Networks**\n\n- intro: CVPR 2014\n- arxiv: [http://arxiv.org/abs/1312.4659](http://arxiv.org/abs/1312.4659)\n- slides: [http://140.122.184.143/paperlinks/Slides/DeepPose_HumanPose_Estimation_via_Deep_Neural_Networks.pptx](http://140.122.184.143/paperlinks/Slides/DeepPose_HumanPose_Estimation_via_Deep_Neural_Networks.pptx)\n- github: [https://github.com/asanakoy/deeppose_tf](https://github.com/asanakoy/deeppose_tf)\n\n**Heterogeneous multi-task learning for human pose estimation with deep convolutional neural network**\n\n- paper: [www.cv-foundation.org/openaccess/content_cvpr_workshops_2014/W15/papers/LI_Heterogeneous_Multi-task_Learning_2014_CVPR_paper.pdf](www.cv-foundation.org/openaccess/content_cvpr_workshops_2014/W15/papers/LI_Heterogeneous_Multi-task_Learning_2014_CVPR_paper.pdf)\n\n**Flowing ConvNets for Human Pose Estimation in Videos**\n\n- arxiv: [http://arxiv.org/abs/1506.02897](http://arxiv.org/abs/1506.02897)\n- homepage: [http://www.robots.ox.ac.uk/~vgg/software/cnn_heatmap/](http://www.robots.ox.ac.uk/~vgg/software/cnn_heatmap/)\n- github: [https://github.com/tpfister/caffe-heatmap](https://github.com/tpfister/caffe-heatmap)\n\n**Sparseness Meets Deepness: 3D Human Pose Estimation from Monocular Video**\n\n![](https://fling.seas.upenn.edu/~xiaowz/dynamic/wordpress/wp-content/uploads/2016/01/overview.png)\n\n- arxiv: [http://arxiv.org/abs/1511.09439](http://arxiv.org/abs/1511.09439)\n- project page: [https://fling.seas.upenn.edu/~xiaowz/dynamic/wordpress/monocular-human-pose/](https://fling.seas.upenn.edu/~xiaowz/dynamic/wordpress/monocular-human-pose/)\n- video: [http://weibo.com/p/230444264a8772b7fff71cd23e40b8a88dcaad](http://weibo.com/p/230444264a8772b7fff71cd23e40b8a88dcaad)\n\n**Structured Feature Learning for Pose Estimation**\n\n- arxiv: [http://arxiv.org/abs/1603.09065](http://arxiv.org/abs/1603.09065)\n- homepage: [http://www.ee.cuhk.edu.hk/~xgwang/projectpage_structured_feature_pose.html](http://www.ee.cuhk.edu.hk/~xgwang/projectpage_structured_feature_pose.html)\n\n## CPM\n\n**Convolutional Pose Machines**\n\n- intro: Convolutional Pose Machines(CPMs)\n- arxiv: [http://arxiv.org/abs/1602.00134](http://arxiv.org/abs/1602.00134)\n- github: [https://github.com/shihenw/convolutional-pose-machines-release](https://github.com/shihenw/convolutional-pose-machines-release)\n- github(PyTorch): [https://github.com/tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation](https://github.com/tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation)\n- github: [https://github.com/timctho/convolutional-pose-machines-tensorflow](https://github.com/timctho/convolutional-pose-machines-tensorflow)\n\n**Stacked Hourglass Networks for Human Pose Estimation**\n\n- homepage: [http://www-personal.umich.edu/~alnewell/pose/](http://www-personal.umich.edu/~alnewell/pose/)\n- arxiv: [http://arxiv.org/abs/1603.06937](http://arxiv.org/abs/1603.06937)\n- github: [https://github.com/anewell/pose-hg-train](https://github.com/anewell/pose-hg-train)\n- demo: [https://github.com/anewell/pose-hg-demo](https://github.com/anewell/pose-hg-demo)\n\n**Chained Predictions Using Convolutional Neural Networks**\n\n- intro: EECV 2016\n- keywords: CNN, structured prediction, RNN, human pose estimation\n- arxiv: [http://arxiv.org/abs/1605.02346](http://arxiv.org/abs/1605.02346)\n\n**DeeperCut: A Deeper, Stronger, and Faster Multi-Person Pose Estimation Model**\n\n- arxiv: [http://arxiv.org/abs/1605.03170](http://arxiv.org/abs/1605.03170)\n- github: [https://github.com/eldar/deepcut-cnn](https://github.com/eldar/deepcut-cnn)\n\n**Real-time Human Pose Estimation from Video with Convolutional Neural Networks**\n\n- arxiv: [http://arxiv.org/abs/1609.07420](http://arxiv.org/abs/1609.07420)\n\n**Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields**\n\n- intro: CVPR 2017 Oral\n- keywords: Part Confidence Maps, Part Affinity Fields & Bipartite Matching & Part Association\n- arxiv: [https://arxiv.org/abs/1611.08050](https://arxiv.org/abs/1611.08050)\n- video: [https://www.youtube.com/watch?v=pW6nZXeWlGM&feature=youtu.be](https://www.youtube.com/watch?v=pW6nZXeWlGM&feature=youtu.be)\n- slides: [http://image-net.org/challenges/talks/2016/Multi-person%20pose%20estimation-CMU.pdf](http://image-net.org/challenges/talks/2016/Multi-person%20pose%20estimation-CMU.pdf)\n- github: [https://github.com/ZheC/Realtime_Multi-Person_Pose_Estimation](https://github.com/ZheC/Realtime_Multi-Person_Pose_Estimation)\n\n**OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields**\n\n- intro: Journal version\n- arxiv: [https://arxiv.org/abs/1812.08008](https://arxiv.org/abs/1812.08008)\n\n**Towards Accurate Multi-person Pose Estimation in the Wild**\n\n- intro: Google\n- intro: CVPR 2017\n- arxiv: [https://arxiv.org/abs/1701.01779](https://arxiv.org/abs/1701.01779)\n\n**Binarized Convolutional Landmark Localizers for Human Pose Estimation and Face Alignment with Limited Resources**\n\n- intro: ICCV 2017 Oral\n- project page: [https://www.adrianbulat.com/binary-cnn-landmarks](https://www.adrianbulat.com/binary-cnn-landmarks)\n- arxiv: [https://www.arxiv.org/abs/1703.00862](https://www.arxiv.org/abs/1703.00862)\n\n**Adversarial PoseNet: A Structure-aware Convolutional Network for Human Pose Estimation**\n\n- arxiv: [https://arxiv.org/abs/1705.00389](https://arxiv.org/abs/1705.00389)\n- video: [http://v.qq.com/x/page/c039862eira.html](http://v.qq.com/x/page/c039862eira.html)\n- video: [http://v.qq.com/x/page/f0398zcvkl5.html](http://v.qq.com/x/page/f0398zcvkl5.html)\n- video: [http://v.qq.com/x/page/w0398ei9m1r.html](http://v.qq.com/x/page/w0398ei9m1r.html)\n\n**A simple yet effective baseline for 3d human pose estimation**\n\n- intro: ICCV 2017\n- arxiv: [https://arxiv.org/abs/1705.03098](https://arxiv.org/abs/1705.03098)\n- github: [https://github.com/una-dinosauria/3d-pose-baseline](https://github.com/una-dinosauria/3d-pose-baseline)\n\n**Human Pose Detection Mining Body Language from Videos**\n\n- blog: [https://medium.com/@samim/human-pose-detection-51268e95ddc2](https://medium.com/@samim/human-pose-detection-51268e95ddc2)\n\n**OpenPose: A Real-Time Multi-Person Keypoint Detection And Multi-Threading C++ Library**\n\n- intro: OpenPose is a library for real-time multi-person keypoint detection and multi-threading written in C++ using OpenCV and Caffe\n- github: [https://github.com/CMU-Perceptual-Computing-Lab/openpose](https://github.com/CMU-Perceptual-Computing-Lab/openpose)\n\n**Learning Feature Pyramids for Human Pose Estimation**\n\n- arxiv: [https://arxiv.org/abs/1708.01101](https://arxiv.org/abs/1708.01101)\n- github: [https://github.com/bearpaw/PyraNet](https://github.com/bearpaw/PyraNet)\n\n**Multi-Context Attention for Human Pose Estimation**\n\n- intro: CVPR 2017\n- arxiv: [https://arxiv.org/abs/1702.07432](https://arxiv.org/abs/1702.07432)\n- github(Torch): [https://github.com/bearpaw/pose-attention](https://github.com/bearpaw/pose-attention)\n\n**Human Pose Estimation with TensorFlow**\n\n[https://github.com/eldar/pose-tensorflow](https://github.com/eldar/pose-tensorflow)\n\n**Cascaded Pyramid Network for Multi-Person Pose Estimation**\n\n- intro: CVPR 2018. Tsinghua University & HuaZhong Univerisity of Science and Technology & Megvii Inc\n- arxiv: [https://arxiv.org/abs/1711.07319](https://arxiv.org/abs/1711.07319)\n- github(official): [https://github.com/chenyilun95/tf-cpn](https://github.com/chenyilun95/tf-cpn)\n- github: [https://github.com/GengDavid/pytorch-cpn](https://github.com/GengDavid/pytorch-cpn)\n\n**LSTM Pose Machines**\n\n- intro: CVPR 2018. SenseTime Research & Sun Yat-sen University\n- arxiv: [https://arxiv.org/abs/1712.06316](https://arxiv.org/abs/1712.06316)\n- github(Caffe, officical): [https://github.com/lawy623/LSTM_Pose_Machines](https://github.com/lawy623/LSTM_Pose_Machines)\n\n**DenseReg: Fully Convolutional Dense Shape Regression In-the-Wild**\n\n- intro: CVPR 2017\n- project page: [http://alpguler.com/DenseReg.html](http://alpguler.com/DenseReg.html)\n- arxiv: [https://arxiv.org/abs/1612.01202](https://arxiv.org/abs/1612.01202)\n- github: [https://github.com/ralpguler/DenseReg](https://github.com/ralpguler/DenseReg)\n\n**DenseReg: Fully Convolutional Dense Shape Regression In-the-Wild**\n\n[https://arxiv.org/abs/1803.02188](https://arxiv.org/abs/1803.02188)\n\n**DensePose: Dense Human Pose Estimation In The Wild**\n\n- intro: CVPR 2018. INRIA & Facebook AI Research\n- project page: [http://densepose.org/](http://densepose.org/)\n- arxiv: [https://arxiv.org/abs/1802.00434](https://arxiv.org/abs/1802.00434)\n- github(CaffeO2): [https://github.com/facebookresearch/DensePose](https://github.com/facebookresearch/DensePose)\n\n**LCR-Net++: Multi-person 2D and 3D Pose Detection in Natural Images**\n\n- intro: journal version of the CVPR 2017 paper\n- arxiv: [https://arxiv.org/abs/1803.00455](https://arxiv.org/abs/1803.00455)\n\n**Deep Pose Consensus Networks**\n\n[https://arxiv.org/abs/1803.08190](https://arxiv.org/abs/1803.08190)\n\n**3D Human Pose Estimation in the Wild by Adversarial Learning**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1803.09722](https://arxiv.org/abs/1803.09722)\n\n**Multi-Scale Structure-Aware Network for Human Pose Estimation**\n\n[https://arxiv.org/abs/1803.09894](https://arxiv.org/abs/1803.09894)\n\n**Co-occurrence Feature Learning from Skeleton Data for Action Recognition and Detection with Hierarchical Aggregation**\n\n- intro: IJCAI 2018 oral. Hikvision Research Institute\n- arxiv: [https://arxiv.org/abs/1804.06055](https://arxiv.org/abs/1804.06055)\n\n**Learning to Refine Human Pose Estimation**\n\n- intro: CVPRW (2018). Workshop: Visual Understanding of Humans in Crowd Scene and the 2nd Look Into Person Challenge (VUHCS-LIP)\n- arxiv: [https://arxiv.org/abs/1804.07909](https://arxiv.org/abs/1804.07909)\n\n**3D Human Pose Estimation with Relational Networks**\n\n[https://arxiv.org/abs/1805.08961](https://arxiv.org/abs/1805.08961)\n\n**Jointly Optimize Data Augmentation and Network Training: Adversarial Data Augmentation in Human Pose Estimation**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1805.09707](https://arxiv.org/abs/1805.09707)\n\n## AlphaPose\n\n**RMPE: Regional Multi-person Pose Estimation**\n\n- intro: ICCV 2017\n- project page: [https://fang-haoshu.github.io/publications/rmpe/](https://fang-haoshu.github.io/publications/rmpe/)\n- arxiv: [https://arxiv.org/abs/1612.00137](https://arxiv.org/abs/1612.00137)\n- paper: [http://openaccess.thecvf.com/content_ICCV_2017/papers/Fang_RMPE_Regional_Multi-Person_ICCV_2017_paper.pdf](http://openaccess.thecvf.com/content_ICCV_2017/papers/Fang_RMPE_Regional_Multi-Person_ICCV_2017_paper.pdf)\n- github(Caffe, official): [https://github.com/MVIG-SJTU/RMPE](https://github.com/MVIG-SJTU/RMPE)\n- github: [https://github.com/Fang-Haoshu/RMPE](https://github.com/Fang-Haoshu/RMPE)\n\n**Pose Flow: Efficient Online Pose Tracking**\n\n[https://arxiv.org/abs/1802.00977](https://arxiv.org/abs/1802.00977)\n\n**AlphaPose: Multi-Person Pose Estimation System**\n\n- intro: an accurate multi-person pose estimation system\n- project page: [http://www.mvig.org/research/alphapose.html](http://www.mvig.org/research/alphapose.html)\n\n- - -\n\n**Computing CNN Loss and Gradients for Pose Estimation with Riemannian Geometry**\n\n[https://arxiv.org/abs/1805.01026](https://arxiv.org/abs/1805.01026)\n\n**Bi-directional Graph Structure Information Model for Multi-Person Pose Estimation**\n\n[https://arxiv.org/abs/1805.00603](https://arxiv.org/abs/1805.00603)\n\n**MultiPoseNet: Fast Multi-Person Pose Estimation using Pose Residual Network**\n\n- intro: ECCV 2018. Middle East Technical University\n- keywords: Pose Residual Network (PRN), person detection, keypoint detection, person segmentation and pose estimation\n- arxiv: [https://arxiv.org/abs/1807.04067](https://arxiv.org/abs/1807.04067)\n- github: [https://github.com/mkocabas/pose-residual-network](https://github.com/mkocabas/pose-residual-network)\n\n**Deep Autoencoder for Combined Human Pose Estimation and body Model Upscaling**\n\n[https://arxiv.org/abs/1807.01511](https://arxiv.org/abs/1807.01511)\n\n**Learning Human Poses from Actions**\n\n- intro: BMVC 2018\n- arxiv: [https://arxiv.org/abs/1807.09075](https://arxiv.org/abs/1807.09075)\n\n**Multi-Scale Supervised Network for Human Pose Estimation**\n\n- intro: ICIP 2018\n- arxiv: [https://arxiv.org/abs/1808.01623](https://arxiv.org/abs/1808.01623)\n\n**CU-Net: Coupled U-Nets**\n\n- intro: BMVC 2018 (Oral)\n- arxiv: [https://arxiv.org/abs/1808.06521](https://arxiv.org/abs/1808.06521)\n\n**Multi-Domain Pose Network for Multi-Person Pose Estimation and Tracking**\n\n[https://arxiv.org/abs/1810.08338](https://arxiv.org/abs/1810.08338)\n\n**Benchmarking and Error Diagnosis in Multi-Instance Pose Estimation**\n\n- intro: ICCV 2017\n- project page: [http://www.vision.caltech.edu/~mronchi/projects/PoseErrorDiagnosis/](http://www.vision.caltech.edu/~mronchi/projects/PoseErrorDiagnosis/)\n- arxiv: [https://arxiv.org/abs/1707.05388](https://arxiv.org/abs/1707.05388)\n- github: [https://github.com/matteorr/coco-analyze](https://github.com/matteorr/coco-analyze)\n\n**Improving Multi-Person Pose Estimation using Label Correction**\n\n[https://arxiv.org/abs/1811.03331](https://arxiv.org/abs/1811.03331)\n\n**Fast Human Pose Estimation**\n\n- intro: Fast Pose Distillation (FPD)\n- arxiv: [https://arxiv.org/abs/1811.05419](https://arxiv.org/abs/1811.05419)\n\n**PoseFix: Model-agnostic General Human Pose Refinement Network**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1812.03595](https://arxiv.org/abs/1812.03595)\n- github(TensorFlow): [https://github.com/mks0601/PoseFix_RELEASE](https://github.com/mks0601/PoseFix_RELEASE)\n\n**Rethinking on Multi-Stage Networks for Human Pose Estimation**\n\n- intro: Megvii Inc. (Face++) & Shanghai Jiao Tong University & Beihang University & Beijing University of Posts and Telecommunications\n- arxiv: [https://arxiv.org/abs/1901.00148](https://arxiv.org/abs/1901.00148)\n- github: [https://github.com/fenglinglwb/MSPN](https://github.com/fenglinglwb/MSPN)\n\n**Deep High-Resolution Representation Learning for Human Pose Estimation**\n\n- intro: CVPR 2019\n- intro: University of Science and Technology of China & Microsoft Research Asia\n- keywords: HRNet\n- arxiv: [https://arxiv.org/abs/1902.09212](https://arxiv.org/abs/1902.09212)\n- project page: [https://jingdongwang2017.github.io/Projects/HRNet/PoseEstimation.html](https://jingdongwang2017.github.io/Projects/HRNet/PoseEstimation.html)\n- github(official): [https://github.com/leoxiaobin/deep-high-resolution-net.pytorch](https://github.com/leoxiaobin/deep-high-resolution-net.pytorch)\n\n**A Context-and-Spatial Aware Network for Multi-Person Pose Estimation**\n\n[https://arxiv.org/abs/1905.05355](https://arxiv.org/abs/1905.05355)\n\n**FastPose: Towards Real-time Pose Estimation and Tracking via Scale-normalized Multi-task Networks**\n\n- intro: Chinese Academy of Sciences & BUPT & Horizon Robotics\n- arxiv: [https://arxiv.org/abs/1908.06290](https://arxiv.org/abs/1908.06290)\n\n**Single-Stage Multi-Person Pose Machines**\n\n- intro: ICCV 2019\n- intro: Yitu Technology\n- arxiv: [https://arxiv.org/abs/1908.09220](https://arxiv.org/abs/1908.09220)\n\n**Single-Network Whole-Body Pose Estimation**\n\n- intro: ICCV 2019\n- project page: [https://github.com/CMU-Perceptual-Computing-Lab/openpose_train](https://github.com/CMU-Perceptual-Computing-Lab/openpose_train)\n- arxiv: [https://arxiv.org/abs/1909.13423](https://arxiv.org/abs/1909.13423)\n\n**NADS-Net: A Nimble Architecture for Driver and Seat Belt Detection via Convolutional Neural Networks**\n\n[https://arxiv.org/abs/1910.03695](https://arxiv.org/abs/1910.03695)\n\n**Distribution-Aware Coordinate Representation for Human Pose Estimation**\n\n- intro: CVPR 2020\n- keywords: Distribution-Aware coordinate Representation of Keypoint (DARK)\n- intro: Results on the COCO keypoint detection challenge: 78.9% AP on the test-dev set (Top-1 in the leaderbord by 12 Oct 2019) and 76.4% AP on the test-challenge set.\n- project page: [https://ilovepose.github.io/coco/](https://ilovepose.github.io/coco/)\n- arxiv: [https://arxiv.org/abs/1910.06278](https://arxiv.org/abs/1910.06278)\n- github: [https://github.com/ilovepose/DarkPose](https://github.com/ilovepose/DarkPose)\n\n**TRB: A Novel Triplet Representation for Understanding 2D Human Body**\n\n- intro: ICCV 2019\n- arxiv: [https://arxiv.org/abs/1910.11535](https://arxiv.org/abs/1910.11535)\n\n**Chirality Nets for Human Pose Regression**\n\n- intro: NeurIPS 2019\n- arxiv: [https://arxiv.org/abs/1911.00029](https://arxiv.org/abs/1911.00029)\n\n**Conservative Wasserstein Training for Pose Estimation**\n\n- intro: ICCV 2019\n- arxiv: [https://arxiv.org/abs/1911.00962](https://arxiv.org/abs/1911.00962)\n\n**DirectPose: Direct End-to-End Multi-Person Pose Estimation**\n\n- intro: The University of Adelaide\n- keywords: Keypoint Alignment (KPAlign)\n- arxiv: [https://arxiv.org/abs/1911.07451](https://arxiv.org/abs/1911.07451)\n\n**The Devil is in the Details: Delving into Unbiased Data Processing for Human Pose Estimation**\n\n- intro: CVPR 2020\n- intro: XForwardAI Technology Co.,Ltd & Tsinghua University\n- arxiv: [https://arxiv.org/abs/1911.07524](https://arxiv.org/abs/1911.07524)\n- github: [https://github.com/HuangJunJie2017/UDP-Pose](https://github.com/HuangJunJie2017/UDP-Pose)\n\n**Simple Pose: Rethinking and Improving a Bottom-up Approach for Multi-Person Pose Estimation**\n\n- intro: AAAI 2020\n- arxiv: [https://arxiv.org/abs/1911.10529](https://arxiv.org/abs/1911.10529)\n- github: [https://github.com/hellojialee/Improved-Body-Parts](https://github.com/hellojialee/Improved-Body-Parts)\n\n**HintPose**\n\n- intro: Joint COCO and Mapillary Workshop at ICCV 2019: Keypoint Detection Challenge Track\n- arxiv: [https://arxiv.org/abs/2003.02170](https://arxiv.org/abs/2003.02170)\n\n**How to Train Your Robust Human Pose Estimator: Pay Attention to the Constraint Cue**\n\n- intro: XForwardAI Technology Co.,Ltd & Tsinghua University\n- arxiv: [https://arxiv.org/abs/2008.07139](https://arxiv.org/abs/2008.07139)\n\n**CoKe: Localized Contrastive Learning for Robust Keypoint Detection**\n\n- intro: Johns Hopkins University\n- arxiv: [https://arxiv.org/abs/2009.14115](https://arxiv.org/abs/2009.14115)\n\n**View-Invariant, Occlusion-Robust Probabilistic Embedding for Human Pose**\n\n- intro: Google Research & California Institute of Technology & Rutgers University\n- arxiv: [https://arxiv.org/abs/2010.13321](https://arxiv.org/abs/2010.13321)\n- gtihub: [https://github.com/google-research/google-research/tree/master/poem](https://github.com/google-research/google-research/tree/master/poem)\n\n**An Empirical Study of the Collapsing Problem in Semi-Supervised 2D Human Pose Estimation**\n\n- intro: Peking University & Microsoft Research Asia\n- arxiv: [https://arxiv.org/abs/2011.12498](https://arxiv.org/abs/2011.12498)\n\n**EfficientPose: Efficient Human Pose Estimation with Neural Architecture Search**\n\n[https://arxiv.org/abs/2012.07086](https://arxiv.org/abs/2012.07086)\n\n**TransPose: Towards Explainable Human Pose Estimation by Transformer**\n\n- intro: Southeast University\n- arxiv: [https://arxiv.org/abs/2012.14214](https://arxiv.org/abs/2012.14214)\n- github: [https://github.com/yangsenius/TransPose](https://github.com/yangsenius/TransPose)\n\n**Rethinking the Heatmap Regression for Bottom-up Human Pose Estimation**\n\n[https://arxiv.org/abs/2012.15175](https://arxiv.org/abs/2012.15175)\n\n**Multi-Hypothesis Pose Networks: Rethinking Top-Down Pose Estimation**\n\n[https://arxiv.org/abs/2101.11223](https://arxiv.org/abs/2101.11223)\n\n**OmniPose: A Multi-Scale Framework for Multi-Person Pose Estimation**\n\n[https://arxiv.org/abs/2103.10180](https://arxiv.org/abs/2103.10180)\n\n**End-to-End Trainable Multi-Instance Pose Estimation with Transformers**\n\n- intro: Swiss Federal Institute of Technology (EPFL)\n- arxiv: [https://arxiv.org/abs/2103.12115](https://arxiv.org/abs/2103.12115)\n\n**TFPose: Direct Human Pose Estimation with Transformers**\n\n- intro: The University of Adelaide & Alibaba Group\n- arxiv: [https://arxiv.org/abs/2103.15320](https://arxiv.org/abs/2103.15320)\n\n**TokenPose: Learning Keypoint Tokens for Human Pose Estimation**\n\n- intro: MEGVII Technology & Tsinghua University & Southeast University & Peng Cheng Laboratory\n- arxiv: [https://arxiv.org/abs/2104.03516](https://arxiv.org/abs/2104.03516)\n\n**Pose Recognition with Cascade Transformers**\n\n- intro: CVPR 2021\n- arxiv: [https://arxiv.org/abs/2104.06976](https://arxiv.org/abs/2104.06976)\n- github: [https://github.com/mlpc-ucsd/PRTR](https://github.com/mlpc-ucsd/PRTR)\n\n**Is 2D Heatmap Representation Even Necessary for Human Pose Estimation?**\n\n- intro: Tsinghua University & MEGVII Technology & Southeast University & Peng Cheng Laboratory\n- arxiv: [https://arxiv.org/abs/2107.03332](https://arxiv.org/abs/2107.03332)\n- github: [https://github.com/leeyegy/SimDR](https://github.com/leeyegy/SimDR)\n\n**InsPose: Instance-Aware Networks for Single-Stage Multi-Person Pose Estimation**\n\n- intro: ACM MM 2021\n- arxiv: [https://arxiv.org/abs/2107.08982](https://arxiv.org/abs/2107.08982)\n\n**Adaptive Dilated Convolution For Human Pose Estimation**\n\n- intro: Megvii & UCAS & CRIPAC & NLPR & CASIA\n- arxiv: [https://arxiv.org/abs/2107.10477](https://arxiv.org/abs/2107.10477)\n\n**PoseDet: Fast Multi-Person Pose Estimation Using Pose Embedding**\n\n- intro: Tsinghua University & Northwestern University\n- arxiv: [https://arxiv.org/abs/2107.10466](https://arxiv.org/abs/2107.10466)\n\n**Online Knowledge Distillation for Efficient Pose Estimation**\n\n- intro: ICCV 2021\n- arxiv: [https://arxiv.org/abs/2108.02092](https://arxiv.org/abs/2108.02092)\n\n**SmoothNet: A Plug-and-Play Network for Refining Human Poses in Videos**\n\n- intro: The Chinese University of Hong Kong & Sensetime Group Ltd. &Shanghai Jiao Tong University & Nanyang Technological University\n- project page: [https://ailingzeng.site/smoothnet](https://ailingzeng.site/smoothnet)\n- arxiv: [https://arxiv.org/abs/2112.13715](https://arxiv.org/abs/2112.13715)\n\n**AdaptivePose: Human Parts as Adaptive Points**\n\n- intro: AAAI 2022\n- intro: Beijing University of Posts and Telecommunications & ByteDance Inc. & Tsinghua University &  Horizon Robotics\n- arxiv: [https://arxiv.org/abs/2112.13635](https://arxiv.org/abs/2112.13635)\n\n**Learning Quality-aware Representation for Multi-person Pose Regression**\n\n- intro: AAAI 2022\n- intro: Beijing University of Posts and Telecommunications & ByteDance Inc. & Tsinghua University &  Horizon Robotics\n- arxiv: [https://arxiv.org/abs/2201.01087](https://arxiv.org/abs/2201.01087)\n\n**Recognition of Freely Selected Keypoints on Human Limbs**\n\n- intro: CVPR 2022 Workshops\n- arxiv: [https://arxiv.org/abs/2204.06326](https://arxiv.org/abs/2204.06326)\n\n**YOLO-Pose: Enhancing YOLO for Multi Person Pose Estimation Using Object Keypoint Similarity Loss**\n\n- intro: Texas Instruments Inc\n- arxiv: [https://arxiv.org/abs/2204.06806](https://arxiv.org/abs/2204.06806)\n- github: [https://github.com/TexasInstruments/edgeai-yolov5](https://github.com/TexasInstruments/edgeai-yolov5)\n- github: [https://github.com/TexasInstruments/edgeai-yolox](https://github.com/TexasInstruments/edgeai-yolox)\n\n**Lite Pose: Efficient Architecture Design for 2D Human Pose Estimation**\n\n- intro: Tsinghua University & CMU & MIT\n- arxiv: [https://arxiv.org/abs/2205.01271](https://arxiv.org/abs/2205.01271)\n- github: [https://github.com/mit-han-lab/litepose](https://github.com/mit-han-lab/litepose)\n\n# Regression-based Method\n\n**Integral Human Pose Regression**\n\n- intro: ECCV 2018\n- arxiv: [https://arxiv.org/abs/1711.08229](https://arxiv.org/abs/1711.08229)\n- slides: [https://jimmysuen.github.io/slides/xiaosun_integral_human_pose_regression.pptx](https://jimmysuen.github.io/slides/xiaosun_integral_human_pose_regression.pptx)\n- github: [https://github.com/JimmySuen/integral-human-pose](https://github.com/JimmySuen/integral-human-pose)\n\n**Human Pose Regression with Residual Log-likelihood Estimation**\n\n- intro: ICCV 2021 Oral\n- intro: Shanghai Jiao Tong University & The Chinese University of Hong Kong & SenseTime Research\n- arxiv: [https://arxiv.org/abs/2107.11291](https://arxiv.org/abs/2107.11291)\n- github: [https://github.com/Jeff-sjtu/res-loglikelihood-regression](https://github.com/Jeff-sjtu/res-loglikelihood-regression)\n\n**Poseur: Direct Human Pose Regression with Transformers**\n\n- intro: The University of Adelaide & Alibaba Damo Academy & Zhejiang University\n- arxiv: [https://arxiv.org/abs/2201.07412](https://arxiv.org/abs/2201.07412)\n\n**Location-free Human Pose Estimation**\n\n- intro: Beijing Jiaotong University & Tencent Youtu Lab\n- arxiv: [https://arxiv.org/abs/2205.12619](https://arxiv.org/abs/2205.12619)\n\n# Top-Down\n\n**Point-Set Anchors for Object Detection, Instance Segmentation and Pose Estimation**\n\n- intro: ECCV 2020\n- intro: MSRA & Peking University\n- arxiv: [https://arxiv.org/abs/2007.02846](https://arxiv.org/abs/2007.02846)\n- github: [https://github.com/FangyunWei/PointSetAnchor](https://github.com/FangyunWei/PointSetAnchor)\n\n# Bottom-Up\n\n**PifPaf: Composite Fields for Human Pose Estimation**\n\n- intro: CVPR 2019\n- intro: EPFL VITA lab\n- keywords: Part Intensity Field (PIF), Part Association Field (PAF)\n- arxiv: [https://arxiv.org/abs/1903.06593](https://arxiv.org/abs/1903.06593)\n\n**OpenPifPaf: Composite Fields for Semantic Keypoint Detection and Spatio-Temporal Association**\n\n- project: [https://openpifpaf.github.io/intro.html](https://openpifpaf.github.io/intro.html)\n- intro: [https://arxiv.org/abs/2103.02440](https://arxiv.org/abs/2103.02440)\n- github: [https://github.com/openpifpaf/openpifpaf](https://github.com/openpifpaf/openpifpaf)\n\n**Bottom-Up Human Pose Estimation Via Disentangled Keypoint Regression**\n\n- intro: CVPR 2021\n- keywords: DEKR\n- intro: University of Science and Technology of China & University of Chinese Academy of Sciences & Microsof\n- arxiv: [https://arxiv.org/abs/2104.02300](https://arxiv.org/abs/2104.02300)\n- github: [https://github.com/HRNet/DEKR](https://github.com/HRNet/DEKR)\n\n**DeepSportLab: a Unified Framework for Ball Detection, Player Instance Segmentation and Pose Estimation in Team Sports Scenes**\n\n- intro: BMVC 2021\n- arxiv: [https://arxiv.org/abs/2112.00627](https://arxiv.org/abs/2112.00627)\n- github: [https://github.com/ispgroupucl/DeepSportLab](https://github.com/ispgroupucl/DeepSportLab)\n\n**Learning Local-Global Contextual Adaptation for Fully End-to-End Bottom-Up Human Pose Estimation**\n\n- intro: Wuhan University & North Carolina State University\n- arxiv: [https://arxiv.org/abs/2109.03622](https://arxiv.org/abs/2109.03622)\n\n**Keypoint Communities**\n\n- intro: ICCV 2021\n- arxiv: [https://arxiv.org/abs/2110.00988](https://arxiv.org/abs/2110.00988)\n\n**The Center of Attention: Center-Keypoint Grouping via Attention for Multi-Person Pose Estimation**\n\n- intro: ICCV 2021\n- intro: Technical University of Munich\n- arxiv: [https://arxiv.org/abs/2110.05132](https://arxiv.org/abs/2110.05132)\n\n**Self-Supervision and Spatial-Sequential Attention Based Loss for Multi-Person Pose Estimation**\n\n[https://arxiv.org/abs/2110.10734](https://arxiv.org/abs/2110.10734)\n\n**Learning Local-Global Contextual Adaptation for Multi-Person Pose Estimation**\n\n- intro: CVPR 2022\n- intro: Wuhan University, NC State University\n- arxiv: [https://arxiv.org/abs/2109.03622](https://arxiv.org/abs/2109.03622)\n\n**I^2R-Net: Intra- and Inter-Human Relation Network for Multi-Person Pose Estimation**\n\n- intro: Xiamen University & Microsoft Research Asia\n- arxiv: [https://arxiv.org/abs/2206.10892](https://arxiv.org/abs/2206.10892)\n\n**End-to-End Multi-Person Pose Estimation with Transformers**\n\n- intro: CVPR 2022 Oral\n- paper: [https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_End-to-End_Multi-Person_Pose_Estimation_With_Transformers_CVPR_2022_paper.pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_End-to-End_Multi-Person_Pose_Estimation_With_Transformers_CVPR_2022_paper.pdf)\n- github: [https://github.com/hikvision-research/opera/tree/main/configs/petr](https://github.com/hikvision-research/opera/tree/main/configs/petr)\n\n# Hand Pose\n\n**Model-based Deep Hand Pose Estimation**\n\n- paper: [http://xingyizhou.xyz/zhou2016model.pdf](http://xingyizhou.xyz/zhou2016model.pdf)\n- github: [https://github.com/tenstep/DeepModel](https://github.com/tenstep/DeepModel)\n\n**Region Ensemble Network: Improving Convolutional Network for Hand Pose Estimation**\n\n- arxiv: [https://arxiv.org/abs/1702.02447](https://arxiv.org/abs/1702.02447)\n\n**Crossing Nets: Combining GANs and VAEs with a Shared Latent Space for Hand Pose Estimation**\n\n- intro: CVPR 2017\n- arxiv: [https://arxiv.org/abs/1702.03431](https://arxiv.org/abs/1702.03431)\n\n**Learning to Disambiguate Strongly Interacting Hands via Probabilistic Per-pixel Part Segmentation**\n\n- intro: 3DV 2021 Oral\n- arxiv: [https://arxiv.org/abs/2107.00434](https://arxiv.org/abs/2107.00434)\n- github: [https://github.com/zc-alexfan/digit-interacting](https://github.com/zc-alexfan/digit-interacting)\n\n# 3D Pose\n\n**Can 3D Pose be Learned from 2D Projections Alone?**\n\n- intro: ECCV 2018 workshop\n- arxiv: [https://arxiv.org/abs/1808.07182](https://arxiv.org/abs/1808.07182)\n\n**Fast and Robust Multi-Person 3D Pose Estimation from Multiple Views**\n\n- project page: [https://zju-3dv.github.io/mvpose/](https://zju-3dv.github.io/mvpose/)\n- arxiv: [https://arxiv.org/abs/1901.04111](https://arxiv.org/abs/1901.04111)\n- github: [https://github.com/zju-3dv/mvpose](https://github.com/zju-3dv/mvpose)\n\n**3D Human Pose Machines with Self-supervised Learning**\n\n- intro: T-PAMI 2019\n- project page: [http://www.sysu-hcp.net/3d_pose_ssl/](http://www.sysu-hcp.net/3d_pose_ssl/)\n- arxiv: [https://arxiv.org/abs/1901.03798](https://arxiv.org/abs/1901.03798)\n- github: [https://github.com/chanyn/3Dpose_ssl](https://github.com/chanyn/3Dpose_ssl)\n\n**Feature Boosting Network For 3D Pose Estimation**\n\n- intro: Nanyang Technological University & Chalmers University of Technology & Peking University & Alibaba Group\n- arxiv: [https://arxiv.org/abs/1901.04877](https://arxiv.org/abs/1901.04877)\n\n**View Invariant 3D Human Pose Estimation**\n\n- intro: MSRA & USTC\n- arxiv: [https://arxiv.org/abs/1901.10841](https://arxiv.org/abs/1901.10841)\n\n**3D Human Pose Estimation from Deep Multi-View 2D Pose**\n\n[https://arxiv.org/abs/1902.02841](https://arxiv.org/abs/1902.02841)\n\n**RepNet: Weakly Supervised Training of an Adversarial Reprojection Network for 3D Human Pose Estimation**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1902.09868](https://arxiv.org/abs/1902.09868)\n\n**DenseBody: Directly Regressing Dense 3D Human Pose and Shape From a Single Color Image**\n\n- intro: Cloudwalk & Shanghai Jiao Tong University\n- arxiv: [https://arxiv.org/abs/1903.10153](https://arxiv.org/abs/1903.10153)\n\n**Camera Distance-aware Top-down Approach for 3D Multi-person Pose Estimation from a Single RGB Image**\n\n- intro: ICCV 2019\n- arxiv: [https://arxiv.org/abs/1907.11346](https://arxiv.org/abs/1907.11346)\n- github: [https://github.com/mks0601/3DMPPE_ROOTNET_RELEASE](https://github.com/mks0601/3DMPPE_ROOTNET_RELEASE)\n\n**Lightweight 3D Human Pose Estimation Network Training Using Teacher-Student Learning**\n\n[https://arxiv.org/abs/2001.05097](https://arxiv.org/abs/2001.05097)\n\n**Cross-View Tracking for Multi-Human 3D Pose Estimation at over 100 FPS**\n\n- intro: CVPR 2020\n- intro: Tsinghua University & AiFi Inc.\n- arxiv: [https://arxiv.org/abs/2003.03972](https://arxiv.org/abs/2003.03972)\n\n**Skeletor: Skeletal Transformers for Robust Body-Pose Estimation**\n\n- intro: University of Surrey\n- arxiv: [https://arxiv.org/abs/2104.11712](https://arxiv.org/abs/2104.11712)\n\n**UltraPose: Synthesizing Dense Pose with 1 Billion Points by Human-body Decoupling 3D Model**\n\n- intro: ICCV 2021\n- intro: Beijing Momo Technology Co., Ltd. & Sun Yat-sen University\n- arxiv: [https://arxiv.org/abs/2110.15267](https://arxiv.org/abs/2110.15267)\n- github: [https://github.com/MomoAILab/ultrapose](https://github.com/MomoAILab/ultrapose)\n\n**Distribution-Aware Single-Stage Models for Multi-Person 3D Pose Estimation**\n\n- intro: CVPR 2022\n- intro: Beihang University & Meitu Inc.\n- arxiv: [https://arxiv.org/abs/2203.07697](https://arxiv.org/abs/2203.07697)\n\n**DeciWatch: A Simple Baseline for 10x Efficient 2D and 3D Pose Estimation**\n\n- intro: The Chinese University of Hong Kong & Sensetime Group Ltd. &  Shanghai Artificial Intelligence Laboratory\n- project page: [https://ailingzeng.site/deciwatch](https://ailingzeng.site/deciwatch)\n- arxiv: [https://arxiv.org/abs/2203.08713](https://arxiv.org/abs/2203.08713)\n\n# 3D Car keypoints Detection\n\n**Occlusion-Net: 2D/3D Occluded Keypoint Localization Using Graph Networks**\n\n- intro: CVPR 2019\n- paper: [http://openaccess.thecvf.com/content_CVPR_2019/papers/Reddy_Occlusion-Net_2D3D_Occluded_Keypoint_Localization_Using_Graph_Networks_CVPR_2019_paper.pdf](http://openaccess.thecvf.com/content_CVPR_2019/papers/Reddy_Occlusion-Net_2D3D_Occluded_Keypoint_Localization_Using_Graph_Networks_CVPR_2019_paper.pdf)\n- github: [https://github.com/dineshreddy91/Occlusion_Net](https://github.com/dineshreddy91/Occlusion_Net)\n\n**RTM3D: Real-time Monocular 3D Detection from Object Keypoints for Autonomous Driving**\n\n- intro: Chinese Academy of Sciences & University of Chinese Academy of Sciences\n- arxiv: [https://arxiv.org/abs/2001.03343](https://arxiv.org/abs/2001.03343)\n- github: [https://github.com/Banconxuan/RTM3D](https://github.com/Banconxuan/RTM3D)\n\n**SMOKE: Single-Stage Monocular 3D Object Detection via Keypoint Estimation**\n\n- intro: 1ZongMu Tech & TU/e\n- arxiv: [https://arxiv.org/abs/2002.10111](https://arxiv.org/abs/2002.10111)\n\n# Pose Estimation and Action Recognition\n\n**2D/3D Pose Estimation and Action Recognition using Multitask Deep Learning**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1802.09232](https://arxiv.org/abs/1802.09232)\n\n**Multi-task Deep Learning for Real-Time 3D Human Pose Estimation and Action Recognition**\n\n- arxiv: [https://arxiv.org/abs/1912.08077](https://arxiv.org/abs/1912.08077)\n- github: [https://github.com/dluvizon/deephar](https://github.com/dluvizon/deephar)\n\n**Video Pose Distillation for Few-Shot, Fine-Grained Sports Action Recognition**\n\n- intro: ICCV 2021 poster\n- intro: Stanford University & Adobe Research\n- arxiv: [https://arxiv.org/abs/2109.01305](https://arxiv.org/abs/2109.01305)\n\n**Skeleton Sequence and RGB Frame Based Multi-Modality Feature Fusion Network for Action Recognition**\n\n- intro: ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)\n- arxiv: [https://arxiv.org/abs/2202.11374](https://arxiv.org/abs/2202.11374)\n\n**Revisiting Skeleton-based Action Recognition**\n\n- intro: CVPR 2022 Oral\n- keywords: PoseConv3D\n- arxiv: [https://arxiv.org/abs/2104.13586](https://arxiv.org/abs/2104.13586)\n- github: [https://github.com/kennymckormick/pyskl](https://github.com/kennymckormick/pyskl)\n- github: [https://github.com/open-mmlab/mmaction2/blob/master/configs/skeleton/posec3d/README.md](https://github.com/open-mmlab/mmaction2/blob/master/configs/skeleton/posec3d/README.md)\n\n# Pose Tracking\n\n**Detect-and-Track: Efficient Pose Estimation in Videos**\n\n- intro: CVPR 2018. CMU & Facebook & Dartmouth\n- intro: Ranked first in ICCV 2017 PoseTrack challenge (keypoint tracking in videos)\n- project page: [https://rohitgirdhar.github.io/DetectAndTrack/](https://rohitgirdhar.github.io/DetectAndTrack/)\n- arxiv: [https://arxiv.org/abs/1712.09184](https://arxiv.org/abs/1712.09184)\n- paper: [http://openaccess.thecvf.com/content_cvpr_2018/papers/Girdhar_Detect-and-Track_Efficient_Pose_CVPR_2018_paper.pdf](http://openaccess.thecvf.com/content_cvpr_2018/papers/Girdhar_Detect-and-Track_Efficient_Pose_CVPR_2018_paper.pdf)\n- github: [https://github.com/facebookresearch/DetectAndTrack/](https://github.com/facebookresearch/DetectAndTrack/)\n\n**Simple Baselines for Human Pose Estimation and Tracking**\n\n- intro: ECCV 2018\n- intro: MSRA\n- keywords: optical flow based pose propagation and similarity measurement\n- arxiv: [https://arxiv.org/abs/1804.06208](https://arxiv.org/abs/1804.06208)\n- github(official): [https://github.com/Microsoft/human-pose-estimation.pytorch](https://github.com/Microsoft/human-pose-estimation.pytorch)\n\n**A Top-down Approach to Articulated Human Pose Estimation and Tracking**\n\n- intro: JD.com Silicon Valley Research Center\n- intro: ECCVW 2018. Workshop: 2nd PoseTrack Challenge\n- arxiv: [https://arxiv.org/abs/1901.07680](https://arxiv.org/abs/1901.07680)\n\n**15 Keypoints Is All You Need**\n\n- intro: Brown University & NEC Labs America\n- arxiv: [https://arxiv.org/abs/1912.02323](https://arxiv.org/abs/1912.02323)\n\n**Learning Dynamics via Graph Neural Networks for Human Pose Estimation and Tracking**\n\n- intro: CVPR 2021\n- intro: Stevens Institute of Technology & Wormpex AI Research & National University of Singapore\n- arxiv: [https://arxiv.org/abs/2106.03772](https://arxiv.org/abs/2106.03772)\n\n# Object Pose Estimation\n\n**Real-Time Object Pose Estimation with Pose Interpreter Networks**\n\n- intro: 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2018)\n- arxiv: [https://arxiv.org/abs/1808.01099](https://arxiv.org/abs/1808.01099)\n- github: [https://github.com/jimmyyhwu/pose-interpreter-networks](https://github.com/jimmyyhwu/pose-interpreter-networks)\n\n# Projects\n\n**MobilePose: Single Person Pose Estimation for Mobile Device**\n\n- intro: a Tiny PyTorch implementation of single person 2D pose estimation framework\n- github: [https://github.com/YuliangXiu/MobilePose-pytorch](https://github.com/YuliangXiu/MobilePose-pytorch)\n github: [https://github.com/MVIG-SJTU/AlphaPose](https://github.com/MVIG-SJTU/AlphaPose)\n\n**PyTorch-Pose: A PyTorch toolkit for 2D Human Pose Estimation**\n\n- intro: a PyTorch implementation of the general pipeline for 2D single human pose estimation.\n- github: [https://github.com/bearpaw/pytorch-pose](https://github.com/bearpaw/pytorch-pose)\n\n**Hourglass, DHN and CPN model in TensorFlow for 2018-FashionAI Key Points Detection of Apparel at TianChi**\n\n- intro: Full pipeline for TianChi FashionAI clothes keypoints detection compitetion in TensorFlow\n- github: [https://github.com/HiKapok/tf.fashionAI](https://github.com/HiKapok/tf.fashionAI)\n\n**FashionAI: KeyPoint Detection Challenge in Keras**\n\n- intro: Code for TianChi 2018 FashionAI Cloth KeyPoint Detection Challenge\n- github: [https://github.com/yuanyuanli85/FashionAI_KeyPoint_Detection_Challenge_Keras](https://github.com/yuanyuanli85/FashionAI_KeyPoint_Detection_Challenge_Keras)\n\n# Challenge\n\n**POSETRACK CHALLENGE: ARTICULATED PEOPLE TRACKING IN THE WILD**\n\n[https://posetrack.net/workshops/eccv2018/#challenges](https://posetrack.net/workshops/eccv2018/#challenges)\n","excerpt":"Papers DeepPose: Human Pose Estimation via Deep Neural Networks intro: CVPR 2014 arxiv:  http://arxiv.org/abs/1312.4659 slides:  http://140","outboundReferences":[],"inboundReferences":[]},"tagsOutbound":{"nodes":[]}},"pageContext":{"tags":[],"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-pose-estimation/","sidebarItems":[{"title":"Categories","items":[{"title":"Commercial","url":"","items":[{"title":"Commercial Structure","url":"/Commercial/Commercial Structure/","items":[]},{"title":"Community of Practice","url":"/Commercial/Community of Practice/","items":[]},{"title":"Domains","url":"/Commercial/Domains/","items":[]},{"title":"Webizen Alliance","url":"/Commercial/Webizen Alliance/","items":[]}]},{"title":"Core Services","url":"","items":[{"title":"Decentralised Ontologies","url":"/Core Services/Decentralised Ontologies/","items":[]},{"title":"Permissive Commons","url":"/Core Services/Permissive Commons/","items":[]},{"title":"Safety Protocols","url":"","items":[{"title":"Safety Protocols","url":"/Core Services/Safety Protocols/Safety Protocols/","items":[]},{"title":"Social Factors","url":"","items":[{"title":"Best Efforts","url":"/Core Services/Safety Protocols/Social Factors/Best Efforts/","items":[]},{"title":"Ending Digital Slavery","url":"/Core Services/Safety Protocols/Social Factors/Ending Digital Slavery/","items":[]},{"title":"Freedom of Thought","url":"/Core Services/Safety Protocols/Social Factors/Freedom of Thought/","items":[]},{"title":"No Golden Handcuffs","url":"/Core Services/Safety Protocols/Social Factors/No Golden Handcuffs/","items":[]},{"title":"Relationships (Social)","url":"/Core Services/Safety Protocols/Social Factors/Relationships (Social)/","items":[]},{"title":"Social Attack Vectors","url":"/Core Services/Safety Protocols/Social Factors/Social Attack Vectors/","items":[]},{"title":"The Webizen Charter","url":"/Core Services/Safety Protocols/Social Factors/The Webizen Charter/","items":[]}]},{"title":"Values Credentials","url":"/Core Services/Safety Protocols/Values Credentials/","items":[]}]},{"title":"Temporal Semantics","url":"/Core Services/Temporal Semantics/","items":[]},{"title":"Verifiable Claims & Credentials","url":"/Core Services/Verifiable Claims & Credentials/","items":[]},{"title":"Webizen Socio-Economics","url":"","items":[{"title":"Biosphere Ontologies","url":"/Core Services/Webizen Socio-Economics/Biosphere Ontologies/","items":[]},{"title":"Centricity","url":"/Core Services/Webizen Socio-Economics/Centricity/","items":[]},{"title":"Currencies","url":"/Core Services/Webizen Socio-Economics/Currencies/","items":[]},{"title":"SocioSphere Ontologies","url":"/Core Services/Webizen Socio-Economics/SocioSphere Ontologies/","items":[]},{"title":"Sustainable Development Goals (ESG)","url":"/Core Services/Webizen Socio-Economics/Sustainable Development Goals (ESG)/","items":[]}]}]},{"title":"Core Technologies","url":"","items":[{"title":"AUTH","url":"","items":[{"title":"Authentication Fabric","url":"/Core Technologies/AUTH/Authentication Fabric/","items":[]}]},{"title":"Webizen App Spec","url":"","items":[{"title":"SemWebSpecs","url":"","items":[{"title":"Core Ontologies","url":"","items":[{"title":"FOAF","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/FOAF/","items":[]},{"title":"General Ontology Information","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/General Ontology Information/","items":[]},{"title":"Human Rights Ontologies","url":"","items":[{"title":"UDHR","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/Human Rights Ontologies/UDHR/","items":[]}]},{"title":"MD-RDF Ontologies","url":"","items":[{"title":"DataTypesOntology (DTO) Core","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/MD-RDF Ontologies/DataTypes Ontology/","items":[]},{"title":"Friend of a Friend (FOAF) Core","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/MD-RDF Ontologies/FOAF/","items":[]}]},{"title":"OWL","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/OWL/","items":[]},{"title":"RDF Schema 1.1","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/RDFS/","items":[]},{"title":"Sitemap","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/Sitemap/","items":[]},{"title":"SKOS","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/SKOS/","items":[]},{"title":"SOIC","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/SOIC/","items":[]}]},{"title":"Semantic Web - An Introduction","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Semantic Web - An Introduction/","items":[]},{"title":"SemWeb-AUTH","url":"","items":[{"title":"WebID-OIDC","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-OIDC/","items":[]},{"title":"WebID-RSA","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-RSA/","items":[]},{"title":"WebID-TLS","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-TLS/","items":[]}]},{"title":"Sparql","url":"","items":[{"title":"Sparql Family","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Sparql/Sparql Family/","items":[]}]},{"title":"W3C Specifications","url":"","items":[{"title":"Linked Data Fragments","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Fragments/","items":[]},{"title":"Linked Data Notifications","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Notifications/","items":[]},{"title":"Linked Data Platform","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Platform/","items":[]},{"title":"Linked Media Fragments","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Media Fragments/","items":[]},{"title":"RDF","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/RDF/","items":[]},{"title":"Web Access Control (WAC)","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Web Access Control (WAC)/","items":[]},{"title":"Web Of Things","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Web Of Things/","items":[]},{"title":"WebID","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/WebID/","items":[]}]}]},{"title":"Webizen App Spec 1.0","url":"/Core Technologies/Webizen App Spec/Webizen App Spec 1.0/","items":[]},{"title":"WebSpec","url":"","items":[{"title":"HTML SPECS","url":"/Core Technologies/Webizen App Spec/WebSpec/HTML SPECS/","items":[]},{"title":"Query Interfaces","url":"","items":[{"title":"GraphQL","url":"/Core Technologies/Webizen App Spec/WebSpec/Query Interfaces/GraphQL/","items":[]}]},{"title":"WebPlatformTools","url":"","items":[{"title":"WebAuthn","url":"/Core Technologies/Webizen App Spec/WebSpec/WebPlatformTools/WebAuthn/","items":[]},{"title":"WebDav","url":"/Core Technologies/Webizen App Spec/WebSpec/WebPlatformTools/WebDav/","items":[]}]}]}]}]},{"title":"Database Requirements","url":"","items":[{"title":"Database Alternatives","url":"","items":[{"title":"Akutan","url":"/Database requirements/Database Alternatives/akutan/","items":[]},{"title":"CayleyGraph","url":"/Database requirements/Database Alternatives/CayleyGraph/","items":[]}]},{"title":"Database Methods","url":"","items":[{"title":"GraphQL","url":"/Database requirements/Database methods/GraphQL/","items":[]},{"title":"Sparql","url":"/Database requirements/Database methods/Sparql/","items":[]}]}]},{"title":"Host Service Requirements","url":"","items":[{"title":"Domain Hosting","url":"/Host Service Requirements/Domain Hosting/","items":[]},{"title":"Email Services","url":"/Host Service Requirements/Email Services/","items":[]},{"title":"LD_PostOffice_SemanticMGR","url":"/Host Service Requirements/LD_PostOffice_SemanticMGR/","items":[]},{"title":"Media Processing","url":"/Host Service Requirements/Media Processing/","items":[{"title":"Ffmpeg","url":"/Host Service Requirements/Media Processing/ffmpeg/","items":[]},{"title":"Opencv","url":"/Host Service Requirements/Media Processing/opencv/","items":[]}]},{"title":"Website Host","url":"/Host Service Requirements/Website Host/","items":[]}]},{"title":"ICT Stack","url":"","items":[{"title":"General References","url":"","items":[{"title":"List of Protocols ISO Model","url":"/ICT Stack/General References/List of Protocols ISO model/","items":[]}]},{"title":"Internet","url":"","items":[{"title":"Internet Stack","url":"/ICT Stack/Internet/Internet Stack/","items":[]}]}]},{"title":"Implementation V1","url":"","items":[{"title":"App-Design-Sdk-V1","url":"","items":[{"title":"Core Apps","url":"","items":[{"title":"Agent Directory","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Agent Directory/","items":[]},{"title":"Credentials & Contracts Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Credentials & Contracts Manager/","items":[]},{"title":"File (Package) Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/File (package) Manager/","items":[]},{"title":"Temporal Apps","url":"","items":[{"title":"Calendar","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Temporal Apps/Calendar/","items":[]},{"title":"Timeline Interface","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Temporal Apps/Timeline Interface/","items":[]}]},{"title":"Webizen Apps (V1)","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Webizen Apps (v1)/","items":[]},{"title":"Webizen Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Webizen Manager/","items":[]}]},{"title":"Data Applications","url":"/Implementation V1/App-design-sdk-v1/Data Applications/","items":[]},{"title":"Design Goals","url":"","items":[{"title":"Design Goals Overview","url":"/Implementation V1/App-design-sdk-v1/Design Goals/Design Goals Overview/","items":[]}]}]},{"title":"Edge","url":"","items":[{"title":"Webizen Local App Functionality","url":"/Implementation V1/edge/Webizen Local App Functionality/","items":[]}]},{"title":"GoLang Libraries","url":"/Implementation V1/GoLang Libraries/","items":[]},{"title":"Implementation V1 Summary","url":"/Implementation V1/Implementation V1 Summary/","items":[]},{"title":"Vps","url":"","items":[{"title":"Server Functionality Summary (VPS)","url":"/Implementation V1/vps/Server Functionality Summary (VPS)/","items":[]}]},{"title":"Webizen 1.0","url":"/Implementation V1/Webizen 1.0/","items":[]},{"title":"Webizen-Connect","url":"","items":[{"title":"Social Media APIs","url":"/Implementation V1/Webizen-Connect/Social Media APIs/","items":[]},{"title":"Webizen-Connect (Summary)","url":"/Implementation V1/Webizen-Connect/Webizen-Connect (summary)/","items":[]}]}]},{"title":"Non-HTTP(s) Protocols","url":"","items":[{"title":"DAT","url":"/Non-HTTP(s) Protocols/DAT/","items":[]},{"title":"GIT","url":"/Non-HTTP(s) Protocols/GIT/","items":[]},{"title":"GUNECO","url":"/Non-HTTP(s) Protocols/GUNECO/","items":[]},{"title":"IPFS","url":"/Non-HTTP(s) Protocols/IPFS/","items":[]},{"title":"Lightning Network","url":"/Non-HTTP(s) Protocols/Lightning Network/","items":[]},{"title":"Non-HTTP(s) Protocols (& DLTs)","url":"/Non-HTTP(s) Protocols/Non-HTTP(s) Protocols (& DLTs)/","items":[]},{"title":"WebRTC","url":"/Non-HTTP(s) Protocols/WebRTC/","items":[]},{"title":"WebSockets","url":"/Non-HTTP(s) Protocols/WebSockets/","items":[]},{"title":"WebTorrent","url":"/Non-HTTP(s) Protocols/WebTorrent/","items":[]}]},{"title":"Old-Work-Archives","url":"","items":[{"title":"2018-Webizen-Net-Au","url":"","items":[{"title":"_Link_library_links","url":"","items":[{"title":"Link Library","url":"/old-work-archives/2018-webizen-net-au/_link_library_links/2018-09-23-wp-linked-data/","items":[]}]},{"title":"_Posts","url":"","items":[{"title":"About W3C","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-27-about-w3c/","items":[]},{"title":"Advanced Functions &#8211; Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-16-advanced-functions-facebook-pages/","items":[]},{"title":"Advanced Search &#038; Discovery Tips","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-advanced-search-discovery-tips/","items":[]},{"title":"An introduction to Virtual Machines.","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-an-introduction-to-virtual-machines/","items":[]},{"title":"Basic Media Analysis &#8211; Part 1 (Audio)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-30-media-analysis-part-1-audio/","items":[]},{"title":"Basic Media Analysis &#8211; Part 2 (visual)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-31-media-analysis-part-2-visual/","items":[]},{"title":"Basic Media Analysis &#8211; Part 3 (Text &#038; Metadata)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-01-01-basic-media-analysis-part-3-text-metadata/","items":[]},{"title":"Building an Economy based upon Knowledge Equity.","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-25-building-an-economy-based-upon-knowledge-equity/","items":[]},{"title":"Choice of Law","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-26-choice-of-law/","items":[]},{"title":"Contemplation of the ITU Dubai Meeting and the Future of the Internet","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-19-contemplation-of-the-itu-dubai-meeting-and-the-future-of-the-internet/","items":[]},{"title":"Creating a Presence &#8211; Online","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-creating-a-presence-online/","items":[]},{"title":"Credentials and Payments by Manu Sporny","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-credentials-and-payments-by-manu-sporny/","items":[]},{"title":"Data Recovery &#038; Collection: Mobile Devices","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-28-mobile-devices-data-recovery-collection/","items":[]},{"title":"Data Recovery: Laptop &#038; Computers","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-28-data-recovery-laptop-computers/","items":[]},{"title":"Decentralized Web Conference 2016","url":"/old-work-archives/2018-webizen-net-au/_posts/2016-06-09-decentralized-web-2016/","items":[]},{"title":"Decentralized Web Summit 2018","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-decentralized-web-summit-2018/","items":[]},{"title":"Does Anonymity exist?","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-does-anonymity-exist/","items":[]},{"title":"Downloading My Data from Social Networks","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-downloading-my-data-from-social-networks/","items":[]},{"title":"Events","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-events/","items":[]},{"title":"Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-16-facebook-pages/","items":[]},{"title":"Google Tracking Data (geolocation)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-google-tracking/","items":[]},{"title":"Human Consciousness","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-human-consciousness/","items":[]},{"title":"Image Recgonition Video Playlist","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-image-recgonition-video-playlist/","items":[]},{"title":"Inferencing (introduction)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-inferencing-introduction/","items":[]},{"title":"Introduction to AI","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-introduction-to-ai/","items":[]},{"title":"Introduction to Linked Data","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-introduction-to-linked-data/","items":[]},{"title":"Introduction to Maltego","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-introduction-to-maltego/","items":[]},{"title":"Introduction to Ontologies","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-ontologies-intro/","items":[]},{"title":"Introduction to Semantic Web","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-introduction-to-semantic-web/","items":[]},{"title":"Knowledge Capital","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-10-17-knowledge-capital/","items":[]},{"title":"Logo&#8217;s, Style Guides and Artwork","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-logos-style-guides-and-artwork/","items":[]},{"title":"MindMapping &#8211; Setting-up a business &#8211; Identity","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-mindmapping-setting-up-a-business-identity/","items":[]},{"title":"Openlink Virtuoso","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-openlink-virtuoso/","items":[]},{"title":"OpenRefine","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-74-2/","items":[]},{"title":"Projects, Customers and Invoicing &#8211; Web-Services for Startups","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-projects-customers-and-invoicing-web-services-for-startups/","items":[]},{"title":"RWW &#038; some Solid history","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-rww-some-solid-history/","items":[]},{"title":"Semantic Web (An Intro)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-semantic-web-an-intro/","items":[]},{"title":"Setting-up Twitter","url":"/old-work-archives/2018-webizen-net-au/_posts/2013-06-07-setting-up-twitter/","items":[]},{"title":"Social Encryption: An Introduction","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-25-social-encryption-an-introduction/","items":[]},{"title":"Stock Content","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-stock-content/","items":[]},{"title":"The WayBack Machine","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-27-the-wayback-machine/","items":[]},{"title":"Tim Berners Lee &#8211; Turing Lecture","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-05-29-tim-berners-lee-turing-lecture/","items":[]},{"title":"Tools of Trade","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-tools-of-trade/","items":[]},{"title":"Trust Factory 2017","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-trust-factory-2017/","items":[]},{"title":"Verifiable Claims (An Introduction)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-vc-intro/","items":[]},{"title":"Web of Things &#8211; an Introduction","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-web-of-things-an-introduction/","items":[]},{"title":"Web-Persistence","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-web-persistence/","items":[]},{"title":"Web-Services &#8211; Marketing Tools","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-web-services-marketing-tools/","items":[]},{"title":"Website Templates","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-templates/","items":[]},{"title":"What is Linked Data?","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-what-is-linked-data/","items":[]},{"title":"What is Open Source Intelligence?","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-what-is-osint/","items":[]},{"title":"WiX","url":"/old-work-archives/2018-webizen-net-au/_posts/2013-01-01-wix/","items":[]}]},{"title":"about","url":"/old-work-archives/2018-webizen-net-au/about/","items":[{"title":"About The Author","url":"/old-work-archives/2018-webizen-net-au/about/about-the-author/","items":[]},{"title":"Applied Theory: Applications for a Human Centric Web","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/","items":[{"title":"Digital Receipts","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/digital-receipts/","items":[]},{"title":"Fake News: Considerations  Principles  The Institution of Socio &#8211; Economic Values","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations/","items":[]},{"title":"Healthy Living Economy","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/healthy-living-economy/","items":[]},{"title":"HyperMedia Solutions &#8211; Adapting HbbTV V2","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/","items":[{"title":"HYPERMEDIA PACKAGES","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/hypermedia-packages/","items":[]},{"title":"USER STORIES: INTERACTIVE VIEWING EXPERIENCE","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/user-stories-interactive-viewing-experience/","items":[]}]},{"title":"Measurements App","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/measurements-app/","items":[]},{"title":"Re:Animation","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/reanimation/","items":[]},{"title":"Solutions to FakeNews: Linked-Data, Ontologies and Verifiable Claims","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/ld-solutions-to-fakenews/","items":[]}]},{"title":"Executive Summary","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/","items":[{"title":"Assisting those who Enforce the Law","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/assisting-those-who-enforce-the-law/","items":[]},{"title":"Consumer Protections","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/consumer-protections/","items":[]},{"title":"Knowledge Banking: Legal Structures","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-banking-legal-structures/","items":[]},{"title":"Knowledge Economics &#8211; Services","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-economics-services/","items":[]},{"title":"Preserving The Freedom to Think","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/preserving-the-freedom-to-think/","items":[]}]},{"title":"History","url":"/old-work-archives/2018-webizen-net-au/about/history/","items":[{"title":"History: Global Governance and ICT.","url":"/old-work-archives/2018-webizen-net-au/about/history/history-global-governance-ict-1/","items":[]}]},{"title":"Knowledge Banking: A Technical Architecture Summary","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/","items":[{"title":"An introduction to Credentials.","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/","items":[{"title":"credentials and custodianship","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/credentials-and-custodianship/","items":[]},{"title":"DIDs and MultiSig","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/dids-and-multisig/","items":[]}]},{"title":"Personal Augmentation of AI","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/personal-augmentation-of-ai/","items":[]},{"title":"Semantic Inferencing","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/semantic-inferencing/","items":[]},{"title":"Web of Things (IoT+LD)","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/web-of-things-iotld/","items":[]}]},{"title":"References","url":"/old-work-archives/2018-webizen-net-au/about/references/","items":[{"title":"Making the distinction between privacy and dignity.","url":"/old-work-archives/2018-webizen-net-au/about/references/privacy-vs-dignity/","items":[]},{"title":"Roles &#8211; Entity Analysis","url":"/old-work-archives/2018-webizen-net-au/about/references/roles-entity-analysis/","items":[]},{"title":"Social Informatics Design Considerations","url":"/old-work-archives/2018-webizen-net-au/about/references/social-informatics-design-concept-and-principles/","items":[]},{"title":"Socio-economic relations | A conceptual model","url":"/old-work-archives/2018-webizen-net-au/about/references/socioeconomic-relations-p1/","items":[]},{"title":"The need for decentralised Open (Linked) Data","url":"/old-work-archives/2018-webizen-net-au/about/references/the-need-for-decentralised-open-linked-data/","items":[]}]},{"title":"The design of new medium","url":"/old-work-archives/2018-webizen-net-au/about/the-design-of-new-medium/","items":[]},{"title":"The need to modernise socioeconomic infrastructure","url":"/old-work-archives/2018-webizen-net-au/about/the-modernisation-of-socioeconomics/","items":[]},{"title":"The Vision","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/","items":[{"title":"Domesticating Pervasive Surveillance","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/a-technical-vision/","items":[]}]}]},{"title":"An Overview","url":"/old-work-archives/2018-webizen-net-au/the-human-centric-infosphere/","items":[]},{"title":"Resource Library","url":"/old-work-archives/2018-webizen-net-au/resource-library/","items":[{"title":"Handong1587","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/","items":[{"title":"_Posts","url":"","items":[{"title":"Computer_science","url":"","items":[{"title":"Algorithm and Data Structure Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-algo-resourses/","items":[]},{"title":"Artificial Intelligence Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-ai-resources/","items":[]},{"title":"Big Data Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-09-22-big-data-resources/","items":[]},{"title":"Computer Science Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-cs-resources/","items":[]},{"title":"Data Mining Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-data-mining-resources/","items":[]},{"title":"Data Science Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-data-science-resources/","items":[]},{"title":"Database Systems Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-database-resources/","items":[]},{"title":"Discrete Optimization Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-discrete-optimization/","items":[]},{"title":"Distribued System Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-12-12-ditributed-system-resources/","items":[]},{"title":"Funny Stuffs Of Computer Science","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-11-18-funny-stuffs-of-cs/","items":[]},{"title":"Robotics","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-09-26-robotics-resources/","items":[]},{"title":"Writting CS Papers","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-11-30-writing-papers/","items":[]}]},{"title":"Computer_vision","url":"","items":[{"title":"Computer Vision Datasets","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-24-datasets/","items":[]},{"title":"Computer Vision Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-12-cv-resources/","items":[]},{"title":"Features","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-10-09-features/","items":[]},{"title":"Recognition, Detection, Segmentation and Tracking","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-10-09-recognition-detection-segmentation-tracking/","items":[]},{"title":"Use FFmpeg to Capture I Frames of Video","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2016-03-03-ffmpeg-i-frame/","items":[]},{"title":"Working on OpenCV","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-12-25-working-on-opencv/","items":[]}]},{"title":"Deep_learning","url":"","items":[{"title":"3D","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2021-07-28-3d/","items":[]},{"title":"Acceleration and Model Compression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-cnn-compression-acceleration/","items":[]},{"title":"Acceleration and Model Compression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-knowledge-distillation/","items":[]},{"title":"Adversarial Attacks and Defences","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-adversarial-attacks-and-defences/","items":[]},{"title":"Audio / Image / Video Generation","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-audio-image-video-generation/","items":[]},{"title":"BEV","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2022-06-27-bev/","items":[]},{"title":"Classification / Recognition","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recognition/","items":[]},{"title":"Deep Learning and Autonomous Driving","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-autonomous-driving/","items":[]},{"title":"Deep Learning Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-pose-estimation/","items":[]},{"title":"Deep Learning Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-applications/","items":[]},{"title":"Deep learning Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-courses/","items":[]},{"title":"Deep Learning Frameworks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-frameworks/","items":[]},{"title":"Deep Learning Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-resources/","items":[]},{"title":"Deep Learning Software and Hardware","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-software-hardware/","items":[]},{"title":"Deep Learning Tricks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tricks/","items":[]},{"title":"Deep Learning Tutorials","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tutorials/","items":[]},{"title":"Deep Learning with Machine Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-with-ml/","items":[]},{"title":"Face Recognition","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-face-recognition/","items":[]},{"title":"Fun With Deep Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-fun-with-deep-learning/","items":[]},{"title":"Generative Adversarial Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gan/","items":[]},{"title":"Graph Convolutional Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gcn/","items":[]},{"title":"Image / Video Captioning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-captioning/","items":[]},{"title":"Image Retrieval","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-retrieval/","items":[]},{"title":"Keep Up With New Trends","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2018-09-03-keep-up-with-new-trends/","items":[]},{"title":"LiDAR 3D Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-lidar-3d-detection/","items":[]},{"title":"Natural Language Processing","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nlp/","items":[]},{"title":"Neural Architecture Search","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nas/","items":[]},{"title":"Object Counting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-counting/","items":[]},{"title":"Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-detection/","items":[]},{"title":"OCR","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-ocr/","items":[]},{"title":"Optical Flow","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-optical-flow/","items":[]},{"title":"Re-ID","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-re-id/","items":[]},{"title":"Recommendation System","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recommendation-system/","items":[]},{"title":"Reinforcement Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rl/","items":[]},{"title":"RNN and LSTM","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rnn-and-lstm/","items":[]},{"title":"Segmentation","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-segmentation/","items":[]},{"title":"Style Transfer","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-style-transfer/","items":[]},{"title":"Super-Resolution","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-super-resolution/","items":[]},{"title":"Tracking","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-tracking/","items":[]},{"title":"Training Deep Neural Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-training-dnn/","items":[]},{"title":"Transfer Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-transfer-learning/","items":[]},{"title":"Unsupervised Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-unsupervised-learning/","items":[]},{"title":"Video Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-video-applications/","items":[]},{"title":"Visual Question Answering","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-vqa/","items":[]},{"title":"Visualizing and Interpreting Convolutional Neural Network","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-visulizing-interpreting-cnn/","items":[]}]},{"title":"Leisure","url":"","items":[{"title":"All About Enya","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-all-about-enya/","items":[]},{"title":"Coldplay","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-coldplay/","items":[]},{"title":"Coldplay","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-nightwish/","items":[]},{"title":"Games","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-13-games/","items":[]},{"title":"Green Day","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-greenday/","items":[]},{"title":"Muse! Muse!","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-muse-muse/","items":[]},{"title":"Oasis","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-oasis/","items":[]},{"title":"Paintings By J.M.","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2016-03-08-paintings-by-jm/","items":[]},{"title":"Papers, Blogs and Websites","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-09-27-papers-blogs-and-websites/","items":[]},{"title":"Welcome To The Black Parade","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-welcome-to-the-black-parade/","items":[]}]},{"title":"Machine_learning","url":"","items":[{"title":"Bayesian Methods","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-bayesian-methods/","items":[]},{"title":"Clustering Algorithms Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-clustering/","items":[]},{"title":"Competitions","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-competitions/","items":[]},{"title":"Dimensionality Reduction Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-dimensionality-reduction/","items":[]},{"title":"Fun With Machine Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-fun-with-ml/","items":[]},{"title":"Graphical Models Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-graphical-models/","items":[]},{"title":"Machine Learning Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-ml-courses/","items":[]},{"title":"Machine Learning Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-ml-resources/","items":[]},{"title":"Natural Language Processing","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-nlp/","items":[]},{"title":"Neural Network","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-neural-network/","items":[]},{"title":"Random Field","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-random-field/","items":[]},{"title":"Random Forests","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-random-forests/","items":[]},{"title":"Regression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-regression/","items":[]},{"title":"Support Vector Machine","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-svm/","items":[]},{"title":"Topic Model","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-topic-model/","items":[]}]},{"title":"Mathematics","url":"","items":[{"title":"Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/mathematics/2016-02-24-resources/","items":[]}]},{"title":"Programming_study","url":"","items":[{"title":"Add Lunr Search Plugin For Blog","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-31-add-lunr-search-plugin-for-blog/","items":[]},{"title":"Android Development Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-05-23-android-resources/","items":[]},{"title":"C++ Programming Solutions","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-09-07-cpp-programming-solutions/","items":[]},{"title":"Commands To Suppress Some Building Errors With Visual Studio","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-24-cmds-to-suppress-some-vs-building-Errors/","items":[]},{"title":"Embedding Python In C/C++","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-10-embedding-python-in-cpp/","items":[]},{"title":"Enable Large Addresses On VS2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-12-14-enable-large-addresses/","items":[]},{"title":"Fix min/max Error In VS2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-02-17-min-max-error-in-vs2015/","items":[]},{"title":"Gflags Build Problems on Windows X86 and Visual Studio 2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-23-gflags-build-problems-winx86-vs2015/","items":[]},{"title":"Glog Build Problems on Windows X86 and Visual Studio 2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-23-glog-build-problems-winx86/","items":[]},{"title":"Horrible Wired Errors Come From Simple Stupid Mistake","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-16-horrible-wired-errors-come-from-simple-stupid-mistake/","items":[]},{"title":"Install Jekyll To Fix Some Local Github-pages Defects","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-11-21-install-jekyll/","items":[]},{"title":"Install Therubyracer Failure","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-03-install-therubyracer/","items":[]},{"title":"Notes On Valgrind and Others","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-05-30-notes-on-valgrind/","items":[]},{"title":"PHP Hello World","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-04-php-hello-world/","items":[]},{"title":"Programming Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-07-01-programming-resources/","items":[]},{"title":"PyInstsaller and Others","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-12-24-pyinstaller-and-others/","items":[]},{"title":"Web Development Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-06-21-web-dev-resources/","items":[]},{"title":"Working on Visual Studio","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-04-03-working-on-vs/","items":[]}]},{"title":"Reading_and_thoughts","url":"","items":[{"title":"Book Reading List","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2015-12-04-book-reading-list/","items":[]},{"title":"Funny Papers","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2015-12-04-funny-papers/","items":[]},{"title":"Reading Materials","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2016-01-18-reading-materials/","items":[]}]},{"title":"Study","url":"","items":[{"title":"Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2017-11-28-courses/","items":[]},{"title":"Essay Writting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2016-01-11-essay-writting/","items":[]},{"title":"Job Hunting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2016-06-02-job-hunting/","items":[]},{"title":"Study Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2018-04-18-resources/","items":[]}]},{"title":"Working_on_linux","url":"","items":[{"title":"Create Multiple Forks of a GitHub Repo","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-12-18-create-multi-forks/","items":[]},{"title":"Linux Git Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-08-02-linux-git/","items":[]},{"title":"Linux Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-07-24-linux-resources/","items":[]},{"title":"Linux SVN Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-08-03-linux-svn/","items":[]},{"title":"Setup vsftpd on Ubuntu 14.10","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2016-07-27-setup-vsftpd/","items":[]},{"title":"Useful Linux Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-07-25-useful-linux-commands/","items":[]},{"title":"vsftpd Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2016-07-28-vsftpd-cmd/","items":[]}]},{"title":"Working_on_mac","url":"","items":[{"title":"Mac Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_mac/2015-07-25-mac-resources/","items":[]}]},{"title":"Working_on_windows","url":"","items":[{"title":"FFmpeg Collection of Utility Methods","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2016-06-05-ffmpeg-utilities/","items":[]},{"title":"Windows Commands and Utilities","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2015-10-27-windows-cmds-utils/","items":[]},{"title":"Windows Dev Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2015-10-27-resources/","items":[]}]}]},{"title":"Drafts","url":"","items":[{"title":"2016-12-30-Setup-Opengrok","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-12-30-setup-opengrok/","items":[]},{"title":"2017-01-20-Packing-C++-Project-to-Single-Executable","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2017-01-20-packing-c++-project-to-single-executable/","items":[]},{"title":"Notes On Caffe Development","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-10-notes-on-caffe-dev/","items":[]},{"title":"Notes On Deep Learning Training","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-12-notes-on-dl-training/","items":[]},{"title":"Notes On Discrete Optimization","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-13-notes-on-discrete-optimization/","items":[]},{"title":"Notes On Gecode","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-13-notes-on-gecode/","items":[]},{"title":"Notes On Inside-Outside Net","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-28-notes-on-ion/","items":[]},{"title":"Notes On K-Means","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-06-notes-on-kmeans/","items":[]},{"title":"Notes On L-BFGS","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-07-notes-on-l-bfgs/","items":[]},{"title":"Notes On Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-04-notes-on-object-detection/","items":[]},{"title":"Notes On Perceptrons","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-10-07-notes-on-perceptrons/","items":[]},{"title":"Notes On Quantized Convolutional Neural Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-07-notes-on-quantized-cnn/","items":[]},{"title":"Notes On Stanford CS2321n","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-02-21-notes-on-cs231n/","items":[]},{"title":"Notes on Suffix Array and Manacher Algorithm","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-08-27-notes-on-suffix-array-and-manacher-algorithm/","items":[]},{"title":"Notes On Tensorflow Development","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2017-04-13-notes-on-tensorflow-dev/","items":[]},{"title":"Notes On YOLO","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-14-notes-on-yolo/","items":[]},{"title":"PASCAL VOC (20) / COCO (80) / ImageNet (200) Detection Categories","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-12-23-imagenet-det-cat/","items":[]},{"title":"Softmax Vs Logistic Vs Sigmoid","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-10-softmax-logistic-sigmoid/","items":[]},{"title":"Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognititon","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-08-31-model-ensemble-of-deteciton/","items":[]}]}]}]}]}]},{"title":"Webizen 2.0","url":"","items":[{"title":"AI Capabilities","url":"","items":[{"title":"AI Capabilities Objectives","url":"/Webizen 2.0/AI Capabilities/AI Capabilities Objectives/","items":[]},{"title":"Audio & Video Analysis","url":"/Webizen 2.0/AI Capabilities/Audio & Video Analysis/","items":[]},{"title":"Image Analysis","url":"/Webizen 2.0/AI Capabilities/Image Analysis/","items":[]},{"title":"Text Analysis","url":"/Webizen 2.0/AI Capabilities/Text Analysis/","items":[]}]},{"title":"LOD-a-lot","url":"/Webizen 2.0/AI Related Links & Notes/","items":[]},{"title":"Mobile Apps","url":"","items":[{"title":"Android","url":"/Webizen 2.0/Mobile Apps/Android/","items":[]},{"title":"General Mobile Architecture","url":"/Webizen 2.0/Mobile Apps/General Mobile Architecture/","items":[]},{"title":"iOS","url":"/Webizen 2.0/Mobile Apps/iOS/","items":[]}]},{"title":"Web Of Things (IoT)","url":"","items":[{"title":"Web Of Things (IoT)","url":"/Webizen 2.0/Web Of Things (IoT)/Web Of Things (IoT)/","items":[]}]},{"title":"Webizen 2.0","url":"/Webizen 2.0/Webizen 2.0/","items":[]},{"title":"Webizen AI OS Platform","url":"/Webizen 2.0/Webizen AI OS Platform/","items":[]},{"title":"Webizen Pro Summary","url":"/Webizen 2.0/Webizen Pro Summary/","items":[]}]},{"title":"Webizen V1 Project Documentation","url":"/","items":[]}]}],"tagsGroups":[],"latestPosts":[{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/the-human-centric-infosphere/","title":"An Overview","lastUpdatedAt":"2022-12-28T19:39:53.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/about-the-author/","title":"About The Author","lastUpdatedAt":"2022-12-28T19:39:53.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/ld-solutions-to-fakenews/","title":"Solutions to FakeNews: Linked-Data, Ontologies and Verifiable Claims","lastUpdatedAt":"2022-12-28T19:34:43.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations/","title":"Fake News: Considerations  Principles  The Institution of Socio &#8211; Economic Values","lastUpdatedAt":"2022-12-28T19:29:53.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/","title":"Handong1587","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-08-27-notes-on-suffix-array-and-manacher-algorithm/","title":"Notes on Suffix Array and Manacher Algorithm","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-10-07-notes-on-perceptrons/","title":"Notes On Perceptrons","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-04-notes-on-object-detection/","title":"Notes On Object Detection","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-10-notes-on-caffe-dev/","title":"Notes On Caffe Development","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-07-notes-on-l-bfgs/","title":"Notes On L-BFGS","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}