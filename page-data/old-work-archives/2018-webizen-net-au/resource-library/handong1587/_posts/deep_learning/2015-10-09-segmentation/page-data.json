{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-segmentation/",
    "result": {"data":{"mdx":{"id":"529ef6b8-6a3f-5297-af3d-def3e1ee5d84","tableOfContents":{"items":[{"url":"#papers","title":"Papers","items":[{"url":"#u-net","title":"U-Net"}]},{"url":"#unified-image-segmentation","title":"Unified Image Segmentation"},{"url":"#foreground-object-segmentation","title":"Foreground Object Segmentation"},{"url":"#semantic-segmentation","title":"Semantic Segmentation","items":[{"url":"#deeplab","title":"DeepLab"},{"url":"#deeplab-v2","title":"DeepLab v2"},{"url":"#deeplab-v3","title":"DeepLab v3"},{"url":"#deeplabv3","title":"DeepLabv3+"},{"url":"#deeperlab","title":"DeeperLab"},{"url":"#auto-deeplab","title":"Auto-DeepLab"},{"url":"#segnet","title":"SegNet"},{"url":"#setr","title":"SETR"}]},{"url":"#instance-segmentation","title":"Instance Segmentation","items":[{"url":"#human-instance-segmentation","title":"Human Instance Segmentation"},{"url":"#video-instance-segmentation","title":"Video Instance Segmentation"}]},{"url":"#panoptic-segmentation","title":"Panoptic Segmentation"},{"url":"#nightime-segmentation","title":"Nightime Segmentation"},{"url":"#face-parsing","title":"Face Parsing"},{"url":"#specific-segmentation","title":"Specific Segmentation"},{"url":"#segment-proposal","title":"Segment Proposal"},{"url":"#scene-labeling--scene-parsing","title":"Scene Labeling / Scene Parsing","items":[{"url":"#pspnet","title":"PSPNet"},{"url":"#benchmarks","title":"Benchmarks"},{"url":"#challenges","title":"Challenges"}]},{"url":"#human-parsing","title":"Human Parsing"},{"url":"#joint-detection-and-segmentation","title":"Joint Detection and Segmentation"},{"url":"#video-object-segmentation","title":"Video Object Segmentation","items":[{"url":"#challenge","title":"Challenge"}]},{"url":"#matting","title":"Matting","items":[{"url":"#trimap-free-matting","title":"trimap-free matting"}]},{"url":"#3d-segmentation","title":"3D Segmentation"},{"url":"#line-parsing","title":"Line Parsing"},{"url":"#projects","title":"Projects"},{"url":"#leaderboard","title":"Leaderboard"},{"url":"#blogs","title":"Blogs"},{"url":"#tutorails--talks","title":"Tutorails / Talks"}]},"fields":{"title":"Segmentation","slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-segmentation/","url":"https://devdocs.webizen.org/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-segmentation/","editUrl":"https://github.com/webizenai/devdocs/tree/main/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-segmentation.md","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022","gitCreatedAt":"2022-12-28T19:22:29.000Z","shouldShowTitle":true},"frontmatter":{"title":"Segmentation","description":null,"imageAlt":null,"tags":[],"date":"2015-10-09T00:00:00.000Z","dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"layout\": \"post\",\n  \"category\": \"deep_learning\",\n  \"title\": \"Segmentation\",\n  \"date\": \"2015-10-09T00:00:00.000Z\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"papers\"\n  }, \"Papers\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Joint Task Learning for Generic Object Extraction\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2014\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://vision.sysu.edu.cn/projects/deep-joint-task-learning/\"\n  }, \"http://vision.sysu.edu.cn/projects/deep-joint-task-learning/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://ss.sysu.edu.cn/~ll/files/NIPS2014_JointTask.pdf\"\n  }, \"http://ss.sysu.edu.cn/~ll/files/NIPS2014_JointTask.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xiaolonw/nips14_loc_seg_testonly\"\n  }, \"https://github.com/xiaolonw/nips14_loc_seg_testonly\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"dataset: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://objectextraction.github.io/\"\n  }, \"http://objectextraction.github.io/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Highly Efficient Forward and Backward Propagation of Convolutional Neural Networks for Pixelwise Classification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1412.4526\"\n  }, \"https://arxiv.org/abs/1412.4526\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code(Caffe): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://dl.dropboxusercontent.com/u/6448899/caffe.zip\"\n  }, \"https://dl.dropboxusercontent.com/u/6448899/caffe.zip\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"author page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.ee.cuhk.edu.hk/~hsli/\"\n  }, \"http://www.ee.cuhk.edu.hk/~hsli/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Segmentation from Natural Language Expressions\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://ronghanghu.com/text_objseg/\"\n  }, \"http://ronghanghu.com/text_objseg/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.06180\"\n  }, \"http://arxiv.org/abs/1603.06180\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(TensorFlow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ronghanghu/text_objseg\"\n  }, \"https://github.com/ronghanghu/text_objseg\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gtihub(Caffe): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Seth-Park/text_objseg_caffe\"\n  }, \"https://github.com/Seth-Park/text_objseg_caffe\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Object Parsing with Graph LSTM\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.07063\"\n  }, \"http://arxiv.org/abs/1603.07063\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fine Hand Segmentation using Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.07454\"\n  }, \"http://arxiv.org/abs/1608.07454\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Feedback Neural Network for Weakly Supervised Geo-Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Facebook Connectivity Lab & Facebook Core Data Science & University of Illinois\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.02766\"\n  }, \"https://arxiv.org/abs/1612.02766\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FusionNet: A deep fully residual convolutional neural network for image segmentation in connectomics\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.05360\"\n  }, \"https://arxiv.org/abs/1612.05360\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A deep learning model integrating FCNNs and CRFs for brain tumor segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.04528\"\n  }, \"https://arxiv.org/abs/1702.04528\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Texture segmentation with Fully Convolutional Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Dublin City University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.05230\"\n  }, \"https://arxiv.org/abs/1703.05230\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast LIDAR-based Road Detection Using Convolutional Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1703.03613\"\n  }, \"https://arxiv.org/abs/1703.03613\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Value Networks Learn to Evaluate and Iteratively Refine Structured Outputs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.04363\"\n  }, \"https://arxiv.org/abs/1703.04363\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://gyglim.github.io/deep-value-net/\"\n  }, \"https://gyglim.github.io/deep-value-net/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Annotating Object Instances with a Polygon-RNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017. CVPR Best Paper Honorable Mention Award\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Toronto\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: PolygonRNN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.toronto.edu/polyrnn/\"\n  }, \"http://www.cs.toronto.edu/polyrnn/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.05548\"\n  }, \"https://arxiv.org/abs/1704.05548\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Efficient Interactive Annotation of Segmentation Datasets with Polygon-RNN++\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: PolygonRNN++\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.toronto.edu/polyrnn/\"\n  }, \"http://www.cs.toronto.edu/polyrnn/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.09693\"\n  }, \"https://arxiv.org/abs/1803.09693\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/davidjesusacu/polyrnn-pp\"\n  }, \"https://github.com/davidjesusacu/polyrnn-pp\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Segmentation via Structured Patch Prediction, Context CRF and Guidance CRF\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_cvpr_2017/papers/Shen_Semantic_Segmentation_via_CVPR_2017_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_cvpr_2017/papers/Shen_Semantic_Segmentation_via_CVPR_2017_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Caffe): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com//FalongShen/SegModel\"\n  }, \"https://github.com//FalongShen/SegModel\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Distantly Supervised Road Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV workshop CVRSUAD2017. Indiana University & Preferred Networks\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.06118\"\n  }, \"https://arxiv.org/abs/1708.06118\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"\\u03A9-Net: Fully Automatic, Multi-View Cardiac MR Detection, Orientation, and Segmentation with Deep Neural Networks\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"\\u03A9-Net (Omega-Net): Fully Automatic, Multi-View Cardiac MR Detection, Orientation, and Segmentation with Deep Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.01094\"\n  }, \"https://arxiv.org/abs/1711.01094\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Superpixel clustering with deep features for unsupervised road segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Preferred Networks, Inc & Indiana University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.05998\"\n  }, \"https://arxiv.org/abs/1711.05998\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning to Segment Human by Watching YouTube\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: TPAMI 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1710.01457\"\n  }, \"https://arxiv.org/abs/1710.01457\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"W-Net: A Deep Model for Fully Unsupervised Image Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.08506\"\n  }, \"https://arxiv.org/abs/1711.08506\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End-to-end detection-segmentation network with ROI convolution\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ISBI 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.02722\"\n  }, \"https://arxiv.org/abs/1801.02722\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Foreground Inference Network for Video Surveillance Using Multi-View Receptive Field\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1801.06593\"\n  }, \"https://arxiv.org/abs/1801.06593\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Piecewise Flat Embedding for Image Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1802.03248\"\n  }, \"https://arxiv.org/abs/1802.03248\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Pyramid CNN for Dense-Leaves Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Computer and Robot Vision, Toronto, May 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.01646\"\n  }, \"https://arxiv.org/abs/1804.01646\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Capsules for Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: convolutional-deconvolutional capsule network, SegCaps, U-Net\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.04241\"\n  }, \"https://arxiv.org/abs/1804.04241\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Object Co-Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1804.06423\"\n  }, \"https://arxiv.org/abs/1804.06423\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Aware Attention Based Deep Object Co-segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1810.06859\"\n  }, \"https://arxiv.org/abs/1810.06859\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Contextual Hourglass Networks for Segmentation and Density Estimation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1806.04009\"\n  }, \"https://arxiv.org/abs/1806.04009\")), mdx(\"h2\", {\n    \"id\": \"u-net\"\n  }, \"U-Net\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"U-Net: Convolutional Networks for Biomedical Image Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: conditionally accepted at MICCAI 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/\"\n  }, \"http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1505.04597\"\n  }, \"http://arxiv.org/abs/1505.04597\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code+data: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-release-2015-10-02.tar.gz\"\n  }, \"http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-release-2015-10-02.tar.gz\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/orobix/retina-unet\"\n  }, \"https://github.com/orobix/retina-unet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jakeret/tf_unet\"\n  }, \"https://github.com/jakeret/tf_unet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://zongwei.leanote.com/post/Pa\"\n  }, \"http://zongwei.leanote.com/post/Pa\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"UNet++: A Nested U-Net Architecture for Medical Image Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: 4th Deep Learning in Medical Image Analysis (DLMIA) Workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.10165\"\n  }, \"https://arxiv.org/abs/1807.10165\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"UNet 3+: A Full-Scale Connected UNet for Medical Image Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICASSP 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2004.08790\"\n  }, \"https://arxiv.org/abs/2004.08790\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ZJUGiveLab/UNet-Version\"\n  }, \"https://github.com/ZJUGiveLab/UNet-Version\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepUNet: A Deep Fully Convolutional Network for Pixel-level Sea-Land Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.00201\"\n  }, \"https://arxiv.org/abs/1709.00201\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TernausNet: U-Net with VGG11 Encoder Pre-Trained on ImageNet for Image Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Lyft Inc. & MIT\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: part of the winning solution (1st out of 735) in the Kaggle: Carvana Image Masking Challenge\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.05746\"\n  }, \"https://arxiv.org/abs/1801.05746\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ternaus/TernausNet\"\n  }, \"https://github.com/ternaus/TernausNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Probabilistic U-Net for Segmentation of Ambiguous Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: DeepMind & German Cancer Research Center\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1806.05034\"\n  }, \"https://arxiv.org/abs/1806.05034\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Dual Pyramid Network for Barcode Segmentation using Barcode-30k Database\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1807.11886\"\n  }, \"https://arxiv.org/abs/1807.11886\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Smoke Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1809.00774\"\n  }, \"https://arxiv.org/abs/1809.00774\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Smoothed Dilated Convolutions for Improved Dense Prediction\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: KDD 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.08931\"\n  }, \"https://arxiv.org/abs/1808.08931\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/divelab/dilated\"\n  }, \"https://github.com/divelab/dilated\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DASNet: Reducing Pixel-level Annotations for Instance and Semantic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1809.06013\"\n  }, \"https://arxiv.org/abs/1809.06013\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improving Fast Segmentation With Teacher-student Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1810.08476\"\n  }, \"https://arxiv.org/abs/1810.08476\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DSNet: An Efficient CNN for Road Scene Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1904.05022\"\n  }, \"https://arxiv.org/abs/1904.05022\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Line Segment Detection Using Transformers without Edges\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2101.01909\"\n  }, \"https://arxiv.org/abs/2101.01909\")), mdx(\"h1\", {\n    \"id\": \"unified-image-segmentation\"\n  }, \"Unified Image Segmentation\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"K-Net: Towards Unified Image Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro:  Nanyang Technological University &  Chinese University of Hong Kon & SenseTime Research & Shanghai AI Laborator\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.mmlab-ntu.com/project/knet/index.html\"\n  }, \"https://www.mmlab-ntu.com/project/knet/index.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2106.14855\"\n  }, \"https://arxiv.org/abs/2106.14855\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ZwwWayne/K-Net/\"\n  }, \"https://github.com/ZwwWayne/K-Net/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Masked-attention Mask Transformer for Universal Image Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://bowenc0221.github.io/mask2former/\"\n  }, \"https://bowenc0221.github.io/mask2former/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2112.01527\"\n  }, \"https://arxiv.org/abs/2112.01527\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/facebookresearch/Mask2Former\"\n  }, \"https://github.com/facebookresearch/Mask2Former\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mask2Former for Video Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Illinois at Urbana-Champaign (UIUC) & Facebook AI Research (FAIR\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2112.10764\"\n  }, \"https://arxiv.org/abs/2112.10764\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/facebookresearch/Mask2Former\"\n  }, \"https://github.com/facebookresearch/Mask2Former\"))), mdx(\"h1\", {\n    \"id\": \"foreground-object-segmentation\"\n  }, \"Foreground Object Segmentation\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pixel Objectness\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://vision.cs.utexas.edu/projects/pixelobjectness/\"\n  }, \"http://vision.cs.utexas.edu/projects/pixelobjectness/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.05349\"\n  }, \"https://arxiv.org/abs/1701.05349\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/suyogduttjain/pixelobjectness\"\n  }, \"https://github.com/suyogduttjain/pixelobjectness\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Deep Convolutional Neural Network for Background Subtraction\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.01731\"\n  }, \"https://arxiv.org/abs/1702.01731\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Multi-scale Features for Foreground Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.01477\"\n  }, \"https://arxiv.org/abs/1808.01477\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lim-anggun/FgSegNet_v2\"\n  }, \"https://github.com/lim-anggun/FgSegNet_v2\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Deep Representations for Semantic Image Parsing: a Comprehensive Overview\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1810.04377\"\n  }, \"https://arxiv.org/abs/1810.04377\")), mdx(\"h1\", {\n    \"id\": \"semantic-segmentation\"\n  }, \"Semantic Segmentation\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fully Convolutional Networks for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2015, PAMI 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: deconvolutional layer, crop layer\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1411.4038\"\n  }, \"http://arxiv.org/abs/1411.4038\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv(PAMI 2016): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.06211\"\n  }, \"http://arxiv.org/abs/1605.06211\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://docs.google.com/presentation/d/1VeWFMpZ8XN7OC3URZP4WdXvOGYckoFWGVN7hApoXVnc\"\n  }, \"https://docs.google.com/presentation/d/1VeWFMpZ8XN7OC3URZP4WdXvOGYckoFWGVN7hApoXVnc\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-pixels.pdf\"\n  }, \"http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-pixels.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"talk: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://techtalks.tv/talks/fully-convolutional-networks-for-semantic-segmentation/61606/\"\n  }, \"http://techtalks.tv/talks/fully-convolutional-networks-for-semantic-segmentation/61606/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/shelhamer/fcn.berkeleyvision.org\"\n  }, \"https://github.com/shelhamer/fcn.berkeleyvision.org\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/BVLC/caffe/wiki/Model-Zoo#fcn\"\n  }, \"https://github.com/BVLC/caffe/wiki/Model-Zoo#fcn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MarvinTeichmann/tensorflow-fcn\"\n  }, \"https://github.com/MarvinTeichmann/tensorflow-fcn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Chainer): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/wkentaro/fcn\"\n  }, \"https://github.com/wkentaro/fcn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/wkentaro/pytorch-fcn\"\n  }, \"https://github.com/wkentaro/pytorch-fcn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/shekkizh/FCN.tensorflow\"\n  }, \"https://github.com/shekkizh/FCN.tensorflow\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://zhangliliang.com/2014/11/28/paper-note-fcn-segment/\"\n  }, \"http://zhangliliang.com/2014/11/28/paper-note-fcn-segment/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"From Image-level to Pixel-level Labeling with Convolutional Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: \\\"Weakly Supervised Semantic Segmentation with Convolutional Networks\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: performs semantic segmentation based only on image-level annotations in a multiple instance learning framework\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1411.6228\"\n  }, \"http://arxiv.org/abs/1411.6228\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://ronan.collobert.com/pub/matos/2015_semisupsemseg_cvpr.pdf\"\n  }, \"http://ronan.collobert.com/pub/matos/2015_semisupsemseg_cvpr.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Feedforward semantic segmentation with zoom-out features\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2015. Toyota Technological Institute at Chicago\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Mostajabi_Feedforward_Semantic_Segmentation_2015_CVPR_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Mostajabi_Feedforward_Semantic_Segmentation_2015_CVPR_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"bitbuckt: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://bitbucket.org/m_mostajabi/zoom-out-release\"\n  }, \"https://bitbucket.org/m_mostajabi/zoom-out-release\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"video: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=HvgvX1LXQa8\"\n  }, \"https://www.youtube.com/watch?v=HvgvX1LXQa8\"))), mdx(\"h2\", {\n    \"id\": \"deeplab\"\n  }, \"DeepLab\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR 2015. DeepLab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1412.7062\"\n  }, \"http://arxiv.org/abs/1412.7062\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"bitbucket: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://bitbucket.org/deeplab/deeplab-public/\"\n  }, \"https://bitbucket.org/deeplab/deeplab-public/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/TheLegendAli/DeepLab-Context\"\n  }, \"https://github.com/TheLegendAli/DeepLab-Context\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Weakly- and Semi-Supervised Learning of a DCNN for Semantic Image Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: DeepLab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1502.02734\"\n  }, \"http://arxiv.org/abs/1502.02734\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"bitbucket: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://bitbucket.org/deeplab/deeplab-public/\"\n  }, \"https://bitbucket.org/deeplab/deeplab-public/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/TheLegendAli/DeepLab-Context\"\n  }, \"https://github.com/TheLegendAli/DeepLab-Context\"))), mdx(\"h2\", {\n    \"id\": \"deeplab-v2\"\n  }, \"DeepLab v2\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: TPAMI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: 79.7% mIOU in the test set, PASCAL VOC-2012 semantic image segmentation task\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Updated version of our previous ICLR 2015 paper\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://liangchiehchen.com/projects/DeepLab.html\"\n  }, \"http://liangchiehchen.com/projects/DeepLab.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1606.00915\"\n  }, \"https://arxiv.org/abs/1606.00915\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"bitbucket: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://bitbucket.org/aquariusjay/deeplab-public-ver2\"\n  }, \"https://bitbucket.org/aquariusjay/deeplab-public-ver2\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/DrSleep/tensorflow-deeplab-resnet\"\n  }, \"https://github.com/DrSleep/tensorflow-deeplab-resnet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/isht7/pytorch-deeplab-resnet\"\n  }, \"https://github.com/isht7/pytorch-deeplab-resnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepLabv2 (ResNet-101)\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://liangchiehchen.com/projects/DeepLabv2_resnet.html\"\n  }, \"http://liangchiehchen.com/projects/DeepLabv2_resnet.html\")), mdx(\"h2\", {\n    \"id\": \"deeplab-v3\"\n  }, \"DeepLab v3\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rethinking Atrous Convolution for Semantic Image Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google. DeepLabv3\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.05587\"\n  }, \"https://arxiv.org/abs/1706.05587\"))), mdx(\"h2\", {\n    \"id\": \"deeplabv3\"\n  }, \"DeepLabv3+\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1802.02611\"\n  }, \"https://arxiv.org/abs/1802.02611\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tensorflow/models/tree/master/research/deeplab\"\n  }, \"https://github.com/tensorflow/models/tree/master/research/deeplab\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://research.googleblog.com/2018/03/semantic-image-segmentation-with.html\"\n  }, \"https://research.googleblog.com/2018/03/semantic-image-segmentation-with.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hualin95/Deeplab-v3plus\"\n  }, \"https://github.com/hualin95/Deeplab-v3plus\"))), mdx(\"h2\", {\n    \"id\": \"deeperlab\"\n  }, \"DeeperLab\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeeperLab: Single-Shot Image Parser\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MIT & Google Inc. & UC Berkeley\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1902.05093\"\n  }, \"https://arxiv.org/abs/1902.05093\"))), mdx(\"h2\", {\n    \"id\": \"auto-deeplab\"\n  }, \"Auto-DeepLab\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Auto-DeepLab: Hierarchical Neural Architecture Search for Semantic Image Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Johns Hopkins University & Google & Stanford University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.02985\"\n  }, \"https://arxiv.org/abs/1901.02985\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tensorflow/models/tree/master/research/deeplab\"\n  }, \"https://github.com/tensorflow/models/tree/master/research/deeplab\"))), mdx(\"hr\", null), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Conditional Random Fields as Recurrent Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Oxford / Stanford / Baidu\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: CRF-RNN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.robots.ox.ac.uk/~szheng/CRFasRNN.html\"\n  }, \"http://www.robots.ox.ac.uk/~szheng/CRFasRNN.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1502.03240\"\n  }, \"http://arxiv.org/abs/1502.03240\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/torrvision/crfasrnn\"\n  }, \"https://github.com/torrvision/crfasrnn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"demo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.robots.ox.ac.uk/~szheng/crfasrnndemo\"\n  }, \"http://www.robots.ox.ac.uk/~szheng/crfasrnndemo\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/martinkersner/train-CRF-RNN\"\n  }, \"https://github.com/martinkersner/train-CRF-RNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BoxSup: Exploiting Bounding Boxes to Supervise Convolutional Networks for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1503.01640\"\n  }, \"http://arxiv.org/abs/1503.01640\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Efficient piecewise training of deep structured models for semantic segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1504.01013\"\n  }, \"http://arxiv.org/abs/1504.01013\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Deconvolution Network for Semantic Segmentation\")), mdx(\"img\", {\n    \"src\": \"http://cvlab.postech.ac.kr/research/deconvnet/images/overall.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: two-stage training: train the network with easy examples first and\\nfine-tune the trained network with more challenging examples later\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: DeconvNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cvlab.postech.ac.kr/research/deconvnet/\"\n  }, \"http://cvlab.postech.ac.kr/research/deconvnet/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1505.04366\"\n  }, \"http://arxiv.org/abs/1505.04366\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2016/bil722/slides/w06-deconvnet.pdf\"\n  }, \"http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2016/bil722/slides/w06-deconvnet.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gitxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://gitxiv.com/posts/9tpJKNTYksN5eWcHz/learning-deconvolution-network-for-semantic-segmentation\"\n  }, \"http://gitxiv.com/posts/9tpJKNTYksN5eWcHz/learning-deconvolution-network-for-semantic-segmentation\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/HyeonwooNoh/DeconvNet\"\n  }, \"https://github.com/HyeonwooNoh/DeconvNet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/HyeonwooNoh/caffe\"\n  }, \"https://github.com/HyeonwooNoh/caffe\"))), mdx(\"h2\", {\n    \"id\": \"segnet\"\n  }, \"SegNet\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SegNet: A Deep Convolutional Encoder-Decoder Architecture for Robust Semantic Pixel-Wise Labelling\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1505.07293\"\n  }, \"http://arxiv.org/abs/1505.07293\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/alexgkendall/caffe-segnet\"\n  }, \"https://github.com/alexgkendall/caffe-segnet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/pfnet-research/chainer-segnet\"\n  }, \"https://github.com/pfnet-research/chainer-segnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation\")), mdx(\"img\", {\n    \"src\": \"http://mi.eng.cam.ac.uk/projects/segnet/images/segnet.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mi.eng.cam.ac.uk/projects/segnet/\"\n  }, \"http://mi.eng.cam.ac.uk/projects/segnet/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1511.00561\"\n  }, \"http://arxiv.org/abs/1511.00561\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/alexgkendall/caffe-segnet\"\n  }, \"https://github.com/alexgkendall/caffe-segnet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"tutorial: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mi.eng.cam.ac.uk/projects/segnet/tutorial.html\"\n  }, \"http://mi.eng.cam.ac.uk/projects/segnet/tutorial.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SegNet: Pixel-Wise Semantic Labelling Using a Deep Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"youtube: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=xfNYAly1iXo\"\n  }, \"https://www.youtube.com/watch?v=xfNYAly1iXo\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"mirror: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://pan.baidu.com/s/1gdUzDlD\"\n  }, \"http://pan.baidu.com/s/1gdUzDlD\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Getting Started with SegNet\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mi.eng.cam.ac.uk/projects/segnet/tutorial.html\"\n  }, \"http://mi.eng.cam.ac.uk/projects/segnet/tutorial.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/alexgkendall/SegNet-Tutorial\"\n  }, \"https://github.com/alexgkendall/SegNet-Tutorial\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ParseNet: Looking Wider to See Better\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro:ICLR 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1506.04579\"\n  }, \"http://arxiv.org/abs/1506.04579\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/weiliu89/caffe/tree/fcn\"\n  }, \"https://github.com/weiliu89/caffe/tree/fcn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"caffe model zoo: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/BVLC/caffe/wiki/Model-Zoo#parsenet-looking-wider-to-see-better\"\n  }, \"https://github.com/BVLC/caffe/wiki/Model-Zoo#parsenet-looking-wider-to-see-better\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Decoupled Deep Neural Network for Semi-supervised Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: DecoupledNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project(paper+code): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cvlab.postech.ac.kr/research/decouplednet/\"\n  }, \"http://cvlab.postech.ac.kr/research/decouplednet/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1506.04924\"\n  }, \"http://arxiv.org/abs/1506.04924\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/HyeonwooNoh/DecoupledNet\"\n  }, \"https://github.com/HyeonwooNoh/DecoupledNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Image Segmentation via Deep Parsing Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2015. CUHK\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Deep Parsing Network (DPN), Markov Random Field (MRF)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://personal.ie.cuhk.edu.hk/~lz013/projects/DPN.html\"\n  }, \"http://personal.ie.cuhk.edu.hk/~lz013/projects/DPN.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv.org: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1509.02634\"\n  }, \"http://arxiv.org/abs/1509.02634\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Liu_Semantic_Image_Segmentation_ICCV_2015_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Liu_Semantic_Image_Segmentation_ICCV_2015_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://personal.ie.cuhk.edu.hk/~pluo/pdf/presentation_dpn.pdf\"\n  }, \"http://personal.ie.cuhk.edu.hk/~pluo/pdf/presentation_dpn.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Scale Context Aggregation by Dilated Convolutions\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR 2016.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Dilated Convolution for Semantic Image Segmentation\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://vladlen.info/publications/multi-scale-context-aggregation-by-dilated-convolutions/\"\n  }, \"http://vladlen.info/publications/multi-scale-context-aggregation-by-dilated-convolutions/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1511.07122\"\n  }, \"http://arxiv.org/abs/1511.07122\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/fyu/dilation\"\n  }, \"https://github.com/fyu/dilation\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/nicolov/segmentation_keras\"\n  }, \"https://github.com/nicolov/segmentation_keras\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.inference.vc/dilated-convolutions-and-kronecker-factorisation/\"\n  }, \"http://www.inference.vc/dilated-convolutions-and-kronecker-factorisation/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Instance-aware Semantic Segmentation via Multi-task Network Cascades\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2016 oral. 1st-place winner of MS COCO 2015 segmentation competition\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: RoI warping layer, Multi-task Network Cascades (MNC)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1512.04412\"\n  }, \"http://arxiv.org/abs/1512.04412\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/daijifeng001/MNC\"\n  }, \"https://github.com/daijifeng001/MNC\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Segmentation on SpaceNet via Multi-task Network Cascades (MNC)\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/the-downlinq/object-segmentation-on-spacenet-via-multi-task-network-cascades-mnc-f1c89d790b42\"\n  }, \"https://medium.com/the-downlinq/object-segmentation-on-spacenet-via-multi-task-network-cascades-mnc-f1c89d790b42\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lncohn/pascal_to_spacenet\"\n  }, \"https://github.com/lncohn/pascal_to_spacenet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Transferrable Knowledge for Semantic Segmentation with Deep Convolutional Neural Network\")), mdx(\"img\", {\n    \"src\": \"http://cvlab.postech.ac.kr/research/transfernet/images/architecture.png\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: TransferNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://cvlab.postech.ac.kr/research/transfernet/\"\n  }, \"http://cvlab.postech.ac.kr/research/transfernet/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1512.07928\"\n  }, \"http://arxiv.org/abs/1512.07928\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/maga33/TransferNet\"\n  }, \"https://github.com/maga33/TransferNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Combining the Best of Convolutional Layers and Recurrent Layers: A Hybrid Network for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.04871\"\n  }, \"http://arxiv.org/abs/1603.04871\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Seed, Expand and Constrain: Three Principles for Weakly-Supervised Image Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1603.06098\"\n  }, \"https://arxiv.org/abs/1603.06098\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kolesman/SEC\"\n  }, \"https://github.com/kolesman/SEC\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ScribbleSup: Scribble-Supervised Convolutional Networks for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://research.microsoft.com/en-us/um/people/jifdai/downloads/scribble_sup/\"\n  }, \"http://research.microsoft.com/en-us/um/people/jifdai/downloads/scribble_sup/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1604.05144\"\n  }, \"http://arxiv.org/abs/1604.05144\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Laplacian Reconstruction and Refinement for Semantic Segmentation\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Laplacian Pyramid Reconstruction and Refinement for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1605.02264\"\n  }, \"https://arxiv.org/abs/1605.02264\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.ics.uci.edu/~fowlkes/papers/gf-eccv16.pdf\"\n  }, \"https://www.ics.uci.edu/~fowlkes/papers/gf-eccv16.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(MatConvNet): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/golnazghiasi/LRR\"\n  }, \"https://github.com/golnazghiasi/LRR\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Natural Scene Image Segmentation Based on Multi-Layer Feature Extraction\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.07586\"\n  }, \"http://arxiv.org/abs/1605.07586\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Convolutional Random Walk Networks for Semantic Image Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.07681\"\n  }, \"http://arxiv.org/abs/1605.07681\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1606.02147\"\n  }, \"http://arxiv.org/abs/1606.02147\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/e-lab/ENet-training\"\n  }, \"https://github.com/e-lab/ENet-training\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Caffe): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/TimoSaemann/ENet\"\n  }, \"https://github.com/TimoSaemann/ENet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/PavlosMelissinos/enet-keras\"\n  }, \"https://github.com/PavlosMelissinos/enet-keras\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kwotsin/TensorFlow-ENet\"\n  }, \"https://github.com/kwotsin/TensorFlow-ENet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://culurciello.github.io/tech/2016/06/20/training-enet.html\"\n  }, \"http://culurciello.github.io/tech/2016/06/20/training-enet.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fully Convolutional Networks for Dense Semantic Labelling of High-Resolution Aerial Imagery\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1606.02585\"\n  }, \"http://arxiv.org/abs/1606.02585\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning Markov Random Field for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1606.07230\"\n  }, \"http://arxiv.org/abs/1606.07230\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Region-based semantic segmentation with end-to-end training\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1607.07671\"\n  }, \"http://arxiv.org/abs/1607.07671\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"githun: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/nightrome/matconvnet-calvin\"\n  }, \"https://github.com/nightrome/matconvnet-calvin\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Built-in Foreground/Background Prior for Weakly-Supervised Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.00446\"\n  }, \"http://arxiv.org/abs/1609.00446\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PixelNet: Towards a General Pixel-level Architecture\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: semantic segmentation, edge detection\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.06694\"\n  }, \"http://arxiv.org/abs/1609.06694\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Exploiting Depth from Single Monocular Images for Object Detection and Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IEEE T. Image Processing\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: propose an RGB-D semantic segmentation method which applies a multi-task training scheme: semantic label prediction and depth value regression\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.01706\"\n  }, \"https://arxiv.org/abs/1610.01706\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PixelNet: Representation of the pixels, by the pixels, and for the pixels\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CMU & Adobe Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.cmu.edu/~aayushb/pixelNet/\"\n  }, \"http://www.cs.cmu.edu/~aayushb/pixelNet/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.06506\"\n  }, \"https://arxiv.org/abs/1702.06506\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Caffe): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aayushbansal/PixelNet\"\n  }, \"https://github.com/aayushbansal/PixelNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Segmentation of Earth Observation Data Using Multimodal and Multi-scale Deep Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.06846\"\n  }, \"http://arxiv.org/abs/1609.06846\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Structured Features for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.07916\"\n  }, \"http://arxiv.org/abs/1609.07916\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CNN-aware Binary Map for General Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICIP 2016 Best Paper / Student Paper Finalist\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1609.09220\"\n  }, \"https://arxiv.org/abs/1609.09220\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Efficient Convolutional Neural Network with Binary Quantization Layer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.06764\"\n  }, \"https://arxiv.org/abs/1611.06764\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mixed context networks for semantic segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Hikvision Research Institute\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1610.05854\"\n  }, \"https://arxiv.org/abs/1610.05854\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"High-Resolution Semantic Labeling with Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.01962\"\n  }, \"https://arxiv.org/abs/1611.01962\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Gated Feedback Refinement Network for Dense Image Labeling\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.umanitoba.ca/~ywang/papers/cvpr17.pdf\"\n  }, \"http://www.cs.umanitoba.ca/~ywang/papers/cvpr17.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RefineNet: Multi-Path Refinement Networks with Identity Mappings for High-Resolution Semantic Segmentation\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017. IoU 83.4% on PASCAL VOC 2012\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.06612\"\n  }, \"https://arxiv.org/abs/1611.06612\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/guosheng/refinenet\"\n  }, \"https://github.com/guosheng/refinenet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"leaderboard: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=6#KEY_Multipath-RefineNet-Res152\"\n  }, \"http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=6#KEY_Multipath-RefineNet-Res152\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Light-Weight RefineNet for Real-Time Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1810.03272\"\n  }, \"https://arxiv.org/abs/1810.03272\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/drsleep/light-weight-refinenet\"\n  }, \"https://github.com/drsleep/light-weight-refinenet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Full-Resolution Residual Networks for Semantic Segmentation in Street Scenes\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Full-Resolution Residual Units (FRRU), Full-Resolution Residual Networks (FRRNs)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.08323\"\n  }, \"https://arxiv.org/abs/1611.08323\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Theano/Lasagne): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/TobyPDE/FRRN\"\n  }, \"https://github.com/TobyPDE/FRRN\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"youtube: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=PNzQ4PNZSzc\"\n  }, \"https://www.youtube.com/watch?v=PNzQ4PNZSzc\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Segmentation using Adversarial Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Facebook AI Research & INRIA. NIPS Workshop on Adversarial Training, Dec 2016, Barcelona, Spain\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.08408\"\n  }, \"https://arxiv.org/abs/1611.08408\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Chainer): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/oyam/Semantic-Segmentation-using-Adversarial-Networks\"\n  }, \"https://github.com/oyam/Semantic-Segmentation-using-Adversarial-Networks\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improving Fully Convolution Network for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.08986\"\n  }, \"https://arxiv.org/abs/1611.08986\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Montreal Institute for Learning Algorithms & Ecole Polytechnique de Montreal\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.09326\"\n  }, \"https://arxiv.org/abs/1611.09326\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/SimJeg/FC-DenseNet\"\n  }, \"https://github.com/SimJeg/FC-DenseNet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/titu1994/Fully-Connected-DenseNets-Semantic-Segmentation\"\n  }, \"https://github.com/titu1994/Fully-Connected-DenseNets-Semantic-Segmentation\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Keras): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/0bserver07/One-Hundred-Layers-Tiramisu\"\n  }, \"https://github.com/0bserver07/One-Hundred-Layers-Tiramisu\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Training Bit Fully Convolutional Network for Fast Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Megvii\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.00212\"\n  }, \"https://arxiv.org/abs/1612.00212\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Classification With an Edge: Improving Semantic Image Segmentation with Boundary Detection\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: \\\"an end-to-end trainable deep convolutional neural network (DCNN) for semantic segmentation\\nwith built-in awareness of semantically meaningful boundaries. \\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.01337\"\n  }, \"https://arxiv.org/abs/1612.01337\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Diverse Sampling for Self-Supervised Learning of Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.01991\"\n  }, \"https://arxiv.org/abs/1612.01991\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mining Pixels: Weakly Supervised Semantic Segmentation Using Image Labels\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Nankai University & University of Oxford & NUS\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.02101\"\n  }, \"https://arxiv.org/abs/1612.02101\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FCNs in the Wild: Pixel-level Adversarial and Constraint-based Adaptation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.02649\"\n  }, \"https://arxiv.org/abs/1612.02649\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Understanding Convolution for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: UCSD & CMU & UIUC & TuSimple\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1702.08502\"\n  }, \"https://arxiv.org/abs/1702.08502\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(MXNet): \", \"[https://github.com/TuSimple/TuSimple-DUC]\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/TuSimple/TuSimple-DUC\"\n  }, \"https://github.com/TuSimple/TuSimple-DUC\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"pretrained-models: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://drive.google.com/drive/folders/0B72xLTlRb0SoREhISlhibFZTRmM\"\n  }, \"https://drive.google.com/drive/folders/0B72xLTlRb0SoREhISlhibFZTRmM\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Label Refinement Network for Coarse-to-Fine Semantic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.arxiv.org/abs/1703.00551\"\n  }, \"https://www.arxiv.org/abs/1703.00551\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Predicting Deeper into the Future of Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Facebook AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.07684\"\n  }, \"https://arxiv.org/abs/1703.07684\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Region Mining with Adversarial Erasing: A Simple Classification to Semantic Segmentation Approach\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017 (oral)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Adversarial Erasing (AE)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.08448\"\n  }, \"https://arxiv.org/abs/1703.08448\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Guided Perturbations: Self Corrective Behavior in Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Maryland & GE Global Research Center\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.07928\"\n  }, \"https://arxiv.org/abs/1703.07928\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Not All Pixels Are Equal: Difficulty-aware Semantic Segmentation via Deep Layer Cascade\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017 spotlight paper\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.01344\"\n  }, \"https://arxiv.org/abs/1704.01344\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Large Kernel Matters -- Improve Semantic Segmentation by Global Convolutional Network\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1703.02719\"\n  }, \"https://arxiv.org/abs/1703.02719\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Loss Max-Pooling for Semantic Image Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.02966\"\n  }, \"https://arxiv.org/abs/1704.02966\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Reformulating Level Sets as Deep Recurrent Neural Network Approach to Semantic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1704.03593\"\n  }, \"https://arxiv.org/abs/1704.03593\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Review on Deep Learning Techniques Applied to Semantic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1704.06857\"\n  }, \"https://arxiv.org/abs/1704.06857\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Joint Semantic and Motion Segmentation for dynamic scenes using Deep Convolutional Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: [International Institute of Information Technology & Max Planck Institute For Intelligent Systems\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.08331\"\n  }, \"https://arxiv.org/abs/1704.08331\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ICNet for Real-Time Semantic Segmentation on High-Resolution Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CUHK & Sensetime\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://hszhao.github.io/projects/icnet/\"\n  }, \"https://hszhao.github.io/projects/icnet/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.08545\"\n  }, \"https://arxiv.org/abs/1704.08545\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hszhao/ICNet\"\n  }, \"https://github.com/hszhao/ICNet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"video: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=qWl9idsCuLQ\"\n  }, \"https://www.youtube.com/watch?v=qWl9idsCuLQ\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Feature Forwarding: Exploiting Encoder Representations for Efficient Semantic Segmentation\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"LinkNet: Exploiting Encoder Representations for Efficient Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://codeac29.github.io/projects/linknet/\"\n  }, \"https://codeac29.github.io/projects/linknet/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.03718\"\n  }, \"https://arxiv.org/abs/1707.03718\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/e-lab/LinkNet\"\n  }, \"https://github.com/e-lab/LinkNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pixel Deconvolutional Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Washington State University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1705.06820\"\n  }, \"https://arxiv.org/abs/1705.06820\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Incorporating Network Built-in Priors in Weakly-supervised Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IEEE TPAMI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.02189\"\n  }, \"https://arxiv.org/abs/1706.02189\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Semantic Segmentation for Automated Driving: Taxonomy, Roadmap and Challenges\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IEEE ITSC 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.02432\"\n  }, \"https://arxiv.org/abs/1707.02432\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Segmentation with Reverse Attention\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2017 oral. University of Southern California\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.06426\"\n  }, \"https://arxiv.org/abs/1707.06426\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Stacked Deconvolutional Network for Semantic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1708.04943\"\n  }, \"https://arxiv.org/abs/1708.04943\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Dilation Factors for Semantic Segmentation of Street Scenes\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: GCPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1709.01956\"\n  }, \"https://arxiv.org/abs/1709.01956\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Self-aware Sampling Scheme to Efficiently Train Fully Convolutional Networks for Semantic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.02764\"\n  }, \"https://arxiv.org/abs/1709.02764\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"One-Shot Learning for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMWC 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arcxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1709.03410\"\n  }, \"https://arxiv.org/abs/1709.03410\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lzzcd001/OSLSM\"\n  }, \"https://github.com/lzzcd001/OSLSM\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An Adaptive Sampling Scheme to Efficiently Train Fully Convolutional Networks for Semantic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.02764\"\n  }, \"https://arxiv.org/abs/1709.02764\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Segmentation from Limited Training Data\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.07665\"\n  }, \"https://arxiv.org/abs/1709.07665\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unsupervised Domain Adaptation for Semantic Segmentation with GANs\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.06969\"\n  }, \"https://arxiv.org/abs/1711.06969\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Neuron-level Selective Context Aggregation for Scene Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.08278\"\n  }, \"https://arxiv.org/abs/1711.08278\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Road Extraction by Deep Residual U-Net\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.10684\"\n  }, \"https://arxiv.org/abs/1711.10684\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mix-and-Match Tuning for Self-Supervised Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://mmlab.ie.cuhk.edu.hk/projects/M&M/\"\n  }, \"http://mmlab.ie.cuhk.edu.hk/projects/M&M/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.00661\"\n  }, \"https://arxiv.org/abs/1712.00661\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/XiaohangZhan/mix-and-match/\"\n  }, \"https://github.com/XiaohangZhan/mix-and-match/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com//liuziwei7/mix-and-match\"\n  }, \"https://github.com//liuziwei7/mix-and-match\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Error Correction for Dense Semantic Image Labeling\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.03812\"\n  }, \"https://arxiv.org/abs/1712.03812\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Segmentation via Highly Fused Convolutional Network with Multiple Soft Cost Functions\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1801.01317\"\n  }, \"https://arxiv.org/abs/1801.01317\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RTSeg: Real-time Semantic Segmentation Comparative Study\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.02758\"\n  }, \"https://arxiv.org/abs/1803.02758\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MSiam/TFSegmentation\"\n  }, \"https://github.com/MSiam/TFSegmentation\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ShuffleSeg: Real-time Semantic Segmentation Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Cairo University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.03816\"\n  }, \"https://arxiv.org/abs/1803.03816\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dynamic-structured Semantic Propagation Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.06067\"\n  }, \"https://arxiv.org/abs/1803.06067\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://sacmehta.github.io/ESPNet/\"\n  }, \"https://sacmehta.github.io/ESPNet/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.06815\"\n  }, \"https://arxiv.org/abs/1803.06815\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/sacmehta/ESPNet\"\n  }, \"https://github.com/sacmehta/ESPNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Context Encoding for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Synchronized Cross-GPU Batch Normalization\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.08904\"\n  }, \"https://arxiv.org/abs/1803.08904\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zhanghang1989/PyTorch-Encoding\"\n  }, \"https://github.com/zhanghang1989/PyTorch-Encoding\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Adaptive Affinity Field for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: UC Berkeley / ICSI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.10335\"\n  }, \"https://arxiv.org/abs/1803.10335\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Predicting Future Instance Segmentations by Forecasting Convolutional Features\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Facebook AI Research & Univ. Grenoble Alpes\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.11496\"\n  }, \"https://arxiv.org/abs/1803.11496\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fully Convolutional Adaptation Networks for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018, Rank 1 in Segmentation Track of Visual Domain Adaptation Challenge 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Fully Convolutional Adaptation Networks (FCAN), Appearance Adaptation Networks (AAN) and Representation Adaptation Networks (RAN)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.08286\"\n  }, \"https://arxiv.org/abs/1804.08286\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning a Discriminative Feature Network for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.09337\"\n  }, \"https://arxiv.org/abs/1804.09337\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Representation Learning for Domain Adaptation of Semantic Image Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.04141\"\n  }, \"https://arxiv.org/abs/1805.04141\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Convolutional CRFs for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.04777\"\n  }, \"https://arxiv.org/abs/1805.04777\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MarvinTeichmann/ConvCRF\"\n  }, \"https://github.com/MarvinTeichmann/ConvCRF\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ContextNet: Exploring Context and Detail for Semantic Segmentation in Real-time\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Toshiba Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.04554\"\n  }, \"https://arxiv.org/abs/1805.04554\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DifNet: Semantic Segmentation by DiffusionNetworks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.08015\"\n  }, \"https://arxiv.org/abs/1805.08015\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pyramid Attention Network for Semantic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1805.10180\"\n  }, \"https://arxiv.org/abs/1805.10180\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Segmentation with Scarce Data\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICML 2018 Workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.00911\"\n  }, \"https://arxiv.org/abs/1807.00911\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attention to Refine through Multi-Scales for Semantic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1807.02917\"\n  }, \"https://arxiv.org/abs/1807.02917\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Guided Upsampling Network for Real-Time Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.07466\"\n  }, \"https://arxiv.org/abs/1807.07466\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning for Semantic Segmentation on Minimal Hardware\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: RoboCup International Symposium 2018. University of Hertfordshire\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.05597\"\n  }, \"https://arxiv.org/abs/1807.05597\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Future Semantic Segmentation with Convolutional LSTM\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.07946\"\n  }, \"https://arxiv.org/abs/1807.07946\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.00897\"\n  }, \"https://arxiv.org/abs/1808.00897\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dual Attention Network for Scene Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1809.02983\"\n  }, \"https://arxiv.org/abs/1809.02983\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Real-Time Joint Semantic Segmentation and Depth Estimation Using Asymmetric Annotations\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1809.04766\"\n  }, \"https://arxiv.org/abs/1809.04766\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Efficient Dense Modules of Asymmetric Convolution for Real-Time Semantic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1809.06323\"\n  }, \"https://arxiv.org/abs/1809.06323\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Image Segmentation by Scale-Adaptive Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Caffe): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/speedinghzl/Scale-Adaptive-Network\"\n  }, \"https://github.com/speedinghzl/Scale-Adaptive-Network\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Recurrent Iterative Gating Networks for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: WACV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.08043\"\n  }, \"https://arxiv.org/abs/1811.08043\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CGNet: A Light-weight Context Guided Network for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.08201\"\n  }, \"https://arxiv.org/abs/1811.08201\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/wutianyiRosun/CGNet\"\n  }, \"https://github.com/wutianyiRosun/CGNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CCNet: Criss-Cross Attention for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Huazhong University of Science and Technology & Horizon Robotics & University of Illinois at Urbana-Champaign\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.11721\"\n  }, \"https://arxiv.org/abs/1811.11721\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/speedinghzl/CCNet\"\n  }, \"https://github.com/speedinghzl/CCNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ShelfNet for Real-time Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Yale University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.11254\"\n  }, \"https://arxiv.org/abs/1811.11254\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/juntang-zhuang/ShelfNet\"\n  }, \"https://github.com/juntang-zhuang/ShelfNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improving Semantic Segmentation via Video Propagation and Label Relaxation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1812.01593\"\n  }, \"https://arxiv.org/abs/1812.01593\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/NVIDIA/semantic-segmentation\"\n  }, \"https://github.com/NVIDIA/semantic-segmentation\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RetinaMask: Learning to predict masks improves state-of-the-art single-shot detection for free\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.03353\"\n  }, \"https://arxiv.org/abs/1901.03353\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/chengyangfu/retinamask\"\n  }, \"https://github.com/chengyangfu/retinamask\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast-SCNN: Fast Semantic Segmentation Network\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1902.04502\"\n  }, \"https://arxiv.org/abs/1902.04502\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Structured Knowledge Distillation for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.04197\"\n  }, \"https://arxiv.org/abs/1903.04197\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"In Defense of Pre-trained ImageNet Architectures for Real-time Semantic Segmentation of Road-driving Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Zagreb\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: SwiftNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.08469\"\n  }, \"https://arxiv.org/abs/1903.08469\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/orsic/swiftnet\"\n  }, \"https://github.com/orsic/swiftnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FastFCN: Rethinking Dilated Convolution in the Backbone for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Chinese Academy of Sciences & Deepwise AI Lab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Joint Pyramid Upsampling (JPU)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://wuhuikai.me/FastFCNProject/\"\n  }, \"http://wuhuikai.me/FastFCNProject/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.11816\"\n  }, \"https://arxiv.org/abs/1903.11816\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/wuhuikai/FastFCN\"\n  }, \"https://github.com/wuhuikai/FastFCN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Significance-aware Information Bottleneck for Domain Adaptive Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: HUST & UTS\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.00876\"\n  }, \"https://arxiv.org/abs/1904.00876\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"GFF: Gated Fully Fusion for Semantic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1904.01803\"\n  }, \"https://arxiv.org/abs/1904.01803\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DADA: Depth-aware Domain Adaptation in Semantic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1904.01886\"\n  }, \"https://arxiv.org/abs/1904.01886\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DFANet: Deep Feature Aggregation for Real-Time Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Megvii Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.02216\"\n  }, \"https://arxiv.org/abs/1904.02216\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ESNet: An Efficient Symmetric Network for Real-time Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1906.09826\"\n  }, \"https://arxiv.org/abs/1906.09826\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xiaoyufenfei/ESNet\"\n  }, \"https://github.com/xiaoyufenfei/ESNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Gated-SCNN: Gated Shape CNNs for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NVIDIA & University of Waterloo & University of Toronto & Vector Institute\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://nv-tlabs.github.io/GSCNN/\"\n  }, \"https://nv-tlabs.github.io/GSCNN/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.05740\"\n  }, \"https://arxiv.org/abs/1907.05740\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DABNet: Depth-wise Asymmetric Bottleneck for Real-time Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.11830\"\n  }, \"https://arxiv.org/abs/1907.11830\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dynamic Graph Message Passing Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1908.06955\"\n  }, \"https://arxiv.org/abs/1908.06955\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Squeeze-and-Attention Networks for Semantic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1909.03402\"\n  }, \"https://arxiv.org/abs/1909.03402\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Global Aggregation then Local Distribution in Fully Convolutional Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.07229\"\n  }, \"https://arxiv.org/abs/1909.07229\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lxtGH/GALD-Net\"\n  }, \"https://github.com/lxtGH/GALD-Net\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Graph-guided Architecture Search for Real-time Semantic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1909.06793\"\n  }, \"https://arxiv.org/abs/1909.06793\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Feature Pyramid Encoding Network for Real-time Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.08599\"\n  }, \"https://arxiv.org/abs/1909.08599\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ACFNet: Attentional Class Feature Network for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.09408\"\n  }, \"https://arxiv.org/abs/1909.09408\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Region Mutual Information Loss for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1910.12037\"\n  }, \"https://arxiv.org/abs/1910.12037\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ZJULearning/RMI\"\n  }, \"https://github.com/ZJULearning/RMI\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Category Anchor-Guided Unsupervised Domain Adaptation for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1910.13049\"\n  }, \"https://arxiv.org/abs/1910.13049\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/RogerZhangzz/CAG_UDA\"\n  }, \"https://github.com/RogerZhangzz/CAG_UDA\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Efficacy of Pixel-Level OOD Detection for Semantic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1911.02897\"\n  }, \"https://arxiv.org/abs/1911.02897\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Location-aware Upsampling for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: LaU\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1911.05250\"\n  }, \"https://arxiv.org/abs/1911.05250\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/HolmesShuan/Location-aware-Upsampling-for-Semantic-Segmentation\"\n  }, \"https://github.com/HolmesShuan/Location-aware-Upsampling-for-Semantic-Segmentation\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FasterSeg: Searching for Faster Real-time Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Texas A&M University & Horizon Robotics Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1912.10917\"\n  }, \"https://arxiv.org/abs/1912.10917\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AlignSeg: Feature-Aligned Segmentation Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2003.00872\"\n  }, \"https://arxiv.org/abs/2003.00872\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Grouping Model for Unified Perceptual Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.11647\"\n  }, \"https://arxiv.org/abs/2003.11647\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spatial Pyramid Based Graph Reasoning for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.10211\"\n  }, \"https://arxiv.org/abs/2003.10211\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Dynamic Routing for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.10401\"\n  }, \"https://arxiv.org/abs/2003.10401\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"giihub(official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yanwei-li/DynamicRouting\"\n  }, \"https://github.com/yanwei-li/DynamicRouting\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning to Predict Context-adaptive Convolution for Semantic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2004.08222\"\n  }, \"https://arxiv.org/abs/2004.08222\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Transferring and Regularizing Prediction for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2006.06570\"\n  }, \"https://arxiv.org/abs/2006.06570\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Tensor Low-Rank Reconstruction for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Top-1 performance on PASCAL-VOC12\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2008.00490\"\n  }, \"https://arxiv.org/abs/2008.00490\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/CWanli/RecoNet\"\n  }, \"https://github.com/CWanli/RecoNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Representative Graph Neural Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2008.05202\"\n  }, \"https://arxiv.org/abs/2008.05202\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"EfficientFCN: Holistically-guided Decoding for Semantic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2008.10487\"\n  }, \"https://arxiv.org/abs/2008.10487\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Improving Semantic Segmentation via Decoupled Body and Edge Supervision\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.10035\"\n  }, \"https://arxiv.org/abs/2007.10035\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lxtGH/DecoupleSegNets\"\n  }, \"https://github.com/lxtGH/DecoupleSegNets\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Auto Seg-Loss: Searching Metric Surrogates for Semantic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2010.07930\"\n  }, \"https://arxiv.org/abs/2010.07930\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PseudoSeg: Designing Pseudo Labels for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2010.09713\"\n  }, \"https://arxiv.org/abs/2010.09713\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/googleinterns/wss\"\n  }, \"https://github.com/googleinterns/wss\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Importance-Aware Semantic Segmentation in Self-Driving with Discrete Wasserstein Training\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2010.12440\"\n  }, \"https://arxiv.org/abs/2010.12440\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pixel-Level Cycle Association: A New Perspective for Domain Adaptive Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2020 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.00147\"\n  }, \"https://arxiv.org/abs/2011.00147\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kgl-prml/Pixel-Level-Cycle-Association\"\n  }, \"https://github.com/kgl-prml/Pixel-Level-Cycle-Association\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CABiNet: Efficient Context Aggregation Network for Low-Latency Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Twente\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.00993\"\n  }, \"https://arxiv.org/abs/2011.00993\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SegBlocks: Block-Based Dynamic Resolution Networks for Real-Time Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2011.12025\"\n  }, \"https://arxiv.org/abs/2011.12025\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Channel-wise Distillation for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.13256\"\n  }, \"https://arxiv.org/abs/2011.13256\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/drilistbox\"\n  }, \"https://github.com/drilistbox\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BoxInst: High-Performance Instance Segmentation with Box Annotations\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Adelaide\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.02310\"\n  }, \"https://arxiv.org/abs/2012.02310\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aim-uofa/AdelaiDet/\"\n  }, \"https://github.com/aim-uofa/AdelaiDet/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scaling Semantic Segmentation Beyond 1K Classes on a Single GPU\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.07489\"\n  }, \"https://arxiv.org/abs/2012.07489\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/shipra25jain/ESSNet\"\n  }, \"https://github.com/shipra25jain/ESSNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cross-Domain Grouping and Alignment for Domain Adaptive Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.08226\"\n  }, \"https://arxiv.org/abs/2012.08226\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Facebook AI & Tel Aviv University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.11582\"\n  }, \"https://arxiv.org/abs/2012.11582\"))), mdx(\"h2\", {\n    \"id\": \"setr\"\n  }, \"SETR\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Fudan University & University of Oxford & University of Surrey & Tencent Youtu Lab & Facebook AI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://fudan-zvg.github.io/SETR/\"\n  }, \"https://fudan-zvg.github.io/SETR/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.15840\"\n  }, \"https://arxiv.org/abs/2012.15840\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/fudan-zvg/SETR\"\n  }, \"https://github.com/fudan-zvg/SETR\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Exploring Cross-Image Pixel Contrast for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Computer Vision Lab, ETH Zurich & SenseTime Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2101.11939\"\n  }, \"https://arxiv.org/abs/2101.11939\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tfzhou/ContrastiveSeg\"\n  }, \"https://github.com/tfzhou/ContrastiveSeg\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Active Boundary Loss for Semantic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2102.02696\"\n  }, \"https://arxiv.org/abs/2102.02696\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Statistical Texture for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Beihang University & SenseTime Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.04133\"\n  }, \"https://arxiv.org/abs/2103.04133\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cross-Dataset Collaborative Learning for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Xilinx Inc. & Chinese Academy of Sciences\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.11351\"\n  }, \"https://arxiv.org/abs/2103.11351\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Vision Transformers for Dense Prediction\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Intel Labs\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.13413\"\n  }, \"https://arxiv.org/abs/2103.13413\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/intel-isl/DPT\"\n  }, \"https://github.com/intel-isl/DPT\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"InverseForm: A Loss Function for Structured Boundary-Aware Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Qualcomm AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.02745\"\n  }, \"https://arxiv.org/abs/2104.02745\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rethinking BiSeNet For Real-time Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Meituan\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.13188\"\n  }, \"https://arxiv.org/abs/2104.13188\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MichaelFan01/STDC-Seg\"\n  }, \"https://github.com/MichaelFan01/STDC-Seg\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Segmenter: Transformer for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Inria\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2105.05633\"\n  }, \"https://arxiv.org/abs/2105.05633\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/rstrudel/segmenter\"\n  }, \"https://github.com/rstrudel/segmenter\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2105.15203\"\n  }, \"https://arxiv.org/abs/2105.15203\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Per-Pixel Classification is Not All You Need for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: UIUC & FAIR\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://bowenc0221.github.io/maskformer/\"\n  }, \"https://bowenc0221.github.io/maskformer/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2107.06278\"\n  }, \"https://arxiv.org/abs/2107.06278\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Unified Efficient Pyramid Transformer for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: School of Data Science, Fudan University & Amazon Web Services & University of California, Davis\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2107.14209\"\n  }, \"https://arxiv.org/abs/2107.14209\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Metric Learning for Open World Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2108.04562\"\n  }, \"https://arxiv.org/abs/2108.04562\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Anchor Active Domain Adaptation for Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021 Oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2108.08012\"\n  }, \"https://arxiv.org/abs/2108.08012\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Generalize then Adapt: Source-Free Domain Adaptive Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Indian Institute of Science & Google Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://sites.google.com/view/sfdaseg\"\n  }, \"https://sites.google.com/view/sfdaseg\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2108.11249\"\n  }, \"https://arxiv.org/abs/2108.11249\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"HRFormer: High-Resolution Transformer for Dense Prediction\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Chinese Academy of Sciences & Institute of Computing Technology, CAS & Peking University & Microsoft Research Asia & Baidu\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2110.09408\"\n  }, \"https://arxiv.org/abs/2110.09408\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/HRNet/HRFormer\"\n  }, \"https://github.com/HRNet/HRFormer\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Hierarchical Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2203.14335\"\n  }, \"https://arxiv.org/abs/2203.14335\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/0liliulei/HieraSeg\"\n  }, \"https://github.com/0liliulei/HieraSeg\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TopFormer: Token Pyramid Transformer for Mobile Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2204.05525\"\n  }, \"https://arxiv.org/abs/2204.05525\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hustvl/TopFormer\"\n  }, \"https://github.com/hustvl/TopFormer\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mask DINO: Towards A Unified Transformer-based Framework for Object Detection and Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The Hong Kong University of Science and Technology & Tsinghua University & International Digital Economy Academy (IDEA) & The Hong Kong University of Science and Technology (Guangzhou)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2206.02777\"\n  }, \"https://arxiv.org/abs/2206.02777\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/IDEACVR/MaskDINO\"\n  }, \"https://github.com/IDEACVR/MaskDINO\"))), mdx(\"h1\", {\n    \"id\": \"instance-segmentation\"\n  }, \"Instance Segmentation\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Simultaneous Detection and Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2014\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"author: Bharath Hariharan, Pablo Arbelaez, Ross Girshick, Jitendra Malik\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1407.1808\"\n  }, \"http://arxiv.org/abs/1407.1808\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Matlab): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bharath272/sds_eccv2014\"\n  }, \"https://github.com/bharath272/sds_eccv2014\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Convolutional Feature Masking for Joint Object and Stuff Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: masking layers\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1412.1283\"\n  }, \"https://arxiv.org/abs/1412.1283\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Dai_Convolutional_Feature_Masking_2015_CVPR_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Dai_Convolutional_Feature_Masking_2015_CVPR_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Proposal-free Network for Instance-level Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1509.02636\"\n  }, \"http://arxiv.org/abs/1509.02636\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hypercolumns for object segmentation and fine-grained localization\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1411.5752\"\n  }, \"https://arxiv.org/abs/1411.5752\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.berkeley.edu/~bharath2/pubs/pdfs/BharathCVPR2015.pdf\"\n  }, \"http://www.cs.berkeley.edu/~bharath2/pubs/pdfs/BharathCVPR2015.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SDS using hypercolumns\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bharath272/sds\"\n  }, \"https://github.com/bharath272/sds\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning to decompose for object detection and instance segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICLR 2016 Workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keyword: CNN / RNN, MNIST, KITTI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1511.06449\"\n  }, \"http://arxiv.org/abs/1511.06449\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Recurrent Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"porject page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://romera-paredes.com/ris\"\n  }, \"http://romera-paredes.com/ris\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1511.08250\"\n  }, \"http://arxiv.org/abs/1511.08250\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Torch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/bernard24/ris\"\n  }, \"https://github.com/bernard24/ris\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"poster: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.eccv2016.org/files/posters/P-4B-46.pdf\"\n  }, \"http://www.eccv2016.org/files/posters/P-4B-46.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"youtube: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=l_WD2OWOqBk\"\n  }, \"https://www.youtube.com/watch?v=l_WD2OWOqBk\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Instance-sensitive Fully Convolutional Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016. instance segment proposal\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.08678\"\n  }, \"http://arxiv.org/abs/1603.08678\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Amodal Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1604.08202\"\n  }, \"http://arxiv.org/abs/1604.08202\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bridging Category-level and Instance-level Semantic Image Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: online bootstrapping\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.06885\"\n  }, \"http://arxiv.org/abs/1605.06885\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bottom-up Instance Segmentation using Deep Higher-Order CRFs\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1609.02583\"\n  }, \"http://arxiv.org/abs/1609.02583\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DeepCut: Object Segmentation from Bounding Box Annotations using Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.07866\"\n  }, \"http://arxiv.org/abs/1605.07866\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End-to-End Instance Segmentation and Counting with Recurrent Attention\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ReInspect\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1605.09410\"\n  }, \"http://arxiv.org/abs/1605.09410\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Translation-aware Fully Convolutional Instance Segmentation\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fully Convolutional Instance-aware Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro:  CVPR 2017 Spotlight paper. winning entry of COCO segmentation challenge 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords:  TA-FCN / FCIS\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.07709\"\n  }, \"https://arxiv.org/abs/1611.07709\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/msracver/FCIS\"\n  }, \"https://github.com/msracver/FCIS\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://onedrive.live.com/?cid=f371d9563727b96f&id=F371D9563727B96F%2197213&authkey=%21AEYOyOirjIutSVk\"\n  }, \"https://onedrive.live.com/?cid=f371d9563727b96f&id=F371D9563727B96F%2197213&authkey=%21AEYOyOirjIutSVk\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"InstanceCut: from Edges to Instances with MultiCut\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.08272\"\n  }, \"https://arxiv.org/abs/1611.08272\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Watershed Transform for Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.08303\"\n  }, \"https://arxiv.org/abs/1611.08303\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Detection Free Instance Segmentation With Labeling Transformations\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.08991\"\n  }, \"https://arxiv.org/abs/1611.08991\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Shape-aware Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.03129\"\n  }, \"https://arxiv.org/abs/1612.03129\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Interpretable Structure-Evolving LSTM\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CMU & Sun Yat-sen University & National University of Singapore & Adobe Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017 spotlight paper\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.03055\"\n  }, \"https://arxiv.org/abs/1703.03055\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mask R-CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017 Best paper award. Facebook AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.06870\"\n  }, \"https://arxiv.org/abs/1703.06870\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://kaiminghe.com/iccv17tutorial/maskrcnn_iccv2017_tutorial_kaiminghe.pdf\"\n  }, \"http://kaiminghe.com/iccv17tutorial/maskrcnn_iccv2017_tutorial_kaiminghe.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, Caffe2): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/facebookresearch/Detectron\"\n  }, \"https://github.com/facebookresearch/Detectron\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/facebookresearch/maskrcnn-benchmark\"\n  }, \"https://github.com/facebookresearch/maskrcnn-benchmark\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/TuSimple/mx-maskrcnn\"\n  }, \"https://github.com/TuSimple/mx-maskrcnn\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://lmb.informatik.uni-freiburg.de/lectures/seminar_brox/seminar_ss17/maskrcnn_slides.pdf\"\n  }, \"https://lmb.informatik.uni-freiburg.de/lectures/seminar_brox/seminar_ss17/maskrcnn_slides.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Keras+TensorFlow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/matterport/Mask_RCNN\"\n  }, \"https://github.com/matterport/Mask_RCNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Faster Training of Mask R-CNN by Focusing on Instance Boundaries\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMW Car IT GmbH\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1809.07069\"\n  }, \"https://arxiv.org/abs/1809.07069\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Boundary-preserving Mask R-CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Huazhong University of Science and Technology & Horizon Robotics Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.08921\"\n  }, \"https://arxiv.org/abs/2007.08921\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hustvl/BMaskR-CNN\"\n  }, \"https://github.com/hustvl/BMaskR-CNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Instance Segmentation via Deep Metric Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1703.10277\"\n  }, \"https://arxiv.org/abs/1703.10277\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pose2Instance: Harnessing Keypoints for Person Instance Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1704.01152\"\n  }, \"https://arxiv.org/abs/1704.01152\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pixelwise Instance Segmentation with a Dynamically Instantiated Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.02386\"\n  }, \"https://arxiv.org/abs/1704.02386\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Instance-Level Salient Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.03604\"\n  }, \"https://arxiv.org/abs/1704.03604\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MEnet: A Metric Expression Network for Salient Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IJCAI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.05638\"\n  }, \"https://arxiv.org/abs/1805.05638\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Instance Segmentation with a Discriminative Loss Function\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Published at \\\"Deep Learning for Robotic Vision\\\", workshop at CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.02551\"\n  }, \"https://arxiv.org/abs/1708.02551\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Wizaron/instance-segmentation-pytorch\"\n  }, \"https://github.com/Wizaron/instance-segmentation-pytorch\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SceneCut: Joint Geometric and Object Segmentation for Indoor Scenes\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.07158\"\n  }, \"https://arxiv.org/abs/1709.07158\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"S4 Net: Single Stage Salient-Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.07618\"\n  }, \"https://arxiv.org/abs/1711.07618\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/RuochenFan/S4Net\"\n  }, \"https://github.com/RuochenFan/S4Net\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Extreme Cut: From Extreme Points to Object Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.09081\"\n  }, \"https://arxiv.org/abs/1711.09081\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning to Segment Every Thing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018. UC Berkeley & Facebook AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: MaskX R-CNN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://ronghanghu.com/seg_every_thing/\"\n  }, \"http://ronghanghu.com/seg_every_thing/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1711.10370\"\n  }, \"https://arxiv.org/abs/1711.10370\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gihtub(official, Caffe2): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ronghanghu/seg_every_thing\"\n  }, \"https://github.com/ronghanghu/seg_every_thing\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Recurrent Neural Networks for Semantic Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://imatge-upc.github.io/rsis/\"\n  }, \"https://imatge-upc.github.io/rsis/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.00617\"\n  }, \"https://arxiv.org/abs/1712.00617\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/imatge-upc/rsis\"\n  }, \"https://github.com/imatge-upc/rsis\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MaskLab: Instance Segmentation by Refining Object Detection with Semantic and Direction Features\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Inc. & RWTH Aachen University & UCLA\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.04837\"\n  }, \"https://arxiv.org/abs/1712.04837\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Recurrent Pixel Embedding for Instance Grouping\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: learning to embed pixels and group them into boundaries, object proposals, semantic segments and instances.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.ics.uci.edu/~skong2/SMMMSG.html\"\n  }, \"http://www.ics.uci.edu/~skong2/SMMMSG.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.08273\"\n  }, \"https://arxiv.org/abs/1712.08273\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aimerykong/Recurrent-Pixel-Embedding-for-Instance-Grouping\"\n  }, \"https://github.com/aimerykong/Recurrent-Pixel-Embedding-for-Instance-Grouping\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.ics.uci.edu/~skong2/slides/pixel_embedding_for_grouping_public_version.pdf\"\n  }, \"http://www.ics.uci.edu/~skong2/slides/pixel_embedding_for_grouping_public_version.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"poster: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.ics.uci.edu/~skong2/slides/pixel_embedding_for_grouping_poster.pdf\"\n  }, \"http://www.ics.uci.edu/~skong2/slides/pixel_embedding_for_grouping_poster.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Annotation-Free and One-Shot Learning for Instance Segmentation of Homogeneous Object Clusters\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1802.00383\"\n  }, \"https://arxiv.org/abs/1802.00383\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Path Aggregation Network for Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018 Spotlight\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CUHK & Peking University & SenseTime Research & YouTu Lab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: PANet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.01534\"\n  }, \"https://arxiv.org/abs/1803.01534\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ShuLiu1993/PANet\"\n  }, \"https://github.com/ShuLiu1993/PANet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning to Segment via Cut-and-Paste\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: weakly-supervised, adversarial learning setup\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.06414\"\n  }, \"https://arxiv.org/abs/1803.06414\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning to Cluster for Proposal-Free Instance Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.06459\"\n  }, \"https://arxiv.org/abs/1803.06459\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bayesian Semantic Instance Segmentation in Open Set World\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1806.00911\"\n  }, \"https://arxiv.org/abs/1806.00911\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TernausNetV2: Fully Convolutional Network for Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1806.00844\"\n  }, \"https://arxiv.org/abs/1806.00844\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ternaus/TernausNetV2\"\n  }, \"https://github.com/ternaus/TernausNetV2\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dynamic Multimodal Instance Segmentation guided by natural language queries\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.02257\"\n  }, \"https://arxiv.org/abs/1807.02257\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/andfoy/query-objseg\"\n  }, \"https://github.com/andfoy/query-objseg\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Traits & Transferability of Adversarial Examples against Instance Segmentation & Object Detection\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1808.01452\"\n  }, \"https://arxiv.org/abs/1808.01452\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Affinity Derivation and Graph Merge for Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.10870\"\n  }, \"https://arxiv.org/abs/1811.10870\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"One-Shot Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Tubingen\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.11507\"\n  }, \"https://arxiv.org/abs/1811.11507\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hybrid Task Cascade for Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The Chinese University of Hong Kong & SenseTime Research & Zhejiang University & The University of Sydney & Nanyang Technological University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Winning entry of COCO 2018 Challenge (object detection task)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.07518\"\n  }, \"https://arxiv.org/abs/1901.07518\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(mmdetection): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/open-mmlab/mmdetection/tree/master/configs/htc\"\n  }, \"https://github.com/open-mmlab/mmdetection/tree/master/configs/htc\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mask Scoring R-CNN\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Huazhong University of Science and Technology & Horizon Robotics Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.00241\"\n  }, \"https://arxiv.org/abs/1903.00241\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/zjhuang22/maskscoring_rcnn\"\n  }, \"https://github.com/zjhuang22/maskscoring_rcnn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TensorMask: A Foundation for Dense Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Facebook AI Research (FAIR)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.12174\"\n  }, \"https://arxiv.org/abs/1903.12174\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Actor-Critic Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: reinforcement learning\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.05126\"\n  }, \"https://arxiv.org/abs/1904.05126\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Instance Segmentation by Jointly Optimizing Spatial Embeddings and Clustering Bandwidth\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1906.11109\"\n  }, \"https://arxiv.org/abs/1906.11109\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/davyneven/SpatialEmbeddings\"\n  }, \"https://github.com/davyneven/SpatialEmbeddings\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"InstaBoost: Boosting Instance Segmentation via Probability Map Guided Copy-Pasting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1908.07801\"\n  }, \"https://arxiv.org/abs/1908.07801\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/GothicAi/Instaboost\"\n  }, \"https://github.com/GothicAi/Instaboost\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SSAP: Single-Shot Instance Segmentation With Affinity Pyramid\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Chinese Academy of Sciences & Horizon Robotics, Inc\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.01616\"\n  }, \"https://arxiv.org/abs/1909.01616\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"YOLACT: Real-time Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: You Only Look At CoefficienTs\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of California, Davis\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: one-stage, Fast NMS\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.02689\"\n  }, \"https://arxiv.org/abs/1904.02689\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, Pytorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/dbolya/yolact\"\n  }, \"https://github.com/dbolya/yolact\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"YOLACT++: Better Real-time Instance Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1912.06218\"\n  }, \"https://arxiv.org/abs/1912.06218\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"YolactEdge: Real-time Instance Segmentation on the Edge\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.12259\"\n  }, \"https://arxiv.org/abs/2012.12259\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/haotian-liu/yolact_edge\"\n  }, \"https://github.com/haotian-liu/yolact_edge\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PolarMask: Single Shot Instance Segmentation with Polar Representation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.13226\"\n  }, \"https://arxiv.org/abs/1909.13226\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xieenze/PolarMask\"\n  }, \"https://github.com/xieenze/PolarMask\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PolarMask++: Enhanced Polar Representation for Single-Shot Instance Segmentation and Beyond\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: TPAMI 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2105.02184\"\n  }, \"https://arxiv.org/abs/2105.02184\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xieenze/PolarMask\"\n  }, \"https://github.com/xieenze/PolarMask\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CenterMask : Real-Time Anchor-Free Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1911.06667\"\n  }, \"https://arxiv.org/abs/1911.06667\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/youngwanLEE/CenterMask\"\n  }, \"https://github.com/youngwanLEE/CenterMask\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/youngwanLEE/centermask2\"\n  }, \"https://github.com/youngwanLEE/centermask2\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CenterMask: single shot instance segmentation with point representation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Meituan Dianping Group\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2004.04446\"\n  }, \"https://arxiv.org/abs/2004.04446\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Shape-aware Feature Extraction for Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1911.11263\"\n  }, \"https://arxiv.org/abs/1911.11263\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PolyTransform: Deep Polygon Transformer for Instance Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1912.02801\"\n  }, \"https://arxiv.org/abs/1912.02801\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"EmbedMask: Embedding Coupling for One-stage Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1912.01954\"\n  }, \"https://arxiv.org/abs/1912.01954\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gitub: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yinghdb/EmbedMask\"\n  }, \"https://github.com/yinghdb/EmbedMask\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SAIS: Single-stage Anchor-free Instance Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1912.01176\"\n  }, \"https://arxiv.org/abs/1912.01176\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SOLO: Segmenting Objects by Locations\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1912.04488\"\n  }, \"https://arxiv.org/abs/1912.04488\"), \"\\n-github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/WXinlong/SOLO\"\n  }, \"https://github.com/WXinlong/SOLO\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SOLOv2: Dynamic, Faster and Stronger\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.10152\"\n  }, \"https://arxiv.org/abs/2003.10152\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aim-uofa/AdelaiDet/\"\n  }, \"https://github.com/aim-uofa/AdelaiDet/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SOLO: A Simple Framework for Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2106.15947\"\n  }, \"https://arxiv.org/abs/2106.15947\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aim-uofa/AdelaiDet/\"\n  }, \"https://github.com/aim-uofa/AdelaiDet/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RDSNet: A New Deep Architecture for Reciprocal Object Detection and Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Chinese Academy of Sciences & 2Horizon Robotics Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1912.05070\"\n  }, \"https://arxiv.org/abs/1912.05070\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/wangsr126/RDSNet\"\n  }, \"https://github.com/wangsr126/RDSNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BlendMask: Top-Down Meets Bottom-Up for Instance Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2001.00309\"\n  }, \"https://arxiv.org/abs/2001.00309\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Conditional Convolutions for Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The University of Adelaide\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.05664\"\n  }, \"https://arxiv.org/abs/2003.05664\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/aim-uofa/adet\"\n  }, \"https://github.com/aim-uofa/adet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PointINS: Point-based Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CUHK & MEGVII & Chinese Academy of Sciences & SmartMore\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.06148\"\n  }, \"https://arxiv.org/abs/2003.06148\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"1st Place Solutions for OpenImage2019 -- Object Detection and Instance Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2003.07557\"\n  }, \"https://arxiv.org/abs/2003.07557\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mask Encoding for Single Shot Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro:  Tongji University & University of Adelaide & Huawei Noah\\u2019s Ark Lab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.11712\"\n  }, \"https://arxiv.org/abs/2003.11712\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Devil is in Classification: A Simple Framework for Long-tail Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.11978\"\n  }, \"https://arxiv.org/abs/2007.11978\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/twangnh/SimCal\"\n  }, \"https://github.com/twangnh/SimCal\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Variational Instance Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2007.11576\"\n  }, \"https://arxiv.org/abs/2007.11576\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mask Point R-CNN\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2008.00460\"\n  }, \"https://arxiv.org/abs/2008.00460\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Forest R-CNN: Large-Vocabulary Long-Tailed Object Detection and Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM MM 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2008.05676\"\n  }, \"https://arxiv.org/abs/2008.05676\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/JialianW/Forest_RCNN\"\n  }, \"https://github.com/JialianW/Forest_RCNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Seesaw Loss for Long-Tailed Instance Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2008.10032\"\n  }, \"https://arxiv.org/abs/2008.10032\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Joint COCO and Mapillary Workshop at ICCV 2019: COCO Instance Segmentation Challenge Track\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: 1st Place Technical Report in ICCV2019/ ECCV2020: MegDetV2\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2010.02475\"\n  }, \"https://arxiv.org/abs/2010.02475\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DCT-Mask: Discrete Cosine Transform Mask Representation for Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Zhejiang University & Alibaba Group\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.09876\"\n  }, \"https://arxiv.org/abs/2011.09876\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The Devil is in the Boundary: Exploiting Boundary Representation for Basis-based Instance Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2011.13241\"\n  }, \"https://arxiv.org/abs/2011.13241\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Robust Instance Segmentation through Reasoning about Multi-Object Occlusion\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2012.02107\"\n  }, \"https://arxiv.org/abs/2012.02107\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Simple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Research & UC Berkeley & Cornell University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.07177\"\n  }, \"https://arxiv.org/abs/2012.07177\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"How Shift Equivariance Impacts Metric Learning for Instance Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2101.05846\"\n  }, \"https://arxiv.org/abs/2101.05846\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FASA: Feature Augmentation and Sampling Adaptation for Long-Tailed Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Nanyang Technological University & Carnegie Mellon Universit\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2102.12867\"\n  }, \"https://arxiv.org/abs/2102.12867\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Occlusion-Aware Instance Segmentation with Overlapping BiLayers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.12340\"\n  }, \"https://arxiv.org/abs/2103.12340\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lkeab/BCNet\"\n  }, \"https://github.com/lkeab/BCNet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"youtube: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=iHlGJppJGiQ\"\n  }, \"https://www.youtube.com/watch?v=iHlGJppJGiQ\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"zhihu: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://zhuanlan.zhihu.com/p/378269087\"\n  }, \"https://zhuanlan.zhihu.com/p/378269087\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sparse Object-level Supervision for Instance Segmentation with Pixel Embeddings\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.14572\"\n  }, \"https://arxiv.org/abs/2103.14572\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kreshuklab/spoco\"\n  }, \"https://github.com/kreshuklab/spoco\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FAPIS: A Few-shot Anchor-free Part-based Instance Segmenter\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.00073\"\n  }, \"https://arxiv.org/abs/2104.00073\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ISTR: End-to-End Instance Segmentation with Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2105.00637\"\n  }, \"https://arxiv.org/abs/2105.00637\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hujiecpp/ISTR\"\n  }, \"https://github.com/hujiecpp/ISTR\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Occlusion-Aware Instance Segmentation with Overlapping BiLayers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The Hong Kong University of Science and Technology & Kuaishou Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: BCNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.12340\"\n  }, \"https://arxiv.org/abs/2103.12340\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lkeab/BCNet\"\n  }, \"https://github.com/lkeab/BCNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SOLQ: Segmenting Objects by Learning Queries\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: MEGVII Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2106.02351\"\n  }, \"https://arxiv.org/abs/2106.02351\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/megvii-research/SOLQ\"\n  }, \"https://github.com/megvii-research/SOLQ\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"1st Place Solution for YouTubeVOS Challenge 2021:Video Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CPVR 2021 Workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2106.06649\"\n  }, \"https://arxiv.org/abs/2106.06649\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Rank & Sort Loss for Object Detection and Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021 Oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2107.11669\"\n  }, \"https://arxiv.org/abs/2107.11669\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kemaloksuz/RankSortLoss\"\n  }, \"https://github.com/kemaloksuz/RankSortLoss\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SOTR: Segmenting Objects with Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2108.06747\"\n  }, \"https://arxiv.org/abs/2108.06747\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/easton-cau/SOTR\"\n  }, \"https://github.com/easton-cau/SOTR\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FaPN: Feature-aligned Pyramid Network for Dense Image Prediction\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2108.07058\"\n  }, \"https://arxiv.org/abs/2108.07058\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/EMI-Group/FaPN\"\n  }, \"https://github.com/EMI-Group/FaPN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Instances as Queries\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: HUST & Tencent\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2105.01928\"\n  }, \"https://arxiv.org/abs/2105.01928\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hustvl/QueryInst\"\n  }, \"https://github.com/hustvl/QueryInst\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mask Transfiner for High-Quality Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ETH Zurich & HKUST & Kuaishou Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arixv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2111.13673\"\n  }, \"https://arxiv.org/abs/2111.13673\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SOIT: Segmenting Objects with Instance-Aware Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2112.11037\"\n  }, \"https://arxiv.org/abs/2112.11037\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yuxiaodongHRI/SOIT\"\n  }, \"https://github.com/yuxiaodongHRI/SOIT\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ContrastMask: Contrastive Learning to Segment Every Thing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2203.09775\"\n  }, \"https://arxiv.org/abs/2203.09775\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sparse Instance Activation for Real-Time Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro CVPR 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Huazhong University of Science & Technology & Horizon Robotics & CASIA\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2203.12827\"\n  }, \"https://arxiv.org/abs/2203.12827\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hustvl/SparseInst\"\n  }, \"https://github.com/hustvl/SparseInst\"))), mdx(\"h2\", {\n    \"id\": \"human-instance-segmentation\"\n  }, \"Human Instance Segmentation\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PersonLab: Person Pose Estimation and Instance Segmentation with a Bottom-Up, Part-Based, Geometric Embedding Model\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google, Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Person detection and pose estimation, segmentation and grouping\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.08225\"\n  }, \"https://arxiv.org/abs/1803.08225\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pose2Seg: Detection Free Human Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Tsinghua Unviersity & BNRist & Tencent AI Lab & Cardiff University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Occluded Human (OCHuman)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.liruilong.cn/Pose2Seg/index.html\"\n  }, \"http://www.liruilong.cn/Pose2Seg/index.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.10683\"\n  }, \"https://arxiv.org/abs/1803.10683\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/liruilong940607/Pose2Seg\"\n  }, \"https://github.com/liruilong940607/Pose2Seg\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"dataset: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://cg.cs.tsinghua.edu.cn/dataset/form.html?dataset=ochuman\"\n  }, \"https://cg.cs.tsinghua.edu.cn/dataset/form.html?dataset=ochuman\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bounding Box Embedding for Single Shot Person Instance Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1807.07674\"\n  }, \"https://arxiv.org/abs/1807.07674\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Parsing R-CNN for Instance-Level Human Analysis\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: COCO 2018 DensePose Challenge Winner\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1811.12596\"\n  }, \"https://arxiv.org/abs/1811.12596\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/soeaver/Parsing-R-CNN\"\n  }, \"https://github.com/soeaver/Parsing-R-CNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Graphonomy: Universal Human Parsing via Graph Transfer Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.04536\"\n  }, \"https://arxiv.org/abs/1904.04536\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Gaoyiminggithub/Graphonomy\"\n  }, \"https://github.com/Gaoyiminggithub/Graphonomy\"))), mdx(\"h2\", {\n    \"id\": \"video-instance-segmentation\"\n  }, \"Video Instance Segmentation\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SipMask: Spatial Information Preservation for Fast Image and Video Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2007.14772\"\n  }, \"https://arxiv.org/abs/2007.14772\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/JialeCao001/SipMask\"\n  }, \"https://github.com/JialeCao001/SipMask\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End-to-End Video Instance Segmentation with Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Meituan & The University of Adelaide\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.14503\"\n  }, \"https://arxiv.org/abs/2011.14503\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spatial Feature Calibration and Temporal Fusion for Effective One-stage Video Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The HongKong Polytechnic University & DAMO Academy, Alibaba Group\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.05606\"\n  }, \"https://arxiv.org/abs/2104.05606\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MinghanLi/STMask\"\n  }, \"https://github.com/MinghanLi/STMask\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Tracking Instances as Queries\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: HUST & Tencent PCG\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2106.11963\"\n  }, \"https://arxiv.org/abs/2106.11963\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video Mask Transfiner for High-Quality Video Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ETH Z\\xA8urich & The Hong Kong University of Science and Technology & Kuaishou Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2207.14012\"\n  }, \"https://arxiv.org/abs/2207.14012\"))), mdx(\"h1\", {\n    \"id\": \"panoptic-segmentation\"\n  }, \"Panoptic Segmentation\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Facebook AI Research (FAIR) & Heidelberg University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.00868\"\n  }, \"https://arxiv.org/abs/1801.00868\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://presentations.cocodataset.org/COCO17-Invited-PanopticAlexKirillov.pdf\"\n  }, \"http://presentations.cocodataset.org/COCO17-Invited-PanopticAlexKirillov.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Panoptic Segmentation with a Joint Semantic and Instance Segmentation Network\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1809.02110\"\n  }, \"https://arxiv.org/abs/1809.02110\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning to Fuse Things and Stuff\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Toyota Research Institute (TRI)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: TASCNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1812.01192\"\n  }, \"https://arxiv.org/abs/1812.01192\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attention-guided Unified Network for Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Chinese Academy of Sciences & Horizon Robotics, Inc. & The Johns Hopkins University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1812.03904\"\n  }, \"https://arxiv.org/abs/1812.03904\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Panoptic Feature Pyramid Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: FAIR\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.02446\"\n  }, \"https://arxiv.org/abs/1901.02446\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"UPSNet: A Unified Panoptic Segmentation Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Uber ATG & University of Toronto & The Chinese University of Hong Kong\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.03784\"\n  }, \"https://arxiv.org/abs/1901.03784\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Single Network Panoptic Segmentation for Street Scene Understanding\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1902.02678\"\n  }, \"https://arxiv.org/abs/1902.02678\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An End-to-End Network for Panoptic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1903.05027\"\n  }, \"https://arxiv.org/abs/1903.05027\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Instance Occlusion for Panoptic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1906.05896\"\n  }, \"https://arxiv.org/abs/1906.05896\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SpatialFlow: Bridging All Tasks for Panoptic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1910.08787\"\n  }, \"https://arxiv.org/abs/1910.08787\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Single-Shot Panoptic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1911.00764\"\n  }, \"https://arxiv.org/abs/1911.00764\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SOGNet: Scene Overlap Graph Network for Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2020. Innovation Award in COCO 2019 challenge\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1911.07527\"\n  }, \"https://arxiv.org/abs/1911.07527\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Panoptic-DeepLab: A Simple, Strong, and Fast Baseline for Bottom-Up Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: UIUC & Google Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1911.10194\"\n  }, \"https://arxiv.org/abs/1911.10194\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PanDA: Panoptic Data Augmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1911.12317\"\n  }, \"https://arxiv.org/abs/1911.12317\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Real-Time Panoptic Segmentation from Dense Detections\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1912.01202\"\n  }, \"https://arxiv.org/abs/1912.01202\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/TRI-ML/realtime_panoptic\"\n  }, \"https://github.com/TRI-ML/realtime_panoptic\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bipartite Conditional Random Fields for Panoptic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1912.05307\"\n  }, \"https://arxiv.org/abs/1912.05307\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unifying Training and Inference for Panoptic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2001.04982\"\n  }, \"https://arxiv.org/abs/2001.04982\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards Bounding-Box Free Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SLAMcore Ltd. & Imperial College London\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2002.07705\"\n  }, \"https://arxiv.org/abs/2002.07705\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Benchmark for LiDAR-based Panoptic Segmentation based on KITTI\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://semantic-kitti.org/\"\n  }, \"http://semantic-kitti.org/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.02371\"\n  }, \"https://arxiv.org/abs/2003.02371\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Axial-DeepLab: Stand-Alone Axial-Attention for Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Johns Hopkins University & Google Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.07853\"\n  }, \"https://arxiv.org/abs/2003.07853\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"EPSNet: Efficient Panoptic Segmentation Network with Cross-layer Attention Fusion\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2003.10142\"\n  }, \"https://arxiv.org/abs/2003.10142\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pixel Consensus Voting for Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2004.01849\"\n  }, \"https://arxiv.org/abs/2004.01849\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"EfficientPS: Efficient Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2004.02307\"\n  }, \"https://arxiv.org/abs/2004.02307\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/DeepSceneSeg/EfficientPS\"\n  }, \"https://github.com/DeepSceneSeg/EfficientPS\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020 Oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: KAIST & Adobe Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2006.11339\"\n  }, \"https://arxiv.org/abs/2006.11339\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mcahny/vps\"\n  }, \"https://github.com/mcahny/vps\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PanoNet: Real-time Panoptic Segmentation through Position-Sensitive Feature Embedding\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2008.00192\"\n  }, \"https://arxiv.org/abs/2008.00192\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Robust Vision Challenge 2020 -- 1st Place Report for Panoptic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2008.10112\"\n  }, \"https://arxiv.org/abs/2008.10112\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Category- and Instance-Aware Pixel Embedding for Fast Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Chinese Academy of Sciences & Horizon Robotics\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2009.13342\"\n  }, \"https://arxiv.org/abs/2009.13342\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Auto-Panoptic: Cooperative Multi-Component Architecture Search for Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Sun Yat-sen University & Huawei Noah\\u2019s Ark Lab & DarkMatter AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2010.16119\"\n  }, \"https://arxiv.org/abs/2010.16119\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Jacobew/AutoPanoptic\"\n  }, \"https://github.com/Jacobew/AutoPanoptic\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scaling Wide Residual Networks for Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Google Research & Johns Hopkins University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.11675\"\n  }, \"https://arxiv.org/abs/2011.11675\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fully Convolutional Networks for Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Chinese University of Hong Kong & University of Oxford & University of Hong Kong & MEGVII Technology4\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.00720\"\n  }, \"https://arxiv.org/abs/2012.00720\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yanwei-li/PanopticFCN\"\n  }, \"https://github.com/yanwei-li/PanopticFCN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MaX-DeepLab: End-to-End Panoptic Segmentation with Mask Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Johns Hopkins University & Google Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.00759\"\n  }, \"https://arxiv.org/abs/2012.00759\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Ada-Segment: Automated Multi-loss Adaptation for Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Sun Yat-Sen University & Huawei Noah\\u2019s Ark Lab & Shanghai Jiao Tong University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.03603\"\n  }, \"https://arxiv.org/abs/2012.03603\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ViP-DeepLab: Learning Visual Perception with Depth-aware Video Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Johns Hopkins University & Google Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.05258\"\n  }, \"https://arxiv.org/abs/2012.05258\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/joe-siyuan-qiao/ViP-DeepLab\"\n  }, \"https://github.com/joe-siyuan-qiao/ViP-DeepLab\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"STEP: Segmenting and Tracking Every Pixel\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Technical University Munich & Google Research & RWTH Aachen University & MPI-IS and University of Tubingen\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2102.11859\"\n  }, \"https://arxiv.org/abs/2102.11859\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cross-View Regularization for Domain Adaptive Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.02584\"\n  }, \"https://arxiv.org/abs/2103.02584\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MaX-DeepLab: End-to-End Panoptic Segmentation with Mask Transformers\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Johns Hopkins University & Google Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arixv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.00759\"\n  }, \"https://arxiv.org/abs/2012.00759\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Panoptic Segmentation Forecasting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.03962\"\n  }, \"https://arxiv.org/abs/2104.03962\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Exemplar-Based Open-Set Panoptic Segmentation Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Seoul National University & Adobe Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://cv.snu.ac.kr/research/EOPSN/\"\n  }, \"https://cv.snu.ac.kr/research/EOPSN/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2105.08336\"\n  }, \"https://arxiv.org/abs/2105.08336\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/jd730/EOPSN\"\n  }, \"https://github.com/jd730/EOPSN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hierarchical Lov\\xE1sz Embeddings for Proposal-free Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2106.04555\"\n  }, \"https://arxiv.org/abs/2106.04555\"))), mdx(\"p\", null, \"P\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"art-aware Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2106.06351\"\n  }, \"https://arxiv.org/abs/2106.06351\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tue-mps/panoptic_parts\"\n  }, \"https://github.com/tue-mps/panoptic_parts\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Panoptic SegFormer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Nanjing University & The University of Hong Kong & NVIDIA & Caltech\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2109.03814\"\n  }, \"https://arxiv.org/abs/2109.03814\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Slot-VPS: Object-centric Representation Learning for Video Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Samsung Research China - Beijing (SRC-B) & 2Samsung Advanced Institute of Technology (SAIT) & University of Oxford & The University of Hong Kong\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2112.08949\"\n  }, \"https://arxiv.org/abs/2112.08949\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CFNet: Learning Correlation Functions for One-Stage Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Zhejiang University & Tencent Youtu Lab & Shanghai Jiao Tong University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2201.04796\"\n  }, \"https://arxiv.org/abs/2201.04796\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Panoptic, Instance and Semantic Relations: A Relational Context Encoder to Enhance Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Qualcomm AI Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2204.05370\"\n  }, \"https://arxiv.org/abs/2204.05370\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PanopticDepth: A Unified Framework for Depth-aware Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Chinese Academy of Sciences & University of Chinese Academy of Sciences & Horizon Robotics, Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2206.00468\"\n  }, \"https://arxiv.org/abs/2206.00468\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CMT-DeepLab: Clustering Mask Transformers for Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022 Oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Johns Hopkins University & KAIST & Google Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2206.08948\"\n  }, \"https://arxiv.org/abs/2206.08948\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Uncertainty-aware Panoptic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Technical University Nurnberg\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2206.14554\"\n  }, \"https://arxiv.org/abs/2206.14554\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"k-means Mask Transformer\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Johns Hopkins University & Google Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2207.04044\"\n  }, \"https://arxiv.org/abs/2207.04044\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/google-research/deeplab2\"\n  }, \"https://github.com/google-research/deeplab2\"))), mdx(\"h1\", {\n    \"id\": \"nightime-segmentation\"\n  }, \"Nightime Segmentation\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Nighttime sky/cloud image segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICIP 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1705.10583\"\n  }, \"https://arxiv.org/abs/1705.10583\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dark Model Adaptation: Semantic Image Segmentation from Daytime to Nighttime\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: International Conference on Intelligent Transportation Systems (ITSC 2018)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1810.02575\"\n  }, \"https://arxiv.org/abs/1810.02575\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Nighttime Image Segmentation with Synthetic Stylized Data, Gradual Adaptation and Uncertainty-Aware Evaluation\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Guided Curriculum Model Adaptation and Uncertainty-Aware Evaluation for Semantic Nighttime Image Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ETH Zurich & KU Leuven\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.05946\"\n  }, \"https://arxiv.org/abs/1901.05946\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bi-Mix: Bidirectional Mixing for Domain Adaptive Nighttime Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2111.10339\"\n  }, \"https://arxiv.org/abs/2111.10339\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ygjwd12345/BiMix\"\n  }, \"https://github.com/ygjwd12345/BiMix\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DANNet: A One-Stage Domain Adaptation Network for Unsupervised Nighttime Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of South Carolina & Farsee2 Technology Ltd\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.10834\"\n  }, \"https://arxiv.org/abs/2104.10834\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/W-zx-Y/DANNet\"\n  }, \"https://github.com/W-zx-Y/DANNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"NightLab: A Dual-level Architecture with Hardness Detection for Segmentation at Night\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2204.05538\"\n  }, \"https://arxiv.org/abs/2204.05538\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/xdeng7/NightLab\"\n  }, \"https://github.com/xdeng7/NightLab\"))), mdx(\"h1\", {\n    \"id\": \"face-parsing\"\n  }, \"Face Parsing\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Face Parsing via Recurrent Propagation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.01936\"\n  }, \"https://arxiv.org/abs/1708.01936\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Face Parsing via a Fully-Convolutional Continuous CRF Neural Network\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1708.03736\"\n  }, \"https://arxiv.org/abs/1708.03736\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Face Parsing with RoI Tanh-Warping\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Software School of Xiamen University & Microsoft Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1906.01342\"\n  }, \"https://arxiv.org/abs/1906.01342\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End-to-End Face Parsing via Interlinked Convolutional Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2002.04831\"\n  }, \"https://arxiv.org/abs/2002.04831\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RoI Tanh-polar Transformer Network for Face Parsing in the Wild\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2102.02717\"\n  }, \"https://arxiv.org/abs/2102.02717\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://ibug.doc.ic.ac.uk/resources/ibugmask/\"\n  }, \"https://ibug.doc.ic.ac.uk/resources/ibugmask/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Decoupled Multi-task Learning with Cyclical Self-Regulation for Face Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2203.14448\"\n  }, \"https://arxiv.org/abs/2203.14448\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/deepinsight/insightface/tree/master/parsing/dml_csr\"\n  }, \"https://github.com/deepinsight/insightface/tree/master/parsing/dml_csr\"))), mdx(\"h1\", {\n    \"id\": \"specific-segmentation\"\n  }, \"Specific Segmentation\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A CNN Cascade for Landmark Guided Semantic Part Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://aaronsplace.co.uk/\"\n  }, \"http://aaronsplace.co.uk/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://aaronsplace.co.uk/papers/jackson2016guided/jackson2016guided.pdf\"\n  }, \"https://aaronsplace.co.uk/papers/jackson2016guided/jackson2016guided.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End-to-end semantic face segmentation with conditional random fields as convolutional, recurrent and adversarial networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.03305\"\n  }, \"https://arxiv.org/abs/1703.03305\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Boundary-sensitive Network for Portrait Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.08675\"\n  }, \"https://arxiv.org/abs/1712.08675\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Boundary-Aware Network for Fast and High-Accuracy Portrait Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Zhejiang University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.03814\"\n  }, \"https://arxiv.org/abs/1901.03814\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Beef Cattle Instance Segmentation Using Fully Convolutional Neural Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.01972\"\n  }, \"https://arxiv.org/abs/1807.01972\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Face Mask Extraction in Video Sequence\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: ConvLSTM & FCN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.09207\"\n  }, \"https://arxiv.org/abs/1807.09207\"))), mdx(\"h1\", {\n    \"id\": \"segment-proposal\"\n  }, \"Segment Proposal\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning to Segment Object Candidates\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Facebook AI Research (FAIR)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: DeepMask. learning segmentation proposals\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1506.06204\"\n  }, \"http://arxiv.org/abs/1506.06204\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/facebookresearch/deepmask\"\n  }, \"https://github.com/facebookresearch/deepmask\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/abbypa/NNProject_DeepMask\"\n  }, \"https://github.com/abbypa/NNProject_DeepMask\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning to Refine Object Segments\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016. Facebook AI Research (FAIR)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SharpMask. an extension of DeepMask which generates higher-fidelity masks using an additional top-down refinement step.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.08695\"\n  }, \"http://arxiv.org/abs/1603.08695\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/facebookresearch/deepmask\"\n  }, \"https://github.com/facebookresearch/deepmask\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FastMask: Segment Object Multi-scale Candidates in One Shot\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017. University of California & Fudan University & Megvii Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.08843\"\n  }, \"https://arxiv.org/abs/1612.08843\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/voidrank/FastMask\"\n  }, \"https://github.com/voidrank/FastMask\"))), mdx(\"h1\", {\n    \"id\": \"scene-labeling--scene-parsing\"\n  }, \"Scene Labeling / Scene Parsing\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Indoor Semantic Segmentation using depth information\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1301.3572\"\n  }, \"http://arxiv.org/abs/1301.3572\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Recurrent Convolutional Neural Networks for Scene Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1306.2795\"\n  }, \"http://arxiv.org/abs/1306.2795\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://people.ee.duke.edu/~lcarin/Yizhe8.14.2015.pdf\"\n  }, \"http://people.ee.duke.edu/~lcarin/Yizhe8.14.2015.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/NP-coder/CLPS1520Project\"\n  }, \"https://github.com/NP-coder/CLPS1520Project\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/rkargon/Scene-Labeling\"\n  }, \"https://github.com/rkargon/Scene-Labeling\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning hierarchical features for scene labeling\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://yann.lecun.com/exdb/publis/pdf/farabet-pami-13.pdf\"\n  }, \"http://yann.lecun.com/exdb/publis/pdf/farabet-pami-13.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-modal unsupervised feature learning for rgb-d scene labeling\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2014\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www3.ntu.edu.sg/home/wanggang/WangECCV2014.pdf\"\n  }, \"http://www3.ntu.edu.sg/home/wanggang/WangECCV2014.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scene Labeling with LSTM Recurrent Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Byeon_Scene_Labeling_With_2015_CVPR_paper.pdf\"\n  }, \"http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Byeon_Scene_Labeling_With_2015_CVPR_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attend, Infer, Repeat: Fast Scene Understanding with Generative Models\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1603.08575\"\n  }, \"http://arxiv.org/abs/1603.08575\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"notes: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.shortscience.org/paper?bibtexKey=journals/corr/EslamiHWTKH16\"\n  }, \"http://www.shortscience.org/paper?bibtexKey=journals/corr/EslamiHWTKH16\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"\\\"Semantic Segmentation for Scene Understanding: Algorithms and Implementations\\\" tutorial\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: 2016 Embedded Vision Summit\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"youtube: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=pQ318oCGJGY\"\n  }, \"https://www.youtube.com/watch?v=pQ318oCGJGY\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Understanding of Scenes through the ADE20K Dataset\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1608.05442\"\n  }, \"https://arxiv.org/abs/1608.05442\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Deep Representations for Scene Labeling with Guided Supervision\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Deep Representations for Scene Labeling with Semantic Context Guided Supervision\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CUHK\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.02493\"\n  }, \"https://arxiv.org/abs/1706.02493\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spatial As Deep: Spatial CNN for Traffic Scene Understanding\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.06080\"\n  }, \"https://arxiv.org/abs/1712.06080\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Path Feedback Recurrent Neural Network for Scene Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.07706\"\n  }, \"http://arxiv.org/abs/1608.07706\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scene Labeling using Recurrent Neural Networks with Explicit Long Range Contextual Dependency\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.07485\"\n  }, \"https://arxiv.org/abs/1611.07485\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FIFO: Learning Fog-invariant Features for Foggy Scene Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2204.01587\"\n  }, \"https://arxiv.org/abs/2204.01587\"))), mdx(\"h2\", {\n    \"id\": \"pspnet\"\n  }, \"PSPNet\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pyramid Scene Parsing Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: mIoU score as 85.4% on PASCAL VOC 2012 and 80.2% on Cityscapes,\\nranked 1st place in ImageNet Scene Parsing Challenge 2016\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://appsrv.cse.cuhk.edu.hk/~hszhao/projects/pspnet/index.html\"\n  }, \"http://appsrv.cse.cuhk.edu.hk/~hszhao/projects/pspnet/index.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.01105\"\n  }, \"https://arxiv.org/abs/1612.01105\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://image-net.org/challenges/talks/2016/SenseCUSceneParsing.pdf\"\n  }, \"http://image-net.org/challenges/talks/2016/SenseCUSceneParsing.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hszhao/PSPNet\"\n  }, \"https://github.com/hszhao/PSPNet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Vladkryvoruchko/PSPNet-Keras-tensorflow\"\n  }, \"https://github.com/Vladkryvoruchko/PSPNet-Keras-tensorflow\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Open Vocabulary Scene Parsing\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1703.08769\"\n  }, \"https://arxiv.org/abs/1703.08769\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Contextual Recurrent Residual Networks for Scene Labeling\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1704.03594\"\n  }, \"https://arxiv.org/abs/1704.03594\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast Scene Understanding for Autonomous Driving\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Published at \\\"Deep Learning for Vehicle Perception\\\", workshop at the IEEE Symposium on Intelligent Vehicles 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.02550\"\n  }, \"https://arxiv.org/abs/1708.02550\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FoveaNet: Perspective-aware Urban Scene Parsing\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1708.02421\"\n  }, \"https://arxiv.org/abs/1708.02421\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BlitzNet: A Real-Time Deep Network for Scene Understanding\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: INRIA\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.02813\"\n  }, \"https://arxiv.org/abs/1708.02813\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Foggy Scene Understanding with Synthetic Data\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1708.07819\"\n  }, \"https://arxiv.org/abs/1708.07819\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Scale-adaptive Convolutions for Scene Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_ICCV_2017/papers/Zhang_Scale-Adaptive_Convolutions_for_ICCV_2017_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_ICCV_2017/papers/Zhang_Scale-Adaptive_Convolutions_for_ICCV_2017_paper.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Restricted Deformable Convolution based Road Scene Semantic Segmentation Using Surround View Cameras\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1801.00708\"\n  }, \"https://arxiv.org/abs/1801.00708\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dense Recurrent Neural Networks for Scene Labeling\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1801.06831\"\n  }, \"https://arxiv.org/abs/1801.06831\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DenseASPP for Semantic Segmentation in Street Scenes\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_DenseASPP_for_Semantic_CVPR_2018_paper.pdf\"\n  }, \"http://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_DenseASPP_for_Semantic_CVPR_2018_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/DeepMotionAIResearch/DenseASPP\"\n  }, \"https://github.com/DeepMotionAIResearch/DenseASPP\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"OCNet: Object Context Network for Scene Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Microsoft Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1809.00916\"\n  }, \"https://arxiv.org/abs/1809.00916\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/PkuRainBow/OCNet\"\n  }, \"https://github.com/PkuRainBow/OCNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PSANet: Point-wise Spatial Attention Network for Scene Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://hszhao.github.io/projects/psanet/\"\n  }, \"https://hszhao.github.io/projects/psanet/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://hszhao.github.io/papers/eccv18_psanet.pdf\"\n  }, \"https://hszhao.github.io/papers/eccv18_psanet.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://docs.google.com/presentation/d/1_brKNBtv8nVu_jOwFRGwVkEPAq8B8hEngBSQuZCWaZA/edit#slide=id.p\"\n  }, \"https://docs.google.com/presentation/d/1_brKNBtv8nVu_jOwFRGwVkEPAq8B8hEngBSQuZCWaZA/edit#slide=id.p\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/hszhao/PSANet\"\n  }, \"https://github.com/hszhao/PSANet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Adaptive Context Network for Scene Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1911.01664\"\n  }, \"https://arxiv.org/abs/1911.01664\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Flow for Fast and Accurate Scene Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2002.10120\"\n  }, \"https://arxiv.org/abs/2002.10120\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/donnyyou/torchcv\"\n  }, \"https://github.com/donnyyou/torchcv\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Strip Pooling: Rethinking Spatial Pooling for Scene Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.13328\"\n  }, \"https://arxiv.org/abs/2003.13328\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Andrew-Qibin/SPNet\"\n  }, \"https://github.com/Andrew-Qibin/SPNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"S3-Net: A Fast and Lightweight Video Scene Understanding Network by Single-shot Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: WACV 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.02265\"\n  }, \"https://arxiv.org/abs/2011.02265\"))), mdx(\"h2\", {\n    \"id\": \"benchmarks\"\n  }, \"Benchmarks\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MIT Scene Parsing Benchmark\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://sceneparsing.csail.mit.edu/\"\n  }, \"http://sceneparsing.csail.mit.edu/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(devkit): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/CSAILVision/sceneparsing\"\n  }, \"https://github.com/CSAILVision/sceneparsing\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Understanding of Urban Street Scenes: Benchmark Suite\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.cityscapes-dataset.com/benchmarks/\"\n  }, \"https://www.cityscapes-dataset.com/benchmarks/\")), mdx(\"h2\", {\n    \"id\": \"challenges\"\n  }, \"Challenges\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Large-scale Scene Understanding Challenge\")), mdx(\"img\", {\n    \"src\": \"http://lsun.cs.princeton.edu/img/overview_4crop.jpg\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://lsun.cs.princeton.edu/\"\n  }, \"http://lsun.cs.princeton.edu/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Places2 Challenge\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://places2.csail.mit.edu/challenge.html\"\n  }, \"http://places2.csail.mit.edu/challenge.html\")), mdx(\"h1\", {\n    \"id\": \"human-parsing\"\n  }, \"Human Parsing\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Human Parsing with Contextualized Convolutional Neural Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2015\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Liang_Human_Parsing_With_ICCV_2015_paper.html\"\n  }, \"http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Liang_Human_Parsing_With_ICCV_2015_paper.html\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Look into Person: Self-supervised Structure-sensitive Learning and A New Benchmark for Human Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017. SYSU & CMU\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Look Into Person (LIP)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://hcp.sysu.edu.cn/lip/\"\n  }, \"http://hcp.sysu.edu.cn/lip/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.05446\"\n  }, \"https://arxiv.org/abs/1703.05446\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Engineering-Course/LIP_SSL\"\n  }, \"https://github.com/Engineering-Course/LIP_SSL\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multiple-Human Parsing in the Wild\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1705.07206\"\n  }, \"https://arxiv.org/abs/1705.07206\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Look into Person: Joint Body Parsing & Pose Estimation Network and A New Benchmark\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: T-PAMI 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Joint Body Parsing & Pose Estimation Network (JPPNet)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.01984\"\n  }, \"https://arxiv.org/abs/1804.01984\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Engineering-Course/LIP_JPPNet\"\n  }, \"https://github.com/Engineering-Course/LIP_JPPNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cross-domain Human Parsing via Adversarial Feature and Label Adaptation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.01260\"\n  }, \"https://arxiv.org/abs/1801.01260\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fusing Hierarchical Convolutional Features for Human Body Segmentation and Clothing Fashion Classification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Wuhan University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.03415\"\n  }, \"https://arxiv.org/abs/1803.03415\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Understanding Humans in Crowded Scenes: Deep Nested Adversarial Learning and A New Benchmark for Multi-Human Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.03287\"\n  }, \"https://arxiv.org/abs/1804.03287\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ZhaoJ9014/Multi-Human-Parsing\"\n  }, \"https://github.com/ZhaoJ9014/Multi-Human-Parsing\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Macro-Micro Adversarial Network for Human Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Macro-Micro Adversarial Net (MMAN)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.08260\"\n  }, \"https://arxiv.org/abs/1807.08260\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/RoyalVane/MMAN\"\n  }, \"https://github.com/RoyalVane/MMAN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Instance-level Human Parsing via Part Grouping Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018 Oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.00157\"\n  }, \"https://arxiv.org/abs/1808.00157\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Adaptive Temporal Encoding Network for Video Instance-level Human Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM MM 2018\\n= arixv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1808.00661\"\n  }, \"https://arxiv.org/abs/1808.00661\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, TensorFlow): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/HCPLab-SYSU/ATEN\"\n  }, \"https://github.com/HCPLab-SYSU/ATEN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Devil in the Details: Towards Accurate Single and Multiple Human Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Context Embedding with Edge Perceiving (CE2P)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1809.05996\"\n  }, \"https://arxiv.org/abs/1809.05996\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/liutinglt/CE2P\"\n  }, \"https://github.com/liutinglt/CE2P\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Cross-Domain Complementary Learning with Synthetic Data for Multi-Person Part Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Washington & Microsof\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.05193\"\n  }, \"https://arxiv.org/abs/1907.05193\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Self-Correction for Human Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1910.09777\"\n  }, \"https://arxiv.org/abs/1910.09777\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/PeikeLi/Self-Correction-Human-Parsing\"\n  }, \"https://github.com/PeikeLi/Self-Correction-Human-Parsing\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Grapy-ML: Graph Pyramid Mutual Learning for Cross-dataset Human Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1911.12053\"\n  }, \"https://arxiv.org/abs/1911.12053\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Charleshhy/Grapy-ML\"\n  }, \"https://github.com/Charleshhy/Grapy-ML\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Semantic Neural Tree for Human Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Institute of Software Chinese Academy of Sciences & State University of New York & JD Finance America Corporation & Tencent Youtu Lab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1912.09622\"\n  }, \"https://arxiv.org/abs/1912.09622\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"code: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://isrc.iscas.ac.cn/gitlab/research/sematree\"\n  }, \"https://isrc.iscas.ac.cn/gitlab/research/sematree\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Self-Learning with Rectification Strategy for Human Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2004.08055\"\n  }, \"https://arxiv.org/abs/2004.08055\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Correlating Edge, Pose with Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2005.01431\"\n  }, \"https://arxiv.org/abs/2005.01431\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ziwei-zh/CorrPM\"\n  }, \"https://github.com/ziwei-zh/CorrPM\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Affinity-aware Compression and Expansion Network for Human Parsing\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2008.10191\"\n  }, \"https://arxiv.org/abs/2008.10191\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Renovating Parsing R-CNN for Accurate Multiple Human Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BUPT & Noah\\u2019s Ark Lab, Huawei Technologies\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2009.09447\"\n  }, \"https://arxiv.org/abs/2009.09447\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/soeaver/RP-R-CNN\"\n  }, \"https://github.com/soeaver/RP-R-CNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Progressive One-shot Human Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.11810\"\n  }, \"https://arxiv.org/abs/2012.11810\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Charleshhy/One-shot-Human-Parsing\"\n  }, \"https://github.com/Charleshhy/One-shot-Human-Parsing\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Differentiable Multi-Granularity Human Representation Learning for Instance-Aware Human Semantic Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.04570\"\n  }, \"https://arxiv.org/abs/2103.04570\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/tfzhou/MG-HumanParsing\"\n  }, \"https://github.com/tfzhou/MG-HumanParsing\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Quality-Aware Network for Human Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BUPT & Institute of Automation Chinese Academy of Sciences & 3Noah\\u2019s Ark Lab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.05997\"\n  }, \"https://arxiv.org/abs/2103.05997\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(Pytorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/soeaver/QANet\"\n  }, \"https://github.com/soeaver/QANet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End-to-end One-shot Human Parsing\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2105.01241\"\n  }, \"https://arxiv.org/abs/2105.01241\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CDGNet: Class Distribution Guided Network for Human Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Ajou University & Tiangong University & Incheon National University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2111.14173\"\n  }, \"https://arxiv.org/abs/2111.14173\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"AIParsing: Anchor-free Instance-level Human Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: IEEE Transactions on Image Processing (TIP)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2207.06854\"\n  }, \"https://arxiv.org/abs/2207.06854\"))), mdx(\"h1\", {\n    \"id\": \"joint-detection-and-segmentation\"\n  }, \"Joint Detection and Segmentation\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Triply Supervised Decoder Networks for Joint Detection and Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1809.09299\"\n  }, \"https://arxiv.org/abs/1809.09299\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"D2Det: Towards High Quality Object Detection and Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Cao_D2Det_Towards_High_Quality_Object_Detection_and_Instance_Segmentation_CVPR_2020_paper.pdf\"\n  }, \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Cao_D2Det_Towards_High_Quality_Object_Detection_and_Instance_Segmentation_CVPR_2020_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/JialeCao001/D2Det\"\n  }, \"https://github.com/JialeCao001/D2Det\"))), mdx(\"h1\", {\n    \"id\": \"video-object-segmentation\"\n  }, \"Video Object Segmentation\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast object segmentation in unconstrained video\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://calvin.inf.ed.ac.uk/software/fast-video-segmentation/\"\n  }, \"http://calvin.inf.ed.ac.uk/software/fast-video-segmentation/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://calvin.inf.ed.ac.uk/wp-content/uploads/Publications/papazoglouICCV2013-camera-ready.pdf\"\n  }, \"http://calvin.inf.ed.ac.uk/wp-content/uploads/Publications/papazoglouICCV2013-camera-ready.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Recurrent Fully Convolutional Networks for Video Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1606.00487\"\n  }, \"https://arxiv.org/abs/1606.00487\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Object Detection, Tracking, and Motion Segmentation for Object-level Video Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.03066\"\n  }, \"http://arxiv.org/abs/1608.03066\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Clockwork Convnets for Video Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2016 Workshops\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: evaluated on the Youtube-Objects, NYUD, and Cityscapes video datasets\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.03609\"\n  }, \"http://arxiv.org/abs/1608.03609\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/shelhamer/clockwork-fcn\"\n  }, \"https://github.com/shelhamer/clockwork-fcn\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"STFCN: Spatio-Temporal FCN for Semantic Video Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://arxiv.org/abs/1608.05971\"\n  }, \"http://arxiv.org/abs/1608.05971\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"One-Shot Video Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: OSVOS\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.vision.ee.ethz.ch/~cvlsegmentation/osvos/\"\n  }, \"http://www.vision.ee.ethz.ch/~cvlsegmentation/osvos/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.05198\"\n  }, \"https://arxiv.org/abs/1611.05198\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kmaninis/OSVOS-caffe\"\n  }, \"https://github.com/kmaninis/OSVOS-caffe\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/scaelles/OSVOS-TensorFlow\"\n  }, \"https://github.com/scaelles/OSVOS-TensorFlow\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/kmaninis/OSVOS-PyTorch\"\n  }, \"https://github.com/kmaninis/OSVOS-PyTorch\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DAVIS: Densely Annotated VIdeo Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://davischallenge.org/\"\n  }, \"http://davischallenge.org/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1704.00675\"\n  }, \"https://arxiv.org/abs/1704.00675\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video Object Segmentation Without Temporal Information\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.06031\"\n  }, \"https://arxiv.org/abs/1709.06031\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Convolutional Gated Recurrent Networks for Video Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1611.05435\"\n  }, \"https://arxiv.org/abs/1611.05435\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Video Object Segmentation from Static Images\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.02646\"\n  }, \"https://arxiv.org/abs/1612.02646\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Video Segmentation by Gated Recurrent Flow Propagation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.08871\"\n  }, \"https://arxiv.org/abs/1612.08871\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FusionSeg: Learning to combine motion and appearance for fully automatic segmention of generic objects in videos\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://vision.cs.utexas.edu/projects/fusionseg/\"\n  }, \"http://vision.cs.utexas.edu/projects/fusionseg/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1701.05384\"\n  }, \"https://arxiv.org/abs/1701.05384\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/suyogduttjain/fusionseg\"\n  }, \"https://github.com/suyogduttjain/fusionseg\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unsupervised learning from video to detect foreground objects in single images\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1703.10901\"\n  }, \"https://arxiv.org/abs/1703.10901\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantically-Guided Video Object Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1704.01926\"\n  }, \"https://arxiv.org/abs/1704.01926\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Video Object Segmentation with Visual Memory\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1704.05737\"\n  }, \"https://arxiv.org/abs/1704.05737\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Flow-free Video Object Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1706.09544\"\n  }, \"https://arxiv.org/abs/1706.09544\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Online Adaptation of Convolutional Neural Networks for Video Object Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1706.09364\"\n  }, \"https://arxiv.org/abs/1706.09364\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video Object Segmentation using Tracked Object Proposals\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR-2017 workshop, DAVIS-2017 Challenge\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.06545\"\n  }, \"https://arxiv.org/abs/1707.06545\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video Object Segmentation with Re-identification\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017 Workshop, DAVIS Challenge on Video Object Segmentation 2017 (Winning Entry)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.00197\"\n  }, \"https://arxiv.org/abs/1708.00197\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, PyTorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lxx1991/VS-ReID\"\n  }, \"https://github.com/lxx1991/VS-ReID\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pixel-Level Matching for Video Object Segmentation using Convolutional Neural Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1708.05137\"\n  }, \"https://arxiv.org/abs/1708.05137\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MaskRNN: Instance Level Video Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NIPS 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.11187\"\n  }, \"https://arxiv.org/abs/1803.11187\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SegFlow: Joint Learning for Video Object Segmentation and Optical Flow\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://sites.google.com/site/yihsuantsai/research/iccv17-segflow\"\n  }, \"https://sites.google.com/site/yihsuantsai/research/iccv17-segflow\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1709.06750\"\n  }, \"https://arxiv.org/abs/1709.06750\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/JingchunCheng/SegFlow\"\n  }, \"https://github.com/JingchunCheng/SegFlow\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video Semantic Object Segmentation by Self-Adaptation of DCNN\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1711.08180\"\n  }, \"https://arxiv.org/abs/1711.08180\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning to Segment Moving Objects\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1712.01127\"\n  }, \"https://arxiv.org/abs/1712.01127\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Instance Embedding Transfer to Unsupervised Video Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Southern California & Google Inc\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1801.00908\"\n  }, \"https://arxiv.org/abs/1801.00908\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/@barvinograd1/instance-embedding-instance-segmentation-without-proposals-31946a7c53e1\"\n  }, \"https://medium.com/@barvinograd1/instance-embedding-instance-segmentation-without-proposals-31946a7c53e1\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Efficient Video Object Segmentation via Network Modulation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Snap Inc. & Northwestern University & Google Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1802.01218\"\n  }, \"https://arxiv.org/abs/1802.01218\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video Object Segmentation with Joint Re-identification and Attention-Aware Mask Propagation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CUHK\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: DyeNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.04242\"\n  }, \"https://arxiv.org/abs/1803.04242\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video Object Segmentation with Language Referring Expressions\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.08006\"\n  }, \"https://arxiv.org/abs/1803.08006\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dynamic Video Segmentation Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: DVSNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.00931\"\n  }, \"https://arxiv.org/abs/1804.00931\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/XUSean0118/DVSNet\"\n  }, \"https://github.com/XUSean0118/DVSNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Low-Latency Video Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018 Spotlight\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.00389\"\n  }, \"https://arxiv.org/abs/1804.00389\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Blazingly Fast Video Object Segmentation with Pixel-Wise Metric Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1804.03131\"\n  }, \"https://arxiv.org/abs/1804.03131\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unsupervised Video Object Segmentation for Deep Reinforcement Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Waterloo\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.07780\"\n  }, \"https://arxiv.org/abs/1805.07780\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast and Accurate Online Video Object Segmentation via Tracking Parts\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1806.02323\"\n  }, \"https://arxiv.org/abs/1806.02323\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/JingchunCheng/FAVOS\"\n  }, \"https://github.com/JingchunCheng/FAVOS\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ReConvNet: Video Object Segmentation with Spatio-Temporal Features Modulation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR Workshop - DAVIS Challenge 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1806.05510\"\n  }, \"https://arxiv.org/abs/1806.05510\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Spatio-Temporal Random Fields for Efficient Video Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1807.03148\"\n  }, \"https://arxiv.org/abs/1807.03148\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast Video Object Segmentation by Reference-Guided Mask Propagation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/1029.pdf\"\n  }, \"http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/1029.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/seoungwugoh/RGMP\"\n  }, \"https://github.com/seoungwugoh/RGMP\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PReMVOS: Proposal-generation, Refinement and Merging for Video Object Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1807.09190\"\n  }, \"https://arxiv.org/abs/1807.09190\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"YouTube-VOS: Sequence-to-Sequence Video Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018. Adobe Research & Snapchat Research & UIUC\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page:\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://youtube-vos.org/\"\n  }, \"https://youtube-vos.org/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1809.00461\"\n  }, \"https://arxiv.org/abs/1809.00461\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"VideoMatch: Matching based Video Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1809.01123\"\n  }, \"https://arxiv.org/abs/1809.01123\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mask Propagation Network for Video Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ByteDance AI Lab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1810.10289\"\n  }, \"https://arxiv.org/abs/1810.10289\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Tukey-Inspired Video Object Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.07958\"\n  }, \"https://arxiv.org/abs/1811.07958\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Generative Appearance Model for End-to-end Video Object Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1811.11611\"\n  }, \"https://arxiv.org/abs/1811.11611\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Unseen Object Segmentation in Videos via Transferable Representations\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACCV 2018 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1901.02444\"\n  }, \"https://arxiv.org/abs/1901.02444\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/wenz116/TransferSeg\"\n  }, \"https://github.com/wenz116/TransferSeg\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FEELVOS: Fast End-to-End Embedding Learning for Video Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: RWTH Aachen University & Google Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1902.09513\"\n  }, \"https://arxiv.org/abs/1902.09513\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RVOS: End-to-End Recurrent Network for Video Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://imatge-upc.github.io/rvos/\"\n  }, \"https://imatge-upc.github.io/rvos/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.05612\"\n  }, \"https://arxiv.org/abs/1903.05612\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BubbleNets: Learning to Select the Guidance Frame in Video Object Segmentation by Deep Sorting Frames\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Michigan\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1903.11779\"\n  }, \"https://arxiv.org/abs/1903.11779\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/griffbr/BubbleNets\"\n  }, \"https://github.com/griffbr/BubbleNets\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"video: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=0kNmm8SBnnU&feature=youtu.be\"\n  }, \"https://www.youtube.com/watch?v=0kNmm8SBnnU&feature=youtu.be\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast video object segmentation with Spatio-Temporal GANs\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1903.12161\"\n  }, \"https://arxiv.org/abs/1903.12161\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video Object Segmentation using Space-Time Memory Networks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Yonsei University & Adobe Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.00607\"\n  }, \"https://arxiv.org/abs/1904.00607\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/seoungwugoh/STM\"\n  }, \"https://github.com/seoungwugoh/STM\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spatiotemporal CNN for Video Object Segmentation\")), mdx(\"p\", null, \"[https://arxiv.org/abs/1904.02363]\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Architecture Search of Dynamic Cells for Semantic Video Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1904.02371\"\n  }, \"https://arxiv.org/abs/1904.02371\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"BoLTVOS: Box-Level Tracking for Video Object Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1904.04552\"\n  }, \"https://arxiv.org/abs/1904.04552\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MAIN: Multi-Attention Instance Network for Video Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1904.05847\"\n  }, \"https://arxiv.org/abs/1904.05847\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MHP-VOS: Multiple Hypotheses Propagation for Video Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019 oral\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.08141\"\n  }, \"https://arxiv.org/abs/1904.08141\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ByteDance AI Lab & UIUC & Adobe Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: MaskTrack R-CNN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1905.04804\"\n  }, \"https://arxiv.org/abs/1905.04804\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/youtubevos/MaskTrackRCNN\"\n  }, \"https://github.com/youtubevos/MaskTrackRCNN\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"OVSNet : Towards One-Pass Real-Time Video Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Zhejiang University & SenseTime Research & Tianjin University]\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1905.10064\"\n  }, \"https://arxiv.org/abs/1905.10064\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Proposal, Tracking and Segmentation (PTS): A Cascaded Network for Video Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Huazhong University of Science and Technology & Horizon Robotics\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1907.01203\"\n  }, \"https://arxiv.org/abs/1907.01203\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/sydney0zq/PTSNet\"\n  }, \"https://github.com/sydney0zq/PTSNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"RANet: Ranking Attention Network for Fast Video Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1908.06647\"\n  }, \"https://arxiv.org/abs/1908.06647\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Storife/RANet\"\n  }, \"https://github.com/Storife/RANet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DMM-Net: Differentiable Mask-Matching Network for Video Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.12471\"\n  }, \"https://arxiv.org/abs/1909.12471\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"CapsuleVOS: Semi-Supervised Video Object Segmentation Using Capsule Routing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1910.00132\"\n  }, \"https://arxiv.org/abs/1910.00132\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Towards Good Practices for Video Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ByteDance AI Lab\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1909.13583\"\n  }, \"https://arxiv.org/abs/1909.13583\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Anchor Diffusion for Unsupervised Video Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1910.10895\"\n  }, \"https://arxiv.org/abs/1910.10895\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning a Spatio-Temporal Embedding for Video Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Cambridge\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1912.08969\"\n  }, \"https://arxiv.org/abs/1912.08969\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Efficient Semantic Video Segmentation with Per-frame Inference\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The University of Adelaide & Huazhong University of Science and Technology & Microsoft Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2002.11433\"\n  }, \"https://arxiv.org/abs/2002.11433\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/irfanICMLL/ETC-Real-time-Per-frame-Semantic-video-segmentation\"\n  }, \"https://github.com/irfanICMLL/ETC-Real-time-Per-frame-Semantic-video-segmentation\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"State-Aware Tracker for Real-Time Video Object Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.00482\"\n  }, \"https://arxiv.org/abs/2003.00482\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MegviiDetection/video_analyst\"\n  }, \"https://github.com/MegviiDetection/video_analyst\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video Object Segmentation with Adaptive Feature Bank and Uncertain-Region Refinement\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: NeurIPS 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2010.07958\"\n  }, \"https://arxiv.org/abs/2010.07958\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SwiftNet: Real-time Video Object Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2102.04604\"\n  }, \"https://arxiv.org/abs/2102.04604\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SG-Net: Spatial Granularity Network for One-Stage Video Instance Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2103.10284\"\n  }, \"https://arxiv.org/abs/2103.10284\")), mdx(\"h2\", {\n    \"id\": \"challenge\"\n  }, \"Challenge\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DAVIS Challenge on Video Object Segmentation 2017\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://davischallenge.org/challenge2017/publications.html\"\n  }, \"http://davischallenge.org/challenge2017/publications.html\")), mdx(\"h1\", {\n    \"id\": \"matting\"\n  }, \"Matting\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Image Matting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Beckman Institute for Advanced Science and Technology & Adobe Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://sites.google.com/view/deepimagematting\"\n  }, \"https://sites.google.com/view/deepimagematting\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.03872\"\n  }, \"https://arxiv.org/abs/1703.03872\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(unofficial): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/open-mmlab/mmediting/tree/master/configs/mattors/dim\"\n  }, \"https://github.com/open-mmlab/mmediting/tree/master/configs/mattors/dim\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(unofficial): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/foamliu/Deep-Image-Matting\"\n  }, \"https://github.com/foamliu/Deep-Image-Matting\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(unofficial): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/foamliu/Deep-Image-Matting-PyTorch\"\n  }, \"https://github.com/foamliu/Deep-Image-Matting-PyTorch\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(unofficial): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/huochaitiantang/pytorch-deep-image-matting\"\n  }, \"https://github.com/huochaitiantang/pytorch-deep-image-matting\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fast Deep Matting for Portrait Animation on Mobile Phone\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM Multimedia Conference (MM) 2017\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: does not need any interaction and can realize real-time matting with 15 fps\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1707.08289\"\n  }, \"https://arxiv.org/abs/1707.08289\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Real-time deep hair matting on mobile devices\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ModiFace Inc, University of Toronto\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1712.07168\"\n  }, \"https://arxiv.org/abs/1712.07168\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TOM-Net: Learning Transparent Object Matting from a Single Image\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://gychen.org/TOM-Net/\"\n  }, \"http://gychen.org/TOM-Net/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.04636\"\n  }, \"https://arxiv.org/abs/1803.04636\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/guanyingc/TOM-Net\"\n  }, \"https://github.com/guanyingc/TOM-Net\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Video Portraits\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: SIGGRAPH 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.11714\"\n  }, \"https://arxiv.org/abs/1805.11714\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"youtube: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=qc5P2bvfl44\"\n  }, \"https://www.youtube.com/watch?v=qc5P2bvfl44\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Inductive Guided Filter: Real-time Deep Image Matting with Weakly Annotated Masks on Mobile Devices\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Shanghai Jiao Tong University & Versa\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1905.06747\"\n  }, \"https://arxiv.org/abs/1905.06747\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Indices Matter: Learning to Index for Deep Image Matting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1908.00672\"\n  }, \"https://arxiv.org/abs/1908.00672\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/poppinace/indexnet_matting\"\n  }, \"https://github.com/poppinace/indexnet_matting\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/open-mmlab/mmediting/tree/master/configs/mattors/indexnet\"\n  }, \"https://github.com/open-mmlab/mmediting/tree/master/configs/mattors/indexnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Disentangled Image Matting\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1909.04686\"\n  }, \"https://arxiv.org/abs/1909.04686\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Natural Image Matting via Guided Contextual Attention\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: AAAI 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2001.04069\"\n  }, \"https://arxiv.org/abs/2001.04069\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Yaoyi-Li/GCA-Matting\"\n  }, \"https://github.com/Yaoyi-Li/GCA-Matting\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"F, B, Alpha Matting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.07711\"\n  }, \"https://arxiv.org/abs/2003.07711\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MarcoForte/FBA_Matting\"\n  }, \"https://github.com/MarcoForte/FBA_Matting\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Background Matting: The World is Your Green Screen\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: University of Washington\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://grail.cs.washington.edu/projects/background-matting/\"\n  }, \"https://grail.cs.washington.edu/projects/background-matting/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2004.00626\"\n  }, \"https://arxiv.org/abs/2004.00626\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/senguptaumd/Background-Matting\"\n  }, \"https://github.com/senguptaumd/Background-Matting\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://towardsdatascience.com/background-matting-the-world-is-your-green-screen-83a3c4f0f635\"\n  }, \"https://towardsdatascience.com/background-matting-the-world-is-your-green-screen-83a3c4f0f635\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hierarchical Opacity Propagation for Image Matting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Shanghai Jiao Tong University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2004.03249\"\n  }, \"https://arxiv.org/abs/2004.03249\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Yaoyi-Li/HOP-Matting\"\n  }, \"https://github.com/Yaoyi-Li/HOP-Matting\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"High-Resolution Deep Image Matting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: UIUC & Adobe Research & University of Oregon\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2009.06613\"\n  }, \"https://arxiv.org/abs/2009.06613\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Learning Affinity-Aware Upsampling for Deep Image Matting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The University of Adelaide & Huazhong University of Science and Technology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.14288\"\n  }, \"https://arxiv.org/abs/2011.14288\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Real-Time High-Resolution Background Matting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://grail.cs.washington.edu/projects/background-matting-v2/\"\n  }, \"https://grail.cs.washington.edu/projects/background-matting-v2/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.07810\"\n  }, \"https://arxiv.org/abs/2012.07810\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/PeterL1n/BackgroundMattingV2\"\n  }, \"https://github.com/PeterL1n/BackgroundMattingV2\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Video Matting via Spatio-Temporal Alignment and Aggregation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.11208\"\n  }, \"https://arxiv.org/abs/2104.11208\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/nowsyn/DVM\"\n  }, \"https://github.com/nowsyn/DVM\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Trimap-guided Feature Mining and Fusion Network for Natural Image Matting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Shanghai Jiao Tong University & ByteDance Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2112.00510\"\n  }, \"https://arxiv.org/abs/2112.00510\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Boosting Robustness of Image Matting with Context Assembling and Strong Data Augmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The University of Adelaide & Adobe Inc. & Zhejiang University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2201.06889\"\n  }, \"https://arxiv.org/abs/2201.06889\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"MatteFormer: Transformer-Based Image Matting via Prior-Tokens\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Seoul National University & NAVER WEBTOON AI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2203.15662\"\n  }, \"https://arxiv.org/abs/2203.15662\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Referring Image Matting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The University of Sydney & JD Explore Academy\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2206.05149\"\n  }, \"https://arxiv.org/abs/2206.05149\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/JizhiziLi/RIM\"\n  }, \"https://github.com/JizhiziLi/RIM\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"One-Trimap Video Matting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ECCV 2022\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2207.13353\"\n  }, \"https://arxiv.org/abs/2207.13353\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Hongje/OTVM\"\n  }, \"https://github.com/Hongje/OTVM\"))), mdx(\"h2\", {\n    \"id\": \"trimap-free-matting\"\n  }, \"trimap-free matting\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Human Matting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ACM Multimedia 2018\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1809.01354\"\n  }, \"https://arxiv.org/abs/1809.01354\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(unofficial): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/lizhengwei1992/Semantic_Human_Matting\"\n  }, \"https://github.com/lizhengwei1992/Semantic_Human_Matting\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Instance Segmentation based Semantic Matting for Compositing Applications\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CRV 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.05457\"\n  }, \"https://arxiv.org/abs/1904.05457\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Late Fusion CNN for Digital Matting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2019\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Zhejiang University & Alibaba Group & University of Texas at Austin\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_A_Late_Fusion_CNN_for_Digital_Matting_CVPR_2019_paper.pdf\"\n  }, \"https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_A_Late_Fusion_CNN_for_Digital_Matting_CVPR_2019_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(official, Keras): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yunkezhang/FusionMatting\"\n  }, \"https://github.com/yunkezhang/FusionMatting\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Attention-Guided Hierarchical Structure Aggregation for Image Matting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://wukaoliu.github.io/HAttMatting/\"\n  }, \"https://wukaoliu.github.io/HAttMatting/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"paper: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Qiao_Attention-Guided_Hierarchical_Structure_Aggregation_for_Image_Matting_CVPR_2020_paper.pdf\"\n  }, \"https://openaccess.thecvf.com/content_CVPR_2020/papers/Qiao_Attention-Guided_Hierarchical_Structure_Aggregation_for_Image_Matting_CVPR_2020_paper.pdf\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/wukaoliu/CVPR2020-HAttMatting\"\n  }, \"https://github.com/wukaoliu/CVPR2020-HAttMatting\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Boosting Semantic Human Matting with Coarse Annotations\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Alibaba Group & Tsinghua University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2004.04955\"\n  }, \"https://arxiv.org/abs/2004.04955\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"End-to-end Animal Image Matting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: Glance and Focus Matting network (GFM), AM-2k dataset, BG-20k dataset\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2010.16188\"\n  }, \"https://arxiv.org/abs/2010.16188\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/JizhiziLi/animal-matting/\"\n  }, \"https://github.com/JizhiziLi/animal-matting/\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Is a Green Screen Really Necessary for Real-Time Human Matting?\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: City University of Hong Kong & SenseTime Research\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2011.11961\"\n  }, \"https://arxiv.org/abs/2011.11961\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ZHKKKe/MODNet\"\n  }, \"https://github.com/ZHKKKe/MODNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-scale Information Assembly for Image Matting\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2101.02391\"\n  }, \"https://arxiv.org/abs/2101.02391\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Salient Image Matting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Fynd & University of Michigan\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2103.12337\"\n  }, \"https://arxiv.org/abs/2103.12337\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mask Guided Matting via Progressive Refinement Network\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The Johns Hopkins University & Adobe\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2012.06722\"\n  }, \"https://arxiv.org/abs/2012.06722\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/yucornetto/MGMatting\"\n  }, \"https://github.com/yucornetto/MGMatting\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Privacy-Preserving Portrait Matting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: The University of Sydney & JD Explore Academy\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.14222\"\n  }, \"https://arxiv.org/abs/2104.14222\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/SHI-Labs/Pseudo-IoU-for-Anchor-Free-Object-Detection\"\n  }, \"https://github.com/SHI-Labs/Pseudo-IoU-for-Anchor-Free-Object-Detection\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Highly Efficient Natural Image Matting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: BMVC 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2110.12748\"\n  }, \"https://arxiv.org/abs/2110.12748\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PP-HumanSeg: Connectivity-Aware Portrait Segmentation with a Large-Scale Teleconferencing Video Dataset\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: WACV 2021 workshop\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Baidu, Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2112.07146\"\n  }, \"https://arxiv.org/abs/2112.07146\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/PaddlePaddle/PaddleSeg\"\n  }, \"https://github.com/PaddlePaddle/PaddleSeg\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Situational Perception Guided Image Matting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: OPPO Research Institute & PicUp.AI & Xmotors\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2204.09276\"\n  }, \"https://arxiv.org/abs/2204.09276\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PP-Matting: High-Accuracy Natural Image Matting\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Baidu Inc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arixv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2204.09433\"\n  }, \"https://arxiv.org/abs/2204.09433\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/PaddlePaddle/PaddleSeg\"\n  }, \"https://github.com/PaddlePaddle/PaddleSeg\"))), mdx(\"h1\", {\n    \"id\": \"3d-segmentation\"\n  }, \"3D Segmentation\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Stanford University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://stanford.edu/~rqi/pointnet/\"\n  }, \"http://stanford.edu/~rqi/pointnet/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1612.00593\"\n  }, \"https://arxiv.org/abs/1612.00593\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/charlesq34/pointnet\"\n  }, \"https://github.com/charlesq34/pointnet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"DA-RNN: Semantic Mapping with Data Associated Recurrent Neural Networks\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1703.03098\"\n  }, \"https://arxiv.org/abs/1703.03098\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SqueezeSeg: Convolutional Neural Nets with Recurrent CRF for Real-Time Road-Object Segmentation from 3D LiDAR Point Cloud\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: UC Berkeley\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1710.07368\"\n  }, \"https://arxiv.org/abs/1710.07368\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SEGCloud: Semantic Segmentation of 3D Point Clouds\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: International Conference of 3D Vision (3DV) 2017 (Spotlight). Stanford University\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"homepage: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://segcloud.stanford.edu/\"\n  }, \"http://segcloud.stanford.edu/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1710.07563\"\n  }, \"https://arxiv.org/abs/1710.07563\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"3D Instance Segmentation via Multi-task Metric Learning\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: KAUST & ETH Zurich\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1906.08650\"\n  }, \"https://arxiv.org/abs/1906.08650\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"3D-MPA: Multi Proposal Aggregation for 3D Semantic Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: RWTH Aachen University & Google & Technical University Munich\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.vision.rwth-aachen.de/publication/00199/\"\n  }, \"https://www.vision.rwth-aachen.de/publication/00199/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2003.13867\"\n  }, \"https://arxiv.org/abs/2003.13867\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PointGroup: Dual-Set Point Grouping for 3D Instance Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: CVPR 2020\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2004.01658\"\n  }, \"https://arxiv.org/abs/2004.01658\"))), mdx(\"h1\", {\n    \"id\": \"line-parsing\"\n  }, \"Line Parsing\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fully Convolutional Line Parsing\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: ICCV 2021\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: UESTC & UC Berkeley\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"arxiv: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2104.11207\"\n  }, \"https://arxiv.org/abs/2104.11207\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github(PyTorch): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/Delay-Xili/F-Clip\"\n  }, \"https://github.com/Delay-Xili/F-Clip\"))), mdx(\"h1\", {\n    \"id\": \"projects\"\n  }, \"Projects\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TF Image Segmentation: Image Segmentation framework\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Image Segmentation framework based on Tensorflow and TF-Slim library\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/warmspringwinds/tf-image-segmentation\"\n  }, \"https://github.com/warmspringwinds/tf-image-segmentation\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"KittiSeg: A Kitti Road Segmentation model implemented in tensorflow.\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"keywords: MultiNet\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: KittiSeg performs segmentation of roads by utilizing an FCN based model.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/MarvinTeichmann/KittiBox\"\n  }, \"https://github.com/MarvinTeichmann/KittiBox\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Semantic Segmentation Architectures Implemented in PyTorch\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: Segnet/FCN/U-Net/Link-Net\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/meetshah1995/pytorch-semseg\"\n  }, \"https://github.com/meetshah1995/pytorch-semseg\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"PyTorch for Semantic Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/ZijunDeng/pytorch-semantic-segmentation\"\n  }, \"https://github.com/ZijunDeng/pytorch-semantic-segmentation\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"LightNet: Light-weight Networks for Semantic Image Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://ansleliu.github.io/LightNet.html\"\n  }, \"https://ansleliu.github.io/LightNet.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ansleliu/LightNet\"\n  }, \"https://github.com/ansleliu/LightNet\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"LightNet++: Boosted Light-weighted Networks for Real-time Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"project page: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://ansleliu.github.io/LightNet.html\"\n  }, \"https://ansleliu.github.io/LightNet.html\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/ansleliu/LightNetPlusPlus\"\n  }, \"https://github.com/ansleliu/LightNetPlusPlus\"))), mdx(\"h1\", {\n    \"id\": \"leaderboard\"\n  }, \"Leaderboard\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Segmentation Results: VOC2012 BETA: Competition \\\"comp6\\\" (train on own data)\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?cls=mean&challengeid=11&compid=6\"\n  }, \"http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?cls=mean&challengeid=11&compid=6\")), mdx(\"h1\", {\n    \"id\": \"blogs\"\n  }, \"Blogs\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Mobile Real-time Video Segmentation\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://research.googleblog.com/2018/03/mobile-real-time-video-segmentation.html\"\n  }, \"https://research.googleblog.com/2018/03/mobile-real-time-video-segmentation.html\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep Learning for Natural Image Segmentation Priors\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://cs.brown.edu/courses/csci2951-t/finals/ghope/\"\n  }, \"http://cs.brown.edu/courses/csci2951-t/finals/ghope/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Image Segmentation Using DIGITS 5\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://devblogs.nvidia.com/parallelforall/image-segmentation-using-digits-5/\"\n  }, \"https://devblogs.nvidia.com/parallelforall/image-segmentation-using-digits-5/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Image Segmentation with Tensorflow using CNNs and Conditional Random Fields\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/18/image-segmentation-with-tensorflow-using-cnns-and-conditional-random-fields/\"\n  }, \"http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/18/image-segmentation-with-tensorflow-using-cnns-and-conditional-random-fields/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Fully Convolutional Networks (FCNs) for Image Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://warmspringwinds.github.io/tensorflow/tf-slim/2017/01/23/fully-convolutional-networks-(fcns)-for-image-segmentation/\"\n  }, \"http://warmspringwinds.github.io/tensorflow/tf-slim/2017/01/23/fully-convolutional-networks-(fcns)-for-image-segmentation/\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"ipn: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/warmspringwinds/tensorflow_notes/blob/master/fully_convolutional_networks.ipynb\"\n  }, \"https://github.com/warmspringwinds/tensorflow_notes/blob/master/fully_convolutional_networks.ipynb\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Image segmentation with Neural Net\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"blog: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/@m.zaradzki/image-segmentation-with-neural-net-d5094d571b1e#.s5f711g1q\"\n  }, \"https://medium.com/@m.zaradzki/image-segmentation-with-neural-net-d5094d571b1e#.s5f711g1q\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"github: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/mzaradzki/neuralnets/tree/master/vgg_segmentation_keras\"\n  }, \"https://github.com/mzaradzki/neuralnets/tree/master/vgg_segmentation_keras\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A 2017 Guide to Semantic Segmentation with Deep Learning\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review\"\n  }, \"http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review\")), mdx(\"h1\", {\n    \"id\": \"tutorails--talks\"\n  }, \"Tutorails / Talks\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A Unified Architecture for Instance and Semantic Segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: FPN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"slides: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://presentations.cocodataset.org/COCO17-Stuff-FAIR.pdf\"\n  }, \"http://presentations.cocodataset.org/COCO17-Stuff-FAIR.pdf\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deep learning for image segmentation\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intro: PyData Warsaw - Mateusz Opala & Micha\\u0142 Jamro\\u017C\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"youtube: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.youtube.com/watch?v=W6r_a5crqGI\"\n  }, \"https://www.youtube.com/watch?v=W6r_a5crqGI\"))));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"---\nlayout: post\ncategory: deep_learning\ntitle: Segmentation\ndate: 2015-10-09\n---\n\n# Papers\n\n**Deep Joint Task Learning for Generic Object Extraction**\n\n- intro: NIPS 2014\n- homepage: [http://vision.sysu.edu.cn/projects/deep-joint-task-learning/](http://vision.sysu.edu.cn/projects/deep-joint-task-learning/)\n- paper: [http://ss.sysu.edu.cn/~ll/files/NIPS2014_JointTask.pdf](http://ss.sysu.edu.cn/~ll/files/NIPS2014_JointTask.pdf)\n- github: [https://github.com/xiaolonw/nips14_loc_seg_testonly](https://github.com/xiaolonw/nips14_loc_seg_testonly)\n- dataset: [http://objectextraction.github.io/](http://objectextraction.github.io/)\n\n**Highly Efficient Forward and Backward Propagation of Convolutional Neural Networks for Pixelwise Classification**\n\n- arxiv: [https://arxiv.org/abs/1412.4526](https://arxiv.org/abs/1412.4526)\n- code(Caffe): [https://dl.dropboxusercontent.com/u/6448899/caffe.zip](https://dl.dropboxusercontent.com/u/6448899/caffe.zip)\n- author page: [http://www.ee.cuhk.edu.hk/~hsli/](http://www.ee.cuhk.edu.hk/~hsli/)\n\n**Segmentation from Natural Language Expressions**\n\n- intro: ECCV 2016\n- project page: [http://ronghanghu.com/text_objseg/](http://ronghanghu.com/text_objseg/)\n- arxiv: [http://arxiv.org/abs/1603.06180](http://arxiv.org/abs/1603.06180)\n- github(TensorFlow): [https://github.com/ronghanghu/text_objseg](https://github.com/ronghanghu/text_objseg)\n- gtihub(Caffe): [https://github.com/Seth-Park/text_objseg_caffe](https://github.com/Seth-Park/text_objseg_caffe)\n\n**Semantic Object Parsing with Graph LSTM**\n\n- arxiv: [http://arxiv.org/abs/1603.07063](http://arxiv.org/abs/1603.07063)\n\n**Fine Hand Segmentation using Convolutional Neural Networks**\n\n- arxiv: [http://arxiv.org/abs/1608.07454](http://arxiv.org/abs/1608.07454)\n\n**Feedback Neural Network for Weakly Supervised Geo-Semantic Segmentation**\n\n- intro: Facebook Connectivity Lab & Facebook Core Data Science & University of Illinois\n- arxiv: [https://arxiv.org/abs/1612.02766](https://arxiv.org/abs/1612.02766)\n\n**FusionNet: A deep fully residual convolutional neural network for image segmentation in connectomics**\n\n- arxiv: [https://arxiv.org/abs/1612.05360](https://arxiv.org/abs/1612.05360)\n\n**A deep learning model integrating FCNNs and CRFs for brain tumor segmentation**\n\n- arxiv: [https://arxiv.org/abs/1702.04528](https://arxiv.org/abs/1702.04528)\n\n**Texture segmentation with Fully Convolutional Networks**\n\n- intro: Dublin City University\n- arxiv: [https://arxiv.org/abs/1703.05230](https://arxiv.org/abs/1703.05230)\n\n**Fast LIDAR-based Road Detection Using Convolutional Neural Networks**\n\n[https://arxiv.org/abs/1703.03613](https://arxiv.org/abs/1703.03613)\n\n**Deep Value Networks Learn to Evaluate and Iteratively Refine Structured Outputs**\n\n- arxiv: [https://arxiv.org/abs/1703.04363](https://arxiv.org/abs/1703.04363)\n- demo: [https://gyglim.github.io/deep-value-net/](https://gyglim.github.io/deep-value-net/)\n\n**Annotating Object Instances with a Polygon-RNN**\n\n- intro: CVPR 2017. CVPR Best Paper Honorable Mention Award\n- intro: University of Toronto\n- keywords: PolygonRNN\n- project page: [http://www.cs.toronto.edu/polyrnn/](http://www.cs.toronto.edu/polyrnn/)\n- arxiv: [https://arxiv.org/abs/1704.05548](https://arxiv.org/abs/1704.05548)\n\n**Efficient Interactive Annotation of Segmentation Datasets with Polygon-RNN++**\n\n- intro: CVPR 2018\n- keywords: PolygonRNN++\n- project page: [http://www.cs.toronto.edu/polyrnn/](http://www.cs.toronto.edu/polyrnn/)\n- arxiv: [https://arxiv.org/abs/1803.09693](https://arxiv.org/abs/1803.09693)\n- github: [https://github.com/davidjesusacu/polyrnn-pp](https://github.com/davidjesusacu/polyrnn-pp)\n\n**Semantic Segmentation via Structured Patch Prediction, Context CRF and Guidance CRF**\n\n- intro: CVPR 2017\n- paper: [http://openaccess.thecvf.com/content_cvpr_2017/papers/Shen_Semantic_Segmentation_via_CVPR_2017_paper.pdf](http://openaccess.thecvf.com/content_cvpr_2017/papers/Shen_Semantic_Segmentation_via_CVPR_2017_paper.pdf)\n- github(Caffe): [https://github.com//FalongShen/SegModel](https://github.com//FalongShen/SegModel)\n\n**Distantly Supervised Road Segmentation**\n\n- intro: ICCV workshop CVRSUAD2017. Indiana University & Preferred Networks\n- arxiv: [https://arxiv.org/abs/1708.06118](https://arxiv.org/abs/1708.06118)\n\n**-Net: Fully Automatic, Multi-View Cardiac MR Detection, Orientation, and Segmentation with Deep Neural Networks**\n\n**-Net (Omega-Net): Fully Automatic, Multi-View Cardiac MR Detection, Orientation, and Segmentation with Deep Neural Networks**\n\n[https://arxiv.org/abs/1711.01094](https://arxiv.org/abs/1711.01094)\n\n**Superpixel clustering with deep features for unsupervised road segmentation**\n\n- intro: Preferred Networks, Inc & Indiana University\n- arxiv: [https://arxiv.org/abs/1711.05998](https://arxiv.org/abs/1711.05998)\n\n**Learning to Segment Human by Watching YouTube**\n\n- intro: TPAMI 2017\n- arxiv: [https://arxiv.org/abs/1710.01457](https://arxiv.org/abs/1710.01457)\n\n**W-Net: A Deep Model for Fully Unsupervised Image Segmentation**\n\n[https://arxiv.org/abs/1711.08506](https://arxiv.org/abs/1711.08506)\n\n**End-to-end detection-segmentation network with ROI convolution**\n\n- intro: ISBI 2018\n- arxiv: [https://arxiv.org/abs/1801.02722](https://arxiv.org/abs/1801.02722)\n\n**A Foreground Inference Network for Video Surveillance Using Multi-View Receptive Field**\n\n[https://arxiv.org/abs/1801.06593](https://arxiv.org/abs/1801.06593)\n\n**Piecewise Flat Embedding for Image Segmentation**\n\n[https://arxiv.org/abs/1802.03248](https://arxiv.org/abs/1802.03248)\n\n**A Pyramid CNN for Dense-Leaves Segmentation**\n\n- intro: Computer and Robot Vision, Toronto, May 2018\n- arxiv: [https://arxiv.org/abs/1804.01646](https://arxiv.org/abs/1804.01646)\n\n**Capsules for Object Segmentation**\n\n- keywords: convolutional-deconvolutional capsule network, SegCaps, U-Net\n- arxiv: [https://arxiv.org/abs/1804.04241](https://arxiv.org/abs/1804.04241)\n\n**Deep Object Co-Segmentation**\n\n[https://arxiv.org/abs/1804.06423](https://arxiv.org/abs/1804.06423)\n\n**Semantic Aware Attention Based Deep Object Co-segmentation**\n\n[https://arxiv.org/abs/1810.06859](https://arxiv.org/abs/1810.06859)\n\n**Contextual Hourglass Networks for Segmentation and Density Estimation**\n\n[https://arxiv.org/abs/1806.04009](https://arxiv.org/abs/1806.04009)\n\n## U-Net\n\n**U-Net: Convolutional Networks for Biomedical Image Segmentation**\n\n- intro: conditionally accepted at MICCAI 2015\n- project page: [http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/](http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)\n- arxiv: [http://arxiv.org/abs/1505.04597](http://arxiv.org/abs/1505.04597)\n- code+data: [http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-release-2015-10-02.tar.gz](http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-release-2015-10-02.tar.gz)\n- github: [https://github.com/orobix/retina-unet](https://github.com/orobix/retina-unet)\n- github: [https://github.com/jakeret/tf_unet](https://github.com/jakeret/tf_unet)\n- notes: [http://zongwei.leanote.com/post/Pa](http://zongwei.leanote.com/post/Pa)\n\n**UNet++: A Nested U-Net Architecture for Medical Image Segmentation**\n\n- intro: 4th Deep Learning in Medical Image Analysis (DLMIA) Workshop\n- arxiv: [https://arxiv.org/abs/1807.10165](https://arxiv.org/abs/1807.10165)\n\n**UNet 3+: A Full-Scale Connected UNet for Medical Image Segmentation**\n\n- intro: ICASSP 2020\n- arxiv: [https://arxiv.org/abs/2004.08790](https://arxiv.org/abs/2004.08790)\n- github: [https://github.com/ZJUGiveLab/UNet-Version](https://github.com/ZJUGiveLab/UNet-Version)\n\n**DeepUNet: A Deep Fully Convolutional Network for Pixel-level Sea-Land Segmentation**\n\n[https://arxiv.org/abs/1709.00201](https://arxiv.org/abs/1709.00201)\n\n**TernausNet: U-Net with VGG11 Encoder Pre-Trained on ImageNet for Image Segmentation**\n\n- intro: Lyft Inc. & MIT\n- intro: part of the winning solution (1st out of 735) in the Kaggle: Carvana Image Masking Challenge\n- arxiv: [https://arxiv.org/abs/1801.05746](https://arxiv.org/abs/1801.05746)\n- github: [https://github.com/ternaus/TernausNet](https://github.com/ternaus/TernausNet)\n\n**A Probabilistic U-Net for Segmentation of Ambiguous Images**\n\n- intro: DeepMind & German Cancer Research Center\n- arxiv: [https://arxiv.org/abs/1806.05034](https://arxiv.org/abs/1806.05034)\n\n**Deep Dual Pyramid Network for Barcode Segmentation using Barcode-30k Database**\n\n[https://arxiv.org/abs/1807.11886](https://arxiv.org/abs/1807.11886)\n\n**Deep Smoke Segmentation**\n\n[https://arxiv.org/abs/1809.00774](https://arxiv.org/abs/1809.00774)\n\n**Smoothed Dilated Convolutions for Improved Dense Prediction**\n\n- intro: KDD 2018\n- arxiv: [https://arxiv.org/abs/1808.08931](https://arxiv.org/abs/1808.08931)\n- github: [https://github.com/divelab/dilated](https://github.com/divelab/dilated)\n\n**DASNet: Reducing Pixel-level Annotations for Instance and Semantic Segmentation**\n\n[https://arxiv.org/abs/1809.06013](https://arxiv.org/abs/1809.06013)\n\n**Improving Fast Segmentation With Teacher-student Learning**\n\n[https://arxiv.org/abs/1810.08476](https://arxiv.org/abs/1810.08476)\n\n**DSNet: An Efficient CNN for Road Scene Segmentation**\n\n[https://arxiv.org/abs/1904.05022](https://arxiv.org/abs/1904.05022)\n\n**Line Segment Detection Using Transformers without Edges**\n\n[https://arxiv.org/abs/2101.01909](https://arxiv.org/abs/2101.01909)\n\n# Unified Image Segmentation\n\n**K-Net: Towards Unified Image Segmentation**\n\n- intro: NeurIPS 2021\n- intro:  Nanyang Technological University &  Chinese University of Hong Kon & SenseTime Research & Shanghai AI Laborator\n- project page: [https://www.mmlab-ntu.com/project/knet/index.html](https://www.mmlab-ntu.com/project/knet/index.html)\n- arxiv: [https://arxiv.org/abs/2106.14855](https://arxiv.org/abs/2106.14855)\n- github: [https://github.com/ZwwWayne/K-Net/](https://github.com/ZwwWayne/K-Net/)\n\n**Masked-attention Mask Transformer for Universal Image Segmentation**\n\n- project page: [https://bowenc0221.github.io/mask2former/](https://bowenc0221.github.io/mask2former/)\n- arxiv: [https://arxiv.org/abs/2112.01527](https://arxiv.org/abs/2112.01527)\n- github: [https://github.com/facebookresearch/Mask2Former](https://github.com/facebookresearch/Mask2Former)\n\n**Mask2Former for Video Instance Segmentation**\n\n- intro: University of Illinois at Urbana-Champaign (UIUC) & Facebook AI Research (FAIR\n- arxiv: [https://arxiv.org/abs/2112.10764](https://arxiv.org/abs/2112.10764)\n- github: [https://github.com/facebookresearch/Mask2Former](https://github.com/facebookresearch/Mask2Former)\n\n# Foreground Object Segmentation\n\n**Pixel Objectness**\n\n- project page: [http://vision.cs.utexas.edu/projects/pixelobjectness/](http://vision.cs.utexas.edu/projects/pixelobjectness/)\n- arxiv: [https://arxiv.org/abs/1701.05349](https://arxiv.org/abs/1701.05349)\n- github: [https://github.com/suyogduttjain/pixelobjectness](https://github.com/suyogduttjain/pixelobjectness)\n\n**A Deep Convolutional Neural Network for Background Subtraction**\n\n- arxiv: [https://arxiv.org/abs/1702.01731](https://arxiv.org/abs/1702.01731)\n\n**Learning Multi-scale Features for Foreground Segmentation**\n\n- arxiv: [https://arxiv.org/abs/1808.01477](https://arxiv.org/abs/1808.01477)\n- github: [https://github.com/lim-anggun/FgSegNet_v2](https://github.com/lim-anggun/FgSegNet_v2)\n\n**Learning Deep Representations for Semantic Image Parsing: a Comprehensive Overview**\n\n[https://arxiv.org/abs/1810.04377](https://arxiv.org/abs/1810.04377)\n\n# Semantic Segmentation\n\n**Fully Convolutional Networks for Semantic Segmentation**\n\n- intro: CVPR 2015, PAMI 2016\n- keywords: deconvolutional layer, crop layer\n- arxiv: [http://arxiv.org/abs/1411.4038](http://arxiv.org/abs/1411.4038)\n- arxiv(PAMI 2016): [http://arxiv.org/abs/1605.06211](http://arxiv.org/abs/1605.06211)\n- slides: [https://docs.google.com/presentation/d/1VeWFMpZ8XN7OC3URZP4WdXvOGYckoFWGVN7hApoXVnc](https://docs.google.com/presentation/d/1VeWFMpZ8XN7OC3URZP4WdXvOGYckoFWGVN7hApoXVnc)\n- slides: [http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-pixels.pdf](http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-pixels.pdf)\n- talk: [http://techtalks.tv/talks/fully-convolutional-networks-for-semantic-segmentation/61606/](http://techtalks.tv/talks/fully-convolutional-networks-for-semantic-segmentation/61606/)\n- github(official): [https://github.com/shelhamer/fcn.berkeleyvision.org](https://github.com/shelhamer/fcn.berkeleyvision.org)\n- github: [https://github.com/BVLC/caffe/wiki/Model-Zoo#fcn](https://github.com/BVLC/caffe/wiki/Model-Zoo#fcn)\n- github: [https://github.com/MarvinTeichmann/tensorflow-fcn](https://github.com/MarvinTeichmann/tensorflow-fcn)\n- github(Chainer): [https://github.com/wkentaro/fcn](https://github.com/wkentaro/fcn)\n- github: [https://github.com/wkentaro/pytorch-fcn](https://github.com/wkentaro/pytorch-fcn)\n- github: [https://github.com/shekkizh/FCN.tensorflow](https://github.com/shekkizh/FCN.tensorflow)\n- notes: [http://zhangliliang.com/2014/11/28/paper-note-fcn-segment/](http://zhangliliang.com/2014/11/28/paper-note-fcn-segment/)\n\n**From Image-level to Pixel-level Labeling with Convolutional Networks**\n\n- intro: CVPR 2015\n- intro: \"Weakly Supervised Semantic Segmentation with Convolutional Networks\"\n- intro: performs semantic segmentation based only on image-level annotations in a multiple instance learning framework\n- arxiv: [http://arxiv.org/abs/1411.6228](http://arxiv.org/abs/1411.6228)\n- paper: [http://ronan.collobert.com/pub/matos/2015_semisupsemseg_cvpr.pdf](http://ronan.collobert.com/pub/matos/2015_semisupsemseg_cvpr.pdf)\n\n**Feedforward semantic segmentation with zoom-out features**\n\n- intro: CVPR 2015. Toyota Technological Institute at Chicago\n- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Mostajabi_Feedforward_Semantic_Segmentation_2015_CVPR_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Mostajabi_Feedforward_Semantic_Segmentation_2015_CVPR_paper.pdf)\n- bitbuckt: [https://bitbucket.org/m_mostajabi/zoom-out-release](https://bitbucket.org/m_mostajabi/zoom-out-release)\n- video: [https://www.youtube.com/watch?v=HvgvX1LXQa8](https://www.youtube.com/watch?v=HvgvX1LXQa8)\n\n## DeepLab\n\n**Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs**\n\n- intro: ICLR 2015. DeepLab\n- arxiv: [http://arxiv.org/abs/1412.7062](http://arxiv.org/abs/1412.7062)\n- bitbucket: [https://bitbucket.org/deeplab/deeplab-public/](https://bitbucket.org/deeplab/deeplab-public/)\n- github: [https://github.com/TheLegendAli/DeepLab-Context](https://github.com/TheLegendAli/DeepLab-Context)\n\n**Weakly- and Semi-Supervised Learning of a DCNN for Semantic Image Segmentation**\n\n- intro: DeepLab\n- arxiv: [http://arxiv.org/abs/1502.02734](http://arxiv.org/abs/1502.02734)\n- bitbucket: [https://bitbucket.org/deeplab/deeplab-public/](https://bitbucket.org/deeplab/deeplab-public/)\n- github: [https://github.com/TheLegendAli/DeepLab-Context](https://github.com/TheLegendAli/DeepLab-Context)\n\n## DeepLab v2\n\n**DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs**\n\n- intro: TPAMI\n- intro: 79.7% mIOU in the test set, PASCAL VOC-2012 semantic image segmentation task\n- intro: Updated version of our previous ICLR 2015 paper\n- project page: [http://liangchiehchen.com/projects/DeepLab.html](http://liangchiehchen.com/projects/DeepLab.html)\n- arxiv: [https://arxiv.org/abs/1606.00915](https://arxiv.org/abs/1606.00915)\n- bitbucket: [https://bitbucket.org/aquariusjay/deeplab-public-ver2](https://bitbucket.org/aquariusjay/deeplab-public-ver2)\n- github: [https://github.com/DrSleep/tensorflow-deeplab-resnet](https://github.com/DrSleep/tensorflow-deeplab-resnet)\n- github: [https://github.com/isht7/pytorch-deeplab-resnet](https://github.com/isht7/pytorch-deeplab-resnet)\n\n**DeepLabv2 (ResNet-101)**\n\n[http://liangchiehchen.com/projects/DeepLabv2_resnet.html](http://liangchiehchen.com/projects/DeepLabv2_resnet.html)\n\n## DeepLab v3\n\n**Rethinking Atrous Convolution for Semantic Image Segmentation**\n\n- intro: Google. DeepLabv3\n- arxiv: [https://arxiv.org/abs/1706.05587](https://arxiv.org/abs/1706.05587)\n\n## DeepLabv3+\n\n**Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation**\n\n- intro: Google Inc.\n- arxiv: [https://arxiv.org/abs/1802.02611](https://arxiv.org/abs/1802.02611)\n- github: [https://github.com/tensorflow/models/tree/master/research/deeplab](https://github.com/tensorflow/models/tree/master/research/deeplab)\n- blog: [https://research.googleblog.com/2018/03/semantic-image-segmentation-with.html](https://research.googleblog.com/2018/03/semantic-image-segmentation-with.html)\n- github: [https://github.com/hualin95/Deeplab-v3plus](https://github.com/hualin95/Deeplab-v3plus)\n\n## DeeperLab\n\n**DeeperLab: Single-Shot Image Parser**\n\n- intro: MIT & Google Inc. & UC Berkeley\n- arxiv: [https://arxiv.org/abs/1902.05093](https://arxiv.org/abs/1902.05093)\n\n## Auto-DeepLab\n\n**Auto-DeepLab: Hierarchical Neural Architecture Search for Semantic Image Segmentation**\n\n- intro: CVPR 2019 oral\n- intro: Johns Hopkins University & Google & Stanford University\n- arxiv: [https://arxiv.org/abs/1901.02985](https://arxiv.org/abs/1901.02985)\n- github: [https://github.com/tensorflow/models/tree/master/research/deeplab](https://github.com/tensorflow/models/tree/master/research/deeplab)\n\n- - -\n\n**Conditional Random Fields as Recurrent Neural Networks**\n\n- intro: ICCV 2015\n- intro: Oxford / Stanford / Baidu\n- keywords: CRF-RNN\n- project page: [http://www.robots.ox.ac.uk/~szheng/CRFasRNN.html](http://www.robots.ox.ac.uk/~szheng/CRFasRNN.html)\n- arxiv: [http://arxiv.org/abs/1502.03240](http://arxiv.org/abs/1502.03240)\n- github: [https://github.com/torrvision/crfasrnn](https://github.com/torrvision/crfasrnn)\n- demo: [http://www.robots.ox.ac.uk/~szheng/crfasrnndemo](http://www.robots.ox.ac.uk/~szheng/crfasrnndemo)\n- github: [https://github.com/martinkersner/train-CRF-RNN](https://github.com/martinkersner/train-CRF-RNN)\n\n**BoxSup: Exploiting Bounding Boxes to Supervise Convolutional Networks for Semantic Segmentation**\n\n- arxiv: [http://arxiv.org/abs/1503.01640](http://arxiv.org/abs/1503.01640)\n\n**Efficient piecewise training of deep structured models for semantic segmentation**\n\n- intro: CVPR 2016\n- arxiv: [http://arxiv.org/abs/1504.01013](http://arxiv.org/abs/1504.01013)\n\n**Learning Deconvolution Network for Semantic Segmentation**\n\n![](http://cvlab.postech.ac.kr/research/deconvnet/images/overall.png)\n\n- intro: ICCV 2015\n- intro: two-stage training: train the network with easy examples first and \nfine-tune the trained network with more challenging examples later\n- keywords: DeconvNet\n- project page: [http://cvlab.postech.ac.kr/research/deconvnet/](http://cvlab.postech.ac.kr/research/deconvnet/)\n- arxiv: [http://arxiv.org/abs/1505.04366](http://arxiv.org/abs/1505.04366)\n- slides: [http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2016/bil722/slides/w06-deconvnet.pdf](http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2016/bil722/slides/w06-deconvnet.pdf)\n- gitxiv: [http://gitxiv.com/posts/9tpJKNTYksN5eWcHz/learning-deconvolution-network-for-semantic-segmentation](http://gitxiv.com/posts/9tpJKNTYksN5eWcHz/learning-deconvolution-network-for-semantic-segmentation)\n- github: [https://github.com/HyeonwooNoh/DeconvNet](https://github.com/HyeonwooNoh/DeconvNet)\n- github: [https://github.com/HyeonwooNoh/caffe](https://github.com/HyeonwooNoh/caffe)\n\n## SegNet\n\n**SegNet: A Deep Convolutional Encoder-Decoder Architecture for Robust Semantic Pixel-Wise Labelling**\n\n- arxiv: [http://arxiv.org/abs/1505.07293](http://arxiv.org/abs/1505.07293)\n- github: [https://github.com/alexgkendall/caffe-segnet](https://github.com/alexgkendall/caffe-segnet)\n- github: [https://github.com/pfnet-research/chainer-segnet](https://github.com/pfnet-research/chainer-segnet)\n\n**SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation**\n\n![](http://mi.eng.cam.ac.uk/projects/segnet/images/segnet.png)\n\n- homepage: [http://mi.eng.cam.ac.uk/projects/segnet/](http://mi.eng.cam.ac.uk/projects/segnet/)\n- arxiv: [http://arxiv.org/abs/1511.00561](http://arxiv.org/abs/1511.00561)\n- github: [https://github.com/alexgkendall/caffe-segnet](https://github.com/alexgkendall/caffe-segnet)\n- tutorial: [http://mi.eng.cam.ac.uk/projects/segnet/tutorial.html](http://mi.eng.cam.ac.uk/projects/segnet/tutorial.html)\n\n**SegNet: Pixel-Wise Semantic Labelling Using a Deep Networks**\n\n- youtube: [https://www.youtube.com/watch?v=xfNYAly1iXo](https://www.youtube.com/watch?v=xfNYAly1iXo)\n- mirror: [http://pan.baidu.com/s/1gdUzDlD](http://pan.baidu.com/s/1gdUzDlD)\n\n**Getting Started with SegNet**\n\n- blog: [http://mi.eng.cam.ac.uk/projects/segnet/tutorial.html](http://mi.eng.cam.ac.uk/projects/segnet/tutorial.html)\n- github: [https://github.com/alexgkendall/SegNet-Tutorial](https://github.com/alexgkendall/SegNet-Tutorial)\n\n**ParseNet: Looking Wider to See Better**\n\n- intro:ICLR 2016\n- arxiv: [http://arxiv.org/abs/1506.04579](http://arxiv.org/abs/1506.04579)\n- github: [https://github.com/weiliu89/caffe/tree/fcn](https://github.com/weiliu89/caffe/tree/fcn)\n- caffe model zoo: [https://github.com/BVLC/caffe/wiki/Model-Zoo#parsenet-looking-wider-to-see-better](https://github.com/BVLC/caffe/wiki/Model-Zoo#parsenet-looking-wider-to-see-better)\n\n**Decoupled Deep Neural Network for Semi-supervised Semantic Segmentation**\n\n- intro: ICLR 2016\n- keywords: DecoupledNet\n- project(paper+code): [http://cvlab.postech.ac.kr/research/decouplednet/](http://cvlab.postech.ac.kr/research/decouplednet/)\n- arxiv: [http://arxiv.org/abs/1506.04924](http://arxiv.org/abs/1506.04924)\n- github: [https://github.com/HyeonwooNoh/DecoupledNet](https://github.com/HyeonwooNoh/DecoupledNet)\n\n**Semantic Image Segmentation via Deep Parsing Network**\n\n- intro: ICCV 2015. CUHK\n- keywords: Deep Parsing Network (DPN), Markov Random Field (MRF)\n- homepage: [http://personal.ie.cuhk.edu.hk/~lz013/projects/DPN.html](http://personal.ie.cuhk.edu.hk/~lz013/projects/DPN.html)\n- arxiv.org: [http://arxiv.org/abs/1509.02634](http://arxiv.org/abs/1509.02634)\n- paper: [http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Liu_Semantic_Image_Segmentation_ICCV_2015_paper.pdf](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Liu_Semantic_Image_Segmentation_ICCV_2015_paper.pdf)\n- slides: [http://personal.ie.cuhk.edu.hk/~pluo/pdf/presentation_dpn.pdf](http://personal.ie.cuhk.edu.hk/~pluo/pdf/presentation_dpn.pdf)\n\n**Multi-Scale Context Aggregation by Dilated Convolutions**\n\n- intro: ICLR 2016.\n- intro: Dilated Convolution for Semantic Image Segmentation\n- homepage: [http://vladlen.info/publications/multi-scale-context-aggregation-by-dilated-convolutions/](http://vladlen.info/publications/multi-scale-context-aggregation-by-dilated-convolutions/)\n- arxiv: [http://arxiv.org/abs/1511.07122](http://arxiv.org/abs/1511.07122)\n- github: [https://github.com/fyu/dilation](https://github.com/fyu/dilation)\n- github: [https://github.com/nicolov/segmentation_keras](https://github.com/nicolov/segmentation_keras)\n- notes: [http://www.inference.vc/dilated-convolutions-and-kronecker-factorisation/](http://www.inference.vc/dilated-convolutions-and-kronecker-factorisation/)\n\n**Instance-aware Semantic Segmentation via Multi-task Network Cascades**\n\n- intro: CVPR 2016 oral. 1st-place winner of MS COCO 2015 segmentation competition\n- keywords: RoI warping layer, Multi-task Network Cascades (MNC)\n- arxiv: [http://arxiv.org/abs/1512.04412](http://arxiv.org/abs/1512.04412)\n- github: [https://github.com/daijifeng001/MNC](https://github.com/daijifeng001/MNC)\n\n**Object Segmentation on SpaceNet via Multi-task Network Cascades (MNC)**\n\n- blog: [https://medium.com/the-downlinq/object-segmentation-on-spacenet-via-multi-task-network-cascades-mnc-f1c89d790b42](https://medium.com/the-downlinq/object-segmentation-on-spacenet-via-multi-task-network-cascades-mnc-f1c89d790b42)\n- github: [https://github.com/lncohn/pascal_to_spacenet](https://github.com/lncohn/pascal_to_spacenet)\n\n**Learning Transferrable Knowledge for Semantic Segmentation with Deep Convolutional Neural Network**\n\n![](http://cvlab.postech.ac.kr/research/transfernet/images/architecture.png)\n\n- intro: TransferNet\n- project page: [http://cvlab.postech.ac.kr/research/transfernet/](http://cvlab.postech.ac.kr/research/transfernet/)\n- arxiv: [http://arxiv.org/abs/1512.07928](http://arxiv.org/abs/1512.07928)\n- github: [https://github.com/maga33/TransferNet](https://github.com/maga33/TransferNet)\n\n**Combining the Best of Convolutional Layers and Recurrent Layers: A Hybrid Network for Semantic Segmentation**\n\n- arxiv: [http://arxiv.org/abs/1603.04871](http://arxiv.org/abs/1603.04871)\n\n**Seed, Expand and Constrain: Three Principles for Weakly-Supervised Image Segmentation**\n\n- intro: ECCV 2016\n- arxiv: [https://arxiv.org/abs/1603.06098](https://arxiv.org/abs/1603.06098)\n- github: [https://github.com/kolesman/SEC](https://github.com/kolesman/SEC)\n\n**ScribbleSup: Scribble-Supervised Convolutional Networks for Semantic Segmentation**\n\n- project page: [http://research.microsoft.com/en-us/um/people/jifdai/downloads/scribble_sup/](http://research.microsoft.com/en-us/um/people/jifdai/downloads/scribble_sup/)\n- arxiv: [http://arxiv.org/abs/1604.05144](http://arxiv.org/abs/1604.05144)\n\n**Laplacian Reconstruction and Refinement for Semantic Segmentation**\n\n**Laplacian Pyramid Reconstruction and Refinement for Semantic Segmentation**\n\n- intro: ECCV 2016\n- arxiv: [https://arxiv.org/abs/1605.02264](https://arxiv.org/abs/1605.02264)\n- paper: [https://www.ics.uci.edu/~fowlkes/papers/gf-eccv16.pdf](https://www.ics.uci.edu/~fowlkes/papers/gf-eccv16.pdf)\n- github(MatConvNet): [https://github.com/golnazghiasi/LRR](https://github.com/golnazghiasi/LRR)\n\n**Natural Scene Image Segmentation Based on Multi-Layer Feature Extraction**\n\n- arxiv: [http://arxiv.org/abs/1605.07586](http://arxiv.org/abs/1605.07586)\n\n**Convolutional Random Walk Networks for Semantic Image Segmentation**\n\n- arxiv: [http://arxiv.org/abs/1605.07681](http://arxiv.org/abs/1605.07681)\n\n**ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation**\n\n- arxiv: [http://arxiv.org/abs/1606.02147](http://arxiv.org/abs/1606.02147)\n- github: [https://github.com/e-lab/ENet-training](https://github.com/e-lab/ENet-training)\n- github(Caffe): [https://github.com/TimoSaemann/ENet](https://github.com/TimoSaemann/ENet)\n- github: [https://github.com/PavlosMelissinos/enet-keras](https://github.com/PavlosMelissinos/enet-keras)\n- github: [https://github.com/kwotsin/TensorFlow-ENet](https://github.com/kwotsin/TensorFlow-ENet)\n- blog: [http://culurciello.github.io/tech/2016/06/20/training-enet.html](http://culurciello.github.io/tech/2016/06/20/training-enet.html)\n\n**Fully Convolutional Networks for Dense Semantic Labelling of High-Resolution Aerial Imagery**\n\n- arxiv: [http://arxiv.org/abs/1606.02585](http://arxiv.org/abs/1606.02585)\n\n**Deep Learning Markov Random Field for Semantic Segmentation**\n\n- arxiv: [http://arxiv.org/abs/1606.07230](http://arxiv.org/abs/1606.07230)\n\n**Region-based semantic segmentation with end-to-end training**\n\n- intro: ECCV 2016\n- arxiv: [http://arxiv.org/abs/1607.07671](http://arxiv.org/abs/1607.07671)\n- githun: [https://github.com/nightrome/matconvnet-calvin](https://github.com/nightrome/matconvnet-calvin)\n\n**Built-in Foreground/Background Prior for Weakly-Supervised Semantic Segmentation**\n\n- intro: ECCV 2016\n- arxiv: [http://arxiv.org/abs/1609.00446](http://arxiv.org/abs/1609.00446)\n\n**PixelNet: Towards a General Pixel-level Architecture**\n\n- intro: semantic segmentation, edge detection\n- arxiv: [http://arxiv.org/abs/1609.06694](http://arxiv.org/abs/1609.06694)\n\n**Exploiting Depth from Single Monocular Images for Object Detection and Semantic Segmentation**\n\n- intro: IEEE T. Image Processing\n- intro: propose an RGB-D semantic segmentation method which applies a multi-task training scheme: semantic label prediction and depth value regression\n- arxiv: [https://arxiv.org/abs/1610.01706](https://arxiv.org/abs/1610.01706)\n\n**PixelNet: Representation of the pixels, by the pixels, and for the pixels**\n\n- intro: CMU & Adobe Research\n- project page: [http://www.cs.cmu.edu/~aayushb/pixelNet/](http://www.cs.cmu.edu/~aayushb/pixelNet/)\n- arxiv: [https://arxiv.org/abs/1702.06506](https://arxiv.org/abs/1702.06506)\n- github(Caffe): [https://github.com/aayushbansal/PixelNet](https://github.com/aayushbansal/PixelNet)\n\n**Semantic Segmentation of Earth Observation Data Using Multimodal and Multi-scale Deep Networks**\n\n- arxiv: [http://arxiv.org/abs/1609.06846](http://arxiv.org/abs/1609.06846)\n\n**Deep Structured Features for Semantic Segmentation**\n\n- arxiv: [http://arxiv.org/abs/1609.07916](http://arxiv.org/abs/1609.07916)\n\n**CNN-aware Binary Map for General Semantic Segmentation**\n\n- intro: ICIP 2016 Best Paper / Student Paper Finalist\n- arxiv: [https://arxiv.org/abs/1609.09220](https://arxiv.org/abs/1609.09220)\n\n**Efficient Convolutional Neural Network with Binary Quantization Layer**\n\n- arxiv: [https://arxiv.org/abs/1611.06764](https://arxiv.org/abs/1611.06764)\n\n**Mixed context networks for semantic segmentation**\n\n- intro: Hikvision Research Institute\n- arxiv: [https://arxiv.org/abs/1610.05854](https://arxiv.org/abs/1610.05854)\n\n**High-Resolution Semantic Labeling with Convolutional Neural Networks**\n\n- arxiv: [https://arxiv.org/abs/1611.01962](https://arxiv.org/abs/1611.01962)\n\n**Gated Feedback Refinement Network for Dense Image Labeling**\n\n- intro: CVPR 2017\n- paper: [http://www.cs.umanitoba.ca/~ywang/papers/cvpr17.pdf](http://www.cs.umanitoba.ca/~ywang/papers/cvpr17.pdf)\n\n**RefineNet: Multi-Path Refinement Networks with Identity Mappings for High-Resolution Semantic Segmentation**\n\n**RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation**\n\n- intro: CVPR 2017. IoU 83.4% on PASCAL VOC 2012\n- arxiv: [https://arxiv.org/abs/1611.06612](https://arxiv.org/abs/1611.06612)\n- github: [https://github.com/guosheng/refinenet](https://github.com/guosheng/refinenet)\n- leaderboard: [http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=6#KEY_Multipath-RefineNet-Res152](http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=6#KEY_Multipath-RefineNet-Res152)\n\n**Light-Weight RefineNet for Real-Time Semantic Segmentation**\n\n- intro: BMVC 2018\n- arxiv: [https://arxiv.org/abs/1810.03272](https://arxiv.org/abs/1810.03272)\n- github: [https://github.com/drsleep/light-weight-refinenet](https://github.com/drsleep/light-weight-refinenet)\n\n**Full-Resolution Residual Networks for Semantic Segmentation in Street Scenes**\n\n- keywords: Full-Resolution Residual Units (FRRU), Full-Resolution Residual Networks (FRRNs)\n- arxiv: [https://arxiv.org/abs/1611.08323](https://arxiv.org/abs/1611.08323)\n- github(Theano/Lasagne): [https://github.com/TobyPDE/FRRN](https://github.com/TobyPDE/FRRN)\n- youtube: [https://www.youtube.com/watch?v=PNzQ4PNZSzc](https://www.youtube.com/watch?v=PNzQ4PNZSzc)\n\n**Semantic Segmentation using Adversarial Networks**\n\n- intro: Facebook AI Research & INRIA. NIPS Workshop on Adversarial Training, Dec 2016, Barcelona, Spain\n- arxiv: [https://arxiv.org/abs/1611.08408](https://arxiv.org/abs/1611.08408)\n- github(Chainer): [https://github.com/oyam/Semantic-Segmentation-using-Adversarial-Networks](https://github.com/oyam/Semantic-Segmentation-using-Adversarial-Networks)\n\n**Improving Fully Convolution Network for Semantic Segmentation**\n\n- arxiv: [https://arxiv.org/abs/1611.08986](https://arxiv.org/abs/1611.08986)\n\n**The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation**\n\n- intro: Montreal Institute for Learning Algorithms & Ecole Polytechnique de Montreal\n- arxiv: [https://arxiv.org/abs/1611.09326](https://arxiv.org/abs/1611.09326)\n- github: [https://github.com/SimJeg/FC-DenseNet](https://github.com/SimJeg/FC-DenseNet)\n- github: [https://github.com/titu1994/Fully-Connected-DenseNets-Semantic-Segmentation](https://github.com/titu1994/Fully-Connected-DenseNets-Semantic-Segmentation)\n- github(Keras): [https://github.com/0bserver07/One-Hundred-Layers-Tiramisu](https://github.com/0bserver07/One-Hundred-Layers-Tiramisu)\n\n**Training Bit Fully Convolutional Network for Fast Semantic Segmentation**\n\n- intro: Megvii\n- arxiv: [https://arxiv.org/abs/1612.00212](https://arxiv.org/abs/1612.00212)\n\n**Classification With an Edge: Improving Semantic Image Segmentation with Boundary Detection**\n\n- intro: \"an end-to-end trainable deep convolutional neural network (DCNN) for semantic segmentation \nwith built-in awareness of semantically meaningful boundaries. \"\n- arxiv: [https://arxiv.org/abs/1612.01337](https://arxiv.org/abs/1612.01337)\n\n**Diverse Sampling for Self-Supervised Learning of Semantic Segmentation**\n\n- arxiv: [https://arxiv.org/abs/1612.01991](https://arxiv.org/abs/1612.01991)\n\n**Mining Pixels: Weakly Supervised Semantic Segmentation Using Image Labels**\n\n- intro: Nankai University & University of Oxford & NUS\n- arxiv: [https://arxiv.org/abs/1612.02101](https://arxiv.org/abs/1612.02101)\n\n**FCNs in the Wild: Pixel-level Adversarial and Constraint-based Adaptation**\n\n- arxiv: [https://arxiv.org/abs/1612.02649](https://arxiv.org/abs/1612.02649)\n\n**Understanding Convolution for Semantic Segmentation**\n\n- intro: UCSD & CMU & UIUC & TuSimple\n- arxiv: [https://arxiv.org/abs/1702.08502](https://arxiv.org/abs/1702.08502)\n- github(MXNet): [https://github.com/TuSimple/TuSimple-DUC]https://github.com/TuSimple/TuSimple-DUC\n- pretrained-models: [https://drive.google.com/drive/folders/0B72xLTlRb0SoREhISlhibFZTRmM](https://drive.google.com/drive/folders/0B72xLTlRb0SoREhISlhibFZTRmM)\n\n**Label Refinement Network for Coarse-to-Fine Semantic Segmentation**\n\n[https://www.arxiv.org/abs/1703.00551](https://www.arxiv.org/abs/1703.00551)\n\n**Predicting Deeper into the Future of Semantic Segmentation**\n\n- intro: Facebook AI Research\n- arxiv: [https://arxiv.org/abs/1703.07684](https://arxiv.org/abs/1703.07684)\n\n**Object Region Mining with Adversarial Erasing: A Simple Classification to Semantic Segmentation Approach**\n\n- intro: CVPR 2017 (oral)\n- keywords: Adversarial Erasing (AE)\n- arxiv: [https://arxiv.org/abs/1703.08448](https://arxiv.org/abs/1703.08448)\n\n**Guided Perturbations: Self Corrective Behavior in Convolutional Neural Networks**\n\n- intro: University of Maryland & GE Global Research Center\n- arxiv: [https://arxiv.org/abs/1703.07928](https://arxiv.org/abs/1703.07928)\n\n**Not All Pixels Are Equal: Difficulty-aware Semantic Segmentation via Deep Layer Cascade**\n\n- intro: CVPR 2017 spotlight paper\n- arxxiv: [https://arxiv.org/abs/1704.01344](https://arxiv.org/abs/1704.01344)\n\n**Large Kernel Matters -- Improve Semantic Segmentation by Global Convolutional Network**\n\n[https://arxiv.org/abs/1703.02719](https://arxiv.org/abs/1703.02719)\n\n**Loss Max-Pooling for Semantic Image Segmentation**\n\n- intro: CVPR 2017\n- arxiv: [https://arxiv.org/abs/1704.02966](https://arxiv.org/abs/1704.02966)\n\n**Reformulating Level Sets as Deep Recurrent Neural Network Approach to Semantic Segmentation**\n\n[https://arxiv.org/abs/1704.03593](https://arxiv.org/abs/1704.03593)\n\n**A Review on Deep Learning Techniques Applied to Semantic Segmentation**\n\n[https://arxiv.org/abs/1704.06857](https://arxiv.org/abs/1704.06857)\n\n**Joint Semantic and Motion Segmentation for dynamic scenes using Deep Convolutional Networks**\n\n- intro: [International Institute of Information Technology & Max Planck Institute For Intelligent Systems\n- arxiv: [https://arxiv.org/abs/1704.08331](https://arxiv.org/abs/1704.08331)\n\n**ICNet for Real-Time Semantic Segmentation on High-Resolution Images**\n\n- intro: CUHK & Sensetime\n- project page: [https://hszhao.github.io/projects/icnet/](https://hszhao.github.io/projects/icnet/)\n- arxiv: [https://arxiv.org/abs/1704.08545](https://arxiv.org/abs/1704.08545)\n- github: [https://github.com/hszhao/ICNet](https://github.com/hszhao/ICNet)\n- video: [https://www.youtube.com/watch?v=qWl9idsCuLQ](https://www.youtube.com/watch?v=qWl9idsCuLQ)\n\n**Feature Forwarding: Exploiting Encoder Representations for Efficient Semantic Segmentation**\n\n**LinkNet: Exploiting Encoder Representations for Efficient Semantic Segmentation**\n\n- project page: [https://codeac29.github.io/projects/linknet/](https://codeac29.github.io/projects/linknet/)\n- arxiv: [https://arxiv.org/abs/1707.03718](https://arxiv.org/abs/1707.03718)\n- github: [https://github.com/e-lab/LinkNet](https://github.com/e-lab/LinkNet)\n\n**Pixel Deconvolutional Networks**\n\n- intro: Washington State University\n- arxiv: [https://arxiv.org/abs/1705.06820](https://arxiv.org/abs/1705.06820)\n\n**Incorporating Network Built-in Priors in Weakly-supervised Semantic Segmentation**\n\n- intro: IEEE TPAMI\n- arxiv: [https://arxiv.org/abs/1706.02189](https://arxiv.org/abs/1706.02189)\n\n**Deep Semantic Segmentation for Automated Driving: Taxonomy, Roadmap and Challenges**\n\n- intro: IEEE ITSC 2017\n- arxiv: [https://arxiv.org/abs/1707.02432](https://arxiv.org/abs/1707.02432)\n\n**Semantic Segmentation with Reverse Attention**\n\n- intro: BMVC 2017 oral. University of Southern California\n- arxiv: [https://arxiv.org/abs/1707.06426](https://arxiv.org/abs/1707.06426)\n\n**Stacked Deconvolutional Network for Semantic Segmentation**\n\n[https://arxiv.org/abs/1708.04943](https://arxiv.org/abs/1708.04943)\n\n**Learning Dilation Factors for Semantic Segmentation of Street Scenes**\n\n- intro: GCPR 2017\n- arxiv: [https://arxiv.org/abs/1709.01956](https://arxiv.org/abs/1709.01956)\n\n**A Self-aware Sampling Scheme to Efficiently Train Fully Convolutional Networks for Semantic Segmentation**\n\n[https://arxiv.org/abs/1709.02764](https://arxiv.org/abs/1709.02764)\n\n**One-Shot Learning for Semantic Segmentation**\n\n- intro: BMWC 2017\n- arcxiv: [https://arxiv.org/abs/1709.03410](https://arxiv.org/abs/1709.03410)\n- github: [https://github.com/lzzcd001/OSLSM](https://github.com/lzzcd001/OSLSM)\n\n**An Adaptive Sampling Scheme to Efficiently Train Fully Convolutional Networks for Semantic Segmentation**\n\n[https://arxiv.org/abs/1709.02764](https://arxiv.org/abs/1709.02764)\n\n**Semantic Segmentation from Limited Training Data**\n\n[https://arxiv.org/abs/1709.07665](https://arxiv.org/abs/1709.07665)\n\n**Unsupervised Domain Adaptation for Semantic Segmentation with GANs**\n\n[https://arxiv.org/abs/1711.06969](https://arxiv.org/abs/1711.06969)\n\n**Neuron-level Selective Context Aggregation for Scene Segmentation**\n\n[https://arxiv.org/abs/1711.08278](https://arxiv.org/abs/1711.08278)\n\n**Road Extraction by Deep Residual U-Net**\n\n[https://arxiv.org/abs/1711.10684](https://arxiv.org/abs/1711.10684)\n\n**Mix-and-Match Tuning for Self-Supervised Semantic Segmentation**\n\n- intro: AAAI 2018\n- project page: [http://mmlab.ie.cuhk.edu.hk/projects/M&M/](http://mmlab.ie.cuhk.edu.hk/projects/M&M/)\n- arxiv: [https://arxiv.org/abs/1712.00661](https://arxiv.org/abs/1712.00661)\n- github: [https://github.com/XiaohangZhan/mix-and-match/](https://github.com/XiaohangZhan/mix-and-match/)\n- github: [https://github.com//liuziwei7/mix-and-match](https://github.com//liuziwei7/mix-and-match)\n\n**Error Correction for Dense Semantic Image Labeling**\n\n[https://arxiv.org/abs/1712.03812](https://arxiv.org/abs/1712.03812)\n\n**Semantic Segmentation via Highly Fused Convolutional Network with Multiple Soft Cost Functions**\n\n[https://arxiv.org/abs/1801.01317](https://arxiv.org/abs/1801.01317)\n\n**RTSeg: Real-time Semantic Segmentation Comparative Study**\n\n- arxiv: [https://arxiv.org/abs/1803.02758](https://arxiv.org/abs/1803.02758)\n- github: [https://github.com/MSiam/TFSegmentation](https://github.com/MSiam/TFSegmentation)\n\n**ShuffleSeg: Real-time Semantic Segmentation Network**\n\n- intro: Cairo University\n- arxiv: [https://arxiv.org/abs/1803.03816](https://arxiv.org/abs/1803.03816)\n\n**Dynamic-structured Semantic Propagation Network**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1803.06067](https://arxiv.org/abs/1803.06067)\n\n**ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation**\n\n- project page: [https://sacmehta.github.io/ESPNet/](https://sacmehta.github.io/ESPNet/)\n- arxiv: [https://arxiv.org/abs/1803.06815](https://arxiv.org/abs/1803.06815)\n- github: [https://github.com/sacmehta/ESPNet](https://github.com/sacmehta/ESPNet)\n\n**Context Encoding for Semantic Segmentation**\n\n- intro: CVPR 2018\n- keywords: Synchronized Cross-GPU Batch Normalization\n- arxiv: [https://arxiv.org/abs/1803.08904](https://arxiv.org/abs/1803.08904)\n- github: [https://github.com/zhanghang1989/PyTorch-Encoding](https://github.com/zhanghang1989/PyTorch-Encoding)\n\n**Adaptive Affinity Field for Semantic Segmentation**\n\n- intro: UC Berkeley / ICSI\n- arxiv: [https://arxiv.org/abs/1803.10335](https://arxiv.org/abs/1803.10335)\n\n**Predicting Future Instance Segmentations by Forecasting Convolutional Features**\n\n- intro: Facebook AI Research & Univ. Grenoble Alpes\n- arxiv: [https://arxiv.org/abs/1803.11496](https://arxiv.org/abs/1803.11496)\n\n**Fully Convolutional Adaptation Networks for Semantic Segmentation**\n\n- intro: CVPR 2018, Rank 1 in Segmentation Track of Visual Domain Adaptation Challenge 2017\n- keywords: Fully Convolutional Adaptation Networks (FCAN), Appearance Adaptation Networks (AAN) and Representation Adaptation Networks (RAN)\n- arxiv: [https://arxiv.org/abs/1804.08286](https://arxiv.org/abs/1804.08286)\n\n**Learning a Discriminative Feature Network for Semantic Segmentation**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1804.09337](https://arxiv.org/abs/1804.09337)\n\n**Deep Representation Learning for Domain Adaptation of Semantic Image Segmentation**\n\n[https://arxiv.org/abs/1805.04141](https://arxiv.org/abs/1805.04141)\n\n**Convolutional CRFs for Semantic Segmentation**\n\n- arxiv: [https://arxiv.org/abs/1805.04777](https://arxiv.org/abs/1805.04777)\n- github: [https://github.com/MarvinTeichmann/ConvCRF](https://github.com/MarvinTeichmann/ConvCRF)\n\n**ContextNet: Exploring Context and Detail for Semantic Segmentation in Real-time**\n\n- intro: Toshiba Research\n- arxiv: [https://arxiv.org/abs/1805.04554](https://arxiv.org/abs/1805.04554)\n\n**DifNet: Semantic Segmentation by DiffusionNetworks**\n\n[https://arxiv.org/abs/1805.08015](https://arxiv.org/abs/1805.08015)\n\n**Pyramid Attention Network for Semantic Segmentation**\n\n[https://arxiv.org/abs/1805.10180](https://arxiv.org/abs/1805.10180)\n\n**Semantic Segmentation with Scarce Data**\n\n- intro: ICML 2018 Workshop\n- arxiv: [https://arxiv.org/abs/1807.00911](https://arxiv.org/abs/1807.00911)\n\n**Attention to Refine through Multi-Scales for Semantic Segmentation**\n\n[https://arxiv.org/abs/1807.02917](https://arxiv.org/abs/1807.02917)\n\n**Guided Upsampling Network for Real-Time Semantic Segmentation**\n\n- intro: BMVC 2018\n- arxiv: [https://arxiv.org/abs/1807.07466](https://arxiv.org/abs/1807.07466)\n\n**Deep Learning for Semantic Segmentation on Minimal Hardware**\n\n- intro: RoboCup International Symposium 2018. University of Hertfordshire\n- arxiv: [https://arxiv.org/abs/1807.05597](https://arxiv.org/abs/1807.05597)\n\n**Future Semantic Segmentation with Convolutional LSTM**\n\n- intro: BMVC 2018\n- arxiv: [https://arxiv.org/abs/1807.07946](https://arxiv.org/abs/1807.07946)\n\n**BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation**\n\n- intro: ECCV 2018\n- arxiv: [https://arxiv.org/abs/1808.00897](https://arxiv.org/abs/1808.00897)\n\n**Dual Attention Network for Scene Segmentation**\n\n[https://arxiv.org/abs/1809.02983](https://arxiv.org/abs/1809.02983)\n\n**Real-Time Joint Semantic Segmentation and Depth Estimation Using Asymmetric Annotations**\n\n[https://arxiv.org/abs/1809.04766](https://arxiv.org/abs/1809.04766)\n\n**Efficient Dense Modules of Asymmetric Convolution for Real-Time Semantic Segmentation**\n\n[https://arxiv.org/abs/1809.06323](https://arxiv.org/abs/1809.06323)\n\n**Semantic Image Segmentation by Scale-Adaptive Networks**\n\n- github(Caffe): [https://github.com/speedinghzl/Scale-Adaptive-Network](https://github.com/speedinghzl/Scale-Adaptive-Network)\n\n**Recurrent Iterative Gating Networks for Semantic Segmentation**\n\n- intro: WACV 2019\n- arxiv: [https://arxiv.org/abs/1811.08043](https://arxiv.org/abs/1811.08043)\n\n**CGNet: A Light-weight Context Guided Network for Semantic Segmentation**\n\n- arxiv: [https://arxiv.org/abs/1811.08201](https://arxiv.org/abs/1811.08201)\n- github: [https://github.com/wutianyiRosun/CGNet](https://github.com/wutianyiRosun/CGNet)\n\n**CCNet: Criss-Cross Attention for Semantic Segmentation**\n\n- intro: Huazhong University of Science and Technology & Horizon Robotics & University of Illinois at Urbana-Champaign\n- arxiv: [https://arxiv.org/abs/1811.11721](https://arxiv.org/abs/1811.11721)\n- github: [https://github.com/speedinghzl/CCNet](https://github.com/speedinghzl/CCNet)\n\n**ShelfNet for Real-time Semantic Segmentation**\n\n- intro: Yale University\n- arxiv: [https://arxiv.org/abs/1811.11254](https://arxiv.org/abs/1811.11254)\n- github: [https://github.com/juntang-zhuang/ShelfNet](https://github.com/juntang-zhuang/ShelfNet)\n\n**Improving Semantic Segmentation via Video Propagation and Label Relaxation**\n\n- intro: CVPR 2019 oral\n- arxiv: [https://arxiv.org/abs/1812.01593](https://arxiv.org/abs/1812.01593)\n- github: [https://github.com/NVIDIA/semantic-segmentation](https://github.com/NVIDIA/semantic-segmentation)\n\n**RetinaMask: Learning to predict masks improves state-of-the-art single-shot detection for free**\n\n- arxiv: [https://arxiv.org/abs/1901.03353](https://arxiv.org/abs/1901.03353)\n- github: [https://github.com/chengyangfu/retinamask](https://github.com/chengyangfu/retinamask)\n\n**Fast-SCNN: Fast Semantic Segmentation Network**\n\n[https://arxiv.org/abs/1902.04502](https://arxiv.org/abs/1902.04502)\n\n**Structured Knowledge Distillation for Semantic Segmentation**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1903.04197](https://arxiv.org/abs/1903.04197)\n\n**In Defense of Pre-trained ImageNet Architectures for Real-time Semantic Segmentation of Road-driving Images**\n\n- intro: CVPR 2019\n- intro: University of Zagreb\n- keywords: SwiftNet\n- arxiv: [https://arxiv.org/abs/1903.08469](https://arxiv.org/abs/1903.08469)\n- github: [https://github.com/orsic/swiftnet](https://github.com/orsic/swiftnet)\n\n**FastFCN: Rethinking Dilated Convolution in the Backbone for Semantic Segmentation**\n\n- intro: Chinese Academy of Sciences & Deepwise AI Lab\n- keywords: Joint Pyramid Upsampling (JPU)\n- project page: [http://wuhuikai.me/FastFCNProject/](http://wuhuikai.me/FastFCNProject/)\n- arxiv: [https://arxiv.org/abs/1903.11816](https://arxiv.org/abs/1903.11816)\n- github: [https://github.com/wuhuikai/FastFCN](https://github.com/wuhuikai/FastFCN)\n\n**Significance-aware Information Bottleneck for Domain Adaptive Semantic Segmentation**\n\n- intro: HUST & UTS\n- arxiv: [https://arxiv.org/abs/1904.00876](https://arxiv.org/abs/1904.00876)\n\n**GFF: Gated Fully Fusion for Semantic Segmentation**\n\n[https://arxiv.org/abs/1904.01803](https://arxiv.org/abs/1904.01803)\n\n**DADA: Depth-aware Domain Adaptation in Semantic Segmentation**\n\n[https://arxiv.org/abs/1904.01886](https://arxiv.org/abs/1904.01886)\n\n**DFANet: Deep Feature Aggregation for Real-Time Semantic Segmentation**\n\n- intro: Megvii Technology\n- arxiv: [https://arxiv.org/abs/1904.02216](https://arxiv.org/abs/1904.02216)\n\n**ESNet: An Efficient Symmetric Network for Real-time Semantic Segmentation**\n\n- arxiv: [https://arxiv.org/abs/1906.09826](https://arxiv.org/abs/1906.09826)\n- github(official): [https://github.com/xiaoyufenfei/ESNet](https://github.com/xiaoyufenfei/ESNet)\n\n**Gated-SCNN: Gated Shape CNNs for Semantic Segmentation**\n\n- intro: NVIDIA & University of Waterloo & University of Toronto & Vector Institute\n- project page: [https://nv-tlabs.github.io/GSCNN/](https://nv-tlabs.github.io/GSCNN/)\n- arxiv: [https://arxiv.org/abs/1907.05740](https://arxiv.org/abs/1907.05740)\n\n**DABNet: Depth-wise Asymmetric Bottleneck for Real-time Semantic Segmentation**\n\n- intro: BMVC 2019\n- arxiv: [https://arxiv.org/abs/1907.11830](https://arxiv.org/abs/1907.11830)\n\n**Dynamic Graph Message Passing Networks**\n\n- intro: CVPR 2020 oral\n- arxiv: [https://arxiv.org/abs/1908.06955](https://arxiv.org/abs/1908.06955)\n\n**Squeeze-and-Attention Networks for Semantic Segmentation**\n\n[https://arxiv.org/abs/1909.03402](https://arxiv.org/abs/1909.03402)\n\n**Global Aggregation then Local Distribution in Fully Convolutional Networks**\n\n- intro: BMVC 2019\n- arxiv: [https://arxiv.org/abs/1909.07229](https://arxiv.org/abs/1909.07229)\n- github: [https://github.com/lxtGH/GALD-Net](https://github.com/lxtGH/GALD-Net)\n\n**Graph-guided Architecture Search for Real-time Semantic Segmentation**\n\n[https://arxiv.org/abs/1909.06793](https://arxiv.org/abs/1909.06793)\n\n**Feature Pyramid Encoding Network for Real-time Semantic Segmentation**\n\n- intro: BMVC 2019\n- arxiv: [https://arxiv.org/abs/1909.08599](https://arxiv.org/abs/1909.08599)\n\n**ACFNet: Attentional Class Feature Network for Semantic Segmentation**\n\n- intro: ICCV 2019\n- arxiv: [https://arxiv.org/abs/1909.09408](https://arxiv.org/abs/1909.09408)\n\n**Region Mutual Information Loss for Semantic Segmentation**\n\n- intro: NeurIPS 2019\n- arxiv: [https://arxiv.org/abs/1910.12037](https://arxiv.org/abs/1910.12037)\n- github: [https://github.com/ZJULearning/RMI](https://github.com/ZJULearning/RMI)\n\n**Category Anchor-Guided Unsupervised Domain Adaptation for Semantic Segmentation**\n\n- intro: NeurIPS 2019\n- arxiv: [https://arxiv.org/abs/1910.13049](https://arxiv.org/abs/1910.13049)\n- github: [https://github.com/RogerZhangzz/CAG_UDA](https://github.com/RogerZhangzz/CAG_UDA)\n\n**Efficacy of Pixel-Level OOD Detection for Semantic Segmentation**\n\n[https://arxiv.org/abs/1911.02897](https://arxiv.org/abs/1911.02897)\n\n**Location-aware Upsampling for Semantic Segmentation**\n\n- keywords: LaU\n- arxiv: [https://arxiv.org/abs/1911.05250](https://arxiv.org/abs/1911.05250)\n- github: [https://github.com/HolmesShuan/Location-aware-Upsampling-for-Semantic-Segmentation](https://github.com/HolmesShuan/Location-aware-Upsampling-for-Semantic-Segmentation)\n\n**FasterSeg: Searching for Faster Real-time Semantic Segmentation**\n\n- intro: ICLR 2020\n- intro: Texas A&M University & Horizon Robotics Inc.\n- arxiv: [https://arxiv.org/abs/1912.10917](https://arxiv.org/abs/1912.10917)\n\n**AlignSeg: Feature-Aligned Segmentation Networks**\n\n[https://arxiv.org/abs/2003.00872](https://arxiv.org/abs/2003.00872)\n\n**Deep Grouping Model for Unified Perceptual Parsing**\n\n- intro: CVPR 2020\n- arxiv: [https://arxiv.org/abs/2003.11647](https://arxiv.org/abs/2003.11647)\n\n**Spatial Pyramid Based Graph Reasoning for Semantic Segmentation**\n\n- intro: CVPR 2020\n- arxiv: [https://arxiv.org/abs/2003.10211](https://arxiv.org/abs/2003.10211)\n\n**Learning Dynamic Routing for Semantic Segmentation**\n\n- intro: CVPR 2020 oral\n- arxiv: [https://arxiv.org/abs/2003.10401](https://arxiv.org/abs/2003.10401)\n- giihub(official): [https://github.com/yanwei-li/DynamicRouting](https://github.com/yanwei-li/DynamicRouting)\n\n**Learning to Predict Context-adaptive Convolution for Semantic Segmentation**\n\n[https://arxiv.org/abs/2004.08222](https://arxiv.org/abs/2004.08222)\n\n**Transferring and Regularizing Prediction for Semantic Segmentation**\n\n- intro: CVPR 2020\n- arxiv: [https://arxiv.org/abs/2006.06570](https://arxiv.org/abs/2006.06570)\n\n**Tensor Low-Rank Reconstruction for Semantic Segmentation**\n\n- intro: ECCV 2020\n- intro: Top-1 performance on PASCAL-VOC12\n- arxiv: [https://arxiv.org/abs/2008.00490](https://arxiv.org/abs/2008.00490)\n- github: [https://github.com/CWanli/RecoNet](https://github.com/CWanli/RecoNet)\n\n**Representative Graph Neural Network**\n\n- intro: ECCV 2020\n- arxiv: [https://arxiv.org/abs/2008.05202](https://arxiv.org/abs/2008.05202)\n\n**EfficientFCN: Holistically-guided Decoding for Semantic Segmentation**\n\n[https://arxiv.org/abs/2008.10487](https://arxiv.org/abs/2008.10487)\n\n**Improving Semantic Segmentation via Decoupled Body and Edge Supervision**\n\n- intro: ECCV 2020\n- arxiv: [https://arxiv.org/abs/2007.10035](https://arxiv.org/abs/2007.10035)\n- github: [https://github.com/lxtGH/DecoupleSegNets](https://github.com/lxtGH/DecoupleSegNets)\n\n**Auto Seg-Loss: Searching Metric Surrogates for Semantic Segmentation**\n\n[https://arxiv.org/abs/2010.07930](https://arxiv.org/abs/2010.07930)\n\n**PseudoSeg: Designing Pseudo Labels for Semantic Segmentation**\n\n- arxiv: [https://arxiv.org/abs/2010.09713](https://arxiv.org/abs/2010.09713)\n- github: [https://github.com/googleinterns/wss](https://github.com/googleinterns/wss)\n\n**Importance-Aware Semantic Segmentation in Self-Driving with Discrete Wasserstein Training**\n\n- intro: AAAI 2020\n- arxiv: [https://arxiv.org/abs/2010.12440](https://arxiv.org/abs/2010.12440)\n\n**Pixel-Level Cycle Association: A New Perspective for Domain Adaptive Semantic Segmentation**\n\n- intro: NeurIPS 2020 oral\n- arxiv: [https://arxiv.org/abs/2011.00147](https://arxiv.org/abs/2011.00147)\n- github: [https://github.com/kgl-prml/Pixel-Level-Cycle-Association](https://github.com/kgl-prml/Pixel-Level-Cycle-Association)\n\n**CABiNet: Efficient Context Aggregation Network for Low-Latency Semantic Segmentation**\n\n- intro: University of Twente\n- arxiv: [https://arxiv.org/abs/2011.00993](https://arxiv.org/abs/2011.00993)\n\n**SegBlocks: Block-Based Dynamic Resolution Networks for Real-Time Segmentation**\n\n[https://arxiv.org/abs/2011.12025](https://arxiv.org/abs/2011.12025)\n\n**Channel-wise Distillation for Semantic Segmentation**\n\n- arxiv: [https://arxiv.org/abs/2011.13256](https://arxiv.org/abs/2011.13256)\n- github: [https://github.com/drilistbox](https://github.com/drilistbox)\n\n**BoxInst: High-Performance Instance Segmentation with Box Annotations**\n\n- intro: University of Adelaide\n- arxiv: [https://arxiv.org/abs/2012.02310](https://arxiv.org/abs/2012.02310)\n- github: [https://github.com/aim-uofa/AdelaiDet/](https://github.com/aim-uofa/AdelaiDet/)\n\n**Scaling Semantic Segmentation Beyond 1K Classes on a Single GPU**\n\n- arxiv: [https://arxiv.org/abs/2012.07489](https://arxiv.org/abs/2012.07489)\n- github: [https://github.com/shipra25jain/ESSNet](https://github.com/shipra25jain/ESSNet)\n\n**Cross-Domain Grouping and Alignment for Domain Adaptive Semantic Segmentation**\n\n- intro: AAAI 2021\n- arxiv: [https://arxiv.org/abs/2012.08226](https://arxiv.org/abs/2012.08226)\n\n**HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation**\n\n- intro: Facebook AI & Tel Aviv University\n- arxiv: [https://arxiv.org/abs/2012.11582](https://arxiv.org/abs/2012.11582)\n\n## SETR\n\n**Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers**\n\n- intro: CVPR 2021\n- intro: Fudan University & University of Oxford & University of Surrey & Tencent Youtu Lab & Facebook AI\n- project page: [https://fudan-zvg.github.io/SETR/](https://fudan-zvg.github.io/SETR/)\n- arxiv: [https://arxiv.org/abs/2012.15840](https://arxiv.org/abs/2012.15840)\n- github: [https://github.com/fudan-zvg/SETR](https://github.com/fudan-zvg/SETR)\n\n**Exploring Cross-Image Pixel Contrast for Semantic Segmentation**\n\n- intro: ICCV 2021 oral\n- intro: Computer Vision Lab, ETH Zurich & SenseTime Research\n- arxiv: [https://arxiv.org/abs/2101.11939](https://arxiv.org/abs/2101.11939)\n- github: [https://github.com/tfzhou/ContrastiveSeg](https://github.com/tfzhou/ContrastiveSeg)\n\n**Active Boundary Loss for Semantic Segmentation**\n\n[https://arxiv.org/abs/2102.02696](https://arxiv.org/abs/2102.02696)\n\n**Learning Statistical Texture for Semantic Segmentation**\n\n- intro: CVPR 2021\n- intro: Beihang University & SenseTime Research\n- arxiv: [https://arxiv.org/abs/2103.04133](https://arxiv.org/abs/2103.04133)\n\n**Cross-Dataset Collaborative Learning for Semantic Segmentation**\n\n- intro: CVPR 2021\n- intro: Xilinx Inc. & Chinese Academy of Sciences\n- arxiv: [https://arxiv.org/abs/2103.11351](https://arxiv.org/abs/2103.11351)\n\n**Vision Transformers for Dense Prediction**\n\n- intro: Intel Labs\n- arxiv: [https://arxiv.org/abs/2103.13413](https://arxiv.org/abs/2103.13413)\n- github: [https://github.com/intel-isl/DPT](https://github.com/intel-isl/DPT)\n\n**InverseForm: A Loss Function for Structured Boundary-Aware Segmentation**\n\n- intro: CVPR 2021 oral\n- intro: Qualcomm AI Research\n- arxiv: [https://arxiv.org/abs/2104.02745](https://arxiv.org/abs/2104.02745)\n\n**Rethinking BiSeNet For Real-time Semantic Segmentation**\n\n- intro: Meituan\n- intro: CVPR 2021\n- arxiv: [https://arxiv.org/abs/2104.13188](https://arxiv.org/abs/2104.13188)\n- github: [https://github.com/MichaelFan01/STDC-Seg](https://github.com/MichaelFan01/STDC-Seg)\n\n**Segmenter: Transformer for Semantic Segmentation**\n\n- intro: Inria\n- arxiv: [https://arxiv.org/abs/2105.05633](https://arxiv.org/abs/2105.05633)\n- github: [https://github.com/rstrudel/segmenter](https://github.com/rstrudel/segmenter)\n\n**SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers**\n\n[https://arxiv.org/abs/2105.15203](https://arxiv.org/abs/2105.15203)\n\n**Per-Pixel Classification is Not All You Need for Semantic Segmentation**\n\n- keywords: UIUC & FAIR\n- project page: [https://bowenc0221.github.io/maskformer/](https://bowenc0221.github.io/maskformer/)\n- arxiv: [https://arxiv.org/abs/2107.06278](https://arxiv.org/abs/2107.06278)\n\n**A Unified Efficient Pyramid Transformer for Semantic Segmentation**\n\n- intro: School of Data Science, Fudan University & Amazon Web Services & University of California, Davis\n- arxiv: [https://arxiv.org/abs/2107.14209](https://arxiv.org/abs/2107.14209)\n\n**Deep Metric Learning for Open World Semantic Segmentation**\n\n- intro: ICCV 2021\n- arxiv: [https://arxiv.org/abs/2108.04562](https://arxiv.org/abs/2108.04562)\n\n**Multi-Anchor Active Domain Adaptation for Semantic Segmentation**\n\n- intro: ICCV 2021 Oral\n- arxiv: [https://arxiv.org/abs/2108.08012](https://arxiv.org/abs/2108.08012)\n\n**Generalize then Adapt: Source-Free Domain Adaptive Semantic Segmentation**\n\n- intro: ICCV 2021\n- intro: Indian Institute of Science & Google Research\n- project page: [https://sites.google.com/view/sfdaseg](https://sites.google.com/view/sfdaseg)\n- arxiv: [https://arxiv.org/abs/2108.11249](https://arxiv.org/abs/2108.11249)\n\n**HRFormer: High-Resolution Transformer for Dense Prediction**\n\n- intro: NeurIPS 2021\n- intro: University of Chinese Academy of Sciences & Institute of Computing Technology, CAS & Peking University & Microsoft Research Asia & Baidu\n- arxiv: [https://arxiv.org/abs/2110.09408](https://arxiv.org/abs/2110.09408)\n- github: [https://github.com/HRNet/HRFormer](https://github.com/HRNet/HRFormer)\n\n**Deep Hierarchical Semantic Segmentation**\n\n- intro: CVPR 2022\n- arxiv: [https://arxiv.org/abs/2203.14335](https://arxiv.org/abs/2203.14335)\n- github: [https://github.com/0liliulei/HieraSeg](https://github.com/0liliulei/HieraSeg)\n\n**TopFormer: Token Pyramid Transformer for Mobile Semantic Segmentation**\n\n- intro: CVPR 2022\n- arxiv: [https://arxiv.org/abs/2204.05525](https://arxiv.org/abs/2204.05525)\n- github: [https://github.com/hustvl/TopFormer](https://github.com/hustvl/TopFormer)\n\n**Mask DINO: Towards A Unified Transformer-based Framework for Object Detection and Segmentation**\n\n- intro: The Hong Kong University of Science and Technology & Tsinghua University & International Digital Economy Academy (IDEA) & The Hong Kong University of Science and Technology (Guangzhou)\n- arxiv: [https://arxiv.org/abs/2206.02777](https://arxiv.org/abs/2206.02777)\n- github: [https://github.com/IDEACVR/MaskDINO](https://github.com/IDEACVR/MaskDINO)\n\n# Instance Segmentation\n\n**Simultaneous Detection and Segmentation**\n\n- intro: ECCV 2014\n- author: Bharath Hariharan, Pablo Arbelaez, Ross Girshick, Jitendra Malik\n- arxiv: [http://arxiv.org/abs/1407.1808](http://arxiv.org/abs/1407.1808)\n- github(Matlab): [https://github.com/bharath272/sds_eccv2014](https://github.com/bharath272/sds_eccv2014)\n\n**Convolutional Feature Masking for Joint Object and Stuff Segmentation**\n\n- intro: CVPR 2015\n- keywords: masking layers\n- arxiv: [https://arxiv.org/abs/1412.1283](https://arxiv.org/abs/1412.1283)\n- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Dai_Convolutional_Feature_Masking_2015_CVPR_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Dai_Convolutional_Feature_Masking_2015_CVPR_paper.pdf)\n\n**Proposal-free Network for Instance-level Object Segmentation**\n\n- paper: [http://arxiv.org/abs/1509.02636](http://arxiv.org/abs/1509.02636)\n\n**Hypercolumns for object segmentation and fine-grained localization**\n\n- intro: CVPR 2015\n- arxiv: [https://arxiv.org/abs/1411.5752](https://arxiv.org/abs/1411.5752)\n- paper: [http://www.cs.berkeley.edu/~bharath2/pubs/pdfs/BharathCVPR2015.pdf](http://www.cs.berkeley.edu/~bharath2/pubs/pdfs/BharathCVPR2015.pdf)\n\n**SDS using hypercolumns**\n\n- github: [https://github.com/bharath272/sds](https://github.com/bharath272/sds)\n\n**Learning to decompose for object detection and instance segmentation**\n\n- intro: ICLR 2016 Workshop\n- keyword: CNN / RNN, MNIST, KITTI\n- arxiv: [http://arxiv.org/abs/1511.06449](http://arxiv.org/abs/1511.06449)\n\n**Recurrent Instance Segmentation**\n\n- intro: ECCV 2016\n- porject page: [http://romera-paredes.com/ris](http://romera-paredes.com/ris)\n- arxiv: [http://arxiv.org/abs/1511.08250](http://arxiv.org/abs/1511.08250)\n- github(Torch): [https://github.com/bernard24/ris](https://github.com/bernard24/ris)\n- poster: [http://www.eccv2016.org/files/posters/P-4B-46.pdf](http://www.eccv2016.org/files/posters/P-4B-46.pdf)\n- youtube: [https://www.youtube.com/watch?v=l_WD2OWOqBk](https://www.youtube.com/watch?v=l_WD2OWOqBk)\n\n**Instance-sensitive Fully Convolutional Networks**\n\n- intro: ECCV 2016. instance segment proposal\n- arxiv: [http://arxiv.org/abs/1603.08678](http://arxiv.org/abs/1603.08678)\n\n**Amodal Instance Segmentation**\n\n- intro: ECCV 2016\n- arxiv: [http://arxiv.org/abs/1604.08202](http://arxiv.org/abs/1604.08202)\n\n**Bridging Category-level and Instance-level Semantic Image Segmentation**\n\n- keywords: online bootstrapping\n- arxiv: [http://arxiv.org/abs/1605.06885](http://arxiv.org/abs/1605.06885)\n\n**Bottom-up Instance Segmentation using Deep Higher-Order CRFs**\n\n- intro: BMVC 2016\n- arxiv: [http://arxiv.org/abs/1609.02583](http://arxiv.org/abs/1609.02583)\n\n**DeepCut: Object Segmentation from Bounding Box Annotations using Convolutional Neural Networks**\n\n- arxiv: [http://arxiv.org/abs/1605.07866](http://arxiv.org/abs/1605.07866)\n\n**End-to-End Instance Segmentation and Counting with Recurrent Attention**\n\n- intro: ReInspect\n- arxiv: [http://arxiv.org/abs/1605.09410](http://arxiv.org/abs/1605.09410)\n\n**Translation-aware Fully Convolutional Instance Segmentation**\n\n**Fully Convolutional Instance-aware Semantic Segmentation**\n\n- intro:  CVPR 2017 Spotlight paper. winning entry of COCO segmentation challenge 2016\n- keywords:  TA-FCN / FCIS\n- arxiv: [https://arxiv.org/abs/1611.07709](https://arxiv.org/abs/1611.07709)\n- github: [https://github.com/msracver/FCIS](https://github.com/msracver/FCIS)\n- slides: [https://onedrive.live.com/?cid=f371d9563727b96f&id=F371D9563727B96F%2197213&authkey=%21AEYOyOirjIutSVk](https://onedrive.live.com/?cid=f371d9563727b96f&id=F371D9563727B96F%2197213&authkey=%21AEYOyOirjIutSVk)\n\n**InstanceCut: from Edges to Instances with MultiCut**\n\n- arxiv: [https://arxiv.org/abs/1611.08272](https://arxiv.org/abs/1611.08272)\n\n**Deep Watershed Transform for Instance Segmentation**\n\n- arxiv: [https://arxiv.org/abs/1611.08303](https://arxiv.org/abs/1611.08303)\n\n**Object Detection Free Instance Segmentation With Labeling Transformations**\n\n- arxiv: [https://arxiv.org/abs/1611.08991](https://arxiv.org/abs/1611.08991)\n\n**Shape-aware Instance Segmentation**\n\n- arxiv: [https://arxiv.org/abs/1612.03129](https://arxiv.org/abs/1612.03129)\n\n**Interpretable Structure-Evolving LSTM**\n\n- intro: CMU & Sun Yat-sen University & National University of Singapore & Adobe Research\n- intro: CVPR 2017 spotlight paper\n- arxiv: [https://arxiv.org/abs/1703.03055](https://arxiv.org/abs/1703.03055)\n\n**Mask R-CNN**\n\n- intro: ICCV 2017 Best paper award. Facebook AI Research\n- arxiv: [https://arxiv.org/abs/1703.06870](https://arxiv.org/abs/1703.06870)\n- slides: [http://kaiminghe.com/iccv17tutorial/maskrcnn_iccv2017_tutorial_kaiminghe.pdf](http://kaiminghe.com/iccv17tutorial/maskrcnn_iccv2017_tutorial_kaiminghe.pdf)\n- github(official, Caffe2): [https://github.com/facebookresearch/Detectron](https://github.com/facebookresearch/Detectron)\n- github: [https://github.com/facebookresearch/maskrcnn-benchmark](https://github.com/facebookresearch/maskrcnn-benchmark)\n- github: [https://github.com/TuSimple/mx-maskrcnn](https://github.com/TuSimple/mx-maskrcnn)\n- slides: [https://lmb.informatik.uni-freiburg.de/lectures/seminar_brox/seminar_ss17/maskrcnn_slides.pdf](https://lmb.informatik.uni-freiburg.de/lectures/seminar_brox/seminar_ss17/maskrcnn_slides.pdf)\n- github(Keras+TensorFlow): [https://github.com/matterport/Mask_RCNN](https://github.com/matterport/Mask_RCNN)\n\n**Faster Training of Mask R-CNN by Focusing on Instance Boundaries**\n\n- intro: BMW Car IT GmbH\n- arxiv: [https://arxiv.org/abs/1809.07069](https://arxiv.org/abs/1809.07069)\n\n**Boundary-preserving Mask R-CNN**\n\n- intro: ECCV 2020\n- intro: Huazhong University of Science and Technology & Horizon Robotics Inc.\n- arxiv: [https://arxiv.org/abs/2007.08921](https://arxiv.org/abs/2007.08921)\n- github: [https://github.com/hustvl/BMaskR-CNN](https://github.com/hustvl/BMaskR-CNN)\n\n**Semantic Instance Segmentation via Deep Metric Learning**\n\n[https://arxiv.org/abs/1703.10277](https://arxiv.org/abs/1703.10277)\n\n**Pose2Instance: Harnessing Keypoints for Person Instance Segmentation**\n\n[https://arxiv.org/abs/1704.01152](https://arxiv.org/abs/1704.01152)\n\n**Pixelwise Instance Segmentation with a Dynamically Instantiated Network**\n\n- intro: CVPR 2017\n- arxiv: [https://arxiv.org/abs/1704.02386](https://arxiv.org/abs/1704.02386)\n\n**Instance-Level Salient Object Segmentation**\n\n- intro: CVPR 2017\n- arxiv: [https://arxiv.org/abs/1704.03604](https://arxiv.org/abs/1704.03604)\n\n**MEnet: A Metric Expression Network for Salient Object Segmentation**\n\n- intro: IJCAI\n- arxiv: [https://arxiv.org/abs/1805.05638](https://arxiv.org/abs/1805.05638)\n\n**Semantic Instance Segmentation with a Discriminative Loss Function**\n\n- intro: Published at \"Deep Learning for Robotic Vision\", workshop at CVPR 2017\n- arxiv: [https://arxiv.org/abs/1708.02551](https://arxiv.org/abs/1708.02551)\n- github: [https://github.com/Wizaron/instance-segmentation-pytorch](https://github.com/Wizaron/instance-segmentation-pytorch)\n\n**SceneCut: Joint Geometric and Object Segmentation for Indoor Scenes**\n\n[https://arxiv.org/abs/1709.07158](https://arxiv.org/abs/1709.07158)\n\n**S4 Net: Single Stage Salient-Instance Segmentation**\n\n- arxiv: [https://arxiv.org/abs/1711.07618](https://arxiv.org/abs/1711.07618)\n- github: [https://github.com/RuochenFan/S4Net](https://github.com/RuochenFan/S4Net)\n\n**Deep Extreme Cut: From Extreme Points to Object Segmentation**\n\n[https://arxiv.org/abs/1711.09081](https://arxiv.org/abs/1711.09081)\n\n**Learning to Segment Every Thing**\n\n- intro: CVPR 2018. UC Berkeley & Facebook AI Research\n- keywords: MaskX R-CNN\n- project page: [http://ronghanghu.com/seg_every_thing/](http://ronghanghu.com/seg_every_thing/)\n- arxiv: [https://arxiv.org/abs/1711.10370](https://arxiv.org/abs/1711.10370)\n- gihtub(official, Caffe2): [https://github.com/ronghanghu/seg_every_thing](https://github.com/ronghanghu/seg_every_thing)\n\n**Recurrent Neural Networks for Semantic Instance Segmentation**\n\n- project page: [https://imatge-upc.github.io/rsis/](https://imatge-upc.github.io/rsis/)\n- arxiv: [https://arxiv.org/abs/1712.00617](https://arxiv.org/abs/1712.00617)\n- github: [https://github.com/imatge-upc/rsis](https://github.com/imatge-upc/rsis)\n\n**MaskLab: Instance Segmentation by Refining Object Detection with Semantic and Direction Features**\n\n- intro: Google Inc. & RWTH Aachen University & UCLA\n- arxiv: [https://arxiv.org/abs/1712.04837](https://arxiv.org/abs/1712.04837)\n\n**Recurrent Pixel Embedding for Instance Grouping**\n\n- intro: learning to embed pixels and group them into boundaries, object proposals, semantic segments and instances.\n- project page: [http://www.ics.uci.edu/~skong2/SMMMSG.html](http://www.ics.uci.edu/~skong2/SMMMSG.html)\n- arxiv: [https://arxiv.org/abs/1712.08273](https://arxiv.org/abs/1712.08273)\n- github: [https://github.com/aimerykong/Recurrent-Pixel-Embedding-for-Instance-Grouping](https://github.com/aimerykong/Recurrent-Pixel-Embedding-for-Instance-Grouping)\n- slides: [http://www.ics.uci.edu/~skong2/slides/pixel_embedding_for_grouping_public_version.pdf](http://www.ics.uci.edu/~skong2/slides/pixel_embedding_for_grouping_public_version.pdf)\n- poster: [http://www.ics.uci.edu/~skong2/slides/pixel_embedding_for_grouping_poster.pdf](http://www.ics.uci.edu/~skong2/slides/pixel_embedding_for_grouping_poster.pdf)\n\n**Annotation-Free and One-Shot Learning for Instance Segmentation of Homogeneous Object Clusters**\n\n[https://arxiv.org/abs/1802.00383](https://arxiv.org/abs/1802.00383)\n\n**Path Aggregation Network for Instance Segmentation**\n\n- intro: CVPR 2018 Spotlight\n- intro: CUHK & Peking University & SenseTime Research & YouTu Lab\n- keywords: PANet\n- arxiv: [https://arxiv.org/abs/1803.01534](https://arxiv.org/abs/1803.01534)\n- github: [https://github.com/ShuLiu1993/PANet](https://github.com/ShuLiu1993/PANet)\n\n**Learning to Segment via Cut-and-Paste**\n\n- intro: Google\n- keywords: weakly-supervised, adversarial learning setup\n- arxiv: [https://arxiv.org/abs/1803.06414](https://arxiv.org/abs/1803.06414)\n\n**Learning to Cluster for Proposal-Free Instance Segmentation**\n\n[https://arxiv.org/abs/1803.06459](https://arxiv.org/abs/1803.06459)\n\n**Bayesian Semantic Instance Segmentation in Open Set World**\n\n[https://arxiv.org/abs/1806.00911](https://arxiv.org/abs/1806.00911)\n\n**TernausNetV2: Fully Convolutional Network for Instance Segmentation**\n\n- arxiv: [https://arxiv.org/abs/1806.00844](https://arxiv.org/abs/1806.00844)\n- github: [https://github.com/ternaus/TernausNetV2](https://github.com/ternaus/TernausNetV2)\n\n**Dynamic Multimodal Instance Segmentation guided by natural language queries**\n\n- intro: ECCV 2018\n- arxiv: [https://arxiv.org/abs/1807.02257](https://arxiv.org/abs/1807.02257)\n- github: [https://github.com/andfoy/query-objseg](https://github.com/andfoy/query-objseg)\n\n**Traits & Transferability of Adversarial Examples against Instance Segmentation & Object Detection**\n\n[https://arxiv.org/abs/1808.01452](https://arxiv.org/abs/1808.01452)\n\n**Affinity Derivation and Graph Merge for Instance Segmentation**\n\n- intro: ECCV 2018\n- arxiv: [https://arxiv.org/abs/1811.10870](https://arxiv.org/abs/1811.10870)\n\n**One-Shot Instance Segmentation**\n\n- intro: University of Tubingen\n- arxiv: [https://arxiv.org/abs/1811.11507](https://arxiv.org/abs/1811.11507)\n\n**Hybrid Task Cascade for Instance Segmentation**\n\n- intro: CVPR 2019\n- intro: The Chinese University of Hong Kong & SenseTime Research & Zhejiang University & The University of Sydney & Nanyang Technological University\n- intro: Winning entry of COCO 2018 Challenge (object detection task)\n- arxiv: [https://arxiv.org/abs/1901.07518](https://arxiv.org/abs/1901.07518)\n- github(mmdetection): [https://github.com/open-mmlab/mmdetection/tree/master/configs/htc](https://github.com/open-mmlab/mmdetection/tree/master/configs/htc)\n\n**Mask Scoring R-CNN**\n\n- intro: CVPR 2019\n- intro: Huazhong University of Science and Technology & Horizon Robotics Inc.\n- arxiv: [https://arxiv.org/abs/1903.00241](https://arxiv.org/abs/1903.00241)\n- github: [https://github.com/zjhuang22/maskscoring_rcnn](https://github.com/zjhuang22/maskscoring_rcnn)\n\n**TensorMask: A Foundation for Dense Object Segmentation**\n\n- intro: Facebook AI Research (FAIR)\n- arxiv: [https://arxiv.org/abs/1903.12174](https://arxiv.org/abs/1903.12174)\n\n**Actor-Critic Instance Segmentation**\n\n- intro: CVPR 2019\n- keywords: reinforcement learning\n- arxiv: [https://arxiv.org/abs/1904.05126](https://arxiv.org/abs/1904.05126)\n\n**Instance Segmentation by Jointly Optimizing Spatial Embeddings and Clustering Bandwidth**\n\n- arxiv: [https://arxiv.org/abs/1906.11109](https://arxiv.org/abs/1906.11109)\n- github: [https://github.com/davyneven/SpatialEmbeddings](https://github.com/davyneven/SpatialEmbeddings)\n\n**InstaBoost: Boosting Instance Segmentation via Probability Map Guided Copy-Pasting**\n\n- intro: ICCV 2019\n- arxiv: [https://arxiv.org/abs/1908.07801](https://arxiv.org/abs/1908.07801)\n- github: [https://github.com/GothicAi/Instaboost](https://github.com/GothicAi/Instaboost)\n\n**SSAP: Single-Shot Instance Segmentation With Affinity Pyramid**\n\n- intro: ICCV 2019\n- intro: Chinese Academy of Sciences & Horizon Robotics, Inc\n- arxiv: [https://arxiv.org/abs/1909.01616](https://arxiv.org/abs/1909.01616)\n\n**YOLACT: Real-time Instance Segmentation**\n\n- intro: You Only Look At CoefficienTs\n- intro: University of California, Davis\n- keywords: one-stage, Fast NMS\n- arxiv: [https://arxiv.org/abs/1904.02689](https://arxiv.org/abs/1904.02689)\n- github(official, Pytorch): [https://github.com/dbolya/yolact](https://github.com/dbolya/yolact)\n\n**YOLACT++: Better Real-time Instance Segmentation**\n\n[https://arxiv.org/abs/1912.06218](https://arxiv.org/abs/1912.06218)\n\n**YolactEdge: Real-time Instance Segmentation on the Edge**\n\n- arxiv: [https://arxiv.org/abs/2012.12259](https://arxiv.org/abs/2012.12259)\n- github: [https://github.com/haotian-liu/yolact_edge](https://github.com/haotian-liu/yolact_edge)\n\n**PolarMask: Single Shot Instance Segmentation with Polar Representation**\n\n- intro: CVPR 2020\n- arxiv: [https://arxiv.org/abs/1909.13226](https://arxiv.org/abs/1909.13226)\n- github: [https://github.com/xieenze/PolarMask](https://github.com/xieenze/PolarMask)\n\n**PolarMask++: Enhanced Polar Representation for Single-Shot Instance Segmentation and Beyond**\n\n- intro: TPAMI 2021\n- arxiv: [https://arxiv.org/abs/2105.02184](https://arxiv.org/abs/2105.02184)\n- github: [https://github.com/xieenze/PolarMask](https://github.com/xieenze/PolarMask)\n\n**CenterMask : Real-Time Anchor-Free Instance Segmentation**\n\n- intro: CVPR 2020\n- arxiv: [https://arxiv.org/abs/1911.06667](https://arxiv.org/abs/1911.06667)\n- github: [https://github.com/youngwanLEE/CenterMask](https://github.com/youngwanLEE/CenterMask)\n- github: [https://github.com/youngwanLEE/centermask2](https://github.com/youngwanLEE/centermask2)\n\n**CenterMask: single shot instance segmentation with point representation**\n\n- intro: CVPR 2020\n- intro: Meituan Dianping Group\n- arxiv: [https://arxiv.org/abs/2004.04446](https://arxiv.org/abs/2004.04446)\n\n**Shape-aware Feature Extraction for Instance Segmentation**\n\n- intro: CVPR 2020\n- arxiv: [https://arxiv.org/abs/1911.11263](https://arxiv.org/abs/1911.11263)\n\n**PolyTransform: Deep Polygon Transformer for Instance Segmentation**\n\n[https://arxiv.org/abs/1912.02801](https://arxiv.org/abs/1912.02801)\n\n**EmbedMask: Embedding Coupling for One-stage Instance Segmentation**\n\n- arxiv: [https://arxiv.org/abs/1912.01954](https://arxiv.org/abs/1912.01954)\n- gitub: [https://github.com/yinghdb/EmbedMask](https://github.com/yinghdb/EmbedMask)\n\n**SAIS: Single-stage Anchor-free Instance Segmentation**\n\n[https://arxiv.org/abs/1912.01176](https://arxiv.org/abs/1912.01176)\n\n**SOLO: Segmenting Objects by Locations**\n\n- arxiv: [https://arxiv.org/abs/1912.04488](https://arxiv.org/abs/1912.04488)\n -github: [https://github.com/WXinlong/SOLO](https://github.com/WXinlong/SOLO)\n\n**SOLOv2: Dynamic, Faster and Stronger**\n\n- arxiv: [https://arxiv.org/abs/2003.10152](https://arxiv.org/abs/2003.10152)\n- github: [https://github.com/aim-uofa/AdelaiDet/](https://github.com/aim-uofa/AdelaiDet/)\n\n**SOLO: A Simple Framework for Instance Segmentation**\n\n- arxiv: [https://arxiv.org/abs/2106.15947](https://arxiv.org/abs/2106.15947)\n- github: [https://github.com/aim-uofa/AdelaiDet/](https://github.com/aim-uofa/AdelaiDet/)\n\n**RDSNet: A New Deep Architecture for Reciprocal Object Detection and Instance Segmentation**\n\n- intro: AAAI 2020\n- intro: Chinese Academy of Sciences & 2Horizon Robotics Inc.\n- arxiv: [https://arxiv.org/abs/1912.05070](https://arxiv.org/abs/1912.05070)\n- github: [https://github.com/wangsr126/RDSNet](https://github.com/wangsr126/RDSNet)\n\n**BlendMask: Top-Down Meets Bottom-Up for Instance Segmentation**\n\n[https://arxiv.org/abs/2001.00309](https://arxiv.org/abs/2001.00309)\n\n**Conditional Convolutions for Instance Segmentation**\n\n- intro: ECCV 2020 oral\n- intro: The University of Adelaide\n- arxiv: [https://arxiv.org/abs/2003.05664](https://arxiv.org/abs/2003.05664)\n- github: [https://github.com/aim-uofa/adet](https://github.com/aim-uofa/adet)\n\n**PointINS: Point-based Instance Segmentation**\n\n- intro: CUHK & MEGVII & Chinese Academy of Sciences & SmartMore\n- arxiv: [https://arxiv.org/abs/2003.06148](https://arxiv.org/abs/2003.06148)\n\n**1st Place Solutions for OpenImage2019 -- Object Detection and Instance Segmentation**\n\n[https://arxiv.org/abs/2003.07557](https://arxiv.org/abs/2003.07557)\n\n**Mask Encoding for Single Shot Instance Segmentation**\n\n- intro: CVPR 2020\n- intro:  Tongji University & University of Adelaide & Huawei Noahs Ark Lab\n- arxiv: [https://arxiv.org/abs/2003.11712](https://arxiv.org/abs/2003.11712)\n\n**The Devil is in Classification: A Simple Framework for Long-tail Instance Segmentation**\n\n- arxiv: [https://arxiv.org/abs/2007.11978](https://arxiv.org/abs/2007.11978)\n- github: [https://github.com/twangnh/SimCal](https://github.com/twangnh/SimCal)\n\n**Deep Variational Instance Segmentation**\n\n[https://arxiv.org/abs/2007.11576](https://arxiv.org/abs/2007.11576)\n\n**Mask Point R-CNN**\n\n[https://arxiv.org/abs/2008.00460](https://arxiv.org/abs/2008.00460)\n\n**Forest R-CNN: Large-Vocabulary Long-Tailed Object Detection and Instance Segmentation**\n\n- intro: ACM MM 2020\n- arxiv: [https://arxiv.org/abs/2008.05676](https://arxiv.org/abs/2008.05676)\n- github: [https://github.com/JialianW/Forest_RCNN](https://github.com/JialianW/Forest_RCNN)\n\n**Seesaw Loss for Long-Tailed Instance Segmentation**\n\n[https://arxiv.org/abs/2008.10032](https://arxiv.org/abs/2008.10032)\n\n**Joint COCO and Mapillary Workshop at ICCV 2019: COCO Instance Segmentation Challenge Track**\n\n- intro: 1st Place Technical Report in ICCV2019/ ECCV2020: MegDetV2\n- arxiv: [https://arxiv.org/abs/2010.02475](https://arxiv.org/abs/2010.02475)\n\n**DCT-Mask: Discrete Cosine Transform Mask Representation for Instance Segmentation**\n\n- intro: Zhejiang University & Alibaba Group\n- arxiv: [https://arxiv.org/abs/2011.09876](https://arxiv.org/abs/2011.09876)\n\n**The Devil is in the Boundary: Exploiting Boundary Representation for Basis-based Instance Segmentation**\n\n[https://arxiv.org/abs/2011.13241](https://arxiv.org/abs/2011.13241)\n\n**Robust Instance Segmentation through Reasoning about Multi-Object Occlusion**\n\n[https://arxiv.org/abs/2012.02107](https://arxiv.org/abs/2012.02107)\n\n**Simple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentation**\n\n- intro: Google Research & UC Berkeley & Cornell University\n- arxiv: [https://arxiv.org/abs/2012.07177](https://arxiv.org/abs/2012.07177)\n\n**How Shift Equivariance Impacts Metric Learning for Instance Segmentation**\n\n[https://arxiv.org/abs/2101.05846](https://arxiv.org/abs/2101.05846)\n\n**FASA: Feature Augmentation and Sampling Adaptation for Long-Tailed Instance Segmentation**\n\n- intro: Nanyang Technological University & Carnegie Mellon Universit\n- arxiv: [https://arxiv.org/abs/2102.12867](https://arxiv.org/abs/2102.12867)\n\n**Deep Occlusion-Aware Instance Segmentation with Overlapping BiLayers**\n\n- intro: CVPR 2021\n- arxiv: [https://arxiv.org/abs/2103.12340](https://arxiv.org/abs/2103.12340)\n- github: [https://github.com/lkeab/BCNet](https://github.com/lkeab/BCNet)\n- youtube: [https://www.youtube.com/watch?v=iHlGJppJGiQ](https://www.youtube.com/watch?v=iHlGJppJGiQ)\n- zhihu: [https://zhuanlan.zhihu.com/p/378269087](https://zhuanlan.zhihu.com/p/378269087)\n\n**Sparse Object-level Supervision for Instance Segmentation with Pixel Embeddings**\n\n- arxiv: [https://arxiv.org/abs/2103.14572](https://arxiv.org/abs/2103.14572)\n- github: [https://github.com/kreshuklab/spoco](https://github.com/kreshuklab/spoco)\n\n**FAPIS: A Few-shot Anchor-free Part-based Instance Segmenter**\n\n- intro: CVPR 2021\n- arxiv: [https://arxiv.org/abs/2104.00073](https://arxiv.org/abs/2104.00073)\n\n**ISTR: End-to-End Instance Segmentation with Transformers**\n\n- arxiv: [https://arxiv.org/abs/2105.00637](https://arxiv.org/abs/2105.00637)\n- github: [https://github.com/hujiecpp/ISTR](https://github.com/hujiecpp/ISTR)\n\n**Deep Occlusion-Aware Instance Segmentation with Overlapping BiLayers**\n\n- intro: CVPR 2021\n- intro: The Hong Kong University of Science and Technology & Kuaishou Technology\n- keywords: BCNet\n- arxiv: [https://arxiv.org/abs/2103.12340](https://arxiv.org/abs/2103.12340)\n- github: [https://github.com/lkeab/BCNet](https://github.com/lkeab/BCNet)\n\n**SOLQ: Segmenting Objects by Learning Queries**\n\n- intro: MEGVII Technology\n- arxiv: [https://arxiv.org/abs/2106.02351](https://arxiv.org/abs/2106.02351)\n- github: [https://github.com/megvii-research/SOLQ](https://github.com/megvii-research/SOLQ)\n\n**1st Place Solution for YouTubeVOS Challenge 2021:Video Instance Segmentation**\n\n- intro: CPVR 2021 Workshop\n- arxiv: [https://arxiv.org/abs/2106.06649](https://arxiv.org/abs/2106.06649)\n\n**Rank & Sort Loss for Object Detection and Instance Segmentation**\n\n- intro: ICCV 2021 Oral\n- arxiv: [https://arxiv.org/abs/2107.11669](https://arxiv.org/abs/2107.11669)\n- github: [https://github.com/kemaloksuz/RankSortLoss](https://github.com/kemaloksuz/RankSortLoss)\n\n**SOTR: Segmenting Objects with Transformers**\n\n- intro: ICCV 2021\n- arxiv: [https://arxiv.org/abs/2108.06747](https://arxiv.org/abs/2108.06747)\n- github: [https://github.com/easton-cau/SOTR](https://github.com/easton-cau/SOTR)\n\n**FaPN: Feature-aligned Pyramid Network for Dense Image Prediction**\n\n- intro: ICCV 2021\n- arxiv: [https://arxiv.org/abs/2108.07058](https://arxiv.org/abs/2108.07058)\n- github: [https://github.com/EMI-Group/FaPN](https://github.com/EMI-Group/FaPN)\n\n**Instances as Queries**\n\n- intro: ICCV 2021\n- intro: HUST & Tencent\n- arxiv: [https://arxiv.org/abs/2105.01928](https://arxiv.org/abs/2105.01928)\n- github: [https://github.com/hustvl/QueryInst](https://github.com/hustvl/QueryInst)\n\n**Mask Transfiner for High-Quality Instance Segmentation**\n\n- intro: ETH Zurich & HKUST & Kuaishou Technology\n- arixv: [https://arxiv.org/abs/2111.13673](https://arxiv.org/abs/2111.13673)\n\n**SOIT: Segmenting Objects with Instance-Aware Transformers**\n\n- intro: AAAI 2022\n- arxiv: [https://arxiv.org/abs/2112.11037](https://arxiv.org/abs/2112.11037)\n- github: [https://github.com/yuxiaodongHRI/SOIT](https://github.com/yuxiaodongHRI/SOIT)\n\n**ContrastMask: Contrastive Learning to Segment Every Thing**\n\n- intro: CVPR 2022\n- arxiv: [https://arxiv.org/abs/2203.09775](https://arxiv.org/abs/2203.09775)\n\n**Sparse Instance Activation for Real-Time Instance Segmentation**\n\n- intro CVPR 2022\n- intro: Huazhong University of Science & Technology & Horizon Robotics & CASIA\n- arxiv: [https://arxiv.org/abs/2203.12827](https://arxiv.org/abs/2203.12827)\n- github: [https://github.com/hustvl/SparseInst](https://github.com/hustvl/SparseInst)\n\n## Human Instance Segmentation\n\n**PersonLab: Person Pose Estimation and Instance Segmentation with a Bottom-Up, Part-Based, Geometric Embedding Model**\n\n- intro: Google, Inc.\n- keywords: Person detection and pose estimation, segmentation and grouping\n- arxiv: [https://arxiv.org/abs/1803.08225](https://arxiv.org/abs/1803.08225)\n\n**Pose2Seg: Detection Free Human Instance Segmentation**\n\n- intro: CVPR 2019\n- intro: Tsinghua Unviersity & BNRist & Tencent AI Lab & Cardiff University\n- keywords: Occluded Human (OCHuman)\n- project page: [http://www.liruilong.cn/Pose2Seg/index.html](http://www.liruilong.cn/Pose2Seg/index.html)\n- arxiv: [https://arxiv.org/abs/1803.10683](https://arxiv.org/abs/1803.10683)\n- github: [https://github.com/liruilong940607/Pose2Seg](https://github.com/liruilong940607/Pose2Seg)\n- dataset: [https://cg.cs.tsinghua.edu.cn/dataset/form.html?dataset=ochuman](https://cg.cs.tsinghua.edu.cn/dataset/form.html?dataset=ochuman)\n\n**Bounding Box Embedding for Single Shot Person Instance Segmentation**\n\n[https://arxiv.org/abs/1807.07674](https://arxiv.org/abs/1807.07674)\n\n**Parsing R-CNN for Instance-Level Human Analysis**\n\n- intro: COCO 2018 DensePose Challenge Winner\n- arxiv: [https://arxiv.org/abs/1811.12596](https://arxiv.org/abs/1811.12596)\n- github: [https://github.com/soeaver/Parsing-R-CNN](https://github.com/soeaver/Parsing-R-CNN)\n\n**Graphonomy: Universal Human Parsing via Graph Transfer Learning**\n\n- intro: CVPR 2019\n- arxiv: [https://arxiv.org/abs/1904.04536](https://arxiv.org/abs/1904.04536)\n- github: [https://github.com/Gaoyiminggithub/Graphonomy](https://github.com/Gaoyiminggithub/Graphonomy)\n\n## Video Instance Segmentation\n\n**SipMask: Spatial Information Preservation for Fast Image and Video Instance Segmentation**\n\n- intro: ECCV 2020\n- arxiv: [https://arxiv.org/abs/2007.14772](https://arxiv.org/abs/2007.14772)\n- github: [https://github.com/JialeCao001/SipMask](https://github.com/JialeCao001/SipMask)\n\n**End-to-End Video Instance Segmentation with Transformers**\n\n- intro: Meituan & The University of Adelaide\n- arxiv: [https://arxiv.org/abs/2011.14503](https://arxiv.org/abs/2011.14503)\n\n**Spatial Feature Calibration and Temporal Fusion for Effective One-stage Video Instance Segmentation**\n\n- intro: CVPR 2021\n- intro: The HongKong Polytechnic University & DAMO Academy, Alibaba Group\n- arxiv: [https://arxiv.org/abs/2104.05606](https://arxiv.org/abs/2104.05606)\n- github: [https://github.com/MinghanLi/STMask](https://github.com/MinghanLi/STMask)\n\n**Tracking Instances as Queries**\n\n- intro: HUST & Tencent PCG\n- arxiv: [https://arxiv.org/abs/2106.11963](https://arxiv.org/abs/2106.11963)\n\n**Video Mask Transfiner for High-Quality Video Instance Segmentation**\n\n- intro: ECCV 2022\n- intro: ETH Zurich & The Hong Kong University of Science and Technology & Kuaishou Technology\n- arxiv: [https://arxiv.org/abs/2207.14012](https://arxiv.org/abs/2207.14012)\n\n# Panoptic Segmentation\n\n**Panoptic Segmentation**\n\n- intro: Facebook AI Research (FAIR) & Heidelberg University\n- arxiv: [https://arxiv.org/abs/1801.00868](https://arxiv.org/abs/1801.00868)\n- slides: [http://presentations.cocodataset.org/COCO17-Invited-PanopticAlexKirillov.pdf](http://presentations.cocodataset.org/COCO17-Invited-PanopticAlexKirillov.pdf)\n\n**Panoptic Segmentation with a Joint Semantic and Instance Segmentation Network**\n\n[https://arxiv.org/abs/1809.02110](https://arxiv.org/abs/1809.02110)\n\n**Learning to Fuse Things and Stuff**\n\n- intro: Toyota Research Institute (TRI)\n- keywords: TASCNet\n- arxiv: [https://arxiv.org/abs/1812.01192](https://arxiv.org/abs/1812.01192)\n\n**Attention-guided Unified Network for Panoptic Segmentation**\n\n- intro: CVPR 2019\n- intro: University of Chinese Academy of Sciences & Horizon Robotics, Inc. & The Johns Hopkins University\n- arxiv: [https://arxiv.org/abs/1812.03904](https://arxiv.org/abs/1812.03904)\n\n**Panoptic Feature Pyramid Networks**\n\n- intro: FAIR\n- arxiv: [https://arxiv.org/abs/1901.02446](https://arxiv.org/abs/1901.02446)\n\n**UPSNet: A Unified Panoptic Segmentation Network**\n\n- intro: Uber ATG & University of Toronto & The Chinese University of Hong Kong\n- arxiv: [https://arxiv.org/abs/1901.03784](https://arxiv.org/abs/1901.03784)\n\n**Single Network Panoptic Segmentation for Street Scene Understanding**\n\n[https://arxiv.org/abs/1902.02678](https://arxiv.org/abs/1902.02678)\n\n**An End-to-End Network for Panoptic Segmentation**\n\n[https://arxiv.org/abs/1903.05027](https://arxiv.org/abs/1903.05027)\n\n**Learning Instance Occlusion for Panoptic Segmentation**\n\n[https://arxiv.org/abs/1906.05896](https://arxiv.org/abs/1906.05896)\n\n**SpatialFlow: Bridging All Tasks for Panoptic Segmentation**\n\n[https://arxiv.org/abs/1910.08787](https://arxiv.org/abs/1910.08787)\n\n**Single-Shot Panoptic Segmentation**\n\n[https://arxiv.org/abs/1911.00764](https://arxiv.org/abs/1911.00764)\n\n**SOGNet: Scene Overlap Graph Network for Panoptic Segmentation**\n\n- intro: AAAI 2020. Innovation Award in COCO 2019 challenge\n- arxiv: [https://arxiv.org/abs/1911.07527](https://arxiv.org/abs/1911.07527)\n\n**Panoptic-DeepLab: A Simple, Strong, and Fast Baseline for Bottom-Up Panoptic Segmentation**\n\n- intro: UIUC & Google Research\n- arxiv: [https://arxiv.org/abs/1911.10194](https://arxiv.org/abs/1911.10194)\n\n**PanDA: Panoptic Data Augmentation**\n\n[https://arxiv.org/abs/1911.12317](https://arxiv.org/abs/1911.12317)\n\n**Real-Time Panoptic Segmentation from Dense Detections**\n\n- intro: CVPR 2020 oral\n- arxiv: [https://arxiv.org/abs/1912.01202](https://arxiv.org/abs/1912.01202)\n- github: [https://github.com/TRI-ML/realtime_panoptic](https://github.com/TRI-ML/realtime_panoptic)\n\n**Bipartite Conditional Random Fields for Panoptic Segmentation**\n\n[https://arxiv.org/abs/1912.05307](https://arxiv.org/abs/1912.05307)\n\n**Unifying Training and Inference for Panoptic Segmentation**\n\n[https://arxiv.org/abs/2001.04982](https://arxiv.org/abs/2001.04982)\n\n**Towards Bounding-Box Free Panoptic Segmentation**\n\n- intro: SLAMcore Ltd. & Imperial College London\n- arxiv: [https://arxiv.org/abs/2002.07705](https://arxiv.org/abs/2002.07705)\n\n**A Benchmark for LiDAR-based Panoptic Segmentation based on KITTI**\n\n- project page: [http://semantic-kitti.org/](http://semantic-kitti.org/)\n- arxiv: [https://arxiv.org/abs/2003.02371](https://arxiv.org/abs/2003.02371)\n\n**Axial-DeepLab: Stand-Alone Axial-Attention for Panoptic Segmentation**\n\n- intro: Johns Hopkins University & Google Research\n- arxiv: [https://arxiv.org/abs/2003.07853](https://arxiv.org/abs/2003.07853)\n\n**EPSNet: Efficient Panoptic Segmentation Network with Cross-layer Attention Fusion**\n\n[https://arxiv.org/abs/2003.10142](https://arxiv.org/abs/2003.10142)\n\n**Pixel Consensus Voting for Panoptic Segmentation**\n\n- intro: CVPR 2020\n- arxiv: [https://arxiv.org/abs/2004.01849](https://arxiv.org/abs/2004.01849)\n\n**EfficientPS: Efficient Panoptic Segmentation**\n\n- arxiv: [https://arxiv.org/abs/2004.02307](https://arxiv.org/abs/2004.02307)\n- github: [https://github.com/DeepSceneSeg/EfficientPS](https://github.com/DeepSceneSeg/EfficientPS)\n\n**Video Panoptic Segmentation**\n\n- intro: CVPR 2020 Oral\n- intro: KAIST & Adobe Research\n- arxiv: [https://arxiv.org/abs/2006.11339](https://arxiv.org/abs/2006.11339)\n- github: [https://github.com/mcahny/vps](https://github.com/mcahny/vps)\n\n**PanoNet: Real-time Panoptic Segmentation through Position-Sensitive Feature Embedding**\n\n[https://arxiv.org/abs/2008.00192](https://arxiv.org/abs/2008.00192)\n\n**Robust Vision Challenge 2020 -- 1st Place Report for Panoptic Segmentation**\n\n[https://arxiv.org/abs/2008.10112](https://arxiv.org/abs/2008.10112)\n\n**Learning Category- and Instance-Aware Pixel Embedding for Fast Panoptic Segmentation**\n\n- intro: Chinese Academy of Sciences & Horizon Robotics\n- arxiv: [https://arxiv.org/abs/2009.13342](https://arxiv.org/abs/2009.13342)\n\n**Auto-Panoptic: Cooperative Multi-Component Architecture Search for Panoptic Segmentation**\n\n- intro: NeurIPS 2020\n- intro: Sun Yat-sen University & Huawei Noahs Ark Lab & DarkMatter AI Research\n- arxiv: [https://arxiv.org/abs/2010.16119](https://arxiv.org/abs/2010.16119)\n- github: [https://github.com/Jacobew/AutoPanoptic](https://github.com/Jacobew/AutoPanoptic)\n\n**Scaling Wide Residual Networks for Panoptic Segmentation**\n\n- intro: Google Research & Johns Hopkins University\n- arxiv: [https://arxiv.org/abs/2011.11675](https://arxiv.org/abs/2011.11675)\n\n**Fully Convolutional Networks for Panoptic Segmentation**\n\n- intro: Chinese University of Hong Kong & University of Oxford & University of Hong Kong & MEGVII Technology4\n- arxiv: [https://arxiv.org/abs/2012.00720](https://arxiv.org/abs/2012.00720)\n- github: [https://github.com/yanwei-li/PanopticFCN](https://github.com/yanwei-li/PanopticFCN)\n\n**MaX-DeepLab: End-to-End Panoptic Segmentation with Mask Transformers**\n\n- intro: Johns Hopkins University & Google Research\n- arxiv: [https://arxiv.org/abs/2012.00759](https://arxiv.org/abs/2012.00759)\n\n**Ada-Segment: Automated Multi-loss Adaptation for Panoptic Segmentation**\n\n- intro: AAAI 2021\n- intro: Sun Yat-Sen University & Huawei Noahs Ark Lab & Shanghai Jiao Tong University\n- arxiv: [https://arxiv.org/abs/2012.03603](https://arxiv.org/abs/2012.03603)\n\n**ViP-DeepLab: Learning Visual Perception with Depth-aware Video Panoptic Segmentation**\n\n- intro: Johns Hopkins University & Google Research\n- arxiv: [https://arxiv.org/abs/2012.05258](https://arxiv.org/abs/2012.05258)\n- github: [https://github.com/joe-siyuan-qiao/ViP-DeepLab](https://github.com/joe-siyuan-qiao/ViP-DeepLab)\n\n**STEP: Segmenting and Tracking Every Pixel**\n\n- intro: Technical University Munich & Google Research & RWTH Aachen University & MPI-IS and University of Tubingen\n- arxiv: [https://arxiv.org/abs/2102.11859](https://arxiv.org/abs/2102.11859)\n\n**Cross-View Regularization for Domain Adaptive Panoptic Segmentation**\n\n- intro: CVPR 2021 oral\n- arxiv: [https://arxiv.org/abs/2103.02584](https://arxiv.org/abs/2103.02584)\n\n**MaX-DeepLab: End-to-End Panoptic Segmentation with Mask Transformers**\n\n- intro: Johns Hopkins University & Google Research\n- arixv: [https://arxiv.org/abs/2012.00759](https://arxiv.org/abs/2012.00759)\n\n**Panoptic Segmentation Forecasting**\n\n- intro: CVPR 2021\n- arxiv: [https://arxiv.org/abs/2104.03962](https://arxiv.org/abs/2104.03962)\n\n**Exemplar-Based Open-Set Panoptic Segmentation Network**\n\n- intro: CVPR 2021\n- intro: Seoul National University & Adobe Research\n- project page: [https://cv.snu.ac.kr/research/EOPSN/](https://cv.snu.ac.kr/research/EOPSN/)\n- arxiv: [https://arxiv.org/abs/2105.08336](https://arxiv.org/abs/2105.08336)\n- github: [https://github.com/jd730/EOPSN](https://github.com/jd730/EOPSN)\n\n**Hierarchical Lovsz Embeddings for Proposal-free Panoptic Segmentation**\n\n- intro: CVPR 2021\n- arxiv: [https://arxiv.org/abs/2106.04555](https://arxiv.org/abs/2106.04555)\n\nP**art-aware Panoptic Segmentation**\n\n- intro: CVPR 2021\n- arxiv: [https://arxiv.org/abs/2106.06351](https://arxiv.org/abs/2106.06351)\n- github: [https://github.com/tue-mps/panoptic_parts](https://github.com/tue-mps/panoptic_parts)\n\n**Panoptic SegFormer**\n\n- intro: Nanjing University & The University of Hong Kong & NVIDIA & Caltech\n- arxiv: [https://arxiv.org/abs/2109.03814](https://arxiv.org/abs/2109.03814)\n\n**Slot-VPS: Object-centric Representation Learning for Video Panoptic Segmentation**\n\n- intro: Samsung Research China - Beijing (SRC-B) & 2Samsung Advanced Institute of Technology (SAIT) & University of Oxford & The University of Hong Kong\n- arxiv: [https://arxiv.org/abs/2112.08949](https://arxiv.org/abs/2112.08949)\n\n**CFNet: Learning Correlation Functions for One-Stage Panoptic Segmentation**\n\n- intro: Zhejiang University & Tencent Youtu Lab & Shanghai Jiao Tong University\n- arxiv: [https://arxiv.org/abs/2201.04796](https://arxiv.org/abs/2201.04796)\n\n**Panoptic, Instance and Semantic Relations: A Relational Context Encoder to Enhance Panoptic Segmentation**\n\n- intro: CVPR 2022\n- intro: Qualcomm AI Research\n- arxiv: [https://arxiv.org/abs/2204.05370](https://arxiv.org/abs/2204.05370)\n\n**PanopticDepth: A Unified Framework for Depth-aware Panoptic Segmentation**\n\n- intro: CVPR 2022\n- intro: Chinese Academy of Sciences & University of Chinese Academy of Sciences & Horizon Robotics, Inc.\n- arxiv: [https://arxiv.org/abs/2206.00468](https://arxiv.org/abs/2206.00468)\n\n**CMT-DeepLab: Clustering Mask Transformers for Panoptic Segmentation**\n\n- intro: CVPR 2022 Oral\n- intro: Johns Hopkins University & KAIST & Google Research\n- arxiv: [https://arxiv.org/abs/2206.08948](https://arxiv.org/abs/2206.08948)\n\n**Uncertainty-aware Panoptic Segmentation**\n\n- intro: Technical University Nurnberg\n- arxiv: [https://arxiv.org/abs/2206.14554](https://arxiv.org/abs/2206.14554)\n\n**k-means Mask Transformer**\n\n- intro: ECCV 2022\n- intro: Johns Hopkins University & Google Research\n- arxiv: [https://arxiv.org/abs/2207.04044](https://arxiv.org/abs/2207.04044)\n- github: [https://github.com/google-research/deeplab2](https://github.com/google-research/deeplab2)\n\n# Nightime Segmentation\n\n**Nighttime sky/cloud image segmentation**\n\n- intro: ICIP 2017\n- arxiv: [https://arxiv.org/abs/1705.10583](https://arxiv.org/abs/1705.10583)\n\n**Dark Model Adaptation: Semantic Image Segmentation from Daytime to Nighttime**\n\n- intro: International Conference on Intelligent Transportation Systems (ITSC 2018)\n- arxiv: [https://arxiv.org/abs/1810.02575](https://arxiv.org/abs/1810.02575)\n\n**Semantic Nighttime Image Segmentation with Synthetic Stylized Data, Gradual Adaptation and Uncertainty-Aware Evaluation**\n\n**Guided Curriculum Model Adaptation and Uncertainty-Aware Evaluation for Semantic Nighttime Image Segmentation**\n\n- intro: ICCV 2019\n- intro: ETH Zurich & KU Leuven\n- arxiv: [https://arxiv.org/abs/1901.05946](https://arxiv.org/abs/1901.05946)\n\n**Bi-Mix: Bidirectional Mixing for Domain Adaptive Nighttime Semantic Segmentation**\n\n- arxiv: [https://arxiv.org/abs/2111.10339](https://arxiv.org/abs/2111.10339)\n- github: [https://github.com/ygjwd12345/BiMix](https://github.com/ygjwd12345/BiMix)\n\n**DANNet: A One-Stage Domain Adaptation Network for Unsupervised Nighttime Semantic Segmentation**\n\n- intro: CVPR 2021 oral\n- intro: University of South Carolina & Farsee2 Technology Ltd\n- arxiv: [https://arxiv.org/abs/2104.10834](https://arxiv.org/abs/2104.10834)\n- github: [https://github.com/W-zx-Y/DANNet](https://github.com/W-zx-Y/DANNet)\n\n**NightLab: A Dual-level Architecture with Hardness Detection for Segmentation at Night**\n\n- intro: CVPR 2022\n- arxiv: [https://arxiv.org/abs/2204.05538](https://arxiv.org/abs/2204.05538)\n- github: [https://github.com/xdeng7/NightLab](https://github.com/xdeng7/NightLab)\n\n# Face Parsing\n\n**Face Parsing via Recurrent Propagation**\n\n- intro: BMVC 2017\n- arxiv: [https://arxiv.org/abs/1708.01936](https://arxiv.org/abs/1708.01936)\n\n**Face Parsing via a Fully-Convolutional Continuous CRF Neural Network**\n\n[https://arxiv.org/abs/1708.03736](https://arxiv.org/abs/1708.03736)\n\n**Face Parsing with RoI Tanh-Warping**\n\n- intro: Software School of Xiamen University & Microsoft Research\n- arxiv: [https://arxiv.org/abs/1906.01342](https://arxiv.org/abs/1906.01342)\n\n**End-to-End Face Parsing via Interlinked Convolutional Neural Networks**\n\n[https://arxiv.org/abs/2002.04831](https://arxiv.org/abs/2002.04831)\n\n**RoI Tanh-polar Transformer Network for Face Parsing in the Wild**\n\n- arxiv: [https://arxiv.org/abs/2102.02717](https://arxiv.org/abs/2102.02717)\n- code: [https://ibug.doc.ic.ac.uk/resources/ibugmask/](https://ibug.doc.ic.ac.uk/resources/ibugmask/)\n\n**Decoupled Multi-task Learning with Cyclical Self-Regulation for Face Parsing**\n\n- intro: CVPR 2022\n- arxiv: [https://arxiv.org/abs/2203.14448](https://arxiv.org/abs/2203.14448)\n- github: [https://github.com/deepinsight/insightface/tree/master/parsing/dml_csr](https://github.com/deepinsight/insightface/tree/master/parsing/dml_csr)\n\n# Specific Segmentation\n\n**A CNN Cascade for Landmark Guided Semantic Part Segmentation**\n\n- project page: [http://aaronsplace.co.uk/](http://aaronsplace.co.uk/)\n- paper: [https://aaronsplace.co.uk/papers/jackson2016guided/jackson2016guided.pdf](https://aaronsplace.co.uk/papers/jackson2016guided/jackson2016guided.pdf)\n\n**End-to-end semantic face segmentation with conditional random fields as convolutional, recurrent and adversarial networks**\n\n- arxiv: [https://arxiv.org/abs/1703.03305](https://arxiv.org/abs/1703.03305)\n\n**Boundary-sensitive Network for Portrait Segmentation**\n\n[https://arxiv.org/abs/1712.08675](https://arxiv.org/abs/1712.08675)\n\n**Boundary-Aware Network for Fast and High-Accuracy Portrait Segmentation**\n\n- intro: Zhejiang University\n- arxiv: [https://arxiv.org/abs/1901.03814](https://arxiv.org/abs/1901.03814)\n\n**Beef Cattle Instance Segmentation Using Fully Convolutional Neural Network**\n\n- intro: BMVC 2018\n- arxiv: [https://arxiv.org/abs/1807.01972](https://arxiv.org/abs/1807.01972)\n\n**Face Mask Extraction in Video Sequence**\n\n- keywords: ConvLSTM & FCN\n- arxiv: [https://arxiv.org/abs/1807.09207](https://arxiv.org/abs/1807.09207)\n\n# Segment Proposal\n\n**Learning to Segment Object Candidates**\n\n- intro: Facebook AI Research (FAIR)\n- intro: DeepMask. learning segmentation proposals\n- arxiv: [http://arxiv.org/abs/1506.06204](http://arxiv.org/abs/1506.06204)\n- github: [https://github.com/facebookresearch/deepmask](https://github.com/facebookresearch/deepmask)\n- github: [https://github.com/abbypa/NNProject_DeepMask](https://github.com/abbypa/NNProject_DeepMask)\n\n**Learning to Refine Object Segments**\n\n- intro: ECCV 2016. Facebook AI Research (FAIR)\n- intro: SharpMask. an extension of DeepMask which generates higher-fidelity masks using an additional top-down refinement step.\n- arxiv: [http://arxiv.org/abs/1603.08695](http://arxiv.org/abs/1603.08695)\n- github: [https://github.com/facebookresearch/deepmask](https://github.com/facebookresearch/deepmask)\n\n**FastMask: Segment Object Multi-scale Candidates in One Shot**\n\n- intro: CVPR 2017. University of California & Fudan University & Megvii Inc.\n- arxiv: [https://arxiv.org/abs/1612.08843](https://arxiv.org/abs/1612.08843)\n- github: [https://github.com/voidrank/FastMask](https://github.com/voidrank/FastMask)\n\n# Scene Labeling / Scene Parsing\n\n**Indoor Semantic Segmentation using depth information**\n\n- arxiv: [http://arxiv.org/abs/1301.3572](http://arxiv.org/abs/1301.3572)\n\n**Recurrent Convolutional Neural Networks for Scene Parsing**\n\n- arxiv: [http://arxiv.org/abs/1306.2795](http://arxiv.org/abs/1306.2795)\n- slides: [http://people.ee.duke.edu/~lcarin/Yizhe8.14.2015.pdf](http://people.ee.duke.edu/~lcarin/Yizhe8.14.2015.pdf)\n- github: [https://github.com/NP-coder/CLPS1520Project](https://github.com/NP-coder/CLPS1520Project)\n- github: [https://github.com/rkargon/Scene-Labeling](https://github.com/rkargon/Scene-Labeling)\n\n**Learning hierarchical features for scene labeling**\n\n- paper: [http://yann.lecun.com/exdb/publis/pdf/farabet-pami-13.pdf](http://yann.lecun.com/exdb/publis/pdf/farabet-pami-13.pdf)\n\n**Multi-modal unsupervised feature learning for rgb-d scene labeling**\n\n- intro: ECCV 2014\n- paper: [http://www3.ntu.edu.sg/home/wanggang/WangECCV2014.pdf](http://www3.ntu.edu.sg/home/wanggang/WangECCV2014.pdf)\n\n**Scene Labeling with LSTM Recurrent Neural Networks**\n\n- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Byeon_Scene_Labeling_With_2015_CVPR_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Byeon_Scene_Labeling_With_2015_CVPR_paper.pdf)\n\n**Attend, Infer, Repeat: Fast Scene Understanding with Generative Models**\n\n- arxiv: [http://arxiv.org/abs/1603.08575](http://arxiv.org/abs/1603.08575)\n- notes: [http://www.shortscience.org/paper?bibtexKey=journals/corr/EslamiHWTKH16](http://www.shortscience.org/paper?bibtexKey=journals/corr/EslamiHWTKH16)\n\n**\"Semantic Segmentation for Scene Understanding: Algorithms and Implementations\" tutorial**\n\n- intro: 2016 Embedded Vision Summit\n- youtube: [https://www.youtube.com/watch?v=pQ318oCGJGY](https://www.youtube.com/watch?v=pQ318oCGJGY)\n\n**Semantic Understanding of Scenes through the ADE20K Dataset**\n\n- arxiv: [https://arxiv.org/abs/1608.05442](https://arxiv.org/abs/1608.05442)\n\n**Learning Deep Representations for Scene Labeling with Guided Supervision**\n\n**Learning Deep Representations for Scene Labeling with Semantic Context Guided Supervision**\n\n- intro: CUHK\n- arxiv: [https://arxiv.org/abs/1706.02493](https://arxiv.org/abs/1706.02493)\n\n**Spatial As Deep: Spatial CNN for Traffic Scene Understanding**\n\n- intro: AAAI 2018\n- arxiv: [https://arxiv.org/abs/1712.06080](https://arxiv.org/abs/1712.06080)\n\n**Multi-Path Feedback Recurrent Neural Network for Scene Parsing**\n\n- arxiv: [http://arxiv.org/abs/1608.07706](http://arxiv.org/abs/1608.07706)\n\n**Scene Labeling using Recurrent Neural Networks with Explicit Long Range Contextual Dependency**\n\n- arxiv: [https://arxiv.org/abs/1611.07485](https://arxiv.org/abs/1611.07485)\n\n**FIFO: Learning Fog-invariant Features for Foggy Scene Segmentation**\n\n- intro: CVPR 2022\n- arxiv: [https://arxiv.org/abs/2204.01587](https://arxiv.org/abs/2204.01587)\n\n## PSPNet\n\n**Pyramid Scene Parsing Network**\n\n- intro: CVPR 2017\n- intro: mIoU score as 85.4% on PASCAL VOC 2012 and 80.2% on Cityscapes, \nranked 1st place in ImageNet Scene Parsing Challenge 2016\n- project page: [http://appsrv.cse.cuhk.edu.hk/~hszhao/projects/pspnet/index.html](http://appsrv.cse.cuhk.edu.hk/~hszhao/projects/pspnet/index.html)\n- arxiv: [https://arxiv.org/abs/1612.01105](https://arxiv.org/abs/1612.01105)\n- slides: [http://image-net.org/challenges/talks/2016/SenseCUSceneParsing.pdf](http://image-net.org/challenges/talks/2016/SenseCUSceneParsing.pdf)\n- github: [https://github.com/hszhao/PSPNet](https://github.com/hszhao/PSPNet)\n- github: [https://github.com/Vladkryvoruchko/PSPNet-Keras-tensorflow](https://github.com/Vladkryvoruchko/PSPNet-Keras-tensorflow)\n\n**Open Vocabulary Scene Parsing**\n\n[https://arxiv.org/abs/1703.08769](https://arxiv.org/abs/1703.08769)\n\n**Deep Contextual Recurrent Residual Networks for Scene Labeling**\n\n[https://arxiv.org/abs/1704.03594](https://arxiv.org/abs/1704.03594)\n\n**Fast Scene Understanding for Autonomous Driving**\n\n- intro: Published at \"Deep Learning for Vehicle Perception\", workshop at the IEEE Symposium on Intelligent Vehicles 2017\n- arxiv: [https://arxiv.org/abs/1708.02550](https://arxiv.org/abs/1708.02550)\n\n**FoveaNet: Perspective-aware Urban Scene Parsing**\n\n[https://arxiv.org/abs/1708.02421](https://arxiv.org/abs/1708.02421)\n\n**BlitzNet: A Real-Time Deep Network for Scene Understanding**\n\n- intro: INRIA\n- arxiv: [https://arxiv.org/abs/1708.02813](https://arxiv.org/abs/1708.02813)\n\n**Semantic Foggy Scene Understanding with Synthetic Data**\n\n[https://arxiv.org/abs/1708.07819](https://arxiv.org/abs/1708.07819)\n\n**Scale-adaptive Convolutions for Scene Parsing**\n\n- intro: ICCV 2017\n- paper: [http://openaccess.thecvf.com/content_ICCV_2017/papers/Zhang_Scale-Adaptive_Convolutions_for_ICCV_2017_paper.pdf](http://openaccess.thecvf.com/content_ICCV_2017/papers/Zhang_Scale-Adaptive_Convolutions_for_ICCV_2017_paper.pdf)\n\n**Restricted Deformable Convolution based Road Scene Semantic Segmentation Using Surround View Cameras**\n\n[https://arxiv.org/abs/1801.00708](https://arxiv.org/abs/1801.00708)\n\n**Dense Recurrent Neural Networks for Scene Labeling**\n\n[https://arxiv.org/abs/1801.06831](https://arxiv.org/abs/1801.06831)\n\n**DenseASPP for Semantic Segmentation in Street Scenes**\n\n- intro: CVPR 2018\n- paper: [http://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_DenseASPP_for_Semantic_CVPR_2018_paper.pdf](http://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_DenseASPP_for_Semantic_CVPR_2018_paper.pdf)\n- github: [https://github.com/DeepMotionAIResearch/DenseASPP](https://github.com/DeepMotionAIResearch/DenseASPP)\n\n**OCNet: Object Context Network for Scene Parsing**\n\n- intro: Microsoft Research\n- arxiv: [https://arxiv.org/abs/1809.00916](https://arxiv.org/abs/1809.00916)\n- github: [https://github.com/PkuRainBow/OCNet](https://github.com/PkuRainBow/OCNet)\n\n**PSANet: Point-wise Spatial Attention Network for Scene Parsing**\n\n- intro: ECCV 2018\n- project page: [https://hszhao.github.io/projects/psanet/](https://hszhao.github.io/projects/psanet/)\n- paper: [https://hszhao.github.io/papers/eccv18_psanet.pdf](https://hszhao.github.io/papers/eccv18_psanet.pdf)\n- slides: [https://docs.google.com/presentation/d/1_brKNBtv8nVu_jOwFRGwVkEPAq8B8hEngBSQuZCWaZA/edit#slide=id.p](https://docs.google.com/presentation/d/1_brKNBtv8nVu_jOwFRGwVkEPAq8B8hEngBSQuZCWaZA/edit#slide=id.p)\n- github: [https://github.com/hszhao/PSANet](https://github.com/hszhao/PSANet)\n\n**Adaptive Context Network for Scene Parsing**\n\n- intro: ICCV 2019\n- arxiv: [https://arxiv.org/abs/1911.01664](https://arxiv.org/abs/1911.01664)\n\n**Semantic Flow for Fast and Accurate Scene Parsing**\n\n- intro: ECCV 2020 oral\n- arxiv: [https://arxiv.org/abs/2002.10120](https://arxiv.org/abs/2002.10120)\n- github: [https://github.com/donnyyou/torchcv](https://github.com/donnyyou/torchcv)\n\n**Strip Pooling: Rethinking Spatial Pooling for Scene Parsing**\n\n- intro: CVPR 2020\n- arxiv: [https://arxiv.org/abs/2003.13328](https://arxiv.org/abs/2003.13328)\n- github: [https://github.com/Andrew-Qibin/SPNet](https://github.com/Andrew-Qibin/SPNet)\n\n**S3-Net: A Fast and Lightweight Video Scene Understanding Network by Single-shot Segmentation**\n\n- intro: WACV 2021\n- arxiv: [https://arxiv.org/abs/2011.02265](https://arxiv.org/abs/2011.02265)\n\n## Benchmarks\n\n**MIT Scene Parsing Benchmark**\n\n- homepage: [http://sceneparsing.csail.mit.edu/](http://sceneparsing.csail.mit.edu/)\n- github(devkit): [https://github.com/CSAILVision/sceneparsing](https://github.com/CSAILVision/sceneparsing)\n\n**Semantic Understanding of Urban Street Scenes: Benchmark Suite**\n\n[https://www.cityscapes-dataset.com/benchmarks/](https://www.cityscapes-dataset.com/benchmarks/)\n\n## Challenges\n\n**Large-scale Scene Understanding Challenge**\n\n![](http://lsun.cs.princeton.edu/img/overview_4crop.jpg)\n\n- homepage: [http://lsun.cs.princeton.edu/](http://lsun.cs.princeton.edu/)\n\n**Places2 Challenge**\n\n[http://places2.csail.mit.edu/challenge.html](http://places2.csail.mit.edu/challenge.html)\n\n# Human Parsing\n\n**Human Parsing with Contextualized Convolutional Neural Network**\n\n- intro: ICCV 2015\n- paper: [http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Liang_Human_Parsing_With_ICCV_2015_paper.html](http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Liang_Human_Parsing_With_ICCV_2015_paper.html)\n\n**Look into Person: Self-supervised Structure-sensitive Learning and A New Benchmark for Human Parsing**\n\n- intro: CVPR 2017. SYSU & CMU\n- keywords: Look Into Person (LIP)\n- project page: [http://hcp.sysu.edu.cn/lip/](http://hcp.sysu.edu.cn/lip/)\n- arxiv: [https://arxiv.org/abs/1703.05446](https://arxiv.org/abs/1703.05446)\n- github: [https://github.com/Engineering-Course/LIP_SSL](https://github.com/Engineering-Course/LIP_SSL)\n\n**Multiple-Human Parsing in the Wild**\n\n[https://arxiv.org/abs/1705.07206](https://arxiv.org/abs/1705.07206)\n\n**Look into Person: Joint Body Parsing & Pose Estimation Network and A New Benchmark**\n\n- intro: T-PAMI 2018\n- keywords: Joint Body Parsing & Pose Estimation Network (JPPNet)\n- arxiv: [https://arxiv.org/abs/1804.01984](https://arxiv.org/abs/1804.01984)\n- github: [https://github.com/Engineering-Course/LIP_JPPNet](https://github.com/Engineering-Course/LIP_JPPNet)\n\n**Cross-domain Human Parsing via Adversarial Feature and Label Adaptation**\n\n- intro: AAAI 2018\n- arxiv: [https://arxiv.org/abs/1801.01260](https://arxiv.org/abs/1801.01260)\n\n**Fusing Hierarchical Convolutional Features for Human Body Segmentation and Clothing Fashion Classification**\n\n- intro: Wuhan University\n- arxiv: [https://arxiv.org/abs/1803.03415](https://arxiv.org/abs/1803.03415)\n\n**Understanding Humans in Crowded Scenes: Deep Nested Adversarial Learning and A New Benchmark for Multi-Human Parsing**\n\n- arxiv: [https://arxiv.org/abs/1804.03287](https://arxiv.org/abs/1804.03287)\n- github: [https://github.com/ZhaoJ9014/Multi-Human-Parsing](https://github.com/ZhaoJ9014/Multi-Human-Parsing)\n\n**Macro-Micro Adversarial Network for Human Parsing**\n\n- intro: ECCV 2018\n- keywords: Macro-Micro Adversarial Net (MMAN)\n- arxiv: [https://arxiv.org/abs/1807.08260](https://arxiv.org/abs/1807.08260)\n- github: [https://github.com/RoyalVane/MMAN](https://github.com/RoyalVane/MMAN)\n\n**Instance-level Human Parsing via Part Grouping Network**\n\n- intro: ECCV 2018 Oral\n- arxiv: [https://arxiv.org/abs/1808.00157](https://arxiv.org/abs/1808.00157)\n\n**Adaptive Temporal Encoding Network for Video Instance-level Human Parsing**\n\n- intro: ACM MM 2018\n= arixv: [https://arxiv.org/abs/1808.00661](https://arxiv.org/abs/1808.00661)\n- github(official, TensorFlow): [https://github.com/HCPLab-SYSU/ATEN](https://github.com/HCPLab-SYSU/ATEN)\n\n**Devil in the Details: Towards Accurate Single and Multiple Human Parsing**\n\n- keywords: Context Embedding with Edge Perceiving (CE2P)\n- arxiv: [https://arxiv.org/abs/1809.05996](https://arxiv.org/abs/1809.05996)\n- github: [https://github.com/liutinglt/CE2P](https://github.com/liutinglt/CE2P)\n\n**Cross-Domain Complementary Learning with Synthetic Data for Multi-Person Part Segmentation**\n\n- intro: University of Washington & Microsof\n- arxiv: [https://arxiv.org/abs/1907.05193](https://arxiv.org/abs/1907.05193)\n\n**Self-Correction for Human Parsing**\n\n- arxiv: [https://arxiv.org/abs/1910.09777](https://arxiv.org/abs/1910.09777)\n- github: [https://github.com/PeikeLi/Self-Correction-Human-Parsing](https://github.com/PeikeLi/Self-Correction-Human-Parsing)\n\n**Grapy-ML: Graph Pyramid Mutual Learning for Cross-dataset Human Parsing**\n\n- intro: AAAI 2020\n- arxiv: [https://arxiv.org/abs/1911.12053](https://arxiv.org/abs/1911.12053)\n- github: [https://github.com/Charleshhy/Grapy-ML](https://github.com/Charleshhy/Grapy-ML)\n\n**Learning Semantic Neural Tree for Human Parsing**\n\n- intro: Institute of Software Chinese Academy of Sciences & State University of New York & JD Finance America Corporation & Tencent Youtu Lab\n- arxiv: [https://arxiv.org/abs/1912.09622](https://arxiv.org/abs/1912.09622)\n- code: [https://isrc.iscas.ac.cn/gitlab/research/sematree](https://isrc.iscas.ac.cn/gitlab/research/sematree)\n\n**Self-Learning with Rectification Strategy for Human Parsing**\n\n- intro: CVPR 2020\n- arxiv: [https://arxiv.org/abs/2004.08055](https://arxiv.org/abs/2004.08055)\n\n**Correlating Edge, Pose with Parsing**\n\n- intro: CVPR 2020\n- arxiv: [https://arxiv.org/abs/2005.01431](https://arxiv.org/abs/2005.01431)\n- github: [https://github.com/ziwei-zh/CorrPM](https://github.com/ziwei-zh/CorrPM)\n\n**Affinity-aware Compression and Expansion Network for Human Parsing**\n\n[https://arxiv.org/abs/2008.10191](https://arxiv.org/abs/2008.10191)\n\n**Renovating Parsing R-CNN for Accurate Multiple Human Parsing**\n\n- intro: ECCV 2020\n- intro: BUPT & Noahs Ark Lab, Huawei Technologies\n- arxiv: [https://arxiv.org/abs/2009.09447](https://arxiv.org/abs/2009.09447)\n- github: [https://github.com/soeaver/RP-R-CNN](https://github.com/soeaver/RP-R-CNN)\n\n**Progressive One-shot Human Parsing**\n\n- intro: AAAI 2021\n- arxiv: [https://arxiv.org/abs/2012.11810](https://arxiv.org/abs/2012.11810)\n- github: [https://github.com/Charleshhy/One-shot-Human-Parsing](https://github.com/Charleshhy/One-shot-Human-Parsing)\n\n**Differentiable Multi-Granularity Human Representation Learning for Instance-Aware Human Semantic Parsing**\n\n- intro: CVPR 2021 oral\n- arxiv: [https://arxiv.org/abs/2103.04570](https://arxiv.org/abs/2103.04570)\n- github: [https://github.com/tfzhou/MG-HumanParsing](https://github.com/tfzhou/MG-HumanParsing)\n\n**Quality-Aware Network for Human Parsing**\n\n- intro: BUPT & Institute of Automation Chinese Academy of Sciences & 3Noahs Ark Lab\n- arxiv: [https://arxiv.org/abs/2103.05997](https://arxiv.org/abs/2103.05997)\n- github(Pytorch): [https://github.com/soeaver/QANet](https://github.com/soeaver/QANet)\n\n**End-to-end One-shot Human Parsing**\n\n[https://arxiv.org/abs/2105.01241](https://arxiv.org/abs/2105.01241)\n\n**CDGNet: Class Distribution Guided Network for Human Parsing**\n\n- intro: Ajou University & Tiangong University & Incheon National University\n- arxiv: [https://arxiv.org/abs/2111.14173](https://arxiv.org/abs/2111.14173)\n\n**AIParsing: Anchor-free Instance-level Human Parsing**\n\n- intro: IEEE Transactions on Image Processing (TIP)\n- arxiv: [https://arxiv.org/abs/2207.06854](https://arxiv.org/abs/2207.06854)\n\n# Joint Detection and Segmentation\n\n**Triply Supervised Decoder Networks for Joint Detection and Segmentation**\n\n[https://arxiv.org/abs/1809.09299](https://arxiv.org/abs/1809.09299)\n\n**D2Det: Towards High Quality Object Detection and Instance Segmentation**\n\n- intro: CVPR 2020\n- paper: [https://openaccess.thecvf.com/content_CVPR_2020/papers/Cao_D2Det_Towards_High_Quality_Object_Detection_and_Instance_Segmentation_CVPR_2020_paper.pdf](https://openaccess.thecvf.com/content_CVPR_2020/papers/Cao_D2Det_Towards_High_Quality_Object_Detection_and_Instance_Segmentation_CVPR_2020_paper.pdf)\n- github: [https://github.com/JialeCao001/D2Det](https://github.com/JialeCao001/D2Det)\n\n# Video Object Segmentation\n\n**Fast object segmentation in unconstrained video**\n\n- project page: [http://calvin.inf.ed.ac.uk/software/fast-video-segmentation/](http://calvin.inf.ed.ac.uk/software/fast-video-segmentation/)\n- paper: [http://calvin.inf.ed.ac.uk/wp-content/uploads/Publications/papazoglouICCV2013-camera-ready.pdf](http://calvin.inf.ed.ac.uk/wp-content/uploads/Publications/papazoglouICCV2013-camera-ready.pdf)\n\n**Recurrent Fully Convolutional Networks for Video Segmentation**\n\n- arxiv: [https://arxiv.org/abs/1606.00487](https://arxiv.org/abs/1606.00487)\n\n**Object Detection, Tracking, and Motion Segmentation for Object-level Video Segmentation**\n\n- arxiv: [http://arxiv.org/abs/1608.03066](http://arxiv.org/abs/1608.03066)\n\n**Clockwork Convnets for Video Semantic Segmentation**\n\n- intro: ECCV 2016 Workshops\n- intro: evaluated on the Youtube-Objects, NYUD, and Cityscapes video datasets\n- arxiv: [http://arxiv.org/abs/1608.03609](http://arxiv.org/abs/1608.03609)\n- github: [https://github.com/shelhamer/clockwork-fcn](https://github.com/shelhamer/clockwork-fcn)\n\n**STFCN: Spatio-Temporal FCN for Semantic Video Segmentation**\n\n- arxiv: [http://arxiv.org/abs/1608.05971](http://arxiv.org/abs/1608.05971)\n\n**One-Shot Video Object Segmentation**\n\n- intro: OSVOS\n- project: [http://www.vision.ee.ethz.ch/~cvlsegmentation/osvos/](http://www.vision.ee.ethz.ch/~cvlsegmentation/osvos/)\n- arxiv: [https://arxiv.org/abs/1611.05198](https://arxiv.org/abs/1611.05198)\n- github(official): [https://github.com/kmaninis/OSVOS-caffe](https://github.com/kmaninis/OSVOS-caffe)\n- github(official): [https://github.com/scaelles/OSVOS-TensorFlow](https://github.com/scaelles/OSVOS-TensorFlow)\n- github(official): [https://github.com/kmaninis/OSVOS-PyTorch](https://github.com/kmaninis/OSVOS-PyTorch)\n\n**DAVIS: Densely Annotated VIdeo Segmentation**\n\n- homepage: [http://davischallenge.org/](http://davischallenge.org/)\n- arxiv: [https://arxiv.org/abs/1704.00675](https://arxiv.org/abs/1704.00675)\n\n**Video Object Segmentation Without Temporal Information**\n\n[https://arxiv.org/abs/1709.06031](https://arxiv.org/abs/1709.06031)\n\n**Convolutional Gated Recurrent Networks for Video Segmentation**\n\n- arxiv: [https://arxiv.org/abs/1611.05435](https://arxiv.org/abs/1611.05435)\n\n**Learning Video Object Segmentation from Static Images**\n\n- arxiv: [https://arxiv.org/abs/1612.02646](https://arxiv.org/abs/1612.02646)\n\n**Semantic Video Segmentation by Gated Recurrent Flow Propagation**\n\n- arxiv: [https://arxiv.org/abs/1612.08871](https://arxiv.org/abs/1612.08871)\n\n**FusionSeg: Learning to combine motion and appearance for fully automatic segmention of generic objects in videos**\n\n- project page: [http://vision.cs.utexas.edu/projects/fusionseg/](http://vision.cs.utexas.edu/projects/fusionseg/)\n- arxiv: [https://arxiv.org/abs/1701.05384](https://arxiv.org/abs/1701.05384)\n- github: [https://github.com/suyogduttjain/fusionseg](https://github.com/suyogduttjain/fusionseg)\n\n**Unsupervised learning from video to detect foreground objects in single images**\n\n[https://arxiv.org/abs/1703.10901](https://arxiv.org/abs/1703.10901)\n\n**Semantically-Guided Video Object Segmentation**\n\n[https://arxiv.org/abs/1704.01926](https://arxiv.org/abs/1704.01926)\n\n**Learning Video Object Segmentation with Visual Memory**\n\n[https://arxiv.org/abs/1704.05737](https://arxiv.org/abs/1704.05737)\n\n**Flow-free Video Object Segmentation**\n\n[https://arxiv.org/abs/1706.09544](https://arxiv.org/abs/1706.09544)\n\n**Online Adaptation of Convolutional Neural Networks for Video Object Segmentation**\n\n[https://arxiv.org/abs/1706.09364](https://arxiv.org/abs/1706.09364)\n\n**Video Object Segmentation using Tracked Object Proposals**\n\n- intro: CVPR-2017 workshop, DAVIS-2017 Challenge\n- arxiv: [https://arxiv.org/abs/1707.06545](https://arxiv.org/abs/1707.06545)\n\n**Video Object Segmentation with Re-identification**\n\n- intro: CVPR 2017 Workshop, DAVIS Challenge on Video Object Segmentation 2017 (Winning Entry)\n- arxiv: [https://arxiv.org/abs/1708.00197](https://arxiv.org/abs/1708.00197)\n- github(official, PyTorch): [https://github.com/lxx1991/VS-ReID](https://github.com/lxx1991/VS-ReID)\n\n**Pixel-Level Matching for Video Object Segmentation using Convolutional Neural Networks**\n\n- intro: ICCV 2017\n- arxiv: [https://arxiv.org/abs/1708.05137](https://arxiv.org/abs/1708.05137)\n\n**MaskRNN: Instance Level Video Object Segmentation**\n\n- intro: NIPS 2017\n- arxiv: [https://arxiv.org/abs/1803.11187](https://arxiv.org/abs/1803.11187)\n\n**SegFlow: Joint Learning for Video Object Segmentation and Optical Flow**\n\n- project page: [https://sites.google.com/site/yihsuantsai/research/iccv17-segflow](https://sites.google.com/site/yihsuantsai/research/iccv17-segflow)\n- arxiv: [https://arxiv.org/abs/1709.06750](https://arxiv.org/abs/1709.06750)\n- github: [https://github.com/JingchunCheng/SegFlow](https://github.com/JingchunCheng/SegFlow)\n\n**Video Semantic Object Segmentation by Self-Adaptation of DCNN**\n\n[https://arxiv.org/abs/1711.08180](https://arxiv.org/abs/1711.08180)\n\n**Learning to Segment Moving Objects**\n\n[https://arxiv.org/abs/1712.01127](https://arxiv.org/abs/1712.01127)\n\n**Instance Embedding Transfer to Unsupervised Video Object Segmentation**\n\n- intro: University of Southern California & Google Inc\n- arxiv: [https://arxiv.org/abs/1801.00908](https://arxiv.org/abs/1801.00908)\n- blog: [https://medium.com/@barvinograd1/instance-embedding-instance-segmentation-without-proposals-31946a7c53e1](https://medium.com/@barvinograd1/instance-embedding-instance-segmentation-without-proposals-31946a7c53e1)\n\n**Efficient Video Object Segmentation via Network Modulation**\n\n- intro: Snap Inc. & Northwestern University & Google Inc.\n- arxiv: [https://arxiv.org/abs/1802.01218](https://arxiv.org/abs/1802.01218)\n\n**Video Object Segmentation with Joint Re-identification and Attention-Aware Mask Propagation**\n\n- intro: ECCV 2018\n- intro: CUHK\n- keywords: DyeNet\n- arxiv: [https://arxiv.org/abs/1803.04242](https://arxiv.org/abs/1803.04242)\n\n**Video Object Segmentation with Language Referring Expressions**\n\n[https://arxiv.org/abs/1803.08006](https://arxiv.org/abs/1803.08006)\n\n**Dynamic Video Segmentation Network**\n\n- intro: CVPR 2018\n- keywords: DVSNet\n- arxiv: [https://arxiv.org/abs/1804.00931](https://arxiv.org/abs/1804.00931)\n- github: [https://github.com/XUSean0118/DVSNet](https://github.com/XUSean0118/DVSNet)\n\n**Low-Latency Video Semantic Segmentation**\n\n- intro: CVPR 2018 Spotlight\n- arxiv: [https://arxiv.org/abs/1804.00389](https://arxiv.org/abs/1804.00389)\n\n**Blazingly Fast Video Object Segmentation with Pixel-Wise Metric Learning**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1804.03131](https://arxiv.org/abs/1804.03131)\n\n**Unsupervised Video Object Segmentation for Deep Reinforcement Learning**\n\n- intro: University of Waterloo\n- arxiv: [https://arxiv.org/abs/1805.07780](https://arxiv.org/abs/1805.07780)\n\n**Fast and Accurate Online Video Object Segmentation via Tracking Parts**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1806.02323](https://arxiv.org/abs/1806.02323)\n- github: [https://github.com/JingchunCheng/FAVOS](https://github.com/JingchunCheng/FAVOS)\n\n**ReConvNet: Video Object Segmentation with Spatio-Temporal Features Modulation**\n\n- intro: CVPR Workshop - DAVIS Challenge 2018\n- arxiv: [https://arxiv.org/abs/1806.05510](https://arxiv.org/abs/1806.05510)\n\n**Deep Spatio-Temporal Random Fields for Efficient Video Segmentation**\n\n- intro: CVPR 2018\n- arxiv: [https://arxiv.org/abs/1807.03148](https://arxiv.org/abs/1807.03148)\n\n**Fast Video Object Segmentation by Reference-Guided Mask Propagation**\n\n- intro: CVPR 2018\n- paper: [http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/1029.pdf](http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/1029.pdf)\n- github: [https://github.com/seoungwugoh/RGMP](https://github.com/seoungwugoh/RGMP)\n\n**PReMVOS: Proposal-generation, Refinement and Merging for Video Object Segmentation**\n\n[https://arxiv.org/abs/1807.09190](https://arxiv.org/abs/1807.09190)\n\n**YouTube-VOS: Sequence-to-Sequence Video Object Segmentation**\n\n- intro: ECCV 2018. Adobe Research & Snapchat Research & UIUC\n- project page:[https://youtube-vos.org/](https://youtube-vos.org/)\n- arxiv: [https://arxiv.org/abs/1809.00461](https://arxiv.org/abs/1809.00461)\n\n**VideoMatch: Matching based Video Object Segmentation**\n\n- intro: ECCV 2018\n- arxiv: [https://arxiv.org/abs/1809.01123](https://arxiv.org/abs/1809.01123)\n\n**Mask Propagation Network for Video Object Segmentation**\n\n- intro: ByteDance AI Lab\n- arxiv: [https://arxiv.org/abs/1810.10289](https://arxiv.org/abs/1810.10289)\n\n**Tukey-Inspired Video Object Segmentation**\n\n[https://arxiv.org/abs/1811.07958](https://arxiv.org/abs/1811.07958)\n\n**A Generative Appearance Model for End-to-end Video Object Segmentation**\n\n[https://arxiv.org/abs/1811.11611](https://arxiv.org/abs/1811.11611)\n\n**Unseen Object Segmentation in Videos via Transferable Representations**\n\n- intro: ACCV 2018 oral\n- arxiv: [https://arxiv.org/abs/1901.02444](https://arxiv.org/abs/1901.02444)\n- github: [https://github.com/wenz116/TransferSeg](https://github.com/wenz116/TransferSeg)\n\n**FEELVOS: Fast End-to-End Embedding Learning for Video Object Segmentation**\n\n- intro: CVPR 2019\n- intro: RWTH Aachen University & Google Inc.\n- arxiv: [https://arxiv.org/abs/1902.09513](https://arxiv.org/abs/1902.09513)\n\n**RVOS: End-to-End Recurrent Network for Video Object Segmentation**\n\n- intro: CVPR 2019\n- project page: [https://imatge-upc.github.io/rvos/](https://imatge-upc.github.io/rvos/)\n- arxiv: [https://arxiv.org/abs/1903.05612](https://arxiv.org/abs/1903.05612)\n\n**BubbleNets: Learning to Select the Guidance Frame in Video Object Segmentation by Deep Sorting Frames**\n\n- intro: CVPR 2019\n- intro: University of Michigan\n- arxiv: [https://arxiv.org/abs/1903.11779](https://arxiv.org/abs/1903.11779)\n- github: [https://github.com/griffbr/BubbleNets](https://github.com/griffbr/BubbleNets)\n- video: [https://www.youtube.com/watch?v=0kNmm8SBnnU&feature=youtu.be](https://www.youtube.com/watch?v=0kNmm8SBnnU&feature=youtu.be)\n\n**Fast video object segmentation with Spatio-Temporal GANs**\n\n[https://arxiv.org/abs/1903.12161](https://arxiv.org/abs/1903.12161)\n\n**Video Object Segmentation using Space-Time Memory Networks**\n\n- intro: ICCV 2019\n- intro: Yonsei University & Adobe Research\n- arxiv: [https://arxiv.org/abs/1904.00607](https://arxiv.org/abs/1904.00607)\n- github: [https://github.com/seoungwugoh/STM](https://github.com/seoungwugoh/STM)\n\n**Spatiotemporal CNN for Video Object Segmentation**\n\n[https://arxiv.org/abs/1904.02363]\n\n**Architecture Search of Dynamic Cells for Semantic Video Segmentation**\n\n[https://arxiv.org/abs/1904.02371](https://arxiv.org/abs/1904.02371)\n\n**BoLTVOS: Box-Level Tracking for Video Object Segmentation**\n\n[https://arxiv.org/abs/1904.04552](https://arxiv.org/abs/1904.04552)\n\n**MAIN: Multi-Attention Instance Network for Video Segmentation**\n\n[https://arxiv.org/abs/1904.05847](https://arxiv.org/abs/1904.05847)\n\n**MHP-VOS: Multiple Hypotheses Propagation for Video Object Segmentation**\n\n- intro: CVPR 2019 oral\n- arxiv: [https://arxiv.org/abs/1904.08141](https://arxiv.org/abs/1904.08141)\n\n**Video Instance Segmentation**\n\n- intro: ICCV 2019\n- intro: ByteDance AI Lab & UIUC & Adobe Research\n- keywords: MaskTrack R-CNN\n- arxiv: [https://arxiv.org/abs/1905.04804](https://arxiv.org/abs/1905.04804)\n- github: [https://github.com/youtubevos/MaskTrackRCNN](https://github.com/youtubevos/MaskTrackRCNN)\n\n**OVSNet : Towards One-Pass Real-Time Video Object Segmentation**\n\n- intro: Zhejiang University & SenseTime Research & Tianjin University]\n- arxiv: [https://arxiv.org/abs/1905.10064](https://arxiv.org/abs/1905.10064)\n\n**Proposal, Tracking and Segmentation (PTS): A Cascaded Network for Video Object Segmentation**\n\n- intro: Huazhong University of Science and Technology & Horizon Robotics\n- arxiv: [https://arxiv.org/abs/1907.01203](https://arxiv.org/abs/1907.01203)\n- github: [https://github.com/sydney0zq/PTSNet](https://github.com/sydney0zq/PTSNet)\n\n**RANet: Ranking Attention Network for Fast Video Object Segmentation**\n\n- intro: ICCV 2019\n- arxiv: [https://arxiv.org/abs/1908.06647](https://arxiv.org/abs/1908.06647)\n- github: [https://github.com/Storife/RANet](https://github.com/Storife/RANet)\n\n**DMM-Net: Differentiable Mask-Matching Network for Video Object Segmentation**\n\n- intro: ICCV 2019\n- arxiv: [https://arxiv.org/abs/1909.12471](https://arxiv.org/abs/1909.12471)\n\n**CapsuleVOS: Semi-Supervised Video Object Segmentation Using Capsule Routing**\n\n- intro: ICCV 2019\n- arxiv: [https://arxiv.org/abs/1910.00132](https://arxiv.org/abs/1910.00132)\n\n**Towards Good Practices for Video Object Segmentation**\n\n- intro: ByteDance AI Lab\n- arxiv: [https://arxiv.org/abs/1909.13583](https://arxiv.org/abs/1909.13583)\n\n**Anchor Diffusion for Unsupervised Video Object Segmentation**\n\n- intro: ICCV 2019\n- arxiv: [https://arxiv.org/abs/1910.10895](https://arxiv.org/abs/1910.10895)\n\n**Learning a Spatio-Temporal Embedding for Video Instance Segmentation**\n\n- intro: University of Cambridge\n- arxiv: [https://arxiv.org/abs/1912.08969](https://arxiv.org/abs/1912.08969)\n\n**Efficient Semantic Video Segmentation with Per-frame Inference**\n\n- intro: ECCV 2020\n- intro: The University of Adelaide & Huazhong University of Science and Technology & Microsoft Research\n- arxiv: [https://arxiv.org/abs/2002.11433](https://arxiv.org/abs/2002.11433)\n- github: [https://github.com/irfanICMLL/ETC-Real-time-Per-frame-Semantic-video-segmentation](https://github.com/irfanICMLL/ETC-Real-time-Per-frame-Semantic-video-segmentation)\n\n**State-Aware Tracker for Real-Time Video Object Segmentation**\n\n- intro: CVPR 2020\n- arxiv: [https://arxiv.org/abs/2003.00482](https://arxiv.org/abs/2003.00482)\n- github: [https://github.com/MegviiDetection/video_analyst](https://github.com/MegviiDetection/video_analyst)\n\n**Video Object Segmentation with Adaptive Feature Bank and Uncertain-Region Refinement**\n\n- intro: NeurIPS 2020\n- arxiv: [https://arxiv.org/abs/2010.07958](https://arxiv.org/abs/2010.07958)\n\n**SwiftNet: Real-time Video Object Segmentation**\n\n[https://arxiv.org/abs/2102.04604](https://arxiv.org/abs/2102.04604)\n\n**SG-Net: Spatial Granularity Network for One-Stage Video Instance Segmentation**\n\n[https://arxiv.org/abs/2103.10284](https://arxiv.org/abs/2103.10284)\n\n## Challenge\n\n**DAVIS Challenge on Video Object Segmentation 2017**\n\n[http://davischallenge.org/challenge2017/publications.html](http://davischallenge.org/challenge2017/publications.html)\n\n# Matting\n\n**Deep Image Matting**\n\n- intro: CVPR 2017\n- intro: Beckman Institute for Advanced Science and Technology & Adobe Research\n- project page: [https://sites.google.com/view/deepimagematting](https://sites.google.com/view/deepimagematting)\n- arxiv: [https://arxiv.org/abs/1703.03872](https://arxiv.org/abs/1703.03872)\n- github(unofficial): [https://github.com/open-mmlab/mmediting/tree/master/configs/mattors/dim](https://github.com/open-mmlab/mmediting/tree/master/configs/mattors/dim)\n- github(unofficial): [https://github.com/foamliu/Deep-Image-Matting](https://github.com/foamliu/Deep-Image-Matting)\n- github(unofficial): [https://github.com/foamliu/Deep-Image-Matting-PyTorch](https://github.com/foamliu/Deep-Image-Matting-PyTorch)\n- github(unofficial): [https://github.com/huochaitiantang/pytorch-deep-image-matting](https://github.com/huochaitiantang/pytorch-deep-image-matting)\n\n**Fast Deep Matting for Portrait Animation on Mobile Phone**\n\n- intro: ACM Multimedia Conference (MM) 2017\n- intro: does not need any interaction and can realize real-time matting with 15 fps\n- arxiv: [https://arxiv.org/abs/1707.08289](https://arxiv.org/abs/1707.08289)\n\n**Real-time deep hair matting on mobile devices**\n\n- intro: ModiFace Inc, University of Toronto\n- arxiv: [https://arxiv.org/abs/1712.07168](https://arxiv.org/abs/1712.07168)\n\n**TOM-Net: Learning Transparent Object Matting from a Single Image**\n\n- intro: CVPR 2018\n- project page: [http://gychen.org/TOM-Net/](http://gychen.org/TOM-Net/)\n- arxiv: [https://arxiv.org/abs/1803.04636](https://arxiv.org/abs/1803.04636)\n- github: [https://github.com/guanyingc/TOM-Net](https://github.com/guanyingc/TOM-Net)\n\n**Deep Video Portraits**\n\n- intro: SIGGRAPH 2018\n- arxiv: [https://arxiv.org/abs/1805.11714](https://arxiv.org/abs/1805.11714)\n- youtube: [https://www.youtube.com/watch?v=qc5P2bvfl44](https://www.youtube.com/watch?v=qc5P2bvfl44)\n\n**Inductive Guided Filter: Real-time Deep Image Matting with Weakly Annotated Masks on Mobile Devices**\n\n- intro: Shanghai Jiao Tong University & Versa\n- arxiv: [https://arxiv.org/abs/1905.06747](https://arxiv.org/abs/1905.06747)\n\n**Indices Matter: Learning to Index for Deep Image Matting**\n\n- intro: ICCV 2019\n- arxiv: [https://arxiv.org/abs/1908.00672](https://arxiv.org/abs/1908.00672)\n- github(official): [https://github.com/poppinace/indexnet_matting](https://github.com/poppinace/indexnet_matting)\n- github: [https://github.com/open-mmlab/mmediting/tree/master/configs/mattors/indexnet](https://github.com/open-mmlab/mmediting/tree/master/configs/mattors/indexnet)\n\n**Disentangled Image Matting**\n\n[https://arxiv.org/abs/1909.04686](https://arxiv.org/abs/1909.04686)\n\n**Natural Image Matting via Guided Contextual Attention**\n\n- intro: AAAI 2020\n- arxiv: [https://arxiv.org/abs/2001.04069](https://arxiv.org/abs/2001.04069)\n- github: [https://github.com/Yaoyi-Li/GCA-Matting](https://github.com/Yaoyi-Li/GCA-Matting)\n\n**F, B, Alpha Matting**\n\n- intro: ECCV 2020\n- arxiv: [https://arxiv.org/abs/2003.07711](https://arxiv.org/abs/2003.07711)\n- github: [https://github.com/MarcoForte/FBA_Matting](https://github.com/MarcoForte/FBA_Matting)\n\n**Background Matting: The World is Your Green Screen**\n\n- intro: CVPR 2020\n- intro: University of Washington\n- project page: [https://grail.cs.washington.edu/projects/background-matting/](https://grail.cs.washington.edu/projects/background-matting/)\n- arxiv: [https://arxiv.org/abs/2004.00626](https://arxiv.org/abs/2004.00626)\n- github: [https://github.com/senguptaumd/Background-Matting](https://github.com/senguptaumd/Background-Matting)\n- blog: [https://towardsdatascience.com/background-matting-the-world-is-your-green-screen-83a3c4f0f635](https://towardsdatascience.com/background-matting-the-world-is-your-green-screen-83a3c4f0f635)\n\n**Hierarchical Opacity Propagation for Image Matting**\n\n- intro: Shanghai Jiao Tong University\n- arxiv: [https://arxiv.org/abs/2004.03249](https://arxiv.org/abs/2004.03249)\n- github: [https://github.com/Yaoyi-Li/HOP-Matting](https://github.com/Yaoyi-Li/HOP-Matting)\n\n**High-Resolution Deep Image Matting**\n\n- intro: UIUC & Adobe Research & University of Oregon\n- arxiv: [https://arxiv.org/abs/2009.06613](https://arxiv.org/abs/2009.06613)\n\n**Learning Affinity-Aware Upsampling for Deep Image Matting**\n\n- intro: The University of Adelaide & Huazhong University of Science and Technology\n- arxiv: [https://arxiv.org/abs/2011.14288](https://arxiv.org/abs/2011.14288)\n\n**Real-Time High-Resolution Background Matting**\n\n- project page: [https://grail.cs.washington.edu/projects/background-matting-v2/](https://grail.cs.washington.edu/projects/background-matting-v2/)\n- arxiv: [https://arxiv.org/abs/2012.07810](https://arxiv.org/abs/2012.07810)\n- github: [https://github.com/PeterL1n/BackgroundMattingV2](https://github.com/PeterL1n/BackgroundMattingV2)\n\n**Deep Video Matting via Spatio-Temporal Alignment and Aggregation**\n\n- intro: CVPR 2021\n- arxiv: [https://arxiv.org/abs/2104.11208](https://arxiv.org/abs/2104.11208)\n- github: [https://github.com/nowsyn/DVM](https://github.com/nowsyn/DVM)\n\n**Trimap-guided Feature Mining and Fusion Network for Natural Image Matting**\n\n- intro: Shanghai Jiao Tong University & ByteDance Inc.\n- arxiv: [https://arxiv.org/abs/2112.00510](https://arxiv.org/abs/2112.00510)\n\n**Boosting Robustness of Image Matting with Context Assembling and Strong Data Augmentation**\n\n- intro: The University of Adelaide & Adobe Inc. & Zhejiang University\n- arxiv: [https://arxiv.org/abs/2201.06889](https://arxiv.org/abs/2201.06889)\n\n**MatteFormer: Transformer-Based Image Matting via Prior-Tokens**\n\n- intro: Seoul National University & NAVER WEBTOON AI\n- arxiv: [https://arxiv.org/abs/2203.15662](https://arxiv.org/abs/2203.15662)\n\n**Referring Image Matting**\n\n- intro: The University of Sydney & JD Explore Academy\n- arxiv: [https://arxiv.org/abs/2206.05149](https://arxiv.org/abs/2206.05149)\n- github: [https://github.com/JizhiziLi/RIM](https://github.com/JizhiziLi/RIM)\n\n**One-Trimap Video Matting**\n\n- intro: ECCV 2022\n- arxiv: [https://arxiv.org/abs/2207.13353](https://arxiv.org/abs/2207.13353)\n- github: [https://github.com/Hongje/OTVM](https://github.com/Hongje/OTVM)\n\n## trimap-free matting\n\n**Semantic Human Matting**\n\n- intro: ACM Multimedia 2018\n- arxiv: [https://arxiv.org/abs/1809.01354](https://arxiv.org/abs/1809.01354)\n- github(unofficial): [https://github.com/lizhengwei1992/Semantic_Human_Matting](https://github.com/lizhengwei1992/Semantic_Human_Matting)\n\n**Instance Segmentation based Semantic Matting for Compositing Applications**\n\n- intro: CRV 2019\n- arxiv: [https://arxiv.org/abs/1904.05457](https://arxiv.org/abs/1904.05457)\n\n**A Late Fusion CNN for Digital Matting**\n\n- intro: CVPR 2019\n- intro: Zhejiang University & Alibaba Group & University of Texas at Austin\n- paper: [https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_A_Late_Fusion_CNN_for_Digital_Matting_CVPR_2019_paper.pdf](https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_A_Late_Fusion_CNN_for_Digital_Matting_CVPR_2019_paper.pdf)\n- github(official, Keras): [https://github.com/yunkezhang/FusionMatting](https://github.com/yunkezhang/FusionMatting)\n\n**Attention-Guided Hierarchical Structure Aggregation for Image Matting**\n\n- intro: CVPR 2020\n- project page: [https://wukaoliu.github.io/HAttMatting/](https://wukaoliu.github.io/HAttMatting/)\n- paper: [https://openaccess.thecvf.com/content_CVPR_2020/papers/Qiao_Attention-Guided_Hierarchical_Structure_Aggregation_for_Image_Matting_CVPR_2020_paper.pdf](https://openaccess.thecvf.com/content_CVPR_2020/papers/Qiao_Attention-Guided_Hierarchical_Structure_Aggregation_for_Image_Matting_CVPR_2020_paper.pdf)\n- github: [https://github.com/wukaoliu/CVPR2020-HAttMatting](https://github.com/wukaoliu/CVPR2020-HAttMatting)\n\n**Boosting Semantic Human Matting with Coarse Annotations**\n\n- intro: Alibaba Group & Tsinghua University\n- arxiv: [https://arxiv.org/abs/2004.04955](https://arxiv.org/abs/2004.04955)\n\n**End-to-end Animal Image Matting**\n\n- keywords: Glance and Focus Matting network (GFM), AM-2k dataset, BG-20k dataset\n- arxiv: [https://arxiv.org/abs/2010.16188](https://arxiv.org/abs/2010.16188)\n- github: [https://github.com/JizhiziLi/animal-matting/](https://github.com/JizhiziLi/animal-matting/)\n\n**Is a Green Screen Really Necessary for Real-Time Human Matting?**\n\n- intro: City University of Hong Kong & SenseTime Research\n- arxiv: [https://arxiv.org/abs/2011.11961](https://arxiv.org/abs/2011.11961)\n- github: [https://github.com/ZHKKKe/MODNet](https://github.com/ZHKKKe/MODNet)\n\n**Multi-scale Information Assembly for Image Matting**\n\n[https://arxiv.org/abs/2101.02391](https://arxiv.org/abs/2101.02391)\n\n**Salient Image Matting**\n\n- intro: Fynd & University of Michigan\n- arxiv: [https://arxiv.org/abs/2103.12337](https://arxiv.org/abs/2103.12337)\n\n**Mask Guided Matting via Progressive Refinement Network**\n\n- intro: CVPR 2021\n- intro: The Johns Hopkins University & Adobe\n- arxiv: [https://arxiv.org/abs/2012.06722](https://arxiv.org/abs/2012.06722)\n- github: [https://github.com/yucornetto/MGMatting](https://github.com/yucornetto/MGMatting)\n\n**Privacy-Preserving Portrait Matting**\n\n- intro: The University of Sydney & JD Explore Academy\n- arxiv: [https://arxiv.org/abs/2104.14222](https://arxiv.org/abs/2104.14222)\n- github: [https://github.com/SHI-Labs/Pseudo-IoU-for-Anchor-Free-Object-Detection](https://github.com/SHI-Labs/Pseudo-IoU-for-Anchor-Free-Object-Detection)\n\n**Highly Efficient Natural Image Matting**\n\n- intro: BMVC 2021\n- arxiv: [https://arxiv.org/abs/2110.12748](https://arxiv.org/abs/2110.12748)\n\n**PP-HumanSeg: Connectivity-Aware Portrait Segmentation with a Large-Scale Teleconferencing Video Dataset**\n\n- intro: WACV 2021 workshop\n- intro: Baidu, Inc.\n- arxiv: [https://arxiv.org/abs/2112.07146](https://arxiv.org/abs/2112.07146)\n- github: [https://github.com/PaddlePaddle/PaddleSeg](https://github.com/PaddlePaddle/PaddleSeg)\n\n**Situational Perception Guided Image Matting**\n\n- intro: OPPO Research Institute & PicUp.AI & Xmotors\n- arxiv: [https://arxiv.org/abs/2204.09276](https://arxiv.org/abs/2204.09276)\n\n**PP-Matting: High-Accuracy Natural Image Matting**\n\n- intro: Baidu Inc.\n- arixv: [https://arxiv.org/abs/2204.09433](https://arxiv.org/abs/2204.09433)\n- github: [https://github.com/PaddlePaddle/PaddleSeg](https://github.com/PaddlePaddle/PaddleSeg)\n\n# 3D Segmentation\n\n**PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation**\n\n- intro: Stanford University\n- project page: [http://stanford.edu/~rqi/pointnet/](http://stanford.edu/~rqi/pointnet/)\n- arxiv: [https://arxiv.org/abs/1612.00593](https://arxiv.org/abs/1612.00593)\n- github: [https://github.com/charlesq34/pointnet](https://github.com/charlesq34/pointnet)\n\n**DA-RNN: Semantic Mapping with Data Associated Recurrent Neural Networks**\n\n[https://arxiv.org/abs/1703.03098](https://arxiv.org/abs/1703.03098)\n\n**SqueezeSeg: Convolutional Neural Nets with Recurrent CRF for Real-Time Road-Object Segmentation from 3D LiDAR Point Cloud**\n\n- intro: UC Berkeley\n- arxiv: [https://arxiv.org/abs/1710.07368](https://arxiv.org/abs/1710.07368)\n\n**SEGCloud: Semantic Segmentation of 3D Point Clouds**\n\n- intro: International Conference of 3D Vision (3DV) 2017 (Spotlight). Stanford University\n- homepage: [http://segcloud.stanford.edu/](http://segcloud.stanford.edu/)\n- arxiv: [https://arxiv.org/abs/1710.07563](https://arxiv.org/abs/1710.07563)\n\n**3D Instance Segmentation via Multi-task Metric Learning**\n\n- intro: KAUST & ETH Zurich\n- arxiv: [https://arxiv.org/abs/1906.08650](https://arxiv.org/abs/1906.08650)\n\n**3D-MPA: Multi Proposal Aggregation for 3D Semantic Instance Segmentation**\n\n- intro: RWTH Aachen University & Google & Technical University Munich\n- project page: [https://www.vision.rwth-aachen.de/publication/00199/](https://www.vision.rwth-aachen.de/publication/00199/)\n- arxiv: [https://arxiv.org/abs/2003.13867](https://arxiv.org/abs/2003.13867)\n\n**PointGroup: Dual-Set Point Grouping for 3D Instance Segmentation**\n\n- intro: CVPR 2020\n- arxiv: [https://arxiv.org/abs/2004.01658](https://arxiv.org/abs/2004.01658)\n\n# Line Parsing\n\n**Fully Convolutional Line Parsing**\n\n- intro: ICCV 2021\n- intro: UESTC & UC Berkeley\n- arxiv: [https://arxiv.org/abs/2104.11207](https://arxiv.org/abs/2104.11207)\n- github(PyTorch): [https://github.com/Delay-Xili/F-Clip](https://github.com/Delay-Xili/F-Clip)\n\n# Projects\n\n**TF Image Segmentation: Image Segmentation framework**\n\n- intro: Image Segmentation framework based on Tensorflow and TF-Slim library\n- github: [https://github.com/warmspringwinds/tf-image-segmentation](https://github.com/warmspringwinds/tf-image-segmentation)\n\n**KittiSeg: A Kitti Road Segmentation model implemented in tensorflow.**\n\n- keywords: MultiNet\n- intro: KittiSeg performs segmentation of roads by utilizing an FCN based model.\n- github: [https://github.com/MarvinTeichmann/KittiBox](https://github.com/MarvinTeichmann/KittiBox)\n\n**Semantic Segmentation Architectures Implemented in PyTorch**\n\n- intro: Segnet/FCN/U-Net/Link-Net\n- github: [https://github.com/meetshah1995/pytorch-semseg](https://github.com/meetshah1995/pytorch-semseg)\n\n**PyTorch for Semantic Segmentation**\n\n[https://github.com/ZijunDeng/pytorch-semantic-segmentation](https://github.com/ZijunDeng/pytorch-semantic-segmentation)\n\n**LightNet: Light-weight Networks for Semantic Image Segmentation**\n\n- project page: [https://ansleliu.github.io/LightNet.html](https://ansleliu.github.io/LightNet.html)\n- github: [https://github.com/ansleliu/LightNet](https://github.com/ansleliu/LightNet)\n\n**LightNet++: Boosted Light-weighted Networks for Real-time Semantic Segmentation**\n\n- project page: [https://ansleliu.github.io/LightNet.html](https://ansleliu.github.io/LightNet.html)\n- github: [https://github.com/ansleliu/LightNetPlusPlus](https://github.com/ansleliu/LightNetPlusPlus)\n\n# Leaderboard\n\n**Segmentation Results: VOC2012 BETA: Competition \"comp6\" (train on own data)**\n\n[http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?cls=mean&challengeid=11&compid=6](http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?cls=mean&challengeid=11&compid=6)\n\n# Blogs\n\n**Mobile Real-time Video Segmentation**\n\n[https://research.googleblog.com/2018/03/mobile-real-time-video-segmentation.html](https://research.googleblog.com/2018/03/mobile-real-time-video-segmentation.html)\n\n**Deep Learning for Natural Image Segmentation Priors**\n\n[http://cs.brown.edu/courses/csci2951-t/finals/ghope/](http://cs.brown.edu/courses/csci2951-t/finals/ghope/)\n\n**Image Segmentation Using DIGITS 5**\n\n[https://devblogs.nvidia.com/parallelforall/image-segmentation-using-digits-5/](https://devblogs.nvidia.com/parallelforall/image-segmentation-using-digits-5/)\n\n**Image Segmentation with Tensorflow using CNNs and Conditional Random Fields**\n[http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/18/image-segmentation-with-tensorflow-using-cnns-and-conditional-random-fields/](http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/18/image-segmentation-with-tensorflow-using-cnns-and-conditional-random-fields/)\n\n**Fully Convolutional Networks (FCNs) for Image Segmentation**\n\n- blog: [http://warmspringwinds.github.io/tensorflow/tf-slim/2017/01/23/fully-convolutional-networks-(fcns)-for-image-segmentation/](http://warmspringwinds.github.io/tensorflow/tf-slim/2017/01/23/fully-convolutional-networks-(fcns)-for-image-segmentation/)\n- ipn: [https://github.com/warmspringwinds/tensorflow_notes/blob/master/fully_convolutional_networks.ipynb](https://github.com/warmspringwinds/tensorflow_notes/blob/master/fully_convolutional_networks.ipynb)\n\n**Image segmentation with Neural Net**\n\n- blog: [https://medium.com/@m.zaradzki/image-segmentation-with-neural-net-d5094d571b1e#.s5f711g1q](https://medium.com/@m.zaradzki/image-segmentation-with-neural-net-d5094d571b1e#.s5f711g1q)\n- github: [https://github.com/mzaradzki/neuralnets/tree/master/vgg_segmentation_keras](https://github.com/mzaradzki/neuralnets/tree/master/vgg_segmentation_keras)\n\n**A 2017 Guide to Semantic Segmentation with Deep Learning**\n\n[http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review)\n\n# Tutorails / Talks\n\n**A Unified Architecture for Instance and Semantic Segmentation**\n\n- intro: FPN\n- slides: [http://presentations.cocodataset.org/COCO17-Stuff-FAIR.pdf](http://presentations.cocodataset.org/COCO17-Stuff-FAIR.pdf)\n\n**Deep learning for image segmentation**\n\n- intro: PyData Warsaw - Mateusz Opala & Micha Jamro\n- youtube: [https://www.youtube.com/watch?v=W6r_a5crqGI](https://www.youtube.com/watch?v=W6r_a5crqGI)\n","excerpt":"Papers Deep Joint Task Learning for Generic Object Extraction intro: NIPS 2014 homepage:  http://vision.sysu.edu.cn/projects/deep-joint-tas","outboundReferences":[],"inboundReferences":[]},"tagsOutbound":{"nodes":[]}},"pageContext":{"tags":[],"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-segmentation/","sidebarItems":[{"title":"Categories","items":[{"title":"Commercial","url":"","items":[{"title":"Commercial Structure","url":"/Commercial/Commercial Structure/","items":[]},{"title":"Community of Practice","url":"/Commercial/Community of Practice/","items":[]},{"title":"Domains","url":"/Commercial/Domains/","items":[]},{"title":"Webizen Alliance","url":"/Commercial/Webizen Alliance/","items":[]}]},{"title":"Core Services","url":"","items":[{"title":"Decentralised Ontologies","url":"/Core Services/Decentralised Ontologies/","items":[]},{"title":"Permissive Commons","url":"/Core Services/Permissive Commons/","items":[]},{"title":"Safety Protocols","url":"","items":[{"title":"Safety Protocols","url":"/Core Services/Safety Protocols/Safety Protocols/","items":[]},{"title":"Social Factors","url":"","items":[{"title":"Best Efforts","url":"/Core Services/Safety Protocols/Social Factors/Best Efforts/","items":[]},{"title":"Ending Digital Slavery","url":"/Core Services/Safety Protocols/Social Factors/Ending Digital Slavery/","items":[]},{"title":"Freedom of Thought","url":"/Core Services/Safety Protocols/Social Factors/Freedom of Thought/","items":[]},{"title":"No Golden Handcuffs","url":"/Core Services/Safety Protocols/Social Factors/No Golden Handcuffs/","items":[]},{"title":"Relationships (Social)","url":"/Core Services/Safety Protocols/Social Factors/Relationships (Social)/","items":[]},{"title":"Social Attack Vectors","url":"/Core Services/Safety Protocols/Social Factors/Social Attack Vectors/","items":[]},{"title":"The Webizen Charter","url":"/Core Services/Safety Protocols/Social Factors/The Webizen Charter/","items":[]}]},{"title":"Values Credentials","url":"/Core Services/Safety Protocols/Values Credentials/","items":[]}]},{"title":"Temporal Semantics","url":"/Core Services/Temporal Semantics/","items":[]},{"title":"Verifiable Claims & Credentials","url":"/Core Services/Verifiable Claims & Credentials/","items":[]},{"title":"Webizen Socio-Economics","url":"","items":[{"title":"Biosphere Ontologies","url":"/Core Services/Webizen Socio-Economics/Biosphere Ontologies/","items":[]},{"title":"Centricity","url":"/Core Services/Webizen Socio-Economics/Centricity/","items":[]},{"title":"Currencies","url":"/Core Services/Webizen Socio-Economics/Currencies/","items":[]},{"title":"SocioSphere Ontologies","url":"/Core Services/Webizen Socio-Economics/SocioSphere Ontologies/","items":[]},{"title":"Sustainable Development Goals (ESG)","url":"/Core Services/Webizen Socio-Economics/Sustainable Development Goals (ESG)/","items":[]}]}]},{"title":"Core Technologies","url":"","items":[{"title":"AUTH","url":"","items":[{"title":"Authentication Fabric","url":"/Core Technologies/AUTH/Authentication Fabric/","items":[]}]},{"title":"Webizen App Spec","url":"","items":[{"title":"SemWebSpecs","url":"","items":[{"title":"Core Ontologies","url":"","items":[{"title":"FOAF","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/FOAF/","items":[]},{"title":"General Ontology Information","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/General Ontology Information/","items":[]},{"title":"Human Rights Ontologies","url":"","items":[{"title":"UDHR","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/Human Rights Ontologies/UDHR/","items":[]}]},{"title":"MD-RDF Ontologies","url":"","items":[{"title":"DataTypesOntology (DTO) Core","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/MD-RDF Ontologies/DataTypes Ontology/","items":[]},{"title":"Friend of a Friend (FOAF) Core","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/MD-RDF Ontologies/FOAF/","items":[]}]},{"title":"OWL","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/OWL/","items":[]},{"title":"RDF Schema 1.1","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/RDFS/","items":[]},{"title":"Sitemap","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/Sitemap/","items":[]},{"title":"SKOS","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/SKOS/","items":[]},{"title":"SOIC","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Core Ontologies/SOIC/","items":[]}]},{"title":"Semantic Web - An Introduction","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Semantic Web - An Introduction/","items":[]},{"title":"SemWeb-AUTH","url":"","items":[{"title":"WebID-OIDC","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-OIDC/","items":[]},{"title":"WebID-RSA","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-RSA/","items":[]},{"title":"WebID-TLS","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/SemWeb-AUTH/WebID-TLS/","items":[]}]},{"title":"Sparql","url":"","items":[{"title":"Sparql Family","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/Sparql/Sparql Family/","items":[]}]},{"title":"W3C Specifications","url":"","items":[{"title":"Linked Data Fragments","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Fragments/","items":[]},{"title":"Linked Data Notifications","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Notifications/","items":[]},{"title":"Linked Data Platform","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Data Platform/","items":[]},{"title":"Linked Media Fragments","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Linked Media Fragments/","items":[]},{"title":"RDF","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/RDF/","items":[]},{"title":"Web Access Control (WAC)","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Web Access Control (WAC)/","items":[]},{"title":"Web Of Things","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/Web Of Things/","items":[]},{"title":"WebID","url":"/Core Technologies/Webizen App Spec/SemWebSpecs/W3C Specifications/WebID/","items":[]}]}]},{"title":"Webizen App Spec 1.0","url":"/Core Technologies/Webizen App Spec/Webizen App Spec 1.0/","items":[]},{"title":"WebSpec","url":"","items":[{"title":"HTML SPECS","url":"/Core Technologies/Webizen App Spec/WebSpec/HTML SPECS/","items":[]},{"title":"Query Interfaces","url":"","items":[{"title":"GraphQL","url":"/Core Technologies/Webizen App Spec/WebSpec/Query Interfaces/GraphQL/","items":[]}]},{"title":"WebPlatformTools","url":"","items":[{"title":"WebAuthn","url":"/Core Technologies/Webizen App Spec/WebSpec/WebPlatformTools/WebAuthn/","items":[]},{"title":"WebDav","url":"/Core Technologies/Webizen App Spec/WebSpec/WebPlatformTools/WebDav/","items":[]}]}]}]}]},{"title":"Database Requirements","url":"","items":[{"title":"Database Alternatives","url":"","items":[{"title":"Akutan","url":"/Database requirements/Database Alternatives/akutan/","items":[]},{"title":"CayleyGraph","url":"/Database requirements/Database Alternatives/CayleyGraph/","items":[]}]},{"title":"Database Methods","url":"","items":[{"title":"GraphQL","url":"/Database requirements/Database methods/GraphQL/","items":[]},{"title":"Sparql","url":"/Database requirements/Database methods/Sparql/","items":[]}]}]},{"title":"Host Service Requirements","url":"","items":[{"title":"Domain Hosting","url":"/Host Service Requirements/Domain Hosting/","items":[]},{"title":"Email Services","url":"/Host Service Requirements/Email Services/","items":[]},{"title":"LD_PostOffice_SemanticMGR","url":"/Host Service Requirements/LD_PostOffice_SemanticMGR/","items":[]},{"title":"Media Processing","url":"/Host Service Requirements/Media Processing/","items":[{"title":"Ffmpeg","url":"/Host Service Requirements/Media Processing/ffmpeg/","items":[]},{"title":"Opencv","url":"/Host Service Requirements/Media Processing/opencv/","items":[]}]},{"title":"Website Host","url":"/Host Service Requirements/Website Host/","items":[]}]},{"title":"ICT Stack","url":"","items":[{"title":"General References","url":"","items":[{"title":"List of Protocols ISO Model","url":"/ICT Stack/General References/List of Protocols ISO model/","items":[]}]},{"title":"Internet","url":"","items":[{"title":"Internet Stack","url":"/ICT Stack/Internet/Internet Stack/","items":[]}]}]},{"title":"Implementation V1","url":"","items":[{"title":"App-Design-Sdk-V1","url":"","items":[{"title":"Core Apps","url":"","items":[{"title":"Agent Directory","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Agent Directory/","items":[]},{"title":"Credentials & Contracts Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Credentials & Contracts Manager/","items":[]},{"title":"File (Package) Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/File (package) Manager/","items":[]},{"title":"Temporal Apps","url":"","items":[{"title":"Calendar","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Temporal Apps/Calendar/","items":[]},{"title":"Timeline Interface","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Temporal Apps/Timeline Interface/","items":[]}]},{"title":"Webizen Apps (V1)","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Webizen Apps (v1)/","items":[]},{"title":"Webizen Manager","url":"/Implementation V1/App-design-sdk-v1/Core Apps/Webizen Manager/","items":[]}]},{"title":"Data Applications","url":"/Implementation V1/App-design-sdk-v1/Data Applications/","items":[]},{"title":"Design Goals","url":"","items":[{"title":"Design Goals Overview","url":"/Implementation V1/App-design-sdk-v1/Design Goals/Design Goals Overview/","items":[]}]}]},{"title":"Edge","url":"","items":[{"title":"Webizen Local App Functionality","url":"/Implementation V1/edge/Webizen Local App Functionality/","items":[]}]},{"title":"GoLang Libraries","url":"/Implementation V1/GoLang Libraries/","items":[]},{"title":"Implementation V1 Summary","url":"/Implementation V1/Implementation V1 Summary/","items":[]},{"title":"Vps","url":"","items":[{"title":"Server Functionality Summary (VPS)","url":"/Implementation V1/vps/Server Functionality Summary (VPS)/","items":[]}]},{"title":"Webizen 1.0","url":"/Implementation V1/Webizen 1.0/","items":[]},{"title":"Webizen-Connect","url":"","items":[{"title":"Social Media APIs","url":"/Implementation V1/Webizen-Connect/Social Media APIs/","items":[]},{"title":"Webizen-Connect (Summary)","url":"/Implementation V1/Webizen-Connect/Webizen-Connect (summary)/","items":[]}]}]},{"title":"Non-HTTP(s) Protocols","url":"","items":[{"title":"DAT","url":"/Non-HTTP(s) Protocols/DAT/","items":[]},{"title":"GIT","url":"/Non-HTTP(s) Protocols/GIT/","items":[]},{"title":"GUNECO","url":"/Non-HTTP(s) Protocols/GUNECO/","items":[]},{"title":"IPFS","url":"/Non-HTTP(s) Protocols/IPFS/","items":[]},{"title":"Lightning Network","url":"/Non-HTTP(s) Protocols/Lightning Network/","items":[]},{"title":"Non-HTTP(s) Protocols (& DLTs)","url":"/Non-HTTP(s) Protocols/Non-HTTP(s) Protocols (& DLTs)/","items":[]},{"title":"WebRTC","url":"/Non-HTTP(s) Protocols/WebRTC/","items":[]},{"title":"WebSockets","url":"/Non-HTTP(s) Protocols/WebSockets/","items":[]},{"title":"WebTorrent","url":"/Non-HTTP(s) Protocols/WebTorrent/","items":[]}]},{"title":"Old-Work-Archives","url":"","items":[{"title":"2018-Webizen-Net-Au","url":"","items":[{"title":"_Link_library_links","url":"","items":[{"title":"Link Library","url":"/old-work-archives/2018-webizen-net-au/_link_library_links/2018-09-23-wp-linked-data/","items":[]}]},{"title":"_Posts","url":"","items":[{"title":"About W3C","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-27-about-w3c/","items":[]},{"title":"Advanced Functions &#8211; Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-16-advanced-functions-facebook-pages/","items":[]},{"title":"Advanced Search &#038; Discovery Tips","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-advanced-search-discovery-tips/","items":[]},{"title":"An introduction to Virtual Machines.","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-an-introduction-to-virtual-machines/","items":[]},{"title":"Basic Media Analysis &#8211; Part 1 (Audio)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-30-media-analysis-part-1-audio/","items":[]},{"title":"Basic Media Analysis &#8211; Part 2 (visual)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-31-media-analysis-part-2-visual/","items":[]},{"title":"Basic Media Analysis &#8211; Part 3 (Text &#038; Metadata)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-01-01-basic-media-analysis-part-3-text-metadata/","items":[]},{"title":"Building an Economy based upon Knowledge Equity.","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-25-building-an-economy-based-upon-knowledge-equity/","items":[]},{"title":"Choice of Law","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-26-choice-of-law/","items":[]},{"title":"Contemplation of the ITU Dubai Meeting and the Future of the Internet","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-19-contemplation-of-the-itu-dubai-meeting-and-the-future-of-the-internet/","items":[]},{"title":"Creating a Presence &#8211; Online","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-creating-a-presence-online/","items":[]},{"title":"Credentials and Payments by Manu Sporny","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-credentials-and-payments-by-manu-sporny/","items":[]},{"title":"Data Recovery &#038; Collection: Mobile Devices","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-28-mobile-devices-data-recovery-collection/","items":[]},{"title":"Data Recovery: Laptop &#038; Computers","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-12-28-data-recovery-laptop-computers/","items":[]},{"title":"Decentralized Web Conference 2016","url":"/old-work-archives/2018-webizen-net-au/_posts/2016-06-09-decentralized-web-2016/","items":[]},{"title":"Decentralized Web Summit 2018","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-decentralized-web-summit-2018/","items":[]},{"title":"Does Anonymity exist?","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-does-anonymity-exist/","items":[]},{"title":"Downloading My Data from Social Networks","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-downloading-my-data-from-social-networks/","items":[]},{"title":"Events","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-events/","items":[]},{"title":"Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-12-16-facebook-pages/","items":[]},{"title":"Google Tracking Data (geolocation)","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-google-tracking/","items":[]},{"title":"Human Consciousness","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-human-consciousness/","items":[]},{"title":"Image Recgonition Video Playlist","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-image-recgonition-video-playlist/","items":[]},{"title":"Inferencing (introduction)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-inferencing-introduction/","items":[]},{"title":"Introduction to AI","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-introduction-to-ai/","items":[]},{"title":"Introduction to Linked Data","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-introduction-to-linked-data/","items":[]},{"title":"Introduction to Maltego","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-introduction-to-maltego/","items":[]},{"title":"Introduction to Ontologies","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-ontologies-intro/","items":[]},{"title":"Introduction to Semantic Web","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-introduction-to-semantic-web/","items":[]},{"title":"Knowledge Capital","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-10-17-knowledge-capital/","items":[]},{"title":"Logo&#8217;s, Style Guides and Artwork","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-logos-style-guides-and-artwork/","items":[]},{"title":"MindMapping &#8211; Setting-up a business &#8211; Identity","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-mindmapping-setting-up-a-business-identity/","items":[]},{"title":"Openlink Virtuoso","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-openlink-virtuoso/","items":[]},{"title":"OpenRefine","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-21-74-2/","items":[]},{"title":"Projects, Customers and Invoicing &#8211; Web-Services for Startups","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-projects-customers-and-invoicing-web-services-for-startups/","items":[]},{"title":"RWW &#038; some Solid history","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-rww-some-solid-history/","items":[]},{"title":"Semantic Web (An Intro)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-semantic-web-an-intro/","items":[]},{"title":"Setting-up Twitter","url":"/old-work-archives/2018-webizen-net-au/_posts/2013-06-07-setting-up-twitter/","items":[]},{"title":"Social Encryption: An Introduction","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-25-social-encryption-an-introduction/","items":[]},{"title":"Stock Content","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-28-stock-content/","items":[]},{"title":"The WayBack Machine","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-27-the-wayback-machine/","items":[]},{"title":"Tim Berners Lee &#8211; Turing Lecture","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-05-29-tim-berners-lee-turing-lecture/","items":[]},{"title":"Tools of Trade","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-tools-of-trade/","items":[]},{"title":"Trust Factory 2017","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-trust-factory-2017/","items":[]},{"title":"Verifiable Claims (An Introduction)","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-vc-intro/","items":[]},{"title":"Web of Things &#8211; an Introduction","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-21-web-of-things-an-introduction/","items":[]},{"title":"Web-Persistence","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-web-persistence/","items":[]},{"title":"Web-Services &#8211; Marketing Tools","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-web-services-marketing-tools/","items":[]},{"title":"Website Templates","url":"/old-work-archives/2018-webizen-net-au/_posts/2012-11-19-templates/","items":[]},{"title":"What is Linked Data?","url":"/old-work-archives/2018-webizen-net-au/_posts/2018-09-23-what-is-linked-data/","items":[]},{"title":"What is Open Source Intelligence?","url":"/old-work-archives/2018-webizen-net-au/_posts/2017-07-23-what-is-osint/","items":[]},{"title":"WiX","url":"/old-work-archives/2018-webizen-net-au/_posts/2013-01-01-wix/","items":[]}]},{"title":"about","url":"/old-work-archives/2018-webizen-net-au/about/","items":[{"title":"About The Author","url":"/old-work-archives/2018-webizen-net-au/about/about-the-author/","items":[]},{"title":"Applied Theory: Applications for a Human Centric Web","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/","items":[{"title":"Digital Receipts","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/digital-receipts/","items":[]},{"title":"Fake News: Considerations  Principles  The Institution of Socio &#8211; Economic Values","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations-%e2%86%92-principles-%e2%86%92-the-institution-of-socio-economic-values/","items":[{"title":"Solutions to FakeNews: Linked-Data, Ontologies and Verifiable Claims","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations-%e2%86%92-principles-%e2%86%92-the-institution-of-socio-economic-values/solutions-to-fakenews-linked-data-ontologies-and-verifiable-claims/","items":[]}]},{"title":"Healthy Living Economy","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/healthy-living-economy/","items":[]},{"title":"HyperMedia Solutions &#8211; Adapting HbbTV V2","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/","items":[{"title":"HYPERMEDIA PACKAGES","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/hypermedia-packages/","items":[]},{"title":"USER STORIES: INTERACTIVE VIEWING EXPERIENCE","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/user-stories-interactive-viewing-experience/","items":[]}]},{"title":"Measurements App","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/measurements-app/","items":[]},{"title":"Re:Animation","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/reanimation/","items":[]}]},{"title":"Executive Summary","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/","items":[{"title":"Assisting those who Enforce the Law","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/assisting-those-who-enforce-the-law/","items":[]},{"title":"Consumer Protections","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/consumer-protections/","items":[]},{"title":"Knowledge Banking: Legal Structures","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-banking-legal-structures/","items":[]},{"title":"Knowledge Economics &#8211; Services","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-economics-services/","items":[]},{"title":"Preserving The Freedom to Think","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/preserving-the-freedom-to-think/","items":[]}]},{"title":"History","url":"/old-work-archives/2018-webizen-net-au/about/history/","items":[{"title":"History: Global Governance and ICT.","url":"/old-work-archives/2018-webizen-net-au/about/history/history-global-governance-ict-1/","items":[]}]},{"title":"Knowledge Banking: A Technical Architecture Summary","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/","items":[{"title":"An introduction to Credentials.","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/","items":[{"title":"credentials and custodianship","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/credentials-and-custodianship/","items":[]},{"title":"DIDs and MultiSig","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/dids-and-multisig/","items":[]}]},{"title":"Personal Augmentation of AI","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/personal-augmentation-of-ai/","items":[]},{"title":"Semantic Inferencing","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/semantic-inferencing/","items":[]},{"title":"Web of Things (IoT+LD)","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/web-of-things-iotld/","items":[]}]},{"title":"References","url":"/old-work-archives/2018-webizen-net-au/about/references/","items":[{"title":"Making the distinction between privacy and dignity.","url":"/old-work-archives/2018-webizen-net-au/about/references/privacy-vs-dignity/","items":[]},{"title":"Roles &#8211; Entity Analysis","url":"/old-work-archives/2018-webizen-net-au/about/references/roles-entity-analysis/","items":[]},{"title":"Social Informatics Design Considerations","url":"/old-work-archives/2018-webizen-net-au/about/references/social-informatics-design-concept-and-principles/","items":[]},{"title":"Socio-economic relations | A conceptual model","url":"/old-work-archives/2018-webizen-net-au/about/references/socioeconomic-relations-p1/","items":[]},{"title":"The need for decentralised Open (Linked) Data","url":"/old-work-archives/2018-webizen-net-au/about/references/the-need-for-decentralised-open-linked-data/","items":[]}]},{"title":"The design of new medium","url":"/old-work-archives/2018-webizen-net-au/about/the-design-of-new-medium/","items":[]},{"title":"The need to modernise socioeconomic infrastructure","url":"/old-work-archives/2018-webizen-net-au/about/the-modernisation-of-socioeconomics/","items":[]},{"title":"The Vision","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/","items":[{"title":"Domesticating Pervasive Surveillance","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/a-technical-vision/","items":[]}]}]},{"title":"An Overview","url":"/old-work-archives/2018-webizen-net-au/the-human-centric-infosphere/","items":[]},{"title":"Embed Link","url":"/old-work-archives/2018-webizen-net-au/embed-link/","items":[]},{"title":"Posts","url":"/old-work-archives/2018-webizen-net-au/posts/","items":[]},{"title":"Privacy Policy","url":"/old-work-archives/2018-webizen-net-au/privacy-policy/","items":[]},{"title":"Resource Library","url":"/old-work-archives/2018-webizen-net-au/resource-library/","items":[{"title":"Handong1587","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/","items":[{"title":"_Posts","url":"","items":[{"title":"Computer_science","url":"","items":[{"title":"Algorithm and Data Structure Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-algo-resourses/","items":[]},{"title":"Artificial Intelligence Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-ai-resources/","items":[]},{"title":"Big Data Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-09-22-big-data-resources/","items":[]},{"title":"Computer Science Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-cs-resources/","items":[]},{"title":"Data Mining Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-data-mining-resources/","items":[]},{"title":"Data Science Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-09-data-science-resources/","items":[]},{"title":"Database Systems Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-database-resources/","items":[]},{"title":"Discrete Optimization Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-10-01-discrete-optimization/","items":[]},{"title":"Distribued System Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-12-12-ditributed-system-resources/","items":[]},{"title":"Funny Stuffs Of Computer Science","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-11-18-funny-stuffs-of-cs/","items":[]},{"title":"Robotics","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-09-26-robotics-resources/","items":[]},{"title":"Writting CS Papers","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_science/2015-11-30-writing-papers/","items":[]}]},{"title":"Computer_vision","url":"","items":[{"title":"Computer Vision Datasets","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-24-datasets/","items":[]},{"title":"Computer Vision Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-09-12-cv-resources/","items":[]},{"title":"Features","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-10-09-features/","items":[]},{"title":"Recognition, Detection, Segmentation and Tracking","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-10-09-recognition-detection-segmentation-tracking/","items":[]},{"title":"Use FFmpeg to Capture I Frames of Video","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2016-03-03-ffmpeg-i-frame/","items":[]},{"title":"Working on OpenCV","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/computer_vision/2015-12-25-working-on-opencv/","items":[]}]},{"title":"Deep_learning","url":"","items":[{"title":"3D","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2021-07-28-3d/","items":[]},{"title":"Acceleration and Model Compression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-cnn-compression-acceleration/","items":[]},{"title":"Acceleration and Model Compression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-knowledge-distillation/","items":[]},{"title":"Adversarial Attacks and Defences","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-adversarial-attacks-and-defences/","items":[]},{"title":"Audio / Image / Video Generation","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-audio-image-video-generation/","items":[]},{"title":"BEV","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2022-06-27-bev/","items":[]},{"title":"Classification / Recognition","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recognition/","items":[]},{"title":"Deep Learning and Autonomous Driving","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-autonomous-driving/","items":[]},{"title":"Deep Learning Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-pose-estimation/","items":[]},{"title":"Deep Learning Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-applications/","items":[]},{"title":"Deep learning Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-courses/","items":[]},{"title":"Deep Learning Frameworks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-frameworks/","items":[]},{"title":"Deep Learning Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-resources/","items":[]},{"title":"Deep Learning Software and Hardware","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-software-hardware/","items":[]},{"title":"Deep Learning Tricks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tricks/","items":[]},{"title":"Deep Learning Tutorials","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tutorials/","items":[]},{"title":"Deep Learning with Machine Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-with-ml/","items":[]},{"title":"Face Recognition","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-face-recognition/","items":[]},{"title":"Fun With Deep Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-fun-with-deep-learning/","items":[]},{"title":"Generative Adversarial Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gan/","items":[]},{"title":"Graph Convolutional Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gcn/","items":[]},{"title":"Image / Video Captioning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-captioning/","items":[]},{"title":"Image Retrieval","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-retrieval/","items":[]},{"title":"Keep Up With New Trends","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2018-09-03-keep-up-with-new-trends/","items":[]},{"title":"LiDAR 3D Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-lidar-3d-detection/","items":[]},{"title":"Natural Language Processing","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nlp/","items":[]},{"title":"Neural Architecture Search","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nas/","items":[]},{"title":"Object Counting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-counting/","items":[]},{"title":"Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-detection/","items":[]},{"title":"OCR","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-ocr/","items":[]},{"title":"Optical Flow","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-optical-flow/","items":[]},{"title":"Re-ID","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-re-id/","items":[]},{"title":"Recommendation System","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recommendation-system/","items":[]},{"title":"Reinforcement Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rl/","items":[]},{"title":"RNN and LSTM","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rnn-and-lstm/","items":[]},{"title":"Segmentation","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-segmentation/","items":[]},{"title":"Style Transfer","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-style-transfer/","items":[]},{"title":"Super-Resolution","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-super-resolution/","items":[]},{"title":"Tracking","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-tracking/","items":[]},{"title":"Training Deep Neural Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-training-dnn/","items":[]},{"title":"Transfer Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-transfer-learning/","items":[]},{"title":"Unsupervised Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-unsupervised-learning/","items":[]},{"title":"Video Applications","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-video-applications/","items":[]},{"title":"Visual Question Answering","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-vqa/","items":[]},{"title":"Visualizing and Interpreting Convolutional Neural Network","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-visulizing-interpreting-cnn/","items":[]}]},{"title":"Leisure","url":"","items":[{"title":"All About Enya","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-all-about-enya/","items":[]},{"title":"Coldplay","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-coldplay/","items":[]},{"title":"Coldplay","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-nightwish/","items":[]},{"title":"Games","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-13-games/","items":[]},{"title":"Green Day","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-greenday/","items":[]},{"title":"Muse! Muse!","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-muse-muse/","items":[]},{"title":"Oasis","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-oasis/","items":[]},{"title":"Paintings By J.M.","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2016-03-08-paintings-by-jm/","items":[]},{"title":"Papers, Blogs and Websites","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-09-27-papers-blogs-and-websites/","items":[]},{"title":"Welcome To The Black Parade","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/leisure/2015-12-21-welcome-to-the-black-parade/","items":[]}]},{"title":"Machine_learning","url":"","items":[{"title":"Bayesian Methods","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-bayesian-methods/","items":[]},{"title":"Clustering Algorithms Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-clustering/","items":[]},{"title":"Competitions","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-competitions/","items":[]},{"title":"Dimensionality Reduction Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-dimensionality-reduction/","items":[]},{"title":"Fun With Machine Learning","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-fun-with-ml/","items":[]},{"title":"Graphical Models Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-graphical-models/","items":[]},{"title":"Machine Learning Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-ml-courses/","items":[]},{"title":"Machine Learning Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-ml-resources/","items":[]},{"title":"Natural Language Processing","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-nlp/","items":[]},{"title":"Neural Network","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-neural-network/","items":[]},{"title":"Random Field","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-random-field/","items":[]},{"title":"Random Forests","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-random-forests/","items":[]},{"title":"Regression","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-regression/","items":[]},{"title":"Support Vector Machine","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-svm/","items":[]},{"title":"Topic Model","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/machine_learning/2015-08-27-topic-model/","items":[]}]},{"title":"Mathematics","url":"","items":[{"title":"Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/mathematics/2016-02-24-resources/","items":[]}]},{"title":"Programming_study","url":"","items":[{"title":"Add Lunr Search Plugin For Blog","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-31-add-lunr-search-plugin-for-blog/","items":[]},{"title":"Android Development Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-05-23-android-resources/","items":[]},{"title":"C++ Programming Solutions","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-09-07-cpp-programming-solutions/","items":[]},{"title":"Commands To Suppress Some Building Errors With Visual Studio","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-24-cmds-to-suppress-some-vs-building-Errors/","items":[]},{"title":"Embedding Python In C/C++","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-10-embedding-python-in-cpp/","items":[]},{"title":"Enable Large Addresses On VS2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-12-14-enable-large-addresses/","items":[]},{"title":"Fix min/max Error In VS2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-02-17-min-max-error-in-vs2015/","items":[]},{"title":"Gflags Build Problems on Windows X86 and Visual Studio 2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-23-gflags-build-problems-winx86-vs2015/","items":[]},{"title":"Glog Build Problems on Windows X86 and Visual Studio 2015","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-23-glog-build-problems-winx86/","items":[]},{"title":"Horrible Wired Errors Come From Simple Stupid Mistake","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-10-16-horrible-wired-errors-come-from-simple-stupid-mistake/","items":[]},{"title":"Install Jekyll To Fix Some Local Github-pages Defects","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-11-21-install-jekyll/","items":[]},{"title":"Install Therubyracer Failure","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-03-install-therubyracer/","items":[]},{"title":"Notes On Valgrind and Others","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-05-30-notes-on-valgrind/","items":[]},{"title":"PHP Hello World","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-07-04-php-hello-world/","items":[]},{"title":"Programming Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2015-07-01-programming-resources/","items":[]},{"title":"PyInstsaller and Others","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-12-24-pyinstaller-and-others/","items":[]},{"title":"Web Development Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-06-21-web-dev-resources/","items":[]},{"title":"Working on Visual Studio","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/programming_study/2016-04-03-working-on-vs/","items":[]}]},{"title":"Reading_and_thoughts","url":"","items":[{"title":"Book Reading List","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2015-12-04-book-reading-list/","items":[]},{"title":"Funny Papers","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2015-12-04-funny-papers/","items":[]},{"title":"Reading Materials","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/reading_and_thoughts/2016-01-18-reading-materials/","items":[]}]},{"title":"Study","url":"","items":[{"title":"Courses","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2017-11-28-courses/","items":[]},{"title":"Essay Writting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2016-01-11-essay-writting/","items":[]},{"title":"Job Hunting","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2016-06-02-job-hunting/","items":[]},{"title":"Study Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/study/2018-04-18-resources/","items":[]}]},{"title":"Working_on_linux","url":"","items":[{"title":"Create Multiple Forks of a GitHub Repo","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-12-18-create-multi-forks/","items":[]},{"title":"Linux Git Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-08-02-linux-git/","items":[]},{"title":"Linux Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-07-24-linux-resources/","items":[]},{"title":"Linux SVN Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-08-03-linux-svn/","items":[]},{"title":"Setup vsftpd on Ubuntu 14.10","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2016-07-27-setup-vsftpd/","items":[]},{"title":"Useful Linux Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2015-07-25-useful-linux-commands/","items":[]},{"title":"vsftpd Commands","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_linux/2016-07-28-vsftpd-cmd/","items":[]}]},{"title":"Working_on_mac","url":"","items":[{"title":"Mac Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_mac/2015-07-25-mac-resources/","items":[]}]},{"title":"Working_on_windows","url":"","items":[{"title":"FFmpeg Collection of Utility Methods","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2016-06-05-ffmpeg-utilities/","items":[]},{"title":"Windows Commands and Utilities","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2015-10-27-windows-cmds-utils/","items":[]},{"title":"Windows Dev Resources","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/working_on_windows/2015-10-27-resources/","items":[]}]}]},{"title":"Drafts","url":"","items":[{"title":"2016-12-30-Setup-Opengrok","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-12-30-setup-opengrok/","items":[]},{"title":"2017-01-20-Packing-C++-Project-to-Single-Executable","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2017-01-20-packing-c++-project-to-single-executable/","items":[]},{"title":"Notes On Caffe Development","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-10-notes-on-caffe-dev/","items":[]},{"title":"Notes On Deep Learning Training","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-12-notes-on-dl-training/","items":[]},{"title":"Notes On Discrete Optimization","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-13-notes-on-discrete-optimization/","items":[]},{"title":"Notes On Gecode","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-13-notes-on-gecode/","items":[]},{"title":"Notes On Inside-Outside Net","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-28-notes-on-ion/","items":[]},{"title":"Notes On K-Means","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-06-notes-on-kmeans/","items":[]},{"title":"Notes On L-BFGS","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-07-notes-on-l-bfgs/","items":[]},{"title":"Notes On Object Detection","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-04-notes-on-object-detection/","items":[]},{"title":"Notes On Perceptrons","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-10-07-notes-on-perceptrons/","items":[]},{"title":"Notes On Quantized Convolutional Neural Networks","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-01-07-notes-on-quantized-cnn/","items":[]},{"title":"Notes On Stanford CS2321n","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-02-21-notes-on-cs231n/","items":[]},{"title":"Notes on Suffix Array and Manacher Algorithm","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-08-27-notes-on-suffix-array-and-manacher-algorithm/","items":[]},{"title":"Notes On Tensorflow Development","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2017-04-13-notes-on-tensorflow-dev/","items":[]},{"title":"Notes On YOLO","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-14-notes-on-yolo/","items":[]},{"title":"PASCAL VOC (20) / COCO (80) / ImageNet (200) Detection Categories","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-12-23-imagenet-det-cat/","items":[]},{"title":"Softmax Vs Logistic Vs Sigmoid","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-10-softmax-logistic-sigmoid/","items":[]},{"title":"Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognititon","url":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2016-08-31-model-ensemble-of-deteciton/","items":[]}]}]}]}]}]},{"title":"Webizen 2.0","url":"","items":[{"title":"AI Capabilities","url":"","items":[{"title":"AI Capabilities Objectives","url":"/Webizen 2.0/AI Capabilities/AI Capabilities Objectives/","items":[]},{"title":"Audio & Video Analysis","url":"/Webizen 2.0/AI Capabilities/Audio & Video Analysis/","items":[]},{"title":"Image Analysis","url":"/Webizen 2.0/AI Capabilities/Image Analysis/","items":[]},{"title":"Text Analysis","url":"/Webizen 2.0/AI Capabilities/Text Analysis/","items":[]}]},{"title":"LOD-a-lot","url":"/Webizen 2.0/AI Related Links & Notes/","items":[]},{"title":"Mobile Apps","url":"","items":[{"title":"Android","url":"/Webizen 2.0/Mobile Apps/Android/","items":[]},{"title":"General Mobile Architecture","url":"/Webizen 2.0/Mobile Apps/General Mobile Architecture/","items":[]},{"title":"iOS","url":"/Webizen 2.0/Mobile Apps/iOS/","items":[]}]},{"title":"Web Of Things (IoT)","url":"","items":[{"title":"Web Of Things (IoT)","url":"/Webizen 2.0/Web Of Things (IoT)/Web Of Things (IoT)/","items":[]}]},{"title":"Webizen 2.0","url":"/Webizen 2.0/Webizen 2.0/","items":[]},{"title":"Webizen AI OS Platform","url":"/Webizen 2.0/Webizen AI OS Platform/","items":[]},{"title":"Webizen Pro Summary","url":"/Webizen 2.0/Webizen Pro Summary/","items":[]}]},{"title":"Webizen V1 Project Documentation","url":"/","items":[]}]}],"tagsGroups":[],"latestPosts":[{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/","title":"Handong1587","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-08-27-notes-on-suffix-array-and-manacher-algorithm/","title":"Notes on Suffix Array and Manacher Algorithm","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-10-07-notes-on-perceptrons/","title":"Notes On Perceptrons","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-04-notes-on-object-detection/","title":"Notes On Object Detection","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-11-10-notes-on-caffe-dev/","title":"Notes On Caffe Development","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-07-notes-on-l-bfgs/","title":"Notes On L-BFGS","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-10-softmax-logistic-sigmoid/","title":"Softmax Vs Logistic Vs Sigmoid","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-12-notes-on-dl-training/","title":"Notes On Deep Learning Training","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-14-notes-on-yolo/","title":"Notes On YOLO","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/old-work-archives/2018-webizen-net-au/resource-library/handong1587/drafts/2015-12-28-notes-on-ion/","title":"Notes On Inside-Outside Net","lastUpdatedAt":"2022-12-28T19:22:29.000Z","lastUpdated":"12/28/2022"},"frontmatter":{"draft":false,"tags":[]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}