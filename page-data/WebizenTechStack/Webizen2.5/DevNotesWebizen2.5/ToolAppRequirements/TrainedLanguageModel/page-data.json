{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ToolAppRequirements/TrainedLanguageModel/",
    "result": {"data":{"mdx":{"id":"d08548e0-aa42-5803-8965-dac1fd94781f","tableOfContents":{"items":[{"url":"#trained-language-model","title":"Trained Language Model","items":[{"url":"#mathematics-ontology","title":"Mathematics Ontology"}]}]},"fields":{"title":"Trained Language Model","slug":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ToolAppRequirements/TrainedLanguageModel/","url":"https://devdocs.webizen.org/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ToolAppRequirements/TrainedLanguageModel/","editUrl":"https://github.com/webizenai/devdocs/tree/main/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ToolAppRequirements/TrainedLanguageModel.md","lastUpdatedAt":"2023-02-08T07:47:07.000Z","lastUpdated":"2/8/2023","gitCreatedAt":"2023-02-08T07:47:07.000Z","shouldShowTitle":false},"frontmatter":{"title":"","description":null,"imageAlt":null,"tags":[],"date":null,"dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"trained-language-model\"\n  }, \"Trained Language Model\"), mdx(\"p\", null, \"This note provides some resources that are either duplicates or an extention of the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/PermissiveCommons/PCTOntologyModelling/PCTWebizenUseOfOntology/\",\n    \"title\": \"PCTWebizenUseOfOntology\"\n  }, \"PCTWebizenUseOfOntology\"), \" notes made also. \"), mdx(\"p\", null, \"In the webizen ecosystem; one of the objectives is to seek to create top-level ontology that is sought to be fit-for-purpose for applications relating to human beings (self); then sociosphere / sociology and biosphere ontologies.  in combination this may be considered an approach that seeks to distinguish our consciousness and our natural world; as something other than another persons 'thing'.  Then, whilst there are many ontologies to describe things, new ontologies may be created using natural language; which would in-turn also be defined in a way that creates meaningful relationships between existing ontologies and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/PermissiveCommons/PCTOntologyModelling/\",\n    \"title\": \"PCTOntologyModelling\"\n  }, \"PCTOntologyModelling\"), \" outputs.\"), mdx(\"p\", null, \"There are some existing Vocab Models that are defined using RDF/OWL.\"), mdx(\"p\", null, \"Any that are not listed below will be be added to \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://drive.google.com/drive/folders/1GVo9jTHBNk597u-jmmT9TFPbaNaSEhi4\"\n  }, \"this NLP google-drive repo\"), \" that also stores info about NLP related docs and notes (although there may be more elsewhere)\"), mdx(\"h2\", {\n    \"id\": \"mathematics-ontology\"\n  }, \"Mathematics Ontology\"), mdx(\"p\", null, \"The use of these works, whilst sought to be designed to support Human Centric principals (including Human Centric AI principals); will end-up being processed by a software agent (on a computer).  Perhaps therefore defining in the 'upper ontology' mathematics may in-turn improve support for 'comprehensible sense making' or in otherwords, inferencing, etc.\"), mdx(\"p\", null, \"LINKS:\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/CLLKazan/MathSearch\"\n  }, \"https://github.com/CLLKazan/MathSearch\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/CLLKazan/OntoMathPro\"\n  }, \"https://github.com/CLLKazan/OntoMathPro\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/CLLKazan/OntoMathPro/tree/develop\"\n  }, \"https://github.com/CLLKazan/OntoMathPro/tree/develop\")), mdx(\"h3\", {\n    \"id\": \"preexisting-large-language-models\"\n  }, \"Pre:Existing Large Language Models.\"), mdx(\"p\", null, \"Whilst investigating solutions, an array of existing language models have been identified that provide a great deal of the underlying data that is considered to be required, although the methods to employ best employ them is presently unclear. \"), mdx(\"p\", null, \"Whilst making a note of the work done previously making enquiries with ChatGPT as is illustrated by: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/VocabularyModelling/ChatGPTDynamicOntology/\",\n    \"title\": \"ChatGPTDynamicOntology\"\n  }, \"ChatGPTDynamicOntology\"), \" and in-turn the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/VocabularyModelling/\",\n    \"title\": \"VocabularyModelling\"\n  }, \"VocabularyModelling\"), \" folder has been created to 'create space' for more thougher investigation. In-order to illustrate the considerations; i'll start with illustrating the resources that i've found so far. \"), mdx(\"p\", null, \"Framenet: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://framenet.icsi.berkeley.edu/fndrupal/\"\n  }, \"https://framenet.icsi.berkeley.edu/fndrupal/\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/chanind/frame-semantic-transformer\"\n  }, \"https://github.com/chanind/frame-semantic-transformer\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/topics/framenet\"\n  }, \"https://github.com/topics/framenet\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/dbamman/latin-bert\"\n  }, \"https://github.com/dbamman/latin-bert\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://wordnet-rdf.princeton.edu/\"\n  }, \"http://wordnet-rdf.princeton.edu/\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://framenet.icsi.berkeley.edu/fndrupal/\"\n  }, \"https://framenet.icsi.berkeley.edu/fndrupal/\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Cyc\"\n  }, \"https://en.wikipedia.org/wiki/Cyc\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://old.datahub.io/dataset/opencyc\"\n  }, \"https://old.datahub.io/dataset/opencyc\"), \" is unavailable;  a version of it has been found: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/asanchez75/opencyc/blob/master/opencyc-latest.owl.gz\"\n  }, \"https://github.com/asanchez75/opencyc/blob/master/opencyc-latest.owl.gz\"), \" \"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.ontologyportal.org/\"\n  }, \"https://www.ontologyportal.org/\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/ontologyportal/sumo\"\n  }, \"https://github.com/ontologyportal/sumo\")), mdx(\"p\", null, \"OntoWordNet LINKS\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://lists.w3.org/Archives/Public/public-swbp-wg/2005Feb/0066.html\"\n  }, \"https://lists.w3.org/Archives/Public/public-swbp-wg/2005Feb/0066.html\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.w3.org/2001/sw/BestPractices/WNET/\"\n  }, \"https://www.w3.org/2001/sw/BestPractices/WNET/\")), mdx(\"p\", null, \"Other links\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://babelnet.org/\"\n  }, \"https://babelnet.org/\")), mdx(\"p\", null, \"NoteAlso: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.wordsapi.com/\"\n  }, \"https://www.wordsapi.com/\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/alammehwish/framester\"\n  }, \"https://github.com/alammehwish/framester\")));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"# Trained Language Model\n\nThis note provides some resources that are either duplicates or an extention of the [[PCTWebizenUseOfOntology]] notes made also. \n\nIn the webizen ecosystem; one of the objectives is to seek to create top-level ontology that is sought to be fit-for-purpose for applications relating to human beings (self); then sociosphere / sociology and biosphere ontologies.  in combination this may be considered an approach that seeks to distinguish our consciousness and our natural world; as something other than another persons 'thing'.  Then, whilst there are many ontologies to describe things, new ontologies may be created using natural language; which would in-turn also be defined in a way that creates meaningful relationships between existing ontologies and [[PCTOntologyModelling]] outputs.\n\nThere are some existing Vocab Models that are defined using RDF/OWL.\n\nAny that are not listed below will be be added to [this NLP google-drive repo](https://drive.google.com/drive/folders/1GVo9jTHBNk597u-jmmT9TFPbaNaSEhi4) that also stores info about NLP related docs and notes (although there may be more elsewhere)\n\n## Mathematics Ontology\n\nThe use of these works, whilst sought to be designed to support Human Centric principals (including Human Centric AI principals); will end-up being processed by a software agent (on a computer).  Perhaps therefore defining in the 'upper ontology' mathematics may in-turn improve support for 'comprehensible sense making' or in otherwords, inferencing, etc.\n\nLINKS:\nhttps://github.com/CLLKazan/MathSearch\nhttps://github.com/CLLKazan/OntoMathPro\nhttps://github.com/CLLKazan/OntoMathPro/tree/develop\n\n### Pre:Existing Large Language Models.\n\nWhilst investigating solutions, an array of existing language models have been identified that provide a great deal of the underlying data that is considered to be required, although the methods to employ best employ them is presently unclear. \n\nWhilst making a note of the work done previously making enquiries with ChatGPT as is illustrated by: [[ChatGPTDynamicOntology]] and in-turn the [[VocabularyModelling]] folder has been created to 'create space' for more thougher investigation. In-order to illustrate the considerations; i'll start with illustrating the resources that i've found so far. \n\nFramenet: https://framenet.icsi.berkeley.edu/fndrupal/\nhttps://github.com/chanind/frame-semantic-transformer\nhttps://github.com/topics/framenet\n\nhttps://github.com/dbamman/latin-bert\nhttp://wordnet-rdf.princeton.edu/\nhttps://framenet.icsi.berkeley.edu/fndrupal/\nhttps://en.wikipedia.org/wiki/Cyc\nhttps://old.datahub.io/dataset/opencyc is unavailable;  a version of it has been found: https://github.com/asanchez75/opencyc/blob/master/opencyc-latest.owl.gz \n\nhttps://www.ontologyportal.org/\nhttps://github.com/ontologyportal/sumo\n\nOntoWordNet LINKS\nhttps://lists.w3.org/Archives/Public/public-swbp-wg/2005Feb/0066.html\nhttps://www.w3.org/2001/sw/BestPractices/WNET/\n\nOther links\nhttps://babelnet.org/\n\nNoteAlso: https://www.wordsapi.com/\n\nhttps://github.com/alammehwish/framester","excerpt":"Trained Language Model This note provides some resources that are either duplicates or an extention of the [ PCTWebizenUseOfOntology ] note…","outboundReferences":[{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"pct-ontology-modelling\"\n  }, \"PCT Ontology Modelling\"), mdx(\"p\", null, \"This document is about Permissive Commons Technology - Ontology Modelling. The high-level introductory description of what ontologies and ontology modelling is about, has been moved to the page about \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/PermissiveCommons/PCTOntologyModelling/UnderstandingOntologies/\",\n    \"title\": \"UnderstandingOntologies\"\n  }, \"UnderstandingOntologies\"), \".\"), mdx(\"p\", null, \"In-order for \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/WebScience/ArtificialMinds/CognitiveAI/CognitiveAI-WIP/\",\n    \"title\": \"CognitiveAI-WIP\"\n  }, \"CognitiveAI-WIP\"), \" systems to meaningfully support the notion of 'common sense', semantic web related ontology technology is sought to be advanced.  In-turn, the objective is to seek to address a number of underlying issues that are considered to be problems with it.\"), mdx(\"h4\", {\n    \"id\": \"quicklinks\"\n  }, \"QuickLinks\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/PermissiveCommons/PCTOntologyModelling/OntologyModelling/\",\n    \"title\": \"OntologyModelling\"\n  }, \"OntologyModelling\"), \" - general introductory notes\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/PermissiveCommons/PCTOntologyModelling/PCTWebizenUseOfOntology/\",\n    \"title\": \"PCTWebizenUseOfOntology\"\n  }, \"PCTWebizenUseOfOntology\"), \" - info about the applied use of ontology\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/WebizenTechStack/VocabularyModelling/\",\n    \"title\": \"VocabularyModelling\"\n  }, \"VocabularyModelling\"), \" - general notes about language modelling\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/PermissiveCommons/PCTOntologyModelling/EnglishLanguageModelling/\",\n    \"title\": \"EnglishLanguageModelling\"\n  }, \"EnglishLanguageModelling\"), \" - specifically about english (NLP) ontology modelling\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/PermissiveCommons/PCTOntologyModelling/BiosphereOntologies/\",\n    \"title\": \"BiosphereOntologies\"\n  }, \"BiosphereOntologies\"), \" - (tbd better: needs top-level ontology)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/PermissiveCommons/PCTOntologyModelling/SocioSphereOntologies/\",\n    \"title\": \"SocioSphereOntologies\"\n  }, \"SocioSphereOntologies\"), \" - (tbd better: needs top-level & BiosphereOntology)\")), mdx(\"h4\", {\n    \"id\": \"webizen-diagram-a-basic-usecase-illustration\"\n  }, \"Webizen Diagram: A Basic UseCase Illustration\"), mdx(\"p\", null, \"\", mdx(\"figure\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"561px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/70aca/webizen_diagram_1-2.jpg\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"61.42857142857143%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIDBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe3GwlQ//8QAGRAAAgMBAAAAAAAAAAAAAAAAAREAECFB/9oACAEBAAEFAmz3YqGD/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFxAAAwEAAAAAAAAAAAAAAAAAAAExIP/aAAgBAQAGPwKjmf/EABoQAAMAAwEAAAAAAAAAAAAAAAABESExQVH/2gAIAQEAAT8hmCSb2Lk6cynkvKTXCPBoSC3PT//aAAwDAQACAAMAAAAQY8//xAAVEQEBAAAAAAAAAAAAAAAAAAAQIf/aAAgBAwEBPxCn/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGhABAAMBAQEAAAAAAAAAAAAAAQARITFBgf/aAAgBAQABPxAeVACtuvnyEXFQcLHvkEXhLXqVAeA+QXOWdPJqLRVq1n//2Q==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"webizen diagram 1 2\",\n    \"title\": \"webizen_diagram_1-2.jpg\",\n    \"src\": \"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/611f2/webizen_diagram_1-2.jpg\",\n    \"srcSet\": [\"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/e2e20/webizen_diagram_1-2.jpg 140w\", \"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/1631d/webizen_diagram_1-2.jpg 281w\", \"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/611f2/webizen_diagram_1-2.jpg 561w\", \"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/652d0/webizen_diagram_1-2.jpg 842w\", \"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/70aca/webizen_diagram_1-2.jpg 966w\"],\n    \"sizes\": \"(max-width: 561px) 100vw, 561px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"webizen_diagram_1-2.jpg\"), \"\\n  \"), \"\"), mdx(\"p\", null, \"The above diagram was produced as part of the process of seeking to get some sort of grasp on how to address the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/SocioEconomicTechReqs/GuardianshipRelations/\",\n    \"title\": \"GuardianshipRelations\"\n  }, \"GuardianshipRelations\"), \" problems. \"), mdx(\"p\", null, \"Further details about the applied usecases are described: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/PermissiveCommons/PCTOntologyModelling/PCTWebizenUseOfOntology/\",\n    \"title\": \"PCTWebizenUseOfOntology\"\n  }, \"PCTWebizenUseOfOntology\"), \"\"), mdx(\"p\", null, \"Part of the purpose of the illustration, is to denote the difference between a persons 'private and personal' \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Inforg\"\n  }, \"inforg\"), \" (seeAlso: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/old-work-archives/WebCivicsMediumPosts/2019/The%20Semantic%20Inforg%20&%20The%20%E2%80%9CHuman%20Centric%20Web%E2%80%9D%E2%80%8A%E2%80%94%E2%80%8AReality%20Check,%20Tech./\",\n    \"title\": \"The Semantic Inforg & The “Human Centric Web” — Reality Check, Tech.\"\n  }, \"The Semantic Inforg & The \\u201CHuman Centric Web\\u201D\\u200A\\u2014\\u200AReality Check, Tech.\"), \") and the resources that are electronically supplied as a consequence of social involvement with others.\"), mdx(\"p\", null, \"This is intended to be empowered via \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/WebScience/SafetyProtocols/ValuesCredentials/\",\n    \"title\": \"ValuesCredentials\"\n  }, \"ValuesCredentials\"), \" which in-turn require core ontologies; that are sought to be delivered using the PCT ecosystems.  \"), mdx(\"p\", null, \"Thereafter; the effect of these components, are intended to support the private operation of 'Webizen' (Agents). \"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"NOTE:  the end-concept of a 'webizen', is that it is a distinguishable class of robot, that is owned by an entity who is responsible for how it is made to operate; and that, all human beings using them, must first have their own.  This in-turn acts to support, \", mdx(\"a\", {\n    parentName: \"em\",\n    \"href\": \"/SocialFactors/WebScience/SafetyProtocols/HumanCentricDigitalIdentity/\",\n    \"title\": \"HumanCentricDigitalIdentity\"\n  }, \"HumanCentricDigitalIdentity\"), \", \", mdx(\"a\", {\n    parentName: \"em\",\n    \"href\": \"/SocialFactors/WebScience/SafetyProtocols/HumanCentricAI/\",\n    \"title\": \"HumanCentricAI\"\n  }, \"HumanCentricAI\"), \" via tooling, that will include a  \", mdx(\"a\", {\n    parentName: \"em\",\n    \"href\": \"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCT-Core-Services/HumanCentricOntology/\",\n    \"title\": \"HumanCentricOntology\"\n  }, \"HumanCentricOntology\"), \" structure - that can be further improved upon overtime\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"The objective for now, is to define the requirements to establish a functional \", mdx(\"a\", {\n    parentName: \"em\",\n    \"href\": \"/SocialFactors/CommercialModels/Webizen/\",\n    \"title\": \"Webizen\"\n  }, \"Webizen\"), \" ecosystem that is then able to be used to further progress the works, upon a common set of principals and technology that supports those socio-economic and technological foundations\")), \" \"), mdx(\"h4\", {\n    \"id\": \"technical-requirements\"\n  }, \"Technical Requirements\"), mdx(\"p\", null, \"The solution that can work, shouldn't consume more than 128MB or at most 1GB of RAM, depending on how the graph model may be processing - complex graphs; which should require upto 2GB RAM to operate in a basic way.  The use of GPU Processing may be employed, but shouldn't be required for whatever the basic solution is. Some GPUs do not have tensor cores whilst others may not support cuda or similar.  Conversely, in future implementations - the use of Neuromorphic Processors is being considered, and perhaps there are significantly beneficial applications for the use of these sorts of hardware components to expressly support the way these fundamental processes are processed. \"), mdx(\"p\", null, \"The complexity of the model will in-turn have various repercussions on performance and resource requirements.  The language model should also be designed to support voice interaction (ie: VoiceToText, and TextToVoice); which in-turn means it should support phonetic analysis. \"), mdx(\"p\", null, \"The language model should be able to work offline; the solution should not require continual communications with a public (cloud) API.   \"), mdx(\"p\", null, \"Perhaps moreover - the difference between 'NLP' and what this process is seeking to achieve, is that the software is not seeking to create an archive of the knowledge of human kind that is available to an AI agent to turn into one massive AI 'language model'; rather, what i'm seeking to achieve is the development of a very well defined vocabulary model, that can support the development of database structures, AI and therein - ontologies & interfaces.\"), mdx(\"p\", null, \"In-order to scope the broad notional concept; there's a question about whether to slim it down or first work to define a 'gold plated' model ie: \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"all the qualities that one might wish for if computing resources for all users wasn't a problem...\"), \"  and thereafter, seek to slim it down as required?  \"), mdx(\"h2\", {\n    \"id\": \"problem-statement\"\n  }, \"Problem Statement\"), mdx(\"p\", null, \"HTTP(s) Ontologies are published online using a HTTP server and ICANN DNS.  \"), mdx(\"p\", null, \"PROBLEM 1:  Often these resources disappear and may only later be found by searching for a record of it in \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://archive.org/\"\n  }, \"archive.org\"), \" or on github.  \"), mdx(\"p\", null, \"PROBLEM 2: The documents (and embedded semantics) may change without notice; and without a known mechanism to distinguish between the intended semantic meanings when defining the document vs. the future definitions that are engendered as a consequence of the content of an ontological dependency changing. \"), mdx(\"p\", null, \"PROBLEM 3:  The level of know-how relating to the production of ontologies can often lead to unintended meanings being semantically defined. \"), mdx(\"p\", null, \"PROBLEM 4:  Tools are most-often defined to be built around OWL which has a top-level concept of 'thing' and not everything relating to our conscious experience of life, is about things; nor are all entities things.\"), mdx(\"p\", null, \"PROBLEM 5:  In-order to decentralise and empower human kind, there must be a way to decentralise AI.  There are various complex reasons, implications and consequences; and whilst these sorts of ideologies may not be universally sought, for those who do want to ensure a means for tooling to support the needs of themselves and others as human beings in a way that requires Decentralised (Human Centric) AI - decentralising ontologies (and other assets) in a manner that can (with the use of cryptography alongside other patterns) provide a fit-for-purpose capacities to participatorily create, make use of and rely upon electronic resources - is essential for all persons who exist in socio-economic structures that are managed using electronic systems.\"), mdx(\"p\", null, \"As far as i am aware, there are not presently well-defined or well-known solutions that are 'fit for purpose' in relation to the requirements of the webizen project; The technical challenges include,\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Defining a way to create ontologies (documents) that are referencable; and,\\na. 'tamper evident'\\nb. temporally distinguishable.\\nc. Able to be targeted as a specific version or group; with logic support for different usecases.\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Defining cryptography methods 'ecosystem' that support the various usecases. (permissions, provonance, etc.)\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Support inferencing methods for 'common sense' related functions; including, a means to process and formulate appropriate responses if the derivative of a functional request renders a result that is 'unclear' (ie: not binary - Yes/No)\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Social Factors;\"), mdx(\"p\", {\n    parentName: \"li\"\n  }, \"a. Provide explainability of decision making processes; including, via the use of permission systems that may distinguish the rights of access to resources based upon external factors (ie: a victim / perpetrator making claims, vs. the capacities of a judge/jury in a court of law)\"), mdx(\"p\", {\n    parentName: \"li\"\n  }, \"b. Support for Children (ie: Content classifications)\"), mdx(\"p\", {\n    parentName: \"li\"\n  }, \"c. Support for storing and maintaining access to the information created by persons who have become deceased.\"), mdx(\"p\", {\n    parentName: \"li\"\n  }, \"d. Self-Archiving related methodologies; ideally, 'useful content' should never dissapear entirely; unless it becomes the case that no human being on the planet (voluntarily) wants to store it; or that it relates to some other complex use-case involving dignity (even then, perhaps the information should be stored somewhere as evidence, idk.  perhaps laws?)\"), mdx(\"p\", {\n    parentName: \"li\"\n  }, \"e. Support for basic economic considerations to be built into the protocols:  This is not about the commercial abuse of a payments system, rather, it is about seeking to ensure that there is a caculation done on the biosphere and socio-sphere implications, as to provide protocol level evidence of such things as energy use and a means to abolish the support that is presently wide-spread witth respect to issues such as digital slavery.\"))), mdx(\"h4\", {\n    \"id\": \"design-implications\"\n  }, \"Design Implications\"), mdx(\"p\", null, \"Somehow there needs to be;\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"A foundational ontology that defines requirements for a data-structure.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"A methodology that is able to be deployed over multiple \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/\",\n    \"title\": \"Non-HTTP(s)Protocols\"\n  }, \"Non-HTTP(s)Protocols\"), \"\")), mdx(\"h5\", {\n    \"id\": \"broader-considerations\"\n  }, \"Broader Considerations\"), mdx(\"p\", null, \"DNS:  it is entirely possible that part of the solution may be to advance solutions that provide an update to DNS. If this is the case, the solution would need to work Side-By-Side with existing DNS.  \"), mdx(\"p\", null, \"SocioEconomics:  There are material costs and gains associated with every human being, irraspective of age or competency.  Existing systems have defines means to extract economic value in relation to any human entity; but they have not well defined how to ensure every human entity is also entitled to be a beneficiary; and indeed also, how that might work. \"), mdx(\"p\", null, \"The \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/SocioEconomicTechReqs/GuardianshipRelations/\",\n    \"title\": \"GuardianshipRelations\"\n  }, \"GuardianshipRelations\"), \" document provides some initial texts in relation to this topic.\"), mdx(\"h2\", {\n    \"id\": \"pct-ontology-modelling-requirements\"\n  }, \"PCT Ontology Modelling Requirements\"), mdx(\"p\", null, \"\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/WebScience/TheValuesProject/\",\n    \"title\": \"TheValuesProject\"\n  }, \"TheValuesProject\"), \" seeks to employ various pre-existing well-known instruments; such as those that have been created via the United Nations and various other internationally well regarded groups and institutions, that are not presently available in an \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/CoreTechnologies/SemanticWeb/\",\n    \"title\": \"SemanticWeb\"\n  }, \"SemanticWeb\"), \" based format.  Some information about existing \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWebOntologies/\",\n    \"title\": \"SemWebOntologies\"\n  }, \"SemWebOntologies\"), \" is provided via that link (although, not exhaustively). \"), mdx(\"p\", null, \"In-order to support the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/WebScience/SafetyProtocols/\",\n    \"title\": \"SafetyProtocols\"\n  }, \"SafetyProtocols\"), \" and related ecosystems, some core work on the ontology methods is required; which will in-turn lead to the development of an ecosystem method for \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/PermissiveCommons/PCTOntologyModelling/SocioSphereOntologies/\",\n    \"title\": \"SocioSphereOntologies\"\n  }, \"SocioSphereOntologies\"), \" and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/PermissiveCommons/PCTOntologyModelling/BiosphereOntologies/\",\n    \"title\": \"BiosphereOntologies\"\n  }, \"BiosphereOntologies\"), \" to compliment existing systems that are well defined for \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"owl:thing\"), \" related requirements.\"), mdx(\"p\", null, \"Additionally, \"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"well known ontologies such as FOAF are now fairly outdated; \"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Most reasoning / ontologicial systems are very much centered aruond the use of OWL; which has a top-level predicate defining anything that employs it as a sub-classes of \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"owl:thing\"), \" \"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Ontologies are currently designed to refer to HTTP-URIs.  By employing \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/\",\n    \"title\": \"Non-HTTP(s)Protocols\"\n  }, \"Non-HTTP(s)Protocols\"), \" a method to define how to support various \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ToolAppRequirements/POCAppRequirements/\",\n    \"title\": \"POCAppRequirements\"\n  }, \"POCAppRequirements\"), \" is thereby invoked.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"A foundational structure needs to be defined to thereafter built upon; and some consideration is being made about what the most appropriate approach may well be.  \")), mdx(\"p\", null, \"Thereafter, once these considerations are better understood; then, there is an ability to create the ontological structures of those ontology documents, including references to other \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \".wellknown\"), \" ontologies and related intended inferencing models, can be better modelled.  \"), mdx(\"h2\", {\n    \"id\": \"pct-ontology-modelling-method\"\n  }, \"PCT Ontology Modelling Method\"), mdx(\"h3\", {\n    \"id\": \"ground-up-ontological-modelling-ideas\"\n  }, \"Ground-Up ontological modelling ideas....\"), mdx(\"h5\", {\n    \"id\": \"atomic-ontologies\"\n  }, \"Atomic Ontologies\"), mdx(\"p\", null, \"The concept of Atomic Ontologies - is about the idea of forming an ontological approach that describes one term; rather than an entire syntax.  thereafter, a group of these atomic ontological resources could be used to define more comprehensive ontological structures.\"), mdx(\"h5\", {\n    \"id\": \"foundational-requirements-rdf-dictionaries\"\n  }, \"Foundational Requirements: RDF Dictionaries?\"), mdx(\"p\", null, \"In-order to address the semantic ontology problems, perhaps the best way is to define a new approach to forming the foundational ontology via a different sort of modelling technique. \"), mdx(\"p\", null, \"An idea of how this may be achieved; is via the use of a dictionary as a sourcefile; for Generating a semantic dictionary using AI (NN/DL/ML); which may then act as a datasource for the creation of an app that provides support for modelling an ontological structure based upon those fundamental predicates. \"), mdx(\"p\", null, \"This initial process, would likely not include an array of terms that relate to brands and various areas of science, yet, the same process could be undertaken with other dictionaries.\"), mdx(\"p\", null, \"Thereby providing a means to create a mapping technique between the historical / traditional foundational predicates; and in-turn, the ability to generate more meaningful relationships with the meaning of other terms; and thereby provide an underlying context for producing ontological (knowledge) modelling.  \"), mdx(\"p\", null, \"Whilst i'm not sure if this theory has merit; i'm working to figure out how it might work now...  \"), mdx(\"p\", null, \"Part of the consideration is; whether and/or how these sorts of requirements might fit into an ecosystem that is designed to employ \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/WebScience/ArtificialMinds/CognitiveAI/CognitiveAI-WIP/\",\n    \"title\": \"CognitiveAI-WIP\"\n  }, \"CognitiveAI-WIP\"), \" related applied computer science theories and principles. \"), mdx(\"p\", null, \"NowTherefore; a few questions with unknown answers.\"), mdx(\"h3\", {\n    \"id\": \"forming-trustworthy-ontological-structures\"\n  }, \"Forming Trustworthy Ontological Structures\"), mdx(\"p\", null, \"The existing Sematnic Web tooling, is built upon HTTP(s) Identifiers and as noted otherwise, there are an array of qualities that are considered to be issues.  \"), mdx(\"p\", null, \"Given the permissive commons ecosystem works provide a foundational opportunity to redefine how these sorts of things are implemented; in a new and different sort of way that may extend beyond merely ensuring support via protocols other than HTTP(s) and related version control and permissions related ecosystem characteristics.\"), mdx(\"p\", null, \"I am now therefore working through some ideas that will remain largely undefined until the though processes are somewhat advanced (as a consequence of having done the work).\"), mdx(\"h3\", {\n    \"id\": \"discovery-work\"\n  }, \"Discovery work\"), mdx(\"p\", null, \"The content below is the discovery work that is being defined as it is written / produced, that is seeking to process a series of complex problems without a known answer or defined approach; as to catalogue related considerations in-order to create one (an approach)\"), mdx(\"p\", null, \"How to best construct an artificial learning model that provides a coheasive data-set as to support a systematic method for foundational principals that can then in-turn be employed for producing \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/PermissiveCommons/PCTOntologyModelling/SocioSphereOntologies/\",\n    \"title\": \"SocioSphereOntologies\"\n  }, \"SocioSphereOntologies\"), \", \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/PermissiveCommons/PCTOntologyModelling/BiosphereOntologies/\",\n    \"title\": \"BiosphereOntologies\"\n  }, \"BiosphereOntologies\"), \" and most importantly a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCT-Core-Services/HumanCentricOntology/\",\n    \"title\": \"HumanCentricOntology\"\n  }, \"HumanCentricOntology\"), \".\"), mdx(\"p\", null, \"The first objective would be to describe a method that can be used to create a resource (software) that is able to be used with the english language. \"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"(it goes without saying, that other languages should be supported - but i'm focusing firstly, upon the language i mostly use and best know)\")), mdx(\"p\", null, \"QUESTION:  is it better to start with the use of english or the use of mathematics; or is it best to ensure the use of both, in-order to create a bridge between human use of linquistics and the computational use of human language, in a way that's in-turn going to be used computationally.  \"), mdx(\"h3\", {\n    \"id\": \"english-language-concepts\"\n  }, \"English Language Concepts\"), mdx(\"p\", null, \"A few core concepts;\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Sentence - a set of words that is complete in itself, typically containing a subject and\\xA0predicate,\\xA0conveying\\xA0a statement, question,\\xA0exclamation, or command, and consisting of a main clause and sometimes one or more\\xA0subordinate\\xA0clauses.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"word - a single distinct meaningful element of speech or writing, used with others (or sometimes alone) to form a sentence and typically shown with a space on either side when written or printed.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"morphemes - a meaningful\\xA0morphological\\xA0unit of a language that cannot be further divided (e.g.\\xA0\", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"in\"), \",\\xA0\", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"come\"), \",\\xA0\", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"-ing\"), \", forming\\xA0\", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"incoming\"), \"\\xA0).\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Grammar - the whole system and structure of a language or of languages in general, usually taken as consisting of syntax and morphology (including\\xA0inflections) and sometimes also phonology and semantics.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"meaning - what is meant by a word, text, concept, or action.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"known - recognized, familiar, or within the scope of knowledge.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"explained - make (an idea or situation) clear to someone by describing it in more detail or revealing relevant facts.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"antecedent - a thing that existed before or\\xA0logically\\xA0precedes\\xA0another.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"consequent - following as a result or effect.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Translation - the process of\\xA0translating\\xA0words or text from one language into another.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"sense - a faculty by which the body\\xA0perceives\\xA0an external\\xA0stimulus; one of the\\xA0faculties\\xA0of sight, smell, hearing, taste, and touch.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Common Sense - good sense and sound judgement in practical matters.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Definition - a statement of the exact meaning of a word, especially in a dictionary.\")), mdx(\"p\", null, \"NOTE: above definitions are generally provided in relation to the use of the term as a noun.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"1.\\xA0NOUN\"), \" - \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A noun is the name of a person, place, thing, or idea.\"), \"\\n\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"2.\\xA0PRONOUN\"), \" - \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A pronoun is a word used in place of a noun.\"), \"\\n\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"3.\\xA0VERB\"), \" - \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A verb expresses action or being.\"), \"\\n\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"4.\\xA0ADJECTIVE\"), \" - \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An adjective modifies or describes a noun or pronoun.\"), \"\\n\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"5.\\xA0ADVERB\"), \" - \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An adverb modifies or describes a verb, an adjective, or another adverb.\"), \"\\n\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"6.\\xA0PREPOSITION\"), \" - \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A preposition is a word placed before a noun or pronoun to form a phrase modifying another word in the sentence.\"), \"\\n\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"7.\\xA0CONJUNCTION\"), \" - \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A conjunction joins words, phrases, or clauses.\"), \"\\n\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"8.\\xA0INTERJECTION\"), \" - \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An interjection is a word used to express emotion.\")), mdx(\"p\", null, \"One of the Antecedent to words is letters of an alphabet, which may in-turn be expressed in an array of computational codes - here's \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.rapidtables.com/convert/number/ascii-hex-bin-dec-converter.html\"\n  }, \"a tool that illustrates this\"), \".\"), mdx(\"h3\", {\n    \"id\": \"computational-language-concepts\"\n  }, \"Computational Language Concepts.\"), mdx(\"p\", null, \"Whilst seeking to make the note, i also understand the fundamental nature of it; apologies, \"), mdx(\"p\", null, \"Computers fundamentally 'speak' binary.  Various abstrations are thereby created, which are fundamentally based upon mathematics.   \"), mdx(\"p\", null, \"There are various 'command' structures that relate to different computational models; relating both, to hardware and software based instruction-sets.  The way through which this is performed has a significant impact on the amount of power (energy) and time (amount of processing required) to achieve some sort of derivative function.  Higher level languages or abstractions (from a computing point of view) are able to engender results that other lower-level methodologies are able to achieve with less time (computational horsepower) / energy.  \"), mdx(\"p\", null, \"Computers are not manufactured to comprehend natural (human) language; although, it is increasingly 'done' via increasingly sophistocated systems, etc.  \"), mdx(\"h6\", {\n    \"id\": \"consideration\"\n  }, mdx(\"strong\", {\n    parentName: \"h6\"\n  }, \"Consideration:\")), mdx(\"p\", null, \"If a possible approach to generate a foundational ontology relating to the use of the english language is able to be produced (and consequentially via use / contributions, refined); is it better to start with the predicates relating to computational language concepts, or human (natural) language concepts? or, is a AI model defined to process a model that involves both?\"), mdx(\"p\", null, \"Whilst the diagram is most certainly flawed / incorrect (requires more work) the general gist of the concept that i'm working through is difficult to conceptually construct; so i hope this helps (even if / as it has errors) - noting in particular, the importance of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/WebScience/Centricity/\",\n    \"title\": \"Centricity\"\n  }, \"Centricity\"), \" factors...\"), mdx(\"p\", null, \"\", mdx(\"figure\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"561px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/d835f99fadbe629ef6bf52c9cba9a001/b8284/AIOntology_concept_Issues.jpg\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"58.57142857142858%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAECBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHcG0ksP//EABcQAAMBAAAAAAAAAAAAAAAAAAABERD/2gAIAQEAAQUCHUVk3//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABkQAAIDAQAAAAAAAAAAAAAAAAAxAREgIf/aAAgBAQAGPwJk10WP/8QAGxABAAICAwAAAAAAAAAAAAAAAQARIWEQMZH/2gAIAQEAAT8hpTFIgQ0Jkc/ZV7gVe+P/2gAMAwEAAgADAAAAENvf/8QAFhEBAQEAAAAAAAAAAAAAAAAAABEh/9oACAEDAQE/EJqP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAHxAAAgICAQUAAAAAAAAAAAAAAREAITFBcRBRYYGh/9oACAEBAAE/ECA0Fh33jilhJXN/ZX1AoFL8xNgSUs+4OrZnnp//2Q==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"AIOntology concept Issues\",\n    \"title\": \"AIOntology_concept_Issues.jpg\",\n    \"src\": \"/static/d835f99fadbe629ef6bf52c9cba9a001/611f2/AIOntology_concept_Issues.jpg\",\n    \"srcSet\": [\"/static/d835f99fadbe629ef6bf52c9cba9a001/e2e20/AIOntology_concept_Issues.jpg 140w\", \"/static/d835f99fadbe629ef6bf52c9cba9a001/1631d/AIOntology_concept_Issues.jpg 281w\", \"/static/d835f99fadbe629ef6bf52c9cba9a001/611f2/AIOntology_concept_Issues.jpg 561w\", \"/static/d835f99fadbe629ef6bf52c9cba9a001/652d0/AIOntology_concept_Issues.jpg 842w\", \"/static/d835f99fadbe629ef6bf52c9cba9a001/b8284/AIOntology_concept_Issues.jpg 985w\"],\n    \"sizes\": \"(max-width: 561px) 100vw, 561px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"AIOntology_concept_Issues.jpg\"), \"\\n  \"), \"\"), mdx(\"p\", null, \"Therein - the general idea or concept is; to process the english language via a AI Process (meaning DL, ML, NN, CNN, etc.) in a manner that can thereafter be used to define a tool (Software Program) for producing RDF based ontologically defined assets / code (documents). \"), mdx(\"p\", null, \"The intended useful purpose of this program is to foundationally support the development of PCT Ontologies, which are in-turn a critical requirement for the production of PCT more broadly; including but not limited to, furnishing the means for others to form alternative and/or different foundational ontological schemas and related processes for logic mapping.\"), mdx(\"p\", null, \"Processing Dimentionalities\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Time\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Energy\")), mdx(\"p\", null, \"Both time and energy have complex attribution frameworks associated with the useful application of those concepts to different constituent 'ecosystems' processes.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Correctness and implication of incorrectness\")), mdx(\"p\", null, \"Methods to consider uncertainty. \"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Centricity\")), mdx(\"p\", null, \"Employing an Agent Centric Approach which employs the use of cryptography; whilst ensuring the operational use of it, is HumanCentric.  \"));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/PermissiveCommons/PCTOntologyModelling/","title":"PCT Ontology Modelling","shouldShowTitle":false}},{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"vocabulary-modelling\"\n  }, \"Vocabulary Modelling\"), mdx(\"p\", null, \"NOTE:  Related works are located in the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/PermissiveCommons/PCTOntologyModelling/\",\n    \"title\": \"PCTOntologyModelling\"\n  }, \"PCTOntologyModelling\"), \" folder.  This is intended to be more technical, as i'm working on some sort of implementation method.\"), mdx(\"p\", null, \"\", mdx(\"figure\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"561px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/05c47cdd5bb104ef59e7257797819ab4/f4296/20230119_webizenDBDiagram1.jpg\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"55.714285714285715%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAIBAwX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHchgUsD//EABgQAAMBAQAAAAAAAAAAAAAAAAABERAh/9oACAEBAAEFAmXiGTP/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAWEAADAAAAAAAAAAAAAAAAAAAQIDH/2gAIAQEABj8CET//xAAbEAACAgMBAAAAAAAAAAAAAAARIQABEEFRkf/aAAgBAQABPyEuiIjm70L9wAAKVP/aAAwDAQACAAMAAAAQEw//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAcEAEAAwEBAAMAAAAAAAAAAAABABExIVFBccH/2gAIAQEAAT8QCDC7eXZ5HR+XSdhRoFuPZl+v2NYgGByYn//Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"20230119 webizenDBDiagram1\",\n    \"title\": \"20230119_webizenDBDiagram1.jpg\",\n    \"src\": \"/static/05c47cdd5bb104ef59e7257797819ab4/611f2/20230119_webizenDBDiagram1.jpg\",\n    \"srcSet\": [\"/static/05c47cdd5bb104ef59e7257797819ab4/e2e20/20230119_webizenDBDiagram1.jpg 140w\", \"/static/05c47cdd5bb104ef59e7257797819ab4/1631d/20230119_webizenDBDiagram1.jpg 281w\", \"/static/05c47cdd5bb104ef59e7257797819ab4/611f2/20230119_webizenDBDiagram1.jpg 561w\", \"/static/05c47cdd5bb104ef59e7257797819ab4/652d0/20230119_webizenDBDiagram1.jpg 842w\", \"/static/05c47cdd5bb104ef59e7257797819ab4/b3430/20230119_webizenDBDiagram1.jpg 1122w\", \"/static/05c47cdd5bb104ef59e7257797819ab4/f4296/20230119_webizenDBDiagram1.jpg 1146w\"],\n    \"sizes\": \"(max-width: 561px) 100vw, 561px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"20230119_webizenDBDiagram1.jpg\"), \"\\n  \"), \"\"), mdx(\"p\", null, \"The Diagram above make an attempt to provide basic summary overview of how ontologies (vocabulary / languages) are used by these systems to define 'semantics'.\"), mdx(\"h4\", {\n    \"id\": \"human-users\"\n  }, \"Human Users\"), mdx(\"p\", null, \"The focus for Human Users presently is English (focus therein - AustralianEnglish, as well as other examples of it) as that's the only natural spoken / written language i am competent in.  Phonetics, tonality and other factors play a role with spoken speech; punctuation and grammar plays a role with written natural language alongside spelling.\"), mdx(\"p\", null, \"Courts use natural langague to process disputes, form common-sense and defined outcomes.  Further considerations are being made in the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/PermissiveCommons/PCTOntologyModelling/EnglishLanguageModelling/\",\n    \"title\": \"EnglishLanguageModelling\"\n  }, \"EnglishLanguageModelling\"), \" document.  This is in-turn not simply about english, but moreover about the broader series of considerations associted with trying to figure out how to define a solution for this component in a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/CommercialModels/BestEfforts/\",\n    \"title\": \"BestEfforts\"\n  }, \"BestEfforts\"), \" and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/CommercialModels/FitForPurpose/\",\n    \"title\": \"FitForPurpose\"\n  }, \"FitForPurpose\"), \" manner.\"), mdx(\"h4\", {\n    \"id\": \"computational-interference\"\n  }, \"Computational Interference\"), mdx(\"p\", null, \"There are many negative implications that develop when even basic AI related processes (ie: spellcheck helpers) re:define a term to another term, that changes the meaning of the sentence or concept that was intended to be communicated by the human being. \"), mdx(\"p\", null, \"These sorts of events create logs; and, complicate assessments - noting - i am not sure of a command that is \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \".wellknown\"), \" that allows a human being to assert a correction for an action that was made by a machine; or, any existing syntax that ensures a machines interference with a persons words is able to be logged, as part of that data-file.  \"), mdx(\"h3\", {\n    \"id\": \"software-agents\"\n  }, \"Software Agents\"), mdx(\"p\", null, \"Software agents fundamentally review english text on a computational basis - ending up with processes parsed in binary. \"), mdx(\"p\", null, \"However; there are various well-defined command structures that are in-effect a machine vocabulary that is contextual to the software / hardware environment. \"), mdx(\"p\", null, \"an instruction set, in-effect...\"), mdx(\"h4\", {\n    \"id\": \"human-centric-software-agent-considerations\"\n  }, \"Human Centric Software Agent Considerations\"), mdx(\"p\", null, \"Therein - one of the objective \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/WebScience/SafetyProtocols/\",\n    \"title\": \"SafetyProtocols\"\n  }, \"SafetyProtocols\"), \" related considerations should include the implications of computer generated deterministic content or artifacts interfering with AI modelling techniques - due to AI related inputs that are not properly labelled.\"), mdx(\"p\", null, \"The example being - 'autocorrect' issues...  changing the meaning of a sentence, and thereafter being employed to determine attributes about the natural agent. \"), mdx(\"h4\", {\n    \"id\": \"natural-language-modelling\"\n  }, \"Natural Language Modelling\"), mdx(\"p\", null, \"The language - english - has evolved over more than 1000 years, which makes it a fairly new language in the scheme of things; yet, the formation of it - has involved the use of many other terms and words that were used by various people who spoke various langauges at various times, in relation to various places.  \"), mdx(\"p\", null, \"Some investigation into related considerations can be found via the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/VocabularyModelling/ChatGPTDynamicOntology/\",\n    \"title\": \"ChatGPTDynamicOntology\"\n  }, \"ChatGPTDynamicOntology\"), \" and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/WebScience/ArtificialMinds/AChatGPTExperimentHolborn/\",\n    \"title\": \"AChatGPTExperimentHolborn\"\n  }, \"AChatGPTExperimentHolborn\"), \" chatlogs; and overall the process of gaining the volume of insights considered usefully important, is still a work in progress.  Indeed; there's an array of advanced concepts, that i think - that its unlikely i'm ever the expert in - so, whilst \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/CommercialModels/BestEfforts/\",\n    \"title\": \"BestEfforts\"\n  }, \"BestEfforts\"), \" are being made - the deliberations is, about seeking to ensure the foundational constructs support the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/\",\n    \"title\": \"SocialFactors\"\n  }, \"SocialFactors\"), \" and particularly therein; any \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/WebScience/SafetyProtocols/\",\n    \"title\": \"SafetyProtocols\"\n  }, \"SafetyProtocols\"), \" (whether noted or yet to be noted) that may be of instrumental importance, as to support the broader \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/WebScience/TheValuesProject/\",\n    \"title\": \"TheValuesProject\"\n  }, \"TheValuesProject\"), \" related implicit and explicit requirements. \"), mdx(\"p\", null, \"Anedotally, it appears to me that these sorts of problems - seemingly haven't been formerally addressed in a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/CommercialModels/FitForPurpose/\",\n    \"title\": \"FitForPurpose\"\n  }, \"FitForPurpose\"), \" way - which is unlikely to be due to some form of negligence in relation to the scientists involved at the time (although - \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/SocialAttackVectors/\",\n    \"title\": \"SocialAttackVectors\"\n  }, \"SocialAttackVectors\"), \" are very likely to have played a role with the consequential application of technology); rather, it is more likely that the technology of the time was unable to do the sorts of things that might otherwise be done, and perhaps sacrifices were made; and then built upon by others, using old work as foundational components for new works.  \"), mdx(\"p\", null, \"In-effect, the implication relates to the concept of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/SocialAttackVectors/CyberAttackVectors/TechDebt/\",\n    \"title\": \"TechDebt\"\n  }, \"TechDebt\"), \" although - not as is mentioned currently by that article.   There is a requirement to seek to ensure, that it is human beings who maintain primary responsibility for what it is they do and the effect of what they say.  AI models can be used to pervert and interfere in those sorts of underlying 'caculations' in ways that can lead to unwanted and/or unintended consequences; that in-turn relates to broader issues such as those noted about \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/SocialAttackVectors/CyberAttackVectors/NobodyAI/\",\n    \"title\": \"NobodyAI\"\n  }, \"NobodyAI\"), \".  \"), mdx(\"p\", null, \"So, the design implication; with respect to the broader and future objectives of the webizen ecosystem - in relation to forming a semantic vocabulary method and apparatus (program),\"), mdx(\"p\", null, \"Whilst my study is not exhaustive - noting people spend their entire lives studing these sorts of fields - which is not what i have done or do...  \"), mdx(\"p\", null, \"it appears to me that the roots of english end-up forming a fabric, that likely related to trade and the movement of people (including conflicts) that results in considerations that are temporally geospatial in nature; which thereafter become influenced by the politics and ideologies associated with groups over the course of space-time stuff, in-effect...  \"), mdx(\"p\", null, \"The ability to produce a 'system of excellence' is likely to require an enormous amount of computational capability; and in-turn, be forged through the use of known languages, over the course of at least the last 1500 years; which is a relatively simple task by comparison to many older languages, yet nonetheless - all somewhat 'linked together'...  \"), mdx(\"p\", null, \"These models would need to be defined in a way that supported continual training / learning.\"), mdx(\"p\", null, \"Yet, this is unlikely to provide a solution that is able to be made able to work on the sorts of devices commonly used by people - such as mobile phones and personal computers..  \"), mdx(\"p\", null, \"It is essential to ensure support for a technique that enables the private use of language, in a manner that can result with artifacts that are comprehensble to other Webizen Owners / users (the human beings - and in-turn, group entities - like companies, etc.).\"), mdx(\"p\", null, \"SO therefore; a high-level model is required that can support extensibility; whilst also, providing something that can be used as a basic component that requires relatively little computational resources on the device that it is functioning on.  This is demonstrated by existing dictionary software that has existed over a very long period of time; but, the desired functionality of this component, is considered to be desirably defined to be far more sophistocated.\"), mdx(\"p\", null, \"Fundamentally also: the objective is not to simply support the english language.  As i do not know other languages well enough, the only reasonable approach i have is to focus on the language i know, and hope that some of the insights and that all of the derivative 'product' output; is useful, for those who are better equipped to look at how to implement other languages.  In many ways, this is a sort of moral hygiene consideration; where the preference is, not to define others via a field of work / study / knowledge, that i do not know; which is intended to be intepreted as an attitude relating to care and consideration, rather than the opposite. \"));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/WebizenTechStack/VocabularyModelling/","title":"Vocabulary Modelling","shouldShowTitle":false}},{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"The notes below seek to illustrate the important role PCT ontologies facilitate.\"), mdx(\"h3\", {\n    \"id\": \"preface\"\n  }, \"Preface\"), mdx(\"p\", null, \"I'm exploring an idea about forming some sort of semantic database method that would use language (english) to structure the ontological predicates. \"), mdx(\"p\", null, \"Considerations are described in the note about \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/PermissiveCommons/PCTOntologyModelling/EnglishLanguageModelling/\",\n    \"title\": \"EnglishLanguageModelling\"\n  }, \"EnglishLanguageModelling\"), \".\"), mdx(\"p\", null, \"Part of the objective is to end up with a software model that can operate on a laptop (or mobile phone) privately.  I am not an expert software developer (coder); as such, there's some aspects to this particular field of endevour that relates to knowledge experts in a different field to my own may know well; but that, i do not.  Therein, if there's some basic answer that i'm not aware of please feel welcome to reach out either via the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.facebook.com/groups/humancentric.ai.tech\"\n  }, \"facebook HumanCentricAI Group\"), \" or contact me directly via \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.linkedin.com/in/ubiquitous/\"\n  }, \"linkedin\"), \" or join one of the community groups noted here: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/\",\n    \"title\": \"README\"\n  }, \"README\"), \"\"), mdx(\"p\", null, \"The webizen environment is intended to provide a high-degree of privacy, and in-turn the permissive commons systems is intended to operate in a manner that complies with the express permissions asserted by Legal Entities (humans and via them, legal entities).\"), mdx(\"p\", null, \"The underlying consideration is that the ability to 'think' and write something that may or may not be communicated to anyone else (or any other agent) should not be subject to interference or survellience.  Any implication any use of the english language either written or as is able to be intepreted via sensors (ie: microphones) for natural language processing, should be private - until such a time as the derivatives of that work are shared with someone else (a 3rd party agent); and even then, permissions and rules should be asserted to the rightful use of any-such derivatives of a persons thought-processes.  \"), mdx(\"p\", null, \"\", mdx(\"figure\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"561px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/ea7054e9626dc5ace3f0f5615dd332ee/4e5ca/Answers_meme.jpg\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"97.85714285714285%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAQFA//EABYBAQEBAAAAAAAAAAAAAAAAAAABAv/aAAwDAQACEAMQAAAB1oJpo22Yy4bRm0CP/8QAGxAAAgMBAQEAAAAAAAAAAAAAAQIAAxIEITH/2gAIAQEAAQUCZ/C2DsGaKRujZ3W05qhcyKqEfP/EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQMBAT8BH//EABcRAQADAAAAAAAAAAAAAAAAABACITH/2gAIAQIBAT8Bslp//8QAHhAAAgIBBQEAAAAAAAAAAAAAAAECESEDEBIiMkH/2gAIAQEABj8C6mXRl5PRVNluWqn9HztlQilt/8QAGhABAAMBAQEAAAAAAAAAAAAAAQARITFBUf/aAAgBAQABPyE2jFjicd7D5l3ZsyyjtD0IbE+Ilujy4aIvyK4//9oADAMBAAIAAwAAABCHEID/xAAWEQEBAQAAAAAAAAAAAAAAAAAQASH/2gAIAQMBAT8Qwh//xAAZEQACAwEAAAAAAAAAAAAAAAAAARARITH/2gAIAQIBAT8QpXvCh3iP/8QAHRABAQADAAIDAAAAAAAAAAAAAREAITFxgUFRYf/aAAgBAQABPxA0gMdfGVhgAfWtieDKbuIaI/XMnqBgnHNHmhVfWWX5psH806wM8l5D5wcBVjb7xgV3n//Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Answers meme\",\n    \"title\": \"Answers_meme.jpg\",\n    \"src\": \"/static/ea7054e9626dc5ace3f0f5615dd332ee/611f2/Answers_meme.jpg\",\n    \"srcSet\": [\"/static/ea7054e9626dc5ace3f0f5615dd332ee/e2e20/Answers_meme.jpg 140w\", \"/static/ea7054e9626dc5ace3f0f5615dd332ee/1631d/Answers_meme.jpg 281w\", \"/static/ea7054e9626dc5ace3f0f5615dd332ee/611f2/Answers_meme.jpg 561w\", \"/static/ea7054e9626dc5ace3f0f5615dd332ee/652d0/Answers_meme.jpg 842w\", \"/static/ea7054e9626dc5ace3f0f5615dd332ee/4e5ca/Answers_meme.jpg 1079w\"],\n    \"sizes\": \"(max-width: 561px) 100vw, 561px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"Answers_meme.jpg\"), \"\\n  \"), \"\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"When getting 'stuck into' the design challenge, the implication became a process of engaging in the study of language in a way, that i hadn't done in a similar way earlier. This is in-turn part of the practical undertaking of trying to figure out what the best possible (based upon what is known now) solutions architecture for addressing this problem; both in the more immediate term, and consequentially thereafter.  it is desirable that the implementation approach is able to evolve overtime (growth, evolution, 'upgradability', etc.) rather than necessarily being entirely replaced, however i may not have the skills and/or support (resources) to be able to achieve this goal for the POC solution.  I also want to expressly note; the underlying sentiments being considered in relation to english - as do in-turn relate to my identity, who and how i communicate and 'think' is sought to be supportively considered for others whose life relates to languages other than english.  Yet, the implications are not simple, as the words used in english are often from other languages (historically).  In-order to form a formal modelling technique, i am now-therefore seeking to work through the complexities, as to form a basis upon which a reduction process may be appropriately therefore undertaken.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"ALSO: As an Australian, I am particularly interested in seeking to support indigenous languages, and in other areas - hearldy and similarly pictorially defined languages are also an area of interest..\")), mdx(\"h2\", {\n    \"id\": \"technology-considerations\"\n  }, \"Technology Considerations\"), mdx(\"h4\", {\n    \"id\": \"pct--webizen---considerations\"\n  }, \"PCT & Webizen - Considerations\"), mdx(\"p\", null, \"Whilst most either don't know about it or don't understand it at all, the way much of our ICT infrastructure build around world-wide-web linked ecosystems functions today is through the use of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/CoreTechnologies/SemanticWeb/\",\n    \"title\": \"SemanticWeb\"\n  }, \"SemanticWeb\"), \" technologies; and in-particular therein, the use of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWebOntologies/\",\n    \"title\": \"SemWebOntologies\"\n  }, \"SemWebOntologies\"), \" which have been designed in a particular way, with particular characteristics, properties and functional purposes / objectives.  There are some functions and applications that these ecosystems do very well; yet this is not universally the case.  The ability to Decentralise has been both an objective and problem, for a very long time.  The growth of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/\",\n    \"title\": \"Non-HTTP(s)Protocols\"\n  }, \"Non-HTTP(s)Protocols\"), \" is in-part due to the consequences of decisions that have been made that have acted to limit and/or frustrate any means sought to be undertaken to decentralise the management of information; from incorporated entities to (better support) humans; and/or, to better support an approach that is inclusive and supportive of the role of humans, in relation to the beneficial use of technology.  In many ways these issues are fundamental to the cause of many \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/SocialFactors/SocialAttackVectors/\",\n    \"title\": \"SocialAttackVectors\"\n  }, \"SocialAttackVectors\"), \" that have been furnished opportunity to proliferate harmfully. \"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"in anycase (sorry, got a bit off-topic, but only 'kind of')\")), mdx(\"p\", null, \"As a consequence of the design differences of the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/PermissiveCommons/PermissiveCommonsTech/\",\n    \"title\": \"PermissiveCommonsTech\"\n  }, \"PermissiveCommonsTech\"), \" and in-turn also the functional designs of the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/\",\n    \"title\": \"WebizenTechStack\"\n  }, \"WebizenTechStack\"), \" that relies upon PCT; there is an opportunity to redefine how ontologies are defined and made able to function.  This is not unlike the practical realities that are employed by any software development that uses a database; and that consequentially, they define their own \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Database_schema\"\n  }, \"Database Schema\"), \", yet in this case - the ecosystems are being throughtfully designed to be decentralised.\"), mdx(\"p\", null, \"So, whilst there needs to be interfaces / APIs that support interactions with other systems, including various \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWebOntologies/\",\n    \"title\": \"SemWebOntologies\"\n  }, \"SemWebOntologies\"), \"; this does not need to be the native methodology that is employed within the Permissive Commons Technology ecosystem.  Indeed also, there are a variety of necessary changes that must be made, in-order to make the technology functional at all.  \"), mdx(\"p\", null, \"Nowtherefore; and, in consideration, rather than employing the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/CoreTechnologies/SemanticWeb/\",\n    \"title\": \"SemanticWeb\"\n  }, \"SemanticWeb\"), \" tooling directly, which is to some-degree an incorrect statement, as whatever the solution design becomes - it'll end-up being produced through the use of SemWeb resources.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"NOTE: the use of SemWeb technologies more directly waas considered important in previous implementation designs focused upon \", mdx(\"a\", {\n    parentName: \"em\",\n    \"href\": \"/old-work-archives/WebCivicsMediumPosts/2019/Knowledge%20Banking%20Infrastructure/\",\n    \"title\": \"Knowledge Banking Infrastructure\"\n  }, \"Knowledge Banking Infrastructure\"), \".  However, these works were found to be unsupported (indeed, i was subjected to various \", mdx(\"a\", {\n    parentName: \"em\",\n    \"href\": \"/SocialFactors/SocialAttackVectors/\",\n    \"title\": \"SocialAttackVectors\"\n  }, \"SocialAttackVectors\"), \" consequentially) seemingly due to the nature of how the designs sought to ensure support for human rights and the means for human beings to own their own data as is in-turn required for the \", mdx(\"a\", {\n    parentName: \"em\",\n    \"href\": \"/SocialFactors/WebScience/SafetyProtocols/HumanCentricAI/\",\n    \"title\": \"HumanCentricAI\"\n  }, \"HumanCentricAI\"), \" capabilities irraspective of broader implementation designs; rather than seeing these sorts of qualities as an opportunity, it was seemingly deemed to be a threat - to whatever it was they were prioritising above all else.\"), \" \"), mdx(\"p\", null, \"Nonetheless; as a consequence of hte design shifts that are presented via these notes more broadly, there is an opportunity to define how the root or 'top level' ontology is defined; and the hypothesis is, that perhaps it can be defined using natural language.\"), mdx(\"p\", null, \"If this approach has validity, part of the intended outcome would seek to conclude how it is that vocabulary ends-up being part of the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/CoreServices/\",\n    \"title\": \"CoreServices\"\n  }, \"CoreServices\"), \" stack, as is thereby employed as a foundational library for everything else that's built on top of it.  \"), mdx(\"h3\", {\n    \"id\": \"permissive-commons-technology--webizen-ecosystems\"\n  }, \"Permissive Commons Technology & Webizen Ecosystems\"), mdx(\"h4\", {\n    \"id\": \"background-on-the-importance-of-top-level-ontology\"\n  }, \"Background on the Importance of Top-Level Ontology\"), mdx(\"p\", null, \"Both the Permissive Commons Technology and Webizen systems use ontologies (and cryptography) as the primary means for defining 'functionality' and the structure of how to access resources. \"), mdx(\"p\", null, \"Ontologies are used throughout the systems for many different purposes, including but not limited to - providing the means to structure electronic assets in a manner that is thereby able to be used in a decentralised way (with permissions, defined using ontologies) across the ecosystem.  \"), mdx(\"p\", null, \"\", mdx(\"figure\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"561px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/05c47cdd5bb104ef59e7257797819ab4/f4296/20230119_webizenDBDiagram1.jpg\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"55.714285714285715%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAIBAwX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHchgUsD//EABgQAAMBAQAAAAAAAAAAAAAAAAABERAh/9oACAEBAAEFAmXiGTP/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAWEAADAAAAAAAAAAAAAAAAAAAQIDH/2gAIAQEABj8CET//xAAbEAACAgMBAAAAAAAAAAAAAAARIQABEEFRkf/aAAgBAQABPyEuiIjm70L9wAAKVP/aAAwDAQACAAMAAAAQEw//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAcEAEAAwEBAAMAAAAAAAAAAAABABExIVFBccH/2gAIAQEAAT8QCDC7eXZ5HR+XSdhRoFuPZl+v2NYgGByYn//Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"20230119 webizenDBDiagram1\",\n    \"title\": \"20230119_webizenDBDiagram1.jpg\",\n    \"src\": \"/static/05c47cdd5bb104ef59e7257797819ab4/611f2/20230119_webizenDBDiagram1.jpg\",\n    \"srcSet\": [\"/static/05c47cdd5bb104ef59e7257797819ab4/e2e20/20230119_webizenDBDiagram1.jpg 140w\", \"/static/05c47cdd5bb104ef59e7257797819ab4/1631d/20230119_webizenDBDiagram1.jpg 281w\", \"/static/05c47cdd5bb104ef59e7257797819ab4/611f2/20230119_webizenDBDiagram1.jpg 561w\", \"/static/05c47cdd5bb104ef59e7257797819ab4/652d0/20230119_webizenDBDiagram1.jpg 842w\", \"/static/05c47cdd5bb104ef59e7257797819ab4/b3430/20230119_webizenDBDiagram1.jpg 1122w\", \"/static/05c47cdd5bb104ef59e7257797819ab4/f4296/20230119_webizenDBDiagram1.jpg 1146w\"],\n    \"sizes\": \"(max-width: 561px) 100vw, 561px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"20230119_webizenDBDiagram1.jpg\"), \"\\n  \"), \"\"), mdx(\"p\", null, \"The historical tools used for ontologies are broadly known to be part of the broader 'semantic web' ecosystem; which declares a HTTP Namespace in connection to an ontology document, which other documents and systems are thereby defined to employ.  Yet it is often the case that the original source (the HTTP URI) either changes or  becomes unavailable overtime.  The implications for technology that is designed to make use of those ontologies in a decentralised manner, is that dependencies become unreliable.  This issue was considered by the Concept of CoolURIs in which it is noted that \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.w3.org/Provider/Style/URI\"\n  }, \"Cool URIs don't change\"), \" and a related \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.w3.org/TR/cooluris/\"\n  }, \"W3C Document was produced on the topic also\"), \", yet as is able to be demonstrated via the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWebOntologies/\",\n    \"title\": \"SemWebOntologies\"\n  }, \"SemWebOntologies\"), \" today, this is still an on-going problem.  Thereafter; one of the fundamental purposes of Permissive Commons is to address this issue alongside other issues that are related to version control and in-turn also, provide a decentralised means to manage archival materials.\"), mdx(\"p\", null, \"As such; PCT and thereby also Webizen systems are designed to provide support for the storage and use of ontologies that are sourced from protocols other than HTTP(s); even though, the primary communications protocols are build upon the use of web-protocols (http, ws, webrtc, etc.); the underlying 'informatics tools' (ie: ontologies and 'hypermedia containers') make use of non-http-protocols, as a means to provide functionality that is not easily facilitated via WWW.  The format of PCT is intended to REQUIRE a HTTP(s) URI as well as information about the location of those ontology assets on other PCT supported protocols, yet the dependency of relying upon the HTTP(s) URI alone, is effectively quashed. \"), mdx(\"p\", null, \"Different protocols support different qualities and will be employed for different purposes; these definitions are intended to be defined - using PCT ontology.  the ecosystem is intended to be designed to seek to ensure \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCTEngineeringConsiderations/Protocolindependence/\",\n    \"title\": \"Protocolindependence\"\n  }, \"Protocolindependence\"), \" (subject to the functionality provided by different protocols and the usefulness of protocols). \"), mdx(\"p\", null, \"Webizen Agents and in-turn also, applications; are intended to function using Ontology.  \"), mdx(\"p\", null, \"The extensibility of AI capabilities, is intended to be harmonised into the Webizen ecosystem using ontology.  \"), mdx(\"h4\", {\n    \"id\": \"webizen-network-flexibility\"\n  }, \"Webizen Network Flexibility\"), mdx(\"p\", null, \"The Webizen ecosystem requires support via a VPN like tunnelling technique; in-order to support 'fully qualified domain names' for users, whose devices are connected on dynamic IP addresses behind firewalls.  This in-turn introduces an opportunity to review how DNS might be employed within the network, as to provide support for an ecosystems solution that is made to work in a complimentary manner (ie: doesn't clash) with external / public ICANN DNS, which may also lead to different opportunities for refactoring other older standards related works as is the topic of the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/PermissiveCommons/PermissiveCommonsTech/PCTWorkInProgress/DIDsEval/\",\n    \"title\": \"DIDsEval\"\n  }, \"DIDsEval\"), \".  \"), mdx(\"p\", null, \"In-order to build the software that operates the underlying 'read-write' server/client, a database structure needs to be defined; and thereafter, built upon, using ontologies. \"), mdx(\"p\", null, \"An additional diagram provides a basic summary below.\"), mdx(\"p\", null, \"\", mdx(\"figure\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"561px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/70aca/webizen_diagram_1-2.jpg\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"61.42857142857143%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIDBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe3GwlQ//8QAGRAAAgMBAAAAAAAAAAAAAAAAAREAECFB/9oACAEBAAEFAmz3YqGD/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFxAAAwEAAAAAAAAAAAAAAAAAAAExIP/aAAgBAQAGPwKjmf/EABoQAAMAAwEAAAAAAAAAAAAAAAABESExQVH/2gAIAQEAAT8hmCSb2Lk6cynkvKTXCPBoSC3PT//aAAwDAQACAAMAAAAQY8//xAAVEQEBAAAAAAAAAAAAAAAAAAAQIf/aAAgBAwEBPxCn/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGhABAAMBAQEAAAAAAAAAAAAAAQARITFBgf/aAAgBAQABPxAeVACtuvnyEXFQcLHvkEXhLXqVAeA+QXOWdPJqLRVq1n//2Q==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"webizen diagram 1 2\",\n    \"title\": \"webizen_diagram_1-2.jpg\",\n    \"src\": \"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/611f2/webizen_diagram_1-2.jpg\",\n    \"srcSet\": [\"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/e2e20/webizen_diagram_1-2.jpg 140w\", \"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/1631d/webizen_diagram_1-2.jpg 281w\", \"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/611f2/webizen_diagram_1-2.jpg 561w\", \"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/652d0/webizen_diagram_1-2.jpg 842w\", \"/static/e39385d63bd9c0d0e64d5b94efd1e7b0/70aca/webizen_diagram_1-2.jpg 966w\"],\n    \"sizes\": \"(max-width: 561px) 100vw, 561px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"webizen_diagram_1-2.jpg\"), \"\\n  \"), \"\"), mdx(\"p\", null, \"Therein - the 'personal vault' - is entirely private, whereas the 'PCT DB' stores and communiates information that is shared with at least one other 'person' (entity or 3rd party agent). The Webizen (ai) agent; is required to operate in a manner that is controlled and defined by the owner of that agent; which thereafter includes a requirement to support the agreements that have been made electronically with others, using cryptographic instruments (credentials, essentially) that are defined - via ontologies. \"), mdx(\"p\", null, \"Whilst there are existing semantic web ontologies; the process of defining a different ecosystem presents an opportunity to redefine how the ontology ecosystem is designed to work 'natively'; therein, whilst mapping to other ontologies is part of how these systems are designed to work;  the question becomes, how might one best form a new solution, in 2023.\"), mdx(\"p\", null, \"A few requirements to support analysis of the context. \"), mdx(\"h4\", {\n    \"id\": \"run-locally\"\n  }, \"Run Locally\"), mdx(\"p\", null, \"The requirement is to end-up with a solution that can be run with a relatively minor amount of hardware resources on a stanard laptop / desktop machine.  This means, that whilst it should be far more sophistocated that traditional 'dictionary' software; it shouldn't require a connection to an online - 'global language model' or 3rd party online service, in-order to function.  As such, there's a variety of considerations about the level of sophistocation that is reasonably feasible; which in-turn, also relates to the approach taken to achieve an outcome.\"), mdx(\"h4\", {\n    \"id\": \"personal-vs-commons\"\n  }, \"Personal Vs. Commons\"), mdx(\"p\", null, \"The solution should support both; the ability for persons to structure their own private semantic 'datastore' in a manner that reflects how they naturally structure the use of vocabulary with mind, whilst noting that this is subject to change and evolution; as well as, being able to participatorily support shared structures - that may be different or a form of translation from what and how it is that they would personally employ language, etc. \"), mdx(\"p\", null, \"These considerations are distinct from the misuse of language (ie: false understandings or beliefs that words might mean one thing - when in-fact the term might mean something else entirely or be intepreted to have the opposite meaning, to what the natural agent intended).\"), mdx(\"h2\", {\n    \"id\": \"mathematics-ontology\"\n  }, \"Mathematics Ontology\"), mdx(\"p\", null, \"The use of these works, whilst sought to be designed to support Human Centric principals (including Human Centric AI principals); will end-up being processed by a software agent (on a computer).  Perhaps therefore defining in the 'upper ontology' mathematics may in-turn improve support for 'comprehensible sense making' or in otherwords, inferencing, etc.\"), mdx(\"p\", null, \"LINKS:\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/CLLKazan/MathSearch\"\n  }, \"https://github.com/CLLKazan/MathSearch\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/CLLKazan/OntoMathPro\"\n  }, \"https://github.com/CLLKazan/OntoMathPro\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/CLLKazan/OntoMathPro/tree/develop\"\n  }, \"https://github.com/CLLKazan/OntoMathPro/tree/develop\")), mdx(\"h3\", {\n    \"id\": \"preexisting-large-language-models\"\n  }, \"Pre:Existing Large Language Models.\"), mdx(\"p\", null, \"Whilst investigating solutions, an array of existing language models have been identified that provide a great deal of the underlying data that is considered to be required, although the methods to employ best employ them is presently unclear. \"), mdx(\"p\", null, \"Whilst making a note of the work done previously making enquiries with ChatGPT as is illustrated by: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/VocabularyModelling/ChatGPTDynamicOntology/\",\n    \"title\": \"ChatGPTDynamicOntology\"\n  }, \"ChatGPTDynamicOntology\"), \" and in-turn the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/VocabularyModelling/\",\n    \"title\": \"VocabularyModelling\"\n  }, \"VocabularyModelling\"), \" folder has been created to 'create space' for more thougher investigation. In-order to illustrate the considerations; i'll start with illustrating the resources that i've found so far. \"), mdx(\"p\", null, \"Framenet: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://framenet.icsi.berkeley.edu/fndrupal/\"\n  }, \"https://framenet.icsi.berkeley.edu/fndrupal/\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/chanind/frame-semantic-transformer\"\n  }, \"https://github.com/chanind/frame-semantic-transformer\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/topics/framenet\"\n  }, \"https://github.com/topics/framenet\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/dbamman/latin-bert\"\n  }, \"https://github.com/dbamman/latin-bert\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://wordnet-rdf.princeton.edu/\"\n  }, \"http://wordnet-rdf.princeton.edu/\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://framenet.icsi.berkeley.edu/fndrupal/\"\n  }, \"https://framenet.icsi.berkeley.edu/fndrupal/\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Cyc\"\n  }, \"https://en.wikipedia.org/wiki/Cyc\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://old.datahub.io/dataset/opencyc\"\n  }, \"https://old.datahub.io/dataset/opencyc\"), \" is unavailable;  a version of it has been found: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/asanchez75/opencyc/blob/master/opencyc-latest.owl.gz\"\n  }, \"https://github.com/asanchez75/opencyc/blob/master/opencyc-latest.owl.gz\"), \" \"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.ontologyportal.org/\"\n  }, \"https://www.ontologyportal.org/\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/ontologyportal/sumo\"\n  }, \"https://github.com/ontologyportal/sumo\")), mdx(\"p\", null, \"OntoWordNet LINKS\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://lists.w3.org/Archives/Public/public-swbp-wg/2005Feb/0066.html\"\n  }, \"https://lists.w3.org/Archives/Public/public-swbp-wg/2005Feb/0066.html\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.w3.org/2001/sw/BestPractices/WNET/\"\n  }, \"https://www.w3.org/2001/sw/BestPractices/WNET/\")), mdx(\"p\", null, \"Other links\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://babelnet.org/\"\n  }, \"https://babelnet.org/\")), mdx(\"p\", null, \"NoteAlso: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.wordsapi.com/\"\n  }, \"https://www.wordsapi.com/\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/alammehwish/framester\"\n  }, \"https://github.com/alammehwish/framester\")), mdx(\"p\", null, \"NOTE: i was also thinking about something that's more like '@enNoun' or '@enNounAu' rather than simply '@en' or '@en_au', etc. But still working on how to formulate the basic concept. Fundamentally, re: nlp / ml/dl, etc. I wasn't sure how complex it might be, whilst seeking to ensure it doesn't consume too much memory / processing power.\"));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/PermissiveCommons/PCTOntologyModelling/PCTWebizenUseOfOntology/","title":"PCTWebizenUseOfOntology","shouldShowTitle":true}},{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"dynamic-ontology\"\n  }, \"Dynamic Ontology\"), mdx(\"p\", null, \"The below text is sourced via the Q&A with ChatGPT to figure out how to create a dynamic ontology solution.  What i'm then doing, is going through and making notes in interleave. \"), mdx(\"p\", null, \"The solution is not intended to be operated by ChatGPT  - rather, this is intended to be a root resource employed locally on systems. \"), mdx(\"h2\", {\n    \"id\": \"chatgpt-interactive-notes\"\n  }, \"ChatGPT Interactive Notes\"), mdx(\"p\", null, \"I am working on a project that seeks to create innovative semantic web related technology. I don't like OWL being used for human beings and as a means to describe parts of our biosphere that is not property of a company, but rather something that is of earth. To address this problem, i am trying to figure out how to create a machine-learning training program, that would be provided an english language dictionary, including information about the use of words in the context of them being used as a NOUN, PRONOUN, VERB, ADJECTIVE, ADVERB, PREPOSITION, CONJUNCTION or INTERJECTION and related descriptions of the definition provided using the english language. The program would process this information and provide a model that can be used for the purpose of defining a top-level ontology that can be used with RDF and RDFS for the creation of RDF ontologies. How can this be achieved?\"), mdx(\"p\", null, \"ChatGPT:\"), mdx(\"p\", null, \"There are several ways to approach this problem of creating a machine-learning training program that can process an English language dictionary and provide a model for defining a top-level ontology that can be used with RDF and RDFS. One approach would be to use natural language processing (NLP) techniques to automatically extract information about the usage and meaning of words in the dictionary.\"), mdx(\"p\", null, \"One specific method to achieve this would be to use a supervised machine learning algorithm, such as a neural network. This would involve training the algorithm on a large dataset of labeled examples of text, where the label is the part of speech (e.g. noun, verb, adjective) and its definition. The algorithm would learn to predict the part of speech and definition based on the input text.\"), mdx(\"p\", null, \"Another approach would be to use unsupervised learning methods such as topic modeling, where the algorithm would be able to identify the latent topics represented by the words and its definition.\"), mdx(\"p\", null, \"Additionally, it's important to note that this is a big task and it would require a lot of computational power and time to process the data, and might require a team of experts in the field of NLP and machine learning to implement it.\"), mdx(\"p\", null, \"Once you have the model, it can be used to automatically classify new words and phrases and generate the top-level ontology for RDF and RDFS. This would allow you to automatically generate RDF ontologies that are more accurate and comprehensive than those created by manual annotation.\"), mdx(\"p\", null, \"Another approach to achieve this would be to use a combination of rule-based and machine learning methods. In this approach, a set of rules would be manually defined to extract information about the usage and meaning of words in the dictionary. These rules would be based on the grammar and syntax of the English language, and would be used to identify and classify words based on their part of speech and definition.\"), mdx(\"p\", null, \"The rule-based system would be used as a pre-processing step to extract the information, and then a machine learning model would be trained on this pre-processed data to improve the accuracy of the classification.\"), mdx(\"p\", null, \"It's also worth mentioning that it's important to have a large, diverse and representative dataset to train the model on, so that the model can generalize well to unseen data.\"), mdx(\"p\", null, \"Additionally, you may want to consider using pre-trained language models like BERT, RoBERTa, GPT-3, etc, that have been trained on large amounts of text data and can be fine-tuned to perform the specific task of part-of-speech tagging and definition extraction.\"), mdx(\"p\", null, \"Once you have the model, it can be used to automatically classify new words and phrases and generate the top-level ontology for RDF and RDFS. This would allow you to automatically generate RDF ontologies that are more accurate and comprehensive than those created by manual annotation.\"), mdx(\"p\", null, \"Another approach to achieve this would be to use a combination of rule-based and machine learning methods. In this approach, a set of rules would be manually defined to extract information about the usage and meaning of words in the dictionary. These rules would be based on the grammar and syntax of the English language, and would be used to identify and classify words based on their part of speech and definition.\"), mdx(\"p\", null, \"The rule-based system would be used as a pre-processing step to extract the information, and then a machine learning model would be trained on this pre-processed data to improve the accuracy of the classification.\"), mdx(\"p\", null, \"It's also worth mentioning that it's important to have a large, diverse and representative dataset to train the model on, so that the model can generalize well to unseen data.\"), mdx(\"p\", null, \"Additionally, you may want to consider using pre-trained language models like BERT, RoBERTa, GPT-3, etc, that have been trained on large amounts of text data and can be fine-tuned to perform the specific task of part-of-speech tagging and definition extraction.\"), mdx(\"p\", null, \"Once you have the model, it can be used to automatically classify new words and phrases and generate the top-level ontology for RDF and RDFS. This would allow you to automatically generate RDF ontologies that are more accurate and comprehensive than those created by manual annotation.\"), mdx(\"p\", null, \"It's also important to note that once you have the top level ontology, It's important to validate the ontology by testing it on a sample data set, and check for any errors, inconsistencies or missing information, and make adjustments accordingly.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"my Question: Can the English Vocabulary be expressed mathematically?\"))), mdx(\"p\", null, \"The English vocabulary can be expressed mathematically to some extent, but it's important to note that natural language is a complex phenomenon and not all aspects of it can be fully captured by mathematical representation.\"), mdx(\"p\", null, \"One way to express the English vocabulary mathematically is by using mathematical models such as probability and statistics. For example, it's possible to use probability distributions to model the likelihood of different words appearing in a given context, and to use statistical methods to analyze the relationships between different words and their meanings.\"), mdx(\"p\", null, \"Another way to express the English vocabulary mathematically is by using formal language theory, which is a branch of theoretical computer science. Formal languages are a mathematical abstraction of natural languages and can be described using mathematical notation, such as regular expressions, context-free grammars, and formal languages. These formal languages provide a mathematical framework for describing the syntax and structure of natural languages.\"), mdx(\"p\", null, \"Additionally, it's possible to use mathematical models such as vector spaces and tensor representations to represent words and phrases, and to use mathematical operations such as matrix multiplication and dot product to perform operations such as similarity, analogy, and relationship between words.\"), mdx(\"p\", null, \"In summary, while it's possible to express the English vocabulary mathematically to some extent, natural language is a complex phenomenon and not all aspects of it can be fully captured by mathematical representation, and it's important to use a combination of mathematical and computational models to represent natural languages.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"My Question: What are the ontological rules for the english language?\"))), mdx(\"p\", null, \"Ontological rules are guidelines for organizing and structuring knowledge in a specific domain. In the context of the English language, ontological rules would be guidelines for how to organize and structure the vocabulary and grammar of the language in a consistent and logical way.\"), mdx(\"p\", null, \"There are several different ontological frameworks that have been proposed for the English language. Some examples include:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://wordnet-rdf.princeton.edu/\"\n  }, \"WordNet\"), \": This is a lexical database that organizes English words into sets of synonyms (synsets) and describes the relationships between them. WordNet provides a hierarchical structure for the English vocabulary, with nouns, verbs, adjectives, and adverbs arranged in a tree-like structure.\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://framenet.icsi.berkeley.edu/fndrupal/\"\n  }, \"FrameNet\"), \": This is a lexical database that organizes English words into frames, which are sets of words that are related to a specific concept or event. FrameNet provides a way to organize the English vocabulary based on the roles that words play in different situations.\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Cyc\"\n  }, \"Cyc\"), \": This is a large-scale ontology that organizes knowledge about the world in a hierarchical and logical way. Cyc includes a large number of concepts and relations, and provides a framework for organizing the English vocabulary in a consistent and logical way.\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.ontologyportal.org/\"\n  }, \"SUMO\"), \": This is a large-scale ontology that organizes knowledge in a hierarchical and logical way. SUMO provides a framework for organizing the English vocabulary in a consistent and logical way, and includes a large number of concepts and relations.\"))), mdx(\"p\", null, \"\", mdx(\"img\", {\n    parentName: \"p\",\n    \"src\": \"/95680cbb7bd85236ea24bc6f677c79a6/SUMOMILO.gif\",\n    \"title\": \"SUMOMILO.gif\"\n  }), \"\\nImageSource: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.ontologyportal.org/\"\n  }, \"Ontology Portal\")), mdx(\"ol\", {\n    \"start\": 5\n  }, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"OntoWordNet: This is an ontology that is based on WordNet, but it provides a more formal and logical structure for the English vocabulary. It organizes words in a hierarchical structure and provides formal definitions and axioms for the concepts represented by the words.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The General English Ontology (GEO): This is an ontology that provides a general structure for organizing the English vocabulary in a consistent and logical way. The GEO provides a high-level structure for organizing concepts and relationships, and it has been used in a variety of NLP and AI applications.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The OpenCyc: An open-source version of the Cyc ontology, it's a large-scale ontology that organizes knowledge about the world in a hierarchical and logical way. It includes a large number of concepts and relations, and provides a framework for organizing the English vocabulary in a consistent and logical way.\")), mdx(\"p\", null, \"It's important to note that these ontologies and frameworks are not mutually exclusive and they can work together in a complementary way. Additionally, these ontologies are continuously being updated and improved by the community of researchers and practitioners.\"), mdx(\"p\", null, \"In summary, ontological rules for the English language are guidelines for organizing and structuring the vocabulary and grammar of the language in a consistent and logical way. There are different ontological frameworks that have been proposed for the English language, such as WordNet, FrameNet, Cyc, SUMO, OntoWordNet, GEO, and OpenCyc, each with its own strengths and weaknesses and they are continuously being updated and improved by the community.\"), mdx(\"p\", null, \"It's worth noting that these ontologies were created by experts in the field, and they are widely used in NLP and AI applications.\"), mdx(\"p\", null, \"In summary, ontological rules for the English language are guidelines for organizing and structuring the vocabulary and grammar of the language in a consistent and logical way, and there are different ontological frameworks that have been proposed for the English language such as WordNet, FrameNet, Cyc, SUMO, etc.\"), mdx(\"p\", null, \"NOTES:\\nOntoWordNet LINKS\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://lists.w3.org/Archives/Public/public-swbp-wg/2005Feb/0066.html\"\n  }, \"https://lists.w3.org/Archives/Public/public-swbp-wg/2005Feb/0066.html\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.w3.org/2001/sw/BestPractices/WNET/\"\n  }, \"https://www.w3.org/2001/sw/BestPractices/WNET/\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://wordnet-rdf.princeton.edu/\"\n  }, \"http://wordnet-rdf.princeton.edu/\"), \"\\nOther links\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://babelnet.org/\"\n  }, \"https://babelnet.org/\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/ontologyportal/sumo\"\n  }, \"https://github.com/ontologyportal/sumo\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://wordnet-rdf.princeton.edu/about\"\n  }, \"http://wordnet-rdf.princeton.edu/about\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://wordnet-rdf.princeton.edu/\"\n  }, \"http://wordnet-rdf.princeton.edu/\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://old.datahub.io/dataset/opencyc\"\n  }, \"https://old.datahub.io/dataset/opencyc\"), \" is unavailable;  a version of it has been found: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/asanchez75/opencyc/blob/master/opencyc-latest.owl.gz\"\n  }, \"https://github.com/asanchez75/opencyc/blob/master/opencyc-latest.owl.gz\"), \" \"), mdx(\"p\", null, \"noteAlso: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.wordsapi.com/\"\n  }, \"https://www.wordsapi.com/\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"My Question:\\nnote; my objective is to specifically seek to maintain the proper use of terms defined using english words. This is distinct to the creation of software that might seek to support NLP related processes for sentences and broader documents. Now Therefore; When defining a high-level schema to describe the logical use of an english term or a group of english terms that are used in camelCase to define an ontological class, subclass, property, relation or datatype; what terms should be used to define the logical use of english terms for the purpose of defining an RDFS ontology document?\"))), mdx(\"p\", null, \"ChatGPT Answer:\"), mdx(\"p\", null, \"When defining a high-level schema to describe the logical use of English terms for the purpose of defining an RDFS ontology document, it's important to use terms that are clear, consistent, and aligned with existing ontologies and standards.\"), mdx(\"p\", null, \"Here are some terms that you may consider using when defining the schema:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Class: A class is a category of things or concepts that share common characteristics. In the context of an RDFS ontology, classes are used to group together resources that have similar properties and relationships.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Subclass: A subclass is a category of things or concepts that are more specific than a general class. In the context of an RDFS ontology, subclasses are used to group together resources that have more specific properties and relationships than a general class.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Property: A property is a characteristic or attribute of a class or individual resource. In the context of an RDFS ontology, properties are used to describe the relationships between classes and individuals.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Relation: A relation is a connection or association between classes or individuals. In the context of an RDFS ontology, relations are used to describe the relationships between classes and individuals.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Datatype: A datatype is a specific type of data, such as a string, integer, or date. In the context of an RDFS ontology, datatypes are used to specify the type of data that a property can hold.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"URI: A URI (Uniform Resource Identifier) is a string of characters that identify a name or a resource on the Internet. In the context of an RDFS ontology, URIs are used to identify and reference classes, properties, and individuals in the ontology.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"RDFS: RDF Schema is a set of classes and properties that provide a vocabulary for expressing constraints on RDF statements.\")), mdx(\"p\", null, \"It's also important to note that when defining the schema, you should use camelCase to define the ontological class, subclass, property, relation, or datatype, as it's one of the conventions followed in RDFS ontologies.\"), mdx(\"p\", null, \"In summary, when defining a high-level schema to describe the logical use of English terms for the purpose of defining an RDFS ontology document, it's important to use terms such as Class, Subclass, Property, Relation, Datatype, URI, RDFS and to use camelCase to define the ontological class, subclass, property, relation, or datatype.\"), mdx(\"p\", null, \"Another important aspect to consider when defining the high-level schema is to align it with existing ontologies and standards. This will make it easier to integrate the ontology with other systems and to ensure that it is consistent with the existing knowledge representation practices.\"), mdx(\"p\", null, \"Some examples of existing ontologies and standards that you may consider aligning your schema with include:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"OWL (Web Ontology Language): OWL is a standard for representing ontologies on the web. It provides a rich set of constructs for describing classes, properties, individuals, and relationships.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"RDF (Resource Description Framework): RDF is a standard for representing information on the web. It provides a way to describe resources and their relationships in a machine-readable format.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"RDFS (RDF Schema): RDFS is a standard for defining vocabularies and constraints on RDF statements. It provides a set of classes and properties that can be used to define the structure of an ontology.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"SKOS (Simple Knowledge Organization System): SKOS is a standard for representing knowledge organization systems, such as thesauri, taxonomies, and other types of controlled vocabularies.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"DC (Dublin Core): DC is a set of 15 properties that can be used to describe resources in a simple, standard way.\")), mdx(\"p\", null, \"By aligning the schema with existing ontologies and standards, you can ensure that the ontology is consistent with the existing knowledge representation practices and it can be easily integrated with other systems.\"), mdx(\"p\", null, \"In summary, when defining a high-level schema to describe the logical use of English terms for the purpose of defining an RDFS ontology document, it's important to use terms such as Class, Subclass, Property, Relation, Datatype, URI, RDFS and to use camelCase to define the ontological class, subclass, property, relation, or datatype. Additionally, aligning the schema with existing ontologies and standards can ensure that the ontology is consistent with the existing knowledge representation practices and it can be easily integrated with other systems.\"), mdx(\"p\", null, \"The only existing ontologies and standards that i want to align the method with is RDF and RDFS. In this case, describe an ontology that provides the constructs for describing the logic of an english dictionary in N3\"), mdx(\"p\", null, \"An ontology that provides the constructs for describing the logic of an English dictionary in N3 (Notation3) using RDF and RDFS could be organized as follows:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Classes: The ontology would define classes for different types of words, such as nouns, verbs, adjectives, and adverbs. These classes would be used to group together resources that have similar properties and relationships.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Properties: The ontology would define properties for describing the characteristics of words, such as their part of speech, definition, and examples of usage. These properties would be used to describe the relationships between classes and individuals.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Relations: The ontology would define relations for describing the connections or associations between words, such as synonyms and antonyms. These relations would be used to describe the relationships between classes and individuals.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Individuals: The ontology would define individuals for each word in the dictionary, with each individual having properties such as part of speech, definition, and examples of usage.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"RDFS: The ontology would use RDFS to define the class hierarchy, properties and restrictions.\")), mdx(\"p\", null, \"Here is an example of how a word \\\"Apple\\\" could be represented in N3 using RDF and RDFS:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"@prefix rdf: [http://www.w3.org/1999/02/22-rdf-syntax-ns#](http://www.w3.org/1999/02/22-rdf-syntax-ns#) . @prefix rdfs: [http://www.w3.org/2000/01/rdf-schema#](http://www.w3.org/2000/01/rdf-schema#) . @prefix dic: [http://example.com/dictionary#](http://example.com/dictionary#) .\\n\\n\")), mdx(\"p\", null, \"dic:Apple a dic:Noun ; rdfs:label \\\"Apple\\\" ; dic:definition \\\"a round fruit with a red, green or yellow skin and a core of small seeds in the middle\\\" ; dic:example \\\"An apple a day keeps the doctor away.\\\" .\"), mdx(\"p\", null, \"In this example, the class \\\"Noun\\\" is defined as a subclass of rdfs:Class, the individual \\\"Apple\\\" is defined as an instance of the class \\\"Noun\\\", and it has properties such as definition and example of usage. The prefix dic: is used to identify the namespace of the ontology, and the properties and classes are defined using the dic: namespace.\"), mdx(\"p\", null, \"Additionally, the ontology could include additional classes and properties to represent more specific information about the words, such as the tense of verbs, singular and plural forms of nouns, comparative and superlative forms of adjectives, etc.\"), mdx(\"p\", null, \"It's also worth noting that, in order to make the ontology more expressive, it can use some additional RDFS constructs such as RDFS:subClassOf, RDFS:domain, RDFS:range, RDFS:subPropertyOf, etc.\"), mdx(\"p\", null, \"Additionally, it's important to note that RDF and RDFS are quite flexible and can be used to represent a wide range of different ontologies and vocabularies. Therefore, you may want to consider consulting existing ontologies and vocabularies, such as WordNet, FrameNet, and others, to identify the best practices and common patterns for representing the logic of an English dictionary.\"), mdx(\"p\", null, \"In summary, an ontology that provides the constructs for describing the logic of an English dictionary in N3 using RDF and RDFS could be organized by defining classes for different types of words, properties for describing the characteristics of words, relations for describing the connections between words, individuals for each word in the dictionary, and using RDFS to define the class hierarchy, properties, and restrictions. Additionally, it can use additional RDFS constructs and also aligning with existing ontologies and standards can help to make the ontology more expressive and consistent.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"My Question: provide a code example in turtle\"))), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-turtle\"\n  }, \"@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\\n@prefix dic: <http://example.com/dictionary#> .\\n\\ndic:Word rdfs:subClassOf rdfs:Resource .\\ndic:Noun rdfs:subClassOf dic:Word .\\ndic:Verb rdfs:subClassOf dic:Word .\\ndic:Adjective rdfs:subClassOf dic:Word .\\ndic:Adverb rdfs:subClassOf dic:Word .\\n\\ndic:partOfSpeech rdfs:domain dic:Word ;\\n                  rdfs:range rdfs:Literal .\\ndic:definition rdfs:domain dic:Word ;\\n                rdfs:range rdfs:Literal .\\ndic:example rdfs:domain dic:Word ;\\n                rdfs:range rdfs:Literal .\\n\\ndic:synonym rdfs:domain dic:Word ;\\n                rdfs:range dic:Word .\\n\\ndic:Apple a dic:Noun ;\\n\\n\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"My Question:\\nhow can multiple prefixes for the same ontological asset be defined so that the ontology document can be provided over multiple protocols (ie: IPFS, WebTorrent, etc) whilst providing the semantic RDF RDFS requirements to define that the document URIs are referring to the same document?\"))), mdx(\"p\", null, \"ChatGPT Response:\"), mdx(\"p\", null, \"When defining an ontology that will be provided over multiple protocols, such as IPFS and WebTorrent, it's important to ensure that the URIs used to reference the ontology document are consistent across all protocols. One way to achieve this is to use multiple prefixes for the same ontological asset, and to define them in such a way that they all refer to the same document.\"), mdx(\"p\", null, \"Here are a few ways to achieve this:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Use a single prefix and different URI schemes: You can use a single prefix and define different URI schemes for the same ontological asset. For example, you can use the prefix \\\"dic:\\\" to refer to the ontology, and then define the URIs as \\\"dic:Apple\\\" for the web, \\\"ipfs:Qm1234567890\\\" for IPFS, and \\\"webtorrent:abcdefgh\\\" for WebTorrent.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Use multiple prefixes and same URI scheme: You can use multiple prefixes for the same ontological asset, and define them to use the same URI scheme. For example, you can use the prefix \\\"dic:\\\" for the web, \\\"ipfs_dic:\\\" for IPFS, and \\\"webtorrent_dic:\\\" for WebTorrent and then define the URIs as \\\"dic:Apple\\\" for the web, \\\"ipfs_dic:Apple\\\" for IPFS, and \\\"webtorrent_dic:Apple\\\" for WebTorrent.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Linked Data Fragments (LDF) : It's a set of conventions that allows to define multiple URIs for the same resource, which can be identified by different access methods. With LDF, you can use the same URI as the representation of the resource, and it will redirect to the appropriate access method.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Use 303 redirection: Use the HTTP 303 status code to redirect requests for the ontology to the appropriate location, depending on the protocol being used. This allows you to use a single URI for the ontology, but redirect requests to the appropriate location based on the protocol being used.\")), mdx(\"p\", null, \"In summary, when defining an ontology that will be provided over multiple protocols, it's important to ensure that the URIs used to reference the ontology document are consistent across all protocols. This can be achieved by using a single prefix and different URI schemes, using multiple prefixes and same URI scheme, using Linked Data Fragments, or using HTTP 303 redirection.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"My question: Provide an example in turtle\"))), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-turtle\"\n  }, \"\\n@prefix dic: <http://example.com/dictionary#> .\\n@prefix ipfs_dic: <ipfs:Qm1234567890/dictionary#> .\\n@prefix webtorrent_dic: <webtorrent:abcdefgh/dictionary#> .\\n\\ndic:Apple a dic:Noun ;\\n    rdfs:label \\\"Apple\\\" ;\\n    dic:definition \\\"a round fruit with a red, green or yellow skin and a core of small seeds in the middle\\\" ;\\n    dic:example \\\"An apple a day keeps the doctor away.\\\" .\\n\\nipfs_dic:Apple owl:sameAs dic:Apple .\\nwebtorrent_dic:Apple owl:sameAs dic:Apple .\\n\\n\")), mdx(\"p\", null, \"In this example, the same class \\\"Apple\\\" is defined using three different prefixes \\\"dic:\\\", \\\"ipfs_dic:\\\", and \\\"webtorrent_dic:\\\", but they refer to the same resource. Then we use the owl:sameAs property to indicate that those resources are the same.\"), mdx(\"p\", null, \"This way, when the ontology is accessed over IPFS, the URI \\\"ipfs_dic:Apple\\\" can be used to reference the class, and when accessed over WebTorrent, the URI \\\"webtorrent_dic:Apple\\\" can be used instead. And, when accessed over the web, the URI \\\"dic:Apple\\\" can be used.\"), mdx(\"p\", null, \"It's also worth noting that, when using the owl:sameAs property, the ontology will be consistent with OWL 2 standard and it will be able to indicate that resources are identical.\"), mdx(\"p\", null, \"Keep in mind that this is an example, and the URIs used in the example are not valid and it's just for illustration purposes.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"My Question:\\nwhat is a solution that provides the ability to define an ontology document as a version that relates to a collection of ontology documents about the same topic. For example; when seeking to describe a law or legislation, the law may change and the ontology document may be only relavent within a particular period of time. So, in turtle, i want to describe a topic collection (ie: a legislative instrument) and relate versions as described in RDF to specific periods of time and provide an ontological reference to the latest version of that document. How could this be achieved? Provide a solution in turtle\"))), mdx(\"p\", null, \"ChatGPT Answer:\\nIn order to define an ontology document as a version that relates to a collection of ontology documents about the same topic, such as a legislative instrument, you can use the RDF and RDFS constructs to describe the topic collection and relate versions to specific periods of time. Here's an example of how this could be achieved in Turtle:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-Turtle\"\n  }, \"@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\\n@prefix law: <http://example.com/legislation#> .\\n@prefix time: <http://www.w3.org/2006/time#> .\\n\\nlaw:LegislativeInstrument rdfs:subClassOf rdfs:Resource .\\nlaw:Version rdfs:subClassOf rdfs:Resource .\\n\\nlaw:hasVersion rdfs:domain law:LegislativeInstrument ;\\n               rdfs:range law:Version .\\n\\nlaw:validFrom rdfs:domain law:Version ;\\n               rdfs:range time:Instant .\\n\\nlaw:validTo rdfs:domain law:Version ;\\n               rdfs:range time:Instant .\\n\\nlaw:latestVersion rdfs:domain law:LegislativeInstrument ;\\n               rdfs:range law:Version .\\n\\nlaw:LegislativeInstrument1 a law:LegislativeInstrument ;\\n    rdfs:label \\\"Legislative Instrument 1\\\" ;\\n    law:hasVersion law:Version1, law:Version2, law:Version3 .\\n\\nlaw:Version1 a law:Version ;\\n    rdfs:label \\\"Version 1\\\" ;\\n    law:validFrom \\\"2022-01-01T00:00:00Z\\\"^^time:Instant ;\\n    law:validTo \\\"2022-12-31T23:59:59Z\\\"^^time:Instant .\\n\\nlaw:Version2 a law:Version ;\\n    rdfs:label \\\"Version 2\\\" ;\\n    law:validFrom \\\"2023-01-01T00:00:00Z\\\"^^time:Instant ;\\n    law:validTo \\\"2023-12-31T23:59:59Z\\\"^^time:Instant .\\n\\nlaw:Version3 a law:Version ;\\n    rdfs:label \\\"Version 3\\\" ;\\n    law:validFrom \\\"2024-01-01T00:00:00Z\\\"^^time:Instant ;\\n    law:validTo \\\"2024-12-31T23:59:59Z\\\"^^time:Instant .\\n\\nlaw:LegislativeInstrument1 law:latestVersion law:Version3 .\\n\\n\")), mdx(\"p\", null, \"In this example, the class \\\"LegislativeInstrument\\\" is defined as a subclass of \\\"Resource\\\", and the class \\\"Version\\\" is defined as a subclass of \\\"Resource\\\" as well. The property \\\"hasVersion\\\" is defined to relate the \\\"LegislativeInstrument\\\" class with the \\\"Version\\\" class. The property \\\"validFrom\\\" and \\\"validTo\\\" are defined to indicate the time range when the version is valid. Finally, the property \\\"latestVersion\\\" is used to indicate the latest version of the legislative instrument.\"), mdx(\"p\", null, \"Here, the specific legislative instrument \\\"LegislativeInstrument1\\\" is defined with three versions \\\"Version1\\\", \\\"Version2\\\" and \\\"Version3\\\". Each version is defined with properties \\\"validFrom\\\" and \\\"validTo\\\" indicating the time range when the version is valid. The latest version \\\"Version3\\\" is indicated using the property \\\"latestVersion\\\".\"), mdx(\"p\", null, \"This way, by using the RDF and RDFS constructs, you can describe the topic collection of a legislative instrument and relate versions to specific periods of time. And also, you can specify the latest version of that document and it will be easy to identify it.\"), mdx(\"p\", null, \"It's worth noting that in this example, I've used the time ontology (time:) to define the time range but you can use other ways to represent time, such as using xsd:dateTime.\"), mdx(\"p\", null, \"It's also worth noting that this is an example, and the URIs and values used in the example are not valid and it's just for illustration purposes.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"My Question:\\nhow can a cryptographic signature be generated on an RDF document to enable a parser to validate whether or not the document has been altered?\"))), mdx(\"p\", null, \"A cryptographic signature can be generated on an RDF document to enable a parser to validate whether or not the document has been altered, by using a digital signature algorithm. A digital signature algorithm, such as RSA or ECDSA, can be used to create a digital signature of the RDF document.\"), mdx(\"p\", null, \"Here's an example of how this could be achieved in Turtle:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-turtle\"\n  }, \"\\n@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\\n@prefix dc: <http://purl.org/dc/elements/1.1/> .\\n@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\\n@prefix sig: <http://example.com/signature#> .\\n\\nsig:Signature rdfs:subClassOf rdfs:Resource .\\nsig:signatureValue rdfs:domain sig:Signature ;\\n                  rdfs:range xsd:base64Binary .\\n\\ndc:creator sig:signatureValue \\\"base64 encoded signature value\\\" .\\ndc:date \\\"2022-09-20T19:20:30-05:00\\\"^^xsd:dateTime .\\n\\n\")), mdx(\"p\", null, \"In this example, we defined a new class \\\"Signature\\\" as a subclass of \\\"Resource\\\" and the property \\\"signatureValue\\\" which is defined to relate the \\\"Signature\\\" class with the value of the signature, which is represented as xsd:base64Binary. Additionally, we use dc:creator and dc:date properties to indicate the signature creator and the date when the signature was generated.\"), mdx(\"p\", null, \"This way, the parser can use the public key of the signature creator to verify the signature value, and check if the document has been altered.\"), mdx(\"p\", null, \"It's important to keep in mind that this is just an example, and in real-world scenarios, the signature should be generated using proper libraries and tools that implement the desired digital signature algorithm. And also it's important to use secure key management techniques to protect the private key.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"my Question;\\nHow do i define a cuDNN training model to process an english dictionary for the purpose of using the vocabulary to define RDF / RDFS ontologies, that do not use OWL\")), mdx(\"p\", null, \"ChatGPT Answer:\"), mdx(\"p\", null, \"The cuDNN library is a GPU-accelerated library for deep neural networks, and it can be used to train models for various tasks such as image classification, natural language processing, and speech recognition.\"), mdx(\"p\", null, \"To define a cuDNN training model to process an English dictionary for the purpose of using the vocabulary to define RDF/RDFS ontologies, you would need to:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Prepare the data: This would involve preprocessing the English dictionary to extract the vocabulary and related information such as part of speech, definition, etc. and format it into a format suitable for training a neural network.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Define the model architecture: This would involve choosing a suitable model architecture that can handle the task of vocabulary extraction, such as a recurrent neural network (RNN) or a transformer-based model.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Train the model: This would involve using cuDNN to train the model on the preprocessed data, using techniques such as backpropagation and stochastic gradient descent.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Use the trained model: Once the model is trained, you can use it to extract vocabulary from new texts and use it to define RDF/RDFS ontologies.\")), mdx(\"p\", null, \"It's worth noting that creating an ontology from text is a complex task, and the final ontology will depend on the specific use case and the ontology model that you choose to represent the vocabulary. Additionally, it's also important to note that using cuDNN for this task is not the most common way, as it's a powerful library that is mostly used for deep learning tasks. There are other libraries and models that might be more suitable for this kind of task, like word2vec, GloVe, or BERT.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"My Question:\\n\", mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"provide an example of preparing hte data in golang and include the syntactic field to define \\\"parts of speech\\\" to distinguish whether a word definition relates to the use of that word in the form of a NOUN, PRONOUN, VERB, ADJECTIVE, ADVERB, PREPOSITION, CONJUNCTION or INTERJECTION.\"))), mdx(\"p\", null, \"Here's an example of how you could prepare the data in Go for a model that aims to distinguish whether a word definition relates to the use of that word in the form of a NOUN, PRONOUN, VERB, ADJECTIVE, ADVERB, PREPOSITION, CONJUNCTION or INTERJECTION:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-go\"\n  }, \"package main\\n\\nimport (\\n    \\\"encoding/json\\\"\\n    \\\"os\\\"\\n)\\n\\ntype Vocab struct {\\n    Word       string `json:\\\"word\\\"`\\n    POS        string `json:\\\"pos\\\"`\\n    Definition string `json:\\\"definition\\\"`\\n}\\n\\nfunc main() {\\n    // load the english dictionary\\n    file, _ := os.Open(\\\"english_dictionary.json\\\")\\n    defer file.Close()\\n\\n    var dictionary map[string]interface{}\\n    json.NewDecoder(file).Decode(&dictionary)\\n\\n    // create a slice to store the vocabulary and related information\\n    var vocab []Vocab\\n\\n    // iterate over the dictionary entries\\n    for word, entry := range dictionary {\\n        pos := entry.(map[string]interface{})[\\\"pos\\\"].(string)\\n        definition := entry.(map[string]interface{})[\\\"definition\\\"].(string)\\n\\n        // add the vocabulary and related information to the vocab slice\\n        vocab = append(vocab, Vocab{Word: word, POS: pos, Definition: definition})\\n    }\\n\\n    // save the vocab slice to a file for training\\n    vocabFile, _ := os.Create(\\\"vocab.json\\\")\\n    defer vocabFile.Close()\\n\\n    json.NewEncoder(vocabFile).Encode(voc\\n\\n\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ChatGPT Question:\\nProvide me an example of how to do step 2, using that model in golang using cuDNN\")), mdx(\"p\", null, \"ChatGPT Answer\\nStep 2 of defining a cuDNN training model to process an English dictionary for the purpose of using the vocabulary to define RDF/RDFS ontologies, would involve defining the model architecture.\"), mdx(\"p\", null, \"Here's an example of how you could define a model architecture in Go using cuDNN:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-go\"\n  }, \"package main\\n\\nimport (\\n    \\\"github.com/dereklstinson/GoCUDA\\\"\\n    \\\"github.com/dereklstinson/GoCUDA/cudnn\\\"\\n)\\n\\nfunc main() {\\n    // create a cudnn handle\\n    handle, _ := cudnn.Create()\\n    defer handle.Destroy()\\n\\n    // define the model architecture\\n    // here we will use a simple feedforward neural network with one hidden layer\\n    inputTensor, _ := cudnn.CreateTensorDescriptor()\\n    defer inputTensor.Destroy()\\n    inputTensor.Set(cudnn.DataTypeFloat, []int32{batchSize, inputSize}, []int32{inputSize, 1})\\n\\n    hiddenTensor, _ := cudnn.CreateTensorDescriptor()\\n    defer hiddenTensor.Destroy()\\n    hiddenTensor.Set(cudnn.DataTypeFloat, []int32{batchSize, hiddenSize}, []int32{hiddenSize, 1})\\n\\n    outputTensor, _ := cudnn.CreateTensorDescriptor()\\n    defer outputTensor.Destroy()\\n    outputTensor.Set(cudnn.DataTypeFloat, []int32{batchSize, outputSize}, []int32{outputSize, 1})\\n\\n    filterDesc, _ := cudnn.CreateFilterDescriptor()\\n    defer\\n    filterDesc.Set(cudnn.DataTypeFloat, []int32{hiddenSize, inputSize})\\n\\n    filterData, _ := GoCUDA.Malloc(filterDesc.Size())\\n    defer filterData.Free()\\n\\n    biasDesc, _ := cudnn.CreateTensorDescriptor()\\n    defer biasDesc.Destroy()\\n    biasDesc.Set(cudnn.DataTypeFloat, []int32{hiddenSize}, []int32{hiddenSize, 1})\\n\\n    biasData, _ := GoCUDA.Malloc(biasDesc.Size())\\n    defer biasData.Free()\\n\\n    // initialize the filter and bias data with random values\\n    rand.Read(filterData.Pointer())\\n    rand.Read(biasData.Pointer())\\n\\n    // create the feedforward neural network\\n    _, _ = handle.CreateFeedForward(inputTensor, filterDesc, filterData, biasDesc, biasData, hiddenTensor, outputTensor)\\n}\\n\\n\")), mdx(\"p\", null, \"This code snippet defines a simple feedforward neural network with one hidden layer, and creates a handle to interact with cuDNN library. It creates the tensor descriptor, filter descriptor, and bias descriptor for the input, hidden, and output layers respectively. It also initializes the filter and bias data with random values using the Go's math/rand package.\"), mdx(\"p\", null, \"It's worth noting that this is just an example, and the actual model architecture will depend on the specific requirements of your use case, and it might require more complex architectures. Also, it's important to note that this example uses a library called GoCUDA which is a Go\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"My question: Provide an example of how to do step 3\")), mdx(\"p\", null, \"Step 3 of defining a cuDNN training model to process an English dictionary for the purpose of using the vocabulary to define RDF/RDFS ontologies, would involve training the model using the preprocessed data.\"), mdx(\"p\", null, \"Here's an example of how you could train the model in Go using cuDNN:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-go\"\n  }, \"package main\\n\\nimport (\\n    \\\"github.com/dereklstinson/GoCUDA\\\"\\n    \\\"github.com/dereklstinson/GoCUDA/cudnn\\\"\\n)\\n\\nfunc main() {\\n    // create a cudnn handle\\n    handle, _ := cudnn.Create()\\n    defer handle.Destroy()\\n\\n    // load the preprocessed data\\n    data, _ := GoCUDA.Malloc(dataSize)\\n    defer data.Free()\\n\\n    labels, _ := GoCUDA.Malloc(labelSize)\\n    defer labels.Free()\\n\\n    // set the data and labels\\n    // ...\\n\\n    // set the training parameters\\n    learningRate := 0.01\\n    weightDecay := 0.0005\\n    momentum := 0.9\\n\\n    // train the model\\n    _, _ = handle.Train(data, labels, learningRate, weightDecay, momentum)\\n}\\n\\n\")), mdx(\"p\", null, \"This code snippet loads the preprocessed data, which is the vocabulary and related information extracted from the English dictionary, and the corresponding labels (the part of speech) into memory, and sets the training parameters such as learning rate, weight decay, and momentum. It then uses the cuDNN library to train the model on the data.\"), mdx(\"p\", null, \"It's important to note that this is a simplified example, and the actual training process will depend on the specific requirements of your use case and the model architecture. Also, it's important to note that this example uses a library called GoCUDA which is a Go library that provides bindings for CUDA, but it doesn't provide bindings for cuDNN library.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"My question; provide an example of step 4\")), mdx(\"p\", null, \"Step 4 of defining a cuDNN training model to process an English dictionary for the purpose of using the vocabulary to define RDF/RDFS ontologies, would involve evaluating the model's performance and fine-tuning it as necessary.\"), mdx(\"p\", null, \"Here's an example of how you could evaluate the model's performance and fine-tune it in Go using cuDNN:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-go\"\n  }, \"\\npackage main\\n\\nimport (\\n    \\\"github.com/dereklstinson/GoCUDA\\\"\\n    \\\"github.com/dereklstinson/GoCUDA/cudnn\\\"\\n)\\n\\nfunc main() {\\n    // create a cudnn handle\\n    handle, _ := cudnn.Create()\\n    defer handle.Destroy()\\n\\n    // load the test data\\n    testData, _ := GoCUDA.Malloc(testDataSize)\\n    defer testData.Free()\\n\\n    testLabels, _ := GoCUDA.Malloc(testLabelSize)\\n    defer testLabels.Free()\\n\\n    // set the test data and labels\\n    // ...\\n\\n    // evaluate the model's performance on the test data\\n    accuracy, _ := handle.Evaluate(testData, testLabels)\\n\\n    // print the accuracy\\n    println(\\\"Accuracy:\\\", accuracy)\\n\\n    // fine-tune the model if necessary\\n    if accuracy < desiredAccuracy {\\n        // adjust the training parameters\\n        learningRate *= 0.1\\n        weightDecay *= 0.1\\n\\n        // retrain the model\\n        _, _ = handle.Train(data, labels, learningRate, weightDecay, momentum)\\n    }\\n}\\n\\n\")), mdx(\"p\", null, \"This code snippet loads test data and labels, and uses the cuDNN library to evaluate the model's performance on this test data. It then prints the accuracy, and if the accuracy is below a certain threshold, it adjusts the training parameters and retrains the model.\"), mdx(\"p\", null, \"It's important to note that this is a simplified example, and the actual evaluation and fine-tuning process will depend on the specific requirements of your use case and the model architecture. Also, it's important to note that this example uses a library called GoCUDA which is a Go library that provides bindings for CUDA, but it doesn't provide bindings for cuDNN library.\"), mdx(\"p\", null, \"As I mentioned earlier, there are no Go libraries that provide bindings for cuDNN, which means that using cuDNN in Go is not a straightforward task, and it would require to use CGo to interact with the cuDNN C library, and this will require a deep understanding of both Go and C programming languages.\"), mdx(\"h3\", {\n    \"id\": \"review-and-considerations\"\n  }, \"Review and considerations\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Its seemingly defined using tensorcores.  my laptop doesn't have tensor cores, only cudacores\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"I didn't know much about the existing solutions like wordnet.\")), mdx(\"h3\", {\n    \"id\": \"following-up\"\n  }, \"Following-up\"), mdx(\"p\", null, \"Overnight, i found the various existing NLP libraries that were highlighted earlier, alongside a relatively easy to use example - \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.wordsapi.com/\"\n  }, \"WordsAPI\"), \" that might be the best choice for producing a Proof of Concept to illustrate the general idea.   Yet, any overly simplified solution (as required to materialise something that demonstrates the general idea); will need an upgrade path.  Furthermore, the method of how to form a longer-term strategy is required.  \"), mdx(\"p\", null, \"It is important to note (as i've started to illustrate \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/WebizenTechStack/Webizen2.5/FunctionalObjectives/RootConcepts/\",\n    \"title\": \"RootConcepts\"\n  }, \"RootConcepts\"), \" ); that this underlying service MUST be able to be operated privately and in a stand-alone manner.  To achieve this solution, the outcome may be that the first time a topic or word is sought to be processed; an API call might be made to go and get the information that's required to be added to the database.  Presently, i'm unsure of the technical implications relating to any methods that are reasonably available to achieve that;  such as - can it run on a mobile phone or laptop?  etc.\"), mdx(\"p\", null, \"As more work continues on the topic (the next day); the below 'work' was produced,\"), mdx(\"h4\", {\n    \"id\": \"chatgpt\"\n  }, \"ChatGPT\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"My Question:\"), \" what are the root languages for the english vocabulary?\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ChatGPT Answer\"), \":\\nThe English vocabulary is made up of words borrowed from many different languages over the centuries. The main root languages of the English vocabulary are:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Germanic: The Germanic languages, including Old English, are the most important source of words in English. They make up around 50% of the words in the English language. Words from Germanic languages include common words such as \\\"house,\\\" \\\"father,\\\" \\\"mother,\\\" \\\"man,\\\" \\\"woman,\\\" \\\"child,\\\" and \\\"dog.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Latin: Latin is the second most important source of words in English. Latin words make up around 30% of the English vocabulary. Many of these words are technical terms in fields such as science, medicine, and law. Words from Latin include \\\"hospital,\\\" \\\"doctor,\\\" \\\"university,\\\" \\\"species,\\\" \\\"algebra,\\\" \\\"formula,\\\" and \\\"jurisdiction.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"French: French is the third most important source of words in English. French words make up around 10% of the English vocabulary. Many French words were borrowed during the Norman Conquest of England in 1066 and the following centuries of Norman rule. Words from French include \\\"money,\\\" \\\"art,\\\" \\\"government,\\\" \\\"justice,\\\" \\\"royalty,\\\" \\\"diamond,\\\" and \\\"restaurant.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Greek: Greek is the fourth most important source of words in English. Greek words make up around 5% of the English vocabulary. Many Greek words were borrowed through Latin, but some were borrowed directly into English. Words from Greek include \\\"philosophy,\\\" \\\"theology,\\\" \\\"anatomy,\\\" \\\"geometry,\\\" \\\"telephone,\\\" \\\"photograph,\\\" and \\\"encyclopedia.\\\"\")), mdx(\"p\", null, \"Other languages that have contributed to the English vocabulary include Arabic, Italian, Spanish, and many others.\"), mdx(\"p\", null, \"In addition to the root languages mentioned above, there are also many other languages that have contributed to the English vocabulary over time. These include:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Arabic: Many Arabic words were borrowed into English through Latin and Greek. Words from Arabic include \\\"algebra,\\\" \\\"alcohol,\\\" \\\"candy,\\\" \\\"jar,\\\" \\\"lemon,\\\" \\\"magazine,\\\" \\\"sofa,\\\" \\\"sugar,\\\" and \\\"zero.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Italian: Words from Italian include \\\"balcony,\\\" \\\"broccoli,\\\" \\\"cappuccino,\\\" \\\"fiasco,\\\" \\\"gazebo,\\\" \\\"grotto,\\\" \\\"paparazzo,\\\" \\\"piano,\\\" \\\"sonata,\\\" and \\\"terrace.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Spanish: Words from Spanish include \\\"alligator,\\\" \\\"barbecue,\\\" \\\"bronco,\\\" \\\"chocolate,\\\" \\\"coyote,\\\" \\\"guerrilla,\\\" \\\"jaguar,\\\" \\\"mosquito,\\\" \\\"mustang,\\\" \\\"patio,\\\" \\\"siesta,\\\" \\\"sombrero,\\\" \\\"taco,\\\" and \\\"tornado.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Native American languages: Words from Native American languages include \\\"chocolate,\\\" \\\"chipmunk,\\\" \\\"moose,\\\" \\\"opossum,\\\" \\\"pecan,\\\" \\\"racoon,\\\" \\\"skunk,\\\" \\\"squash,\\\" \\\"tobacco,\\\" and \\\"tomato.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Asian languages: Words from Asian languages include \\\"bamboo,\\\" \\\"guru,\\\" \\\"karma,\\\" \\\"pajama,\\\" \\\"tycoon,\\\" \\\"yoga,\\\" and \\\"zen.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"African languages: Words from African languages include \\\"banjo,\\\" \\\"jazz,\\\" \\\"okra,\\\" \\\"yam,\\\" and \\\"Zulu.\\\"\")), mdx(\"p\", null, \"It's worth noting that these are just a few examples of the many languages that have contributed to the English vocabulary over time. The English language is known for its rich history of borrowing words from other languages, and this is one of the reasons why it has such a diverse and dynamic vocabulary.\"), mdx(\"p\", null, \"My question: provide an example relating to norse and old norse \"), mdx(\"p\", null, \"Sure, here are a few examples of words that have been borrowed from Old Norse and Norse into the English language:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Anguish\\\" comes from the Old Norse word \\\"angr\\\" meaning \\\"grief\\\" or \\\"sorrow.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Berserk\\\" comes from the Old Norse word \\\"berserkr\\\" meaning \\\"a wild warrior.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Bliss\\\" comes from the Old Norse word \\\"bliss\\\" meaning \\\"happiness.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Eke\\\" means \\\"also\\\" or \\\"additionally\\\" comes from the Old Norse word \\\"eigi\\\" meaning \\\"also\\\" or \\\"in addition.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Eg\\\" meaning \\\"I\\\" from Old Norse \\\"eg\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Fjord\\\" comes from the Old Norse word \\\"fj\\xF6r\\xF0r\\\" meaning \\\"a narrow inlet of the sea.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Knurl\\\" comes from the Old Norse word \\\"knurr\\\" meaning \\\"a small knot or knob.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Mist\\\" comes from the Old Norse word \\\"mist\\\" meaning \\\"moisture.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Ransack\\\" comes from the Old Norse word \\\"rannsaka\\\" meaning \\\"to search through.\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Scowl\\\" comes from the Old Norse word \\\"skul\\\" meaning \\\"a face with a frown.\\\"\")), mdx(\"p\", null, \"It is worth noting that the Norse and Old Norse languages are closely related, and the vast majority of words borrowed into English from Old Norse came directly or indirectly from Norse. Norse is also known as Old Icelandic, it is a Germanic language that was spoken by the Vikings and other inhabitants of the Norse regions of Scandinavia and the North Atlantic islands in the Middle Ages.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"My question: what benefit might the use of a neuromorphic processer provide for processing a natural language model?\")), \"  (note: that was part of the question)\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ChatGPT:\"), \"\\nA neuromorphic processor is a type of computer processor that is designed to mimic the way the human brain works. These processors use artificial neural networks, which are modeled after the structure and function of the human brain, to perform tasks such as pattern recognition and decision-making.\"), mdx(\"p\", null, \"The use of a neuromorphic processor for processing a natural language model could provide several benefits.\"), mdx(\"p\", null, \"-Neuromorphic processors are highly energy-efficient, which makes them well-suited for running large-scale natural language processing models on mobile or embedded devices.\"), mdx(\"p\", null, \"-Neuromorphic processors are also highly parallel, which means they can perform multiple computations simultaneously. This can lead to faster and more efficient processing of natural language models, as well as the ability to handle larger models.\"), mdx(\"p\", null, \"-Neuromorphic processors are also highly adaptable and can learn from new data, which means they can improve their performance over time. This can be particularly useful for natural language processing, as the meaning and usage of words and phrases can change over time, and a model that can adapt to these changes will be more accurate and useful.\"), mdx(\"p\", null, \"-Neuromorphic processors can also be more robust to noise, errors and variations in the data, which can be common in natural language data.\"), mdx(\"p\", null, \"It's worth mentioning that the field of neuromorphic computing and Neuromorphic processors are relatively new and still in development, and more research is needed to fully understand their potential benefits and limitations.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"My Question: what is the earliest known time the english language was first used?\"))), mdx(\"p\", null, \"ChatGPT: \"), mdx(\"p\", null, \"The earliest known use of the English language dates back to the 5th century AD, when Germanic tribes, such as the Angles, Saxons, and Jutes, began to migrate to the island of Great Britain and settled there. These tribes spoke a Germanic language, which over time evolved into Old English.\"), mdx(\"p\", null, \"Old English, also known as Anglo-Saxon, was the language spoken in England from the 5th century to the Norman conquest in 1066 AD. Old English is considered to be the earliest form of the English language, and it was written in the runic alphabet, which was later replaced by the Latin alphabet.\"), mdx(\"p\", null, \"Old English was a complex and inflected language, with a rich vocabulary and many grammatical features. However, it was quite different from the English spoken today and would be difficult for modern speakers to understand without study or translation.\"), mdx(\"p\", null, \"It's worth mentioning that the Angles, Saxons, and Jutes were not the only people that were in Great Britain during this time, there were also the Celts, and others, and they were speaking different languages, and the Germanic language of the invaders slowly replaced the Celtic languages and others, it took several centuries to form the language we know today as English.\"));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/WebizenTechStack/VocabularyModelling/ChatGPTDynamicOntology/","title":"Dynamic Ontology","shouldShowTitle":false}}],"inboundReferences":[]},"tagsOutbound":{"nodes":[]}},"pageContext":{"tags":[],"slug":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ToolAppRequirements/TrainedLanguageModel/","sidebarItems":[{"title":"Categories","items":[{"title":"Agent-Labelling-WIP","url":"/Agent-Labelling-WIP/","items":[]},{"title":"Documentation Method","url":"/DocumentationMethod/","items":[]},{"title":"DRAFT: Guide For Developers","url":"/GuideForDevelopers/","items":[{"title":"Dev Practices Guide","url":"/GuideForDevelopers/DevPractices/","items":[]},{"title":"Expression Of Interest","url":"/GuideForDevelopers/ExpressionOfInterest/","items":[]},{"title":"Webizen on Discord","url":"/GuideForDevelopers/WebizenDiscord/","items":[]},{"title":"Webizen Terms","url":"/GuideForDevelopers/WebizenTerms/","items":[]}]},{"title":"Old-Work-Archives","url":"/old-work-archives/","items":[{"title":"2005 Lots of ideas - some big & some small","url":"/old-work-archives/2005LotsOfIdeas-SomeBig&SomeSmall/","items":[]},{"title":"2018-Webizen-Net-Au","url":"/old-work-archives/2018-webizen-net-au/","items":[{"title":"_Link_library_links","url":"","items":[{"title":"Link Library","url":"/old-work-archives/2018-webizen-net-au/_link_library_links/2018-09-23-wp-linked-data/","items":[]}]},{"title":"about","url":"/old-work-archives/2018-webizen-net-au/about/","items":[{"title":"About The Author","url":"/old-work-archives/2018-webizen-net-au/about/about-the-author/","items":[]},{"title":"Applied Theory: Applications for a Human Centric Web","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/","items":[{"title":"Digital Receipts","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/digital-receipts/","items":[]},{"title":"Fake News: Considerations → Principles → The Institution of Socio & Economic Values","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/fake-news-considerations/","items":[]},{"title":"Healthy Living Economy","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/healthy-living-economy/","items":[]},{"title":"HyperMedia Solutions Adapting HbbTV V2","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/","items":[{"title":"HYPERMEDIA PACKAGES","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/hypermedia-packages/","items":[]},{"title":"USER STORIES: INTERACTIVE VIEWING EXPERIENCE","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/hypermedia-solutions-adapting-hbbtv-v2/user-stories-interactive-viewing-experience/","items":[]}]},{"title":"Measurements App","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/measurements-app/","items":[]},{"title":"Re:Animation","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/reanimation/","items":[]},{"title":"Solutions to FakeNews: Linked-Data, Ontologies and Verifiable Claims","url":"/old-work-archives/2018-webizen-net-au/about/applied-theory-applications-for-a-human-centric-web/ld-solutions-to-fakenews/","items":[]}]},{"title":"Executive Summary","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/","items":[{"title":"Assisting those who Enforce the Law","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/assisting-those-who-enforce-the-law/","items":[]},{"title":"Consumer Protections","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/consumer-protections/","items":[]},{"title":"Knowledge Banking: Legal Structures","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-banking-legal-structures/","items":[]},{"title":"Knowledge Economics &#8211; Services","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/knowledge-economics-services/","items":[]},{"title":"Preserving The Freedom to Think","url":"/old-work-archives/2018-webizen-net-au/about/executive-summary/preserving-the-freedom-to-think/","items":[]}]},{"title":"History","url":"","items":[{"title":"History: Global Governance and ICT.","url":"/old-work-archives/2018-webizen-net-au/about/history/history-global-governance-ict-1/","items":[]}]},{"title":"Knowledge Banking: A Technical Architecture Summary","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/","items":[{"title":"An introduction to Credentials.","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/","items":[{"title":"credentials and custodianship","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/credentials-and-custodianship/","items":[]},{"title":"DIDs and MultiSig","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/what-are-credentials/dids-and-multisig/","items":[]}]},{"title":"Personal Augmentation of AI","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/personal-augmentation-of-ai/","items":[]},{"title":"Semantic Inferencing","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/semantic-inferencing/","items":[]},{"title":"Web of Things (IoT+LD)","url":"/old-work-archives/2018-webizen-net-au/about/knowledge-banking-a-technical-architecture-summary/web-of-things-iotld/","items":[]}]},{"title":"References","url":"/old-work-archives/2018-webizen-net-au/about/references/","items":[{"title":"Making the distinction between ‘privacy’ and ‘dignity’.","url":"/old-work-archives/2018-webizen-net-au/about/references/privacy-vs-dignity/","items":[]},{"title":"Roles & Entity Analysis","url":"/old-work-archives/2018-webizen-net-au/about/references/roles-entity-analysis/","items":[]},{"title":"Social Informatics Design Considerations","url":"/old-work-archives/2018-webizen-net-au/about/references/social-informatics-design-concept-and-principles/","items":[]},{"title":"Socio-economic relations | A conceptual model","url":"/old-work-archives/2018-webizen-net-au/about/references/socioeconomic-relations-p1/","items":[]},{"title":"The need for decentralised Open (Linked) Data","url":"/old-work-archives/2018-webizen-net-au/about/references/the-need-for-decentralised-open-linked-data/","items":[]}]},{"title":"The design of new medium","url":"/old-work-archives/2018-webizen-net-au/about/the-design-of-new-medium/","items":[]},{"title":"The need to modernise socioeconomic infrastructure","url":"/old-work-archives/2018-webizen-net-au/about/the-modernisation-of-socioeconomics/","items":[]},{"title":"The Vision","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/","items":[{"title":"Domesticating Pervasive Surveillance","url":"/old-work-archives/2018-webizen-net-au/about/the-vision/a-technical-vision/","items":[]}]}]},{"title":"Posts","url":"","items":[{"title":"About W3C","url":"/old-work-archives/2018-webizen-net-au/posts/About W3C/","items":[]},{"title":"Advanced Functions & Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/posts/Advanced Functions & Facebook Pages/","items":[]},{"title":"Advanced Search & Discovery Tips","url":"/old-work-archives/2018-webizen-net-au/posts/Advanced Search & Discovery Tips/","items":[]},{"title":"An Introduction to Virtual Machines","url":"/old-work-archives/2018-webizen-net-au/posts/An introduction to Virtual Machines/","items":[]},{"title":"Basic Media Analysis & Part 1 (Audio)","url":"/old-work-archives/2018-webizen-net-au/posts/Basic Media Analysis & Part 1 (Audio)/","items":[]},{"title":"Basic Media Analysis & Part 2 (Visual)","url":"/old-work-archives/2018-webizen-net-au/posts/Basic Media Analysis & Part 2 (visual)/","items":[]},{"title":"Basic Media Analysis & Part 3 (Text & Metadata)","url":"/old-work-archives/2018-webizen-net-au/posts/Basic Media Analysis & Part 3 (Text & Metadata)/","items":[]},{"title":"Building an Economy Based upon Knowledge Equity","url":"/old-work-archives/2018-webizen-net-au/posts/Building an Economy based upon Knowledge Equity/","items":[]},{"title":"Choice of Law","url":"/old-work-archives/2018-webizen-net-au/posts/Choice of Law/","items":[]},{"title":"Contemplation of the ITU Dubai Meeting and the Future of the Internet","url":"/old-work-archives/2018-webizen-net-au/posts/Contemplation of the ITU Dubai Meeting and the Future of the Internet/","items":[]},{"title":"Creating a Presence & Online","url":"/old-work-archives/2018-webizen-net-au/posts/Creating a Presence & Online/","items":[]},{"title":"Credentials and Payments by Manu Sporny","url":"/old-work-archives/2018-webizen-net-au/posts/Credentials and Payments by Manu Sporny/","items":[]},{"title":"Data Recovery - Laptop & Computers","url":"/old-work-archives/2018-webizen-net-au/posts/Data Recovery - Laptop & Computers/","items":[]},{"title":"Data Recovery & Collection Mobile Devices","url":"/old-work-archives/2018-webizen-net-au/posts/Data Recovery & Collection Mobile Devices/","items":[]},{"title":"Decentralized Web Conference 2016","url":"/old-work-archives/2018-webizen-net-au/posts/Decentralized Web Conference 2016/","items":[]},{"title":"Decentralized Web Summit 2018","url":"/old-work-archives/2018-webizen-net-au/posts/Decentralized Web Summit 2018/","items":[]},{"title":"Does Anonymity Exist","url":"/old-work-archives/2018-webizen-net-au/posts/Does Anonymity exist/","items":[]},{"title":"Downloading My Data From Social Networks","url":"/old-work-archives/2018-webizen-net-au/posts/Downloading My Data from Social Networks/","items":[]},{"title":"Facebook Pages","url":"/old-work-archives/2018-webizen-net-au/posts/Facebook Pages/","items":[]},{"title":"Google Tracking Data (Geolocation)","url":"/old-work-archives/2018-webizen-net-au/posts/Google Tracking Data (geolocation)/","items":[]},{"title":"Human Consciousness","url":"/old-work-archives/2018-webizen-net-au/posts/Human Consciousness/","items":[]},{"title":"Image Recgonition Video Playlist","url":"/old-work-archives/2018-webizen-net-au/posts/Image Recgonition Video Playlist/","items":[]},{"title":"Inferencing (Introduction)","url":"/old-work-archives/2018-webizen-net-au/posts/Inferencing (introduction)/","items":[]},{"title":"Introduction to AI","url":"/old-work-archives/2018-webizen-net-au/posts/Introduction to AI/","items":[]},{"title":"Introduction to Maltego","url":"/old-work-archives/2018-webizen-net-au/posts/Introduction to Maltego/","items":[]},{"title":"Introduction to Ontologies","url":"/old-work-archives/2018-webizen-net-au/posts/Introduction to Ontologies/","items":[]},{"title":"Introduction to Semantic Web","url":"/old-work-archives/2018-webizen-net-au/posts/Introduction to Semantic Web/","items":[]},{"title":"Knowledge-Capital","url":"/old-work-archives/2018-webizen-net-au/posts/knowledge-capital/","items":[]},{"title":"Logos-Style-Guides-and-Artwork","url":"/old-work-archives/2018-webizen-net-au/posts/logos-style-guides-and-artwork/","items":[]},{"title":"MindMapping & Setting-up a Business & Identity","url":"/old-work-archives/2018-webizen-net-au/posts/MindMapping & Setting-up a business & Identity/","items":[]},{"title":"Openlink Virtuoso","url":"/old-work-archives/2018-webizen-net-au/posts/Openlink Virtuoso/","items":[]},{"title":"OpenRefine","url":"/old-work-archives/2018-webizen-net-au/posts/OpenRefine/","items":[]},{"title":"Projects-Customers-and-Invoicing-Web-Services-for-Startups","url":"/old-work-archives/2018-webizen-net-au/posts/projects-customers-and-invoicing-web-services-for-startups/","items":[]},{"title":"RWW & some Solid History","url":"/old-work-archives/2018-webizen-net-au/posts/RWW & some Solid history/","items":[]},{"title":"Semantic Web (An Intro)","url":"/old-work-archives/2018-webizen-net-au/posts/Semantic Web (An Intro)/","items":[]},{"title":"Setting-up Twitter","url":"/old-work-archives/2018-webizen-net-au/posts/Setting-up Twitter/","items":[]},{"title":"Social Encryption An Introduction","url":"/old-work-archives/2018-webizen-net-au/posts/Social Encryption An Introduction/","items":[]},{"title":"Stock Content","url":"/old-work-archives/2018-webizen-net-au/posts/Stock Content/","items":[]},{"title":"The WayBack Machine","url":"/old-work-archives/2018-webizen-net-au/posts/The WayBack Machine/","items":[]},{"title":"Tim Berners Lee & Turing Lecture","url":"/old-work-archives/2018-webizen-net-au/posts/Tim Berners Lee & Turing Lecture/","items":[]},{"title":"Tools-of-Trade","url":"/old-work-archives/2018-webizen-net-au/posts/tools-of-trade/","items":[]},{"title":"Trust Factory 2017","url":"/old-work-archives/2018-webizen-net-au/posts/Trust Factory 2017/","items":[]},{"title":"Verifiable Claims (An Introduction)","url":"/old-work-archives/2018-webizen-net-au/posts/Verifiable Claims (An Introduction)/","items":[]},{"title":"Web of Things & an Introduction","url":"/old-work-archives/2018-webizen-net-au/posts/Web of Things & an Introduction/","items":[]},{"title":"Web-Persistence","url":"/old-work-archives/2018-webizen-net-au/posts/Web-Persistence/","items":[]},{"title":"Web-Services & Marketing Tools","url":"/old-work-archives/2018-webizen-net-au/posts/Web-Services & Marketing Tools/","items":[]},{"title":"Website Templates","url":"/old-work-archives/2018-webizen-net-au/posts/Website Templates/","items":[]},{"title":"What is <span class=\"textannotation disambiguated wl-thing\" id=\"urn:local-text-annotation-16v2koc9fcuj5lwn7helj9zpo9t4iqv4\" itemid=\"http://data.wordlift.io/wl0293/entity/linked_data\">Linked Data</span>?","url":"/old-work-archives/2018-webizen-net-au/posts/Introduction to Linked Data/","items":[]},{"title":"What Is Linked Data","url":"/old-work-archives/2018-webizen-net-au/posts/What is Linked Data/","items":[]},{"title":"What Is Open Source Intelligence","url":"/old-work-archives/2018-webizen-net-au/posts/What is Open Source Intelligence/","items":[]}]},{"title":"Resource Library","url":"/old-work-archives/2018-webizen-net-au/resource-library/","items":[]}]},{"title":"Basedrive","url":"/old-work-archives/Basedrive/","items":[]},{"title":"Human Centric","url":"/old-work-archives/Human-Centric/","items":[]},{"title":"iBANK - Concept overview","url":"/old-work-archives/iBank/","items":[]},{"title":"LinkedIn Articles","url":"/old-work-archives/LinkedInArticles/","items":[{"title":"AI & Software Agents: Social-Engineering Considerations","url":"/old-work-archives/LinkedInArticles/AI&SoftwareAgentsSocial-Engineering Considerations/","items":[]},{"title":"AI, Digital Identity & Guardianship Systems?","url":"/old-work-archives/LinkedInArticles/linkedinNoteAIDigitalIdentity&Guardianship Systems/","items":[]},{"title":"Knowledge & Agent Labelling: Clear Labelling of AI Interactions & some ideas about how to test students, by AI.","url":"/old-work-archives/LinkedInArticles/LinkedInLabellingAiAgents/","items":[]},{"title":"Reinventing the Kindness Equation","url":"/old-work-archives/LinkedInArticles/ReinventingTheKindnessEquation/","items":[]},{"title":"What is the Definition of an 'AI Weapon'","url":"/old-work-archives/LinkedInArticles/WhatIsTheDefinitionOfAnAIWeapon/","items":[]}]},{"title":"WebCivics BizPlan 2018","url":"/old-work-archives/WebCivicsBizPlan2018/","items":[]},{"title":"WebCivics Medium Posts","url":"/old-work-archives/WebCivicsMediumPosts/","items":[{"title":"2019","url":"","items":[{"title":"An Open Letter - What is your Digital Identity Mandate for Humanity","url":"/old-work-archives/WebCivicsMediumPosts/2019/AnOpenLetter-WhatisyourDigitalIdentity MandateforHumanity/","items":[]},{"title":"Building a #NewStart for the Australian Creative Sector.","url":"/old-work-archives/WebCivicsMediumPosts/2019/BuildingaNewStartfortheAustralianCreative Sector./","items":[]},{"title":"Building a Safe Environment for Kids to Thrive with Their ‘Digital Twin’","url":"/old-work-archives/WebCivicsMediumPosts/2019/Building a safe environment for Kids to thrive with their ‘Digital Twin’/","items":[]},{"title":"Causal Relationships between Social informatics design and Quantum Mechanical Phenomenon.","url":"/old-work-archives/WebCivicsMediumPosts/2019/CausalRelationshipsbetweenSocial informaticsdesignandQuantumMechanical Phenomenon./","items":[]},{"title":"Comms & Security Privacy vs. Dignity","url":"/old-work-archives/WebCivicsMediumPosts/2019/Comms&SecurityPrivacyVsDignity/","items":[]},{"title":"Cyber Security Infrastructure, AI & Semantics","url":"/old-work-archives/WebCivicsMediumPosts/2019/CyberSecurityInfrastructureAI&Semantics/","items":[]},{"title":"Dependents The Emergence of Cyber Nation. Estates of ‘Virtual IDentity’","url":"/old-work-archives/WebCivicsMediumPosts/2019/DependentsTheEmergenceOfCyberNationEstatesOfVirtualIDentity/","items":[]},{"title":"Engineering Einstein","url":"/old-work-archives/WebCivicsMediumPosts/2019/EngineeringEinstein/","items":[]},{"title":"Health Informatics History, Challenges & Opportunities","url":"/old-work-archives/WebCivicsMediumPosts/2019/HealthInformaticsHistoryChallenges& Opportunities/","items":[]},{"title":"History Community, Civics & GLAM. Means to Bootstrap Digital Economy Growth & Knowledge Banking Tools.","url":"/old-work-archives/WebCivicsMediumPosts/2019/HistoryCommunityCivics&GLAMMeanstoBootstrapDigitalEconomyGrowth&KnowledgeBankingTools./","items":[]},{"title":"History of Banking, Knowledge Economy and Moral Poverty","url":"/old-work-archives/WebCivicsMediumPosts/2019/History of Banking, Knowledge Economy and Moral Poverty/","items":[]},{"title":"HyperMedia Exhibition & Events Spaces","url":"/old-work-archives/WebCivicsMediumPosts/2019/HyperMediaExhibition&EventsSpaces/","items":[]},{"title":"Inforgs & The Collective Infosphere","url":"/old-work-archives/WebCivicsMediumPosts/2019/Inforgs&TheCollectiveInfosphere/","items":[]},{"title":"Knowledge Age - A conceptual evolution of the Cyber-Physical from our Present Information Age","url":"/old-work-archives/WebCivicsMediumPosts/2019/KnowledgeAge-AConceptualEvolutionoftheCyber-PhysicalfromourPresentInformationAge/","items":[]},{"title":"Knowledge Banking Infrastructure","url":"/old-work-archives/WebCivicsMediumPosts/2019/Knowledge Banking Infrastructure/","items":[]},{"title":"Knowledge Banking Infrastructure - Cyber Socio-Economic Foundations for Our Shared World","url":"/old-work-archives/WebCivicsMediumPosts/2019/Knowledge Banking Infrastructure - Cyber Socio-Economic Foundations for our shared world/","items":[]},{"title":"Knowledge Clouds","url":"/old-work-archives/WebCivicsMediumPosts/2019/Knowledge Clouds/","items":[]},{"title":"Media Analytics & Hyper-Media Services","url":"/old-work-archives/WebCivicsMediumPosts/2019/MediaAnalytics&Hyper-MediaServices/","items":[]},{"title":"Micropayments Standards - An Economic Imperative for the Knowledge Age","url":"/old-work-archives/WebCivicsMediumPosts/2019/MicropaymentsStandards-AnEconomicImperativefortheKnowledgeAge/","items":[]},{"title":"Open Data v3.0 Permissive Commons","url":"/old-work-archives/WebCivicsMediumPosts/2019/OpenDatav3.0PermissiveCommons/","items":[]},{"title":"Skills & Social Activities","url":"/old-work-archives/WebCivicsMediumPosts/2019/Skills&SocialActivities/","items":[]},{"title":"Small to Medium Business, WebPayments & Knowledge Banking","url":"/old-work-archives/WebCivicsMediumPosts/2019/SmallToMediumBusinessWebPayments&KnowledgeBanking/","items":[]},{"title":"Tech for Permissive Commons","url":"/old-work-archives/WebCivicsMediumPosts/2019/TechforPermissiveCommons/","items":[]},{"title":"The Case for a ‘Human Centric’ Global Cyber Infrastructure Project","url":"/old-work-archives/WebCivicsMediumPosts/2019/TheCaseforaHumanCentricGlobalCyberInfrastructureProject/","items":[]},{"title":"The Semantic Inforg & The “Human Centric Web” — Reality Check, Tech.","url":"/old-work-archives/WebCivicsMediumPosts/2019/The Semantic Inforg & The “Human Centric Web” — Reality Check, Tech./","items":[]},{"title":"Tooling for Democracies","url":"/old-work-archives/WebCivicsMediumPosts/2019/ToolingforDemocracies/","items":[]},{"title":"Universitas Doctrina et Sapientiae","url":"/old-work-archives/WebCivicsMediumPosts/2019/UniversitasDoctrinaetSapientiae/","items":[]},{"title":"Why a Trust Factory (“think tank”)","url":"/old-work-archives/WebCivicsMediumPosts/2019/WhyaTrustFactorythinktank/","items":[]},{"title":"WoT Smart Cities Engineering Digital Twin Things & Ecosystems.","url":"/old-work-archives/WebCivicsMediumPosts/2019/WoTSmartCitiesEngineeringDigitalTwinThings&Ecosystems/","items":[]}]},{"title":"During-Covid","url":"","items":[{"title":"A Future For Australians","url":"/old-work-archives/WebCivicsMediumPosts/during-covid/AFutureForAustralians/","items":[]},{"title":"A Future to Support Informed Decisions S.T.E.A.M & Stars","url":"/old-work-archives/WebCivicsMediumPosts/during-covid/AFuturetoSupportInformedDecisionsSTEAM&Stars/","items":[]},{"title":"A Major Manifestation Problem","url":"/old-work-archives/WebCivicsMediumPosts/during-covid/AMajorManifestationProblem/","items":[]},{"title":"Choices about the future of Knowledge Governance & alternatives Solutions to what appears to be how VaccinePassports are now being made","url":"/old-work-archives/WebCivicsMediumPosts/during-covid/ChoicesaboutthefutureofKnowledgeGovernanceAlternativesSolutionstoVaccinePassports/","items":[]},{"title":"Digital Covid19 “Vaccine Passport”","url":"/old-work-archives/WebCivicsMediumPosts/during-covid/DigitalCovid19VaccinePassports/","items":[]},{"title":"Do We Need a Space Time Navigator","url":"/old-work-archives/WebCivicsMediumPosts/during-covid/DoWeNeedaSpaceTimeNavigator/","items":[]},{"title":"Is an International Cyber Migration Even Possible","url":"/old-work-archives/WebCivicsMediumPosts/during-covid/IsanInternationalCyberMigrationEvenPossible/","items":[]}]}]},{"title":"Webizen Group 2015","url":"/old-work-archives/WebizenGroup2015/","items":[]}]},{"title":"Permissive Commons","url":"/PermissiveCommons/","items":[{"title":"PCT Ontology Modelling","url":"/PermissiveCommons/PCTOntologyModelling/","items":[{"title":"Biosphere Ontologies","url":"/PermissiveCommons/PCTOntologyModelling/BiosphereOntologies/","items":[]},{"title":"English Language Modelling","url":"/PermissiveCommons/PCTOntologyModelling/EnglishLanguageModelling/","items":[]},{"title":"NLP","url":"/PermissiveCommons/PCTOntologyModelling/NLP/","items":[]},{"title":"Ontology Modelling","url":"/PermissiveCommons/PCTOntologyModelling/OntologyModelling/","items":[]},{"title":"OntologyWork","url":"","items":[{"title":"OWL","url":"/PermissiveCommons/PCTOntologyModelling/OntologyWork/OWL/","items":[]}]},{"title":"PCTWebizenUseOfOntology","url":"/PermissiveCommons/PCTOntologyModelling/PCTWebizenUseOfOntology/","items":[]},{"title":"SocioSphere Ontologies","url":"/PermissiveCommons/PCTOntologyModelling/SocioSphereOntologies/","items":[]},{"title":"Understanding Ontologies","url":"/PermissiveCommons/PCTOntologyModelling/UnderstandingOntologies/","items":[]}]},{"title":"Permissive Commons Tech","url":"/PermissiveCommons/PermissiveCommonsTech/","items":[{"title":"PCTRequirements","url":"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/","items":[{"title":"Engineering Considerations","url":"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCTEngineeringConsiderations/","items":[{"title":"Cryptographic Signatures","url":"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCTEngineeringConsiderations/CryptographicSignatures/","items":[]},{"title":"Energy Consumption","url":"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCTEngineeringConsiderations/EnergyConsumption/","items":[]},{"title":"ForTheGoodOfHumanity","url":"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCTEngineeringConsiderations/ForTheGoodOfHumanity/","items":[]},{"title":"Object Ontology Capabilities.","url":"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCTEngineeringConsiderations/ObjectOntologyCapabilities/","items":[]},{"title":"PCT-DNS Considerations","url":"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCTEngineeringConsiderations/PCT-DNS-Considerations/","items":[]},{"title":"Protocol Independence","url":"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCTEngineeringConsiderations/Protocolindependence/","items":[]},{"title":"PublishingWorkflow","url":"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCTEngineeringConsiderations/PublishingWorkflow/","items":[]},{"title":"SocioEconomic Relations","url":"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCTEngineeringConsiderations/SocioEconomicRelations/","items":[]},{"title":"Temporal Semantics","url":"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCTEngineeringConsiderations/PCTTemporalSemantics/","items":[]},{"title":"Version Control","url":"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCTEngineeringConsiderations/VersionControl/","items":[]}]},{"title":"PCT_PeaceInfrastructureProjectRequirements","url":"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCT_PeaceInfrastructureProjectRequirements/","items":[]},{"title":"PCT-Core-Services","url":"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCT-Core-Services/","items":[{"title":"Decentralised Ontologies","url":"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCT-Core-Services/DecentralisedOntologies/","items":[]},{"title":"Human Centric Ontology","url":"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCT-Core-Services/HumanCentricOntology/","items":[]}]},{"title":"PCTSpecifications","url":"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCTSpecifications/","items":[{"title":"Permissive Commons Categories","url":"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCTSpecifications/PermissiveCommonsCategories/","items":[]}]},{"title":"Permissive Commons Technology Docs","url":"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCTREADME/","items":[]},{"title":"Use Cases","url":"/PermissiveCommons/PermissiveCommonsTech/PCTRequirements/PCTuse-cases/","items":[]}]},{"title":"Problem Statement","url":"/PermissiveCommons/PermissiveCommonsTech/PCTProblemStatement/","items":[]},{"title":"What are 'The Commons'","url":"/PermissiveCommons/PermissiveCommonsTech/WhatAreTheCommons/","items":[]},{"title":"What is 'Open Data'","url":"/PermissiveCommons/PermissiveCommonsTech/WhatIsOpenData/","items":[]},{"title":"Work in Progress","url":"/PermissiveCommons/PermissiveCommonsTech/PCTWorkInProgress/","items":[{"title":"Collect Existing Ontologies","url":"/PermissiveCommons/PermissiveCommonsTech/PCTWorkInProgress/CollectExistingOntologies/","items":[]},{"title":"DIDsEval","url":"/PermissiveCommons/PermissiveCommonsTech/PCTWorkInProgress/DIDsEval/","items":[]},{"title":"Knowledge Modelling","url":"/PermissiveCommons/PermissiveCommonsTech/PCTWorkInProgress/KnowledgeModelling/","items":[{"title":"Agent Ontology Modelling","url":"/PermissiveCommons/PermissiveCommonsTech/PCTWorkInProgress/KnowledgeModelling/AgentOntologyModelling/","items":[]},{"title":"GeoTemporalSemantics","url":"/PermissiveCommons/PermissiveCommonsTech/PCTWorkInProgress/KnowledgeModelling/GeoTemporalSemantics/","items":[]}]},{"title":"Minimum Wages","url":"/PermissiveCommons/PermissiveCommonsTech/PCTWorkInProgress/MinimumWages/","items":[]},{"title":"Ontology in Markdown Example","url":"/PermissiveCommons/PermissiveCommonsTech/PCTWorkInProgress/RDF2MD-Example/","items":[]},{"title":"Permissive Commons Technology (PCT) Requirements.","url":"/PermissiveCommons/PermissiveCommonsTech/PCTWorkInProgress/PermissiveCommonsRequirements/","items":[]},{"title":"Safety Considerations","url":"/PermissiveCommons/PermissiveCommonsTech/PCTWorkInProgress/SafetyConsiderations/","items":[]}]}]},{"title":"Sustainable Development Goals (ESG)","url":"/PermissiveCommons/SDGs/","items":[]}]},{"title":"Social Factors","url":"/SocialFactors/","items":[{"title":"Background","url":"/SocialFactors/Background/","items":[]},{"title":"Commercial Models","url":"/SocialFactors/CommercialModels/","items":[{"title":"Best Efforts","url":"/SocialFactors/CommercialModels/BestEfforts/","items":[]},{"title":"Currencies","url":"/SocialFactors/CommercialModels/Currencies/","items":[{"title":"Financial Payment Types","url":"/SocialFactors/CommercialModels/Currencies/FinancialPaymentTypes/","items":[]},{"title":"Gifts and Donations","url":"/SocialFactors/CommercialModels/Currencies/GiftsAndDonations/","items":[]},{"title":"Micro Payments","url":"/SocialFactors/CommercialModels/Currencies/Micropayments/","items":[]},{"title":"Non-Financial Currencies","url":"/SocialFactors/CommercialModels/Currencies/Non-FinancialCurrencies/","items":[]}]},{"title":"Economic Systems","url":"/SocialFactors/CommercialModels/EconomicSystems/","items":[]},{"title":"Environmental, Social and Governance (ESG)","url":"/SocialFactors/CommercialModels/ESG/","items":[{"title":"Biosphere Calcs","url":"/SocialFactors/CommercialModels/ESG/BiosphereCalcs/","items":[]},{"title":"Energy Calcs","url":"/SocialFactors/CommercialModels/ESG/EnergyCalcs/","items":[]},{"title":"Sociosphere Calcs","url":"/SocialFactors/CommercialModels/ESG/SocioshereCalcs/","items":[]}]},{"title":"Fit For Purpose","url":"/SocialFactors/CommercialModels/FitForPurpose/","items":[]},{"title":"Hardware Strategy","url":"/SocialFactors/CommercialModels/HardwareStrategy/","items":[]},{"title":"Historical Information","url":"/SocialFactors/CommercialModels/Historical Information/","items":[{"title":"Domains","url":"/SocialFactors/CommercialModels/Historical Information/Domains/","items":[]},{"title":"Value Accounting Initiatives","url":"/SocialFactors/CommercialModels/Historical Information/ValueAccountingInitiatives/","items":[]},{"title":"Web Civics","url":"/SocialFactors/CommercialModels/Historical Information/WebCivics/","items":[]}]},{"title":"The Work Project","url":"/SocialFactors/CommercialModels/WorkProject/","items":[{"title":"Contribution Classifications","url":"/SocialFactors/CommercialModels/WorkProject/ContributionClassifications/","items":[]},{"title":"Equipment and Supplies","url":"/SocialFactors/CommercialModels/WorkProject/EquipmentAndSupplies/","items":[]},{"title":"Intellectual Property","url":"/SocialFactors/CommercialModels/WorkProject/IntellectualProperty/","items":[]},{"title":"Knowledge Work","url":"/SocialFactors/CommercialModels/WorkProject/KnowledgeWork/","items":[]},{"title":"Labour Work","url":"/SocialFactors/CommercialModels/WorkProject/LabourWork/","items":[]},{"title":"Licensing Frameworks","url":"/SocialFactors/CommercialModels/WorkProject/LicensingFrameworks/","items":[]},{"title":"Project Financing","url":"/SocialFactors/CommercialModels/WorkProject/ProjectFinancing/","items":[]},{"title":"Resources","url":"/SocialFactors/CommercialModels/WorkProject/Resources/","items":[]},{"title":"Work Valuation Methods","url":"/SocialFactors/CommercialModels/WorkProject/WorkValuationMethods/","items":[]}]},{"title":"Trust Factory","url":"/SocialFactors/CommercialModels/TrustFactory/","items":[]},{"title":"Webizen","url":"/SocialFactors/CommercialModels/Webizen/","items":[]},{"title":"Webizen Alliance","url":"/SocialFactors/CommercialModels/WebizenAlliance/","items":[{"title":"Community of Practice","url":"/SocialFactors/CommercialModels/WebizenAlliance/CommunityOfPractice/","items":[]},{"title":"Early Stage Income Strategies","url":"/SocialFactors/CommercialModels/WebizenAlliance/EarlyStageIncomeStrategies/","items":[]},{"title":"The Webizen Charter","url":"/SocialFactors/CommercialModels/WebizenAlliance/TheWebizenCharter/","items":[]},{"title":"Webizen Host Providers","url":"/SocialFactors/CommercialModels/WebizenAlliance/WebizenAllianceHostProviders/","items":[]}]},{"title":"Webizen Pro VAR Solutions","url":"/SocialFactors/CommercialModels/WebizenProVARSolutions/","items":[]},{"title":"WebizenPro Usecases","url":"/SocialFactors/CommercialModels/WebizenProUsecases/","items":[{"title":"Webizen Pro Ecosystem Usecases","url":"/SocialFactors/CommercialModels/WebizenProUsecases/WebizenProEcosystemUsecases/","items":[]},{"title":"Webizen Pro Edge UseCases","url":"/SocialFactors/CommercialModels/WebizenProUsecases/WebizenProEdgeUseCases/","items":[]},{"title":"Webizen Pro Use-Cases","url":"/SocialFactors/CommercialModels/WebizenProUsecases/WebizenProUse-Cases/","items":[]}]}]},{"title":"Commercial-Technical Requirements","url":"/SocialFactors/SocioEconomicTechReqs/","items":[{"title":"Account Creation","url":"/SocialFactors/SocioEconomicTechReqs/AccountCreation/","items":[]},{"title":"Guardianship Relations","url":"/SocialFactors/SocioEconomicTechReqs/GuardianshipRelations/","items":[]},{"title":"Guardianship Semantics","url":"/SocialFactors/SocioEconomicTechReqs/GuardianshipSemantics/","items":[]},{"title":"Support for Human Agency","url":"/SocialFactors/SocioEconomicTechReqs/SupportForHumanAgency/","items":[]}]},{"title":"Peace Infrastructure Project","url":"/SocialFactors/PeaceInfrastructureProject/","items":[{"title":"About the Peace Infrastructure Project","url":"/SocialFactors/PeaceInfrastructureProject/AboutThePeaceInfrastructureProject/","items":[]}]},{"title":"Social Attack Vectors","url":"/SocialFactors/SocialAttackVectors/","items":[{"title":"Criminal Activity","url":"/SocialFactors/SocialAttackVectors/CriminalActivity/","items":[{"title":"Corporate Crime","url":"/SocialFactors/SocialAttackVectors/CriminalActivity/CorporateCrime/","items":[]},{"title":"Environmental Crime","url":"/SocialFactors/SocialAttackVectors/CriminalActivity/EnvironmentalCrime/","items":[]},{"title":"Financial Crimes","url":"/SocialFactors/SocialAttackVectors/CriminalActivity/FinancialCrimes/","items":[]},{"title":"Fraud","url":"/SocialFactors/SocialAttackVectors/CriminalActivity/Fraud/","items":[]},{"title":"Proxy Attacks","url":"/SocialFactors/SocialAttackVectors/CriminalActivity/ProxyAttacks/","items":[]}]},{"title":"Cyber Attack Vectors","url":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/","items":[{"title":"Attacks Online","url":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/AttacksOnline/","items":[]},{"title":"Cyber Crime","url":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/CyberCrime/","items":[]},{"title":"Database Attacks","url":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/DataBaseAttacks/","items":[]},{"title":"DeepFakes","url":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/DeepFakes/","items":[]},{"title":"Digital Slavery","url":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/DigitalSlavery/","items":[]},{"title":"MisRepresentation","url":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/MisRepresentation/","items":[]},{"title":"NobodyAI","url":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/NobodyAI/","items":[]},{"title":"Permanent Identifiers","url":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/permanentIdentifiers/","items":[]},{"title":"Tech Debt","url":"/SocialFactors/SocialAttackVectors/CyberAttackVectors/TechDebt/","items":[]}]},{"title":"Discrimination based attacks.","url":"/SocialFactors/SocialAttackVectors/discriminationBasedAttacks/","items":[]},{"title":"Dishonesty","url":"/SocialFactors/SocialAttackVectors/Dishonesty/","items":[]},{"title":"Strategic Harms & Exploitation","url":"/SocialFactors/SocialAttackVectors/StrategicHarms/","items":[{"title":"\"The Secret\"","url":"/SocialFactors/SocialAttackVectors/StrategicHarms/TheSecret/","items":[]},{"title":"Academic / Institutional Funnelling","url":"/SocialFactors/SocialAttackVectors/StrategicHarms/AcademicInstitutionalFunnelling/","items":[]},{"title":"Authorised Thinkers","url":"/SocialFactors/SocialAttackVectors/StrategicHarms/AuthorisedThinkers/","items":[]},{"title":"Brain Rape","url":"/SocialFactors/SocialAttackVectors/StrategicHarms/BrainRape/","items":[]},{"title":"Commercial Exploitation","url":"/SocialFactors/SocialAttackVectors/StrategicHarms/CommercialExploitation/","items":[]},{"title":"Compromise","url":"/SocialFactors/SocialAttackVectors/StrategicHarms/Compromise/","items":[]},{"title":"Dehumanisation","url":"/SocialFactors/SocialAttackVectors/StrategicHarms/Dehumanisation/","items":[]},{"title":"Fake News","url":"/SocialFactors/SocialAttackVectors/StrategicHarms/FakeNews/","items":[]},{"title":"False Attribution","url":"/SocialFactors/SocialAttackVectors/StrategicHarms/FalseAttribution/","items":[]},{"title":"Impairment","url":"/SocialFactors/SocialAttackVectors/StrategicHarms/Impairment/","items":[]},{"title":"Manipulation","url":"/SocialFactors/SocialAttackVectors/StrategicHarms/Manipulation/","items":[]},{"title":"Psychological Attack & PsyOps","url":"/SocialFactors/SocialAttackVectors/StrategicHarms/PsychologicalAttack/","items":[]},{"title":"Public Sector Wrong Doings","url":"/SocialFactors/SocialAttackVectors/StrategicHarms/PublicSectorWrongDoings/","items":[]},{"title":"Reversal","url":"/SocialFactors/SocialAttackVectors/StrategicHarms/Reversal/","items":[]},{"title":"Social Contract Gamification","url":"/SocialFactors/SocialAttackVectors/StrategicHarms/SocialContractGamification/","items":[]},{"title":"TemporalAttacks","url":"/SocialFactors/SocialAttackVectors/StrategicHarms/TemporalAttacks/","items":[]},{"title":"The Harvester","url":"/SocialFactors/SocialAttackVectors/StrategicHarms/TheHarvester/","items":[]},{"title":"You Must Be Famous!!!","url":"/SocialFactors/SocialAttackVectors/StrategicHarms/MustBeFamous/","items":[]}]},{"title":"Torts","url":"/SocialFactors/SocialAttackVectors/Torts/","items":[{"title":"Economic Torts","url":"/SocialFactors/SocialAttackVectors/Torts/EconomicTorts/","items":[]},{"title":"Intentional Torts","url":"/SocialFactors/SocialAttackVectors/Torts/IntentionalTorts/","items":[]},{"title":"Negligence","url":"/SocialFactors/SocialAttackVectors/Torts/Negligence/","items":[]},{"title":"Nuisance","url":"/SocialFactors/SocialAttackVectors/Torts/Nuisance/","items":[]}]}]},{"title":"Web Science","url":"/SocialFactors/WebScience/","items":[{"title":"Artificial Minds","url":"/SocialFactors/WebScience/ArtificialMinds/","items":[{"title":"A ChatGPT Experiment: Holborn","url":"/SocialFactors/WebScience/ArtificialMinds/AChatGPTExperimentHolborn/","items":[]},{"title":"BotScience","url":"/SocialFactors/WebScience/ArtificialMinds/BotScience/","items":[]},{"title":"Cognitive AI","url":"/SocialFactors/WebScience/ArtificialMinds/CognitiveAI/","items":[{"title":"Cognitive AI","url":"/SocialFactors/WebScience/ArtificialMinds/CognitiveAI/CognitiveAI-WIP/","items":[]},{"title":"Defeasible Logic","url":"/SocialFactors/WebScience/ArtificialMinds/CognitiveAI/DefeasibleLogic/","items":[]},{"title":"Plausible Reasoning","url":"/SocialFactors/WebScience/ArtificialMinds/CognitiveAI/PlausibleReasoning/","items":[]}]},{"title":"The Artificial Minds List","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/","items":[{"title":"Baymax","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Baymax/","items":[]},{"title":"Bishop - Aliens","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Bishop - Aliens/","items":[]},{"title":"Borg - Star Trek","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Borg - Star Trek/","items":[]},{"title":"ChatGPT","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/ChatGPT/","items":[]},{"title":"Edwin Jarvis","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Edwin Jarvis/","items":[]},{"title":"IBM Watson","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/IBM Watson/","items":[]},{"title":"Max - Flight of the Navigator","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Max - Flight of the Navigator/","items":[]},{"title":"Rosie - The Jetsons","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Rosie - The Jetsons/","items":[]},{"title":"Sarah - Eureka","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/Sarah - Eureka/","items":[]},{"title":"SkyNet","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/SkyNet/","items":[]},{"title":"The Doctor - Star Trek Voyager","url":"/SocialFactors/WebScience/ArtificialMinds/TheArtificialMindsIndex/The Doctor - Star Trek Voyager/","items":[]}]},{"title":"The Webizen Agent","url":"/SocialFactors/WebScience/ArtificialMinds/TheWebizenAgent/","items":[]}]},{"title":"Banishment & Exile.","url":"/SocialFactors/WebScience/banishmentExile/","items":[]},{"title":"Category Theory","url":"/SocialFactors/WebScience/CategoryTheory/","items":[]},{"title":"Centricity","url":"/SocialFactors/WebScience/Centricity/","items":[]},{"title":"Human-Centric AI Ethics","url":"/SocialFactors/WebScience/HumanCentricAIEthics/","items":[]},{"title":"Identity Modelling","url":"/SocialFactors/WebScience/IdentityModelling/","items":[]},{"title":"identityModelling","url":"","items":[{"title":"NISTIDOntology","url":"/SocialFactors/WebScience/identityModelling/NISTIDOntology/","items":[]},{"title":"Personal Ontology","url":"/SocialFactors/WebScience/identityModelling/PersonalOntology/","items":[]}]},{"title":"Learning Modals","url":"/SocialFactors/WebScience/LearningModals/","items":[]},{"title":"Nomenclature","url":"/SocialFactors/WebScience/nomenclature/","items":[{"title":"Data Vs. Quads","url":"/SocialFactors/WebScience/nomenclature/datavsquads/","items":[]}]},{"title":"Safety Protocols","url":"/SocialFactors/WebScience/SafetyProtocols/","items":[{"title":"Agent Labelling","url":"/SocialFactors/WebScience/SafetyProtocols/AgentLabelling/","items":[]},{"title":"Data Portability","url":"/SocialFactors/WebScience/SafetyProtocols/DataPortability/","items":[]},{"title":"Ending Digital Slavery","url":"/SocialFactors/WebScience/SafetyProtocols/EndingDigitalSlavery/","items":[]},{"title":"Fair Work Protocols","url":"/SocialFactors/WebScience/SafetyProtocols/FairWorkProtocols/","items":[]},{"title":"Freedom of Thought","url":"/SocialFactors/WebScience/SafetyProtocols/FreedomOfThought/","items":[]},{"title":"Human Centric AI","url":"/SocialFactors/WebScience/SafetyProtocols/HumanCentricAI/","items":[]},{"title":"HumanCentric Digital Identity","url":"/SocialFactors/WebScience/SafetyProtocols/HumanCentricDigitalIdentity/","items":[]},{"title":"Knowledge Qualification Methods","url":"/SocialFactors/WebScience/SafetyProtocols/KnowledgeQualificationMethods/","items":[]},{"title":"No Lock-ins","url":"/SocialFactors/WebScience/SafetyProtocols/NoLock-ins/","items":[]},{"title":"Protecting Children","url":"/SocialFactors/WebScience/SafetyProtocols/ProtectingChildren/","items":[]},{"title":"Relationships (Social)","url":"/SocialFactors/WebScience/SafetyProtocols/Relationships(Social)/","items":[]},{"title":"Values Credentials","url":"/SocialFactors/WebScience/SafetyProtocols/ValuesCredentials/","items":[]}]},{"title":"Science of Consciousness","url":"/SocialFactors/WebScience/ScienceOfConsciousness/","items":[]},{"title":"The Values Project","url":"/SocialFactors/WebScience/TheValuesProject/","items":[]}]},{"title":"Webizen 3.0 Setup User Experience","url":"/SocialFactors/Webizen3.0SetupUserExperience/","items":[]},{"title":"Webizen: For Humans","url":"/SocialFactors/WebizenForHumans/","items":[]}]},{"title":"Webizen Docs Introduction","url":"/","items":[]},{"title":"Webizen Tech Stack","url":"/WebizenTechStack/","items":[{"title":"Authentication Fabric","url":"/WebizenTechStack/AuthenticationFabric/","items":[{"title":"Verifiable Credentials","url":"/WebizenTechStack/AuthenticationFabric/VerifiableCredentials/","items":[]},{"title":"WebAuthn","url":"/WebizenTechStack/AuthenticationFabric/WebAuthn/","items":[]},{"title":"WebID","url":"/WebizenTechStack/AuthenticationFabric/WebID/","items":[]}]},{"title":"Core Services","url":"/WebizenTechStack/CoreServices/","items":[{"title":"Non-HTTP(s) Protocols","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/","items":[{"title":"Chia","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/Chia/","items":[]},{"title":"DAT","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/DAT/","items":[]},{"title":"GIT","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/GIT/","items":[]},{"title":"GUNECO","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/GUNECO/","items":[]},{"title":"Hedera","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/Hedera/","items":[]},{"title":"Holochain","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/Holochain/","items":[]},{"title":"IOTA","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/IOTA/","items":[]},{"title":"IPFS","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/IPFS/","items":[]},{"title":"IPLD","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/IPLD/","items":[]},{"title":"Lightning Network","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/LightningNetwork/","items":[]},{"title":"NYM","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/NYM/","items":[]},{"title":"Obyte","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/obyte/","items":[]},{"title":"WebCash","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/WebCash/","items":[]},{"title":"WebRTC","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/WebRTC/","items":[]},{"title":"WebSockets","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/WebSockets/","items":[]},{"title":"WebTorrent","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/WebTorrent/","items":[]},{"title":"WireGuard","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/WireGuard/","items":[]},{"title":"XRP Ledger","url":"/WebizenTechStack/CoreServices/Non-HTTP(s)Protocols/XRPLedger/","items":[]}]},{"title":"Verifiable Claims & Credentials","url":"/WebizenTechStack/CoreServices/VerifiableClaims&Credentials/","items":[]}]},{"title":"Core Technologies","url":"/WebizenTechStack/CoreTechnologies/","items":[{"title":"GoLang Libraries","url":"/WebizenTechStack/CoreTechnologies/GoLangLibraries/","items":[]},{"title":"Open Badges","url":"/WebizenTechStack/CoreTechnologies/OpenBadges/","items":[]},{"title":"Semantic Web","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/","items":[{"title":"GRDDL","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/GRDDL/","items":[]},{"title":"Semantic Web Authentication Tech","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWeb-AUTH/","items":[{"title":"WebID-OIDC","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWeb-AUTH/WebID-OIDC/","items":[]},{"title":"WebID-RSA","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWeb-AUTH/WebID-RSA/","items":[]},{"title":"WebID-TLS","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWeb-AUTH/WebID-TLS/","items":[]}]},{"title":"SemWebOntologies","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWebOntologies/","items":[{"title":"DAML+OIL","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWebOntologies/DAML+OIL/","items":[]},{"title":"Friend of a Friend (FOAF) Core","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWebOntologies/FOAF/","items":[]},{"title":"HumanRightsOntologies","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWebOntologies/HumanRightsOntologies/","items":[{"title":"UDHR","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWebOntologies/HumanRightsOntologies/UDHR/","items":[]}]},{"title":"LKIF-Core","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWebOntologies/LKIF-Core/","items":[]},{"title":"MD-RDF Ontologies","url":"","items":[{"title":"DataTypesOntology (DTO) Core","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWebOntologies/MD-RDF Ontologies/DataTypes Ontology/","items":[]}]},{"title":"OWL","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWebOntologies/OWL/","items":[]},{"title":"RDFS","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWebOntologies/RDFS/","items":[]},{"title":"Sitemap","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWebOntologies/Sitemap/","items":[]},{"title":"SKOS","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWebOntologies/SKOS/","items":[]},{"title":"SOIC","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SemWebOntologies/SOIC/","items":[]}]},{"title":"Sparql Family","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/SparqlFamily/","items":[]},{"title":"W3C Specifications","url":"","items":[{"title":"Linked Data Fragments","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/Linked Data Fragments/","items":[]},{"title":"Linked Data Notifications","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/Linked Data Notifications/","items":[]},{"title":"Linked Data Platform","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/Linked Data Platform/","items":[]},{"title":"Linked Media Fragments","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/Linked Media Fragments/","items":[]},{"title":"RDF","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/RDF/","items":[]},{"title":"Web Access Control (WAC)","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/Web Access Control (WAC)/","items":[]},{"title":"Web Of Things","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/Web Of Things/","items":[]},{"title":"WebID Specifications","url":"/WebizenTechStack/CoreTechnologies/SemanticWeb/W3C Specifications/WebID Specifications/","items":[]}]}]},{"title":"Temporal Semantics","url":"/WebizenTechStack/CoreTechnologies/TemporalSemantics/","items":[]}]},{"title":"Engineering Considerations","url":"/WebizenTechStack/EngineeringConsiderations/","items":[{"title":"Authentication Logic","url":"/WebizenTechStack/EngineeringConsiderations/AUTHLogic/","items":[]},{"title":"Containerisation","url":"/WebizenTechStack/EngineeringConsiderations/Containerisation/","items":[]},{"title":"Cryptography","url":"/WebizenTechStack/EngineeringConsiderations/Cryptography/","items":[]},{"title":"Database Requirements","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/","items":[{"title":"DatabaseAlternatives","url":"","items":[{"title":"Akutan","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseAlternatives/akutan/","items":[]},{"title":"Apache Kafka","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseAlternatives/ApacheKafka/","items":[]},{"title":"Bad Wolf","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseAlternatives/BadWolf/","items":[]},{"title":"CayleyGraph","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseAlternatives/CayleyGraph/","items":[]}]},{"title":"DatabaseMethods","url":"","items":[{"title":"BQL","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseMethods/BQL/","items":[]},{"title":"GraphQL","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseMethods/GraphQL/","items":[]},{"title":"Sparql","url":"/WebizenTechStack/EngineeringConsiderations/DatabaseRequirements/DatabaseMethods/Sparql/","items":[]}]}]},{"title":"Email Server Logic","url":"/WebizenTechStack/EngineeringConsiderations/MailServerLogic/","items":[]},{"title":"InternetStrategy","url":"/WebizenTechStack/EngineeringConsiderations/InternetStrategy/","items":[{"title":"DNS Considerations","url":"/WebizenTechStack/EngineeringConsiderations/InternetStrategy/DNSConsiderations/","items":[]},{"title":"General Internet Info","url":"/WebizenTechStack/EngineeringConsiderations/InternetStrategy/InternetSummaryInfo/","items":[]},{"title":"List of Protocols ISO model","url":"/WebizenTechStack/EngineeringConsiderations/InternetStrategy/ListOfProtocolsISOmodel/","items":[]}]},{"title":"Prolog","url":"/WebizenTechStack/EngineeringConsiderations/Prolog/","items":[]}]},{"title":"Private DataStore (Vault)","url":"/WebizenTechStack/DataStoreVaultNotes/","items":[]},{"title":"Vocabulary Modelling","url":"/WebizenTechStack/VocabularyModelling/","items":[{"title":"Dynamic Ontology","url":"/WebizenTechStack/VocabularyModelling/ChatGPTDynamicOntology/","items":[]},{"title":"Ontology App Development","url":"/WebizenTechStack/VocabularyModelling/OntologyAppDev/","items":[]},{"title":"TopLevelOntologyNLPResearch","url":"/WebizenTechStack/VocabularyModelling/TopLevelOntologyNLPResearch/","items":[]}]},{"title":"Webize","url":"/WebizenTechStack/Webize/","items":[{"title":"Appy","url":"/WebizenTechStack/Webize/appy/","items":[]},{"title":"Beaker Browser (Fork)","url":"/WebizenTechStack/Webize/BeakerBrowser/","items":[]},{"title":"Solid","url":"/WebizenTechStack/Webize/Solid/","items":[]},{"title":"Syncthing","url":"/WebizenTechStack/Webize/Syncthing/","items":[]}]},{"title":"Webizen 2.5 Dev","url":"/WebizenTechStack/Webizen2.5/","items":[{"title":"Chat GPT Supported Notes","url":"/WebizenTechStack/Webizen2.5/ChatGPTSupported/","items":[{"title":"ChatGPTDistributedDBGoNotes","url":"/WebizenTechStack/Webizen2.5/ChatGPTSupported/ChatGPTDistributedDBGoNotes/","items":[]},{"title":"Go WebID-OIDC & ChatGPT","url":"/WebizenTechStack/Webizen2.5/ChatGPTSupported/GoLangWebIDOIDC/","items":[]}]},{"title":"DevNotesWebizen2.5","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/","items":[{"title":"AgentAPI","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/AgentAPI/","items":[]},{"title":"Cryptography Notes","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/CryptographyNotes/","items":[]},{"title":"ImplementationNotes-2.5","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/","items":[{"title":"Golang Packages","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/GoLangPackages/","items":[]},{"title":"Webizen 2.5 Host Components","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/Webizen2.5HostComponents/","items":[{"title":"Caddy Server Implementation","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/Webizen2.5HostComponents/CaddyServerImplementation/","items":[]},{"title":"Implementation Progress","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/Webizen2.5HostComponents/ImplementationProgress2.5/","items":[{"title":"Auth UseCases","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/Webizen2.5HostComponents/ImplementationProgress2.5/AuthUseCases/","items":[]},{"title":"jsonInterfaces","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/Webizen2.5HostComponents/ImplementationProgress2.5/jsonInterfaces/","items":[]},{"title":"Modding Solid","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/Webizen2.5HostComponents/ImplementationProgress2.5/ModdingSolid/","items":[]},{"title":"VerifiableCredentialLibrary","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/Webizen2.5HostComponents/ImplementationProgress2.5/VerifiableCredentialLibrary/","items":[]},{"title":"WebizenDB","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/Webizen2.5HostComponents/ImplementationProgress2.5/WebizenDB/","items":[]}]},{"title":"Solid / RWW / CrossCloud - Fork","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/Webizen2.5HostComponents/SolidBasedSystemsFork/","items":[]},{"title":"Webizen Networking 2.5","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/Webizen2.5HostComponents/BasicWebizenNetworking2.5/","items":[{"title":"HeadScale Implementation","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/Webizen2.5HostComponents/BasicWebizenNetworking2.5/HeadScaleImplementation/","items":[]},{"title":"Headscale UI","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/Webizen2.5HostComponents/BasicWebizenNetworking2.5/Headscale-UI/","items":[]},{"title":"TailNets","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/Webizen2.5HostComponents/BasicWebizenNetworking2.5/TailNets/","items":[]},{"title":"WebizenDNSNotes","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/Webizen2.5HostComponents/BasicWebizenNetworking2.5/WebizenDNSNotes/","items":[]}]},{"title":"WebizenServiceManagement","url":"","items":[{"title":"Agent Logic","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/Webizen2.5HostComponents/WebizenServiceManagement/AgentLogic/","items":[]},{"title":"Curator","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/Webizen2.5HostComponents/WebizenServiceManagement/Curator/","items":[]},{"title":"Curator Logic Engine","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/Webizen2.5HostComponents/WebizenServiceManagement/CuratorLogic/","items":[]},{"title":"EmailMethodsModification","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/Webizen2.5HostComponents/WebizenServiceManagement/EmailMethodsModification/","items":[]},{"title":"Json App Interface","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/Webizen2.5HostComponents/WebizenServiceManagement/JsonAppInterface/","items":[]},{"title":"WebizenHostWebPlatform V2.5","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/Webizen2.5HostComponents/WebizenServiceManagement/WebizenHostWebPlatform/","items":[]}]}]},{"title":"Webizen Identity Fabric","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/WebizenID/","items":[{"title":"WebizenID-DNS","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/WebizenID/WebizenID-DNS/","items":[]},{"title":"WebizenID-TLS","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/WebizenID/WebizenID-TLS/","items":[]}]}]},{"title":"PCT-SocialAPI","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/PCT-SocialAPI/","items":[]},{"title":"RWW Notes & Info","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/RWWNotesInfo/","items":[]},{"title":"ToolAppRequirements","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ToolAppRequirements/","items":[{"title":"Proof Of Concept App Reqs","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ToolAppRequirements/POCAppRequirements/","items":[]},{"title":"Trained Language Model","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ToolAppRequirements/TrainedLanguageModel/","items":[]}]},{"title":"WebizenEngine","url":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/WebizenEngine/","items":[]}]},{"title":"FunctionalObjectives","url":"/WebizenTechStack/Webizen2.5/FunctionalObjectives/","items":[{"title":"FUNCTIONS","url":"/WebizenTechStack/Webizen2.5/FunctionalObjectives/FUNCTIONS/","items":[]},{"title":"HelperAppObjectives","url":"/WebizenTechStack/Webizen2.5/FunctionalObjectives/HelperAppObjectives/","items":[]},{"title":"PCT-NOTES","url":"/WebizenTechStack/Webizen2.5/FunctionalObjectives/PCT-NOTES/","items":[]},{"title":"Webizen - Root Concepts","url":"/WebizenTechStack/Webizen2.5/FunctionalObjectives/RootConcepts/","items":[]}]},{"title":"POC of Core Concepts","url":"/WebizenTechStack/Webizen2.5/POCOfCoreConcepts/","items":[]},{"title":"Sacrifices-Hard Problems","url":"/WebizenTechStack/Webizen2.5/Sacrifices-hardproblems/","items":[]}]},{"title":"Webizen 3.0","url":"/WebizenTechStack/Webizen3.0/","items":[{"title":"Client Software Requirements","url":"/WebizenTechStack/Webizen3.0/ClientSoftwareRequirements/","items":[]},{"title":"Host Software Requirements","url":"/WebizenTechStack/Webizen3.0/HostServiceRequirements/","items":[{"title":"Domain Hosting","url":"/WebizenTechStack/Webizen3.0/HostServiceRequirements/DomainHosting/","items":[]},{"title":"Media Processing","url":"/WebizenTechStack/Webizen3.0/HostServiceRequirements/MediaProcessing/","items":[{"title":"Ffmpeg","url":"/WebizenTechStack/Webizen3.0/HostServiceRequirements/MediaProcessing/ffmpeg/","items":[]},{"title":"Opencv","url":"/WebizenTechStack/Webizen3.0/HostServiceRequirements/MediaProcessing/opencv/","items":[]}]},{"title":"Networking Considerations","url":"/WebizenTechStack/Webizen3.0/HostServiceRequirements/NetworkingConsiderations/","items":[]}]},{"title":"HyperMedia Containers","url":"/WebizenTechStack/Webizen3.0/HyperMediaContainers/","items":[{"title":"Knowledge Documents","url":"/WebizenTechStack/Webizen3.0/HyperMediaContainers/KnowledgeDocuments/","items":[]},{"title":"webizen.n3","url":"/WebizenTechStack/Webizen3.0/HyperMediaContainers/webizen.n3/","items":[]}]}]},{"title":"Webizen 3.5","url":"/WebizenTechStack/Webizen3.5/","items":[{"title":"AI Capabilities","url":"/WebizenTechStack/Webizen3.5/AICapabilities/","items":[{"title":"AI Capabilities Objectives","url":"/WebizenTechStack/Webizen3.5/AICapabilities/AICapabilitiesObjectives/","items":[]},{"title":"Audio & Video Analysis","url":"/WebizenTechStack/Webizen3.5/AICapabilities/Audio & Video Analysis/","items":[]},{"title":"Image Analysis","url":"/WebizenTechStack/Webizen3.5/AICapabilities/Image Analysis/","items":[]},{"title":"Text Analysis","url":"/WebizenTechStack/Webizen3.5/AICapabilities/Text Analysis/","items":[]}]},{"title":"Web Of Things (IoT)","url":"/WebizenTechStack/Webizen3.5/WebOfThings(IoT)/","items":[]},{"title":"Webizen AI OS Platform","url":"/WebizenTechStack/Webizen3.5/WebizenAiOS-Platform/","items":[]},{"title":"Webizen Pro Series","url":"/WebizenTechStack/Webizen3.5/WebizenProSeries/","items":[{"title":"Webizen Pro","url":"/WebizenTechStack/Webizen3.5/WebizenProSeries/WebizenPro/","items":[]},{"title":"Webizen Pro - Edge","url":"/WebizenTechStack/Webizen3.5/WebizenProSeries/WebizenPro-Edge/","items":[]},{"title":"WebizenProHardware","url":"/WebizenTechStack/Webizen3.5/WebizenProSeries/WebizenProHardware/","items":[]},{"title":"WebizenProSoftware","url":"/WebizenTechStack/Webizen3.5/WebizenProSeries/WebizenProSoftware/","items":[]}]},{"title":"Webizen Vision","url":"/WebizenTechStack/Webizen3.5/WebizenVision/","items":[]}]},{"title":"Webizen 4.0","url":"/WebizenTechStack/Webizen4.0/","items":[{"title":"MyWebizen","url":"/WebizenTechStack/Webizen4.0/MyWebizen/","items":[]}]},{"title":"Webizen Apps","url":"/WebizenTechStack/WebizenApps/","items":[{"title":"Historical RWW Apps","url":"/WebizenTechStack/WebizenApps/Historical RWW Apps/","items":[]},{"title":"Webizen 3.5 Apps","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/","items":[{"title":"Media Production","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/MediaProduction/","items":[]},{"title":"Mobile Apps","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/MobileApps/","items":[{"title":"Android","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/MobileApps/Android/","items":[]},{"title":"iOS","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/MobileApps/iOS/","items":[]},{"title":"The Webizen (mobile) Agent","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/MobileApps/TheWebizen(mobile)Agent/","items":[]}]},{"title":"Search","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/Search/","items":[]},{"title":"Webizen Host Apps","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/HostApps/","items":[{"title":"Email Services","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/HostApps/EmailServices/","items":[]},{"title":"Webizen Server - WebApps","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/HostApps/WebizenServer-WebApps/","items":[]},{"title":"Website Hosting","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/HostApps/WebsiteHost/","items":[]}]},{"title":"Webizen Manager","url":"/WebizenTechStack/WebizenApps/Webizen3.5Apps/WebizenManager/","items":[]}]},{"title":"Webizen Interfaces","url":"/WebizenTechStack/WebizenApps/WebizenInterfaces/","items":[{"title":"API","url":"/WebizenTechStack/WebizenApps/WebizenInterfaces/API/","items":[]},{"title":"The Attendant","url":"/WebizenTechStack/WebizenApps/WebizenInterfaces/TheAttendant/","items":[]},{"title":"TheWebizen","url":"/WebizenTechStack/WebizenApps/WebizenInterfaces/TheWebizen/","items":[]}]},{"title":"Webizen3.0Apps","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/","items":[{"title":"Design Goals","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/DesignGoals/","items":[]},{"title":"MobileBasics","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/MobileBasics/","items":[]},{"title":"WADE No-Code - Low-Code","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/NoCodeAppDev/","items":[]},{"title":"Webizen App Spec","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/WebizenAppSpec/","items":[{"title":"DOAP Form Example","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/WebizenAppSpec/DOAP form Example/","items":[]},{"title":"WebSpec","url":"","items":[{"title":"HTML SPECS","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/WebizenAppSpec/WebSpec/HTML SPECS/","items":[]},{"title":"Query Interfaces","url":"","items":[{"title":"GraphQL Query Specs","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/WebizenAppSpec/WebSpec/Query Interfaces/GraphQL Query Specs/","items":[]}]},{"title":"WebPlatformTools","url":"","items":[{"title":"WebAuthn","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/WebizenAppSpec/WebSpec/WebPlatformTools/WebAuthn/","items":[]},{"title":"WebDav","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/WebizenAppSpec/WebSpec/WebPlatformTools/WebDav/","items":[]}]}]}]},{"title":"Webizen Core Apps","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/","items":[{"title":"Library","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Library/","items":[{"title":"HyperMedia Library","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Library/HyperMediaLibrary/","items":[]},{"title":"Knowledge Clouds","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Library/KnowledgeClouds/","items":[]}]},{"title":"Social Web Apps","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/SocialWeb/","items":[]},{"title":"Socialweb","url":"","items":[{"title":"Agent Directory","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Socialweb/AgentDirectory/","items":[]},{"title":"Credentials & Contracts Manager","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Socialweb/Credentials & Contracts Manager/","items":[]},{"title":"The Work Platform","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Socialweb/TheWorkPlatform/","items":[]},{"title":"Webizen Social","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Socialweb/WebizenSocial/","items":[]}]},{"title":"Temporal Apps","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/TemporalApps/","items":[{"title":"Calendar","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/TemporalApps/Calendar/","items":[]},{"title":"Timeline Interface","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/TemporalApps/TimelineInterface/","items":[]}]},{"title":"Tools","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Tools/","items":[{"title":"Asset Manager","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Tools/AssetManager/","items":[]},{"title":"Cookie Monster","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Tools/CookieMonster/","items":[]},{"title":"Credential Generator","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Tools/CredentialGenerator/","items":[]},{"title":"Faceted Search","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Tools/FacetedSearch/","items":[]},{"title":"Form Builder","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Tools/FormBuilder/","items":[]},{"title":"Kanban","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Tools/Kanban/","items":[]},{"title":"Ontology Maker","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Tools/OntologyMaker/","items":[]},{"title":"Social Search","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Tools/Social-Search/","items":[]},{"title":"TimelineMaker","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Tools/TimelineMaker/","items":[]},{"title":"Weblog","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Tools/Weblog/","items":[]}]}]},{"title":"Webizen-Connect","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/Webizen-Connect/","items":[{"title":"Data Applications","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/Webizen-Connect/Data Applications/","items":[]},{"title":"Social Media APIs","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/Webizen-Connect/Social Media APIs/","items":[]},{"title":"UI Toolkits","url":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/Webizen-Connect/UIToolKits/","items":[]}]}]}]}]},{"title":"Work in Progress","url":"/WorkInProgress/","items":[]}]}],"tagsGroups":[],"latestPosts":[{"fields":{"slug":"/GuideForDevelopers/ExpressionOfInterest/","title":"Expression Of Interest","lastUpdatedAt":"2023-02-08T07:47:07.000Z","lastUpdated":"2/8/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ToolAppRequirements/","title":"ToolAppRequirements","lastUpdatedAt":"2023-02-08T07:47:07.000Z","lastUpdated":"2/8/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ToolAppRequirements/POCAppRequirements/","title":"Proof Of Concept App Reqs","lastUpdatedAt":"2023-02-08T07:47:07.000Z","lastUpdated":"2/8/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ToolAppRequirements/TrainedLanguageModel/","title":"Trained Language Model","lastUpdatedAt":"2023-02-08T07:47:07.000Z","lastUpdated":"2/8/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/WebizenTechStack/WebizenApps/Webizen3.0Apps/CoreApps/Tools/FormBuilder/","title":"Form Builder","lastUpdatedAt":"2023-02-08T07:47:07.000Z","lastUpdated":"2/8/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/SocialFactors/WebScience/nomenclature/","title":"Nomenclature","lastUpdatedAt":"2023-02-06T15:18:49.000Z","lastUpdated":"2/6/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/SocialFactors/WebScience/nomenclature/datavsquads/","title":"Data Vs. Quads","lastUpdatedAt":"2023-02-06T15:18:49.000Z","lastUpdated":"2/6/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/RWWNotesInfo/","title":"RWW Notes & Info","lastUpdatedAt":"2023-02-06T15:18:49.000Z","lastUpdated":"2/6/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/WebizenTechStack/Webizen2.5/DevNotesWebizen2.5/ImplementationNotes-2.5/WebizenID/","title":"Webizen Identity Fabric","lastUpdatedAt":"2023-02-06T15:18:49.000Z","lastUpdated":"2/6/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/GuideForDevelopers/DevPractices/","title":"Dev Practices Guide","lastUpdatedAt":"2023-02-05T06:25:02.000Z","lastUpdated":"2/5/2023"},"frontmatter":{"draft":false,"tags":[]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}