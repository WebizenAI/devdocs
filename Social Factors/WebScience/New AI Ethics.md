
It has been a continual area of annoyance, that ‘ai ethics’ folk; increasingly, involved due to the significant ‘value’ associated to contracts in the area; but seemingly, devoid of a variety of prerequisite.

Whilst multi-nationals and large institutions go about forming ‘ai ethics’ bodies of work, seemingly not cheap; whilst going on about ai implementations, for whatever cause; they’ve not done much at all to ensure that human beings have support via electronic systems, digital / web / ‘ai’ systems; even just, to seek access to justice in circumstances that may well lead to innocent & injured people, people subjected to organised violence - ending their lives, of having their lives ended in-effect or materially due to wrongs, that any good ‘ai ethics’ system - should have reasonable capacity to better understand, sooner.

This ‘mainframe’ like - money first policy framework, is a form of moral poverty that is, to me, simply detestable.  I hear from staff members of politicians offices; who suggest, nothing i’ve done has impacted ‘government policy’, whilst the fools are logging into systems that are being developed to in-part depend upon infrastructure that i was involved in creating, globally.  This isn’t about honesty, its about violence.

And they do this, not to the criminals - apparently, they’re too hard to sort out; no, they go after the good actors, who they know, they can assault without consequence because - they’re good actors, unwilling to break the law regardless of how it is these people, assault our values, as a society overall. 

So.  The implication for “Ai Ethics’, for those who actually want to talk about ‘reality check tech’, for those who actually want to build solutions that improve our capacity to sort out bad actors via courts; is, that by the production of solutions that provide ‘democratisation’ of electronic evidence, then, the ability to do real-world ‘ai ethics’ becomes possible in ways that was previously impossible, as a consequence of designs. 

Mainframes, that are built to command the requirements of rulers - not rights, human rights or other words; has nothing to do with ‘ethics’ in a world, that is said to be about building peace infrastructure.  

Systems, designed to support acts of violence with legal impunity, due to systems designs; and other political-sciences related manoeuvres, don’t cost less, aren’t about ‘ethics’ or various values statements that are said to be the guiding instruments bound to their terms of employment; they’re not provided the right to assault the human rights of children, or their loved ones as to exploit children; that’s not part of the employment contract that is legally permissible, with impunity & without insurable (or uninsurable) risk / liability.  

So the benefit, of webizen, for people who actually care about ‘ethics’ or moral equities, socio-economic systems, solutions and the means to use technology as a series of tools to support the interests of our human family; is that through means, to democratise ‘ai servers’ so that there’s a means to include, consideration for natural justice, for the needs, rights, values and considerations of importance for natural persons, in their private capacity; regardless of any other role they may hold in our societies, that there’s now a technical means to figure out how it is, we’re able to make them more meaningful than before.