This document is a continuation of the [[AgentLabelling]] note provided in the section about [[SafetyProtocols]].  Whilst the webizen systems will address these sorts of issues as part of those broader [[SafetyProtocols]], it is somewhat obvious that forming an approach to the fairly old issue, more broadly, of the importance of providing information about the agent responsible for content associated with (electronic) communiations is becoming increasingly important.  As such, this note was initially drafted as i thought about whether or not a W3C Community Group or similar might be established to consider how an ecosystems solution that is more broadly applicable, might be forged.

Yet, my concern is that doing that work would be both unpaid and take my time away from doing this work on producing the [[WebizenTechStack]] that innately seeks to address the underlying problems in anycase; therein, the difference between seeking to do good, and seeking to engage in activities that might result in positive outcomes for others; but in a way that doesn't consider the various implications otherwise considered in the production of the [[Webizen]] and [[PermissiveCommons]] ecosystem outcomes; which are only able to be brought about, if i maintain my focus on seeking to bring it about.

As such; see some notes below, which will in-turn end-up being part of what is defined in the webizen ecosystems, and perhaps if others think they're useful, may end-up being taken-on by others and/or turned into web standards at some later time.  

​I'm thinking that there should be some w3c works done on defining a method for agent labelling.  I'm not sure if that might be something that this CG could get stuck into, or whether it is an objective body of work that might be better done elsewhere (either a different W3C CG or a different venue).  

### Problem definition:

AI agents have played a role in the communication between natural persons and other natural persons and/or legal entities via electronic communications for some time.   Most people are familiar with the problems caused merely via autocorrect issues, yet the implications of software agents is becoming more pronounced.

Whilst there are many positive benefits of software agents, there are also risks. 

Some of those risks relate to whether or not an observer is able to distinguish between whom or what it is that has produced correspondence or other communications and related derivatives.

### Agent Labelling concept:

The agent labelling concept is an initiative that seeks to define a technical method to enunciate in a human & machine readable manner what type of agent is responsible for any part of a communicated message.  Messages or content may be wholly or partially generated by a software agent, interactivity with natural & legal agents. 

Software agents have different classifications and often also names.

In some mediums these semantics can be illustrated using rdf.  In other circumstances it may be labelled using metadata or even a specific font that by default enables the consumers or observers of content for whom a response is sought to be elicited may thereby be provided information about the provenance of how the information has been generated.   

In some cases multiple software agents may be involved in the creation of a document or artifact transmitted to others.

## Agent labelling considerations;  

### ​Verifiability / Tamper Evidence vs. "honour systems"​

Presently, there is no good method that is built into the technology ecosystem; that I am aware of.  In most cases involving actors whose behaviour is considered to be consistent with 'good', at the time, a solution to address this kind of issue may be something that is considered assistive and the natural person / legal entity will want to make use of it, rather than seeking to misrepresent the provenance of how the content was generated.  In these use cases there are also benefits associated with the ability to clearly denote responsibility in association to any mistakes that may have been made (without seeking to determine responsibility in relation to the effect any such instances may associate with).  This is also a common problem with AutoCorrect technologies that may only act to change a word; yet, the implication of that change may have a significant impact on the interpreted meaning of the document and/or artifact.

In other instances, the use of Software Agents may be employed far more comprehensively, and it has been shown that some agents have a capacity / propensity to 'make stuff up'[2] and this leads to one of many problems, such as the implication that these agents will at times create misinformation and disinformation. 

In circumstances where an 'honour system' is being employed; the means to easily distinguish what parts were made by which agents, is a function or feature that is sought to be employed by the user / publisher / creator / disseminator of the content / artifact.  Yet this is not always the case - either - in relation to a natural or legal agent on a common or contextual basis.   There are complex social factors that play a meaningful role in seeking to determine an appropriate solution in this area and it may well be the case that there is a large volume of work that would need to be done to mitigate risks related to any misguided and/or misappropriated attempts to pervert the ability to create a solution that is helpful, and does not unnecessarily or disproportionately exert power and/or influence over the use of these sorts of tools.  

Thereafter; the greater challenge appears to be to define methods that may support tamper-evidence of artifacts and/or strengthened informatics that provides support for determining the provenance of electronic documents and/or artifacts where the agent is seeking to intentionally deceive and/or mislead the recipient and/or observers.  These sorts of use-cases may apply to institutions of public trust as much as they may also apply to persons engaged in cybercrime.   The implications are not merely related to Ai Agents such as the now publically well known and advanced systems that are increasingly celebrated; but also, as noted earlier, AutoCorrect functions and in-turn also, even spreadsheets.  Whilst any useful solution may not simply be defined via technological standards, but rather an ecosystem approach that might employ both public and/or 'platform' policy in addition to technological tools (methods), the challenge in these latter use cases is complicated by the underlying social factors considering the circumstances whereby the user (transmitter, etc.) expressly does not want there to be a means to distinguish between the work of a software agent and that of their own making (although the two are loosely coupled). 

### Types of Software Agents;

not all software agents are the same.  Different software agents have different qualities, traits and 'relations' / implications.  Natural persons (may) employ software agents as a personal aid; via systems that are private, personal and associated with that natural person, much like a significantly enhanced electronic calculator...   In other instances, large institutions may seek to operate their businesses using advanced designs of software agents to successfully operate their business and mitigate risks via designs that make use of software agents.  one example of these sorts of situations i describe as #NoBodyAI - whereby the notion is, that designs are produced that are intended to have the effect of mitigating risks in a manner where if 'found out' it is intended that any repercussive effects are simply put down to a 'software glitch' or similar, and that no-body (person / legal entity) is responsible. #NoBodyAi.

### Societal Benefit of AI.  

There are various challenging issues that through the course of my work and related research, I have sought to figure out methods that were not immediately obvious to me, as to address those problems.  Commonly this has involved speaking with the government.  In some of these problem domains, issues are set aside and a great deal of effort (energy / resources) are applied towards the objective purpose of seeking to 'do nothing' (commonly known as 'bureaucracy', which appears to me to be a very kind interpretation when considered in relation to some areas of purposefully good pursuits).  The introduction of Large-Scale AI services brings about an opportunity for persons who would otherwise not be capable of resolving problems that may relate to matters of great importance; including but not exclusive to the human rights of persons, to be supported in seeking to form methods to address those problems.

These types of circumstances may lead to frictions, between historical and/or traditional barriers and the statements, purpose and considerations made by law and/or other legal and/or ethical/moral contracts and constructs (ie: codes of conduct that are defined and employed in a manner that is consistent with basic legal principles, as are often defined by human rights related instruments, etc.).  This is assumed to be particularly beneficial for persons whose subsistence is experienced in poverty; and that, meaningful assistance by competent professionals has simply not been materially available and/or accessible; and that, in extraordinary circumstances where that may not be the case, these resources may be easily redirected at low cost.  Therein, whilst any such circumstances of poor behaviour may not be consistent with law, if it is never able to be heard - many consider any such approach to be acceptable (ie: risk management);  now therefore, the implication becomes one whereby the introduction of advanced software agents - significantly impacts the broader circumstances.  This is also particularly the case for persons who are considered (rightly or wrongly) to require some sort of advocate and/or guardian, whose statements are said to be unreliable.   Whilst some may seek the same qualities to be built into software, as to allay any threat of exposure that may come about otherwise; these sorts of complex considerations, may also be an important part of a scope of works that considers how to define a more complex approach for agent labelling that acts to prioritize human rights above wrongs, irrespective of the inconvenience that may engender upon some who may seek to be successful via the employment of solutions that represent a different kind of structure.

[2] https://lists.w3.org/Archives/Public/public-cogai/2023Jan/0009.html