<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta data-react-helmet="true" name="twitter:image:alt" content="This repo provides information about the webizen development objectives, considerations and related experimentation!"/><meta data-react-helmet="true" name="twitter:image" content="https://devdocs.webizen.org/graph-visualisation.jpg"/><meta data-react-helmet="true" name="twitter:description" content="Awesome Computer Vision:  A curated list of awesome computer vision resources, inspired by  awesome-php . For a list people in computer vis…"/><meta data-react-helmet="true" name="twitter:title" content="Awesome Computer Vision: Awesome"/><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"/><meta data-react-helmet="true" property="article:section" content="None"/><meta data-react-helmet="true" property="article:author" content="http://examples.opengraphprotocol.us/profile.html"/><meta data-react-helmet="true" property="article:modified_time" content="2022-12-30T11:53:44.000Z"/><meta data-react-helmet="true" property="article:published_time" content="2022-12-28T20:06:17.000Z"/><meta data-react-helmet="true" property="og:description" content="Awesome Computer Vision:  A curated list of awesome computer vision resources, inspired by  awesome-php . For a list people in computer vis…"/><meta data-react-helmet="true" property="og:site_name"/><meta data-react-helmet="true" property="og:image:alt" content="This repo provides information about the webizen development objectives, considerations and related experimentation!"/><meta data-react-helmet="true" property="og:image" content="https://devdocs.webizen.org/graph-visualisation.jpg"/><meta data-react-helmet="true" property="og:url" content="https://devdocs.webizen.org/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-computer-vision/"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:title" content="Awesome Computer Vision: Awesome"/><meta data-react-helmet="true" name="image" content="https://devdocs.webizen.org/graph-visualisation.jpg"/><meta data-react-helmet="true" name="description" content="Awesome Computer Vision:  A curated list of awesome computer vision resources, inspired by  awesome-php . For a list people in computer vis…"/><meta name="generator" content="Gatsby 4.6.0"/><style data-href="/styles.d9e480e5c6375621c4fd.css" data-identity="gatsby-global-css">.tippy-box[data-animation=fade][data-state=hidden]{opacity:0}[data-tippy-root]{max-width:calc(100vw - 10px)}.tippy-box{background-color:#333;border-radius:4px;color:#fff;font-size:14px;line-height:1.4;outline:0;position:relative;transition-property:visibility,opacity,-webkit-transform;transition-property:transform,visibility,opacity;transition-property:transform,visibility,opacity,-webkit-transform;white-space:normal}.tippy-box[data-placement^=top]>.tippy-arrow{bottom:0}.tippy-box[data-placement^=top]>.tippy-arrow:before{border-top-color:initial;border-width:8px 8px 0;bottom:-7px;left:0;-webkit-transform-origin:center top;transform-origin:center top}.tippy-box[data-placement^=bottom]>.tippy-arrow{top:0}.tippy-box[data-placement^=bottom]>.tippy-arrow:before{border-bottom-color:initial;border-width:0 8px 8px;left:0;top:-7px;-webkit-transform-origin:center bottom;transform-origin:center bottom}.tippy-box[data-placement^=left]>.tippy-arrow{right:0}.tippy-box[data-placement^=left]>.tippy-arrow:before{border-left-color:initial;border-width:8px 0 8px 8px;right:-7px;-webkit-transform-origin:center left;transform-origin:center left}.tippy-box[data-placement^=right]>.tippy-arrow{left:0}.tippy-box[data-placement^=right]>.tippy-arrow:before{border-right-color:initial;border-width:8px 8px 8px 0;left:-7px;-webkit-transform-origin:center right;transform-origin:center right}.tippy-box[data-inertia][data-state=visible]{transition-timing-function:cubic-bezier(.54,1.5,.38,1.11)}.tippy-arrow{color:#333;height:16px;width:16px}.tippy-arrow:before{border-color:transparent;border-style:solid;content:"";position:absolute}.tippy-content{padding:5px 9px;position:relative;z-index:1}.tippy-box[data-theme~=light]{background-color:#fff;box-shadow:0 0 20px 4px rgba(154,161,177,.15),0 4px 80px -8px rgba(36,40,47,.25),0 4px 4px -2px rgba(91,94,105,.15);color:#26323d}.tippy-box[data-theme~=light][data-placement^=top]>.tippy-arrow:before{border-top-color:#fff}.tippy-box[data-theme~=light][data-placement^=bottom]>.tippy-arrow:before{border-bottom-color:#fff}.tippy-box[data-theme~=light][data-placement^=left]>.tippy-arrow:before{border-left-color:#fff}.tippy-box[data-theme~=light][data-placement^=right]>.tippy-arrow:before{border-right-color:#fff}.tippy-box[data-theme~=light]>.tippy-backdrop{background-color:#fff}.tippy-box[data-theme~=light]>.tippy-svg-arrow{fill:#fff}html{font-family:SF Pro SC,SF Pro Text,SF Pro Icons,PingFang SC,Helvetica Neue,Helvetica,Arial,sans-serif}body{word-wrap:break-word;-ms-hyphens:auto;-webkit-hyphens:auto;hyphens:auto;overflow-wrap:break-word;-ms-word-break:break-all;word-break:break-word}blockquote,body,dd,dt,fieldset,figure,h1,h2,h3,h4,h5,h6,hr,html,iframe,legend,p,pre,textarea{margin:0;padding:0}h1,h2,h3,h4,h5,h6{font-size:100%;font-weight:400}button,input,select{margin:0}html{box-sizing:border-box}*,:after,:before{box-sizing:inherit}img,video{height:auto;max-width:100%}iframe{border:0}table{border-collapse:collapse;border-spacing:0}td,th{padding:0}</style><style data-styled="" data-styled-version="5.3.5">.fnAJEh{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;font-size:14px;background-color:#005cc5;color:#ffffff;padding:16px;}/*!sc*/
.fnAJEh:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.fnAJEh:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.czsBQU{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;color:#ffffff;margin-right:16px;}/*!sc*/
.czsBQU:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.czsBQU:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.kLOWMo{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;font-family:SFMono-Regular,Consolas,"Liberation Mono",Menlo,Courier,monospace;color:#ffffff;}/*!sc*/
.kLOWMo:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.kLOWMo:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.kEUvCO{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;display:block;color:inherit;margin-left:24px;}/*!sc*/
.kEUvCO:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.kEUvCO:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.fdzjHV{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;color:#24292e;display:block;}/*!sc*/
.fdzjHV:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.fdzjHV:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.HGjBQ{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;display:block;}/*!sc*/
.HGjBQ:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.HGjBQ:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.bQLMRL{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;font-size:16px;display:inline-block;padding-top:4px;padding-bottom:4px;color:#586069;font-weight:medium;}/*!sc*/
.bQLMRL:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.bQLMRL:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){.bQLMRL{font-size:14px;}}/*!sc*/
.ekSqTm{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;padding:8px;margin-left:-32px;color:#2f363d;}/*!sc*/
.ekSqTm:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.ekSqTm:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.cKRjba{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
.cKRjba:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.cKRjba:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.iLYDsn{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;margin-bottom:4px;}/*!sc*/
.iLYDsn:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.iLYDsn:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
data-styled.g1[id="Link-sc-1brdqhf-0"]{content:"fnAJEh,czsBQU,kLOWMo,kEUvCO,fdzjHV,HGjBQ,bQLMRL,ekSqTm,cKRjba,iLYDsn,"}/*!sc*/
.EuMgV{z-index:20;width:auto;height:auto;-webkit-clip:auto;clip:auto;position:absolute;overflow:hidden;}/*!sc*/
.EuMgV:not(:focus){-webkit-clip:rect(1px,1px,1px,1px);clip:rect(1px,1px,1px,1px);-webkit-clip-path:inset(50%);clip-path:inset(50%);height:1px;width:1px;margin:-1px;padding:0;}/*!sc*/
data-styled.g2[id="skip-link__SkipLink-sc-1z0kjxc-0"]{content:"EuMgV,"}/*!sc*/
.fbaWCe{display:none;margin-left:8px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.fbaWCe{display:inline;}}/*!sc*/
.bLwTGz{font-weight:600;display:inline-block;margin-bottom:4px;}/*!sc*/
.cQAYyE{font-weight:600;}/*!sc*/
.gHwtLv{font-size:14px;color:#444d56;margin-top:4px;}/*!sc*/
data-styled.g4[id="Text-sc-1s3uzov-0"]{content:"fbaWCe,bLwTGz,cQAYyE,gHwtLv,"}/*!sc*/
.ifkhtm{background-color:#ffffff;color:#24292e;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;min-height:100vh;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}/*!sc*/
.gSrgIV{top:0;z-index:1;position:-webkit-sticky;position:sticky;}/*!sc*/
.iTlzRc{padding-left:16px;padding-right:16px;background-color:#24292e;color:rgba(255,255,255,0.7);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:66px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.iTlzRc{padding-left:24px;padding-right:24px;}}/*!sc*/
.kCrfOd{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.gELiHA{margin-left:24px;display:none;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.gELiHA{display:block;}}/*!sc*/
.gYHnkh{position:relative;}/*!sc*/
.dMFMzl{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/
.jhCmHN{display:none;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.jhCmHN{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}/*!sc*/
.elXfHl{color:rgba(255,255,255,0.7);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.gjFLbZ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.gjFLbZ{display:none;}}/*!sc*/
.gucKKf{color:rgba(255,255,255,0.7);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:0;background-color:none;cursor:pointer;}/*!sc*/
.gucKKf:hover{fill:rgba(255,255,255,0.7);color:rgba(255,255,255,0.7);}/*!sc*/
.gucKKf svg{fill:rgba(255,255,255,0.7);}/*!sc*/
.fBMuRw{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;}/*!sc*/
.bQaVuO{color:#2f363d;background-color:#fafbfc;display:none;height:calc(100vh - 66px);min-width:260px;max-width:360px;position:-webkit-sticky;position:sticky;top:66px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.bQaVuO{display:block;}}/*!sc*/
.eeDmz{height:100%;border-style:solid;border-color:#e1e4e8;border-width:0;border-right-width:1px;border-radius:0;}/*!sc*/
.kSoTbZ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}/*!sc*/
.nElVQ{padding:24px;border-style:solid;border-color:#e1e4e8;border-width:0;border-radius:0;border-top-width:1px;}/*!sc*/
.iXtyim{margin-left:0;padding-top:4px;padding-bottom:4px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;border-style:solid;border-color:#e1e4e8;border-width:0;border-radius:0;border-bottom-width:0;}/*!sc*/
.vaHQm{margin-bottom:4px;margin-top:4px;font-size:14px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
.hIjKHD{color:#586069;font-weight:400;display:block;}/*!sc*/
.icYakO{padding-left:8px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;}/*!sc*/
.jLseWZ{margin-left:16px;padding-top:0;padding-bottom:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;border-style:solid;border-color:#e1e4e8;border-width:0;border-radius:0;border-bottom-width:0;}/*!sc*/
.kRSqJi{margin-bottom:0;margin-top:8px;font-size:14px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
.klfmeZ{max-width:1440px;-webkit-flex:1;-ms-flex:1;flex:1;}/*!sc*/
.TZbDV{padding:24px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;width:100%;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-flex-direction:row-reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse;}/*!sc*/
@media screen and (min-width:544px){.TZbDV{padding:32px;}}/*!sc*/
@media screen and (min-width:768px){.TZbDV{padding:40px;}}/*!sc*/
@media screen and (min-width:1012px){.TZbDV{padding:48px;}}/*!sc*/
.DPDMP{display:none;max-height:calc(100vh - 66px - 24px);position:-webkit-sticky;position:sticky;top:90px;width:220px;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;margin-left:40px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){.DPDMP{display:block;}}/*!sc*/
.gUNLMu{margin:0;padding:0;}/*!sc*/
.bzTeHX{padding-left:0;}/*!sc*/
.bnaGYs{padding-left:16px;}/*!sc*/
.meQBK{width:100%;}/*!sc*/
.jYYExC{margin-bottom:32px;background-color:#f6f8fa;display:block;border-width:1px;border-style:solid;border-color:#e1e4e8;border-radius:6px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){.jYYExC{display:none;}}/*!sc*/
.hgiZBa{padding:16px;}/*!sc*/
.hnQOQh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.gEqaxf{padding:16px;border-top:1px solid;border-color:border.gray;}/*!sc*/
.ksEcN{margin-top:64px;padding-top:32px;padding-bottom:32px;border-style:solid;border-color:#e1e4e8;border-width:0;border-top-width:1px;border-radius:0;}/*!sc*/
.jsSpbO{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
data-styled.g5[id="Box-nv15kw-0"]{content:"ifkhtm,gSrgIV,iTlzRc,kCrfOd,gELiHA,gYHnkh,dMFMzl,jhCmHN,elXfHl,gjFLbZ,gucKKf,fBMuRw,bQaVuO,eeDmz,kSoTbZ,nElVQ,iXtyim,vaHQm,hIjKHD,icYakO,jLseWZ,kRSqJi,klfmeZ,TZbDV,DPDMP,gUNLMu,bzTeHX,bnaGYs,meQBK,jYYExC,hgiZBa,hnQOQh,gEqaxf,ksEcN,jsSpbO,"}/*!sc*/
.cjGjQg{position:relative;display:inline-block;padding:6px 16px;font-family:inherit;font-weight:600;line-height:20px;white-space:nowrap;vertical-align:middle;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;border-radius:6px;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;font-size:14px;}/*!sc*/
.cjGjQg:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
.cjGjQg:focus{outline:none;}/*!sc*/
.cjGjQg:disabled{cursor:default;}/*!sc*/
.cjGjQg:disabled svg{opacity:0.6;}/*!sc*/
data-styled.g6[id="ButtonBase-sc-181ps9o-0"]{content:"cjGjQg,"}/*!sc*/
.fafffn{margin-right:8px;}/*!sc*/
data-styled.g8[id="StyledOcticon-uhnt7w-0"]{content:"bhRGQB,fafffn,"}/*!sc*/
.fTkTnC{font-weight:600;font-size:32px;margin:0;font-size:12px;font-weight:500;color:#959da5;margin-bottom:4px;text-transform:uppercase;font-family:Content-font,Roboto,sans-serif;}/*!sc*/
.ffNRvO{font-weight:600;font-size:32px;margin:0;}/*!sc*/
data-styled.g12[id="Heading-sc-1cjoo9h-0"]{content:"fTkTnC,ffNRvO,"}/*!sc*/
.ifFLoZ{color:#0366d6;border:1px solid rgba(27,31,35,0.15);background-color:#fafbfc;box-shadow:0 1px 0 rgba(27,31,35,0.04);margin-left:16px;}/*!sc*/
.ifFLoZ:hover{color:#ffffff;background-color:#0366d6;border-color:rgba(27,31,35,0.15);box-shadow:0 1px 0 rgba(27,31,35,0.1);}/*!sc*/
.ifFLoZ:focus{border-color:rgba(27,31,35,0.15);box-shadow:0 0 0 3px rgba(0,92,197,0.4);}/*!sc*/
.ifFLoZ:active{color:#ffffff;background-color:hsla(212,97%,40%,1);box-shadow:inset 0 1px 0 rgba(5,38,76,0.2);border-color:rgba(27,31,35,0.15);}/*!sc*/
.ifFLoZ:disabled{color:rgba(3,102,214,0.5);background-color:#fafbfc;border-color:rgba(27,31,35,0.15);}/*!sc*/
.fKTxJr{color:#0366d6;border:1px solid rgba(27,31,35,0.15);background-color:#fafbfc;box-shadow:0 1px 0 rgba(27,31,35,0.04);}/*!sc*/
.fKTxJr:hover{color:#ffffff;background-color:#0366d6;border-color:rgba(27,31,35,0.15);box-shadow:0 1px 0 rgba(27,31,35,0.1);}/*!sc*/
.fKTxJr:focus{border-color:rgba(27,31,35,0.15);box-shadow:0 0 0 3px rgba(0,92,197,0.4);}/*!sc*/
.fKTxJr:active{color:#ffffff;background-color:hsla(212,97%,40%,1);box-shadow:inset 0 1px 0 rgba(5,38,76,0.2);border-color:rgba(27,31,35,0.15);}/*!sc*/
.fKTxJr:disabled{color:rgba(3,102,214,0.5);background-color:#fafbfc;border-color:rgba(27,31,35,0.15);}/*!sc*/
.cXFtEt{color:#0366d6;border:1px solid rgba(27,31,35,0.15);background-color:#fafbfc;box-shadow:0 1px 0 rgba(27,31,35,0.04);margin-left:16px;}/*!sc*/
.cXFtEt:hover{color:#ffffff;background-color:#0366d6;border-color:rgba(27,31,35,0.15);box-shadow:0 1px 0 rgba(27,31,35,0.1);}/*!sc*/
.cXFtEt:focus{border-color:rgba(27,31,35,0.15);box-shadow:0 0 0 3px rgba(0,92,197,0.4);}/*!sc*/
.cXFtEt:active{color:#ffffff;background-color:hsla(212,97%,40%,1);box-shadow:inset 0 1px 0 rgba(5,38,76,0.2);border-color:rgba(27,31,35,0.15);}/*!sc*/
.cXFtEt:disabled{color:rgba(3,102,214,0.5);background-color:#fafbfc;border-color:rgba(27,31,35,0.15);}/*!sc*/
data-styled.g13[id="ButtonOutline-sc-15gta9l-0"]{content:"ifFLoZ,fKTxJr,cXFtEt,"}/*!sc*/
.iEGqHu{color:rgba(255,255,255,0.7);background-color:transparent;border:1px solid #444d56;box-shadow:none;}/*!sc*/
data-styled.g14[id="dark-button__DarkButton-sc-bvvmfe-0"]{content:"iEGqHu,"}/*!sc*/
.ljCWQd{border:0;font-size:inherit;font-family:inherit;background-color:transparent;-webkit-appearance:none;color:inherit;width:100%;}/*!sc*/
.ljCWQd:focus{outline:0;}/*!sc*/
data-styled.g15[id="TextInput__Input-sc-1apmpmt-0"]{content:"ljCWQd,"}/*!sc*/
.dHfzvf{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;min-height:34px;font-size:14px;line-height:20px;color:#24292e;vertical-align:middle;background-repeat:no-repeat;background-position:right 8px center;border:1px solid #e1e4e8;border-radius:6px;outline:none;box-shadow:inset 0 1px 0 rgba(225,228,232,0.2);padding:6px 12px;width:240px;}/*!sc*/
.dHfzvf .TextInput-icon{-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;color:#959da5;margin:0 8px;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;}/*!sc*/
.dHfzvf:focus-within{border-color:#0366d6;box-shadow:0 0 0 3px rgba(3,102,214,0.3);}/*!sc*/
@media (min-width:768px){.dHfzvf{font-size:14px;}}/*!sc*/
data-styled.g16[id="TextInput__Wrapper-sc-1apmpmt-1"]{content:"dHfzvf,"}/*!sc*/
.khRwtY{font-size:16px !important;color:rgba(255,255,255,0.7);background-color:rgba(255,255,255,0.07);border:1px solid transparent;box-shadow:none;}/*!sc*/
.khRwtY:focus{border:1px solid #444d56 outline:none;box-shadow:none;}/*!sc*/
data-styled.g17[id="dark-text-input__DarkTextInput-sc-1s2iwzn-0"]{content:"khRwtY,"}/*!sc*/
.bqVpte.active{font-weight:600;color:#2f363d;}/*!sc*/
data-styled.g19[id="nav-items__NavLink-sc-tqz5wl-0"]{content:"bqVpte,"}/*!sc*/
.kEKZhO.active{font-weight:600;color:#2f363d;}/*!sc*/
data-styled.g20[id="nav-items__NavBox-sc-tqz5wl-1"]{content:"kEKZhO,"}/*!sc*/
.gCPbFb{margin-top:24px;margin-bottom:16px;-webkit-scroll-margin-top:90px;-moz-scroll-margin-top:90px;-ms-scroll-margin-top:90px;scroll-margin-top:90px;}/*!sc*/
.gCPbFb .octicon-link{visibility:hidden;}/*!sc*/
.gCPbFb:hover .octicon-link,.gCPbFb:focus-within .octicon-link{visibility:visible;}/*!sc*/
data-styled.g22[id="heading__StyledHeading-sc-1fu06k9-0"]{content:"gCPbFb,"}/*!sc*/
.fGjcEF{margin-top:0;padding-bottom:4px;font-size:32px;border-bottom:1px solid #e1e4e8;}/*!sc*/
data-styled.g23[id="heading__StyledH1-sc-1fu06k9-1"]{content:"fGjcEF,"}/*!sc*/
.fvbkiW{padding-bottom:4px;font-size:24px;border-bottom:1px solid #e1e4e8;}/*!sc*/
data-styled.g24[id="heading__StyledH2-sc-1fu06k9-2"]{content:"fvbkiW,"}/*!sc*/
.vaKyq{font-size:16px;}/*!sc*/
data-styled.g26[id="heading__StyledH4-sc-1fu06k9-4"]{content:"vaKyq,"}/*!sc*/
.gEWVYQ{font-size:14px;color:#6a737d;}/*!sc*/
data-styled.g28[id="heading__StyledH6-sc-1fu06k9-6"]{content:"gEWVYQ,"}/*!sc*/
.elBfYx{max-width:100%;box-sizing:content-box;background-color:#ffffff;}/*!sc*/
data-styled.g30[id="image__Image-sc-1r30dtv-0"]{content:"elBfYx,"}/*!sc*/
.dFVIUa{padding-left:2em;margin-bottom:4px;}/*!sc*/
.dFVIUa ul,.dFVIUa ol{margin-top:0;margin-bottom:0;}/*!sc*/
.dFVIUa li{line-height:1.6;}/*!sc*/
.dFVIUa li > p{margin-top:16px;}/*!sc*/
.dFVIUa li + li{margin-top:8px;}/*!sc*/
data-styled.g32[id="list__List-sc-s5kxp2-0"]{content:"dFVIUa,"}/*!sc*/
.iNQqSl{margin:0 0 16px;}/*!sc*/
data-styled.g34[id="paragraph__Paragraph-sc-17pab92-0"]{content:"iNQqSl,"}/*!sc*/
.drDDht{z-index:0;}/*!sc*/
data-styled.g37[id="layout___StyledBox-sc-7a5ttt-0"]{content:"drDDht,"}/*!sc*/
.flyUPp{list-style:none;}/*!sc*/
data-styled.g39[id="table-of-contents___StyledBox-sc-1jtv948-0"]{content:"flyUPp,"}/*!sc*/
.bPkrfP{grid-area:table-of-contents;overflow:auto;}/*!sc*/
data-styled.g40[id="post-page___StyledBox-sc-17hbw1s-0"]{content:"bPkrfP,"}/*!sc*/
</style><title data-react-helmet="true">Awesome Computer Vision: Awesome - Webizen Development Related Documentation.</title><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper picture.object-fit-polyfill{position:static!important}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){if(void 0===e.target.dataset.mainImage)return;if(void 0===e.target.dataset.gatsbyImageSsr)return;const t=e.target;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="icon" href="/favicon-32x32.png?v=202c3b6fa23c481f8badd00dc2119591" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="sitemap" type="application/xml" href="/sitemap/sitemap-index.xml"/><link rel="preconnect" href="https://www.googletagmanager.com"/><link rel="dns-prefetch" href="https://www.googletagmanager.com"/><link as="script" rel="preload" href="/webpack-runtime-1fe3daf7582b39746d36.js"/><link as="script" rel="preload" href="/framework-6c63f85700e5678d2c2a.js"/><link as="script" rel="preload" href="/f0e45107-3309acb69b4ccd30ce0c.js"/><link as="script" rel="preload" href="/0e226fb0-1cb0709e5ed968a9c435.js"/><link as="script" rel="preload" href="/dc6a8720040df98778fe970bf6c000a41750d3ae-8fdfd959b24cacbf7cee.js"/><link as="script" rel="preload" href="/app-f28009dab402ccf9360c.js"/><link as="script" rel="preload" href="/commons-c89ede6cb9a530ac5a37.js"/><link as="script" rel="preload" href="/component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js-46274f1a3983fff8a36b.js"/><link as="fetch" rel="preload" href="/page-data/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-computer-vision/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/2230547434.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/2320115945.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/3495835395.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/451533639.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><a class="Link-sc-1brdqhf-0 fnAJEh skip-link__SkipLink-sc-1z0kjxc-0 EuMgV" color="auto.white" href="#skip-nav" font-size="1">Skip to content</a><div display="flex" color="text.primary" class="Box-nv15kw-0 ifkhtm"><div class="Box-nv15kw-0 gSrgIV"><div display="flex" height="66" color="header.text" class="Box-nv15kw-0 iTlzRc"><div display="flex" class="Box-nv15kw-0 kCrfOd"><a color="header.logo" mr="3" class="Link-sc-1brdqhf-0 czsBQU" href="/"><svg aria-hidden="true" role="img" class="StyledOcticon-uhnt7w-0 bhRGQB" viewBox="0 0 16 16" width="32" height="32" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path></svg></a><a color="header.logo" font-family="mono" class="Link-sc-1brdqhf-0 kLOWMo" href="/">Wiki</a><div display="none,,,block" class="Box-nv15kw-0 gELiHA"><div role="combobox" aria-expanded="false" aria-haspopup="listbox" aria-labelledby="downshift-search-label" class="Box-nv15kw-0 gYHnkh"><span class="TextInput__Wrapper-sc-1apmpmt-1 dHfzvf dark-text-input__DarkTextInput-sc-1s2iwzn-0 khRwtY TextInput-wrapper" width="240"><input type="text" aria-autocomplete="list" aria-labelledby="downshift-search-label" autoComplete="off" value="" id="downshift-search-input" placeholder="Search Wiki" class="TextInput__Input-sc-1apmpmt-0 ljCWQd"/></span></div></div></div><div display="flex" class="Box-nv15kw-0 dMFMzl"><div display="none,,,flex" class="Box-nv15kw-0 jhCmHN"><div display="flex" color="header.text" class="Box-nv15kw-0 elXfHl"><a display="block" color="inherit" target="_blank" rel="noopener noreferrer" href="https://github.com/webizenai/devdocs/" class="Link-sc-1brdqhf-0 kEUvCO">Github</a><a display="block" color="inherit" target="_blank" rel="noopener noreferrer" href="https://twitter.com/webcivics" class="Link-sc-1brdqhf-0 kEUvCO">Twitter</a></div><button aria-label="Theme" aria-expanded="false" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 cjGjQg ifFLoZ iEGqHu"><svg aria-hidden="true" role="img" class="octicon octicon-sun" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z"></path></svg></button></div><div display="flex,,,none" class="Box-nv15kw-0 gjFLbZ"><button aria-label="Search" aria-expanded="false" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 cjGjQg fKTxJr iEGqHu"><svg aria-hidden="true" role="img" class="octicon octicon-search" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M11.5 7a4.499 4.499 0 11-8.998 0A4.499 4.499 0 0111.5 7zm-.82 4.74a6 6 0 111.06-1.06l3.04 3.04a.75.75 0 11-1.06 1.06l-3.04-3.04z"></path></svg></button></div><button aria-label="Show Graph Visualisation" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 cjGjQg cXFtEt iEGqHu"><div title="Show Graph Visualisation" aria-label="Show Graph Visualisation" color="header.text" display="flex" class="Box-nv15kw-0 gucKKf"><svg t="1607341341241" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" width="20" height="20"><path d="M512 512m-125.866667 0a125.866667 125.866667 0 1 0 251.733334 0 125.866667 125.866667 0 1 0-251.733334 0Z"></path><path d="M512 251.733333m-72.533333 0a72.533333 72.533333 0 1 0 145.066666 0 72.533333 72.533333 0 1 0-145.066666 0Z"></path><path d="M614.4 238.933333c0 4.266667 2.133333 8.533333 2.133333 12.8 0 19.2-4.266667 36.266667-12.8 51.2 81.066667 36.266667 138.666667 117.333333 138.666667 211.2C742.4 640 640 744.533333 512 744.533333s-230.4-106.666667-230.4-232.533333c0-93.866667 57.6-174.933333 138.666667-211.2-8.533333-14.933333-12.8-32-12.8-51.2 0-4.266667 0-8.533333 2.133333-12.8-110.933333 42.666667-189.866667 147.2-189.866667 273.066667 0 160 130.133333 292.266667 292.266667 292.266666S804.266667 672 804.266667 512c0-123.733333-78.933333-230.4-189.866667-273.066667z"></path><path d="M168.533333 785.066667m-72.533333 0a72.533333 72.533333 0 1 0 145.066667 0 72.533333 72.533333 0 1 0-145.066667 0Z"></path><path d="M896 712.533333m-61.866667 0a61.866667 61.866667 0 1 0 123.733334 0 61.866667 61.866667 0 1 0-123.733334 0Z"></path><path d="M825.6 772.266667c-74.666667 89.6-187.733333 147.2-313.6 147.2-93.866667 0-181.333333-32-249.6-87.466667-10.666667 19.2-25.6 34.133333-44.8 44.8C298.666667 942.933333 401.066667 981.333333 512 981.333333c149.333333 0 281.6-70.4 366.933333-177.066666-21.333333-4.266667-40.533333-17.066667-53.333333-32zM142.933333 684.8c-25.6-53.333333-38.4-110.933333-38.4-172.8C104.533333 288 288 104.533333 512 104.533333S919.466667 288 919.466667 512c0 36.266667-6.4 72.533333-14.933334 106.666667 23.466667 2.133333 42.666667 10.666667 57.6 25.6 12.8-42.666667 19.2-87.466667 19.2-132.266667 0-258.133333-211.2-469.333333-469.333333-469.333333S42.666667 253.866667 42.666667 512c0 74.666667 17.066667 142.933333 46.933333 204.8 14.933333-14.933333 32-27.733333 53.333333-32z"></path></svg><span display="none,,,inline" class="Text-sc-1s3uzov-0 fbaWCe">Show Graph Visualisation</span></div></button><div display="flex,,,none" class="Box-nv15kw-0 gjFLbZ"><button aria-label="Menu" aria-expanded="false" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 cjGjQg ifFLoZ iEGqHu"><svg aria-hidden="true" role="img" class="octicon octicon-three-bars" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M1 2.75A.75.75 0 011.75 2h12.5a.75.75 0 110 1.5H1.75A.75.75 0 011 2.75zm0 5A.75.75 0 011.75 7h12.5a.75.75 0 110 1.5H1.75A.75.75 0 011 7.75zM1.75 12a.75.75 0 100 1.5h12.5a.75.75 0 100-1.5H1.75z"></path></svg></button></div></div></div></div><div display="flex" class="Box-nv15kw-0 layout___StyledBox-sc-7a5ttt-0 fBMuRw drDDht"><div display="none,,,block" height="calc(100vh - 66px)" color="auto.gray.8" class="Box-nv15kw-0 bQaVuO"><div height="100%" style="overflow:auto" class="Box-nv15kw-0 eeDmz"><div display="flex" class="Box-nv15kw-0 kSoTbZ"><div class="Box-nv15kw-0 nElVQ"><div display="flex" class="Box-nv15kw-0 kSoTbZ"><h2 color="text.disabled" font-size="12px" font-weight="500" class="Heading-sc-1cjoo9h-0 fTkTnC">Categories</h2><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Commercial</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Core Services</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Core Technologies</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Database Requirements</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Host Service Requirements</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 fdzjHV bqVpte" display="block" sx="[object Object]" href="/HyperMedia Library/">HyperMedia Library</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">ICT Stack</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Implementation V1</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Non-HTTP(s) Protocols</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Old-Work-Archives</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">2018-Webizen-Net-Au</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">_Link_library_links</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">_Posts</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/about/">about</a><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/the-human-centric-infosphere/">An Overview</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/">Resource Library</a><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">awesomeLists</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a aria-current="page" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte active" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-computer-vision/">Awesome Computer Vision: Awesome</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awsome-nl-gen/">Awesome Natural Language Generation Awesome</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-semweb/">Awesome Semantic Web Awesome</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-general/">Awesome-General</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/">Handong1587</a><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018 - Web Civics BizPlan/">EXECUTIVE SUMMARY</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Webizen 2.0</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 fdzjHV bqVpte" display="block" sx="[object Object]" href="/">Webizen V1 Project Documentation</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div></div></div></div></div></div><main class="Box-nv15kw-0 klfmeZ"><div id="skip-nav" display="flex" width="100%" class="Box-nv15kw-0 TZbDV"><div display="none,,block" class="Box-nv15kw-0 post-page___StyledBox-sc-17hbw1s-0 DPDMP bPkrfP"><span display="inline-block" font-weight="bold" class="Text-sc-1s3uzov-0 bLwTGz">On this page</span><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#awesome-computer-vision-awesome" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Awesome Computer Vision: Awesome</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#contributing" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Contributing</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#table-of-contents" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Table of Contents</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#awesome-lists" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Awesome Lists</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#books" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Books</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#courses" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Courses</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#papers" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Papers</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#tutorials-and-talks" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Tutorials and talks</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#software" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Software</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#datasets" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Datasets</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#sun-rgb-d---a-rgb-d-scene-understanding-benchmark-suite" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">SUN RGB-D - A RGB-D Scene Understanding Benchmark Suite</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#nyu-depth-v2---indoor-segmentation-and-support-inference-from-rgbd-images" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">NYU depth v2 - Indoor Segmentation and Support Inference from RGBD Images</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#aerial-image-segmentation---learning-aerial-image-segmentation-from-online-maps" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Aerial Image Segmentation - Learning Aerial Image Segmentation From Online Maps</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#resources-for-students" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Resources for students</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#blogs" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Blogs</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#links" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Links</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#songs" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Songs</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#licenses" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Licenses</a></li></ul></li></ul></div><div width="100%" class="Box-nv15kw-0 meQBK"><div display="block,,none" class="Box-nv15kw-0 jYYExC"><div class="Box-nv15kw-0 hgiZBa"><div display="flex" class="Box-nv15kw-0 hnQOQh"><span font-weight="bold" class="Text-sc-1s3uzov-0 cQAYyE">On this page</span></div></div><div class="Box-nv15kw-0 gEqaxf"><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#awesome-computer-vision-awesome" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Awesome Computer Vision: Awesome</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#contributing" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Contributing</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#table-of-contents" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Table of Contents</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#awesome-lists" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Awesome Lists</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#books" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Books</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#courses" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Courses</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#papers" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Papers</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#tutorials-and-talks" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Tutorials and talks</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#software" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Software</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#datasets" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Datasets</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#sun-rgb-d---a-rgb-d-scene-understanding-benchmark-suite" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">SUN RGB-D - A RGB-D Scene Understanding Benchmark Suite</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#nyu-depth-v2---indoor-segmentation-and-support-inference-from-rgbd-images" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">NYU depth v2 - Indoor Segmentation and Support Inference from RGBD Images</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#aerial-image-segmentation---learning-aerial-image-segmentation-from-online-maps" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Aerial Image Segmentation - Learning Aerial Image Segmentation From Online Maps</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#resources-for-students" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Resources for students</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#blogs" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Blogs</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#links" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Links</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#songs" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Songs</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#licenses" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Licenses</a></li></ul></li></ul></div></div><h1 id="awesome-computer-vision-awesome" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#awesome-computer-vision-" color="auto.gray.8" aria-label="Awesome Computer Vision:  permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Awesome Computer Vision: <a target="_blank" rel="noopener noreferrer" href="https://github.com/sindresorhus/awesome" class="Link-sc-1brdqhf-0 cKRjba"><img src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg" alt="Awesome" class="image__Image-sc-1r30dtv-0 elBfYx"/></a></h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl">A curated list of awesome computer vision resources, inspired by <a target="_blank" rel="noopener noreferrer" href="https://github.com/ziadoz/awesome-php" class="Link-sc-1brdqhf-0 cKRjba">awesome-php</a>.</p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl">For a list people in computer vision listed with their academic genealogy, please visit <a target="_blank" rel="noopener noreferrer" href="https://github.com/jbhuang0604/awesome-computer-vision/blob/master/people.md" class="Link-sc-1brdqhf-0 cKRjba">here</a></p><h2 id="contributing" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#contributing" color="auto.gray.8" aria-label="Contributing permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Contributing</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl">Please feel free to send me <a target="_blank" rel="noopener noreferrer" href="https://github.com/jbhuang0604/awesome-computer-vision/pulls" class="Link-sc-1brdqhf-0 cKRjba">pull requests</a> or email (<a target="_blank" rel="noopener noreferrer" href="mailto:jbhuang@vt.edu" class="Link-sc-1brdqhf-0 cKRjba">jbhuang@vt.edu</a>) to add links.</p><h2 id="table-of-contents" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#table-of-contents" color="auto.gray.8" aria-label="Table of Contents permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Table of Contents</h2><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a class="Link-sc-1brdqhf-0 cKRjba" href="/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/#awesome-lists/">Awesome Lists</a></li><li><a class="Link-sc-1brdqhf-0 cKRjba" href="/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/#books/">Books</a></li><li><a class="Link-sc-1brdqhf-0 cKRjba" href="/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/#courses/">Courses</a></li><li><a class="Link-sc-1brdqhf-0 cKRjba" href="/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/#papers/">Papers</a></li><li><a class="Link-sc-1brdqhf-0 cKRjba" href="/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/#software/">Software</a></li><li><a class="Link-sc-1brdqhf-0 cKRjba" href="/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/#datasets/">Datasets</a></li><li><a class="Link-sc-1brdqhf-0 cKRjba" href="/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/#Pre-trained-Computer-Vision-Models/">Pre-trained Computer Vision Models</a></li><li><a class="Link-sc-1brdqhf-0 cKRjba" href="/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/#tutorials-and-talks/">Tutorials and Talks</a></li><li><a class="Link-sc-1brdqhf-0 cKRjba" href="/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/#resources-for-students/">Resources for students</a></li><li><a class="Link-sc-1brdqhf-0 cKRjba" href="/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/#blogs/">Blogs</a></li><li><a class="Link-sc-1brdqhf-0 cKRjba" href="/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/#links/">Links</a></li><li><a class="Link-sc-1brdqhf-0 cKRjba" href="/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/#songs/">Songs</a></li></ul><h2 id="awesome-lists" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#awesome-lists" color="auto.gray.8" aria-label="Awesome Lists permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Awesome Lists</h2><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/josephmisiti/awesome-machine-learning" class="Link-sc-1brdqhf-0 cKRjba">Awesome Machine Learning</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/kjw0612/awesome-deep-vision" class="Link-sc-1brdqhf-0 cKRjba">Awesome Deep Vision</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/zhaoxin94/awesome-domain-adaptation" class="Link-sc-1brdqhf-0 cKRjba">Awesome Domain Adaptation</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/amusi/awesome-object-detection" class="Link-sc-1brdqhf-0 cKRjba">Awesome Object Detection</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/timzhang642/3D-Machine-Learning" class="Link-sc-1brdqhf-0 cKRjba">Awesome 3D Machine Learning</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/jinwchoi/awesome-action-recognition" class="Link-sc-1brdqhf-0 cKRjba">Awesome Action Recognition</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/bertjiazheng/awesome-scene-understanding" class="Link-sc-1brdqhf-0 cKRjba">Awesome Scene Understanding</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/yenchenlin/awesome-adversarial-machine-learning" class="Link-sc-1brdqhf-0 cKRjba">Awesome Adversarial Machine Learning</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/chbrian/awesome-adversarial-examples-dl" class="Link-sc-1brdqhf-0 cKRjba">Awesome Adversarial Deep Learning</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/polarisZhao/awesome-face" class="Link-sc-1brdqhf-0 cKRjba">Awesome Face</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/ChanChiChoi/awesome-Face_Recognition" class="Link-sc-1brdqhf-0 cKRjba">Awesome Face Recognition</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/wangzheallen/awesome-human-pose-estimation" class="Link-sc-1brdqhf-0 cKRjba">Awesome Human Pose Estimation</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/fepegar/awesome-medical-imaging" class="Link-sc-1brdqhf-0 cKRjba">Awesome medical imaging</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/heyalexej/awesome-images" class="Link-sc-1brdqhf-0 cKRjba">Awesome Images</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/ericjang/awesome-graphics" class="Link-sc-1brdqhf-0 cKRjba">Awesome Graphics</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/yenchenlin/awesome-NeRF" class="Link-sc-1brdqhf-0 cKRjba">Awesome Neural Radiance Fields</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/vsitzmann/awesome-implicit-representations" class="Link-sc-1brdqhf-0 cKRjba">Awesome Implicit Neural Representations</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/weihaox/awesome-neural-rendering" class="Link-sc-1brdqhf-0 cKRjba">Awesome Neural Rendering</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/awesomedata/awesome-public-datasets" class="Link-sc-1brdqhf-0 cKRjba">Awesome Public Datasets</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/jsbroks/awesome-dataset-tools" class="Link-sc-1brdqhf-0 cKRjba">Awesome Dataset Tools</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/sunglok/awesome-robotics-datasets" class="Link-sc-1brdqhf-0 cKRjba">Awesome Robotics Datasets</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/fritzlabs/Awesome-Mobile-Machine-Learning" class="Link-sc-1brdqhf-0 cKRjba">Awesome Mobile Machine Learning</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/wangyongjie-ntu/Awesome-explainable-AI" class="Link-sc-1brdqhf-0 cKRjba">Awesome Explainable AI</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/datamllab/awesome-fairness-in-ai" class="Link-sc-1brdqhf-0 cKRjba">Awesome Fairness in AI</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/jphall663/awesome-machine-learning-interpretability" class="Link-sc-1brdqhf-0 cKRjba">Awesome Machine Learning Interpretability</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/EthicalML/awesome-production-machine-learning" class="Link-sc-1brdqhf-0 cKRjba">Awesome Production Machine Learning</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/danieljf24/awesome-video-text-retrieval" class="Link-sc-1brdqhf-0 cKRjba">Awesome Video Text Retrieval</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/weihaox/awesome-image-translation" class="Link-sc-1brdqhf-0 cKRjba">Awesome Image-to-Image Translation</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/1900zyh/Awesome-Image-Inpainting" class="Link-sc-1brdqhf-0 cKRjba">Awesome Image Inpainting</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/vinthony/awesome-deep-hdr" class="Link-sc-1brdqhf-0 cKRjba">Awesome Deep HDR</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/matthewvowels1/Awesome-Video-Generation" class="Link-sc-1brdqhf-0 cKRjba">Awesome Video Generation</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/nashory/gans-awesome-applications" class="Link-sc-1brdqhf-0 cKRjba">Awesome GAN applications</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/zhoubolei/awesome-generative-modeling" class="Link-sc-1brdqhf-0 cKRjba">Awesome Generative Modeling</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/weiaicunzai/awesome-image-classification" class="Link-sc-1brdqhf-0 cKRjba">Awesome Image Classification</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/ChristosChristofidis/awesome-deep-learning" class="Link-sc-1brdqhf-0 cKRjba">Awesome Deep Learning</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/XindiWu/Awesome-Machine-Learning-in-Biomedical-Healthcare-Imaging" class="Link-sc-1brdqhf-0 cKRjba">Awesome Machine Learning in Biomedical(Healthcare) Imaging</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/abhineet123/Deep-Learning-for-Tracking-and-Detection" class="Link-sc-1brdqhf-0 cKRjba">Awesome Deep Learning for Tracking and Detection</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/wangzheallen/awesome-human-pose-estimation" class="Link-sc-1brdqhf-0 cKRjba">Awesome Human Pose Estimation</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis" class="Link-sc-1brdqhf-0 cKRjba">Awesome Deep Learning for Video Analysis</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/yuewang-cuhk/awesome-vision-language-pretraining-papers" class="Link-sc-1brdqhf-0 cKRjba">Awesome Vision + Language</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/kiloreux/awesome-robotics" class="Link-sc-1brdqhf-0 cKRjba">Awesome Robotics</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/dk-liang/Awesome-Visual-Transformer" class="Link-sc-1brdqhf-0 cKRjba">Awesome Visual Transformer</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/ChanganVR/awesome-embodied-vision" class="Link-sc-1brdqhf-0 cKRjba">Awesome Embodied Vision</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/hoya012/awesome-anomaly-detection" class="Link-sc-1brdqhf-0 cKRjba">Awesome Anomaly Detection</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/thaoshibe/awesome-makeup-transfer" class="Link-sc-1brdqhf-0 cKRjba">Awesome Makeup Transfer</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/subeeshvasu/Awesome-Learning-with-Label-Noise" class="Link-sc-1brdqhf-0 cKRjba">Awesome Learning with Label Noise</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/subeeshvasu/Awesome-Deblurring" class="Link-sc-1brdqhf-0 cKRjba">Awesome Deblurring</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/subeeshvasu/Awsome_Deep_Geometry_Learning" class="Link-sc-1brdqhf-0 cKRjba">Awsome Deep Geometry Learning</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/subeeshvasu/Awesome-Image-Distortion-Correction" class="Link-sc-1brdqhf-0 cKRjba">Awesome Image Distortion Correction</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/subeeshvasu/Awesome-Neuron-Segmentation-in-EM-Images" class="Link-sc-1brdqhf-0 cKRjba">Awesome Neuron Segmentation in EM Images</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/subeeshvasu/Awsome_Delineation" class="Link-sc-1brdqhf-0 cKRjba">Awsome Delineation</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/subeeshvasu/Awesome-ImageHarmonization" class="Link-sc-1brdqhf-0 cKRjba">Awesome ImageHarmonization</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/subeeshvasu/Awsome-GAN-Training" class="Link-sc-1brdqhf-0 cKRjba">Awsome GAN Training</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/tstanislawek/awesome-document-understanding" class="Link-sc-1brdqhf-0 cKRjba">Awesome Document Understanding</a></li></ul><h2 id="books" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#books" color="auto.gray.8" aria-label="Books permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Books</h2><h4 id="computer-vision" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#computer-vision" color="auto.gray.8" aria-label="Computer Vision permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Computer Vision</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.computervisionmodels.com/" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision:  Models, Learning, and Inference</a> - Simon J. D. Prince 2012</li><li><a target="_blank" rel="noopener noreferrer" href="http://szeliski.org/Book/" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision: Theory and Application</a> - Rick Szeliski 2010</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.amazon.com/Computer-Vision-Modern-Approach-2nd/dp/013608592X/ref=dp_ob_title_bk" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision: A Modern Approach (2nd edition)</a> - David Forsyth and Jean Ponce 2011</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.robots.ox.ac.uk/~vgg/hzbook/" class="Link-sc-1brdqhf-0 cKRjba">Multiple View Geometry in Computer Vision</a> - Richard Hartley and Andrew Zisserman 2004</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.amazon.com/Computer-Vision-Linda-G-Shapiro/dp/0130307963" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision</a> - Linda G. Shapiro 2001</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.amazon.com/Vision-Science-Phenomenology-Stephen-Palmer/dp/0262161834/" class="Link-sc-1brdqhf-0 cKRjba">Vision Science: Photons to Phenomenology</a> - Stephen E. Palmer 1999</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.morganclaypool.com/doi/abs/10.2200/S00332ED1V01Y201103AIM011" class="Link-sc-1brdqhf-0 cKRjba">Visual Object Recognition synthesis lecture</a> - Kristen Grauman and Bastian Leibe 2011</li><li><a target="_blank" rel="noopener noreferrer" href="http://cvfxbook.com/" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision for Visual Effects</a> - Richard J. Radke, 2012</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.amazon.com/High-Dynamic-Range-Imaging-Second/dp/012374914X" class="Link-sc-1brdqhf-0 cKRjba">High dynamic range imaging: acquisition, display, and image-based lighting</a> - Reinhard, E., Heidrich, W., Debevec, P., Pattanaik, S., Ward, G., Myszkowski, K 2010</li><li><a target="_blank" rel="noopener noreferrer" href="https://people.csail.mit.edu/jsolomon/share/book/numerical_book.pdf" class="Link-sc-1brdqhf-0 cKRjba">Numerical Algorithms: Methods for Computer Vision, Machine Learning, and Graphics</a> - Justin Solomon 2015</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.amazon.com/Processing-Analysis-Activate-Learning-Engineering/dp/1285179528" class="Link-sc-1brdqhf-0 cKRjba">Image Processing and Analysis</a> - Stan Birchfield 2018</li><li><a target="_blank" rel="noopener noreferrer" href="http://web.stanford.edu/class/cs231a/" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision, From 3D Reconstruction to Recognition</a> - Silvio Savarese 2018</li></ul><h4 id="opencv-programming" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#opencv-programming" color="auto.gray.8" aria-label="OpenCV Programming permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>OpenCV Programming</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.amazon.com/Learning-OpenCV-Computer-Vision-Library/dp/0596516134" class="Link-sc-1brdqhf-0 cKRjba">Learning OpenCV: Computer Vision with the OpenCV Library</a> - Gary Bradski and Adrian Kaehler</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.pyimagesearch.com/practical-python-opencv/" class="Link-sc-1brdqhf-0 cKRjba">Practical Python and OpenCV</a> - Adrian Rosebrock</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.amazon.com/OpenCV-Essentials-Oscar-Deniz-Suarez/dp/1783984244/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1424594237&amp;sr=1-1&amp;keywords=opencv+essentials#" class="Link-sc-1brdqhf-0 cKRjba">OpenCV Essentials</a> - Oscar Deniz Suarez, Mª del Milagro Fernandez Carrobles, Noelia Vallez Enano, Gloria Bueno Garcia, Ismael Serrano Gracia</li></ul><h4 id="machine-learning" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#machine-learning" color="auto.gray.8" aria-label="Machine Learning permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Machine Learning</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://research.microsoft.com/en-us/um/people/cmbishop/prml/index.htm" class="Link-sc-1brdqhf-0 cKRjba">Pattern Recognition and Machine Learning</a> - Christopher M. Bishop 2007</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.engineering.upm.ro/master-ie/sacpi/mat_did/info068/docum/Neural%20Networks%20for%20Pattern%20Recognition.pdf" class="Link-sc-1brdqhf-0 cKRjba">Neural Networks for Pattern Recognition</a> - Christopher M. Bishop 1995</li><li><a target="_blank" rel="noopener noreferrer" href="http://pgm.stanford.edu/" class="Link-sc-1brdqhf-0 cKRjba">Probabilistic Graphical Models: Principles and Techniques</a> - Daphne Koller and Nir Friedman 2009</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.amazon.com/Pattern-Classification-2nd-Richard-Duda/dp/0471056693" class="Link-sc-1brdqhf-0 cKRjba">Pattern Classification</a> - Peter E. Hart, David G. Stork, and Richard O. Duda 2000</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.amazon.com/Machine-Learning-Tom-M-Mitchell/dp/0070428077/" class="Link-sc-1brdqhf-0 cKRjba">Machine Learning</a> - Tom M. Mitchell 1997</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.gaussianprocess.org/gpml/" class="Link-sc-1brdqhf-0 cKRjba">Gaussian processes for machine learning</a> - Carl Edward Rasmussen and Christopher K. I. Williams 2005</li><li><a target="_blank" rel="noopener noreferrer" href="https://work.caltech.edu/telecourse.html" class="Link-sc-1brdqhf-0 cKRjba">Learning From Data</a>- Yaser S. Abu-Mostafa, Malik Magdon-Ismail and Hsuan-Tien Lin 2012</li><li><a target="_blank" rel="noopener noreferrer" href="http://neuralnetworksanddeeplearning.com/" class="Link-sc-1brdqhf-0 cKRjba">Neural Networks and Deep Learning</a> - Michael Nielsen 2014</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.ucl.ac.uk/staff/d.barber/brml/" class="Link-sc-1brdqhf-0 cKRjba">Bayesian Reasoning and Machine Learning</a> - David Barber, Cambridge University Press, 2012</li></ul><h4 id="fundamentals" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#fundamentals" color="auto.gray.8" aria-label="Fundamentals permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Fundamentals</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.amazon.com/Linear-Algebra-Its-Applications-4th/dp/0030105676/ref=sr_1_4?ie=UTF8&amp;qid=1421433773&amp;sr=8-4&amp;keywords=Linear+Algebra+and+Its+Applications" class="Link-sc-1brdqhf-0 cKRjba">Linear Algebra and Its Applications</a> - Gilbert Strang 1995</li></ul><h2 id="courses" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#courses" color="auto.gray.8" aria-label="Courses permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Courses</h2><h4 id="computer-vision-1" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#computer-vision" color="auto.gray.8" aria-label="Computer Vision permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Computer Vision</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://inside.mines.edu/~whoff/courses/EENG512/" class="Link-sc-1brdqhf-0 cKRjba">EENG 512 / CSCI 512 - Computer Vision</a> - William Hoff (Colorado School of Mines)</li><li><a target="_blank" rel="noopener noreferrer" href="https://sites.google.com/site/ucbcs29443/" class="Link-sc-1brdqhf-0 cKRjba">Visual Object and Activity Recognition</a> - Alexei A. Efros and Trevor Darrell (UC Berkeley)</li><li><a target="_blank" rel="noopener noreferrer" href="http://courses.cs.washington.edu/courses/cse455/12wi/" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision</a> - Steve Seitz (University of Washington)</li><li>Visual Recognition <a target="_blank" rel="noopener noreferrer" href="http://vision.cs.utexas.edu/381V-spring2016/" class="Link-sc-1brdqhf-0 cKRjba">Spring 2016</a>, <a target="_blank" rel="noopener noreferrer" href="http://vision.cs.utexas.edu/381V-fall2016/" class="Link-sc-1brdqhf-0 cKRjba">Fall 2016</a> - Kristen Grauman (UT Austin)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.tamaraberg.com/teaching/Spring_15/" class="Link-sc-1brdqhf-0 cKRjba">Language and Vision</a> - Tamara Berg (UNC Chapel Hill)</li><li><a target="_blank" rel="noopener noreferrer" href="http://vision.stanford.edu/teaching/cs231n/" class="Link-sc-1brdqhf-0 cKRjba">Convolutional Neural Networks for Visual Recognition</a> - Fei-Fei Li and Andrej Karpathy (Stanford University)</li><li><a target="_blank" rel="noopener noreferrer" href="http://cs.nyu.edu/~fergus/teaching/vision/index.html" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision</a> - Rob Fergus (NYU)</li><li><a target="_blank" rel="noopener noreferrer" href="https://courses.engr.illinois.edu/cs543/sp2015/" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision</a> - Derek Hoiem (UIUC)</li><li><a target="_blank" rel="noopener noreferrer" href="http://vision.stanford.edu/teaching/cs131_fall1415/index.html" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision: Foundations and Applications</a> - Kalanit Grill-Spector and Fei-Fei Li (Stanford University)</li><li><a target="_blank" rel="noopener noreferrer" href="http://vision.stanford.edu/teaching/cs431_spring1314/" class="Link-sc-1brdqhf-0 cKRjba">High-Level Vision: Behaviors, Neurons and Computational Models</a> - Fei-Fei Li (Stanford University)</li><li><a target="_blank" rel="noopener noreferrer" href="http://6.869.csail.mit.edu/fa15/" class="Link-sc-1brdqhf-0 cKRjba">Advances in Computer Vision</a> - Antonio Torralba and Bill Freeman (MIT)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.vision.rwth-aachen.de/course/11/" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision</a> - Bastian Leibe (RWTH Aachen University)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.vision.rwth-aachen.de/course/9/" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision 2</a> - Bastian Leibe (RWTH Aachen University)</li><li><a target="_blank" rel="noopener noreferrer" href="http://klewel.com/conferences/epfl-computer-vision/" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision</a> Pascal Fua (EPFL):</li><li><a target="_blank" rel="noopener noreferrer" href="http://cvlab-dresden.de/courses/computer-vision-1/" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision 1</a> Carsten Rother (TU Dresden):</li><li><a target="_blank" rel="noopener noreferrer" href="http://cvlab-dresden.de/courses/CV2/" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision 2</a> Carsten Rother (TU Dresden):</li><li><a target="_blank" rel="noopener noreferrer" href="https://youtu.be/RDkwklFGMfo?list=PLTBdjV_4f-EJn6udZ34tht9EVIW7lbeo4" class="Link-sc-1brdqhf-0 cKRjba">Multiple View Geometry</a> Daniel Cremers (TU Munich):</li></ul><h4 id="computational-photography" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#computational-photography" color="auto.gray.8" aria-label="Computational Photography permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Computational Photography</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://inst.eecs.berkeley.edu/~cs194-26/fa14/" class="Link-sc-1brdqhf-0 cKRjba">Image Manipulation and Computational Photography</a> - Alexei A. Efros (UC Berkeley)</li><li><a target="_blank" rel="noopener noreferrer" href="http://graphics.cs.cmu.edu/courses/15-463/2012_fall/463.html" class="Link-sc-1brdqhf-0 cKRjba">Computational Photography</a> - Alexei A. Efros (CMU)</li><li><a target="_blank" rel="noopener noreferrer" href="https://courses.engr.illinois.edu/cs498dh3/" class="Link-sc-1brdqhf-0 cKRjba">Computational Photography</a> - Derek Hoiem (UIUC)</li><li><a target="_blank" rel="noopener noreferrer" href="http://cs.brown.edu/courses/csci1290/" class="Link-sc-1brdqhf-0 cKRjba">Computational Photography</a> - James Hays (Brown University)</li><li><a target="_blank" rel="noopener noreferrer" href="http://stellar.mit.edu/S/course/6/sp12/6.815/" class="Link-sc-1brdqhf-0 cKRjba">Digital &amp; Computational Photography</a> - Fredo Durand (MIT)</li><li><a target="_blank" rel="noopener noreferrer" href="http://ocw.mit.edu/courses/media-arts-and-sciences/mas-531-computational-camera-and-photography-fall-2009/" class="Link-sc-1brdqhf-0 cKRjba">Computational Camera and Photography</a> - Ramesh Raskar (MIT Media Lab)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.udacity.com/course/computational-photography--ud955" class="Link-sc-1brdqhf-0 cKRjba">Computational Photography</a> - Irfan Essa (Georgia Tech)</li><li><a target="_blank" rel="noopener noreferrer" href="http://graphics.stanford.edu/courses/" class="Link-sc-1brdqhf-0 cKRjba">Courses in Graphics</a> - Stanford University</li><li><a target="_blank" rel="noopener noreferrer" href="http://cs.nyu.edu/~fergus/teaching/comp_photo/index.html" class="Link-sc-1brdqhf-0 cKRjba">Computational Photography</a> - Rob Fergus (NYU)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.toronto.edu/~kyros/courses/320/" class="Link-sc-1brdqhf-0 cKRjba">Introduction to Visual Computing</a> - Kyros Kutulakos (University of Toronto)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.toronto.edu/~kyros/courses/2530/" class="Link-sc-1brdqhf-0 cKRjba">Computational Photography</a> - Kyros Kutulakos (University of Toronto)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.ecse.rpi.edu/~rjradke/cvfxcourse.html" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision for Visual Effects</a> - Rich Radke (Rensselaer Polytechnic Institute)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.ecse.rpi.edu/~rjradke/improccourse.html" class="Link-sc-1brdqhf-0 cKRjba">Introduction to Image Processing</a> - Rich Radke (Rensselaer Polytechnic Institute)</li></ul><h4 id="machine-learning-and-statistical-learning" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#machine-learning-and-statistical-learning" color="auto.gray.8" aria-label="Machine Learning and Statistical Learning permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Machine Learning and Statistical Learning</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="https://www.coursera.org/learn/machine-learning" class="Link-sc-1brdqhf-0 cKRjba">Machine Learning</a> - Andrew Ng (Stanford University)</li><li><a target="_blank" rel="noopener noreferrer" href="https://work.caltech.edu/telecourse.html" class="Link-sc-1brdqhf-0 cKRjba">Learning from Data</a> - Yaser S. Abu-Mostafa (Caltech)</li><li><a target="_blank" rel="noopener noreferrer" href="https://class.stanford.edu/courses/HumanitiesandScience/StatLearning/Winter2015/about" class="Link-sc-1brdqhf-0 cKRjba">Statistical Learning</a> - Trevor Hastie and Rob Tibshirani (Stanford University)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.mit.edu/~9.520/fall14/" class="Link-sc-1brdqhf-0 cKRjba">Statistical Learning Theory and Applications</a> - Tomaso Poggio, Lorenzo Rosasco, Carlo Ciliberto, Charlie Frogner, Georgios Evangelopoulos, Ben Deen (MIT)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.stat.rice.edu/~gallen/stat640.html" class="Link-sc-1brdqhf-0 cKRjba">Statistical Learning</a> - Genevera Allen (Rice University)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.berkeley.edu/~jordan/courses/294-fall09/" class="Link-sc-1brdqhf-0 cKRjba">Practical Machine Learning</a> - Michael Jordan (UC Berkeley)</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/course_information_theory_pattern_recognition/" class="Link-sc-1brdqhf-0 cKRjba">Course on Information Theory, Pattern Recognition, and Neural Networks</a> - David MacKay (University of Cambridge)</li><li><a target="_blank" rel="noopener noreferrer" href="http://web.stanford.edu/~lmackey/stats306b/" class="Link-sc-1brdqhf-0 cKRjba">Methods for Applied Statistics: Unsupervised Learning</a> - Lester Mackey (Stanford)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.robots.ox.ac.uk/~az/lectures/ml/index.html" class="Link-sc-1brdqhf-0 cKRjba">Machine Learning</a> - Andrew Zisserman (University of Oxford)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.udacity.com/course/intro-to-machine-learning--ud120" class="Link-sc-1brdqhf-0 cKRjba">Intro to Machine Learning</a> - Sebastian Thrun (Stanford University)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.udacity.com/course/machine-learning--ud262" class="Link-sc-1brdqhf-0 cKRjba">Machine Learning</a> - Charles Isbell, Michael Littman (Georgia Tech)</li><li><a target="_blank" rel="noopener noreferrer" href="https://cs231n.github.io/" class="Link-sc-1brdqhf-0 cKRjba">(Convolutional) Neural Networks for Visual Recognition</a> - Fei-Fei Li, Andrej Karphaty, Justin Johnson (Stanford University)</li><li><a target="_blank" rel="noopener noreferrer" href="https://youtu.be/QZmZFeZxEKI?list=PLTBdjV_4f-EIiongKlS9OKrBEp8QR47Wl" class="Link-sc-1brdqhf-0 cKRjba">Machine Learning for Computer Vision</a> - Rudolph Triebel (TU Munich)</li></ul><h4 id="optimization" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#optimization" color="auto.gray.8" aria-label="Optimization permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Optimization</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://stanford.edu/class/ee364a/" class="Link-sc-1brdqhf-0 cKRjba">Convex Optimization I</a> - Stephen Boyd (Stanford University)</li><li><a target="_blank" rel="noopener noreferrer" href="http://stanford.edu/class/ee364b/" class="Link-sc-1brdqhf-0 cKRjba">Convex Optimization II</a> - Stephen Boyd (Stanford University)</li><li><a target="_blank" rel="noopener noreferrer" href="https://class.stanford.edu/courses/Engineering/CVX101/Winter2014/about" class="Link-sc-1brdqhf-0 cKRjba">Convex Optimization</a> - Stephen Boyd (Stanford University)</li><li><a target="_blank" rel="noopener noreferrer" href="http://optimization.mit.edu/classes.php" class="Link-sc-1brdqhf-0 cKRjba">Optimization at MIT</a> - (MIT)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.stat.cmu.edu/~ryantibs/convexopt/" class="Link-sc-1brdqhf-0 cKRjba">Convex Optimization</a> - Ryan Tibshirani (CMU)</li></ul><h2 id="papers" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#papers" color="auto.gray.8" aria-label="Papers permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Papers</h2><h4 id="conference-papers-on-the-web" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#conference-papers-on-the-web" color="auto.gray.8" aria-label="Conference papers on the web permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Conference papers on the web</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.cvpapers.com/" class="Link-sc-1brdqhf-0 cKRjba">CVPapers</a> - Computer vision papers on the web</li><li><a target="_blank" rel="noopener noreferrer" href="http://kesen.realtimerendering.com/" class="Link-sc-1brdqhf-0 cKRjba">SIGGRAPH Paper on the web</a> - Graphics papers on the web</li><li><a target="_blank" rel="noopener noreferrer" href="http://papers.nips.cc/" class="Link-sc-1brdqhf-0 cKRjba">NIPS Proceedings</a> - NIPS papers on the web</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cv-foundation.org/openaccess/menu.py" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision Foundation open access</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://iris.usc.edu/Vision-Notes/bibliography/contents.html" class="Link-sc-1brdqhf-0 cKRjba">Annotated Computer Vision Bibliography</a> - Keith Price (USC)</li><li><a target="_blank" rel="noopener noreferrer" href="http://iris.usc.edu/Information/Iris-Conferences.html" class="Link-sc-1brdqhf-0 cKRjba">Calendar of Computer Image Analysis, Computer Vision Conferences</a> - (USC)</li></ul><h4 id="survey-papers" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#survey-papers" color="auto.gray.8" aria-label="Survey Papers permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Survey Papers</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://surveys.visionbib.com/index.html" class="Link-sc-1brdqhf-0 cKRjba">Visionbib Survey Paper List</a></p></li><li><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://www.nowpublishers.com/CGV" class="Link-sc-1brdqhf-0 cKRjba">Foundations and Trends® in Computer Graphics and Vision</a></p></li><li><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://link.springer.com/book/10.1007/978-0-387-31439-6" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision: A Reference Guide</a></p><h2 id="pre-trained-computer-vision-models" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#pre-trained-computer-vision-models" color="auto.gray.8" aria-label="Pre-trained Computer Vision Models permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Pre-trained Computer Vision Models</h2></li><li><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://github.com/shubham-shahh/Open-Source-Models" class="Link-sc-1brdqhf-0 cKRjba">List of Computer Vision models</a> These models are trained on custom objects</p></li></ul><h2 id="tutorials-and-talks" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#tutorials-and-talks" color="auto.gray.8" aria-label="Tutorials and talks permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Tutorials and talks</h2><h4 id="computer-vision-2" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#computer-vision" color="auto.gray.8" aria-label="Computer Vision permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Computer Vision</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.computervisiontalks.com/" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision Talks</a> - Lectures, keynotes, panel discussions on computer vision</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=Mqg6eorYRIQ" class="Link-sc-1brdqhf-0 cKRjba">The Three R&#x27;s of Computer Vision</a> - Jitendra Malik (UC Berkeley) 2013</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/epsrcws08_blake_amv/" class="Link-sc-1brdqhf-0 cKRjba">Applications to Machine Vision</a> - Andrew Blake (Microsoft Research) 2008</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/kdd08_malik_fis/?q=image" class="Link-sc-1brdqhf-0 cKRjba">The Future of Image Search</a> - Jitendra Malik (UC Berkeley) 2008</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=M17oGxh3Ny8" class="Link-sc-1brdqhf-0 cKRjba">Should I do a PhD in Computer Vision?</a> - Fatih Porikli (Australian National University)</li></ul><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.ipam.ucla.edu/programs/summer-schools/graduate-summer-school-computer-vision/?tab=schedule" class="Link-sc-1brdqhf-0 cKRjba">Graduate Summer School 2013: Computer Vision</a> - IPAM, 2013</li></ul><h4 id="recent-conference-talks" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#recent-conference-talks" color="auto.gray.8" aria-label="Recent Conference Talks permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Recent Conference Talks</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.pamitc.org/cvpr15/" class="Link-sc-1brdqhf-0 cKRjba">CVPR 2015</a> - Jun 2015</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/eccv2014_zurich/" class="Link-sc-1brdqhf-0 cKRjba">ECCV 2014</a> - Sep 2014</li><li><a target="_blank" rel="noopener noreferrer" href="http://techtalks.tv/cvpr-2014-oral-talks/" class="Link-sc-1brdqhf-0 cKRjba">CVPR 2014</a> - Jun 2014</li><li><a target="_blank" rel="noopener noreferrer" href="http://techtalks.tv/iccv2013/" class="Link-sc-1brdqhf-0 cKRjba">ICCV 2013</a> - Dec 2013</li><li><a target="_blank" rel="noopener noreferrer" href="http://techtalks.tv/icml/2013/" class="Link-sc-1brdqhf-0 cKRjba">ICML 2013</a> - Jul 2013</li><li><a target="_blank" rel="noopener noreferrer" href="http://techtalks.tv/cvpr2013/" class="Link-sc-1brdqhf-0 cKRjba">CVPR 2013</a> - Jun 2013</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/eccv2012_firenze/" class="Link-sc-1brdqhf-0 cKRjba">ECCV 2012</a> - Oct 2012</li><li><a target="_blank" rel="noopener noreferrer" href="http://techtalks.tv/icml/2012/orals/" class="Link-sc-1brdqhf-0 cKRjba">ICML 2012</a> - Jun 2012</li><li><a target="_blank" rel="noopener noreferrer" href="http://techtalks.tv/cvpr2012webcast/" class="Link-sc-1brdqhf-0 cKRjba">CVPR 2012</a> - Jun 2012</li></ul><h4 id="3d-computer-vision" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#3d-computer-vision" color="auto.gray.8" aria-label="3D Computer Vision permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>3D Computer Vision</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=kyIzMr917Rc" class="Link-sc-1brdqhf-0 cKRjba">3D Computer Vision: Past, Present, and Future</a> - Steve Seitz (University of Washington) 2011</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=04Kgg3QEXFI" class="Link-sc-1brdqhf-0 cKRjba">Reconstructing the World from Photos on the Internet</a> - Steve Seitz (University of Washington) 2013</li></ul><h4 id="internet-vision" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#internet-vision" color="auto.gray.8" aria-label="Internet Vision permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Internet Vision</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.technologyreview.com/video/426265/meet-2011-tr35-winner-noah-snavely/" class="Link-sc-1brdqhf-0 cKRjba">The Distributed Camera</a> - Noah Snavely (Cornell University) 2011</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=UHkCa9-Z1Ps" class="Link-sc-1brdqhf-0 cKRjba">Planet-Scale Visual Understanding</a> - Noah Snavely (Cornell University) 2014</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=6MWEfpKUfRc" class="Link-sc-1brdqhf-0 cKRjba">A Trillion Photos</a> - Steve Seitz (University of Washington) 2013</li></ul><h4 id="computational-photography-1" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#computational-photography" color="auto.gray.8" aria-label="Computational Photography permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Computational Photography</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=j90_0Ndk7XM" class="Link-sc-1brdqhf-0 cKRjba">Reflections on Image-Based Modeling and Rendering</a> - Richard Szeliski (Microsoft Research) 2013</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=ZvPaHZZVPRk" class="Link-sc-1brdqhf-0 cKRjba">Photographing Events over Time</a> - William T. Freeman (MIT) 2011</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/nipsworkshops2011_weiss_deconvolution/" class="Link-sc-1brdqhf-0 cKRjba">Old and New algorithm for Blind Deconvolution</a> -  Yair Weiss (The Hebrew University of Jerusalem) 2011</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/nipsworkshops2010_milanfar_tmi/" class="Link-sc-1brdqhf-0 cKRjba">A Tour of Modern &quot;Image Processing&quot;</a> -  Peyman Milanfar (UC Santa Cruz/Google) 2010</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/mlss07_blake_tiivp/" class="Link-sc-1brdqhf-0 cKRjba">Topics in image and video processing</a> Andrew Blake (Microsoft Research) 2007</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=HJVNI0mkmqk" class="Link-sc-1brdqhf-0 cKRjba">Computational Photography</a> - William T. Freeman (MIT) 2012</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=_BWnIQY_X98" class="Link-sc-1brdqhf-0 cKRjba">Revealing the Invisible</a> - Frédo Durand (MIT) 2012</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=rE-hVtytT-I" class="Link-sc-1brdqhf-0 cKRjba">Overview of Computer Vision and Visual Effects</a> - Rich Radke (Rensselaer Polytechnic Institute) 2014</li></ul><h4 id="learning-and-vision" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#learning-and-vision" color="auto.gray.8" aria-label="Learning and Vision permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Learning and Vision</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/colt2011_freeman_help/?q=computer%20vision" class="Link-sc-1brdqhf-0 cKRjba">Where machine vision needs help from machine learning</a> - William T. Freeman (MIT) 2011</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/mlss08au_lucey_linv/" class="Link-sc-1brdqhf-0 cKRjba">Learning in Computer Vision</a> - Simon Lucey (CMU) 2008</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/nips09_weiss_lil/?q=computer%20vision" class="Link-sc-1brdqhf-0 cKRjba">Learning and Inference in Low-Level Vision</a> - Yair Weiss (The Hebrew University of Jerusalem) 2009</li></ul><h4 id="object-recognition" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#object-recognition" color="auto.gray.8" aria-label="Object Recognition permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Object Recognition</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://research.microsoft.com/apps/video/dl.aspx?id=231358" class="Link-sc-1brdqhf-0 cKRjba">Object Recognition</a> - Larry Zitnick (Microsoft Research)</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/mlas06_li_gmvoo/?q=Fei-Fei%20Li" class="Link-sc-1brdqhf-0 cKRjba">Generative Models for Visual Objects and Object Recognition via Bayesian Inference</a> - Fei-Fei Li (Stanford University)</li></ul><h4 id="graphical-models" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#graphical-models" color="auto.gray.8" aria-label="Graphical Models permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Graphical Models</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/uai2012_felzenszwalb_computer_vision/?q=computer%20vision" class="Link-sc-1brdqhf-0 cKRjba">Graphical Models for Computer Vision</a> - Pedro Felzenszwalb (Brown University) 2012</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/mlss09uk_ghahramani_gm/" class="Link-sc-1brdqhf-0 cKRjba">Graphical Models</a> - Zoubin Ghahramani (University of Cambridge) 2009</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/mlss06tw_roweis_mlpgm/" class="Link-sc-1brdqhf-0 cKRjba">Machine Learning, Probability and Graphical Models</a> - Sam Roweis (NYU) 2006</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/mlss09us_weiss_gma/?q=Graphical%20Models" class="Link-sc-1brdqhf-0 cKRjba">Graphical Models and Applications</a> -  Yair Weiss (The Hebrew University of Jerusalem) 2009</li></ul><h4 id="machine-learning-1" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#machine-learning" color="auto.gray.8" aria-label="Machine Learning permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Machine Learning</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="https://nikola-rt.ee.washington.edu/people/bulyko/papers/em.pdf" class="Link-sc-1brdqhf-0 cKRjba">A Gentle Tutorial of the EM Algorithm</a> - Jeff A. Bilmes (UC Berkeley) 1998</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/mlss09uk_bishop_ibi/" class="Link-sc-1brdqhf-0 cKRjba">Introduction To Bayesian Inference</a> - Christopher Bishop (Microsoft Research) 2009</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/mlss06tw_lin_svm/" class="Link-sc-1brdqhf-0 cKRjba">Support Vector Machines</a> - Chih-Jen Lin (National Taiwan University) 2006</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/mlss09uk_jordan_bfway/" class="Link-sc-1brdqhf-0 cKRjba">Bayesian or Frequentist, Which Are You? </a> - Michael I. Jordan (UC Berkeley)</li></ul><h4 id="optimization-1" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#optimization" color="auto.gray.8" aria-label="Optimization permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Optimization</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/nips2010_wright_oaml/" class="Link-sc-1brdqhf-0 cKRjba">Optimization Algorithms in Machine Learning</a> - Stephen J. Wright (University of Wisconsin-Madison)</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/mlss07_vandenberghe_copt/?q=convex%20optimization" class="Link-sc-1brdqhf-0 cKRjba">Convex Optimization</a> - Lieven Vandenberghe (University of California, Los Angeles)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=oZqoWozVDVg" class="Link-sc-1brdqhf-0 cKRjba">Continuous Optimization in Computer Vision</a> - Andrew Fitzgibbon (Microsoft Research)</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/sahd2014_bach_stochastic_gradient/" class="Link-sc-1brdqhf-0 cKRjba">Beyond stochastic gradient descent for large-scale machine learning</a> - Francis Bach (INRIA)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/playlist?list=PLTBdjV_4f-EJ7A2iIH5L5ztqqrWYjP2RI" class="Link-sc-1brdqhf-0 cKRjba">Variational Methods for Computer Vision</a> - Daniel Cremers (Technische Universität München) (<a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=GgcbVPNd3SI" class="Link-sc-1brdqhf-0 cKRjba">lecture 18 missing from playlist</a>)</li></ul><h4 id="deep-learning" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#deep-learning" color="auto.gray.8" aria-label="Deep Learning permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Deep Learning</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/jul09_hinton_deeplearn/" class="Link-sc-1brdqhf-0 cKRjba">A tutorial on Deep Learning</a> - Geoffrey E. Hinton (University of Toronto)</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/kdd2014_salakhutdinov_deep_learning/?q=Hidden%20Markov%20model#" class="Link-sc-1brdqhf-0 cKRjba">Deep Learning</a> -  Ruslan Salakhutdinov (University of Toronto)</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/kdd2014_bengio_deep_learning/" class="Link-sc-1brdqhf-0 cKRjba">Scaling up Deep Learning</a> - Yoshua Bengio (University of Montreal)</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/machine_krizhevsky_imagenet_classification/?q=deep%20learning" class="Link-sc-1brdqhf-0 cKRjba">ImageNet Classification with Deep Convolutional Neural Networks</a> -  Alex Krizhevsky (University of Toronto)</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/sahd2014_lecun_deep_learning/" class="Link-sc-1brdqhf-0 cKRjba">The Unreasonable Effectivness Of Deep Learning</a> Yann LeCun (NYU/Facebook Research) 2014</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=qgx57X0fBdA" class="Link-sc-1brdqhf-0 cKRjba">Deep Learning for Computer Vision</a> - Rob Fergus (NYU/Facebook Research)</li><li><a target="_blank" rel="noopener noreferrer" href="http://videolectures.net/sahd2014_mallat_dimensional_learning/" class="Link-sc-1brdqhf-0 cKRjba">High-dimensional learning with deep network contractions</a> - Stéphane Mallat (Ecole Normale Superieure)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.ipam.ucla.edu/programs/summer-schools/graduate-summer-school-deep-learning-feature-learning/?tab=schedule" class="Link-sc-1brdqhf-0 cKRjba">Graduate Summer School 2012: Deep Learning, Feature Learning</a> - IPAM, 2012</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.fields.utoronto.ca/programs/scientific/14-15/bigdata/machine/" class="Link-sc-1brdqhf-0 cKRjba">Workshop on Big Data and Statistical Machine Learning</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/channel/UC3ywjSv5OsDiDAnOP8C1NiQ" class="Link-sc-1brdqhf-0 cKRjba">Machine Learning Summer School</a> - Reykjavik, Iceland 2014<ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=JuimBuvEWBg" class="Link-sc-1brdqhf-0 cKRjba">Deep Learning Session 1</a> - Yoshua Bengio (Universtiy of Montreal)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=Fl-W7_z3w3o" class="Link-sc-1brdqhf-0 cKRjba">Deep Learning Session 2</a> - Yoshua Bengio (University of Montreal)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=_cohR7LAgWA" class="Link-sc-1brdqhf-0 cKRjba">Deep Learning Session 3</a> - Yoshua Bengio (University of Montreal)</li></ul></li></ul><h2 id="software" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#software" color="auto.gray.8" aria-label="Software permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Software</h2><h4 id="annotation-tools" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#annotation-tools" color="auto.gray.8" aria-label="Annotation tools permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Annotation tools</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://commacoloring.herokuapp.com/" class="Link-sc-1brdqhf-0 cKRjba">Comma Coloring</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://annotorious.github.io/" class="Link-sc-1brdqhf-0 cKRjba">Annotorious</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://labelme.csail.mit.edu/Release3.0/" class="Link-sc-1brdqhf-0 cKRjba">LabelME</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/sanko-shoko/gtmaker" class="Link-sc-1brdqhf-0 cKRjba">gtmaker</a></li></ul><h4 id="external-resource-links" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#external-resource-links" color="auto.gray.8" aria-label="External Resource Links permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>External Resource Links</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="https://sites.google.com/site/jbhuang0604/resources/vision" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision Resources</a> - Jia-Bin Huang (UIUC)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cvpapers.com/rr.html" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision Algorithm Implementations</a> - CVPapers</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.csee.wvu.edu/~xinl/reproducible_research.html" class="Link-sc-1brdqhf-0 cKRjba">Source Code Collection for Reproducible Research</a> - Xin Li (West Virginia University)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.cmu.edu/afs/cs/project/cil/ftp/html/v-source.html" class="Link-sc-1brdqhf-0 cKRjba">CMU Computer Vision Page</a></li></ul><h4 id="general-purpose-computer-vision-library" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#general-purpose-computer-vision-library" color="auto.gray.8" aria-label="General Purpose Computer Vision Library permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>General Purpose Computer Vision Library</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://opencv.org/" class="Link-sc-1brdqhf-0 cKRjba">Open CV</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://kyamagu.github.io/mexopencv/" class="Link-sc-1brdqhf-0 cKRjba">mexopencv</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://simplecv.org/" class="Link-sc-1brdqhf-0 cKRjba">SimpleCV</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/jesolem/PCV" class="Link-sc-1brdqhf-0 cKRjba">Open source Python module for computer vision</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/liuliu/ccv" class="Link-sc-1brdqhf-0 cKRjba">ccv: A Modern Computer Vision Library</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.vlfeat.org/" class="Link-sc-1brdqhf-0 cKRjba">VLFeat</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.mathworks.com/products/computer-vision/" class="Link-sc-1brdqhf-0 cKRjba">Matlab Computer Vision System Toolbox</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://vision.ucsd.edu/~pdollar/toolbox/doc/index.html" class="Link-sc-1brdqhf-0 cKRjba">Piotr&#x27;s Computer Vision Matlab Toolbox</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://pointclouds.org/" class="Link-sc-1brdqhf-0 cKRjba">PCL: Point Cloud Library</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://gitorious.org/imageutilities" class="Link-sc-1brdqhf-0 cKRjba">ImageUtilities</a></li></ul><h4 id="multiple-view-computer-vision" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#multiple-view-computer-vision" color="auto.gray.8" aria-label="Multiple-view Computer Vision permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Multiple-view Computer Vision</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.robots.ox.ac.uk/~vgg/hzbook/code/" class="Link-sc-1brdqhf-0 cKRjba">MATLAB Functions for Multiple View Geometry</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://staffhome.ecm.uwa.edu.au/~00011811/Research/MatlabFns/index.html" class="Link-sc-1brdqhf-0 cKRjba">Peter Kovesi&#x27;s Matlab Functions for Computer Vision and Image Analysis</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://laurentkneip.github.io/opengv/" class="Link-sc-1brdqhf-0 cKRjba">OpenGV </a> - geometric computer vision algorithms</li><li><a target="_blank" rel="noopener noreferrer" href="http://cmp.felk.cvut.cz/mini/" class="Link-sc-1brdqhf-0 cKRjba">MinimalSolvers</a> - Minimal problems solver</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.gcc.tu-darmstadt.de/home/proj/mve/" class="Link-sc-1brdqhf-0 cKRjba">Multi-View Environment</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://ccwu.me/vsfm/" class="Link-sc-1brdqhf-0 cKRjba">Visual SFM</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.cornell.edu/~snavely/bundler/" class="Link-sc-1brdqhf-0 cKRjba">Bundler SFM</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://imagine.enpc.fr/~moulonp/openMVG/" class="Link-sc-1brdqhf-0 cKRjba">openMVG: open Multiple View Geometry</a> - Multiple View Geometry; Structure from Motion library &amp; softwares</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.di.ens.fr/pmvs/" class="Link-sc-1brdqhf-0 cKRjba">Patch-based Multi-view Stereo V2</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.di.ens.fr/cmvs/" class="Link-sc-1brdqhf-0 cKRjba">Clustering Views for Multi-view Stereo</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.gris.informatik.tu-darmstadt.de/projects/floating-scale-surface-recon/" class="Link-sc-1brdqhf-0 cKRjba">Floating Scale Surface Reconstruction</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.gcc.tu-darmstadt.de/home/proj/texrecon/" class="Link-sc-1brdqhf-0 cKRjba">Large-Scale Texturing of 3D Reconstructions</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/openMVG/awesome_3DReconstruction_list" class="Link-sc-1brdqhf-0 cKRjba">Awesome 3D reconstruction list</a></li></ul><h4 id="feature-detection-and-extraction" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#feature-detection-and-extraction" color="auto.gray.8" aria-label="Feature Detection and Extraction permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Feature Detection and Extraction</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.vlfeat.org/" class="Link-sc-1brdqhf-0 cKRjba">VLFeat</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.ubc.ca/~lowe/keypoints/" class="Link-sc-1brdqhf-0 cKRjba">SIFT</a><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>David G. Lowe, &quot;Distinctive image features from scale-invariant keypoints,&quot; International Journal of Computer Vision, 60, 2 (2004), pp. 91-110.</li></ul></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.robots.ox.ac.uk/~vedaldi/code/siftpp.html" class="Link-sc-1brdqhf-0 cKRjba">SIFT++</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.asl.ethz.ch/people/lestefan/personal/BRISK" class="Link-sc-1brdqhf-0 cKRjba">BRISK</a><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>Stefan Leutenegger, Margarita Chli and Roland Siegwart, &quot;BRISK: Binary Robust Invariant Scalable Keypoints&quot;, ICCV 2011</li></ul></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.vision.ee.ethz.ch/~surf/" class="Link-sc-1brdqhf-0 cKRjba">SURF</a><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>Herbert Bay, Andreas Ess, Tinne Tuytelaars, Luc Van Gool, &quot;SURF: Speeded Up Robust Features&quot;, Computer Vision and Image Understanding (CVIU), Vol. 110, No. 3, pp. 346--359, 2008</li></ul></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.ivpe.com/freak.htm" class="Link-sc-1brdqhf-0 cKRjba">FREAK</a><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>A. Alahi, R. Ortiz, and P. Vandergheynst, &quot;FREAK: Fast Retina Keypoint&quot;, CVPR 2012</li></ul></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.robesafe.com/personal/pablo.alcantarilla/kaze.html" class="Link-sc-1brdqhf-0 cKRjba">AKAZE</a><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>Pablo F. Alcantarilla, Adrien Bartoli and Andrew J. Davison, &quot;KAZE Features&quot;, ECCV 2012</li></ul></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/nourani/LBP" class="Link-sc-1brdqhf-0 cKRjba">Local Binary Patterns</a></li></ul><h4 id="high-dynamic-range-imaging" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#high-dynamic-range-imaging" color="auto.gray.8" aria-label="High Dynamic Range Imaging permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>High Dynamic Range Imaging</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/banterle/HDR_Toolbox" class="Link-sc-1brdqhf-0 cKRjba">HDR_Toolbox</a></li></ul><h4 id="semantic-segmentation" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#semantic-segmentation" color="auto.gray.8" aria-label="Semantic Segmentation permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Semantic Segmentation</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.it-caesar.com/list-of-contemporary-semantic-segmentation-datasets/" class="Link-sc-1brdqhf-0 cKRjba">List of Semantic Segmentation algorithms</a></li></ul><h4 id="low-level-vision" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#low-level-vision" color="auto.gray.8" aria-label="Low-level Vision permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Low-level Vision</h4><h6 id="stereo-vision" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#stereo-vision" color="auto.gray.8" aria-label="Stereo Vision permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Stereo Vision</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://vision.middlebury.edu/stereo/" class="Link-sc-1brdqhf-0 cKRjba">Middlebury Stereo Vision</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php?benchmark=stero" class="Link-sc-1brdqhf-0 cKRjba">The KITTI Vision Benchmark Suite</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cvlibs.net/software/libelas/" class="Link-sc-1brdqhf-0 cKRjba">LIBELAS: Library for Efficient Large-scale Stereo Matching</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.6d-vision.com/ground-truth-stixel-dataset" class="Link-sc-1brdqhf-0 cKRjba">Ground Truth Stixel Dataset</a></li></ul><h6 id="optical-flow" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#optical-flow" color="auto.gray.8" aria-label="Optical Flow permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Optical Flow</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://vision.middlebury.edu/flow/" class="Link-sc-1brdqhf-0 cKRjba">Middlebury Optical Flow Evaluation</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://sintel.is.tue.mpg.de/" class="Link-sc-1brdqhf-0 cKRjba">MPI-Sintel Optical Flow Dataset and Evaluation</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php?benchmark=flow" class="Link-sc-1brdqhf-0 cKRjba">The KITTI Vision Benchmark Suite</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://hci.iwr.uni-heidelberg.de/Benchmarks/document/Challenging_Data_for_Stereo_and_Optical_Flow/" class="Link-sc-1brdqhf-0 cKRjba">HCI Challenge</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://people.csail.mit.edu/celiu/OpticalFlow/" class="Link-sc-1brdqhf-0 cKRjba">Coarse2Fine Optical Flow</a> - Ce Liu (MIT)</li><li><a target="_blank" rel="noopener noreferrer" href="http://cs.brown.edu/~dqsun/code/cvpr10_flow_code.zip" class="Link-sc-1brdqhf-0 cKRjba">Secrets of Optical Flow Estimation and Their Principles</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://people.csail.mit.edu/celiu/OpticalFlow/" class="Link-sc-1brdqhf-0 cKRjba">C++/MatLab Optical Flow by C. Liu (based on Brox et al. and Bruhn et al.)</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.ctim.es/research_works/parallel_robust_optical_flow/" class="Link-sc-1brdqhf-0 cKRjba">Parallel Robust Optical Flow by Sánchez Pérez et al.</a></li></ul><h6 id="image-denoising" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#image-denoising" color="auto.gray.8" aria-label="Image Denoising permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Image Denoising</h6><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl">BM3D, KSVD,</p><h6 id="super-resolution" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#super-resolution" color="auto.gray.8" aria-label="Super-resolution permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Super-resolution</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.robots.ox.ac.uk/~vgg/software/SR/" class="Link-sc-1brdqhf-0 cKRjba">Multi-frame image super-resolution</a><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>Pickup, L. C. Machine Learning in Multi-frame Image Super-resolution, PhD thesis 2008</li></ul></li><li><a target="_blank" rel="noopener noreferrer" href="http://people.csail.mit.edu/billf/project%20pages/sresCode/Markov%20Random%20Fields%20for%20Super-Resolution.html" class="Link-sc-1brdqhf-0 cKRjba">Markov Random Fields for Super-Resolution</a><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>W. T Freeman and C. Liu. Markov Random Fields for Super-resolution and Texture Synthesis. In A. Blake, P. Kohli, and C. Rother, eds., Advances in Markov Random Fields for Vision and Image Processing, Chapter 10. MIT Press, 2011</li></ul></li><li><a target="_blank" rel="noopener noreferrer" href="https://people.mpi-inf.mpg.de/~kkim/supres/supres.htm" class="Link-sc-1brdqhf-0 cKRjba">Sparse regression and natural image prior</a><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>K. I. Kim and Y. Kwon, &quot;Single-image super-resolution using sparse regression and natural image prior&quot;, IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 32, no. 6, pp. 1127-1133, 2010.</li></ul></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.technion.ac.il/~elad/Various/SingleImageSR_TIP14_Box.zip" class="Link-sc-1brdqhf-0 cKRjba">Single-Image Super Resolution via a Statistical Model</a><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>T. Peleg and M. Elad, A Statistical Prediction Model Based on Sparse Representations for Single Image Super-Resolution, IEEE Transactions on Image Processing, Vol. 23, No. 6, Pages 2569-2582, June 2014</li></ul></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.technion.ac.il/~elad/Various/Single_Image_SR.zip" class="Link-sc-1brdqhf-0 cKRjba">Sparse Coding for Super-Resolution</a><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>R. Zeyde, M. Elad, and M. Protter On Single Image Scale-Up using Sparse-Representations, Curves &amp; Surfaces, Avignon-France, June 24-30, 2010 (appears also in Lecture-Notes-on-Computer-Science - LNCS).</li></ul></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.ifp.illinois.edu/~jyang29/ScSR.htm" class="Link-sc-1brdqhf-0 cKRjba">Patch-wise Sparse Recovery</a><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>Jianchao Yang, John Wright, Thomas Huang, and Yi Ma. Image super-resolution via sparse representation. IEEE Transactions on Image Processing (TIP), vol. 19, issue 11, 2010.</li></ul></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.jdl.ac.cn/user/hchang/doc/code.rar" class="Link-sc-1brdqhf-0 cKRjba">Neighbor embedding</a><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>H. Chang, D.Y. Yeung, Y. Xiong. Super-resolution through neighbor embedding. Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), vol.1, pp.275-282, Washington, DC, USA, 27 June - 2 July 2004.</li></ul></li><li><a target="_blank" rel="noopener noreferrer" href="https://sites.google.com/site/yuzhushome/single-image-super-resolution-using-deformable-patches" class="Link-sc-1brdqhf-0 cKRjba">Deformable Patches</a><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>Yu Zhu, Yanning Zhang and Alan Yuille, Single Image Super-resolution using Deformable Patches, CVPR 2014</li></ul></li><li><a target="_blank" rel="noopener noreferrer" href="http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html" class="Link-sc-1brdqhf-0 cKRjba">SRCNN</a><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>Chao Dong, Chen Change Loy, Kaiming He, Xiaoou Tang, Learning a Deep Convolutional Network for Image Super-Resolution, in ECCV 2014</li></ul></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.vision.ee.ethz.ch/~timofter/ACCV2014_ID820_SUPPLEMENTARY/index.html" class="Link-sc-1brdqhf-0 cKRjba">A+: Adjusted Anchored Neighborhood Regression</a><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>R. Timofte, V. De Smet, and L. Van Gool. A+: Adjusted Anchored Neighborhood Regression for Fast Super-Resolution, ACCV 2014</li></ul></li><li><a target="_blank" rel="noopener noreferrer" href="https://sites.google.com/site/jbhuang0604/publications/struct_sr" class="Link-sc-1brdqhf-0 cKRjba">Transformed Self-Exemplars</a><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>Jia-Bin Huang, Abhishek Singh, and Narendra Ahuja, Single Image Super-Resolution using Transformed Self-Exemplars, IEEE Conference on Computer Vision and Pattern Recognition, 2015</li></ul></li></ul><h6 id="image-deblurring" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#image-deblurring" color="auto.gray.8" aria-label="Image Deblurring permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Image Deblurring</h6><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl">Non-blind deconvolution</p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://homes.cs.washington.edu/~shanqi/work/spvdeconv/" class="Link-sc-1brdqhf-0 cKRjba">Spatially variant non-blind deconvolution</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://cg.postech.ac.kr/research/deconv_outliers/" class="Link-sc-1brdqhf-0 cKRjba">Handling Outliers in Non-blind Image Deconvolution</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://cs.nyu.edu/~dilip/research/fast-deconvolution/" class="Link-sc-1brdqhf-0 cKRjba">Hyper-Laplacian Priors</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://people.csail.mit.edu/danielzoran/epllcode.zip" class="Link-sc-1brdqhf-0 cKRjba">From Learning Models of Natural Image Patches to Whole Image Restoration</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://lxu.me/projects/dcnn/" class="Link-sc-1brdqhf-0 cKRjba">Deep Convolutional Neural Network for Image Deconvolution</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://webdav.is.mpg.de/pixel/neural_deconvolution/" class="Link-sc-1brdqhf-0 cKRjba">Neural Deconvolution</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl">Blind deconvolution</p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.nyu.edu/~fergus/research/deblur.html" class="Link-sc-1brdqhf-0 cKRjba">Removing Camera Shake From A Single Photograph</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cse.cuhk.edu.hk/leojia/projects/motion_deblurring/" class="Link-sc-1brdqhf-0 cKRjba">High-quality motion deblurring from a single image</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cse.cuhk.edu.hk/leojia/projects/robust_deblur/" class="Link-sc-1brdqhf-0 cKRjba">Two-Phase Kernel Estimation for Robust Motion Deblurring</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://people.csail.mit.edu/taegsang/Documents/RadonDeblurringCode.zip" class="Link-sc-1brdqhf-0 cKRjba">Blur kernel estimation using the radon transform</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://cg.postech.ac.kr/research/fast_motion_deblurring/" class="Link-sc-1brdqhf-0 cKRjba">Fast motion deblurring</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://cs.nyu.edu//~dilip/research/blind-deconvolution/" class="Link-sc-1brdqhf-0 cKRjba">Blind Deconvolution Using a Normalized Sparsity Measure</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.huji.ac.il/~raananf/projects/deblur/" class="Link-sc-1brdqhf-0 cKRjba">Blur-kernel estimation from spectral irregularities</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.wisdom.weizmann.ac.il/~levina/papers/LevinEtalCVPR2011Code.zip" class="Link-sc-1brdqhf-0 cKRjba">Efficient marginal likelihood optimization in blind deconvolution</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cse.cuhk.edu.hk/leojia/projects/l0deblur/" class="Link-sc-1brdqhf-0 cKRjba">Unnatural L0 Sparse Representation for Natural Image Deblurring</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://cs.brown.edu/~lbsun/deblur2013/deblur2013iccp.html" class="Link-sc-1brdqhf-0 cKRjba">Edge-based Blur Kernel Estimation Using Patch Priors</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.wisdom.weizmann.ac.il/~vision/BlindDeblur.html" class="Link-sc-1brdqhf-0 cKRjba">Blind Deblurring Using Internal Patch Recurrence</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl">Non-uniform Deblurring</p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.di.ens.fr/willow/research/deblurring/" class="Link-sc-1brdqhf-0 cKRjba">Non-uniform Deblurring for Shaken Images</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://grail.cs.washington.edu/projects/mdf_deblurring/" class="Link-sc-1brdqhf-0 cKRjba">Single Image Deblurring Using Motion Density Functions</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://research.microsoft.com/en-us/um/redmond/groups/ivm/imudeblurring/" class="Link-sc-1brdqhf-0 cKRjba">Image Deblurring using Inertial Measurement Sensors</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://webdav.is.mpg.de/pixel/fast_removal_of_camera_shake/" class="Link-sc-1brdqhf-0 cKRjba">Fast Removal of Non-uniform Camera Shake</a></li></ul><h6 id="image-completion" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#image-completion" color="auto.gray.8" aria-label="Image Completion permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Image Completion</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://registry.gimp.org/node/27986" class="Link-sc-1brdqhf-0 cKRjba">GIMP Resynthesizer</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://lafarren.com/image-completer/" class="Link-sc-1brdqhf-0 cKRjba">Priority BP</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.ece.ucsb.edu/~psen/melding" class="Link-sc-1brdqhf-0 cKRjba">ImageMelding</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://sites.google.com/site/jbhuang0604/publications/struct_completion" class="Link-sc-1brdqhf-0 cKRjba">PlanarStructureCompletion</a></li></ul><h6 id="image-retargeting" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#image-retargeting" color="auto.gray.8" aria-label="Image Retargeting permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Image Retargeting</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://people.csail.mit.edu/mrub/retargetme/" class="Link-sc-1brdqhf-0 cKRjba">RetargetMe</a></li></ul><h6 id="alpha-matting" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#alpha-matting" color="auto.gray.8" aria-label="Alpha Matting permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Alpha Matting</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.alphamatting.com/" class="Link-sc-1brdqhf-0 cKRjba">Alpha Matting Evaluation</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://people.csail.mit.edu/alevin/matting.tar.gz" class="Link-sc-1brdqhf-0 cKRjba">Closed-form image matting</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.vision.huji.ac.il/SpectralMatting/" class="Link-sc-1brdqhf-0 cKRjba">Spectral Matting</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.mathworks.com/matlabcentral/fileexchange/31412-learning-based-digital-matting" class="Link-sc-1brdqhf-0 cKRjba">Learning-based Matting</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.alphamatting.com/ImprovingMattingComprehensiveSamplingSets_CVPR2013.zip" class="Link-sc-1brdqhf-0 cKRjba">Improving Image Matting using Comprehensive Sampling Sets</a></li></ul><h6 id="image-pyramid" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#image-pyramid" color="auto.gray.8" aria-label="Image Pyramid permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Image Pyramid</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.cns.nyu.edu/~eero/steerpyr/" class="Link-sc-1brdqhf-0 cKRjba">The Steerable Pyramid</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.curvelet.org/" class="Link-sc-1brdqhf-0 cKRjba">CurveLab</a></li></ul><h6 id="edge-preserving-image-processing" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#edge-preserving-image-processing" color="auto.gray.8" aria-label="Edge-preserving image processing permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Edge-preserving image processing</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://people.csail.mit.edu/sparis/bf/" class="Link-sc-1brdqhf-0 cKRjba">Fast Bilateral Filter</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.cityu.edu.hk/~qiyang/publications/code/qx.cvpr09.ctbf.zip" class="Link-sc-1brdqhf-0 cKRjba">O(1) Bilateral Filter</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.cityu.edu.hk/~qiyang/publications/eccv-12/" class="Link-sc-1brdqhf-0 cKRjba">Recursive Bilateral Filtering</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cse.cuhk.edu.hk/leojia/projects/rollguidance/" class="Link-sc-1brdqhf-0 cKRjba">Rolling Guidance Filter</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cse.cuhk.edu.hk/leojia/projects/texturesep/index.html" class="Link-sc-1brdqhf-0 cKRjba">Relative Total Variation</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cse.cuhk.edu.hk/leojia/projects/L0smoothing/index.html" class="Link-sc-1brdqhf-0 cKRjba">L0 Gradient Optimization</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.inf.ufrgs.br/~eslgastal/DomainTransform/" class="Link-sc-1brdqhf-0 cKRjba">Domain Transform</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://inf.ufrgs.br/~eslgastal/AdaptiveManifolds/" class="Link-sc-1brdqhf-0 cKRjba">Adaptive Manifold</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://research.microsoft.com/en-us/um/people/kahe/eccv10/" class="Link-sc-1brdqhf-0 cKRjba">Guided image filtering</a></li></ul><h4 id="intrinsic-images" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#intrinsic-images" color="auto.gray.8" aria-label="Intrinsic Images permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Intrinsic Images</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://people.tuebingen.mpg.de/mkiefel/projects/intrinsic/" class="Link-sc-1brdqhf-0 cKRjba">Recovering Intrinsic Images with a global Sparsity Prior on Reflectance</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://giga.cps.unizar.es/~elenag/projects/EGSR2012_intrinsic/" class="Link-sc-1brdqhf-0 cKRjba">Intrinsic Images by Clustering</a></li></ul><h4 id="contour-detection-and-image-segmentation" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#contour-detection-and-image-segmentation" color="auto.gray.8" aria-label="Contour Detection and Image Segmentation permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Contour Detection and Image Segmentation</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://coewww.rutgers.edu/riul/research/code/EDISON/" class="Link-sc-1brdqhf-0 cKRjba">Mean Shift Segmentation</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://cs.brown.edu/~pff/segment/" class="Link-sc-1brdqhf-0 cKRjba">Graph-based Segmentation</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cis.upenn.edu/~jshi/software/" class="Link-sc-1brdqhf-0 cKRjba">Normalized Cut</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://grabcut.weebly.com/background--algorithm.html" class="Link-sc-1brdqhf-0 cKRjba">Grab Cut</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html" class="Link-sc-1brdqhf-0 cKRjba">Contour Detection and Image Segmentation</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://research.microsoft.com/en-us/downloads/389109f6-b4e8-404c-84bf-239f7cbf4e3d/" class="Link-sc-1brdqhf-0 cKRjba">Structured Edge Detection</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://web.mit.edu/phillipi/pmi-boundaries/" class="Link-sc-1brdqhf-0 cKRjba">Pointwise Mutual Information</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://ivrl.epfl.ch/research/superpixels" class="Link-sc-1brdqhf-0 cKRjba">SLIC Super-pixel</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.vlfeat.org/overview/quickshift.html" class="Link-sc-1brdqhf-0 cKRjba">QuickShift</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.toronto.edu/~babalex/research.html" class="Link-sc-1brdqhf-0 cKRjba">TurboPixels</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://mingyuliu.net/" class="Link-sc-1brdqhf-0 cKRjba">Entropy Rate Superpixel</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.vsi.cs.uni-frankfurt.de/research/current-projects/research/superpixel-segmentation/" class="Link-sc-1brdqhf-0 cKRjba">Contour Relaxed Superpixels</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.mvdblive.org/seeds/" class="Link-sc-1brdqhf-0 cKRjba">SEEDS</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/davidstutz/seeds-revised" class="Link-sc-1brdqhf-0 cKRjba">SEEDS Revised</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/" class="Link-sc-1brdqhf-0 cKRjba">Multiscale Combinatorial Grouping</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/pdollar/edges" class="Link-sc-1brdqhf-0 cKRjba">Fast Edge Detection Using Structured Forests</a></li></ul><h4 id="interactive-image-segmentation" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#interactive-image-segmentation" color="auto.gray.8" aria-label="Interactive Image Segmentation permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Interactive Image Segmentation</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://cns.bu.edu/~lgrady/software.html" class="Link-sc-1brdqhf-0 cKRjba">Random Walker</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.tc.umn.edu/~baixx015/" class="Link-sc-1brdqhf-0 cKRjba">Geodesic Segmentation</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://research.microsoft.com/apps/pubs/default.aspx?id=69040" class="Link-sc-1brdqhf-0 cKRjba">Lazy Snapping</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://powerwatershed.sourceforge.net/" class="Link-sc-1brdqhf-0 cKRjba">Power Watershed</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.adobe.com/technology/people/san-jose/brian-price.html" class="Link-sc-1brdqhf-0 cKRjba">Geodesic Graph Cut</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.cmu.edu/~olivierd/" class="Link-sc-1brdqhf-0 cKRjba">Segmentation by Transduction</a></li></ul><h4 id="video-segmentation" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#video-segmentation" color="auto.gray.8" aria-label="Video Segmentation permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Video Segmentation</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/image-and-video-segmentation/video-segmentation-with-superpixels/" class="Link-sc-1brdqhf-0 cKRjba">Video Segmentation with Superpixels</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cc.gatech.edu/cpl/projects/videosegmentation/" class="Link-sc-1brdqhf-0 cKRjba">Efficient hierarchical graph-based video segmentation</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://lmb.informatik.uni-freiburg.de/Publications/2011/OB11/" class="Link-sc-1brdqhf-0 cKRjba">Object segmentation in video</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cse.buffalo.edu/~jcorso/r/supervoxels/" class="Link-sc-1brdqhf-0 cKRjba">Streaming hierarchical video segmentation</a></li></ul><h4 id="camera-calibration" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#camera-calibration" color="auto.gray.8" aria-label="Camera calibration permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Camera calibration</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.vision.caltech.edu/bouguetj/calib_doc/" class="Link-sc-1brdqhf-0 cKRjba">Camera Calibration Toolbox for Matlab</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://docs.opencv.org/trunk/doc/tutorials/calib3d/camera_calibration/camera_calibration.html#" class="Link-sc-1brdqhf-0 cKRjba">Camera calibration With OpenCV</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://sites.google.com/site/prclibo/toolbox" class="Link-sc-1brdqhf-0 cKRjba">Multiple Camera Calibration Toolbox</a></li></ul><h4 id="simultaneous-localization-and-mapping" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#simultaneous-localization-and-mapping" color="auto.gray.8" aria-label="Simultaneous localization and mapping permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Simultaneous localization and mapping</h4><h6 id="slam-community" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#slam-community" color="auto.gray.8" aria-label="SLAM community: permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>SLAM community:</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="https://www.openslam.org/" class="Link-sc-1brdqhf-0 cKRjba">openSLAM</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cvlibs.net/datasets/kitti/eval_odometry.php" class="Link-sc-1brdqhf-0 cKRjba">Kitti Odometry: benchmark for outdoor visual odometry (codes may be available)</a></li></ul><h6 id="trackingodometry" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#trackingodometry" color="auto.gray.8" aria-label="Tracking/Odometry: permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Tracking/Odometry:</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.cvlibs.net/software/libviso/" class="Link-sc-1brdqhf-0 cKRjba">LIBVISO2: C++ Library for Visual Odometry 2</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.robots.ox.ac.uk/~gk/PTAM/" class="Link-sc-1brdqhf-0 cKRjba">PTAM: Parallel tracking and mapping</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/GerhardR/kfusion" class="Link-sc-1brdqhf-0 cKRjba">KFusion: Implementation of KinectFusion</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Nerei/kinfu_remake" class="Link-sc-1brdqhf-0 cKRjba">kinfu_remake: Lightweight, reworked and optimized version of Kinfu.</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://las-vegas.uni-osnabrueck.de/related-projects/lvr-kinfu/" class="Link-sc-1brdqhf-0 cKRjba">LVR-KinFu: kinfu_remake based Large Scale KinectFusion with online reconstruction</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.robots.ox.ac.uk/~victor/infinitam/" class="Link-sc-1brdqhf-0 cKRjba">InfiniTAM: Implementation of multi-platform large-scale depth tracking and fusion</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/nachtmar/VoxelHashing" class="Link-sc-1brdqhf-0 cKRjba">VoxelHashing: Large-scale KinectFusion</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://apt.cs.manchester.ac.uk/projects/PAMELA/tools/SLAMBench/" class="Link-sc-1brdqhf-0 cKRjba">SLAMBench: Multiple-implementation of KinectFusion</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/uzh-rpg/rpg_svo" class="Link-sc-1brdqhf-0 cKRjba">SVO: Semi-direct visual odometry</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/tum-vision/dvo_slam" class="Link-sc-1brdqhf-0 cKRjba">DVO: dense visual odometry</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://code.google.com/p/fovis/" class="Link-sc-1brdqhf-0 cKRjba">FOVIS: RGB-D visual odometry</a></li></ul><h6 id="graph-optimization" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#graph-optimization" color="auto.gray.8" aria-label="Graph Optimization: permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Graph Optimization:</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="https://collab.cc.gatech.edu/borg/gtsam?destination=node%2F299" class="Link-sc-1brdqhf-0 cKRjba">GTSAM: General smoothing and mapping library for Robotics and SFM</a> -- Georgia Institute of Technology</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/RainerKuemmerle/g2o" class="Link-sc-1brdqhf-0 cKRjba">G2O: General framework for graph optomization</a></li></ul><h6 id="loop-closure" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#loop-closure" color="auto.gray.8" aria-label="Loop Closure: permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Loop Closure:</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.robots.ox.ac.uk/~mjc/Software.htm" class="Link-sc-1brdqhf-0 cKRjba">FabMap: appearance-based loop closure system</a> - also available in <a target="_blank" rel="noopener noreferrer" href="http://docs.opencv.org/2.4/modules/contrib/doc/openfabmap.html" class="Link-sc-1brdqhf-0 cKRjba">OpenCV2.4.11</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://webdiis.unizar.es/~dorian/index.php?p=32" class="Link-sc-1brdqhf-0 cKRjba">DBoW2: binary bag-of-words loop detection system</a></li></ul><h6 id="localization--mapping" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#localization--mapping" color="auto.gray.8" aria-label="Localization &amp; Mapping: permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Localization &amp; Mapping:</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="https://code.google.com/p/ratslam/" class="Link-sc-1brdqhf-0 cKRjba">RatSLAM</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/tum-vision/lsd_slam" class="Link-sc-1brdqhf-0 cKRjba">LSD-SLAM</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/raulmur/ORB_SLAM" class="Link-sc-1brdqhf-0 cKRjba">ORB-SLAM</a></li></ul><h4 id="single-view-spatial-understanding" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#single-view-spatial-understanding" color="auto.gray.8" aria-label="Single-view Spatial Understanding permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Single-view Spatial Understanding</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://web.engr.illinois.edu/~dhoiem/projects/software.html" class="Link-sc-1brdqhf-0 cKRjba">Geometric Context</a> - Derek Hoiem (CMU)</li><li><a target="_blank" rel="noopener noreferrer" href="http://web.engr.illinois.edu/~dhoiem/software/counter.php?Down=varsha_spatialLayout.zip" class="Link-sc-1brdqhf-0 cKRjba">Recovering Spatial Layout</a> - Varsha Hedau (UIUC)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.cmu.edu/~./dclee/code/index.html" class="Link-sc-1brdqhf-0 cKRjba">Geometric Reasoning</a> - David C. Lee (CMU)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/arron2003/rgbd2full3d" class="Link-sc-1brdqhf-0 cKRjba">RGBD2Full3D</a> - Ruiqi Guo (UIUC)</li></ul><h4 id="object-detection" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#object-detection" color="auto.gray.8" aria-label="Object Detection permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Object Detection</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://pascal.inrialpes.fr/soft/olt/" class="Link-sc-1brdqhf-0 cKRjba">INRIA Object Detection and Localization Toolkit</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.berkeley.edu/~rbg/latent/" class="Link-sc-1brdqhf-0 cKRjba">Discriminatively trained deformable part models</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/rbgirshick/voc-dpm" class="Link-sc-1brdqhf-0 cKRjba">VOC-DPM</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.ics.uci.edu/~dramanan/software/sparse/" class="Link-sc-1brdqhf-0 cKRjba">Histograms of Sparse Codes for Object Detection</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/rbgirshick/rcnn" class="Link-sc-1brdqhf-0 cKRjba">R-CNN: Regions with Convolutional Neural Network Features</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/ShaoqingRen/SPP_net" class="Link-sc-1brdqhf-0 cKRjba">SPP-Net</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://mmcheng.net/bing/comment-page-9/" class="Link-sc-1brdqhf-0 cKRjba">BING: Objectness Estimation</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/pdollar/edges" class="Link-sc-1brdqhf-0 cKRjba">Edge Boxes</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Russell91/ReInspect" class="Link-sc-1brdqhf-0 cKRjba">ReInspect</a></li></ul><h4 id="nearest-neighbor-search" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#nearest-neighbor-search" color="auto.gray.8" aria-label="Nearest Neighbor Search permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Nearest Neighbor Search</h4><h6 id="general-purpose-nearest-neighbor-search" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#general-purpose-nearest-neighbor-search" color="auto.gray.8" aria-label="General purpose nearest neighbor search permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>General purpose nearest neighbor search</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.umd.edu/~mount/ANN/" class="Link-sc-1brdqhf-0 cKRjba">ANN: A Library for Approximate Nearest Neighbor Searching</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.ubc.ca/research/flann/" class="Link-sc-1brdqhf-0 cKRjba">FLANN - Fast Library for Approximate Nearest Neighbors</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://vincentfpgarcia.github.io/kNN-CUDA/" class="Link-sc-1brdqhf-0 cKRjba">Fast k nearest neighbor search using GPU</a></li></ul><h6 id="nearest-neighbor-field-estimation" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#nearest-neighbor-field-estimation" color="auto.gray.8" aria-label="Nearest Neighbor Field Estimation permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Nearest Neighbor Field Estimation</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://gfx.cs.princeton.edu/gfx/pubs/Barnes_2009_PAR/index.php" class="Link-sc-1brdqhf-0 cKRjba">PatchMatch</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://gfx.cs.princeton.edu/pubs/Barnes_2010_TGP/index.php" class="Link-sc-1brdqhf-0 cKRjba">Generalized PatchMatch</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.eng.tau.ac.il/~simonk/CSH/" class="Link-sc-1brdqhf-0 cKRjba">Coherency Sensitive Hashing</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/fbesse/pmbp" class="Link-sc-1brdqhf-0 cKRjba">PMBP: PatchMatch Belief Propagation</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.eng.tau.ac.il/~avidan/papers/TreeCANN_code_20121022.rar" class="Link-sc-1brdqhf-0 cKRjba">TreeCANN</a></li></ul><h4 id="visual-tracking" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#visual-tracking" color="auto.gray.8" aria-label="Visual Tracking permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Visual Tracking</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="https://sites.google.com/site/trackerbenchmark/benchmarks/v10" class="Link-sc-1brdqhf-0 cKRjba">Visual Tracker Benchmark</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.votchallenge.net/" class="Link-sc-1brdqhf-0 cKRjba">Visual Tracking Challenge</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.ces.clemson.edu/~stb/klt/" class="Link-sc-1brdqhf-0 cKRjba">Kanade-Lucas-Tomasi Feature Tracker</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.eng.tau.ac.il/~oron/ELK/ELK.html" class="Link-sc-1brdqhf-0 cKRjba">Extended Lucas-Kanade Tracking</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.vision.ee.ethz.ch/boostingTrackers/" class="Link-sc-1brdqhf-0 cKRjba">Online-boosting Tracking</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www4.comp.polyu.edu.hk/~cslzhang/STC/STC.htm" class="Link-sc-1brdqhf-0 cKRjba">Spatio-Temporal Context Learning</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.shengfenghe.com/visual-tracking-via-locality-sensitive-histograms.html" class="Link-sc-1brdqhf-0 cKRjba">Locality Sensitive Histograms</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cv-foundation.org/openaccess/content_iccv_workshops_2013/W03/papers/Xiao_An_Enhanced_Adaptive_2013_ICCV_paper.pdf" class="Link-sc-1brdqhf-0 cKRjba">Enhanced adaptive coupled-layer LGTracker++</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://personal.ee.surrey.ac.uk/Personal/Z.Kalal/tld.html" class="Link-sc-1brdqhf-0 cKRjba">TLD: Tracking - Learning - Detection</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.gnebehay.com/cmt/" class="Link-sc-1brdqhf-0 cKRjba">CMT: Clustering of Static-Adaptive Correspondences for Deformable Object Tracking</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://home.isr.uc.pt/~henriques/circulant/" class="Link-sc-1brdqhf-0 cKRjba">Kernelized Correlation Filters</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cvl.isy.liu.se/en/research/objrec/visualtracking/scalvistrack/index.html" class="Link-sc-1brdqhf-0 cKRjba">Accurate Scale Estimation for Robust Visual Tracking</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://cs-people.bu.edu/jmzhang/MEEM/MEEM.html" class="Link-sc-1brdqhf-0 cKRjba">Multiple Experts using Entropy Minimization</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.dabi.temple.edu/~hbling/code/TGPR.htm" class="Link-sc-1brdqhf-0 cKRjba">TGPR</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://sites.google.com/site/jbhuang0604/publications/cf2" class="Link-sc-1brdqhf-0 cKRjba">CF2: Hierarchical Convolutional Features for Visual Tracking</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://webdocs.cs.ualberta.ca/~vis/mtf/index.html" class="Link-sc-1brdqhf-0 cKRjba">Modular Tracking Framework</a></li></ul><h4 id="saliency-detection" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#saliency-detection" color="auto.gray.8" aria-label="Saliency Detection permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Saliency Detection</h4><h4 id="attributes" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#attributes" color="auto.gray.8" aria-label="Attributes permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Attributes</h4><h4 id="action-reconition" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#action-reconition" color="auto.gray.8" aria-label="Action Reconition permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Action Reconition</h4><h4 id="egocentric-cameras" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#egocentric-cameras" color="auto.gray.8" aria-label="Egocentric cameras permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Egocentric cameras</h4><h4 id="human-in-the-loop-systems" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#human-in-the-loop-systems" color="auto.gray.8" aria-label="Human-in-the-loop systems permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Human-in-the-loop systems</h4><h4 id="image-captioning" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#image-captioning" color="auto.gray.8" aria-label="Image Captioning permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Image Captioning</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/karpathy/neuraltalk" class="Link-sc-1brdqhf-0 cKRjba">NeuralTalk</a> -</li></ul><h4 id="optimization-2" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#optimization" color="auto.gray.8" aria-label="Optimization permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Optimization</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://ceres-solver.org/" class="Link-sc-1brdqhf-0 cKRjba">Ceres Solver</a> - Nonlinear least-square problem and unconstrained optimization solver</li><li><a target="_blank" rel="noopener noreferrer" href="http://ab-initio.mit.edu/wiki/index.php/NLopt" class="Link-sc-1brdqhf-0 cKRjba">NLopt</a>- Nonlinear least-square problem and unconstrained optimization solver</li><li><a target="_blank" rel="noopener noreferrer" href="http://hci.iwr.uni-heidelberg.de/opengm2/" class="Link-sc-1brdqhf-0 cKRjba">OpenGM</a> - Factor graph based discrete optimization and inference solver</li><li><a target="_blank" rel="noopener noreferrer" href="https://collab.cc.gatech.edu/borg/gtsam/" class="Link-sc-1brdqhf-0 cKRjba">GTSAM</a> - Factor graph based lease-square optimization solver</li></ul><h4 id="deep-learning-1" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#deep-learning" color="auto.gray.8" aria-label="Deep Learning permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Deep Learning</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/kjw0612/awesome-deep-vision" class="Link-sc-1brdqhf-0 cKRjba">Awesome Deep Vision</a></li></ul><h4 id="machine-learning-2" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#machine-learning" color="auto.gray.8" aria-label="Machine Learning permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Machine Learning</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/josephmisiti/awesome-machine-learning" class="Link-sc-1brdqhf-0 cKRjba">Awesome Machine Learning</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://idiap.github.io/bob/" class="Link-sc-1brdqhf-0 cKRjba">Bob: a free signal processing and machine learning toolbox for researchers</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/" class="Link-sc-1brdqhf-0 cKRjba">LIBSVM -- A Library for Support Vector Machines</a></li></ul><h2 id="datasets" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#datasets" color="auto.gray.8" aria-label="Datasets permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Datasets</h2><h4 id="external-dataset-link-collection" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#external-dataset-link-collection" color="auto.gray.8" aria-label="External Dataset Link Collection permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>External Dataset Link Collection</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.cvpapers.com/datasets.html" class="Link-sc-1brdqhf-0 cKRjba">CV Datasets on the web</a> - CVPapers</li><li><a target="_blank" rel="noopener noreferrer" href="http://rodrigob.github.io/are_we_there_yet/build/" class="Link-sc-1brdqhf-0 cKRjba">Are we there yet?</a> - Which paper provides the best results on standard dataset X?</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cvpapers.com/datasets.html" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision Dataset on the web</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://riemenschneider.hayko.at/vision/dataset/" class="Link-sc-1brdqhf-0 cKRjba">Yet Another Computer Vision Index To Datasets</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.computervisiononline.com/datasets" class="Link-sc-1brdqhf-0 cKRjba">ComputerVisionOnline Datasets</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://homepages.inf.ed.ac.uk/cgi/rbf/CVONLINE/entries.pl?TAG363" class="Link-sc-1brdqhf-0 cKRjba">CVOnline Dataset</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://clickdamage.com/sourcecode/cv_datasets.php" class="Link-sc-1brdqhf-0 cKRjba">CV datasets</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://datasets.visionbib.com/info-index.html" class="Link-sc-1brdqhf-0 cKRjba">visionbib</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.visualdata.io/" class="Link-sc-1brdqhf-0 cKRjba">VisualData</a></li></ul><h4 id="low-level-vision-1" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#low-level-vision" color="auto.gray.8" aria-label="Low-level Vision permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Low-level Vision</h4><h6 id="stereo-vision-1" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#stereo-vision" color="auto.gray.8" aria-label="Stereo Vision permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Stereo Vision</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://vision.middlebury.edu/stereo/" class="Link-sc-1brdqhf-0 cKRjba">Middlebury Stereo Vision</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php?benchmark=stero" class="Link-sc-1brdqhf-0 cKRjba">The KITTI Vision Benchmark Suite</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cvlibs.net/software/libelas/" class="Link-sc-1brdqhf-0 cKRjba">LIBELAS: Library for Efficient Large-scale Stereo Matching</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.6d-vision.com/ground-truth-stixel-dataset" class="Link-sc-1brdqhf-0 cKRjba">Ground Truth Stixel Dataset</a></li></ul><h6 id="optical-flow-1" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#optical-flow" color="auto.gray.8" aria-label="Optical Flow permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Optical Flow</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://vision.middlebury.edu/flow/" class="Link-sc-1brdqhf-0 cKRjba">Middlebury Optical Flow Evaluation</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://sintel.is.tue.mpg.de/" class="Link-sc-1brdqhf-0 cKRjba">MPI-Sintel Optical Flow Dataset and Evaluation</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php?benchmark=flow" class="Link-sc-1brdqhf-0 cKRjba">The KITTI Vision Benchmark Suite</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://hci.iwr.uni-heidelberg.de/Benchmarks/document/Challenging_Data_for_Stereo_and_Optical_Flow/" class="Link-sc-1brdqhf-0 cKRjba">HCI Challenge</a></li></ul><h6 id="video-object-segmentation" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#video-object-segmentation" color="auto.gray.8" aria-label="Video Object Segmentation permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Video Object Segmentation</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://davischallenge.org/" class="Link-sc-1brdqhf-0 cKRjba">DAVIS: Densely Annotated VIdeo Segmentation</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://web.engr.oregonstate.edu/~lif/SegTrack2/dataset.html" class="Link-sc-1brdqhf-0 cKRjba">SegTrack v2</a></li></ul><h6 id="change-detection" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#change-detection" color="auto.gray.8" aria-label="Change Detection permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Change Detection</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.gti.ssr.upm.es/data/LASIESTA" class="Link-sc-1brdqhf-0 cKRjba">Labeled and Annotated Sequences for Integral Evaluation of SegmenTation Algorithms</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.changedetection.net/" class="Link-sc-1brdqhf-0 cKRjba">ChangeDetection.net</a></li></ul><h6 id="image-super-resolutions" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#image-super-resolutions" color="auto.gray.8" aria-label="Image Super-resolutions permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Image Super-resolutions</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="https://eng.ucmerced.edu/people/cyang35/ECCV14/ECCV14.html" class="Link-sc-1brdqhf-0 cKRjba">Single-Image Super-Resolution: A Benchmark</a></li></ul><h4 id="intrinsic-images-1" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#intrinsic-images" color="auto.gray.8" aria-label="Intrinsic Images permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Intrinsic Images</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.mit.edu/~kimo/publications/intrinsic/" class="Link-sc-1brdqhf-0 cKRjba">Ground-truth dataset and baseline evaluations for intrinsic image algorithms</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://opensurfaces.cs.cornell.edu/intrinsic/" class="Link-sc-1brdqhf-0 cKRjba">Intrinsic Images in the Wild</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cic.uab.cat/Datasets/synthetic_intrinsic_image_dataset/" class="Link-sc-1brdqhf-0 cKRjba">Intrinsic Image Evaluation on Synthetic Complex Scenes</a></li></ul><h4 id="material-recognition" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#material-recognition" color="auto.gray.8" aria-label="Material Recognition permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Material Recognition</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://opensurfaces.cs.cornell.edu/" class="Link-sc-1brdqhf-0 cKRjba">OpenSurface</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://people.csail.mit.edu/celiu/CVPR2010/" class="Link-sc-1brdqhf-0 cKRjba">Flickr Material Database</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://opensurfaces.cs.cornell.edu/publications/minc/" class="Link-sc-1brdqhf-0 cKRjba">Materials in Context Dataset</a></li></ul><h4 id="multi-view-reconsturction" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#multi-view-reconsturction" color="auto.gray.8" aria-label="Multi-view Reconsturction permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Multi-view Reconsturction</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://vision.middlebury.edu/mview/" class="Link-sc-1brdqhf-0 cKRjba">Multi-View Stereo Reconstruction</a></li></ul><h4 id="saliency-detection-1" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#saliency-detection" color="auto.gray.8" aria-label="Saliency Detection permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Saliency Detection</h4><h4 id="visual-tracking-1" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#visual-tracking" color="auto.gray.8" aria-label="Visual Tracking permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Visual Tracking</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="https://sites.google.com/site/trackerbenchmark/benchmarks/v10" class="Link-sc-1brdqhf-0 cKRjba">Visual Tracker Benchmark</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://sites.google.com/site/benchmarkpami/" class="Link-sc-1brdqhf-0 cKRjba">Visual Tracker Benchmark v1.1</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.votchallenge.net/" class="Link-sc-1brdqhf-0 cKRjba">VOT Challenge</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://tracking.cs.princeton.edu/" class="Link-sc-1brdqhf-0 cKRjba">Princeton Tracking Benchmark</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://webdocs.cs.ualberta.ca/~vis/trackDB/" class="Link-sc-1brdqhf-0 cKRjba">Tracking Manipulation Tasks (TMT)</a></li></ul><h4 id="visual-surveillance" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#visual-surveillance" color="auto.gray.8" aria-label="Visual Surveillance permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Visual Surveillance</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.viratdata.org/" class="Link-sc-1brdqhf-0 cKRjba">VIRAT</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://cam2.ecn.purdue.edu/" class="Link-sc-1brdqhf-0 cKRjba">CAM2</a></li></ul><h4 id="saliency-detection-2" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#saliency-detection" color="auto.gray.8" aria-label="Saliency Detection permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Saliency Detection</h4><h4 id="change-detection-1" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#change-detection" color="auto.gray.8" aria-label="Change detection permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Change detection</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://changedetection.net/" class="Link-sc-1brdqhf-0 cKRjba">ChangeDetection.net</a></li></ul><h4 id="visual-recognition" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#visual-recognition" color="auto.gray.8" aria-label="Visual Recognition permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Visual Recognition</h4><h6 id="image-classification" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#image-classification" color="auto.gray.8" aria-label="Image Classification permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Image Classification</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://pascallin.ecs.soton.ac.uk/challenges/VOC/" class="Link-sc-1brdqhf-0 cKRjba">The PASCAL Visual Object Classes</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.image-net.org/challenges/LSVRC/2014/" class="Link-sc-1brdqhf-0 cKRjba">ImageNet Large Scale Visual Recognition Challenge</a></li></ul><h6 id="self-supervised-learning" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#self-supervised-learning" color="auto.gray.8" aria-label="Self-supervised Learning permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Self-supervised Learning</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/yukimasano/PASS" class="Link-sc-1brdqhf-0 cKRjba">PASS: An An ImageNet replacement for self-supervised pretraining without humans</a></li></ul><h6 id="scene-recognition" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#scene-recognition" color="auto.gray.8" aria-label="Scene Recognition permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Scene Recognition</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://groups.csail.mit.edu/vision/SUN/" class="Link-sc-1brdqhf-0 cKRjba">SUN Database</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://places.csail.mit.edu/" class="Link-sc-1brdqhf-0 cKRjba">Place Dataset</a></li></ul><h6 id="object-detection-1" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#object-detection" color="auto.gray.8" aria-label="Object Detection permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Object Detection</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://pascallin.ecs.soton.ac.uk/challenges/VOC/" class="Link-sc-1brdqhf-0 cKRjba">The PASCAL Visual Object Classes</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.image-net.org/challenges/LSVRC/2014/" class="Link-sc-1brdqhf-0 cKRjba">ImageNet Object Detection Challenge</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://mscoco.org/" class="Link-sc-1brdqhf-0 cKRjba">Microsoft COCO</a></li></ul><h6 id="semantic-labeling" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#semantic-labeling" color="auto.gray.8" aria-label="Semantic labeling permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Semantic labeling</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://dags.stanford.edu/projects/scenedataset.html" class="Link-sc-1brdqhf-0 cKRjba">Stanford background dataset</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/" class="Link-sc-1brdqhf-0 cKRjba">CamVid</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.unc.edu/~jtighe/Papers/ECCV10/" class="Link-sc-1brdqhf-0 cKRjba">Barcelona Dataset</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.unc.edu/~jtighe/Papers/ECCV10/siftflow/SiftFlowDataset.zip" class="Link-sc-1brdqhf-0 cKRjba">SIFT Flow Dataset</a></li></ul><h6 id="multi-view-object-detection" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#multi-view-object-detection" color="auto.gray.8" aria-label="Multi-view Object Detection permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Multi-view Object Detection</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://cvgl.stanford.edu/resources.html" class="Link-sc-1brdqhf-0 cKRjba">3D Object Dataset</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://cvlab.epfl.ch/data/pose" class="Link-sc-1brdqhf-0 cKRjba">EPFL Car Dataset</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cvlibs.net/datasets/kitti/eval_object.php" class="Link-sc-1brdqhf-0 cKRjba">KTTI Dection Dataset</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://sun3d.cs.princeton.edu/" class="Link-sc-1brdqhf-0 cKRjba">SUN 3D Dataset</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://cvgl.stanford.edu/projects/pascal3d.html" class="Link-sc-1brdqhf-0 cKRjba">PASCAL 3D+</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://nyc3d.cs.cornell.edu/" class="Link-sc-1brdqhf-0 cKRjba">NYU Car Dataset</a></li></ul><h6 id="fine-grained-visual-recognition" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#fine-grained-visual-recognition" color="auto.gray.8" aria-label="Fine-grained Visual Recognition permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Fine-grained Visual Recognition</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="https://sites.google.com/site/fgcomp2013/" class="Link-sc-1brdqhf-0 cKRjba">Fine-grained Classification Challenge</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.vision.caltech.edu/visipedia/CUB-200.html" class="Link-sc-1brdqhf-0 cKRjba">Caltech-UCSD Birds 200</a></li></ul><h6 id="pedestrian-detection" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#pedestrian-detection" color="auto.gray.8" aria-label="Pedestrian Detection permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Pedestrian Detection</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/" class="Link-sc-1brdqhf-0 cKRjba">Caltech Pedestrian Detection Benchmark</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://data.vision.ee.ethz.ch/cvl/aess/dataset/" class="Link-sc-1brdqhf-0 cKRjba">ETHZ Pedestrian Detection</a></li></ul><h4 id="action-recognition" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#action-recognition" color="auto.gray.8" aria-label="Action Recognition permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Action Recognition</h4><h6 id="image-based" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#image-based" color="auto.gray.8" aria-label="Image-based permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Image-based</h6><h6 id="video-based" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#video-based" color="auto.gray.8" aria-label="Video-based permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Video-based</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.di.ens.fr/~laptev/actions/hollywood2/" class="Link-sc-1brdqhf-0 cKRjba">HOLLYWOOD2 Dataset</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://crcv.ucf.edu/data/UCF_Sports_Action.php" class="Link-sc-1brdqhf-0 cKRjba">UCF Sports Action Data Set</a></li></ul><h6 id="image-deblurring-1" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH6-sc-1fu06k9-6 ffNRvO gCPbFb gEWVYQ Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#image-deblurring" color="auto.gray.8" aria-label="Image Deblurring permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Image Deblurring</h6><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://cs.brown.edu/~lbsun/deblur2013/deblur2013iccp.html" class="Link-sc-1brdqhf-0 cKRjba">Sun dataset</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.wisdom.weizmann.ac.il/~levina/papers/LevinEtalCVPR09Data.rar" class="Link-sc-1brdqhf-0 cKRjba">Levin dataset</a></li></ul><h4 id="image-captioning-1" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#image-captioning" color="auto.gray.8" aria-label="Image Captioning permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Image Captioning</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/KCCA.html" class="Link-sc-1brdqhf-0 cKRjba">Flickr 8K</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://shannon.cs.illinois.edu/DenotationGraph/" class="Link-sc-1brdqhf-0 cKRjba">Flickr 30K</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://mscoco.org/" class="Link-sc-1brdqhf-0 cKRjba">Microsoft COCO</a></li></ul><h4 id="scene-understanding" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#scene-understanding" color="auto.gray.8" aria-label="Scene Understanding permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Scene Understanding</h4><h1 id="sun-rgb-d---a-rgb-d-scene-understanding-benchmark-suite" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#sun-rgb-d---a-rgb-d-scene-understanding-benchmark-suite" color="auto.gray.8" aria-label="SUN RGB-D - A RGB-D Scene Understanding Benchmark Suite permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><a target="_blank" rel="noopener noreferrer" href="http://rgbd.cs.princeton.edu/" class="Link-sc-1brdqhf-0 cKRjba">SUN RGB-D</a> - A RGB-D Scene Understanding Benchmark Suite</h1><h1 id="nyu-depth-v2---indoor-segmentation-and-support-inference-from-rgbd-images" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#nyu-depth-v2---indoor-segmentation-and-support-inference-from-rgbd-images" color="auto.gray.8" aria-label="NYU depth v2 - Indoor Segmentation and Support Inference from RGBD Images permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><a target="_blank" rel="noopener noreferrer" href="http://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html" class="Link-sc-1brdqhf-0 cKRjba">NYU depth v2</a> - Indoor Segmentation and Support Inference from RGBD Images</h1><h4 id="aerial-images" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#aerial-images" color="auto.gray.8" aria-label="Aerial images permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Aerial images</h4><h1 id="aerial-image-segmentation---learning-aerial-image-segmentation-from-online-maps" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#aerial-image-segmentation---learning-aerial-image-segmentation-from-online-maps" color="auto.gray.8" aria-label="Aerial Image Segmentation - Learning Aerial Image Segmentation From Online Maps permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><a target="_blank" rel="noopener noreferrer" href="https://zenodo.org/record/1154821#.WmN9kHWnHIp" class="Link-sc-1brdqhf-0 cKRjba">Aerial Image Segmentation</a> - Learning Aerial Image Segmentation From Online Maps</h1><h2 id="resources-for-students" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#resources-for-students" color="auto.gray.8" aria-label="Resources for students permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Resources for students</h2><h4 id="resource-link-collection" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#resource-link-collection" color="auto.gray.8" aria-label="Resource link collection permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Resource link collection</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://people.csail.mit.edu/fredo/student.html" class="Link-sc-1brdqhf-0 cKRjba">Resources for students</a> - Frédo Durand (MIT)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.dgp.toronto.edu/~hertzman/advice/" class="Link-sc-1brdqhf-0 cKRjba">Advice for Graduate Students</a> - Aaron Hertzmann (Adobe Research)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.dgp.toronto.edu/~hertzman/courses/gradSkills/2010/" class="Link-sc-1brdqhf-0 cKRjba">Graduate Skills Seminars</a> - Yashar Ganjali, Aaron Hertzmann (University of Toronto)</li><li><a target="_blank" rel="noopener noreferrer" href="http://research.microsoft.com/en-us/um/people/simonpj/papers/giving-a-talk/giving-a-talk.htm" class="Link-sc-1brdqhf-0 cKRjba">Research Skills</a> - Simon Peyton Jones (Microsoft Research)</li><li><a target="_blank" rel="noopener noreferrer" href="http://web.engr.illinois.edu/~taoxie/advice.htm" class="Link-sc-1brdqhf-0 cKRjba">Resource collection</a> - Tao Xie (UIUC) and Yuan Xie (UCSB)</li></ul><h4 id="writing" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#writing" color="auto.gray.8" aria-label="Writing permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Writing</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://people.csail.mit.edu/fredo/FredoGoodWriting.pdf" class="Link-sc-1brdqhf-0 cKRjba">Write Good Papers</a> - Frédo Durand (MIT)</li><li><a target="_blank" rel="noopener noreferrer" href="http://people.csail.mit.edu/fredo/PUBLI/writing.pdf" class="Link-sc-1brdqhf-0 cKRjba">Notes on writing</a> - Frédo Durand (MIT)</li><li><a target="_blank" rel="noopener noreferrer" href="http://people.csail.mit.edu/fredo/FredoBadWriting.pdf" class="Link-sc-1brdqhf-0 cKRjba">How to Write a Bad Article</a> - Frédo Durand (MIT)</li><li><a target="_blank" rel="noopener noreferrer" href="http://billf.mit.edu/sites/default/files/documents/cvprPapers.pdf" class="Link-sc-1brdqhf-0 cKRjba">How to write a good CVPR submission</a> - William T. Freeman (MIT)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=g3dkRsTqdDA" class="Link-sc-1brdqhf-0 cKRjba">How to write a great research paper</a> - Simon Peyton Jones (Microsoft Research)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.slideshare.net/jdily/how-to-write-a-siggraph-paper" class="Link-sc-1brdqhf-0 cKRjba">How to write a SIGGRAPH paper</a> - SIGGRAPH ASIA 2011 Course</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.dgp.toronto.edu/~hertzman/advice/writing-technical-papers.pdf" class="Link-sc-1brdqhf-0 cKRjba">Writing Research Papers</a> - Aaron Hertzmann (Adobe Research)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.computer.org/csdl/mags/cg/1987/12/mcg1987120062.pdf" class="Link-sc-1brdqhf-0 cKRjba">How to Write a Paper for SIGGRAPH</a> - Jim Blinn</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.siggraph.org/sites/default/files/kajiya.pdf" class="Link-sc-1brdqhf-0 cKRjba">How to Get Your SIGGRAPH Paper Rejected</a> - Jim Kajiya (Microsoft Research)</li><li><a class="Link-sc-1brdqhf-0 cKRjba" href="/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/www.liyiwei.org/courses/how-siga11/liyiwei.pptx/">How to write a SIGGRAPH paper</a> - Li-Yi Wei (The University of Hong Kong)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www-hagen.informatik.uni-kl.de/~bertram/talks/getpublished.pdf" class="Link-sc-1brdqhf-0 cKRjba">How to Write a Great Paper</a> - Martin Martin Hering Hering--Bertram (Hochschule Bremen University of Applied Sciences)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www-ui.is.s.u-tokyo.ac.jp/~takeo/writings/siggraph.html" class="Link-sc-1brdqhf-0 cKRjba">How to have a paper get into SIGGRAPH?</a> - Takeo Igarashi (The University of Tokyo)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.cmu.edu/~pausch/Randy/Randy/raibert.htm" class="Link-sc-1brdqhf-0 cKRjba">Good Writing</a> - Marc H. Raibert (Boston Dynamics, Inc.)</li><li><a target="_blank" rel="noopener noreferrer" href="http://web.engr.illinois.edu/~dhoiem/presentations/How%20to%20Write%20a%20Computer%20Vison%20Paper.ppt" class="Link-sc-1brdqhf-0 cKRjba">How to Write a Computer Vision Paper</a> - Derek Hoiem (UIUC)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.dartmouth.edu/~wjarosz/writing.html" class="Link-sc-1brdqhf-0 cKRjba">Common mistakes in technical writing</a> - Wojciech Jarosz (Dartmouth College)</li></ul><h4 id="presentation" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#presentation" color="auto.gray.8" aria-label="Presentation permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Presentation</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://people.csail.mit.edu/fredo/TalkAdvice.pdf" class="Link-sc-1brdqhf-0 cKRjba">Giving a Research Talk</a> - Frédo Durand (MIT)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.dgp.toronto.edu/~hertzman/courses/gradSkills/2010/GivingGoodTalks.pdf" class="Link-sc-1brdqhf-0 cKRjba">How to give a good talk</a> - David Fleet (University of Toronto) and Aaron Hertzmann (Adobe Research)</li><li><a target="_blank" rel="noopener noreferrer" href="http://colinpurrington.com/tips/poster-design" class="Link-sc-1brdqhf-0 cKRjba">Designing conference posters</a> - Colin Purrington</li></ul><h4 id="research" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#research" color="auto.gray.8" aria-label="Research permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Research</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://people.csail.mit.edu/billf/www/papers/doresearch.pdf" class="Link-sc-1brdqhf-0 cKRjba">How to do research</a> - William T. Freeman (MIT)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.virginia.edu/~robins/YouAndYourResearch.html" class="Link-sc-1brdqhf-0 cKRjba">You and Your Research</a> - Richard Hamming</li><li><a target="_blank" rel="noopener noreferrer" href="http://yima.csl.illinois.edu/psfile/bogus.pdf" class="Link-sc-1brdqhf-0 cKRjba">Warning Signs of Bogus Progress in Research in an Age of Rich Computation and Information</a> - Yi Ma (UIUC)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.quackwatch.com/01QuackeryRelatedTopics/signs.html" class="Link-sc-1brdqhf-0 cKRjba">Seven Warning Signs of Bogus Science</a> - Robert L. Park</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=v2Qaf8t8I6c" class="Link-sc-1brdqhf-0 cKRjba">Five Principles for Choosing Research Problems in Computer Graphics</a> - Thomas Funkhouser (Cornell University)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.indiana.edu/mit.research.how.to.html" class="Link-sc-1brdqhf-0 cKRjba">How To Do Research In the MIT AI Lab</a> - David Chapman (MIT)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.slideshare.net/antiw/recent-advances-in-computer-vision" class="Link-sc-1brdqhf-0 cKRjba">Recent Advances in Computer Vision</a> - Ming-Hsuan Yang (UC Merced)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.slideshare.net/jbhuang/how-to-come-up-with-new-research-ideas-4005840" class="Link-sc-1brdqhf-0 cKRjba">How to Come Up with Research Ideas in Computer Vision?</a> - Jia-Bin Huang (UIUC)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.slideshare.net/jbhuang/how-to-read-academic-papers" class="Link-sc-1brdqhf-0 cKRjba">How to Read Academic Papers</a> - Jia-Bin Huang (UIUC)</li></ul><h4 id="time-management" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH4-sc-1fu06k9-4 ffNRvO gCPbFb vaKyq Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#time-management" color="auto.gray.8" aria-label="Time Management permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Time Management</h4><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=oTugjssqOT0" class="Link-sc-1brdqhf-0 cKRjba">Time Management</a> - Randy Pausch (CMU)</li></ul><h2 id="blogs" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#blogs" color="auto.gray.8" aria-label="Blogs permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Blogs</h2><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.learnopencv.com/" class="Link-sc-1brdqhf-0 cKRjba">Learn OpenCV</a> - Satya Mallick</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.computervisionblog.com/" class="Link-sc-1brdqhf-0 cKRjba">Tombone&#x27;s Computer Vision Blog</a> - Tomasz Malisiewicz</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.visiondummy.com/" class="Link-sc-1brdqhf-0 cKRjba">Computer vision for dummies</a> - Vincent Spruyt</li><li><a target="_blank" rel="noopener noreferrer" href="http://karpathy.github.io/" class="Link-sc-1brdqhf-0 cKRjba">Andrej Karpathy blog</a> - Andrej Karpathy</li><li><a target="_blank" rel="noopener noreferrer" href="http://aishack.in/" class="Link-sc-1brdqhf-0 cKRjba">AI Shack</a> - Utkarsh Sinha</li><li><a target="_blank" rel="noopener noreferrer" href="http://computer-vision-talks.com/" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision Talks</a> - Eugene Khvedchenya</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/jrobchin/Computer-Vision-Basics-with-Python-Keras-and-OpenCV" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision Basics with Python Keras and OpenCV</a> - Jason Chin (University of Western Ontario)</li></ul><h2 id="links" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#links" color="auto.gray.8" aria-label="Links permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Links</h2><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.ubc.ca/~lowe/vision.html" class="Link-sc-1brdqhf-0 cKRjba">The Computer Vision Industry</a> - David Lowe</li><li><a target="_blank" rel="noopener noreferrer" href="http://hci.iwr.uni-heidelberg.de/Links/German_Vision/" class="Link-sc-1brdqhf-0 cKRjba">German Computer Vision Research Groups &amp; Companies</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/ChristosChristofidis/awesome-deep-learning" class="Link-sc-1brdqhf-0 cKRjba">awesome-deep-learning</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/josephmisiti/awesome-machine-learning" class="Link-sc-1brdqhf-0 cKRjba">awesome-machine-learning</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.eecs.berkeley.edu/~junyanz/cat/cat_papers.html" class="Link-sc-1brdqhf-0 cKRjba">Cat Paper Collection</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.rsipvision.com/computer-vision-news/" class="Link-sc-1brdqhf-0 cKRjba">Computer Vision News</a></li><li></li></ul><h2 id="songs" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#songs" color="auto.gray.8" aria-label="Songs permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Songs</h2><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><a target="_blank" rel="noopener noreferrer" href="http://danielwedge.com/fmatrix/" class="Link-sc-1brdqhf-0 cKRjba">The Fundamental Matrix Song</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://danielwedge.com/ransac/" class="Link-sc-1brdqhf-0 cKRjba">The RANSAC Song</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=DQWI1kvmwRg" class="Link-sc-1brdqhf-0 cKRjba">Machine Learning A Cappella - Overfitting Thriller</a></li></ul><h2 id="licenses" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#licenses" color="auto.gray.8" aria-label="Licenses permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Licenses</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl">License</p><a target="_blank" rel="noopener noreferrer" href="http://creativecommons.org/publicdomain/zero/1.0/" class="Link-sc-1brdqhf-0 cKRjba"><img src="http://i.creativecommons.org/p/zero/1.0/88x31.png" alt="CC0" class="image__Image-sc-1r30dtv-0 elBfYx"/></a><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl">To the extent possible under law, <a class="Link-sc-1brdqhf-0 cKRjba" href="/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/www.jiabinhuang.com/">Jia-Bin Huang</a> has waived all copyright and related or neighboring rights to this work.</p><div class="Box-nv15kw-0 ksEcN"><div display="flex" class="Box-nv15kw-0 jsSpbO"><a href="https://github.com/webizenai/devdocs/tree/main/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-computer-vision.md" class="Link-sc-1brdqhf-0 iLYDsn"><svg aria-hidden="true" role="img" class="StyledOcticon-uhnt7w-0 fafffn" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M11.013 1.427a1.75 1.75 0 012.474 0l1.086 1.086a1.75 1.75 0 010 2.474l-8.61 8.61c-.21.21-.47.364-.756.445l-3.251.93a.75.75 0 01-.927-.928l.929-3.25a1.75 1.75 0 01.445-.758l8.61-8.61zm1.414 1.06a.25.25 0 00-.354 0L10.811 3.75l1.439 1.44 1.263-1.263a.25.25 0 000-.354l-1.086-1.086zM11.189 6.25L9.75 4.81l-6.286 6.287a.25.25 0 00-.064.108l-.558 1.953 1.953-.558a.249.249 0 00.108-.064l6.286-6.286z"></path></svg>Edit this page</a><div><span font-size="1" color="auto.gray.7" class="Text-sc-1s3uzov-0 gHwtLv">Last updated on<!-- --> <b>12/30/2022</b></span></div></div></div></div></div></main></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script async="" src="https://www.googletagmanager.com/gtag/js?id="></script><script>
      
      
      if(true) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){window.dataLayer && window.dataLayer.push(arguments);}
        gtag('js', new Date());

        
      }
      </script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/old-work-archives/2018-webizen-net-au/resource-library/awesomeLists/awesome-computer-vision/";window.___webpackCompilationHash="10c8b9c1f9dde870e591";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-2526e2a471eef3b9c3b2.js"],"app":["/app-f28009dab402ccf9360c.js"],"component---node-modules-gatsby-theme-primer-wiki-src-pages-404-js":["/component---node-modules-gatsby-theme-primer-wiki-src-pages-404-js-bd1c4b7f67a97d4f99af.js"],"component---node-modules-gatsby-theme-primer-wiki-src-templates-latest-query-js":["/component---node-modules-gatsby-theme-primer-wiki-src-templates-latest-query-js-6ed623c5d829c1a69525.js"],"component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js":["/component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js-46274f1a3983fff8a36b.js"]};/*]]>*/</script><script src="/polyfill-2526e2a471eef3b9c3b2.js" nomodule=""></script><script src="/component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js-46274f1a3983fff8a36b.js" async=""></script><script src="/commons-c89ede6cb9a530ac5a37.js" async=""></script><script src="/app-f28009dab402ccf9360c.js" async=""></script><script src="/dc6a8720040df98778fe970bf6c000a41750d3ae-8fdfd959b24cacbf7cee.js" async=""></script><script src="/0e226fb0-1cb0709e5ed968a9c435.js" async=""></script><script src="/f0e45107-3309acb69b4ccd30ce0c.js" async=""></script><script src="/framework-6c63f85700e5678d2c2a.js" async=""></script><script src="/webpack-runtime-1fe3daf7582b39746d36.js" async=""></script></body></html>