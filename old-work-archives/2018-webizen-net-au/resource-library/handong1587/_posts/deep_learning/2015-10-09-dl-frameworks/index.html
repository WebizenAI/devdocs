<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta data-react-helmet="true" name="twitter:image:alt" content="This repo provides information about the webizen development objectives, considerations and related experimentation!"/><meta data-react-helmet="true" name="twitter:image" content="https://devdocs.webizen.org/graph-visualisation.jpg"/><meta data-react-helmet="true" name="twitter:description" content="Amazon DSSTNE Amazon DSSTNE: Deep Scalable Sparse Tensor Network Engine intro: Deep Scalable Sparse Tensor Network Engine (DSSTNE) is an Am…"/><meta data-react-helmet="true" name="twitter:title" content="Deep Learning Frameworks"/><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"/><meta data-react-helmet="true" property="article:section" content="None"/><meta data-react-helmet="true" property="article:author" content="http://examples.opengraphprotocol.us/profile.html"/><meta data-react-helmet="true" property="article:modified_time" content="2022-12-28T19:22:29.000Z"/><meta data-react-helmet="true" property="article:published_time" content="2015-10-09T00:00:00.000Z"/><meta data-react-helmet="true" property="og:description" content="Amazon DSSTNE Amazon DSSTNE: Deep Scalable Sparse Tensor Network Engine intro: Deep Scalable Sparse Tensor Network Engine (DSSTNE) is an Am…"/><meta data-react-helmet="true" property="og:site_name"/><meta data-react-helmet="true" property="og:image:alt" content="This repo provides information about the webizen development objectives, considerations and related experimentation!"/><meta data-react-helmet="true" property="og:image" content="https://devdocs.webizen.org/graph-visualisation.jpg"/><meta data-react-helmet="true" property="og:url" content="https://devdocs.webizen.org/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-frameworks/"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:title" content="Deep Learning Frameworks"/><meta data-react-helmet="true" name="image" content="https://devdocs.webizen.org/graph-visualisation.jpg"/><meta data-react-helmet="true" name="description" content="Amazon DSSTNE Amazon DSSTNE: Deep Scalable Sparse Tensor Network Engine intro: Deep Scalable Sparse Tensor Network Engine (DSSTNE) is an Am…"/><meta name="generator" content="Gatsby 4.6.0"/><style data-href="/styles.d9e480e5c6375621c4fd.css" data-identity="gatsby-global-css">.tippy-box[data-animation=fade][data-state=hidden]{opacity:0}[data-tippy-root]{max-width:calc(100vw - 10px)}.tippy-box{background-color:#333;border-radius:4px;color:#fff;font-size:14px;line-height:1.4;outline:0;position:relative;transition-property:visibility,opacity,-webkit-transform;transition-property:transform,visibility,opacity;transition-property:transform,visibility,opacity,-webkit-transform;white-space:normal}.tippy-box[data-placement^=top]>.tippy-arrow{bottom:0}.tippy-box[data-placement^=top]>.tippy-arrow:before{border-top-color:initial;border-width:8px 8px 0;bottom:-7px;left:0;-webkit-transform-origin:center top;transform-origin:center top}.tippy-box[data-placement^=bottom]>.tippy-arrow{top:0}.tippy-box[data-placement^=bottom]>.tippy-arrow:before{border-bottom-color:initial;border-width:0 8px 8px;left:0;top:-7px;-webkit-transform-origin:center bottom;transform-origin:center bottom}.tippy-box[data-placement^=left]>.tippy-arrow{right:0}.tippy-box[data-placement^=left]>.tippy-arrow:before{border-left-color:initial;border-width:8px 0 8px 8px;right:-7px;-webkit-transform-origin:center left;transform-origin:center left}.tippy-box[data-placement^=right]>.tippy-arrow{left:0}.tippy-box[data-placement^=right]>.tippy-arrow:before{border-right-color:initial;border-width:8px 8px 8px 0;left:-7px;-webkit-transform-origin:center right;transform-origin:center right}.tippy-box[data-inertia][data-state=visible]{transition-timing-function:cubic-bezier(.54,1.5,.38,1.11)}.tippy-arrow{color:#333;height:16px;width:16px}.tippy-arrow:before{border-color:transparent;border-style:solid;content:"";position:absolute}.tippy-content{padding:5px 9px;position:relative;z-index:1}.tippy-box[data-theme~=light]{background-color:#fff;box-shadow:0 0 20px 4px rgba(154,161,177,.15),0 4px 80px -8px rgba(36,40,47,.25),0 4px 4px -2px rgba(91,94,105,.15);color:#26323d}.tippy-box[data-theme~=light][data-placement^=top]>.tippy-arrow:before{border-top-color:#fff}.tippy-box[data-theme~=light][data-placement^=bottom]>.tippy-arrow:before{border-bottom-color:#fff}.tippy-box[data-theme~=light][data-placement^=left]>.tippy-arrow:before{border-left-color:#fff}.tippy-box[data-theme~=light][data-placement^=right]>.tippy-arrow:before{border-right-color:#fff}.tippy-box[data-theme~=light]>.tippy-backdrop{background-color:#fff}.tippy-box[data-theme~=light]>.tippy-svg-arrow{fill:#fff}html{font-family:SF Pro SC,SF Pro Text,SF Pro Icons,PingFang SC,Helvetica Neue,Helvetica,Arial,sans-serif}body{word-wrap:break-word;-ms-hyphens:auto;-webkit-hyphens:auto;hyphens:auto;overflow-wrap:break-word;-ms-word-break:break-all;word-break:break-word}blockquote,body,dd,dt,fieldset,figure,h1,h2,h3,h4,h5,h6,hr,html,iframe,legend,p,pre,textarea{margin:0;padding:0}h1,h2,h3,h4,h5,h6{font-size:100%;font-weight:400}button,input,select{margin:0}html{box-sizing:border-box}*,:after,:before{box-sizing:inherit}img,video{height:auto;max-width:100%}iframe{border:0}table{border-collapse:collapse;border-spacing:0}td,th{padding:0}</style><style data-styled="" data-styled-version="5.3.5">.fnAJEh{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;font-size:14px;background-color:#005cc5;color:#ffffff;padding:16px;}/*!sc*/
.fnAJEh:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.fnAJEh:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.czsBQU{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;color:#ffffff;margin-right:16px;}/*!sc*/
.czsBQU:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.czsBQU:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.kLOWMo{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;font-family:SFMono-Regular,Consolas,"Liberation Mono",Menlo,Courier,monospace;color:#ffffff;}/*!sc*/
.kLOWMo:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.kLOWMo:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.kEUvCO{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;display:block;color:inherit;margin-left:24px;}/*!sc*/
.kEUvCO:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.kEUvCO:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.HGjBQ{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;display:block;}/*!sc*/
.HGjBQ:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.HGjBQ:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.fdzjHV{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;color:#24292e;display:block;}/*!sc*/
.fdzjHV:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.fdzjHV:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.bQLMRL{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;font-size:16px;display:inline-block;padding-top:4px;padding-bottom:4px;color:#586069;font-weight:medium;}/*!sc*/
.bQLMRL:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.bQLMRL:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){.bQLMRL{font-size:14px;}}/*!sc*/
.ekSqTm{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;padding:8px;margin-left:-32px;color:#2f363d;}/*!sc*/
.ekSqTm:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.ekSqTm:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.cKRjba{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
.cKRjba:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.cKRjba:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.iLYDsn{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;margin-bottom:4px;}/*!sc*/
.iLYDsn:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.iLYDsn:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
data-styled.g1[id="Link-sc-1brdqhf-0"]{content:"fnAJEh,czsBQU,kLOWMo,kEUvCO,HGjBQ,fdzjHV,bQLMRL,ekSqTm,cKRjba,iLYDsn,"}/*!sc*/
.EuMgV{z-index:20;width:auto;height:auto;-webkit-clip:auto;clip:auto;position:absolute;overflow:hidden;}/*!sc*/
.EuMgV:not(:focus){-webkit-clip:rect(1px,1px,1px,1px);clip:rect(1px,1px,1px,1px);-webkit-clip-path:inset(50%);clip-path:inset(50%);height:1px;width:1px;margin:-1px;padding:0;}/*!sc*/
data-styled.g2[id="skip-link__SkipLink-sc-1z0kjxc-0"]{content:"EuMgV,"}/*!sc*/
.fbaWCe{display:none;margin-left:8px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.fbaWCe{display:inline;}}/*!sc*/
.bLwTGz{font-weight:600;display:inline-block;margin-bottom:4px;}/*!sc*/
.cQAYyE{font-weight:600;}/*!sc*/
.gHwtLv{font-size:14px;color:#444d56;margin-top:4px;}/*!sc*/
data-styled.g4[id="Text-sc-1s3uzov-0"]{content:"fbaWCe,bLwTGz,cQAYyE,gHwtLv,"}/*!sc*/
.ifkhtm{background-color:#ffffff;color:#24292e;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;min-height:100vh;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}/*!sc*/
.gSrgIV{top:0;z-index:1;position:-webkit-sticky;position:sticky;}/*!sc*/
.iTlzRc{padding-left:16px;padding-right:16px;background-color:#24292e;color:rgba(255,255,255,0.7);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:66px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.iTlzRc{padding-left:24px;padding-right:24px;}}/*!sc*/
.kCrfOd{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.gELiHA{margin-left:24px;display:none;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.gELiHA{display:block;}}/*!sc*/
.gYHnkh{position:relative;}/*!sc*/
.dMFMzl{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/
.jhCmHN{display:none;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.jhCmHN{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}/*!sc*/
.elXfHl{color:rgba(255,255,255,0.7);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.gjFLbZ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.gjFLbZ{display:none;}}/*!sc*/
.gucKKf{color:rgba(255,255,255,0.7);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:0;background-color:none;cursor:pointer;}/*!sc*/
.gucKKf:hover{fill:rgba(255,255,255,0.7);color:rgba(255,255,255,0.7);}/*!sc*/
.gucKKf svg{fill:rgba(255,255,255,0.7);}/*!sc*/
.fBMuRw{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;}/*!sc*/
.bQaVuO{color:#2f363d;background-color:#fafbfc;display:none;height:calc(100vh - 66px);min-width:260px;max-width:360px;position:-webkit-sticky;position:sticky;top:66px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.bQaVuO{display:block;}}/*!sc*/
.eeDmz{height:100%;border-style:solid;border-color:#e1e4e8;border-width:0;border-right-width:1px;border-radius:0;}/*!sc*/
.kSoTbZ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}/*!sc*/
.nElVQ{padding:24px;border-style:solid;border-color:#e1e4e8;border-width:0;border-radius:0;border-top-width:1px;}/*!sc*/
.iXtyim{margin-left:0;padding-top:4px;padding-bottom:4px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;border-style:solid;border-color:#e1e4e8;border-width:0;border-radius:0;border-bottom-width:0;}/*!sc*/
.vaHQm{margin-bottom:4px;margin-top:4px;font-size:14px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
.hIjKHD{color:#586069;font-weight:400;display:block;}/*!sc*/
.icYakO{padding-left:8px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;}/*!sc*/
.jLseWZ{margin-left:16px;padding-top:0;padding-bottom:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;border-style:solid;border-color:#e1e4e8;border-width:0;border-radius:0;border-bottom-width:0;}/*!sc*/
.kRSqJi{margin-bottom:0;margin-top:8px;font-size:14px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
.klfmeZ{max-width:1440px;-webkit-flex:1;-ms-flex:1;flex:1;}/*!sc*/
.TZbDV{padding:24px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;width:100%;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-flex-direction:row-reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse;}/*!sc*/
@media screen and (min-width:544px){.TZbDV{padding:32px;}}/*!sc*/
@media screen and (min-width:768px){.TZbDV{padding:40px;}}/*!sc*/
@media screen and (min-width:1012px){.TZbDV{padding:48px;}}/*!sc*/
.DPDMP{display:none;max-height:calc(100vh - 66px - 24px);position:-webkit-sticky;position:sticky;top:90px;width:220px;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;margin-left:40px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){.DPDMP{display:block;}}/*!sc*/
.gUNLMu{margin:0;padding:0;}/*!sc*/
.bzTeHX{padding-left:0;}/*!sc*/
.bnaGYs{padding-left:16px;}/*!sc*/
.meQBK{width:100%;}/*!sc*/
.fkoaiG{margin-bottom:24px;}/*!sc*/
.biGwYR{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.jYYExC{margin-bottom:32px;background-color:#f6f8fa;display:block;border-width:1px;border-style:solid;border-color:#e1e4e8;border-radius:6px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){.jYYExC{display:none;}}/*!sc*/
.hgiZBa{padding:16px;}/*!sc*/
.hnQOQh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.gEqaxf{padding:16px;border-top:1px solid;border-color:border.gray;}/*!sc*/
.ksEcN{margin-top:64px;padding-top:32px;padding-bottom:32px;border-style:solid;border-color:#e1e4e8;border-width:0;border-top-width:1px;border-radius:0;}/*!sc*/
.jsSpbO{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
data-styled.g5[id="Box-nv15kw-0"]{content:"ifkhtm,gSrgIV,iTlzRc,kCrfOd,gELiHA,gYHnkh,dMFMzl,jhCmHN,elXfHl,gjFLbZ,gucKKf,fBMuRw,bQaVuO,eeDmz,kSoTbZ,nElVQ,iXtyim,vaHQm,hIjKHD,icYakO,jLseWZ,kRSqJi,klfmeZ,TZbDV,DPDMP,gUNLMu,bzTeHX,bnaGYs,meQBK,fkoaiG,biGwYR,jYYExC,hgiZBa,hnQOQh,gEqaxf,ksEcN,jsSpbO,"}/*!sc*/
.cjGjQg{position:relative;display:inline-block;padding:6px 16px;font-family:inherit;font-weight:600;line-height:20px;white-space:nowrap;vertical-align:middle;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;border-radius:6px;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;font-size:14px;}/*!sc*/
.cjGjQg:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
.cjGjQg:focus{outline:none;}/*!sc*/
.cjGjQg:disabled{cursor:default;}/*!sc*/
.cjGjQg:disabled svg{opacity:0.6;}/*!sc*/
data-styled.g6[id="ButtonBase-sc-181ps9o-0"]{content:"cjGjQg,"}/*!sc*/
.fafffn{margin-right:8px;}/*!sc*/
data-styled.g8[id="StyledOcticon-uhnt7w-0"]{content:"bhRGQB,fafffn,"}/*!sc*/
.fTkTnC{font-weight:600;font-size:32px;margin:0;font-size:12px;font-weight:500;color:#959da5;margin-bottom:4px;text-transform:uppercase;font-family:Content-font,Roboto,sans-serif;}/*!sc*/
.glhHOU{font-weight:600;font-size:32px;margin:0;margin-right:8px;}/*!sc*/
.ffNRvO{font-weight:600;font-size:32px;margin:0;}/*!sc*/
data-styled.g12[id="Heading-sc-1cjoo9h-0"]{content:"fTkTnC,glhHOU,ffNRvO,"}/*!sc*/
.ifFLoZ{color:#0366d6;border:1px solid rgba(27,31,35,0.15);background-color:#fafbfc;box-shadow:0 1px 0 rgba(27,31,35,0.04);margin-left:16px;}/*!sc*/
.ifFLoZ:hover{color:#ffffff;background-color:#0366d6;border-color:rgba(27,31,35,0.15);box-shadow:0 1px 0 rgba(27,31,35,0.1);}/*!sc*/
.ifFLoZ:focus{border-color:rgba(27,31,35,0.15);box-shadow:0 0 0 3px rgba(0,92,197,0.4);}/*!sc*/
.ifFLoZ:active{color:#ffffff;background-color:hsla(212,97%,40%,1);box-shadow:inset 0 1px 0 rgba(5,38,76,0.2);border-color:rgba(27,31,35,0.15);}/*!sc*/
.ifFLoZ:disabled{color:rgba(3,102,214,0.5);background-color:#fafbfc;border-color:rgba(27,31,35,0.15);}/*!sc*/
.fKTxJr{color:#0366d6;border:1px solid rgba(27,31,35,0.15);background-color:#fafbfc;box-shadow:0 1px 0 rgba(27,31,35,0.04);}/*!sc*/
.fKTxJr:hover{color:#ffffff;background-color:#0366d6;border-color:rgba(27,31,35,0.15);box-shadow:0 1px 0 rgba(27,31,35,0.1);}/*!sc*/
.fKTxJr:focus{border-color:rgba(27,31,35,0.15);box-shadow:0 0 0 3px rgba(0,92,197,0.4);}/*!sc*/
.fKTxJr:active{color:#ffffff;background-color:hsla(212,97%,40%,1);box-shadow:inset 0 1px 0 rgba(5,38,76,0.2);border-color:rgba(27,31,35,0.15);}/*!sc*/
.fKTxJr:disabled{color:rgba(3,102,214,0.5);background-color:#fafbfc;border-color:rgba(27,31,35,0.15);}/*!sc*/
.cXFtEt{color:#0366d6;border:1px solid rgba(27,31,35,0.15);background-color:#fafbfc;box-shadow:0 1px 0 rgba(27,31,35,0.04);margin-left:16px;}/*!sc*/
.cXFtEt:hover{color:#ffffff;background-color:#0366d6;border-color:rgba(27,31,35,0.15);box-shadow:0 1px 0 rgba(27,31,35,0.1);}/*!sc*/
.cXFtEt:focus{border-color:rgba(27,31,35,0.15);box-shadow:0 0 0 3px rgba(0,92,197,0.4);}/*!sc*/
.cXFtEt:active{color:#ffffff;background-color:hsla(212,97%,40%,1);box-shadow:inset 0 1px 0 rgba(5,38,76,0.2);border-color:rgba(27,31,35,0.15);}/*!sc*/
.cXFtEt:disabled{color:rgba(3,102,214,0.5);background-color:#fafbfc;border-color:rgba(27,31,35,0.15);}/*!sc*/
data-styled.g13[id="ButtonOutline-sc-15gta9l-0"]{content:"ifFLoZ,fKTxJr,cXFtEt,"}/*!sc*/
.iEGqHu{color:rgba(255,255,255,0.7);background-color:transparent;border:1px solid #444d56;box-shadow:none;}/*!sc*/
data-styled.g14[id="dark-button__DarkButton-sc-bvvmfe-0"]{content:"iEGqHu,"}/*!sc*/
.ljCWQd{border:0;font-size:inherit;font-family:inherit;background-color:transparent;-webkit-appearance:none;color:inherit;width:100%;}/*!sc*/
.ljCWQd:focus{outline:0;}/*!sc*/
data-styled.g15[id="TextInput__Input-sc-1apmpmt-0"]{content:"ljCWQd,"}/*!sc*/
.dHfzvf{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;min-height:34px;font-size:14px;line-height:20px;color:#24292e;vertical-align:middle;background-repeat:no-repeat;background-position:right 8px center;border:1px solid #e1e4e8;border-radius:6px;outline:none;box-shadow:inset 0 1px 0 rgba(225,228,232,0.2);padding:6px 12px;width:240px;}/*!sc*/
.dHfzvf .TextInput-icon{-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;color:#959da5;margin:0 8px;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;}/*!sc*/
.dHfzvf:focus-within{border-color:#0366d6;box-shadow:0 0 0 3px rgba(3,102,214,0.3);}/*!sc*/
@media (min-width:768px){.dHfzvf{font-size:14px;}}/*!sc*/
data-styled.g16[id="TextInput__Wrapper-sc-1apmpmt-1"]{content:"dHfzvf,"}/*!sc*/
.khRwtY{font-size:16px !important;color:rgba(255,255,255,0.7);background-color:rgba(255,255,255,0.07);border:1px solid transparent;box-shadow:none;}/*!sc*/
.khRwtY:focus{border:1px solid #444d56 outline:none;box-shadow:none;}/*!sc*/
data-styled.g17[id="dark-text-input__DarkTextInput-sc-1s2iwzn-0"]{content:"khRwtY,"}/*!sc*/
.bqVpte.active{font-weight:600;color:#2f363d;}/*!sc*/
data-styled.g19[id="nav-items__NavLink-sc-tqz5wl-0"]{content:"bqVpte,"}/*!sc*/
.kEKZhO.active{font-weight:600;color:#2f363d;}/*!sc*/
data-styled.g20[id="nav-items__NavBox-sc-tqz5wl-1"]{content:"kEKZhO,"}/*!sc*/
.gCPbFb{margin-top:24px;margin-bottom:16px;-webkit-scroll-margin-top:90px;-moz-scroll-margin-top:90px;-ms-scroll-margin-top:90px;scroll-margin-top:90px;}/*!sc*/
.gCPbFb .octicon-link{visibility:hidden;}/*!sc*/
.gCPbFb:hover .octicon-link,.gCPbFb:focus-within .octicon-link{visibility:visible;}/*!sc*/
data-styled.g22[id="heading__StyledHeading-sc-1fu06k9-0"]{content:"gCPbFb,"}/*!sc*/
.fGjcEF{margin-top:0;padding-bottom:4px;font-size:32px;border-bottom:1px solid #e1e4e8;}/*!sc*/
data-styled.g23[id="heading__StyledH1-sc-1fu06k9-1"]{content:"fGjcEF,"}/*!sc*/
.fvbkiW{padding-bottom:4px;font-size:24px;border-bottom:1px solid #e1e4e8;}/*!sc*/
data-styled.g24[id="heading__StyledH2-sc-1fu06k9-2"]{content:"fvbkiW,"}/*!sc*/
.elBfYx{max-width:100%;box-sizing:content-box;background-color:#ffffff;}/*!sc*/
data-styled.g30[id="image__Image-sc-1r30dtv-0"]{content:"elBfYx,"}/*!sc*/
.dFVIUa{padding-left:2em;margin-bottom:4px;}/*!sc*/
.dFVIUa ul,.dFVIUa ol{margin-top:0;margin-bottom:0;}/*!sc*/
.dFVIUa li{line-height:1.6;}/*!sc*/
.dFVIUa li > p{margin-top:16px;}/*!sc*/
.dFVIUa li + li{margin-top:8px;}/*!sc*/
data-styled.g32[id="list__List-sc-s5kxp2-0"]{content:"dFVIUa,"}/*!sc*/
.iNQqSl{margin:0 0 16px;}/*!sc*/
data-styled.g34[id="paragraph__Paragraph-sc-17pab92-0"]{content:"iNQqSl,"}/*!sc*/
.drDDht{z-index:0;}/*!sc*/
data-styled.g37[id="layout___StyledBox-sc-7a5ttt-0"]{content:"drDDht,"}/*!sc*/
.flyUPp{list-style:none;}/*!sc*/
data-styled.g39[id="table-of-contents___StyledBox-sc-1jtv948-0"]{content:"flyUPp,"}/*!sc*/
.bPkrfP{grid-area:table-of-contents;overflow:auto;}/*!sc*/
data-styled.g40[id="post-page___StyledBox-sc-17hbw1s-0"]{content:"bPkrfP,"}/*!sc*/
</style><title data-react-helmet="true">Deep Learning Frameworks - Webizen Development Related Documentation.</title><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper picture.object-fit-polyfill{position:static!important}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){if(void 0===e.target.dataset.mainImage)return;if(void 0===e.target.dataset.gatsbyImageSsr)return;const t=e.target;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="icon" href="/favicon-32x32.png?v=202c3b6fa23c481f8badd00dc2119591" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="sitemap" type="application/xml" href="/sitemap/sitemap-index.xml"/><link rel="preconnect" href="https://www.googletagmanager.com"/><link rel="dns-prefetch" href="https://www.googletagmanager.com"/><link as="script" rel="preload" href="/webpack-runtime-1fe3daf7582b39746d36.js"/><link as="script" rel="preload" href="/framework-6c63f85700e5678d2c2a.js"/><link as="script" rel="preload" href="/f0e45107-3309acb69b4ccd30ce0c.js"/><link as="script" rel="preload" href="/0e226fb0-1cb0709e5ed968a9c435.js"/><link as="script" rel="preload" href="/dc6a8720040df98778fe970bf6c000a41750d3ae-8fdfd959b24cacbf7cee.js"/><link as="script" rel="preload" href="/app-f28009dab402ccf9360c.js"/><link as="script" rel="preload" href="/commons-c89ede6cb9a530ac5a37.js"/><link as="script" rel="preload" href="/component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js-46274f1a3983fff8a36b.js"/><link as="fetch" rel="preload" href="/page-data/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-frameworks/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/2230547434.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/2320115945.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/3495835395.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/451533639.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><a class="Link-sc-1brdqhf-0 fnAJEh skip-link__SkipLink-sc-1z0kjxc-0 EuMgV" color="auto.white" href="#skip-nav" font-size="1">Skip to content</a><div display="flex" color="text.primary" class="Box-nv15kw-0 ifkhtm"><div class="Box-nv15kw-0 gSrgIV"><div display="flex" height="66" color="header.text" class="Box-nv15kw-0 iTlzRc"><div display="flex" class="Box-nv15kw-0 kCrfOd"><a color="header.logo" mr="3" class="Link-sc-1brdqhf-0 czsBQU" href="/"><svg aria-hidden="true" role="img" class="StyledOcticon-uhnt7w-0 bhRGQB" viewBox="0 0 16 16" width="32" height="32" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path></svg></a><a color="header.logo" font-family="mono" class="Link-sc-1brdqhf-0 kLOWMo" href="/">Wiki</a><div display="none,,,block" class="Box-nv15kw-0 gELiHA"><div role="combobox" aria-expanded="false" aria-haspopup="listbox" aria-labelledby="downshift-search-label" class="Box-nv15kw-0 gYHnkh"><span class="TextInput__Wrapper-sc-1apmpmt-1 dHfzvf dark-text-input__DarkTextInput-sc-1s2iwzn-0 khRwtY TextInput-wrapper" width="240"><input type="text" aria-autocomplete="list" aria-labelledby="downshift-search-label" autoComplete="off" value="" id="downshift-search-input" placeholder="Search Wiki" class="TextInput__Input-sc-1apmpmt-0 ljCWQd"/></span></div></div></div><div display="flex" class="Box-nv15kw-0 dMFMzl"><div display="none,,,flex" class="Box-nv15kw-0 jhCmHN"><div display="flex" color="header.text" class="Box-nv15kw-0 elXfHl"><a display="block" color="inherit" target="_blank" rel="noopener noreferrer" href="https://github.com/webizenai/devdocs/" class="Link-sc-1brdqhf-0 kEUvCO">Github</a><a display="block" color="inherit" target="_blank" rel="noopener noreferrer" href="https://twitter.com/webcivics" class="Link-sc-1brdqhf-0 kEUvCO">Twitter</a></div><button aria-label="Theme" aria-expanded="false" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 cjGjQg ifFLoZ iEGqHu"><svg aria-hidden="true" role="img" class="octicon octicon-sun" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z"></path></svg></button></div><div display="flex,,,none" class="Box-nv15kw-0 gjFLbZ"><button aria-label="Search" aria-expanded="false" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 cjGjQg fKTxJr iEGqHu"><svg aria-hidden="true" role="img" class="octicon octicon-search" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M11.5 7a4.499 4.499 0 11-8.998 0A4.499 4.499 0 0111.5 7zm-.82 4.74a6 6 0 111.06-1.06l3.04 3.04a.75.75 0 11-1.06 1.06l-3.04-3.04z"></path></svg></button></div><button aria-label="Show Graph Visualisation" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 cjGjQg cXFtEt iEGqHu"><div title="Show Graph Visualisation" aria-label="Show Graph Visualisation" color="header.text" display="flex" class="Box-nv15kw-0 gucKKf"><svg t="1607341341241" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" width="20" height="20"><path d="M512 512m-125.866667 0a125.866667 125.866667 0 1 0 251.733334 0 125.866667 125.866667 0 1 0-251.733334 0Z"></path><path d="M512 251.733333m-72.533333 0a72.533333 72.533333 0 1 0 145.066666 0 72.533333 72.533333 0 1 0-145.066666 0Z"></path><path d="M614.4 238.933333c0 4.266667 2.133333 8.533333 2.133333 12.8 0 19.2-4.266667 36.266667-12.8 51.2 81.066667 36.266667 138.666667 117.333333 138.666667 211.2C742.4 640 640 744.533333 512 744.533333s-230.4-106.666667-230.4-232.533333c0-93.866667 57.6-174.933333 138.666667-211.2-8.533333-14.933333-12.8-32-12.8-51.2 0-4.266667 0-8.533333 2.133333-12.8-110.933333 42.666667-189.866667 147.2-189.866667 273.066667 0 160 130.133333 292.266667 292.266667 292.266666S804.266667 672 804.266667 512c0-123.733333-78.933333-230.4-189.866667-273.066667z"></path><path d="M168.533333 785.066667m-72.533333 0a72.533333 72.533333 0 1 0 145.066667 0 72.533333 72.533333 0 1 0-145.066667 0Z"></path><path d="M896 712.533333m-61.866667 0a61.866667 61.866667 0 1 0 123.733334 0 61.866667 61.866667 0 1 0-123.733334 0Z"></path><path d="M825.6 772.266667c-74.666667 89.6-187.733333 147.2-313.6 147.2-93.866667 0-181.333333-32-249.6-87.466667-10.666667 19.2-25.6 34.133333-44.8 44.8C298.666667 942.933333 401.066667 981.333333 512 981.333333c149.333333 0 281.6-70.4 366.933333-177.066666-21.333333-4.266667-40.533333-17.066667-53.333333-32zM142.933333 684.8c-25.6-53.333333-38.4-110.933333-38.4-172.8C104.533333 288 288 104.533333 512 104.533333S919.466667 288 919.466667 512c0 36.266667-6.4 72.533333-14.933334 106.666667 23.466667 2.133333 42.666667 10.666667 57.6 25.6 12.8-42.666667 19.2-87.466667 19.2-132.266667 0-258.133333-211.2-469.333333-469.333333-469.333333S42.666667 253.866667 42.666667 512c0 74.666667 17.066667 142.933333 46.933333 204.8 14.933333-14.933333 32-27.733333 53.333333-32z"></path></svg><span display="none,,,inline" class="Text-sc-1s3uzov-0 fbaWCe">Show Graph Visualisation</span></div></button><div display="flex,,,none" class="Box-nv15kw-0 gjFLbZ"><button aria-label="Menu" aria-expanded="false" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 cjGjQg ifFLoZ iEGqHu"><svg aria-hidden="true" role="img" class="octicon octicon-three-bars" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M1 2.75A.75.75 0 011.75 2h12.5a.75.75 0 110 1.5H1.75A.75.75 0 011 2.75zm0 5A.75.75 0 011.75 7h12.5a.75.75 0 110 1.5H1.75A.75.75 0 011 7.75zM1.75 12a.75.75 0 100 1.5h12.5a.75.75 0 100-1.5H1.75z"></path></svg></button></div></div></div></div><div display="flex" class="Box-nv15kw-0 layout___StyledBox-sc-7a5ttt-0 fBMuRw drDDht"><div display="none,,,block" height="calc(100vh - 66px)" color="auto.gray.8" class="Box-nv15kw-0 bQaVuO"><div height="100%" style="overflow:auto" class="Box-nv15kw-0 eeDmz"><div display="flex" class="Box-nv15kw-0 kSoTbZ"><div class="Box-nv15kw-0 nElVQ"><div display="flex" class="Box-nv15kw-0 kSoTbZ"><h2 color="text.disabled" font-size="12px" font-weight="500" class="Heading-sc-1cjoo9h-0 fTkTnC">Categories</h2><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Commercial</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Core Services</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Core Technologies</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Database Requirements</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Host Service Requirements</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">ICT Stack</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Implementation V1</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Non-HTTP(s) Protocols</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Old-Work-Archives</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">2018-Webizen-Net-Au</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">_Link_library_links</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">_Posts</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/about/">about</a><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/the-human-centric-infosphere/">An Overview</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/">Resource Library</a><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/">Handong1587</a><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">_Posts</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Computer_science</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Computer_vision</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Deep_learning</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2021-07-28-3d/">3D</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-cnn-compression-acceleration/">Acceleration and Model Compression</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-knowledge-distillation/">Acceleration and Model Compression</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-adversarial-attacks-and-defences/">Adversarial Attacks and Defences</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-audio-image-video-generation/">Audio / Image / Video Generation</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2022-06-27-bev/">BEV</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recognition/">Classification / Recognition</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-autonomous-driving/">Deep Learning and Autonomous Driving</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-pose-estimation/">Deep Learning Applications</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-applications/">Deep Learning Applications</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-courses/">Deep learning Courses</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a aria-current="page" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte active" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-frameworks/">Deep Learning Frameworks</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-resources/">Deep Learning Resources</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-software-hardware/">Deep Learning Software and Hardware</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tricks/">Deep Learning Tricks</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tutorials/">Deep Learning Tutorials</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-with-ml/">Deep Learning with Machine Learning</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-face-recognition/">Face Recognition</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-fun-with-deep-learning/">Fun With Deep Learning</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gan/">Generative Adversarial Networks</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gcn/">Graph Convolutional Networks</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-captioning/">Image / Video Captioning</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-retrieval/">Image Retrieval</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2018-09-03-keep-up-with-new-trends/">Keep Up With New Trends</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-lidar-3d-detection/">LiDAR 3D Object Detection</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nlp/">Natural Language Processing</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nas/">Neural Architecture Search</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-counting/">Object Counting</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-detection/">Object Detection</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-ocr/">OCR</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-optical-flow/">Optical Flow</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-re-id/">Re-ID</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recommendation-system/">Recommendation System</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rl/">Reinforcement Learning</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rnn-and-lstm/">RNN and LSTM</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-segmentation/">Segmentation</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-style-transfer/">Style Transfer</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-super-resolution/">Super-Resolution</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-tracking/">Tracking</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-training-dnn/">Training Deep Neural Networks</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-transfer-learning/">Transfer Learning</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-unsupervised-learning/">Unsupervised Learning</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-video-applications/">Video Applications</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-vqa/">Visual Question Answering</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-visulizing-interpreting-cnn/">Visualizing and Interpreting Convolutional Neural Network</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Leisure</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Machine_learning</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Mathematics</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Programming_study</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Reading_and_thoughts</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Study</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Working_on_linux</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Working_on_mac</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Working_on_windows</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Drafts</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div></div></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Webizen 2.0</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 fdzjHV bqVpte" display="block" sx="[object Object]" href="/">Webizen V1 Project Documentation</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div></div></div></div></div></div><main class="Box-nv15kw-0 klfmeZ"><div id="skip-nav" display="flex" width="100%" class="Box-nv15kw-0 TZbDV"><div display="none,,block" class="Box-nv15kw-0 post-page___StyledBox-sc-17hbw1s-0 DPDMP bPkrfP"><span display="inline-block" font-weight="bold" class="Text-sc-1s3uzov-0 bLwTGz">On this page</span><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#amazon-dsstne" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Amazon DSSTNE</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#apache-singa" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Apache SINGA</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#blocks" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Blocks</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#braincore" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">BrainCore</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#brainstorm" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Brainstorm</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#caffe" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Caffe</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#multi-gpu--mpi-caffe" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Multi-GPU / MPI Caffe</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#caffe-utils" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Caffe Utils</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#caffe2" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Caffe2</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#cdnn2" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">CDNN2</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#chainer" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Chainer</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#cntk" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">CNTK</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#convnetjs" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">ConvNetJS</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#deepbeliefsdk" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">DeepBeliefSDK</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#deepdetect" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">DeepDetect</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#deeplearning4j-dl4j" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Deeplearning4j (DL4J)</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#deeplearningkit" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">DeepLearningKit</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#deepspark" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">DeepSpark</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#digits" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">DIGITS</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#dp" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">dp</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#dragon" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Dragon</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#dynet" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">DyNet</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#idlf" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">IDLF</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#keras" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Keras</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#knet" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Knet</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#lasagne" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Lasagne</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#leaf" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Leaf</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#lightnet" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">LightNet</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#matconvnet" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">MatConvNet</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#marvin" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Marvin</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#mochajl" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Mocha.jl</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#mxnet" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">MXNet</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#ncnn" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">ncnn</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#neocortexjs" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">neocortex.js</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#neon" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Neon</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#nnabla" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">NNabla</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#opendeep" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">OpenDeep</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#opennn" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">OpenNN</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#paddle" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Paddle</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#petuum" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Petuum</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#plaidml" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">PlaidML</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#platoon" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Platoon</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#poseidon" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Poseidon</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#purine" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Purine</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#pytorch" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">PyTorch</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#tensorflow" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">TensorFlow</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#tensordebugger-tdb" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">TensorDebugger (TDB)</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#papers" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Papers</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#tutorials" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Tutorials</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#theano" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Theano</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#tiny-dnn-tiny-cnn" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">tiny-dnn (tiny-cnn)</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#torch" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Torch</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#veles" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">VELES</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#webdnn" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">WebDNN</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#yann" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Yann</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#benchmarks" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Benchmarks</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#tutorials-1" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Tutorials</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#papers-1" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Papers</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#projects" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Projects</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#references" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">References</a></li></ul></div><div width="100%" class="Box-nv15kw-0 meQBK"><div class="Box-nv15kw-0 fkoaiG"><div display="flex" class="Box-nv15kw-0 biGwYR"><h1 class="Heading-sc-1cjoo9h-0 glhHOU">Deep Learning Frameworks</h1></div></div><div display="block,,none" class="Box-nv15kw-0 jYYExC"><div class="Box-nv15kw-0 hgiZBa"><div display="flex" class="Box-nv15kw-0 hnQOQh"><span font-weight="bold" class="Text-sc-1s3uzov-0 cQAYyE">On this page</span></div></div><div class="Box-nv15kw-0 gEqaxf"><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#amazon-dsstne" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Amazon DSSTNE</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#apache-singa" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Apache SINGA</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#blocks" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Blocks</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#braincore" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">BrainCore</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#brainstorm" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Brainstorm</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#caffe" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Caffe</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#multi-gpu--mpi-caffe" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Multi-GPU / MPI Caffe</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#caffe-utils" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Caffe Utils</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#caffe2" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Caffe2</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#cdnn2" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">CDNN2</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#chainer" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Chainer</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#cntk" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">CNTK</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#convnetjs" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">ConvNetJS</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#deepbeliefsdk" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">DeepBeliefSDK</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#deepdetect" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">DeepDetect</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#deeplearning4j-dl4j" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Deeplearning4j (DL4J)</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#deeplearningkit" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">DeepLearningKit</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#deepspark" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">DeepSpark</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#digits" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">DIGITS</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#dp" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">dp</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#dragon" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Dragon</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#dynet" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">DyNet</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#idlf" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">IDLF</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#keras" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Keras</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#knet" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Knet</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#lasagne" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Lasagne</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#leaf" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Leaf</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#lightnet" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">LightNet</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#matconvnet" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">MatConvNet</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#marvin" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Marvin</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#mochajl" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Mocha.jl</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#mxnet" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">MXNet</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#ncnn" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">ncnn</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#neocortexjs" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">neocortex.js</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#neon" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Neon</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#nnabla" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">NNabla</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#opendeep" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">OpenDeep</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#opennn" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">OpenNN</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#paddle" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Paddle</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#petuum" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Petuum</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#plaidml" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">PlaidML</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#platoon" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Platoon</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#poseidon" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Poseidon</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#purine" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Purine</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#pytorch" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">PyTorch</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#tensorflow" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">TensorFlow</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#tensordebugger-tdb" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">TensorDebugger (TDB)</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#papers" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Papers</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#tutorials" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Tutorials</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#theano" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Theano</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#tiny-dnn-tiny-cnn" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">tiny-dnn (tiny-cnn)</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#torch" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Torch</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#veles" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">VELES</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#webdnn" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">WebDNN</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#yann" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Yann</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#benchmarks" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Benchmarks</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#tutorials-1" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Tutorials</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#papers-1" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Papers</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#projects" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Projects</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#references" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">References</a></li></ul></div></div><h1 id="amazon-dsstne" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#amazon-dsstne" color="auto.gray.8" aria-label="Amazon DSSTNE permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Amazon DSSTNE</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Amazon DSSTNE: Deep Scalable Sparse Tensor Network Engine</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Deep Scalable Sparse Tensor Network Engine (DSSTNE) is an Amazon developed library
for building Deep Learning (DL) machine learning (ML) models</li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/amznlabs/amazon-dsstne" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/amznlabs/amazon-dsstne</a></li></ul><h1 id="apache-singa" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#apache-singa" color="auto.gray.8" aria-label="Apache SINGA permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Apache SINGA</h1><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>project-website: <a target="_blank" rel="noopener noreferrer" href="http://singa.incubator.apache.org/" class="Link-sc-1brdqhf-0 cKRjba">http://singa.incubator.apache.org/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/apache/incubator-singa" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/apache/incubator-singa</a></li><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://www.comp.nus.edu.sg/~ooibc/singaopen-mm15.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://www.comp.nus.edu.sg/~ooibc/singaopen-mm15.pdf</a></li><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://www.comp.nus.edu.sg/~ooibc/singa-tomm.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://www.comp.nus.edu.sg/~ooibc/singa-tomm.pdf</a></li></ul><h1 id="blocks" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#blocks" color="auto.gray.8" aria-label="Blocks permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Blocks</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Blocks: A Theano framework for building and training neural networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/mila-udem/blocks" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/mila-udem/blocks</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Blocks and Fuel: Frameworks for deep learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1506.00619" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1506.00619</a></li></ul><h1 id="braincore" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#braincore" color="auto.gray.8" aria-label="BrainCore permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>BrainCore</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>BrainCore: The iOS and OS X neural network framework</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://github.com/aleph7/BrainCore" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/aleph7/BrainCore</a></p><h1 id="brainstorm" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#brainstorm" color="auto.gray.8" aria-label="Brainstorm permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Brainstorm</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Brainstorm: Fast, flexible and fun neural networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/IDSIA/brainstorm" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/IDSIA/brainstorm</a></li></ul><h1 id="caffe" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#caffe" color="auto.gray.8" aria-label="Caffe permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Caffe</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Caffe: Convolutional Architecture for Fast Feature Embedding</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/BVLC/caffe" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/BVLC/caffe</a></li><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1408.5093" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1408.5093</a></li><li>tutorial: <a target="_blank" rel="noopener noreferrer" href="http://tutorial.caffe.berkeleyvision.org/" class="Link-sc-1brdqhf-0 cKRjba">http://tutorial.caffe.berkeleyvision.org/</a></li><li>slides: <a target="_blank" rel="noopener noreferrer" href="http://vision.stanford.edu/teaching/cs231n/slides/caffe_tutorial.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://vision.stanford.edu/teaching/cs231n/slides/caffe_tutorial.pdf</a></li><li>slides: <a target="_blank" rel="noopener noreferrer" href="http://vision.princeton.edu/courses/COS598/2015sp/slides/Caffe/caffe_tutorial.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://vision.princeton.edu/courses/COS598/2015sp/slides/Caffe/caffe_tutorial.pdf</a></li><li>caffe-doc: <a target="_blank" rel="noopener noreferrer" href="http://caffe.berkeleyvision.org/doxygen/index.html" class="Link-sc-1brdqhf-0 cKRjba">http://caffe.berkeleyvision.org/doxygen/index.html</a></li><li>tutorials(&quot;CAFFE with CUDA&quot;): <a target="_blank" rel="noopener noreferrer" href="http://pan.baidu.com/s/1i4kmpyH" class="Link-sc-1brdqhf-0 cKRjba">http://pan.baidu.com/s/1i4kmpyH</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>OpenCL Caffe</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: an experimental, community-maintained branch</li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/BVLC/caffe/tree/opencl" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/BVLC/caffe/tree/opencl</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Caffe on both Linux and Windows</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/Microsoft/caffe" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Microsoft/caffe</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>ApolloCaffe: a fork of Caffe that supports dynamic networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://apollocaffe.com/" class="Link-sc-1brdqhf-0 cKRjba">http://apollocaffe.com/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="http://github.com/Russell91/apollocaffe" class="Link-sc-1brdqhf-0 cKRjba">http://github.com/Russell91/apollocaffe</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>fb-caffe-exts: Some handy utility libraries and tools for the Caffe deep learning framework</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: fb-caffe-exts is a collection of extensions developed at FB while using Caffe in (mainly) production scenarios.</li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/facebook/fb-caffe-exts" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/facebook/fb-caffe-exts</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Caffe-Android-Lib: Porting caffe to android platform</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/sh1r0/caffe-android-lib" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/sh1r0/caffe-android-lib</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>caffe-android-demo: An android caffe demo app exploiting caffe pre-trained ImageNet model for image classification</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/sh1r0/caffe-android-demo" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/sh1r0/caffe-android-demo</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Caffe.js: Run Caffe models in the browser using ConvNetJS</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/chaosmail/caffejs/" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/chaosmail/caffejs/</a></li><li>demo: <a target="_blank" rel="noopener noreferrer" href="http://chaosmail.github.io/caffejs/models.html" class="Link-sc-1brdqhf-0 cKRjba">http://chaosmail.github.io/caffejs/models.html</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Intel Caffe</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: This fork of BVLC/Caffe is dedicated to improving performance of this deep learning framework when running on CPU,
in particular Intel® Xeon processors (HSW+) and Intel® Xeon Phi processors</li><li>github <a target="_blank" rel="noopener noreferrer" href="https://github.com/intel/caffe" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/intel/caffe</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>NVIDIA Caffe</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://github.com/NVIDIA/caffe" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/NVIDIA/caffe</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Mini-Caffe</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Minimal runtime core of Caffe, Forward only, GPU support and Memory efficiency.</li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/luoyetx/mini-caffe" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/luoyetx/mini-caffe</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Caffe on Mobile Devices</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Optimized (for size and speed) Caffe lib for iOS and Android with demo APP.</li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/solrex/caffe-mobile" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/solrex/caffe-mobile</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>CaffeOnACL</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Using ARM Compute Library (NEON+GPU) to speed up caffe; Providing utilities to debug, profile and tune application performance</li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/OAID/caffeOnACL" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/OAID/caffeOnACL</a></li></ul><h2 id="multi-gpu--mpi-caffe" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#multi-gpu--mpi-caffe" color="auto.gray.8" aria-label="Multi-GPU / MPI Caffe permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Multi-GPU / MPI Caffe</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Caffe with OpenMPI-based Multi-GPU support</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: A fork of Caffe with OpenMPI-based Multi-GPU (mainly data parallel) support for action recognition and more.</li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/yjxiong/caffe/tree/mem" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/yjxiong/caffe/tree/mem</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>mpi-caffe: Model-distributed Deep Learning with Caffe and MPI</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>project page: <a target="_blank" rel="noopener noreferrer" href="https://computing.ece.vt.edu/~steflee/mpi-caffe.html" class="Link-sc-1brdqhf-0 cKRjba">https://computing.ece.vt.edu/~steflee/mpi-caffe.html</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/steflee/mpi-caffe" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/steflee/mpi-caffe</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Caffe-MPI for Deep Learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/Caffe-MPI/Caffe-MPI.github.io" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Caffe-MPI/Caffe-MPI.github.io</a></li><li>slides: <a target="_blank" rel="noopener noreferrer" href="http://mug.mvapich.cse.ohio-state.edu/static/media/mug/presentations/2016/Caffe-MPI_A_Parallel_Framework_on_the_GPU_Clusters.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://mug.mvapich.cse.ohio-state.edu/static/media/mug/presentations/2016/Caffe-MPI_A_Parallel_Framework_on_the_GPU_Clusters.pdf</a></li></ul><h2 id="caffe-utils" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#caffe-utils" color="auto.gray.8" aria-label="Caffe Utils permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Caffe Utils</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Caffe-model</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Python script to generate prototxt on Caffe, specially the inception_v3\inception_v4\inception_resnet\fractalnet</li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/soeaver/caffe-model" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/soeaver/caffe-model</a></li></ul><h1 id="caffe2" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#caffe2" color="auto.gray.8" aria-label="Caffe2 permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Caffe2</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Caffe2: A New Lightweight, Modular, and Scalable Deep Learning Framework</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Caffe2 is a deep learning framework made with expression, speed, and modularity in mind.
It is an experimental refactoring of Caffe, and allows a more flexible way to organize computation.</li><li>homepage: <a target="_blank" rel="noopener noreferrer" href="https://caffe2.ai/" class="Link-sc-1brdqhf-0 cKRjba">https://caffe2.ai/</a></li><li>github <a target="_blank" rel="noopener noreferrer" href="https://github.com/caffe2/caffe2" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/caffe2/caffe2</a></li><li>github <a target="_blank" rel="noopener noreferrer" href="https://github.com/Yangqing/caffe2" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Yangqing/caffe2</a></li><li>model zoo: <a target="_blank" rel="noopener noreferrer" href="https://caffe2.ai/docs/zoo.html" class="Link-sc-1brdqhf-0 cKRjba">https://caffe2.ai/docs/zoo.html</a></li><li>models: <a target="_blank" rel="noopener noreferrer" href="https://github.com/caffe2/models" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/caffe2/models</a></li></ul><h1 id="cdnn2" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#cdnn2" color="auto.gray.8" aria-label="CDNN2 permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>CDNN2</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>CDNN2 - CEVA Deep Neural Network Software Framework</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl">intro: Accelerating the development of Artificial Intelligence and its deployment in Low-Power Embedded Systems</p></li><li><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl">homepage: <a target="_blank" rel="noopener noreferrer" href="http://launch.ceva-dsp.com/cdnn2/" class="Link-sc-1brdqhf-0 cKRjba">http://launch.ceva-dsp.com/cdnn2/</a></p></li><li><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl">blog: <a target="_blank" rel="noopener noreferrer" href="http://www.tomshardware.com/news/ceva-cdnn2-tensorflow-embedded-systems,32158.html" class="Link-sc-1brdqhf-0 cKRjba">http://www.tomshardware.com/news/ceva-cdnn2-tensorflow-embedded-systems,32158.html</a></p></li></ul><h1 id="chainer" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#chainer" color="auto.gray.8" aria-label="Chainer permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Chainer</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Chainer: a neural network framework</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>website: <a target="_blank" rel="noopener noreferrer" href="http://chainer.org/" class="Link-sc-1brdqhf-0 cKRjba">http://chainer.org/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/pfnet/chainer" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/pfnet/chainer</a></li><li>benchmark: <a target="_blank" rel="noopener noreferrer" href="http://chainer.readthedocs.org/en/latest/comparison.html" class="Link-sc-1brdqhf-0 cKRjba">http://chainer.readthedocs.org/en/latest/comparison.html</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Introduction to Chainer: Neural Networks in Python</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://multithreaded.stitchfix.com/blog/2015/12/09/intro-to-chainer/" class="Link-sc-1brdqhf-0 cKRjba">http://multithreaded.stitchfix.com/blog/2015/12/09/intro-to-chainer/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/stitchfix/Algorithms-Notebooks" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/stitchfix/Algorithms-Notebooks</a></li></ul><h1 id="cntk" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#cntk" color="auto.gray.8" aria-label="CNTK permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>CNTK</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>CNTK: Computational Network Toolkit</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/Microsoft/CNTK" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Microsoft/CNTK</a></li><li>book: <a target="_blank" rel="noopener noreferrer" href="http://research.microsoft.com/pubs/226641/CNTKBook-20160121.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://research.microsoft.com/pubs/226641/CNTKBook-20160121.pdf</a></li><li>tutorial: <a target="_blank" rel="noopener noreferrer" href="http://research.microsoft.com/en-us/um/people/dongyu/CNTK-Tutorial-NIPS2015.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://research.microsoft.com/en-us/um/people/dongyu/CNTK-Tutorial-NIPS2015.pdf</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>An Introduction to Computational Networks and the Computational Network Toolkit</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://research.microsoft.com/apps/pubs/?id=226641" class="Link-sc-1brdqhf-0 cKRjba">http://research.microsoft.com/apps/pubs/?id=226641</a></p><h1 id="convnetjs" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#convnetjs" color="auto.gray.8" aria-label="ConvNetJS permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>ConvNetJS</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>ConvNetJS: Deep Learning in Javascript. Train Convolutional Neural Networks (or ordinary ones) in your browser</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/karpathy/convnetjs" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/karpathy/convnetjs</a></li></ul><h1 id="deepbeliefsdk" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#deepbeliefsdk" color="auto.gray.8" aria-label="DeepBeliefSDK permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>DeepBeliefSDK</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DeepBeliefSDK: The SDK for Jetpac&#x27;s iOS, Android, Linux, and OS X Deep Belief image recognition framework</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/jetpacapp/DeepBeliefSDK" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/jetpacapp/DeepBeliefSDK</a></li><li>demo: <a target="_blank" rel="noopener noreferrer" href="https://github.com/jetpacapp/Jetpac-Deep-Belief-Demo-App" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/jetpacapp/Jetpac-Deep-Belief-Demo-App</a></li><li>demo: <a target="_blank" rel="noopener noreferrer" href="https://github.com/jetpacapp/Jetpac-Deep-Belief-Learner-Demo-App" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/jetpacapp/Jetpac-Deep-Belief-Learner-Demo-App</a></li></ul><h1 id="deepdetect" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#deepdetect" color="auto.gray.8" aria-label="DeepDetect permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>DeepDetect</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DeepDetect: Open Source API &amp; Deep Learning Server</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>webiste: <a target="_blank" rel="noopener noreferrer" href="http://www.deepdetect.com/" class="Link-sc-1brdqhf-0 cKRjba">http://www.deepdetect.com/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/beniz/deepdetect" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/beniz/deepdetect</a></li></ul><h1 id="deeplearning4j-dl4j" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#deeplearning4j-dl4j" color="auto.gray.8" aria-label="Deeplearning4j (DL4J) permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Deeplearning4j (DL4J)</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deeplearning4j: Deep Learning for Java</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://deeplearning4j.org/" class="Link-sc-1brdqhf-0 cKRjba">http://deeplearning4j.org/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/deeplearning4j/deeplearning4j" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/deeplearning4j/deeplearning4j</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deeplearning4j images for cuda and hadoop.</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/deeplearning4j/docker" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/deeplearning4j/docker</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deeplearning4J Examples</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Deeplearning4j Examples (DL4J, DL4J Spark, DataVec)</li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/deeplearning4j/dl4j-examples" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/deeplearning4j/dl4j-examples</a></li></ul><h1 id="deeplearningkit" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#deeplearningkit" color="auto.gray.8" aria-label="DeepLearningKit permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>DeepLearningKit</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DeepLearningKit: Open Source Deep Learning Framework for Apple&#x27;s tvOS, iOS and OS X</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://deeplearningkit.org/" class="Link-sc-1brdqhf-0 cKRjba">http://deeplearningkit.org/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/DeepLearningKit/DeepLearningKit" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/DeepLearningKit/DeepLearningKit</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Tutorial — Using DeepLearningKit with iOS for iPhone and iPad</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://medium.com/@atveit/tutorial-using-deeplearningkit-with-ios-for-iphone-and-ipad-de727679bae4#.1bvnhxhjo" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@atveit/tutorial-using-deeplearningkit-with-ios-for-iphone-and-ipad-de727679bae4#.1bvnhxhjo</a></p><h1 id="deepspark" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#deepspark" color="auto.gray.8" aria-label="DeepSpark permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>DeepSpark</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DeepSpark: Deeplearning framework running on Spark</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/deepspark/deepspark" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/deepspark/deepspark</a></li><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://deepspark.snu.ac.kr/" class="Link-sc-1brdqhf-0 cKRjba">http://deepspark.snu.ac.kr/</a></li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1602.08191" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1602.08191</a></li></ul><h1 id="digits" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#digits" color="auto.gray.8" aria-label="DIGITS permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>DIGITS</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DIGITS: the Deep Learning GPU Training System</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="https://developer.nvidia.com/digits" class="Link-sc-1brdqhf-0 cKRjba">https://developer.nvidia.com/digits</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/NVIDIA/DIGITS" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/NVIDIA/DIGITS</a></li></ul><h1 id="dp" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#dp" color="auto.gray.8" aria-label="dp permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>dp</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>dp: A deep learning library for streamlining research and development using the Torch7 distribution</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/nicholas-leonard/dp" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/nicholas-leonard/dp</a></li><li>manual: <a target="_blank" rel="noopener noreferrer" href="https://dp.readthedocs.org/en/latest/" class="Link-sc-1brdqhf-0 cKRjba">https://dp.readthedocs.org/en/latest/</a></li><li>manual: <a target="_blank" rel="noopener noreferrer" href="https://github.com/nicholas-leonard/dp/blob/master/doc/index.md" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/nicholas-leonard/dp/blob/master/doc/index.md</a></li></ul><h1 id="dragon" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#dragon" color="auto.gray.8" aria-label="Dragon permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Dragon</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Dragon: A Computation Graph Virtual Machine Based Deep Learning Framework</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1707.08265" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1707.08265</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/neopenx/Dragon" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/neopenx/Dragon</a></li></ul><h1 id="dynet" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#dynet" color="auto.gray.8" aria-label="DyNet permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>DyNet</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DyNet: The Dynamic Neural Network Toolkit </strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>paper: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1701.03980" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1701.03980</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/clab/dynet" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/clab/dynet</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DyNet Benchmarks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/neulab/dynet-benchmark" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/neulab/dynet-benchmark</a></li></ul><h1 id="idlf" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#idlf" color="auto.gray.8" aria-label="IDLF permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>IDLF</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>IDLF: The Intel® Deep Learning Framework</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>website: <a target="_blank" rel="noopener noreferrer" href="https://01.org/zh/intel-deep-learning-framework?langredirect=1" class="Link-sc-1brdqhf-0 cKRjba">https://01.org/zh/intel-deep-learning-framework?langredirect=1</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/01org/idlf" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/01org/idlf</a></li></ul><h1 id="keras" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#keras" color="auto.gray.8" aria-label="Keras permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Keras</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Keras: Deep Learning library for Theano and TensorFlow</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/fchollet/keras" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/fchollet/keras</a></li><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://blog.keras.io/introducing-keras-10.html" class="Link-sc-1brdqhf-0 cKRjba">http://blog.keras.io/introducing-keras-10.html</a></li><li>docs: <a target="_blank" rel="noopener noreferrer" href="http://keras.io/getting-started/functional-api-guide/" class="Link-sc-1brdqhf-0 cKRjba">http://keras.io/getting-started/functional-api-guide/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>MarcBS/keras fork</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/MarcBS/keras" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/MarcBS/keras</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Hera: Train/evaluate a Keras model, get metrics streamed to a dashboard in your browser.</strong></p><img src="https://cloud.githubusercontent.com/assets/5866348/16719660/13460bee-46e2-11e6-8ab1-56873807390d.gif" class="image__Image-sc-1r30dtv-0 elBfYx"/><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/jakebian/hera" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/jakebian/hera</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Installing Keras for deep learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://www.pyimagesearch.com/2016/07/18/installing-keras-for-deep-learning/" class="Link-sc-1brdqhf-0 cKRjba">http://www.pyimagesearch.com/2016/07/18/installing-keras-for-deep-learning/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Keras Applications - deep learning models that are made available alongside pre-trained weights</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://keras.io/applications/" class="Link-sc-1brdqhf-0 cKRjba">https://keras.io/applications/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Keras resources: Directory of tutorials and open-source code repositories for working with Keras, the Python deep learning library</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/fchollet/keras-resources" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/fchollet/keras-resources</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Keras.js: Run trained Keras models in the browser, with GPU support</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="https://transcranial.github.io/keras-js/" class="Link-sc-1brdqhf-0 cKRjba">https://transcranial.github.io/keras-js/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/transcranial/keras-js" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/transcranial/keras-js</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>keras2cpp</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: This is a bunch of code to port Keras neural network model into pure C++.</li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/pplonski/keras2cpp" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/pplonski/keras2cpp</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>keras-cn: Chinese keras documents with more examples, explanations and tips.</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/MoyanZitto/keras-cn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/MoyanZitto/keras-cn</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Kerasify: Small library for running Keras models from a C++ application</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://github.com/moof2k/kerasify" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/moof2k/kerasify</a></p><h1 id="knet" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#knet" color="auto.gray.8" aria-label="Knet permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Knet</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Knet: Koç University deep learning framework</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Knet (pronounced &quot;kay-net&quot;) is the Koç University deep learning framework implemented in Julia by Deniz Yuret and collaborators.</li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/denizyuret/Knet.jl" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/denizyuret/Knet.jl</a></li><li>doc: <a target="_blank" rel="noopener noreferrer" href="https://knet.readthedocs.org/en/latest/" class="Link-sc-1brdqhf-0 cKRjba">https://knet.readthedocs.org/en/latest/</a></li></ul><h1 id="lasagne" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#lasagne" color="auto.gray.8" aria-label="Lasagne permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Lasagne</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Lasagne: Lightweight library to build and train neural networks in Theano</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/Lasagne/Lasagne" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Lasagne/Lasagne</a></li><li>docs: <a target="_blank" rel="noopener noreferrer" href="http://lasagne.readthedocs.org/en/latest/" class="Link-sc-1brdqhf-0 cKRjba">http://lasagne.readthedocs.org/en/latest/</a></li></ul><h1 id="leaf" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#leaf" color="auto.gray.8" aria-label="Leaf permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Leaf</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Leaf: The Hacker&#x27;s Machine Learning Engine</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://autumnai.github.io/leaf/leaf/index.html" class="Link-sc-1brdqhf-0 cKRjba">http://autumnai.github.io/leaf/leaf/index.html</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/autumnai/leaf" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/autumnai/leaf</a></li><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://autumnai.com/leaf/book/leaf.html" class="Link-sc-1brdqhf-0 cKRjba">http://autumnai.com/leaf/book/leaf.html</a></li><li>homepage(&quot;The Hacker&#x27;s Machine Intelligence Platform&quot;): <a target="_blank" rel="noopener noreferrer" href="http://autumnai.com/" class="Link-sc-1brdqhf-0 cKRjba">http://autumnai.com/</a></li></ul><h1 id="lightnet" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#lightnet" color="auto.gray.8" aria-label="LightNet permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>LightNet</h1><img src="https://raw.githubusercontent.com/yechengxi/LightNet/master/LightNet.png" class="image__Image-sc-1r30dtv-0 elBfYx"/><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>LightNet: A Versatile, Standalone and Matlab-based Environment for Deep Learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://www.umiacs.umd.edu/~yzyang/LightNet/" class="Link-sc-1brdqhf-0 cKRjba">http://www.umiacs.umd.edu/~yzyang/LightNet/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/yechengxi/lightnet" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/yechengxi/lightnet</a></li></ul><h1 id="matconvnet" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#matconvnet" color="auto.gray.8" aria-label="MatConvNet permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>MatConvNet</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>MatConvNet: CNNs for MATLAB</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://www.vlfeat.org/matconvnet/" class="Link-sc-1brdqhf-0 cKRjba">http://www.vlfeat.org/matconvnet/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/vlfeat/matconvnet" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/vlfeat/matconvnet</a></li></ul><h1 id="marvin" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#marvin" color="auto.gray.8" aria-label="Marvin permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Marvin</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Marvin: A minimalist GPU-only N-dimensional ConvNet framework</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://marvin.is/" class="Link-sc-1brdqhf-0 cKRjba">http://marvin.is/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/PrincetonVision/marvin" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/PrincetonVision/marvin</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>MatConvNet: CNNs for MATLAB</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://www.vlfeat.org/matconvnet/" class="Link-sc-1brdqhf-0 cKRjba">http://www.vlfeat.org/matconvnet/</a></li><li>pretianed models: <a target="_blank" rel="noopener noreferrer" href="http://www.vlfeat.org/matconvnet/pretrained/" class="Link-sc-1brdqhf-0 cKRjba">http://www.vlfeat.org/matconvnet/pretrained/</a></li></ul><h1 id="mochajl" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#mochajl" color="auto.gray.8" aria-label="Mocha.jl permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Mocha.jl</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Mocha.jl: Deep Learning for Julia</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://devblogs.nvidia.com/parallelforall/mocha-jl-deep-learning-julia/" class="Link-sc-1brdqhf-0 cKRjba">http://devblogs.nvidia.com/parallelforall/mocha-jl-deep-learning-julia/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/pluskid/Mocha.jl" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/pluskid/Mocha.jl</a></li></ul><h1 id="mxnet" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#mxnet" color="auto.gray.8" aria-label="MXNet permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>MXNet</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>MXNet</strong></p><img src="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/banner.png" class="image__Image-sc-1r30dtv-0 elBfYx"/><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/dmlc/mxnet" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/dmlc/mxnet</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>paper: <a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/paper/mxnet-learningsys.pdf" class="Link-sc-1brdqhf-0 cKRjba">https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/paper/mxnet-learningsys.pdf</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>MXNet Model Gallery: Pre-trained Models of DMLC Project</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/dmlc/mxnet-model-gallery" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/dmlc/mxnet-model-gallery</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>a short introduction to mxnet design and implementation (chinese)</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/dmlc/mxnet/blob/master/doc/overview_chn.md" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/dmlc/mxnet/blob/master/doc/overview_chn.md</a></li><li>github-issues: <a target="_blank" rel="noopener noreferrer" href="https://github.com/dmlc/mxnet/issues/797" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/dmlc/mxnet/issues/797</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep learning for hackers with MXnet (1) GPU installation and MNIST</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://no2147483647.wordpress.com/2015/12/07/deep-learning-for-hackers-with-mxnet-1/" class="Link-sc-1brdqhf-0 cKRjba">https://no2147483647.wordpress.com/2015/12/07/deep-learning-for-hackers-with-mxnet-1/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>mxnet_Efficient, Flexible Deep Learning Framework</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>slides: <a target="_blank" rel="noopener noreferrer" href="http://vdisk.weibo.com/s/z5dg0jVVHv2pn/1450157571" class="Link-sc-1brdqhf-0 cKRjba">http://vdisk.weibo.com/s/z5dg0jVVHv2pn/1450157571</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Use Caffe operator in MXNet</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://dmlc.ml/mxnet/2016/07/29/use-caffe-operator-in-mxnet.html" class="Link-sc-1brdqhf-0 cKRjba">http://dmlc.ml/mxnet/2016/07/29/use-caffe-operator-in-mxnet.html</a>**</li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Learning in a Single File for Smart Devices</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://mxnet.readthedocs.org/en/latest/tutorial/smart_device.html" class="Link-sc-1brdqhf-0 cKRjba">https://mxnet.readthedocs.org/en/latest/tutorial/smart_device.html</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>MXNet Pascal Titan X benchmark</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://dmlc.ml/mxnet/2016/08/03/mxnet-titanx-benchmark.html" class="Link-sc-1brdqhf-0 cKRjba">http://dmlc.ml/mxnet/2016/08/03/mxnet-titanx-benchmark.html</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>用MXnet实战深度学习之一:安装GPU版mxnet并跑一个MNIST手写数字识别</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://phunter.farbox.com/post/mxnet-tutorial1" class="Link-sc-1brdqhf-0 cKRjba">http://phunter.farbox.com/post/mxnet-tutorial1</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>用MXnet实战深度学习之二:Neural art</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://phunter.farbox.com/post/mxnet-tutorial2" class="Link-sc-1brdqhf-0 cKRjba">http://phunter.farbox.com/post/mxnet-tutorial2</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Programming Models and Systems Design for Deep Learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>video: <a target="_blank" rel="noopener noreferrer" href="http://research.microsoft.com/apps/video/default.aspx?id=262396" class="Link-sc-1brdqhf-0 cKRjba">http://research.microsoft.com/apps/video/default.aspx?id=262396</a></li><li>video: <a target="_blank" rel="noopener noreferrer" href="http://pan.baidu.com/s/1mgSnj64" class="Link-sc-1brdqhf-0 cKRjba">http://pan.baidu.com/s/1mgSnj64</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Awesome MXNet</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: This page contains a curated list of awesome MXnet examples, tutorials and blogs.</li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/dmlc/mxnet/blob/master/example/README.md" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/dmlc/mxnet/blob/master/example/README.md</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Getting Started with MXNet</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://indico.io/blog/getting-started-with-mxnet/" class="Link-sc-1brdqhf-0 cKRjba">https://indico.io/blog/getting-started-with-mxnet/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>gtc_tutorial: MXNet Tutorial for NVidia GTC 2016</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>report: <a target="_blank" rel="noopener noreferrer" href="http://on-demand.gputechconf.com/gtc/2016/video/S6853.html" class="Link-sc-1brdqhf-0 cKRjba">http://on-demand.gputechconf.com/gtc/2016/video/S6853.html</a></li><li>tutorial: <a target="_blank" rel="noopener noreferrer" href="http://on-demand.gputechconf.com/gtc/2016/video/L6143.html" class="Link-sc-1brdqhf-0 cKRjba">http://on-demand.gputechconf.com/gtc/2016/video/L6143.html</a></li><li>video: <a target="_blank" rel="noopener noreferrer" href="http://pan.baidu.com/s/1eS58Gue" class="Link-sc-1brdqhf-0 cKRjba">http://pan.baidu.com/s/1eS58Gue</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/dmlc/mxnet-gtc-tutorial" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/dmlc/mxnet-gtc-tutorial</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>MXNET Dependency Engine</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://yuyang0.github.io/articles/mxnet-engine.html" class="Link-sc-1brdqhf-0 cKRjba">http://yuyang0.github.io/articles/mxnet-engine.html</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>MXNET是这样压榨深度学习的内存消耗的</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>doc: <a target="_blank" rel="noopener noreferrer" href="https://github.com/dmlc/mxnet/blob/master/docs/zh/note_memory.md" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/dmlc/mxnet/blob/master/docs/zh/note_memory.md</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>WhatsThis-iOS: MXNet WhatThis Example for iOS</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/pppoe/WhatsThis-iOS" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/pppoe/WhatsThis-iOS</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>MXNET-MPI: Embedding MPI parallelism in Parameter Server Task Model for scaling Deep Learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: IBM T J Watson Research Center</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1801.03855" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1801.03855</a></li></ul><h1 id="ncnn" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#ncnn" color="auto.gray.8" aria-label="ncnn permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>ncnn</h1><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ncnn is a high-performance neural network inference framework optimized for the mobile platform</li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/Tencent/ncnn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Tencent/ncnn</a></li></ul><h1 id="neocortexjs" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#neocortexjs" color="auto.gray.8" aria-label="neocortex.js permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>neocortex.js</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Run trained deep neural networks in the browser or node.js</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://scienceai.github.io/neocortex/" class="Link-sc-1brdqhf-0 cKRjba">http://scienceai.github.io/neocortex/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/scienceai/neocortex" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/scienceai/neocortex</a></li></ul><h1 id="neon" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#neon" color="auto.gray.8" aria-label="Neon permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Neon</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Neon: Nervana’s Python-based deep learning library</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>website: <a target="_blank" rel="noopener noreferrer" href="http://neon.nervanasys.com/docs/latest/index.html" class="Link-sc-1brdqhf-0 cKRjba">http://neon.nervanasys.com/docs/latest/index.html</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/NervanaSystems/neon" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/NervanaSystems/neon</a></li><li>website: <a target="_blank" rel="noopener noreferrer" href="https://www.nervanasys.com/learn/" class="Link-sc-1brdqhf-0 cKRjba">https://www.nervanasys.com/learn/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Tools to convert Caffe models to neon&#x27;s serialization format</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/NervanaSystems/caffe2neon" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/NervanaSystems/caffe2neon</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Nervana’s Deep Learning Course</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="https://www.nervanasys.com/deep-learning-tutorials/" class="Link-sc-1brdqhf-0 cKRjba">https://www.nervanasys.com/deep-learning-tutorials/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/NervanaSystems/neon_course" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/NervanaSystems/neon_course</a></li></ul><h1 id="nnabla" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#nnabla" color="auto.gray.8" aria-label="NNabla permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>NNabla</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>NNabla - Neural Network Libraries by Sony</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: NNabla - Neural Network Libraries NNabla is a deep learning framework that is intended to be used for research, development and production. We aim it running everywhere like desktop PCs, HPC clusters, embedded devices and production servers.</li><li>homepage: <a target="_blank" rel="noopener noreferrer" href="https://nnabla.org/" class="Link-sc-1brdqhf-0 cKRjba">https://nnabla.org/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/sony/nnabla" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/sony/nnabla</a></li></ul><h1 id="opendeep" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#opendeep" color="auto.gray.8" aria-label="OpenDeep permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>OpenDeep</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>OpenDeep: a fully modular &amp; extensible deep learning framework in Python</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Modular &amp; extensible deep learning framework built on Theano</li><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://www.opendeep.org/" class="Link-sc-1brdqhf-0 cKRjba">http://www.opendeep.org/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/vitruvianscience/opendeep" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/vitruvianscience/opendeep</a></li></ul><h1 id="opennn" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#opennn" color="auto.gray.8" aria-label="OpenNN permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>OpenNN</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>OpenNN - Open Neural Networks Library</strong></p><img src="http://opennn.net/images/OpenNN%20screenshot.png" class="image__Image-sc-1r30dtv-0 elBfYx"/><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://opennn.net/" class="Link-sc-1brdqhf-0 cKRjba">http://opennn.net/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/artelnics/opennn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/artelnics/opennn</a></li></ul><h1 id="paddle" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#paddle" color="auto.gray.8" aria-label="Paddle permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Paddle</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>PaddlePaddle: PArallel Distributed Deep LEarning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://www.paddlepaddle.org/" class="Link-sc-1brdqhf-0 cKRjba">http://www.paddlepaddle.org/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/baidu/Paddle" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/baidu/Paddle</a></li><li>installation: <a target="_blank" rel="noopener noreferrer" href="http://www.paddlepaddle.org/doc/build/" class="Link-sc-1brdqhf-0 cKRjba">http://www.paddlepaddle.org/doc/build/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>基于Spark的异构分布式深度学习平台</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://geek.csdn.net/news/detail/58867" class="Link-sc-1brdqhf-0 cKRjba">http://geek.csdn.net/news/detail/58867</a></p><h1 id="petuum" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#petuum" color="auto.gray.8" aria-label="Petuum permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Petuum</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Petuum: a distributed machine learning framework</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>website: <a target="_blank" rel="noopener noreferrer" href="http://petuum.github.io/" class="Link-sc-1brdqhf-0 cKRjba">http://petuum.github.io/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/petuum/bosen" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/petuum/bosen</a></li></ul><h1 id="plaidml" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#plaidml" color="auto.gray.8" aria-label="PlaidML permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>PlaidML</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>PlaidML: A framework for making deep learning work everywhere</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://vertex.ai/" class="Link-sc-1brdqhf-0 cKRjba">http://vertex.ai/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/plaidml/plaidml" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/plaidml/plaidml</a></li></ul><h1 id="platoon" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#platoon" color="auto.gray.8" aria-label="Platoon permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Platoon</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Platoon: Multi-GPU mini-framework for Theano</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/mila-udem/platoon" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/mila-udem/platoon</a></li></ul><h1 id="poseidon" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#poseidon" color="auto.gray.8" aria-label="Poseidon permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Poseidon</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Poseidon: Distributed Deep Learning Framework on Petuum</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/petuum/poseidon" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/petuum/poseidon</a></li><li>wiki: <a target="_blank" rel="noopener noreferrer" href="https://github.com/petuum/poseidon/wiki" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/petuum/poseidon/wiki</a></li></ul><h1 id="purine" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#purine" color="auto.gray.8" aria-label="Purine permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Purine</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Purine: A bi-graph based deep learning framework</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/purine/purine2" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/purine/purine2</a></li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1412.6249" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1412.6249</a></li></ul><h1 id="pytorch" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#pytorch" color="auto.gray.8" aria-label="PyTorch permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>PyTorch</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>PyTorch</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/pytorch/pytorch" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/pytorch/pytorch</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Datasets, Transforms and Models specific to Computer Vision</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://github.com/pytorch/vision/" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/pytorch/vision/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Convert torch to pytorch</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://github.com/clcarwin/convert_torch_to_pytorch" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/clcarwin/convert_torch_to_pytorch</a></p><h1 id="tensorflow" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#tensorflow" color="auto.gray.8" aria-label="TensorFlow permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>TensorFlow</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>TensorFlow</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>website: <a target="_blank" rel="noopener noreferrer" href="http://tensorflow.org/" class="Link-sc-1brdqhf-0 cKRjba">http://tensorflow.org/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/tensorflow/tensorflow" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/tensorflow/tensorflow</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/distributed_runtime" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/distributed_runtime</a></li><li>tutorial: <a target="_blank" rel="noopener noreferrer" href="http://tensorflow.org/tutorials" class="Link-sc-1brdqhf-0 cKRjba">http://tensorflow.org/tutorials</a></li><li>tutorial: <a target="_blank" rel="noopener noreferrer" href="https://github.com/nlintz/TensorFlow-Tutorials" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/nlintz/TensorFlow-Tutorials</a></li><li>stackoverflow: <a target="_blank" rel="noopener noreferrer" href="https://stackoverflow.com/questions/tagged/tensorflow" class="Link-sc-1brdqhf-0 cKRjba">https://stackoverflow.com/questions/tagged/tensorflow</a></li><li>benchmark: <a target="_blank" rel="noopener noreferrer" href="https://github.com/soumith/convnet-benchmarks/issues/66" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/soumith/convnet-benchmarks/issues/66</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Benchmarks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: A selection of image classification models were tested across multiple platforms to create a point of reference for the TensorFlow community</li><li>homepage: <a target="_blank" rel="noopener noreferrer" href="https://www.tensorflow.org/performance/benchmarks" class="Link-sc-1brdqhf-0 cKRjba">https://www.tensorflow.org/performance/benchmarks</a></li></ul><h2 id="tensordebugger-tdb" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#tensordebugger-tdb" color="auto.gray.8" aria-label="TensorDebugger (TDB) permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>TensorDebugger (TDB)</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>TensorDebugger(TDB): Interactive, node-by-node debugging and visualization for TensorFlow</strong></p><img src="https://camo.githubusercontent.com/4c671d2b359c9984472f37a73136971fd60e76e4/687474703a2f2f692e696d6775722e636f6d2f6e30506d58516e2e676966" class="image__Image-sc-1r30dtv-0 elBfYx"/><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/ericjang/tdb" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/ericjang/tdb</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>ofxMSATensorFlow: OpenFrameworks addon for Google&#x27;s data-flow graph based numerical computation / machine intelligence library TensorFlow.</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/memo/ofxMSATensorFlow" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/memo/ofxMSATensorFlow</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>TFLearn: Deep learning library featuring a higher-level API for TensorFlow</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://tflearn.org/" class="Link-sc-1brdqhf-0 cKRjba">http://tflearn.org/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/tflearn/tflearn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/tflearn/tflearn</a></li><li>examples: <a target="_blank" rel="noopener noreferrer" href="https://github.com/tflearn/tflearn/blob/0.1.0/examples/README.md" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/tflearn/tflearn/blob/0.1.0/examples/README.md</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>TensorFlow on Spark</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/adatao/tensorspark" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/adatao/tensorspark</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>TensorBoard</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>TensorFlow.jl: A Julia wrapper for the TensorFlow Python library</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/benmoran/TensorFlow.jl" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/benmoran/TensorFlow.jl</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>TensorLayer: Deep learning and Reinforcement learning library for TensorFlow</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/zsdonghao/tensorlayer" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/zsdonghao/tensorlayer</a></li><li>docs: <a target="_blank" rel="noopener noreferrer" href="http://tensorlayer.readthedocs.io/en/latest/" class="Link-sc-1brdqhf-0 cKRjba">http://tensorlayer.readthedocs.io/en/latest/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>OpenCL support for TensorFlow</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/benoitsteiner/tensorflow-opencl" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/benoitsteiner/tensorflow-opencl</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Pretty Tensor: Fluent Networks in TensorFlow</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/google/prettytensor" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/google/prettytensor</a></li><li>docs: <a target="_blank" rel="noopener noreferrer" href="https://github.com/google/prettytensor/blob/master/docs/pretty_tensor_top_level.md" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/google/prettytensor/blob/master/docs/pretty_tensor_top_level.md</a></li><li>tutorials: <a target="_blank" rel="noopener noreferrer" href="https://github.com/google/prettytensor/tree/master/prettytensor/tutorial" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/google/prettytensor/tree/master/prettytensor/tutorial</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Rust language bindings for TensorFlow</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/tensorflow/rust" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/tensorflow/rust</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>TensorFlow Ecosystem: Integration of TensorFlow with other open-source frameworks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/tensorflow/ecosystem" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/tensorflow/ecosystem</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Caffe to TensorFlow</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Convert Caffe models to TensorFlow.</li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/ethereon/caffe-tensorflow" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/ethereon/caffe-tensorflow</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>TensorFlow Mobile</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://www.tensorflow.org/mobile/" class="Link-sc-1brdqhf-0 cKRjba">https://www.tensorflow.org/mobile/</a></p><h2 id="papers" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#papers" color="auto.gray.8" aria-label="Papers permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Papers</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1603.04467" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1603.04467</a></li><li>whitepaper: <a target="_blank" rel="noopener noreferrer" href="http://download.tensorflow.org/paper/whitepaper2015.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://download.tensorflow.org/paper/whitepaper2015.pdf</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>TensorFlow: A system for large-scale machine learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1605.08695" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1605.08695</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>TensorFlow Distributions</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1711.10604" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1711.10604</a></p><h2 id="tutorials" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#tutorials" color="auto.gray.8" aria-label="Tutorials permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Tutorials</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>TensorFlow 官方文档中文版</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>tutorial-zh: <a target="_blank" rel="noopener noreferrer" href="https://github.com/jikexueyuanwiki/tensorflow-zh" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/jikexueyuanwiki/tensorflow-zh</a></li><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://wiki.jikexueyuan.com/project/tensorflow-zh/" class="Link-sc-1brdqhf-0 cKRjba">http://wiki.jikexueyuan.com/project/tensorflow-zh/</a></li></ul><h1 id="theano" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#theano" color="auto.gray.8" aria-label="Theano permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Theano</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Theano</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>website: <a target="_blank" rel="noopener noreferrer" href="http://deeplearning.net/software/theano/index.html" class="Link-sc-1brdqhf-0 cKRjba">http://deeplearning.net/software/theano/index.html</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/Theano/Theano" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Theano/Theano</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Theano-Tutorials: Bare bones introduction to machine learning from linear regression to convolutional neural networks using Theano</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/Newmu/Theano-Tutorials" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Newmu/Theano-Tutorials</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Theano: A Python framework for fast computation of mathematical expressions</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1605.02688" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1605.02688</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Configuring Theano For High Performance Deep Learning</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://www.johnwittenauer.net/configuring-theano-for-high-performance-deep-learning/" class="Link-sc-1brdqhf-0 cKRjba">http://www.johnwittenauer.net/configuring-theano-for-high-performance-deep-learning/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Theano: a short practical guide</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>slides: <a target="_blank" rel="noopener noreferrer" href="http://folinoid.com/show/theano/" class="Link-sc-1brdqhf-0 cKRjba">http://folinoid.com/show/theano/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Ian Goodfellow&#x27;s Tutorials on Theano</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>slides: <a target="_blank" rel="noopener noreferrer" href="http://pan.baidu.com/s/1slbzhF3#path=%252F%25E6%2588%2591%25E7%259A%2584%25E5%2588%2586%25E4%25BA%25AB%252F201604%252FIan%2520Goodfellow&#x27;s%2520Tutorials%2520on%2520Theano" class="Link-sc-1brdqhf-0 cKRjba">http://pan.baidu.com/s/1slbzhF3#path=%252F%25E6%2588%2591%25E7%259A%2584%25E5%2588%2586%25E4%25BA%25AB%252F201604%252FIan%2520Goodfellow&#x27;s%2520Tutorials%2520on%2520Theano</a></li><li>github(&quot;theano_exercises&quot;): <a target="_blank" rel="noopener noreferrer" href="https://github.com/goodfeli/theano_exercises" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/goodfeli/theano_exercises</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Plato: A library built on top of Theano</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/petered/plato" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/petered/plato</a></li><li>tutorial: <a target="_blank" rel="noopener noreferrer" href="https://rawgit.com/petered/plato/master/plato_tutorial.html" class="Link-sc-1brdqhf-0 cKRjba">https://rawgit.com/petered/plato/master/plato_tutorial.html</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Theano Windows Install Guide</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/mrakgr/Tutorials/blob/master/theano_install.md" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/mrakgr/Tutorials/blob/master/theano_install.md</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Theano-MPI: a Theano-based Distributed Training Framework</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1605.08325" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1605.08325</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/uoguelph-mlrg/Theano-MPI" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/uoguelph-mlrg/Theano-MPI</a></li></ul><h1 id="tiny-dnn-tiny-cnn" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#tiny-dnn-tiny-cnn" color="auto.gray.8" aria-label="tiny-dnn (tiny-cnn) permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>tiny-dnn (tiny-cnn)</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>tiny-dnn: A header only, dependency-free deep learning framework in C++11</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>inrtro: tiny-dnn is a C++11 implementation of deep learning.
It is suitable for deep learning on limited computational resource, embedded systems and IoT devices.</li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/tiny-dnn/tiny-dnn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/tiny-dnn/tiny-dnn</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/nyanp/tiny-cnn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/nyanp/tiny-cnn</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep learning with C++ - an introduction to tiny-dnn</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>slides: <a target="_blank" rel="noopener noreferrer" href="http://www.slideshare.net/ssuser756ec5/deep-learning-with-c-an-introduction-to-tinydnn" class="Link-sc-1brdqhf-0 cKRjba">http://www.slideshare.net/ssuser756ec5/deep-learning-with-c-an-introduction-to-tinydnn</a></li></ul><h1 id="torch" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#torch" color="auto.gray.8" aria-label="Torch permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Torch</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Torch</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>website: <a target="_blank" rel="noopener noreferrer" href="http://torch.ch/" class="Link-sc-1brdqhf-0 cKRjba">http://torch.ch/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/torch/torch7" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/torch/torch7</a></li><li>cheatsheet: <a target="_blank" rel="noopener noreferrer" href="https://github.com/torch/torch7/wiki/Cheatsheet" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/torch/torch7/wiki/Cheatsheet</a> </li><li>tutorials(&quot;Getting started with Torch&quot;): <a target="_blank" rel="noopener noreferrer" href="http://torch.ch/docs/getting-started.html#_" class="Link-sc-1brdqhf-0 cKRjba">http://torch.ch/docs/getting-started.html#_</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>loadcaffe: Load Caffe networks in Torch7</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/szagoruyko/loadcaffe" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/szagoruyko/loadcaffe</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Applied Deep Learning for Computer Vision with Torch</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="https://github.com/soumith/cvpr2015" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/soumith/cvpr2015</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>pytorch: Python wrappers for torch and lua</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/hughperkins/pytorch" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/hughperkins/pytorch</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Torch Toolbox: A collection of snippets and libraries for Torch</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/e-lab/torch-toolbox" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/e-lab/torch-toolbox</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>cltorch: a Hardware-Agnostic Backend for the Torch Deep Neural Network Library, Based on OpenCL</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1606.04884" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1606.04884</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/hughperkins/cltorch" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/hughperkins/cltorch</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Torchnet: An Open-Source Platform for (Deep) Learning Research</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>paper: <a target="_blank" rel="noopener noreferrer" href="https://lvdmaaten.github.io/publications/papers/Torchnet_2016.pdf" class="Link-sc-1brdqhf-0 cKRjba">https://lvdmaaten.github.io/publications/papers/Torchnet_2016.pdf</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/torchnet/torchnet" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/torchnet/torchnet</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>THFFmpeg: Torch bindings for FFmpeg (reading videos only)</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/MichaelMathieu/THFFmpeg" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/MichaelMathieu/THFFmpeg</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>caffegraph: Load Caffe networks in Torch7 using nngraph</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/nhynes/caffegraph" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/nhynes/caffegraph</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Optimized-Torch: Intel Torch is dedicated to improving Torch performance when running on CPU</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Intel Torch gets 4.66x speedup using the convnet-benchmarks which includes AlexNet,VGG-E,GoogLenet,ResidualNet</li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/xhzhao/optimized-torch" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/xhzhao/optimized-torch</a></li><li>benchmark: <a target="_blank" rel="noopener noreferrer" href="https://github.com/xhzhao/Optimized-Torch-benchmark" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/xhzhao/Optimized-Torch-benchmark</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Torch Video Tutorials</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/Atcold/torch-Video-Tutorials" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Atcold/torch-Video-Tutorials</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Torch in Action</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/nicholas-leonard/torch-in-action" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/nicholas-leonard/torch-in-action</a></li></ul><h1 id="veles" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#veles" color="auto.gray.8" aria-label="VELES permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>VELES</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>VELES: Distributed platform for rapid Deep learning application development</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>website: <a target="_blank" rel="noopener noreferrer" href="https://velesnet.ml/" class="Link-sc-1brdqhf-0 cKRjba">https://velesnet.ml/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/Samsung/veles" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Samsung/veles</a></li><li>workflow: <a target="_blank" rel="noopener noreferrer" href="https://velesnet.ml/forge/forge.html" class="Link-sc-1brdqhf-0 cKRjba">https://velesnet.ml/forge/forge.html</a></li></ul><h1 id="webdnn" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#webdnn" color="auto.gray.8" aria-label="WebDNN permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>WebDNN</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>WebDNN: Fastest DNN Execution Framework on Web Browser</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="https://mil-tokyo.github.io/webdnn/" class="Link-sc-1brdqhf-0 cKRjba">https://mil-tokyo.github.io/webdnn/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/mil-tokyo/webdnn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/mil-tokyo/webdnn</a></li></ul><h1 id="yann" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#yann" color="auto.gray.8" aria-label="Yann permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Yann</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Yann: Yet Another Neural Network Toolbox</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: It is a toolbox for building and learning convolutional neural networks, built on top of theano</li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/ragavvenkatesan/yann" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/ragavvenkatesan/yann</a></li><li>docs: <a target="_blank" rel="noopener noreferrer" href="http://yann.readthedocs.io/en/master/" class="Link-sc-1brdqhf-0 cKRjba">http://yann.readthedocs.io/en/master/</a></li></ul><h1 id="benchmarks" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#benchmarks" color="auto.gray.8" aria-label="Benchmarks permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Benchmarks</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Easy benchmarking of all publicly accessible implementations of convnets</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://github.com/soumith/convnet-benchmarks" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/soumith/convnet-benchmarks</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Stanford DAWN Deep Learning Benchmark (DAWNBench) - An End-to-End Deep Learning Benchmark and Competition</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://dawn.cs.stanford.edu/benchmark/index.html" class="Link-sc-1brdqhf-0 cKRjba">http://dawn.cs.stanford.edu/benchmark/index.html</a></p><h1 id="tutorials-1" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#tutorials" color="auto.gray.8" aria-label="Tutorials permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Tutorials</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Learning Implementations and Frameworks (DLIF)</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>tutorial: <a target="_blank" rel="noopener noreferrer" href="https://sites.google.com/site/dliftutorial/" class="Link-sc-1brdqhf-0 cKRjba">https://sites.google.com/site/dliftutorial/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/delta2323/DLIF-tutorial" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/delta2323/DLIF-tutorial</a></li></ul><h1 id="papers-1" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#papers" color="auto.gray.8" aria-label="Papers permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Papers</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Comparative Study of Deep Learning Software Frameworks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Caffe / Neon / TensorFlow / Theano / Torch</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1511.06435" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1511.06435</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/DL-Benchmarks/DL-Benchmarks" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/DL-Benchmarks/DL-Benchmarks</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Benchmarking State-of-the-Art Deep Learning Software Tools</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Caffe, CNTK, MXNet, TensorFlow, and Torch</li><li>project page: <a target="_blank" rel="noopener noreferrer" href="http://dlbench.comp.hkbu.edu.hk/" class="Link-sc-1brdqhf-0 cKRjba">http://dlbench.comp.hkbu.edu.hk/</a></li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1608.07249" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1608.07249</a></li></ul><h1 id="projects" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#projects" color="auto.gray.8" aria-label="Projects permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Projects</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>TensorFuse: Common interface for Theano, CGT, and TensorFlow</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/dementrock/tensorfuse" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/dementrock/tensorfuse</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DeepRosetta: An universal deep learning models conversor</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/edgarriba/DeepRosetta" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/edgarriba/DeepRosetta</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Learning Model Convertors</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ysh329/deep-learning-model-convertor" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/ysh329/deep-learning-model-convertor</a></p><h1 id="references" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#references" color="auto.gray.8" aria-label="References permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>References</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Frameworks and Libraries for Deep Learning</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://creative-punch.net/2015/07/frameworks-and-libraries-for-deep-learning/" class="Link-sc-1brdqhf-0 cKRjba">http://creative-punch.net/2015/07/frameworks-and-libraries-for-deep-learning/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>TensorFlow vs. Theano vs. Torch</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://github.com/zer0n/deepframeworks/blob/master/README.md" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/zer0n/deepframeworks/blob/master/README.md</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Evaluation of Deep Learning Toolkits</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://github.com/zer0n/deepframeworks/blob/master/README.md" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/zer0n/deepframeworks/blob/master/README.md</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Machine Learning libraries and frameworks</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://medium.com/@abduljaleel/deep-machine-learning-libraries-and-frameworks-5fdf2bb6bfbe#.q1mhj7c36" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@abduljaleel/deep-machine-learning-libraries-and-frameworks-5fdf2bb6bfbe#.q1mhj7c36</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Torch vs Theano</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://fastml.com/torch-vs-theano/" class="Link-sc-1brdqhf-0 cKRjba">http://fastml.com/torch-vs-theano/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Learning Software: NVIDIA Deep Learning SDK</strong></p><img src="https://developer.nvidia.com/sites/default/files/akamai/cuda/images/deeplearning/digits-2-gpu-utilization_faded.png" class="image__Image-sc-1r30dtv-0 elBfYx"/><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://developer.nvidia.com/deep-learning-software" class="Link-sc-1brdqhf-0 cKRjba">https://developer.nvidia.com/deep-learning-software</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A comparison of deep learning frameworks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Theano/CGT/Torch/MXNet</li><li>gist: <a target="_blank" rel="noopener noreferrer" href="https://gist.github.com/bartvm/69adf7aad100d58831b0" class="Link-sc-1brdqhf-0 cKRjba">https://gist.github.com/bartvm/69adf7aad100d58831b0</a></li><li>webo: <a target="_blank" rel="noopener noreferrer" href="http://weibo.com/p/1001603946281180481229" class="Link-sc-1brdqhf-0 cKRjba">http://weibo.com/p/1001603946281180481229</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>TensorFlow Meets Microsoft’s CNTK</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://esciencegroup.com/2016/02/08/tensorflow-meets-microsofts-cntk/" class="Link-sc-1brdqhf-0 cKRjba">http://esciencegroup.com/2016/02/08/tensorflow-meets-microsofts-cntk/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Is there a case for still using Torch, Theano, Brainstorm, MXNET and not switching to TensorFlow?</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>reddit: <!-- -->[https://www.reddit.com/r/MachineLearning/comments/47qh90/is_there_a_case_for_still_using_torch_theano/][https://www.reddit.com/r/MachineLearning/comments/47qh90/is_there_a_case_for_still_using_torch_theano/]</li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DL4J vs. Torch vs. Theano vs. Caffe vs. TensorFlow</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://deeplearning4j.org/compare-dl4j-torch7-pylearn.html" class="Link-sc-1brdqhf-0 cKRjba">http://deeplearning4j.org/compare-dl4j-torch7-pylearn.html</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Popular Deep Learning Libraries</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://machinelearningmastery.com/popular-deep-learning-libraries/" class="Link-sc-1brdqhf-0 cKRjba">http://machinelearningmastery.com/popular-deep-learning-libraries/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>The simple example of Theano and Lasagne super power</strong></p><img src="https://grzegorzgwardys.files.wordpress.com/2016/05/modified_cnn.png?w=640" class="image__Image-sc-1r30dtv-0 elBfYx"/><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://grzegorzgwardys.wordpress.com/2016/05/15/the-simple-example-of-theano-and-lasagne-super-power/" class="Link-sc-1brdqhf-0 cKRjba">https://grzegorzgwardys.wordpress.com/2016/05/15/the-simple-example-of-theano-and-lasagne-super-power/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Comparison of deep learning software</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>wiki: <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Comparison_of_deep_learning_software" class="Link-sc-1brdqhf-0 cKRjba">https://en.wikipedia.org/wiki/Comparison_of_deep_learning_software</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A Look at Popular Machine Learning Frameworks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://redmonk.com/fryan/2016/06/06/a-look-at-popular-machine-learning-frameworks/" class="Link-sc-1brdqhf-0 cKRjba">http://redmonk.com/fryan/2016/06/06/a-look-at-popular-machine-learning-frameworks/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>5 Deep Learning Projects You Can No Longer Overlook</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>keywords: Leaf / tiny-cnn / Layered / Brain / neon</li><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://www.kdnuggets.com/2016/07/five-deep-learning-projects-cant-overlook.html" class="Link-sc-1brdqhf-0 cKRjba">http://www.kdnuggets.com/2016/07/five-deep-learning-projects-cant-overlook.html</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Comparison of Deep Learning Libraries After Years of Use</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Torch / MxNet / Theano / Caffe</li><li>blog:<a target="_blank" rel="noopener noreferrer" href="http://www.erogol.com/comparison-deep-learning-libraries-years-use/" class="Link-sc-1brdqhf-0 cKRjba">http://www.erogol.com/comparison-deep-learning-libraries-years-use/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Learning Part 1: Comparison of Symbolic Deep Learning Frameworks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Theano / TensorFlow / MXNET</li><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://blog.revolutionanalytics.com/2016/08/deep-learning-part-1.html" class="Link-sc-1brdqhf-0 cKRjba">http://blog.revolutionanalytics.com/2016/08/deep-learning-part-1.html</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Learning Frameworks Compared</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>youtube: <a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=MDP9FfsNx60" class="Link-sc-1brdqhf-0 cKRjba">https://www.youtube.com/watch?v=MDP9FfsNx60</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/llSourcell/tensorflow_vs_theano" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/llSourcell/tensorflow_vs_theano</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DL4J vs. Torch vs. Theano vs. Caffe vs. TensorFlow</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://deeplearning4j.org/compare-dl4j-torch7-pylearn.html" class="Link-sc-1brdqhf-0 cKRjba">https://deeplearning4j.org/compare-dl4j-torch7-pylearn.html</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Learning frameworks: a review before finishing 2016</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://medium.com/@ricardo.guerrero/deep-learning-frameworks-a-review-before-finishing-2016-5b3ab4010b06#.a6fdrqssl" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@ricardo.guerrero/deep-learning-frameworks-a-review-before-finishing-2016-5b3ab4010b06#.a6fdrqssl</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>The Anatomy of Deep Learning Frameworks</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://medium.com/@gokul_uf/the-anatomy-of-deep-learning-frameworks-46e2a7af5e47" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@gokul_uf/the-anatomy-of-deep-learning-frameworks-46e2a7af5e47</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Python Deep Learning Frameworks Reviewed</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://indico.io/blog/python-deep-learning-frameworks-reviewed/" class="Link-sc-1brdqhf-0 cKRjba">https://indico.io/blog/python-deep-learning-frameworks-reviewed/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Apple’s deep learning frameworks: BNNS vs. Metal CNN</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://machinethink.net/blog/apple-deep-learning-bnns-versus-metal-cnn/" class="Link-sc-1brdqhf-0 cKRjba">http://machinethink.net/blog/apple-deep-learning-bnns-versus-metal-cnn/</a></p><div class="Box-nv15kw-0 ksEcN"><div display="flex" class="Box-nv15kw-0 jsSpbO"><a href="https://github.com/webizenai/devdocs/tree/main/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-frameworks.md" class="Link-sc-1brdqhf-0 iLYDsn"><svg aria-hidden="true" role="img" class="StyledOcticon-uhnt7w-0 fafffn" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M11.013 1.427a1.75 1.75 0 012.474 0l1.086 1.086a1.75 1.75 0 010 2.474l-8.61 8.61c-.21.21-.47.364-.756.445l-3.251.93a.75.75 0 01-.927-.928l.929-3.25a1.75 1.75 0 01.445-.758l8.61-8.61zm1.414 1.06a.25.25 0 00-.354 0L10.811 3.75l1.439 1.44 1.263-1.263a.25.25 0 000-.354l-1.086-1.086zM11.189 6.25L9.75 4.81l-6.286 6.287a.25.25 0 00-.064.108l-.558 1.953 1.953-.558a.249.249 0 00.108-.064l6.286-6.286z"></path></svg>Edit this page</a><div><span font-size="1" color="auto.gray.7" class="Text-sc-1s3uzov-0 gHwtLv">Last updated on<!-- --> <b>12/28/2022</b></span></div></div></div></div></div></main></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script async="" src="https://www.googletagmanager.com/gtag/js?id="></script><script>
      
      
      if(true) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){window.dataLayer && window.dataLayer.push(arguments);}
        gtag('js', new Date());

        
      }
      </script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-frameworks/";window.___webpackCompilationHash="10c8b9c1f9dde870e591";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-2526e2a471eef3b9c3b2.js"],"app":["/app-f28009dab402ccf9360c.js"],"component---node-modules-gatsby-theme-primer-wiki-src-pages-404-js":["/component---node-modules-gatsby-theme-primer-wiki-src-pages-404-js-bd1c4b7f67a97d4f99af.js"],"component---node-modules-gatsby-theme-primer-wiki-src-templates-latest-query-js":["/component---node-modules-gatsby-theme-primer-wiki-src-templates-latest-query-js-6ed623c5d829c1a69525.js"],"component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js":["/component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js-46274f1a3983fff8a36b.js"]};/*]]>*/</script><script src="/polyfill-2526e2a471eef3b9c3b2.js" nomodule=""></script><script src="/component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js-46274f1a3983fff8a36b.js" async=""></script><script src="/commons-c89ede6cb9a530ac5a37.js" async=""></script><script src="/app-f28009dab402ccf9360c.js" async=""></script><script src="/dc6a8720040df98778fe970bf6c000a41750d3ae-8fdfd959b24cacbf7cee.js" async=""></script><script src="/0e226fb0-1cb0709e5ed968a9c435.js" async=""></script><script src="/f0e45107-3309acb69b4ccd30ce0c.js" async=""></script><script src="/framework-6c63f85700e5678d2c2a.js" async=""></script><script src="/webpack-runtime-1fe3daf7582b39746d36.js" async=""></script></body></html>