<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta data-react-helmet="true" name="twitter:image:alt" content="This repo provides information about the webizen development objectives, considerations and related experimentation!"/><meta data-react-helmet="true" name="twitter:image" content="https://devdocs.webizen.org/graph-visualisation.jpg"/><meta data-react-helmet="true" name="twitter:description" content="Types of RNN 1) Plain Tanh Recurrent Nerual Networks 2) Gated Recurrent Neural Networks (GRU) 3) Long Short-Term Memory (LSTM) Tutorials Th…"/><meta data-react-helmet="true" name="twitter:title" content="RNN and LSTM"/><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"/><meta data-react-helmet="true" property="article:section" content="None"/><meta data-react-helmet="true" property="article:author" content="http://examples.opengraphprotocol.us/profile.html"/><meta data-react-helmet="true" property="article:modified_time" content="2022-12-28T19:22:29.000Z"/><meta data-react-helmet="true" property="article:published_time" content="2015-10-09T00:00:00.000Z"/><meta data-react-helmet="true" property="og:description" content="Types of RNN 1) Plain Tanh Recurrent Nerual Networks 2) Gated Recurrent Neural Networks (GRU) 3) Long Short-Term Memory (LSTM) Tutorials Th…"/><meta data-react-helmet="true" property="og:site_name"/><meta data-react-helmet="true" property="og:image:alt" content="This repo provides information about the webizen development objectives, considerations and related experimentation!"/><meta data-react-helmet="true" property="og:image" content="https://devdocs.webizen.org/graph-visualisation.jpg"/><meta data-react-helmet="true" property="og:url" content="https://devdocs.webizen.org/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rnn-and-lstm/"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:title" content="RNN and LSTM"/><meta data-react-helmet="true" name="image" content="https://devdocs.webizen.org/graph-visualisation.jpg"/><meta data-react-helmet="true" name="description" content="Types of RNN 1) Plain Tanh Recurrent Nerual Networks 2) Gated Recurrent Neural Networks (GRU) 3) Long Short-Term Memory (LSTM) Tutorials Th…"/><meta name="generator" content="Gatsby 4.6.0"/><style data-href="/styles.d9e480e5c6375621c4fd.css" data-identity="gatsby-global-css">.tippy-box[data-animation=fade][data-state=hidden]{opacity:0}[data-tippy-root]{max-width:calc(100vw - 10px)}.tippy-box{background-color:#333;border-radius:4px;color:#fff;font-size:14px;line-height:1.4;outline:0;position:relative;transition-property:visibility,opacity,-webkit-transform;transition-property:transform,visibility,opacity;transition-property:transform,visibility,opacity,-webkit-transform;white-space:normal}.tippy-box[data-placement^=top]>.tippy-arrow{bottom:0}.tippy-box[data-placement^=top]>.tippy-arrow:before{border-top-color:initial;border-width:8px 8px 0;bottom:-7px;left:0;-webkit-transform-origin:center top;transform-origin:center top}.tippy-box[data-placement^=bottom]>.tippy-arrow{top:0}.tippy-box[data-placement^=bottom]>.tippy-arrow:before{border-bottom-color:initial;border-width:0 8px 8px;left:0;top:-7px;-webkit-transform-origin:center bottom;transform-origin:center bottom}.tippy-box[data-placement^=left]>.tippy-arrow{right:0}.tippy-box[data-placement^=left]>.tippy-arrow:before{border-left-color:initial;border-width:8px 0 8px 8px;right:-7px;-webkit-transform-origin:center left;transform-origin:center left}.tippy-box[data-placement^=right]>.tippy-arrow{left:0}.tippy-box[data-placement^=right]>.tippy-arrow:before{border-right-color:initial;border-width:8px 8px 8px 0;left:-7px;-webkit-transform-origin:center right;transform-origin:center right}.tippy-box[data-inertia][data-state=visible]{transition-timing-function:cubic-bezier(.54,1.5,.38,1.11)}.tippy-arrow{color:#333;height:16px;width:16px}.tippy-arrow:before{border-color:transparent;border-style:solid;content:"";position:absolute}.tippy-content{padding:5px 9px;position:relative;z-index:1}.tippy-box[data-theme~=light]{background-color:#fff;box-shadow:0 0 20px 4px rgba(154,161,177,.15),0 4px 80px -8px rgba(36,40,47,.25),0 4px 4px -2px rgba(91,94,105,.15);color:#26323d}.tippy-box[data-theme~=light][data-placement^=top]>.tippy-arrow:before{border-top-color:#fff}.tippy-box[data-theme~=light][data-placement^=bottom]>.tippy-arrow:before{border-bottom-color:#fff}.tippy-box[data-theme~=light][data-placement^=left]>.tippy-arrow:before{border-left-color:#fff}.tippy-box[data-theme~=light][data-placement^=right]>.tippy-arrow:before{border-right-color:#fff}.tippy-box[data-theme~=light]>.tippy-backdrop{background-color:#fff}.tippy-box[data-theme~=light]>.tippy-svg-arrow{fill:#fff}html{font-family:SF Pro SC,SF Pro Text,SF Pro Icons,PingFang SC,Helvetica Neue,Helvetica,Arial,sans-serif}body{word-wrap:break-word;-ms-hyphens:auto;-webkit-hyphens:auto;hyphens:auto;overflow-wrap:break-word;-ms-word-break:break-all;word-break:break-word}blockquote,body,dd,dt,fieldset,figure,h1,h2,h3,h4,h5,h6,hr,html,iframe,legend,p,pre,textarea{margin:0;padding:0}h1,h2,h3,h4,h5,h6{font-size:100%;font-weight:400}button,input,select{margin:0}html{box-sizing:border-box}*,:after,:before{box-sizing:inherit}img,video{height:auto;max-width:100%}iframe{border:0}table{border-collapse:collapse;border-spacing:0}td,th{padding:0}</style><style data-styled="" data-styled-version="5.3.5">.fnAJEh{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;font-size:14px;background-color:#005cc5;color:#ffffff;padding:16px;}/*!sc*/
.fnAJEh:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.fnAJEh:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.czsBQU{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;color:#ffffff;margin-right:16px;}/*!sc*/
.czsBQU:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.czsBQU:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.kLOWMo{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;font-family:SFMono-Regular,Consolas,"Liberation Mono",Menlo,Courier,monospace;color:#ffffff;}/*!sc*/
.kLOWMo:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.kLOWMo:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.kEUvCO{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;display:block;color:inherit;margin-left:24px;}/*!sc*/
.kEUvCO:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.kEUvCO:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.HGjBQ{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;display:block;}/*!sc*/
.HGjBQ:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.HGjBQ:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.fdzjHV{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;color:#24292e;display:block;}/*!sc*/
.fdzjHV:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.fdzjHV:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.bQLMRL{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;font-size:16px;display:inline-block;padding-top:4px;padding-bottom:4px;color:#586069;font-weight:medium;}/*!sc*/
.bQLMRL:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.bQLMRL:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){.bQLMRL{font-size:14px;}}/*!sc*/
.ekSqTm{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;padding:8px;margin-left:-32px;color:#2f363d;}/*!sc*/
.ekSqTm:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.ekSqTm:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.cKRjba{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
.cKRjba:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.cKRjba:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.iLYDsn{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;margin-bottom:4px;}/*!sc*/
.iLYDsn:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.iLYDsn:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
data-styled.g1[id="Link-sc-1brdqhf-0"]{content:"fnAJEh,czsBQU,kLOWMo,kEUvCO,HGjBQ,fdzjHV,bQLMRL,ekSqTm,cKRjba,iLYDsn,"}/*!sc*/
.EuMgV{z-index:20;width:auto;height:auto;-webkit-clip:auto;clip:auto;position:absolute;overflow:hidden;}/*!sc*/
.EuMgV:not(:focus){-webkit-clip:rect(1px,1px,1px,1px);clip:rect(1px,1px,1px,1px);-webkit-clip-path:inset(50%);clip-path:inset(50%);height:1px;width:1px;margin:-1px;padding:0;}/*!sc*/
data-styled.g2[id="skip-link__SkipLink-sc-1z0kjxc-0"]{content:"EuMgV,"}/*!sc*/
.fbaWCe{display:none;margin-left:8px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.fbaWCe{display:inline;}}/*!sc*/
.bLwTGz{font-weight:600;display:inline-block;margin-bottom:4px;}/*!sc*/
.cQAYyE{font-weight:600;}/*!sc*/
.gHwtLv{font-size:14px;color:#444d56;margin-top:4px;}/*!sc*/
data-styled.g4[id="Text-sc-1s3uzov-0"]{content:"fbaWCe,bLwTGz,cQAYyE,gHwtLv,"}/*!sc*/
.ifkhtm{background-color:#ffffff;color:#24292e;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;min-height:100vh;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}/*!sc*/
.gSrgIV{top:0;z-index:1;position:-webkit-sticky;position:sticky;}/*!sc*/
.iTlzRc{padding-left:16px;padding-right:16px;background-color:#24292e;color:rgba(255,255,255,0.7);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:66px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.iTlzRc{padding-left:24px;padding-right:24px;}}/*!sc*/
.kCrfOd{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.gELiHA{margin-left:24px;display:none;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.gELiHA{display:block;}}/*!sc*/
.gYHnkh{position:relative;}/*!sc*/
.dMFMzl{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/
.jhCmHN{display:none;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.jhCmHN{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}/*!sc*/
.elXfHl{color:rgba(255,255,255,0.7);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.gjFLbZ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.gjFLbZ{display:none;}}/*!sc*/
.gucKKf{color:rgba(255,255,255,0.7);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:0;background-color:none;cursor:pointer;}/*!sc*/
.gucKKf:hover{fill:rgba(255,255,255,0.7);color:rgba(255,255,255,0.7);}/*!sc*/
.gucKKf svg{fill:rgba(255,255,255,0.7);}/*!sc*/
.fBMuRw{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;}/*!sc*/
.bQaVuO{color:#2f363d;background-color:#fafbfc;display:none;height:calc(100vh - 66px);min-width:260px;max-width:360px;position:-webkit-sticky;position:sticky;top:66px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.bQaVuO{display:block;}}/*!sc*/
.eeDmz{height:100%;border-style:solid;border-color:#e1e4e8;border-width:0;border-right-width:1px;border-radius:0;}/*!sc*/
.kSoTbZ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}/*!sc*/
.nElVQ{padding:24px;border-style:solid;border-color:#e1e4e8;border-width:0;border-radius:0;border-top-width:1px;}/*!sc*/
.iXtyim{margin-left:0;padding-top:4px;padding-bottom:4px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;border-style:solid;border-color:#e1e4e8;border-width:0;border-radius:0;border-bottom-width:0;}/*!sc*/
.vaHQm{margin-bottom:4px;margin-top:4px;font-size:14px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
.hIjKHD{color:#586069;font-weight:400;display:block;}/*!sc*/
.icYakO{padding-left:8px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;}/*!sc*/
.jLseWZ{margin-left:16px;padding-top:0;padding-bottom:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;border-style:solid;border-color:#e1e4e8;border-width:0;border-radius:0;border-bottom-width:0;}/*!sc*/
.kRSqJi{margin-bottom:0;margin-top:8px;font-size:14px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
.klfmeZ{max-width:1440px;-webkit-flex:1;-ms-flex:1;flex:1;}/*!sc*/
.TZbDV{padding:24px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;width:100%;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-flex-direction:row-reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse;}/*!sc*/
@media screen and (min-width:544px){.TZbDV{padding:32px;}}/*!sc*/
@media screen and (min-width:768px){.TZbDV{padding:40px;}}/*!sc*/
@media screen and (min-width:1012px){.TZbDV{padding:48px;}}/*!sc*/
.DPDMP{display:none;max-height:calc(100vh - 66px - 24px);position:-webkit-sticky;position:sticky;top:90px;width:220px;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;margin-left:40px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){.DPDMP{display:block;}}/*!sc*/
.gUNLMu{margin:0;padding:0;}/*!sc*/
.bzTeHX{padding-left:0;}/*!sc*/
.bnaGYs{padding-left:16px;}/*!sc*/
.meQBK{width:100%;}/*!sc*/
.fkoaiG{margin-bottom:24px;}/*!sc*/
.biGwYR{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.jYYExC{margin-bottom:32px;background-color:#f6f8fa;display:block;border-width:1px;border-style:solid;border-color:#e1e4e8;border-radius:6px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){.jYYExC{display:none;}}/*!sc*/
.hgiZBa{padding:16px;}/*!sc*/
.hnQOQh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.gEqaxf{padding:16px;border-top:1px solid;border-color:border.gray;}/*!sc*/
.ksEcN{margin-top:64px;padding-top:32px;padding-bottom:32px;border-style:solid;border-color:#e1e4e8;border-width:0;border-top-width:1px;border-radius:0;}/*!sc*/
.jsSpbO{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
data-styled.g5[id="Box-nv15kw-0"]{content:"ifkhtm,gSrgIV,iTlzRc,kCrfOd,gELiHA,gYHnkh,dMFMzl,jhCmHN,elXfHl,gjFLbZ,gucKKf,fBMuRw,bQaVuO,eeDmz,kSoTbZ,nElVQ,iXtyim,vaHQm,hIjKHD,icYakO,jLseWZ,kRSqJi,klfmeZ,TZbDV,DPDMP,gUNLMu,bzTeHX,bnaGYs,meQBK,fkoaiG,biGwYR,jYYExC,hgiZBa,hnQOQh,gEqaxf,ksEcN,jsSpbO,"}/*!sc*/
.cjGjQg{position:relative;display:inline-block;padding:6px 16px;font-family:inherit;font-weight:600;line-height:20px;white-space:nowrap;vertical-align:middle;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;border-radius:6px;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;font-size:14px;}/*!sc*/
.cjGjQg:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
.cjGjQg:focus{outline:none;}/*!sc*/
.cjGjQg:disabled{cursor:default;}/*!sc*/
.cjGjQg:disabled svg{opacity:0.6;}/*!sc*/
data-styled.g6[id="ButtonBase-sc-181ps9o-0"]{content:"cjGjQg,"}/*!sc*/
.fafffn{margin-right:8px;}/*!sc*/
data-styled.g8[id="StyledOcticon-uhnt7w-0"]{content:"bhRGQB,fafffn,"}/*!sc*/
.fTkTnC{font-weight:600;font-size:32px;margin:0;font-size:12px;font-weight:500;color:#959da5;margin-bottom:4px;text-transform:uppercase;font-family:Content-font,Roboto,sans-serif;}/*!sc*/
.glhHOU{font-weight:600;font-size:32px;margin:0;margin-right:8px;}/*!sc*/
.ffNRvO{font-weight:600;font-size:32px;margin:0;}/*!sc*/
data-styled.g12[id="Heading-sc-1cjoo9h-0"]{content:"fTkTnC,glhHOU,ffNRvO,"}/*!sc*/
.ifFLoZ{color:#0366d6;border:1px solid rgba(27,31,35,0.15);background-color:#fafbfc;box-shadow:0 1px 0 rgba(27,31,35,0.04);margin-left:16px;}/*!sc*/
.ifFLoZ:hover{color:#ffffff;background-color:#0366d6;border-color:rgba(27,31,35,0.15);box-shadow:0 1px 0 rgba(27,31,35,0.1);}/*!sc*/
.ifFLoZ:focus{border-color:rgba(27,31,35,0.15);box-shadow:0 0 0 3px rgba(0,92,197,0.4);}/*!sc*/
.ifFLoZ:active{color:#ffffff;background-color:hsla(212,97%,40%,1);box-shadow:inset 0 1px 0 rgba(5,38,76,0.2);border-color:rgba(27,31,35,0.15);}/*!sc*/
.ifFLoZ:disabled{color:rgba(3,102,214,0.5);background-color:#fafbfc;border-color:rgba(27,31,35,0.15);}/*!sc*/
.fKTxJr{color:#0366d6;border:1px solid rgba(27,31,35,0.15);background-color:#fafbfc;box-shadow:0 1px 0 rgba(27,31,35,0.04);}/*!sc*/
.fKTxJr:hover{color:#ffffff;background-color:#0366d6;border-color:rgba(27,31,35,0.15);box-shadow:0 1px 0 rgba(27,31,35,0.1);}/*!sc*/
.fKTxJr:focus{border-color:rgba(27,31,35,0.15);box-shadow:0 0 0 3px rgba(0,92,197,0.4);}/*!sc*/
.fKTxJr:active{color:#ffffff;background-color:hsla(212,97%,40%,1);box-shadow:inset 0 1px 0 rgba(5,38,76,0.2);border-color:rgba(27,31,35,0.15);}/*!sc*/
.fKTxJr:disabled{color:rgba(3,102,214,0.5);background-color:#fafbfc;border-color:rgba(27,31,35,0.15);}/*!sc*/
.cXFtEt{color:#0366d6;border:1px solid rgba(27,31,35,0.15);background-color:#fafbfc;box-shadow:0 1px 0 rgba(27,31,35,0.04);margin-left:16px;}/*!sc*/
.cXFtEt:hover{color:#ffffff;background-color:#0366d6;border-color:rgba(27,31,35,0.15);box-shadow:0 1px 0 rgba(27,31,35,0.1);}/*!sc*/
.cXFtEt:focus{border-color:rgba(27,31,35,0.15);box-shadow:0 0 0 3px rgba(0,92,197,0.4);}/*!sc*/
.cXFtEt:active{color:#ffffff;background-color:hsla(212,97%,40%,1);box-shadow:inset 0 1px 0 rgba(5,38,76,0.2);border-color:rgba(27,31,35,0.15);}/*!sc*/
.cXFtEt:disabled{color:rgba(3,102,214,0.5);background-color:#fafbfc;border-color:rgba(27,31,35,0.15);}/*!sc*/
data-styled.g13[id="ButtonOutline-sc-15gta9l-0"]{content:"ifFLoZ,fKTxJr,cXFtEt,"}/*!sc*/
.iEGqHu{color:rgba(255,255,255,0.7);background-color:transparent;border:1px solid #444d56;box-shadow:none;}/*!sc*/
data-styled.g14[id="dark-button__DarkButton-sc-bvvmfe-0"]{content:"iEGqHu,"}/*!sc*/
.ljCWQd{border:0;font-size:inherit;font-family:inherit;background-color:transparent;-webkit-appearance:none;color:inherit;width:100%;}/*!sc*/
.ljCWQd:focus{outline:0;}/*!sc*/
data-styled.g15[id="TextInput__Input-sc-1apmpmt-0"]{content:"ljCWQd,"}/*!sc*/
.dHfzvf{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;min-height:34px;font-size:14px;line-height:20px;color:#24292e;vertical-align:middle;background-repeat:no-repeat;background-position:right 8px center;border:1px solid #e1e4e8;border-radius:6px;outline:none;box-shadow:inset 0 1px 0 rgba(225,228,232,0.2);padding:6px 12px;width:240px;}/*!sc*/
.dHfzvf .TextInput-icon{-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;color:#959da5;margin:0 8px;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;}/*!sc*/
.dHfzvf:focus-within{border-color:#0366d6;box-shadow:0 0 0 3px rgba(3,102,214,0.3);}/*!sc*/
@media (min-width:768px){.dHfzvf{font-size:14px;}}/*!sc*/
data-styled.g16[id="TextInput__Wrapper-sc-1apmpmt-1"]{content:"dHfzvf,"}/*!sc*/
.khRwtY{font-size:16px !important;color:rgba(255,255,255,0.7);background-color:rgba(255,255,255,0.07);border:1px solid transparent;box-shadow:none;}/*!sc*/
.khRwtY:focus{border:1px solid #444d56 outline:none;box-shadow:none;}/*!sc*/
data-styled.g17[id="dark-text-input__DarkTextInput-sc-1s2iwzn-0"]{content:"khRwtY,"}/*!sc*/
.bqVpte.active{font-weight:600;color:#2f363d;}/*!sc*/
data-styled.g19[id="nav-items__NavLink-sc-tqz5wl-0"]{content:"bqVpte,"}/*!sc*/
.kEKZhO.active{font-weight:600;color:#2f363d;}/*!sc*/
data-styled.g20[id="nav-items__NavBox-sc-tqz5wl-1"]{content:"kEKZhO,"}/*!sc*/
.gCPbFb{margin-top:24px;margin-bottom:16px;-webkit-scroll-margin-top:90px;-moz-scroll-margin-top:90px;-ms-scroll-margin-top:90px;scroll-margin-top:90px;}/*!sc*/
.gCPbFb .octicon-link{visibility:hidden;}/*!sc*/
.gCPbFb:hover .octicon-link,.gCPbFb:focus-within .octicon-link{visibility:visible;}/*!sc*/
data-styled.g22[id="heading__StyledHeading-sc-1fu06k9-0"]{content:"gCPbFb,"}/*!sc*/
.fGjcEF{margin-top:0;padding-bottom:4px;font-size:32px;border-bottom:1px solid #e1e4e8;}/*!sc*/
data-styled.g23[id="heading__StyledH1-sc-1fu06k9-1"]{content:"fGjcEF,"}/*!sc*/
.fvbkiW{padding-bottom:4px;font-size:24px;border-bottom:1px solid #e1e4e8;}/*!sc*/
data-styled.g24[id="heading__StyledH2-sc-1fu06k9-2"]{content:"fvbkiW,"}/*!sc*/
.daTFSy{height:4px;padding:0;margin:24px 0;background-color:#e1e4e8;border:0;}/*!sc*/
data-styled.g29[id="horizontal-rule__HorizontalRule-sc-1731hye-0"]{content:"daTFSy,"}/*!sc*/
.elBfYx{max-width:100%;box-sizing:content-box;background-color:#ffffff;}/*!sc*/
data-styled.g30[id="image__Image-sc-1r30dtv-0"]{content:"elBfYx,"}/*!sc*/
.dFVIUa{padding-left:2em;margin-bottom:4px;}/*!sc*/
.dFVIUa ul,.dFVIUa ol{margin-top:0;margin-bottom:0;}/*!sc*/
.dFVIUa li{line-height:1.6;}/*!sc*/
.dFVIUa li > p{margin-top:16px;}/*!sc*/
.dFVIUa li + li{margin-top:8px;}/*!sc*/
data-styled.g32[id="list__List-sc-s5kxp2-0"]{content:"dFVIUa,"}/*!sc*/
.iNQqSl{margin:0 0 16px;}/*!sc*/
data-styled.g34[id="paragraph__Paragraph-sc-17pab92-0"]{content:"iNQqSl,"}/*!sc*/
.drDDht{z-index:0;}/*!sc*/
data-styled.g37[id="layout___StyledBox-sc-7a5ttt-0"]{content:"drDDht,"}/*!sc*/
.flyUPp{list-style:none;}/*!sc*/
data-styled.g39[id="table-of-contents___StyledBox-sc-1jtv948-0"]{content:"flyUPp,"}/*!sc*/
.bPkrfP{grid-area:table-of-contents;overflow:auto;}/*!sc*/
data-styled.g40[id="post-page___StyledBox-sc-17hbw1s-0"]{content:"bPkrfP,"}/*!sc*/
</style><title data-react-helmet="true">RNN and LSTM - Webizen Development Related Documentation.</title><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper picture.object-fit-polyfill{position:static!important}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){if(void 0===e.target.dataset.mainImage)return;if(void 0===e.target.dataset.gatsbyImageSsr)return;const t=e.target;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="icon" href="/favicon-32x32.png?v=202c3b6fa23c481f8badd00dc2119591" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="sitemap" type="application/xml" href="/sitemap/sitemap-index.xml"/><link rel="preconnect" href="https://www.googletagmanager.com"/><link rel="dns-prefetch" href="https://www.googletagmanager.com"/><link as="script" rel="preload" href="/webpack-runtime-1fe3daf7582b39746d36.js"/><link as="script" rel="preload" href="/framework-6c63f85700e5678d2c2a.js"/><link as="script" rel="preload" href="/f0e45107-3309acb69b4ccd30ce0c.js"/><link as="script" rel="preload" href="/0e226fb0-1cb0709e5ed968a9c435.js"/><link as="script" rel="preload" href="/dc6a8720040df98778fe970bf6c000a41750d3ae-8fdfd959b24cacbf7cee.js"/><link as="script" rel="preload" href="/app-f28009dab402ccf9360c.js"/><link as="script" rel="preload" href="/commons-c89ede6cb9a530ac5a37.js"/><link as="script" rel="preload" href="/component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js-46274f1a3983fff8a36b.js"/><link as="fetch" rel="preload" href="/page-data/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rnn-and-lstm/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/2230547434.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/2320115945.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/3495835395.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/451533639.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><a class="Link-sc-1brdqhf-0 fnAJEh skip-link__SkipLink-sc-1z0kjxc-0 EuMgV" color="auto.white" href="#skip-nav" font-size="1">Skip to content</a><div display="flex" color="text.primary" class="Box-nv15kw-0 ifkhtm"><div class="Box-nv15kw-0 gSrgIV"><div display="flex" height="66" color="header.text" class="Box-nv15kw-0 iTlzRc"><div display="flex" class="Box-nv15kw-0 kCrfOd"><a color="header.logo" mr="3" class="Link-sc-1brdqhf-0 czsBQU" href="/"><svg aria-hidden="true" role="img" class="StyledOcticon-uhnt7w-0 bhRGQB" viewBox="0 0 16 16" width="32" height="32" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path></svg></a><a color="header.logo" font-family="mono" class="Link-sc-1brdqhf-0 kLOWMo" href="/">Wiki</a><div display="none,,,block" class="Box-nv15kw-0 gELiHA"><div role="combobox" aria-expanded="false" aria-haspopup="listbox" aria-labelledby="downshift-search-label" class="Box-nv15kw-0 gYHnkh"><span class="TextInput__Wrapper-sc-1apmpmt-1 dHfzvf dark-text-input__DarkTextInput-sc-1s2iwzn-0 khRwtY TextInput-wrapper" width="240"><input type="text" aria-autocomplete="list" aria-labelledby="downshift-search-label" autoComplete="off" value="" id="downshift-search-input" placeholder="Search Wiki" class="TextInput__Input-sc-1apmpmt-0 ljCWQd"/></span></div></div></div><div display="flex" class="Box-nv15kw-0 dMFMzl"><div display="none,,,flex" class="Box-nv15kw-0 jhCmHN"><div display="flex" color="header.text" class="Box-nv15kw-0 elXfHl"><a display="block" color="inherit" target="_blank" rel="noopener noreferrer" href="https://github.com/webizenai/devdocs/" class="Link-sc-1brdqhf-0 kEUvCO">Github</a><a display="block" color="inherit" target="_blank" rel="noopener noreferrer" href="https://twitter.com/webcivics" class="Link-sc-1brdqhf-0 kEUvCO">Twitter</a></div><button aria-label="Theme" aria-expanded="false" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 cjGjQg ifFLoZ iEGqHu"><svg aria-hidden="true" role="img" class="octicon octicon-sun" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z"></path></svg></button></div><div display="flex,,,none" class="Box-nv15kw-0 gjFLbZ"><button aria-label="Search" aria-expanded="false" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 cjGjQg fKTxJr iEGqHu"><svg aria-hidden="true" role="img" class="octicon octicon-search" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M11.5 7a4.499 4.499 0 11-8.998 0A4.499 4.499 0 0111.5 7zm-.82 4.74a6 6 0 111.06-1.06l3.04 3.04a.75.75 0 11-1.06 1.06l-3.04-3.04z"></path></svg></button></div><button aria-label="Show Graph Visualisation" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 cjGjQg cXFtEt iEGqHu"><div title="Show Graph Visualisation" aria-label="Show Graph Visualisation" color="header.text" display="flex" class="Box-nv15kw-0 gucKKf"><svg t="1607341341241" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" width="20" height="20"><path d="M512 512m-125.866667 0a125.866667 125.866667 0 1 0 251.733334 0 125.866667 125.866667 0 1 0-251.733334 0Z"></path><path d="M512 251.733333m-72.533333 0a72.533333 72.533333 0 1 0 145.066666 0 72.533333 72.533333 0 1 0-145.066666 0Z"></path><path d="M614.4 238.933333c0 4.266667 2.133333 8.533333 2.133333 12.8 0 19.2-4.266667 36.266667-12.8 51.2 81.066667 36.266667 138.666667 117.333333 138.666667 211.2C742.4 640 640 744.533333 512 744.533333s-230.4-106.666667-230.4-232.533333c0-93.866667 57.6-174.933333 138.666667-211.2-8.533333-14.933333-12.8-32-12.8-51.2 0-4.266667 0-8.533333 2.133333-12.8-110.933333 42.666667-189.866667 147.2-189.866667 273.066667 0 160 130.133333 292.266667 292.266667 292.266666S804.266667 672 804.266667 512c0-123.733333-78.933333-230.4-189.866667-273.066667z"></path><path d="M168.533333 785.066667m-72.533333 0a72.533333 72.533333 0 1 0 145.066667 0 72.533333 72.533333 0 1 0-145.066667 0Z"></path><path d="M896 712.533333m-61.866667 0a61.866667 61.866667 0 1 0 123.733334 0 61.866667 61.866667 0 1 0-123.733334 0Z"></path><path d="M825.6 772.266667c-74.666667 89.6-187.733333 147.2-313.6 147.2-93.866667 0-181.333333-32-249.6-87.466667-10.666667 19.2-25.6 34.133333-44.8 44.8C298.666667 942.933333 401.066667 981.333333 512 981.333333c149.333333 0 281.6-70.4 366.933333-177.066666-21.333333-4.266667-40.533333-17.066667-53.333333-32zM142.933333 684.8c-25.6-53.333333-38.4-110.933333-38.4-172.8C104.533333 288 288 104.533333 512 104.533333S919.466667 288 919.466667 512c0 36.266667-6.4 72.533333-14.933334 106.666667 23.466667 2.133333 42.666667 10.666667 57.6 25.6 12.8-42.666667 19.2-87.466667 19.2-132.266667 0-258.133333-211.2-469.333333-469.333333-469.333333S42.666667 253.866667 42.666667 512c0 74.666667 17.066667 142.933333 46.933333 204.8 14.933333-14.933333 32-27.733333 53.333333-32z"></path></svg><span display="none,,,inline" class="Text-sc-1s3uzov-0 fbaWCe">Show Graph Visualisation</span></div></button><div display="flex,,,none" class="Box-nv15kw-0 gjFLbZ"><button aria-label="Menu" aria-expanded="false" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 cjGjQg ifFLoZ iEGqHu"><svg aria-hidden="true" role="img" class="octicon octicon-three-bars" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M1 2.75A.75.75 0 011.75 2h12.5a.75.75 0 110 1.5H1.75A.75.75 0 011 2.75zm0 5A.75.75 0 011.75 7h12.5a.75.75 0 110 1.5H1.75A.75.75 0 011 7.75zM1.75 12a.75.75 0 100 1.5h12.5a.75.75 0 100-1.5H1.75z"></path></svg></button></div></div></div></div><div display="flex" class="Box-nv15kw-0 layout___StyledBox-sc-7a5ttt-0 fBMuRw drDDht"><div display="none,,,block" height="calc(100vh - 66px)" color="auto.gray.8" class="Box-nv15kw-0 bQaVuO"><div height="100%" style="overflow:auto" class="Box-nv15kw-0 eeDmz"><div display="flex" class="Box-nv15kw-0 kSoTbZ"><div class="Box-nv15kw-0 nElVQ"><div display="flex" class="Box-nv15kw-0 kSoTbZ"><h2 color="text.disabled" font-size="12px" font-weight="500" class="Heading-sc-1cjoo9h-0 fTkTnC">Categories</h2><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Commercial</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Core Services</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Core Technologies</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Database Requirements</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Host Service Requirements</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">ICT Stack</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Implementation V1</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Non-HTTP(s) Protocols</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Old-Work-Archives</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">2018-Webizen-Net-Au</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">_Link_library_links</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">_Posts</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/about/">about</a><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/the-human-centric-infosphere/">An Overview</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/">Resource Library</a><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/">Handong1587</a><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">_Posts</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Computer_science</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Computer_vision</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Deep_learning</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2021-07-28-3d/">3D</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-cnn-compression-acceleration/">Acceleration and Model Compression</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-knowledge-distillation/">Acceleration and Model Compression</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-adversarial-attacks-and-defences/">Adversarial Attacks and Defences</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-audio-image-video-generation/">Audio / Image / Video Generation</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2022-06-27-bev/">BEV</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recognition/">Classification / Recognition</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-autonomous-driving/">Deep Learning and Autonomous Driving</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-pose-estimation/">Deep Learning Applications</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-applications/">Deep Learning Applications</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-courses/">Deep learning Courses</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-frameworks/">Deep Learning Frameworks</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-resources/">Deep Learning Resources</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-software-hardware/">Deep Learning Software and Hardware</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tricks/">Deep Learning Tricks</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tutorials/">Deep Learning Tutorials</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-with-ml/">Deep Learning with Machine Learning</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-face-recognition/">Face Recognition</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-fun-with-deep-learning/">Fun With Deep Learning</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gan/">Generative Adversarial Networks</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gcn/">Graph Convolutional Networks</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-captioning/">Image / Video Captioning</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-retrieval/">Image Retrieval</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2018-09-03-keep-up-with-new-trends/">Keep Up With New Trends</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-lidar-3d-detection/">LiDAR 3D Object Detection</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nlp/">Natural Language Processing</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nas/">Neural Architecture Search</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-counting/">Object Counting</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-detection/">Object Detection</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-ocr/">OCR</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-optical-flow/">Optical Flow</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-re-id/">Re-ID</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recommendation-system/">Recommendation System</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rl/">Reinforcement Learning</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a aria-current="page" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte active" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rnn-and-lstm/">RNN and LSTM</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-segmentation/">Segmentation</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-style-transfer/">Style Transfer</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-super-resolution/">Super-Resolution</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-tracking/">Tracking</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-training-dnn/">Training Deep Neural Networks</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-transfer-learning/">Transfer Learning</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-unsupervised-learning/">Unsupervised Learning</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-video-applications/">Video Applications</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-vqa/">Visual Question Answering</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-visulizing-interpreting-cnn/">Visualizing and Interpreting Convolutional Neural Network</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Leisure</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Machine_learning</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Mathematics</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Programming_study</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Reading_and_thoughts</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Study</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Working_on_linux</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Working_on_mac</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Working_on_windows</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Drafts</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div></div></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Webizen 2.0</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 fdzjHV bqVpte" display="block" sx="[object Object]" href="/">Webizen V1 Project Documentation</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div></div></div></div></div></div><main class="Box-nv15kw-0 klfmeZ"><div id="skip-nav" display="flex" width="100%" class="Box-nv15kw-0 TZbDV"><div display="none,,block" class="Box-nv15kw-0 post-page___StyledBox-sc-17hbw1s-0 DPDMP bPkrfP"><span display="inline-block" font-weight="bold" class="Text-sc-1s3uzov-0 bLwTGz">On this page</span><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#types-of-rnn" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Types of RNN</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#tutorials" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Tutorials</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#how-to-build-a-recurrent-neural-network-in-tensorflow" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">How to build a Recurrent Neural Network in TensorFlow</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#unfolding-rnns" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Unfolding RNNs</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#train-rnn" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Train RNN</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#learn-to-execute-programs" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Learn To Execute Programs</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#attention-models" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Attention Models</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#papers" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Papers</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#lstmvis" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">LSTMVis</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#lightrnn" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">LightRNN</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#projects" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Projects</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#blogs" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Blogs</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#optimizing-rnn-baidu-silicon-valley-ai-lab" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Optimizing RNN (Baidu Silicon Valley AI Lab)</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#resources" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Resources</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#reading-and-questions" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Reading and Questions</a></li></ul></div><div width="100%" class="Box-nv15kw-0 meQBK"><div class="Box-nv15kw-0 fkoaiG"><div display="flex" class="Box-nv15kw-0 biGwYR"><h1 class="Heading-sc-1cjoo9h-0 glhHOU">RNN and LSTM</h1></div></div><div display="block,,none" class="Box-nv15kw-0 jYYExC"><div class="Box-nv15kw-0 hgiZBa"><div display="flex" class="Box-nv15kw-0 hnQOQh"><span font-weight="bold" class="Text-sc-1s3uzov-0 cQAYyE">On this page</span></div></div><div class="Box-nv15kw-0 gEqaxf"><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#types-of-rnn" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Types of RNN</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#tutorials" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Tutorials</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#how-to-build-a-recurrent-neural-network-in-tensorflow" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">How to build a Recurrent Neural Network in TensorFlow</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#unfolding-rnns" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Unfolding RNNs</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#train-rnn" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Train RNN</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#learn-to-execute-programs" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Learn To Execute Programs</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#attention-models" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Attention Models</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#papers" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Papers</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#lstmvis" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">LSTMVis</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#lightrnn" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">LightRNN</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#projects" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Projects</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#blogs" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Blogs</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#optimizing-rnn-baidu-silicon-valley-ai-lab" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Optimizing RNN (Baidu Silicon Valley AI Lab)</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#resources" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Resources</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#reading-and-questions" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Reading and Questions</a></li></ul></div></div><h1 id="types-of-rnn" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#types-of-rnn" color="auto.gray.8" aria-label="Types of RNN permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Types of RNN</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl">1) Plain Tanh Recurrent Nerual Networks</p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl">2) Gated Recurrent Neural Networks (GRU)</p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl">3) Long Short-Term Memory (LSTM)</p><h1 id="tutorials" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#tutorials" color="auto.gray.8" aria-label="Tutorials permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Tutorials</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>The Unreasonable Effectiveness of Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" class="Link-sc-1brdqhf-0 cKRjba">http://karpathy.github.io/2015/05/21/rnn-effectiveness/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Understanding LSTM Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" class="Link-sc-1brdqhf-0 cKRjba">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></li><li>blog(zh): <a target="_blank" rel="noopener noreferrer" href="http://www.jianshu.com/p/9dc9f41f0b29" class="Link-sc-1brdqhf-0 cKRjba">http://www.jianshu.com/p/9dc9f41f0b29</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A Beginner’s Guide to Recurrent Networks and LSTMs</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://deeplearning4j.org/lstm.html" class="Link-sc-1brdqhf-0 cKRjba">http://deeplearning4j.org/lstm.html</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A Deep Dive into Recurrent Neural Nets</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://nikhilbuduma.com/2015/01/11/a-deep-dive-into-recurrent-neural-networks/" class="Link-sc-1brdqhf-0 cKRjba">http://nikhilbuduma.com/2015/01/11/a-deep-dive-into-recurrent-neural-networks/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Exploring LSTMs</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://blog.echen.me/2017/05/30/exploring-lstms/" class="Link-sc-1brdqhf-0 cKRjba">http://blog.echen.me/2017/05/30/exploring-lstms/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A tutorial on training recurrent neural networks, covering BPPT, RTRL, EKF and the &quot;echo state network&quot; approach</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf</a></li><li>slides: <a target="_blank" rel="noopener noreferrer" href="http://deeplearning.cs.cmu.edu/notes/shaoweiwang.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://deeplearning.cs.cmu.edu/notes/shaoweiwang.pdf</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Long Short-Term Memory: Tutorial on LSTM Recurrent Networks</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://people.idsia.ch/~juergen/lstm/index.htm" class="Link-sc-1brdqhf-0 cKRjba">http://people.idsia.ch/~juergen/lstm/index.htm</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>LSTM implementation explained</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://apaszke.github.io/lstm-explained.html" class="Link-sc-1brdqhf-0 cKRjba">http://apaszke.github.io/lstm-explained.html</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Recurrent Neural Networks Tutorial</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>Part 1(Introduction to RNNs): <a target="_blank" rel="noopener noreferrer" href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/" class="Link-sc-1brdqhf-0 cKRjba">http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/</a></li><li>Part 2(Implementing a RNN using Python and Theano): <a target="_blank" rel="noopener noreferrer" href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/" class="Link-sc-1brdqhf-0 cKRjba">http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/</a></li><li>Part 3(Understanding the Backpropagation Through Time (BPTT) algorithm): <a target="_blank" rel="noopener noreferrer" href="http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/" class="Link-sc-1brdqhf-0 cKRjba">http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/</a></li><li>Part 4(Implementing a GRU/LSTM RNN): <a target="_blank" rel="noopener noreferrer" href="http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/" class="Link-sc-1brdqhf-0 cKRjba">http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Recurrent Neural Networks in DL4J</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://deeplearning4j.org/usingrnns.html" class="Link-sc-1brdqhf-0 cKRjba">http://deeplearning4j.org/usingrnns.html</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Learning RNN Hierarchies</strong></p><img src="https://cloud.githubusercontent.com/assets/8753078/11612806/46e59834-9c2e-11e5-8309-7a93aa72383c.png" class="image__Image-sc-1r30dtv-0 elBfYx"/><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/pranv/lrh/blob/master/about.md" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/pranv/lrh/blob/master/about.md</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Element-Research Torch RNN Tutorial for recurrent neural nets : let&#x27;s predict time series with a laptop GPU</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://christopher5106.github.io/deep/learning/2016/07/14/element-research-torch-rnn-tutorial.html" class="Link-sc-1brdqhf-0 cKRjba">https://christopher5106.github.io/deep/learning/2016/07/14/element-research-torch-rnn-tutorial.html</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>RNNs in Tensorflow, a Practical Guide and Undocumented Features</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/" class="Link-sc-1brdqhf-0 cKRjba">http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Learning about LSTMs using Torch</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://kbullaughey.github.io/lstm-play/" class="Link-sc-1brdqhf-0 cKRjba">http://kbullaughey.github.io/lstm-play/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/kbullaughey/lstm-play" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/kbullaughey/lstm-play</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Build a Neural Network (LIVE)</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: LSTM</li><li>youtube: <a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=KvoZU-ItDiE" class="Link-sc-1brdqhf-0 cKRjba">https://www.youtube.com/watch?v=KvoZU-ItDiE</a></li><li>mirror: <a target="_blank" rel="noopener noreferrer" href="https://pan.baidu.com/s/1i4KoumL" class="Link-sc-1brdqhf-0 cKRjba">https://pan.baidu.com/s/1i4KoumL</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/llSourcell/build_a_neural_net_live" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/llSourcell/build_a_neural_net_live</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deriving LSTM Gradient for Backpropagation</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://wiseodd.github.io/techblog/2016/08/12/lstm-backprop/" class="Link-sc-1brdqhf-0 cKRjba">http://wiseodd.github.io/techblog/2016/08/12/lstm-backprop/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>TensorFlow RNN Tutorial</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://svds.com/tensorflow-rnn-tutorial/" class="Link-sc-1brdqhf-0 cKRjba">https://svds.com/tensorflow-rnn-tutorial/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>RNN Training Tips and Tricks</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://github.com/karpathy/char-rnn#tips-and-tricks" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/karpathy/char-rnn#tips-and-tricks</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Tips for Training Recurrent Neural Networks</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://danijar.com/tips-for-training-recurrent-neural-networks/" class="Link-sc-1brdqhf-0 cKRjba">http://danijar.com/tips-for-training-recurrent-neural-networks/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A Tour of Recurrent Neural Network Algorithms for Deep Learning</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://machinelearningmastery.com/recurrent-neural-network-algorithms-for-deep-learning/" class="Link-sc-1brdqhf-0 cKRjba">http://machinelearningmastery.com/recurrent-neural-network-algorithms-for-deep-learning/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Fundamentals of Deep Learning – Introduction to Recurrent Neural Networks</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://www.analyticsvidhya.com/blog/2017/12/introduction-to-recurrent-neural-networks/" class="Link-sc-1brdqhf-0 cKRjba">https://www.analyticsvidhya.com/blog/2017/12/introduction-to-recurrent-neural-networks/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Essentials of Deep Learning : Introduction to Long Short Term Memory</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://www.analyticsvidhya.com/blog/2017/12/fundamentals-of-deep-learning-introduction-to-lstm/" class="Link-sc-1brdqhf-0 cKRjba">https://www.analyticsvidhya.com/blog/2017/12/fundamentals-of-deep-learning-introduction-to-lstm/</a></p><h2 id="how-to-build-a-recurrent-neural-network-in-tensorflow" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#how-to-build-a-recurrent-neural-network-in-tensorflow" color="auto.gray.8" aria-label="How to build a Recurrent Neural Network in TensorFlow permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>How to build a Recurrent Neural Network in TensorFlow</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>How to build a Recurrent Neural Network in TensorFlow (1/7)</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://medium.com/@erikhallstrm/hello-world-rnn-83cd7105b767#.2vozogqf7" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@erikhallstrm/hello-world-rnn-83cd7105b767#.2vozogqf7</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Using the RNN API in TensorFlow (2/7)</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://medium.com/@erikhallstrm/tensorflow-rnn-api-2bb31821b185#.h0ycrjuo3" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@erikhallstrm/tensorflow-rnn-api-2bb31821b185#.h0ycrjuo3</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Using the LSTM API in TensorFlow (3/7)</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://medium.com/@erikhallstrm/using-the-tensorflow-lstm-api-3-7-5f2b97ca6b73#.k7aciqaxn" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@erikhallstrm/using-the-tensorflow-lstm-api-3-7-5f2b97ca6b73#.k7aciqaxn</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Using the Multilayered LSTM API in TensorFlow (4/7)</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://medium.com/@erikhallstrm/using-the-tensorflow-multilayered-lstm-api-f6e7da7bbe40#.dj7dy92m5" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@erikhallstrm/using-the-tensorflow-multilayered-lstm-api-f6e7da7bbe40#.dj7dy92m5</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Using the DynamicRNN API in TensorFlow (5/7)</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://medium.com/@erikhallstrm/using-the-dynamicrnn-api-in-tensorflow-7237aba7f7ea#.49qw259ks" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@erikhallstrm/using-the-dynamicrnn-api-in-tensorflow-7237aba7f7ea#.49qw259ks</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Using the Dropout API in TensorFlow (6/7)</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://medium.com/@erikhallstrm/using-the-dropout-api-in-tensorflow-2b2e6561dfeb#.a7mc3o9aq" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@erikhallstrm/using-the-dropout-api-in-tensorflow-2b2e6561dfeb#.a7mc3o9aq</a></p><h2 id="unfolding-rnns" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#unfolding-rnns" color="auto.gray.8" aria-label="Unfolding RNNs permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Unfolding RNNs</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Unfolding RNNs: RNN : Concepts and Architectures</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://suriyadeepan.github.io/2017-01-07-unfolding-rnn/" class="Link-sc-1brdqhf-0 cKRjba">http://suriyadeepan.github.io/2017-01-07-unfolding-rnn/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Unfolding RNNs II: Vanilla, GRU, LSTM RNNs from scratch in Tensorflow</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://suriyadeepan.github.io/2017-02-13-unfolding-rnn-2/" class="Link-sc-1brdqhf-0 cKRjba">http://suriyadeepan.github.io/2017-02-13-unfolding-rnn-2/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/suriyadeepan/rnn-from-scratch" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/suriyadeepan/rnn-from-scratch</a></li></ul><h1 id="train-rnn" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#train-rnn" color="auto.gray.8" aria-label="Train RNN permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Train RNN</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>On the difficulty of training Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>author: Razvan Pascanu, Tomas Mikolov, Yoshua Bengio</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1211.5063" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1211.5063</a></li><li>video talks: <a target="_blank" rel="noopener noreferrer" href="http://techtalks.tv/talks/on-the-difficulty-of-training-recurrent-neural-networks/58134/" class="Link-sc-1brdqhf-0 cKRjba">http://techtalks.tv/talks/on-the-difficulty-of-training-recurrent-neural-networks/58134/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A Simple Way to Initialize Recurrent Networks of Rectified Linear Units</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1504.00941" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1504.00941</a></li><li>gitxiv: <a target="_blank" rel="noopener noreferrer" href="http://gitxiv.com/posts/7j5JXvP3kn5Jf8Waj/irnn-experiment-with-pixel-by-pixel-sequential-mnist" class="Link-sc-1brdqhf-0 cKRjba">http://gitxiv.com/posts/7j5JXvP3kn5Jf8Waj/irnn-experiment-with-pixel-by-pixel-sequential-mnist</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/fchollet/keras/blob/master/examples/mnist_irnn.py" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/fchollet/keras/blob/master/examples/mnist_irnn.py</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://gist.github.com/GabrielPereyra/353499f2e6e407883b32" class="Link-sc-1brdqhf-0 cKRjba">https://gist.github.com/GabrielPereyra/353499f2e6e407883b32</a></li><li>blog(&quot;Implementing Recurrent Neural Net using chainer!&quot;): <a target="_blank" rel="noopener noreferrer" href="http://t-satoshi.blogspot.jp/2015/06/implementing-recurrent-neural-net-using.html" class="Link-sc-1brdqhf-0 cKRjba">http://t-satoshi.blogspot.jp/2015/06/implementing-recurrent-neural-net-using.html</a></li><li>reddit: <a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/MachineLearning/comments/31rinf/150400941_a_simple_way_to_initialize_recurrent/" class="Link-sc-1brdqhf-0 cKRjba">https://www.reddit.com/r/MachineLearning/comments/31rinf/150400941_a_simple_way_to_initialize_recurrent/</a></li><li>reddit: <a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/MachineLearning/comments/32tgvw/has_anyone_been_able_to_reproduce_the_results_in/" class="Link-sc-1brdqhf-0 cKRjba">https://www.reddit.com/r/MachineLearning/comments/32tgvw/has_anyone_been_able_to_reproduce_the_results_in/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Batch Normalized Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1510.01378" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1510.01378</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Sequence Level Training with Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICLR 2016</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1511.06732" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1511.06732</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/MIXER" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/facebookresearch/MIXER</a></li><li>notes: <a target="_blank" rel="noopener noreferrer" href="https://www.evernote.com/shard/s189/sh/ada01a82-70a9-48d4-985c-20492ab91e84/8da92be19e704996dc2b929473abed46" class="Link-sc-1brdqhf-0 cKRjba">https://www.evernote.com/shard/s189/sh/ada01a82-70a9-48d4-985c-20492ab91e84/8da92be19e704996dc2b929473abed46</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Training Recurrent Neural Networks (PhD thesis)</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>atuhor: Ilya Sutskever</li><li>thesis: <a target="_blank" rel="noopener noreferrer" href="https://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf" class="Link-sc-1brdqhf-0 cKRjba">https://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep learning for control using augmented Hessian-free optimization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://studywolf.wordpress.com/2016/04/04/deep-learning-for-control-using-augmented-hessian-free-optimization/" class="Link-sc-1brdqhf-0 cKRjba">https://studywolf.wordpress.com/2016/04/04/deep-learning-for-control-using-augmented-hessian-free-optimization/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/studywolf/blog/blob/master/train_AHF/train_hf.py" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/studywolf/blog/blob/master/train_AHF/train_hf.py</a></li></ul><hr class="horizontal-rule__HorizontalRule-sc-1731hye-0 daTFSy"/><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Hierarchical Conflict Propagation: Sequence Learning in a Recurrent Deep Neural Network</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1602.08118" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1602.08118</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Recurrent Batch Normalization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1603.09025" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1603.09025</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/iassael/torch-bnlstm" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/iassael/torch-bnlstm</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/cooijmanstim/recurrent-batch-normalization" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/cooijmanstim/recurrent-batch-normalization</a></li><li>github(&quot;LSTM with Batch Normalization&quot;): <a target="_blank" rel="noopener noreferrer" href="https://github.com/fchollet/keras/pull/2183" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/fchollet/keras/pull/2183</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/jihunchoi/recurrent-batch-normalization-pytorch" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/jihunchoi/recurrent-batch-normalization-pytorch</a></li><li>notes: <a target="_blank" rel="noopener noreferrer" href="http://www.shortscience.org/paper?bibtexKey=journals/corr/CooijmansBLC16" class="Link-sc-1brdqhf-0 cKRjba">http://www.shortscience.org/paper?bibtexKey=journals/corr/CooijmansBLC16</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Batch normalized LSTM for Tensorflow</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://olavnymoen.com/2016/07/07/rnn-batch-normalization" class="Link-sc-1brdqhf-0 cKRjba">http://olavnymoen.com/2016/07/07/rnn-batch-normalization</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/OlavHN/bnlstm" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/OlavHN/bnlstm</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Optimizing Performance of Recurrent Neural Networks on GPUs</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1604.01946" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1604.01946</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/parallel-forall/code-samples/blob/master/posts/rnn/LSTM.cu" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/parallel-forall/code-samples/blob/master/posts/rnn/LSTM.cu</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Path-Normalized Optimization of Recurrent Neural Networks with ReLU Activations</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1605.07154" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1605.07154</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Explaining and illustrating orthogonal initialization for recurrent neural networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://smerity.com/articles/2016/orthogonal_init.html" class="Link-sc-1brdqhf-0 cKRjba">http://smerity.com/articles/2016/orthogonal_init.html</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Professor Forcing: A New Algorithm for Training Recurrent Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: NIPS 2016</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1610.09038" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1610.09038</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/anirudh9119/LM_GANS" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/anirudh9119/LM_GANS</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Selected for an oral presentation at NIPS, 2016. University of Zurich and ETH Zurich</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1610.09513" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1610.09513</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/dannyneil/public_plstm" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/dannyneil/public_plstm</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/Enny1991/PLSTM" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Enny1991/PLSTM</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/philipperemy/tensorflow-phased-lstm" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/philipperemy/tensorflow-phased-lstm</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/PhasedLSTMCell" class="Link-sc-1brdqhf-0 cKRjba">https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/PhasedLSTMCell</a></li><li>reddit: <a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/MachineLearning/comments/5bmfw5/r_phased_lstm_accelerating_recurrent_network/" class="Link-sc-1brdqhf-0 cKRjba">https://www.reddit.com/r/MachineLearning/comments/5bmfw5/r_phased_lstm_accelerating_recurrent_network/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Tuning Recurrent Neural Networks with Reinforcement Learning (RL Tuner)</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://openreview.net/pdf?id=BJ8fyHceg" class="Link-sc-1brdqhf-0 cKRjba">http://openreview.net/pdf?id=BJ8fyHceg</a></li><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://magenta.tensorflow.org/2016/11/09/tuning-recurrent-networks-with-reinforcement-learning/" class="Link-sc-1brdqhf-0 cKRjba">https://magenta.tensorflow.org/2016/11/09/tuning-recurrent-networks-with-reinforcement-learning/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/tensorflow/magenta/tree/master/magenta/models/rl_tuner" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/tensorflow/magenta/tree/master/magenta/models/rl_tuner</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Capacity and Trainability in Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Google Brain</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1611.09913" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1611.09913</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Large-Batch Training for LSTM and Beyond</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: UC Berkeley &amp; UCLA &amp; Google</li><li>paper: <a target="_blank" rel="noopener noreferrer" href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-138.pdf" class="Link-sc-1brdqhf-0 cKRjba">https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-138.pdf</a></li></ul><h1 id="learn-to-execute-programs" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#learn-to-execute-programs" color="auto.gray.8" aria-label="Learn To Execute Programs permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Learn To Execute Programs</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Learning to Execute</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1410.4615" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1410.4615</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/wojciechz/learning_to_execute" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/wojciechz/learning_to_execute</a></li><li>github(Tensorflow): <a target="_blank" rel="noopener noreferrer" href="https://github.com/raindeer/seq2seq_experiments" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/raindeer/seq2seq_experiments</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Neural Programmer-Interpreters</strong></p><img src="/assets/dl-materials/rnn_lstm/NPI/add.gif" class="image__Image-sc-1r30dtv-0 elBfYx"/><img src="/assets/dl-materials/rnn_lstm/NPI/cars.gif" class="image__Image-sc-1r30dtv-0 elBfYx"/><img src="/assets/dl-materials/rnn_lstm/NPI/sort_full.gif" class="image__Image-sc-1r30dtv-0 elBfYx"/><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro:  Google DeepMind. ICLR 2016 Best Paper</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1511.06279" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1511.06279</a></li><li>project page: <a target="_blank" rel="noopener noreferrer" href="http://www-personal.umich.edu/~reedscot/iclr_project.html" class="Link-sc-1brdqhf-0 cKRjba">http://www-personal.umic (Google DeepMind. ICLR 2016 Best Paper)h.edu/~reedscot/iclr_project.html</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/mokemokechicken/keras_npi" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/mokemokechicken/keras_npi</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A Programmer-Interpreter Neural Network Architecture for Prefrontal Cognitive Control</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>paper: <a target="_blank" rel="noopener noreferrer" href="https://www.researchgate.net/publication/273912337_A_ProgrammerInterpreter_Neural_Network_Architecture_for_Prefrontal_Cognitive_Control" class="Link-sc-1brdqhf-0 cKRjba">https://www.researchgate.net/publication/273912337_A_ProgrammerInterpreter_Neural_Network_Architecture_for_Prefrontal_Cognitive_Control</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Convolutional RNN: an Enhanced Model for Extracting Features from Sequential Data</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1602.05875" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1602.05875</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Neural Random-Access Machines</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1511.06392" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1511.06392</a></li></ul><h1 id="attention-models" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#attention-models" color="auto.gray.8" aria-label="Attention Models permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Attention Models</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Recurrent Models of Visual Attention</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Google DeepMind. NIPS 2014</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1406.6247" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1406.6247</a></li><li>data: <a target="_blank" rel="noopener noreferrer" href="https://github.com/deepmind/mnist-cluttered" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/deepmind/mnist-cluttered</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/Element-Research/rnn/blob/master/examples/recurrent-visual-attention.lua" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Element-Research/rnn/blob/master/examples/recurrent-visual-attention.lua</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Recurrent Model of Visual Attention</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Google DeepMind</li><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1406.6247" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1406.6247</a></li><li>gitxiv: <a target="_blank" rel="noopener noreferrer" href="http://gitxiv.com/posts/ZEobCXSh23DE8a8mo/recurrent-models-of-visual-attention" class="Link-sc-1brdqhf-0 cKRjba">http://gitxiv.com/posts/ZEobCXSh23DE8a8mo/recurrent-models-of-visual-attention</a></li><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://torch.ch/blog/2015/09/21/rmva.html" class="Link-sc-1brdqhf-0 cKRjba">http://torch.ch/blog/2015/09/21/rmva.html</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/Element-Research/rnn/blob/master/scripts/evaluate-rva.lua" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Element-Research/rnn/blob/master/scripts/evaluate-rva.lua</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1502.03044" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1502.03044</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/kelvinxu/arctic-captions" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/kelvinxu/arctic-captions</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A Neural Attention Model for Abstractive Sentence Summarization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: EMNLP 2015. Facebook AI Research</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1509.00685" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1509.00685</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/facebook/NAMAS" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/facebook/NAMAS</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Effective Approaches to Attention-based Neural Machine Translation</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: EMNLP 2015</li><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://nlp.stanford.edu/pubs/emnlp15_attn.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://nlp.stanford.edu/pubs/emnlp15_attn.pdf</a></li><li>project: <a target="_blank" rel="noopener noreferrer" href="http://nlp.stanford.edu/projects/nmt/" class="Link-sc-1brdqhf-0 cKRjba">http://nlp.stanford.edu/projects/nmt/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/lmthang/nmt.matlab" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/lmthang/nmt.matlab</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Generating Images from Captions with Attention</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1511.02793" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1511.02793</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/emansim/text2image" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/emansim/text2image</a></li><li>demo: <a target="_blank" rel="noopener noreferrer" href="http://www.cs.toronto.edu/~emansim/cap2im.html" class="Link-sc-1brdqhf-0 cKRjba">http://www.cs.toronto.edu/~emansim/cap2im.html</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Attention and Memory in Deep Learning and NLP</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/" class="Link-sc-1brdqhf-0 cKRjba">http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Survey on the attention based RNN model and its applications in computer vision</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1601.06823" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1601.06823</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Attention in Long Short-Term Memory Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://machinelearningmastery.com/attention-long-short-term-memory-recurrent-neural-networks/" class="Link-sc-1brdqhf-0 cKRjba">http://machinelearningmastery.com/attention-long-short-term-memory-recurrent-neural-networks/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>How to Visualize Your Recurrent Neural Network with Attention in Keras</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://medium.com/datalogue/attention-in-keras-1892773a4f22" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/datalogue/attention-in-keras-1892773a4f22</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/datalogue/keras-attention" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/datalogue/keras-attention</a></li></ul><h1 id="papers" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#papers" color="auto.gray.8" aria-label="Papers permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Papers</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Generating Sequences With Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1308.0850" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1308.0850</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/hardmaru/write-rnn-tensorflow" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/hardmaru/write-rnn-tensorflow</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/szcom/rnnlib" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/szcom/rnnlib</a></li><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://blog.otoro.net/2015/12/12/handwriting-generation-demo-in-tensorflow/" class="Link-sc-1brdqhf-0 cKRjba">http://blog.otoro.net/2015/12/12/handwriting-generation-demo-in-tensorflow/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A Clockwork RNN</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1402.3511" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1402.3511</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/makistsantekidis/clockworkrnn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/makistsantekidis/clockworkrnn</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/zergylord/ClockworkRNN" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/zergylord/ClockworkRNN</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Unsupervised Learning of Video Representations using LSTMs</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICML 2015</li><li>project page: <a target="_blank" rel="noopener noreferrer" href="http://www.cs.toronto.edu/~nitish/unsupervised_video/" class="Link-sc-1brdqhf-0 cKRjba">http://www.cs.toronto.edu/~nitish/unsupervised_video/</a></li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1502.04681" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1502.04681</a></li><li>code: <a target="_blank" rel="noopener noreferrer" href="http://www.cs.toronto.edu/~nitish/unsupervised_video/unsup_video_lstm.tar.gz" class="Link-sc-1brdqhf-0 cKRjba">http://www.cs.toronto.edu/~nitish/unsupervised_video/unsup_video_lstm.tar.gz</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/emansim/unsupervised-videos" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/emansim/unsupervised-videos</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>An Empirical Exploration of Recurrent Network Architectures</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ACL 2015. Tree RNNs aka Recursive Neural Networks</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1503.00075" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1503.00075</a></li><li>slides: <a target="_blank" rel="noopener noreferrer" href="http://lit.eecs.umich.edu/wp-content/uploads/2015/10/tree-lstms.pptx" class="Link-sc-1brdqhf-0 cKRjba">http://lit.eecs.umich.edu/wp-content/uploads/2015/10/tree-lstms.pptx</a></li><li>gitxiv: <a target="_blank" rel="noopener noreferrer" href="http://www.gitxiv.com/posts/esrArT2iLmSfNRrto/tree-structured-long-short-term-memory-networks" class="Link-sc-1brdqhf-0 cKRjba">http://www.gitxiv.com/posts/esrArT2iLmSfNRrto/tree-structured-long-short-term-memory-networks</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/stanfordnlp/treelstm" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/stanfordnlp/treelstm</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/ofirnachum/tree_rnn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/ofirnachum/tree_rnn</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>LSTM: A Search Space Odyssey</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1503.04069" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1503.04069</a></li><li>notes: <a target="_blank" rel="noopener noreferrer" href="https://www.evernote.com/shard/s189/sh/48da42c5-8106-4f0d-b835-c203466bfac4/50d7a3c9a961aefd937fae3eebc6f540" class="Link-sc-1brdqhf-0 cKRjba">https://www.evernote.com/shard/s189/sh/48da42c5-8106-4f0d-b835-c203466bfac4/50d7a3c9a961aefd937fae3eebc6f540</a></li><li>blog(&quot;Dissecting the LSTM&quot;): <a target="_blank" rel="noopener noreferrer" href="https://medium.com/jim-fleming/implementing-lstm-a-search-space-odyssey-7d50c3bacf93#.crg8pztop" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/jim-fleming/implementing-lstm-a-search-space-odyssey-7d50c3bacf93#.crg8pztop</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/jimfleming/lstm_search" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/jimfleming/lstm_search</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1503.01007" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1503.01007</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/facebook/Stack-RNN" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/facebook/Stack-RNN</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A Critical Review of Recurrent Neural Networks for Sequence Learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1506.00019" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1506.00019</a></li><li>review: <a target="_blank" rel="noopener noreferrer" href="http://blog.terminal.com/a-thorough-and-readable-review-on-rnns/" class="Link-sc-1brdqhf-0 cKRjba">http://blog.terminal.com/a-thorough-and-readable-review-on-rnns/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Visualizing and Understanding Recurrent Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICLR 2016. Andrej Karpathy, Justin Johnson, Fei-Fei Li</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1506.02078" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1506.02078</a></li><li>slides: <a target="_blank" rel="noopener noreferrer" href="http://www.robots.ox.ac.uk/~seminars/seminars/Extra/2015_07_06_AndrejKarpathy.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://www.robots.ox.ac.uk/~seminars/seminars/Extra/2015_07_06_AndrejKarpathy.pdf</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/karpathy/char-rnn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/karpathy/char-rnn</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Winner of MSCOCO image captioning challenge, 2015</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1506.03099" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1506.03099</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1506.04214" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1506.04214</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/loliverhennigh/Convolutional-LSTM-in-Tensorflow" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/loliverhennigh/Convolutional-LSTM-in-Tensorflow</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Grid Long Short-Term Memory</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1507.01526" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1507.01526</a></li><li>github(Torch7): <a target="_blank" rel="noopener noreferrer" href="https://github.com/coreylynch/grid-lstm/" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/coreylynch/grid-lstm/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Depth-Gated LSTM</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1508.03790" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1508.03790</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/kaishengyao/cnn/tree/master/cnn" class="Link-sc-1brdqhf-0 cKRjba">GitHub(dglstm.h+dglstm.cc)</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Knowledge Tracing</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>paper: <a target="_blank" rel="noopener noreferrer" href="https://web.stanford.edu/~cpiech/bio/papers/deepKnowledgeTracing.pdf" class="Link-sc-1brdqhf-0 cKRjba">https://web.stanford.edu/~cpiech/bio/papers/deepKnowledgeTracing.pdf</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/chrispiech/DeepKnowledgeTracing" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/chrispiech/DeepKnowledgeTracing</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Top-down Tree Long Short-Term Memory Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1511.00060" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1511.00060</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/XingxingZhang/td-treelstm" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/XingxingZhang/td-treelstm</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Improving performance of recurrent neural network with relu nonlinearity</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICLR 2016</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1511.03771" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1511.03771</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Alternative structures for character-level RNNs</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: INRIA &amp; Facebook AI Research. ICLR 2016</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1511.06303" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1511.06303</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/facebook/Conditional-character-based-RNN" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/facebook/Conditional-character-based-RNN</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Long Short-Term Memory-Networks for Machine Reading</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1601.06733" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1601.06733</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/cheng6076/SNLI-attention" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/cheng6076/SNLI-attention</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Lipreading with Long Short-Term Memory</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1601.08188" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1601.08188</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Associative Long Short-Term Memory</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1602.03032" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1602.03032</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/mohammadpz/Associative_LSTM" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/mohammadpz/Associative_LSTM</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Representation of linguistic form and function in recurrent neural networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1602.08952" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1602.08952</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Architectural Complexity Measures of Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1602.08210" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1602.08210</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Easy-First Dependency Parsing with Hierarchical Tree LSTMs</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1603.00375" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1603.00375</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Training Input-Output Recurrent Neural Networks through Spectral Methods</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1603.00954" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1603.00954</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Sequential Neural Models with Stochastic Layers</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1605.07571" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1605.07571</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/marcofraccaro/srnn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/marcofraccaro/srnn</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Neural networks with differentiable structure</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1606.06216" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1606.06216</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/ThomasMiconi/DiffRNN" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/ThomasMiconi/DiffRNN</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>What You Get Is What You See: A Visual Markup Decompiler</strong></p><img src="https://camo.githubusercontent.com/d5c6c528cdb25b504b1de298bc34d7109de06aea/687474703a2f2f6c73746d2e736561732e686172766172642e6564752f6c617465782f6e6574776f726b2e706e67" class="image__Image-sc-1r30dtv-0 elBfYx"/><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>project page: <a target="_blank" rel="noopener noreferrer" href="http://lstm.seas.harvard.edu/latex/" class="Link-sc-1brdqhf-0 cKRjba">http://lstm.seas.harvard.edu/latex/</a></li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1609.04938" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1609.04938</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/harvardnlp/im2markup" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/harvardnlp/im2markup</a></li><li>github(Tensorflow): <a target="_blank" rel="noopener noreferrer" href="https://github.com/ssampang/im2latex" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/ssampang/im2latex</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/opennmt/im2text" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/opennmt/im2text</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/ritheshkumar95/im2latex-tensorflow" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/ritheshkumar95/im2latex-tensorflow</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Hybrid computing using a neural network with dynamic external memory</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Nature 2016</li><li>keywords: Differentiable Neural Computer (DNC)
<a target="_blank" rel="noopener noreferrer" href="https://www.nature.com/articles/nature20101.epdf?author_access_token=ImTXBI8aWbYxYQ51Plys8NRgN0jAjWel9jnR3ZoTv0MggmpDmwljGswxVdeocYSurJ3hxupzWuRNeGvvXnoO8o4jTJcnAyhGuZzXJ1GEaD-Z7E6X_a9R-xqJ9TfJWBqz" class="Link-sc-1brdqhf-0 cKRjba">https://www.nature.com/articles/nature20101.epdf?author_access_token=ImTXBI8aWbYxYQ51Plys8NRgN0jAjWel9jnR3ZoTv0MggmpDmwljGswxVdeocYSurJ3hxupzWuRNeGvvXnoO8o4jTJcnAyhGuZzXJ1GEaD-Z7E6X_a9R-xqJ9TfJWBqz</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/deepmind/dnc" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/deepmind/dnc</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>project page: <a target="_blank" rel="noopener noreferrer" href="https://imatge-upc.github.io/skiprnn-2017-telecombcn/" class="Link-sc-1brdqhf-0 cKRjba">https://imatge-upc.github.io/skiprnn-2017-telecombcn/</a></li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1708.06834" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1708.06834</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Dilated Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: NIPS 2017. IBM &amp; University of Illinois at Urbana-Champaign</li><li>keywords: DilatedRNN</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1710.02224" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1710.02224</a></li><li>github(Tensorflow): <a target="_blank" rel="noopener noreferrer" href="https://github.com/code-terminator/DilatedRNN" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/code-terminator/DilatedRNN</a><a target="_blank" rel="noopener noreferrer" href="https://github.com/zalandoresearch/pt-dilate-rnn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/zalandoresearch/pt-dilate-rnn</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Excitation Backprop for RNNs</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1711.06778" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1711.06778</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Recurrent Relational Networks for Complex Relational Reasoning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>project page: <a target="_blank" rel="noopener noreferrer" href="https://rasmusbergpalm.github.io/recurrent-relational-networks/" class="Link-sc-1brdqhf-0 cKRjba">https://rasmusbergpalm.github.io/recurrent-relational-networks/</a></li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1711.08028" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1711.08028</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com//rasmusbergpalm/recurrent-relational-networks" class="Link-sc-1brdqhf-0 cKRjba">https://github.com//rasmusbergpalm/recurrent-relational-networks</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Learning Compact Recurrent Neural Networks with Block-Term Tensor Decomposition</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: University of Electronic Science and Technology of China &amp; Brown University &amp; University of Utah &amp; XJERA LABS PTE.LTD</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.05134" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.05134</a></li></ul><h2 id="lstmvis" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#lstmvis" color="auto.gray.8" aria-label="LSTMVis permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>LSTMVis</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks</strong></p><img src="https://raw.githubusercontent.com/HendrikStrobelt/LSTMVis/master/docs/img/teaser_V2_small.png" class="image__Image-sc-1r30dtv-0 elBfYx"/><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://lstm.seas.harvard.edu/" class="Link-sc-1brdqhf-0 cKRjba">http://lstm.seas.harvard.edu/</a></li><li>demo: <a target="_blank" rel="noopener noreferrer" href="http://lstm.seas.harvard.edu/client/index.html" class="Link-sc-1brdqhf-0 cKRjba">http://lstm.seas.harvard.edu/client/index.html</a></li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1606.07461" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1606.07461</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/HendrikStrobelt/LSTMVis" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/HendrikStrobelt/LSTMVis</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Recurrent Memory Array Structures</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1607.03085" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1607.03085</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/krocki/ArrayLSTM" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/krocki/ArrayLSTM</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Recurrent Highway Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>author: Julian Georg Zilly, Rupesh Kumar Srivastava, Jan Koutník, Jürgen Schmidhuber</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1607.03474" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1607.03474</a></li><li>github(Tensorflow+Torch): <a target="_blank" rel="noopener noreferrer" href="https://github.com/julian121266/RecurrentHighwayNetworks/" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/julian121266/RecurrentHighwayNetworks/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DeepSoft: A vision for a deep model of software</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1608.00092" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1608.00092</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Recurrent Neural Networks With Limited Numerical Precision</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1608.06902" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1608.06902</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Hierarchical Multiscale Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1609.01704" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1609.01704</a></li><li>notes: <a target="_blank" rel="noopener noreferrer" href="https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/hm-rnn.md" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/hm-rnn.md</a></li><li>notes: <a target="_blank" rel="noopener noreferrer" href="https://medium.com/@jimfleming/notes-on-hierarchical-multiscale-recurrent-neural-networks-7362532f3b64#.pag4kund0" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@jimfleming/notes-on-hierarchical-multiscale-recurrent-neural-networks-7362532f3b64#.pag4kund0</a></li></ul><h2 id="lightrnn" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#lightrnn" color="auto.gray.8" aria-label="LightRNN permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>LightRNN</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>LightRNN: Memory and Computation-Efficient Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: NIPS 2016</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1610.09893" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1610.09893</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Full-Capacity Unitary Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: NIPS 2016</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1611.00035" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1611.00035</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/stwisdom/urnn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/stwisdom/urnn</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DeepCoder: Learning to Write Programs</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1611.01989" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1611.01989</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>shuttleNet: A biologically-inspired RNN with loop connection and parameter sharing</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1611.05216" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1611.05216</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Tracking the World State with Recurrent Entity Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Facebook AI Research</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1612.03969" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1612.03969</a></li><li>github(Official): <a target="_blank" rel="noopener noreferrer" href="https://github.com/facebook/MemNN/tree/master/EntNet-babi" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/facebook/MemNN/tree/master/EntNet-babi</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Robust LSTM-Autoencoders for Face De-Occlusion in the Wild</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: National University of Singapore &amp; Peking University</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1612.08534" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1612.08534</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Simplified Gating in Long Short-term Memory (LSTM) Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1701.03441" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1701.03441</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/jingweimo/Modified-LSTM" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/jingweimo/Modified-LSTM</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>The Statistical Recurrent Unit</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: CMU</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1703.00381" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1703.00381</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Factorization tricks for LSTM networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICLR 2017 Workshop</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1703.10722" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1703.10722</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/okuchaiev/f-lm" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/okuchaiev/f-lm</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Bayesian Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: UC Berkeley</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1704.02798" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1704.02798</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/mirceamironenco/BayesianRecurrentNN" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/mirceamironenco/BayesianRecurrentNN</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Fast-Slow Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1705.08639" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1705.08639</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/amujika/Fast-Slow-LSTM" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/amujika/Fast-Slow-LSTM</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Visualizing LSTM decisions</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1705.08153" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1705.08153</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Recurrent Additive Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: [University of Washington &amp; Allen Institute for Artificial Intelligence</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1705.07393" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1705.07393</a></li><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://www.kentonl.com/pub/llz.2017.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://www.kentonl.com/pub/llz.2017.pdf</a></li><li>github(PyTorch): <a target="_blank" rel="noopener noreferrer" href="https://github.com/bheinzerling/ran" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/bheinzerling/ran</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Recent Advances in Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: University of Toronto &amp; University of Waterloo</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1801.01078" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1801.01078</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Grow and Prune Compact, Fast, and Accurate LSTMs</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1805.11797" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1805.11797</a></p><h1 id="projects" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#projects" color="auto.gray.8" aria-label="Projects permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Projects</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>NeuralTalk (Deprecated): a Python+numpy project for learning Multimodal Recurrent Neural Networks that describe images with sentences</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/karpathy/neuraltalk" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/karpathy/neuraltalk</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>NeuralTalk2: Efficient Image Captioning code in Torch, runs on GPU</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/karpathy/neuraltalk2" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/karpathy/neuraltalk2</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>char-rnn in Blocks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/johnarevalo/blocks-char-rnn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/johnarevalo/blocks-char-rnn</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Project: pycaffe-recurrent</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>code: <a target="_blank" rel="noopener noreferrer" href="https://github.com/kuprel/pycaffe-recurrent/" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/kuprel/pycaffe-recurrent/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Using neural networks for password cracking</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://0day.work/using-neural-networks-for-password-cracking/" class="Link-sc-1brdqhf-0 cKRjba">https://0day.work/using-neural-networks-for-password-cracking/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/gehaxelt/RNN-Passwords" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/gehaxelt/RNN-Passwords</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>torch-rnn: Efficient, reusable RNNs and LSTMs for torch</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/jcjohnson/torch-rnn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/jcjohnson/torch-rnn</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deploying a model trained with GPU in Torch into JavaScript, for everyone to use</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://testuggine.ninja/blog/torch-conversion" class="Link-sc-1brdqhf-0 cKRjba">http://testuggine.ninja/blog/torch-conversion</a></li><li>demo: <a target="_blank" rel="noopener noreferrer" href="http://testuggine.ninja/DRUMPF-9000/" class="Link-sc-1brdqhf-0 cKRjba">http://testuggine.ninja/DRUMPF-9000/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/Darktex/char-rnn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Darktex/char-rnn</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>LSTM implementation on Caffe</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/junhyukoh/caffe-lstm" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/junhyukoh/caffe-lstm</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>JNN: Java Neural Network Library</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: C2W model, LSTM-based Language Model, LSTM-based Part-Of-Speech-Tagger Model</li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/wlin12/JNN" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/wlin12/JNN</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>LSTM-Autoencoder: Seq2Seq LSTM Autoencoder</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/cheng6076/LSTM-Autoencoder" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/cheng6076/LSTM-Autoencoder</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>RNN Language Model Variations</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Standard LSTM, Gated Feedback LSTM, 1D-Grid LSTM</li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/cheng6076/mlm" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/cheng6076/mlm</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>keras-extra: Extra Layers for Keras to connect CNN with RNN</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/anayebi/keras-extra" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/anayebi/keras-extra</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Dynamic Vanilla RNN, GRU, LSTM,2layer Stacked LSTM with Tensorflow Higher Order Ops</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/KnHuq/Dynamic_RNN_Tensorflow" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/KnHuq/Dynamic_RNN_Tensorflow</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>PRNN: A fast implementation of recurrent neural network layers in CUDA</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Baidu Research</li><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://svail.github.io/persistent_rnns/" class="Link-sc-1brdqhf-0 cKRjba">https://svail.github.io/persistent_rnns/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/baidu-research/persistent-rnn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/baidu-research/persistent-rnn</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>min-char-rnn: Minimal character-level language model with a Vanilla Recurrent Neural Network, in Python/numpy</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/weixsong/min-char-rnn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/weixsong/min-char-rnn</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>rnn: Recurrent Neural Network library for Torch7&#x27;s nn</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/Element-Research/rnn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Element-Research/rnn</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>word-rnn-tensorflow: Multi-layer Recurrent Neural Networks (LSTM, RNN) for word-level language models in Python using TensorFlow</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/hunkim/word-rnn-tensorflow" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/hunkim/word-rnn-tensorflow</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>tf-char-rnn: Tensorflow implementation of char-rnn</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/shagunsodhani/tf-char-rnn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/shagunsodhani/tf-char-rnn</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>translit-rnn: Automatic transliteration with LSTM</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://yerevann.github.io/2016/09/09/automatic-transliteration-with-lstm/" class="Link-sc-1brdqhf-0 cKRjba">http://yerevann.github.io/2016/09/09/automatic-transliteration-with-lstm/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/YerevaNN/translit-rnn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/YerevaNN/translit-rnn</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>tf_lstm.py: Simple implementation of LSTM in Tensorflow in 50 lines (+ 130 lines of data generation and comments)</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>gist: <a target="_blank" rel="noopener noreferrer" href="https://gist.github.com/nivwusquorum/b18ce332bde37e156034e5d3f60f8a23" class="Link-sc-1brdqhf-0 cKRjba">https://gist.github.com/nivwusquorum/b18ce332bde37e156034e5d3f60f8a23</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Handwriting generating with RNN</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/Arn-O/kadenze-deep-creative-apps/blob/master/final-project/glyphs-rnn.ipynb" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Arn-O/kadenze-deep-creative-apps/blob/master/final-project/glyphs-rnn.ipynb</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>RecNet - Recurrent Neural Network Framework</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/joergfranke/recnet" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/joergfranke/recnet</a></li></ul><h1 id="blogs" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#blogs" color="auto.gray.8" aria-label="Blogs permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Blogs</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Survey on Attention-based Models Applied in NLP</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://yanran.li/peppypapers/2015/10/07/survey-attention-model-1.html" class="Link-sc-1brdqhf-0 cKRjba">http://yanran.li/peppypapers/2015/10/07/survey-attention-model-1.html</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Survey on Advanced Attention-based Models</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://yanran.li/peppypapers/2015/10/07/survey-attention-model-2.html" class="Link-sc-1brdqhf-0 cKRjba">http://yanran.li/peppypapers/2015/10/07/survey-attention-model-2.html</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Online Representation Learning in Recurrent Neural Language Models</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://www.marekrei.com/blog/online-representation-learning-in-recurrent-neural-language-models/" class="Link-sc-1brdqhf-0 cKRjba">http://www.marekrei.com/blog/online-representation-learning-in-recurrent-neural-language-models/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Fun with Recurrent Neural Nets: One More Dive into CNTK and TensorFlow</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://esciencegroup.com/2016/03/04/fun-with-recurrent-neural-nets-one-more-dive-into-cntk-and-tensorflow/" class="Link-sc-1brdqhf-0 cKRjba">http://esciencegroup.com/2016/03/04/fun-with-recurrent-neural-nets-one-more-dive-into-cntk-and-tensorflow/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Materials to understand LSTM</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://medium.com/@shiyan/materials-to-understand-lstm-34387d6454c1#.4mt3bzoau" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@shiyan/materials-to-understand-lstm-34387d6454c1#.4mt3bzoau</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Understanding LSTM and its diagrams</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl">:star::star::star::star::star:</p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://medium.com/@shiyan/understanding-lstm-and-its-diagrams-37e2f46f1714" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@shiyan/understanding-lstm-and-its-diagrams-37e2f46f1714</a></li><li>slides: <a target="_blank" rel="noopener noreferrer" href="https://github.com/shi-yan/FreeWill/blob/master/Docs/Diagrams/lstm_diagram.pptx" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/shi-yan/FreeWill/blob/master/Docs/Diagrams/lstm_diagram.pptx</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Persistent RNNs: 30 times faster RNN layers at small mini-batch sizes</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Persistent RNNs: Stashing Recurrent Weights On-Chip</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Greg Diamos, Baidu Silicon Valley AI Lab</li><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://jmlr.org/proceedings/papers/v48/diamos16.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://jmlr.org/proceedings/papers/v48/diamos16.pdf</a></li><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://svail.github.io/persistent_rnns/" class="Link-sc-1brdqhf-0 cKRjba">http://svail.github.io/persistent_rnns/</a></li><li>slides: <a target="_blank" rel="noopener noreferrer" href="http://on-demand.gputechconf.com/gtc/2016/presentation/s6673-greg-diamos-persisten-rnns.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://on-demand.gputechconf.com/gtc/2016/presentation/s6673-greg-diamos-persisten-rnns.pdf</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>All of Recurrent Neural Networks</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://medium.com/@jianqiangma/all-about-recurrent-neural-networks-9e5ae2936f6e#.q4s02elqg" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@jianqiangma/all-about-recurrent-neural-networks-9e5ae2936f6e#.q4s02elqg</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Rolling and Unrolling RNNs</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://shapeofdata.wordpress.com/2016/04/27/rolling-and-unrolling-rnns/" class="Link-sc-1brdqhf-0 cKRjba">https://shapeofdata.wordpress.com/2016/04/27/rolling-and-unrolling-rnns/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Sequence prediction using recurrent neural networks(LSTM) with TensorFlow: LSTM regression using TensorFlow</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://mourafiq.com/2016/05/15/predicting-sequences-using-rnn-in-tensorflow.html" class="Link-sc-1brdqhf-0 cKRjba">http://mourafiq.com/2016/05/15/predicting-sequences-using-rnn-in-tensorflow.html</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/mouradmourafiq/tensorflow-lstm-regression" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/mouradmourafiq/tensorflow-lstm-regression</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>LSTMs</strong></p><img src="https://shapeofdata.files.wordpress.com/2016/06/lstm.png?w=640" class="image__Image-sc-1r30dtv-0 elBfYx"/><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://shapeofdata.wordpress.com/2016/06/04/lstms/" class="Link-sc-1brdqhf-0 cKRjba">https://shapeofdata.wordpress.com/2016/06/04/lstms/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Machines and Magic: Teaching Computers to Write Harry Potter</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://medium.com/@joycex99/machines-and-magic-teaching-computers-to-write-harry-potter-37839954f252#.4fxemal9t" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@joycex99/machines-and-magic-teaching-computers-to-write-harry-potter-37839954f252#.4fxemal9t</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/joycex99/hp-word-model" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/joycex99/hp-word-model</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Crash Course in Recurrent Neural Networks for Deep Learning</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://machinelearningmastery.com/crash-course-recurrent-neural-networks-deep-learning/" class="Link-sc-1brdqhf-0 cKRjba">http://machinelearningmastery.com/crash-course-recurrent-neural-networks-deep-learning/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Understanding Stateful LSTM Recurrent Neural Networks in Python with Keras</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://machinelearningmastery.com/understanding-stateful-lstm-recurrent-neural-networks-python-keras/" class="Link-sc-1brdqhf-0 cKRjba">http://machinelearningmastery.com/understanding-stateful-lstm-recurrent-neural-networks-python-keras/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Recurrent Neural Networks in Tensorflow</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>part I: <a target="_blank" rel="noopener noreferrer" href="http://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html" class="Link-sc-1brdqhf-0 cKRjba">http://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html</a></li><li>part II: <a target="_blank" rel="noopener noreferrer" href="http://r2rt.com/recurrent-neural-networks-in-tensorflow-ii.html" class="Link-sc-1brdqhf-0 cKRjba">http://r2rt.com/recurrent-neural-networks-in-tensorflow-ii.html</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Written Memories: Understanding, Deriving and Extending the LSTM</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html" class="Link-sc-1brdqhf-0 cKRjba">http://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Attention and Augmented Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://distill.pub/2016/augmented-rnns/" class="Link-sc-1brdqhf-0 cKRjba">http://distill.pub/2016/augmented-rnns/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/distillpub/post--augmented-rnns" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/distillpub/post--augmented-rnns</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Interpreting and Visualizing Neural Networks for Text Processing</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://civisanalytics.com/blog/data-science/2016/09/22/neural-network-visualization/" class="Link-sc-1brdqhf-0 cKRjba">https://civisanalytics.com/blog/data-science/2016/09/22/neural-network-visualization/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A simple design pattern for recurrent deep learning in TensorFlow</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://medium.com/@devnag/a-simple-design-pattern-for-recurrent-deep-learning-in-tensorflow-37aba4e2fd6b#.homq9zsyr" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@devnag/a-simple-design-pattern-for-recurrent-deep-learning-in-tensorflow-37aba4e2fd6b#.homq9zsyr</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/devnag/tensorflow-bptt" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/devnag/tensorflow-bptt</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>RNN Spelling Correction: To crack a nut with a sledgehammer</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://medium.com/@yaoyaowd/rnn-spelling-correction-to-crack-a-nut-with-a-sledgehammer-7f5aa442c08c#.mc2ycyfda" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@yaoyaowd/rnn-spelling-correction-to-crack-a-nut-with-a-sledgehammer-7f5aa442c08c#.mc2ycyfda</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Recurrent Neural Network Gradients, and Lessons Learned Therein</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://willwolf.io/en/2016/10/13/recurrent-neural-network-gradients-and-lessons-learned-therein/" class="Link-sc-1brdqhf-0 cKRjba">http://willwolf.io/en/2016/10/13/recurrent-neural-network-gradients-and-lessons-learned-therein/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A noob’s guide to implementing RNN-LSTM using Tensorflow</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://monik.in/a-noobs-guide-to-implementing-rnn-lstm-using-tensorflow/" class="Link-sc-1brdqhf-0 cKRjba">http://monik.in/a-noobs-guide-to-implementing-rnn-lstm-using-tensorflow/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Non-Zero Initial States for Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://r2rt.com/non-zero-initial-states-for-recurrent-neural-networks.html" class="Link-sc-1brdqhf-0 cKRjba">http://r2rt.com/non-zero-initial-states-for-recurrent-neural-networks.html</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Interpreting neurons in an LSTM network</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://yerevann.github.io/2017/06/27/interpreting-neurons-in-an-LSTM-network/" class="Link-sc-1brdqhf-0 cKRjba">http://yerevann.github.io/2017/06/27/interpreting-neurons-in-an-LSTM-network/</a></p><h2 id="optimizing-rnn-baidu-silicon-valley-ai-lab" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#optimizing-rnn-baidu-silicon-valley-ai-lab" color="auto.gray.8" aria-label="Optimizing RNN (Baidu Silicon Valley AI Lab) permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Optimizing RNN (Baidu Silicon Valley AI Lab)</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Optimizing RNN performance</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://svail.github.io/rnn_perf/" class="Link-sc-1brdqhf-0 cKRjba">http://svail.github.io/rnn_perf/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Optimizing RNNs with Differentiable Graphs</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://svail.github.io/diff_graphs/" class="Link-sc-1brdqhf-0 cKRjba">http://svail.github.io/diff_graphs/</a></li><li>notes: <a target="_blank" rel="noopener noreferrer" href="http://research.baidu.com/svail-tech-notes-optimizing-rnns-differentiable-graphs/" class="Link-sc-1brdqhf-0 cKRjba">http://research.baidu.com/svail-tech-notes-optimizing-rnns-differentiable-graphs/</a></li></ul><h1 id="resources" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#resources" color="auto.gray.8" aria-label="Resources permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Resources</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Awesome Recurrent Neural Networks - A curated list of resources dedicated to RNN</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://jiwonkim.org/awesome-rnn/" class="Link-sc-1brdqhf-0 cKRjba">http://jiwonkim.org/awesome-rnn/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/kjw0612/awesome-rnn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/kjw0612/awesome-rnn</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Jürgen Schmidhuber&#x27;s page on Recurrent Neural Networks</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://people.idsia.ch/~juergen/rnn.html" class="Link-sc-1brdqhf-0 cKRjba">http://people.idsia.ch/~juergen/rnn.html</a></p><h1 id="reading-and-questions" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#reading-and-questions" color="auto.gray.8" aria-label="Reading and Questions permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Reading and Questions</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Are there any Recurrent convolutional neural network network implementations out there ?</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>reddit: <a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/MachineLearning/comments/4chu3y/are_there_any_recurrent_convolutional_neural/" class="Link-sc-1brdqhf-0 cKRjba">https://www.reddit.com/r/MachineLearning/comments/4chu3y/are_there_any_recurrent_convolutional_neural/</a></li></ul><div class="Box-nv15kw-0 ksEcN"><div display="flex" class="Box-nv15kw-0 jsSpbO"><a href="https://github.com/webizenai/devdocs/tree/main/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rnn-and-lstm.md" class="Link-sc-1brdqhf-0 iLYDsn"><svg aria-hidden="true" role="img" class="StyledOcticon-uhnt7w-0 fafffn" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M11.013 1.427a1.75 1.75 0 012.474 0l1.086 1.086a1.75 1.75 0 010 2.474l-8.61 8.61c-.21.21-.47.364-.756.445l-3.251.93a.75.75 0 01-.927-.928l.929-3.25a1.75 1.75 0 01.445-.758l8.61-8.61zm1.414 1.06a.25.25 0 00-.354 0L10.811 3.75l1.439 1.44 1.263-1.263a.25.25 0 000-.354l-1.086-1.086zM11.189 6.25L9.75 4.81l-6.286 6.287a.25.25 0 00-.064.108l-.558 1.953 1.953-.558a.249.249 0 00.108-.064l6.286-6.286z"></path></svg>Edit this page</a><div><span font-size="1" color="auto.gray.7" class="Text-sc-1s3uzov-0 gHwtLv">Last updated on<!-- --> <b>12/28/2022</b></span></div></div></div></div></div></main></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script async="" src="https://www.googletagmanager.com/gtag/js?id="></script><script>
      
      
      if(true) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){window.dataLayer && window.dataLayer.push(arguments);}
        gtag('js', new Date());

        
      }
      </script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rnn-and-lstm/";window.___webpackCompilationHash="10c8b9c1f9dde870e591";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-2526e2a471eef3b9c3b2.js"],"app":["/app-f28009dab402ccf9360c.js"],"component---node-modules-gatsby-theme-primer-wiki-src-pages-404-js":["/component---node-modules-gatsby-theme-primer-wiki-src-pages-404-js-bd1c4b7f67a97d4f99af.js"],"component---node-modules-gatsby-theme-primer-wiki-src-templates-latest-query-js":["/component---node-modules-gatsby-theme-primer-wiki-src-templates-latest-query-js-6ed623c5d829c1a69525.js"],"component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js":["/component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js-46274f1a3983fff8a36b.js"]};/*]]>*/</script><script src="/polyfill-2526e2a471eef3b9c3b2.js" nomodule=""></script><script src="/component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js-46274f1a3983fff8a36b.js" async=""></script><script src="/commons-c89ede6cb9a530ac5a37.js" async=""></script><script src="/app-f28009dab402ccf9360c.js" async=""></script><script src="/dc6a8720040df98778fe970bf6c000a41750d3ae-8fdfd959b24cacbf7cee.js" async=""></script><script src="/0e226fb0-1cb0709e5ed968a9c435.js" async=""></script><script src="/f0e45107-3309acb69b4ccd30ce0c.js" async=""></script><script src="/framework-6c63f85700e5678d2c2a.js" async=""></script><script src="/webpack-runtime-1fe3daf7582b39746d36.js" async=""></script></body></html>