<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta data-react-helmet="true" name="twitter:image:alt" content="This repo provides information about the webizen development objectives, considerations and related experimentation!"/><meta data-react-helmet="true" name="twitter:image" content="https://devdocs.webizen.org/graph-visualisation.jpg"/><meta data-react-helmet="true" name="twitter:description" content="Tutorials Popular Training Approaches of DNNs — A Quick Overview https://medium.com/@asjad/popular-training-approaches-of-dnns-a-quick-over…"/><meta data-react-helmet="true" name="twitter:title" content="Training Deep Neural Networks"/><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"/><meta data-react-helmet="true" property="article:section" content="None"/><meta data-react-helmet="true" property="article:author" content="http://examples.opengraphprotocol.us/profile.html"/><meta data-react-helmet="true" property="article:modified_time" content="2022-12-30T11:53:44.000Z"/><meta data-react-helmet="true" property="article:published_time" content="2015-10-09T00:00:00.000Z"/><meta data-react-helmet="true" property="og:description" content="Tutorials Popular Training Approaches of DNNs — A Quick Overview https://medium.com/@asjad/popular-training-approaches-of-dnns-a-quick-over…"/><meta data-react-helmet="true" property="og:site_name"/><meta data-react-helmet="true" property="og:image:alt" content="This repo provides information about the webizen development objectives, considerations and related experimentation!"/><meta data-react-helmet="true" property="og:image" content="https://devdocs.webizen.org/graph-visualisation.jpg"/><meta data-react-helmet="true" property="og:url" content="https://devdocs.webizen.org/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-training-dnn/"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:title" content="Training Deep Neural Networks"/><meta data-react-helmet="true" name="image" content="https://devdocs.webizen.org/graph-visualisation.jpg"/><meta data-react-helmet="true" name="description" content="Tutorials Popular Training Approaches of DNNs — A Quick Overview https://medium.com/@asjad/popular-training-approaches-of-dnns-a-quick-over…"/><meta name="generator" content="Gatsby 4.6.0"/><style data-href="/styles.d9e480e5c6375621c4fd.css" data-identity="gatsby-global-css">.tippy-box[data-animation=fade][data-state=hidden]{opacity:0}[data-tippy-root]{max-width:calc(100vw - 10px)}.tippy-box{background-color:#333;border-radius:4px;color:#fff;font-size:14px;line-height:1.4;outline:0;position:relative;transition-property:visibility,opacity,-webkit-transform;transition-property:transform,visibility,opacity;transition-property:transform,visibility,opacity,-webkit-transform;white-space:normal}.tippy-box[data-placement^=top]>.tippy-arrow{bottom:0}.tippy-box[data-placement^=top]>.tippy-arrow:before{border-top-color:initial;border-width:8px 8px 0;bottom:-7px;left:0;-webkit-transform-origin:center top;transform-origin:center top}.tippy-box[data-placement^=bottom]>.tippy-arrow{top:0}.tippy-box[data-placement^=bottom]>.tippy-arrow:before{border-bottom-color:initial;border-width:0 8px 8px;left:0;top:-7px;-webkit-transform-origin:center bottom;transform-origin:center bottom}.tippy-box[data-placement^=left]>.tippy-arrow{right:0}.tippy-box[data-placement^=left]>.tippy-arrow:before{border-left-color:initial;border-width:8px 0 8px 8px;right:-7px;-webkit-transform-origin:center left;transform-origin:center left}.tippy-box[data-placement^=right]>.tippy-arrow{left:0}.tippy-box[data-placement^=right]>.tippy-arrow:before{border-right-color:initial;border-width:8px 8px 8px 0;left:-7px;-webkit-transform-origin:center right;transform-origin:center right}.tippy-box[data-inertia][data-state=visible]{transition-timing-function:cubic-bezier(.54,1.5,.38,1.11)}.tippy-arrow{color:#333;height:16px;width:16px}.tippy-arrow:before{border-color:transparent;border-style:solid;content:"";position:absolute}.tippy-content{padding:5px 9px;position:relative;z-index:1}.tippy-box[data-theme~=light]{background-color:#fff;box-shadow:0 0 20px 4px rgba(154,161,177,.15),0 4px 80px -8px rgba(36,40,47,.25),0 4px 4px -2px rgba(91,94,105,.15);color:#26323d}.tippy-box[data-theme~=light][data-placement^=top]>.tippy-arrow:before{border-top-color:#fff}.tippy-box[data-theme~=light][data-placement^=bottom]>.tippy-arrow:before{border-bottom-color:#fff}.tippy-box[data-theme~=light][data-placement^=left]>.tippy-arrow:before{border-left-color:#fff}.tippy-box[data-theme~=light][data-placement^=right]>.tippy-arrow:before{border-right-color:#fff}.tippy-box[data-theme~=light]>.tippy-backdrop{background-color:#fff}.tippy-box[data-theme~=light]>.tippy-svg-arrow{fill:#fff}html{font-family:SF Pro SC,SF Pro Text,SF Pro Icons,PingFang SC,Helvetica Neue,Helvetica,Arial,sans-serif}body{word-wrap:break-word;-ms-hyphens:auto;-webkit-hyphens:auto;hyphens:auto;overflow-wrap:break-word;-ms-word-break:break-all;word-break:break-word}blockquote,body,dd,dt,fieldset,figure,h1,h2,h3,h4,h5,h6,hr,html,iframe,legend,p,pre,textarea{margin:0;padding:0}h1,h2,h3,h4,h5,h6{font-size:100%;font-weight:400}button,input,select{margin:0}html{box-sizing:border-box}*,:after,:before{box-sizing:inherit}img,video{height:auto;max-width:100%}iframe{border:0}table{border-collapse:collapse;border-spacing:0}td,th{padding:0}</style><style data-styled="" data-styled-version="5.3.5">.fnAJEh{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;font-size:14px;background-color:#005cc5;color:#ffffff;padding:16px;}/*!sc*/
.fnAJEh:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.fnAJEh:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.czsBQU{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;color:#ffffff;margin-right:16px;}/*!sc*/
.czsBQU:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.czsBQU:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.kLOWMo{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;font-family:SFMono-Regular,Consolas,"Liberation Mono",Menlo,Courier,monospace;color:#ffffff;}/*!sc*/
.kLOWMo:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.kLOWMo:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.kEUvCO{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;display:block;color:inherit;margin-left:24px;}/*!sc*/
.kEUvCO:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.kEUvCO:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.fdzjHV{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;color:#24292e;display:block;}/*!sc*/
.fdzjHV:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.fdzjHV:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.HGjBQ{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;display:block;}/*!sc*/
.HGjBQ:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.HGjBQ:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.bQLMRL{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;font-size:16px;display:inline-block;padding-top:4px;padding-bottom:4px;color:#586069;font-weight:medium;}/*!sc*/
.bQLMRL:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.bQLMRL:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){.bQLMRL{font-size:14px;}}/*!sc*/
.ekSqTm{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;padding:8px;margin-left:-32px;color:#2f363d;}/*!sc*/
.ekSqTm:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.ekSqTm:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.cKRjba{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
.cKRjba:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.cKRjba:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.iLYDsn{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;margin-bottom:4px;}/*!sc*/
.iLYDsn:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.iLYDsn:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
data-styled.g1[id="Link-sc-1brdqhf-0"]{content:"fnAJEh,czsBQU,kLOWMo,kEUvCO,fdzjHV,HGjBQ,bQLMRL,ekSqTm,cKRjba,iLYDsn,"}/*!sc*/
.EuMgV{z-index:20;width:auto;height:auto;-webkit-clip:auto;clip:auto;position:absolute;overflow:hidden;}/*!sc*/
.EuMgV:not(:focus){-webkit-clip:rect(1px,1px,1px,1px);clip:rect(1px,1px,1px,1px);-webkit-clip-path:inset(50%);clip-path:inset(50%);height:1px;width:1px;margin:-1px;padding:0;}/*!sc*/
data-styled.g2[id="skip-link__SkipLink-sc-1z0kjxc-0"]{content:"EuMgV,"}/*!sc*/
.fbaWCe{display:none;margin-left:8px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.fbaWCe{display:inline;}}/*!sc*/
.bLwTGz{font-weight:600;display:inline-block;margin-bottom:4px;}/*!sc*/
.cQAYyE{font-weight:600;}/*!sc*/
.gHwtLv{font-size:14px;color:#444d56;margin-top:4px;}/*!sc*/
data-styled.g4[id="Text-sc-1s3uzov-0"]{content:"fbaWCe,bLwTGz,cQAYyE,gHwtLv,"}/*!sc*/
.ifkhtm{background-color:#ffffff;color:#24292e;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;min-height:100vh;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}/*!sc*/
.gSrgIV{top:0;z-index:1;position:-webkit-sticky;position:sticky;}/*!sc*/
.iTlzRc{padding-left:16px;padding-right:16px;background-color:#24292e;color:rgba(255,255,255,0.7);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:66px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.iTlzRc{padding-left:24px;padding-right:24px;}}/*!sc*/
.kCrfOd{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.gELiHA{margin-left:24px;display:none;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.gELiHA{display:block;}}/*!sc*/
.gYHnkh{position:relative;}/*!sc*/
.dMFMzl{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/
.jhCmHN{display:none;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.jhCmHN{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}/*!sc*/
.elXfHl{color:rgba(255,255,255,0.7);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.gjFLbZ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.gjFLbZ{display:none;}}/*!sc*/
.gucKKf{color:rgba(255,255,255,0.7);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:0;background-color:none;cursor:pointer;}/*!sc*/
.gucKKf:hover{fill:rgba(255,255,255,0.7);color:rgba(255,255,255,0.7);}/*!sc*/
.gucKKf svg{fill:rgba(255,255,255,0.7);}/*!sc*/
.fBMuRw{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;}/*!sc*/
.bQaVuO{color:#2f363d;background-color:#fafbfc;display:none;height:calc(100vh - 66px);min-width:260px;max-width:360px;position:-webkit-sticky;position:sticky;top:66px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.bQaVuO{display:block;}}/*!sc*/
.eeDmz{height:100%;border-style:solid;border-color:#e1e4e8;border-width:0;border-right-width:1px;border-radius:0;}/*!sc*/
.kSoTbZ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}/*!sc*/
.nElVQ{padding:24px;border-style:solid;border-color:#e1e4e8;border-width:0;border-radius:0;border-top-width:1px;}/*!sc*/
.iXtyim{margin-left:0;padding-top:4px;padding-bottom:4px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;border-style:solid;border-color:#e1e4e8;border-width:0;border-radius:0;border-bottom-width:0;}/*!sc*/
.vaHQm{margin-bottom:4px;margin-top:4px;font-size:14px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
.hIjKHD{color:#586069;font-weight:400;display:block;}/*!sc*/
.icYakO{padding-left:8px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;}/*!sc*/
.jLseWZ{margin-left:16px;padding-top:0;padding-bottom:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;border-style:solid;border-color:#e1e4e8;border-width:0;border-radius:0;border-bottom-width:0;}/*!sc*/
.kRSqJi{margin-bottom:0;margin-top:8px;font-size:14px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
.klfmeZ{max-width:1440px;-webkit-flex:1;-ms-flex:1;flex:1;}/*!sc*/
.TZbDV{padding:24px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;width:100%;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-flex-direction:row-reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse;}/*!sc*/
@media screen and (min-width:544px){.TZbDV{padding:32px;}}/*!sc*/
@media screen and (min-width:768px){.TZbDV{padding:40px;}}/*!sc*/
@media screen and (min-width:1012px){.TZbDV{padding:48px;}}/*!sc*/
.DPDMP{display:none;max-height:calc(100vh - 66px - 24px);position:-webkit-sticky;position:sticky;top:90px;width:220px;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;margin-left:40px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){.DPDMP{display:block;}}/*!sc*/
.gUNLMu{margin:0;padding:0;}/*!sc*/
.bzTeHX{padding-left:0;}/*!sc*/
.bnaGYs{padding-left:16px;}/*!sc*/
.meQBK{width:100%;}/*!sc*/
.fkoaiG{margin-bottom:24px;}/*!sc*/
.biGwYR{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.jYYExC{margin-bottom:32px;background-color:#f6f8fa;display:block;border-width:1px;border-style:solid;border-color:#e1e4e8;border-radius:6px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){.jYYExC{display:none;}}/*!sc*/
.hgiZBa{padding:16px;}/*!sc*/
.hnQOQh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.gEqaxf{padding:16px;border-top:1px solid;border-color:border.gray;}/*!sc*/
.ksEcN{margin-top:64px;padding-top:32px;padding-bottom:32px;border-style:solid;border-color:#e1e4e8;border-width:0;border-top-width:1px;border-radius:0;}/*!sc*/
.jsSpbO{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
data-styled.g5[id="Box-nv15kw-0"]{content:"ifkhtm,gSrgIV,iTlzRc,kCrfOd,gELiHA,gYHnkh,dMFMzl,jhCmHN,elXfHl,gjFLbZ,gucKKf,fBMuRw,bQaVuO,eeDmz,kSoTbZ,nElVQ,iXtyim,vaHQm,hIjKHD,icYakO,jLseWZ,kRSqJi,klfmeZ,TZbDV,DPDMP,gUNLMu,bzTeHX,bnaGYs,meQBK,fkoaiG,biGwYR,jYYExC,hgiZBa,hnQOQh,gEqaxf,ksEcN,jsSpbO,"}/*!sc*/
.cjGjQg{position:relative;display:inline-block;padding:6px 16px;font-family:inherit;font-weight:600;line-height:20px;white-space:nowrap;vertical-align:middle;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;border-radius:6px;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;font-size:14px;}/*!sc*/
.cjGjQg:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
.cjGjQg:focus{outline:none;}/*!sc*/
.cjGjQg:disabled{cursor:default;}/*!sc*/
.cjGjQg:disabled svg{opacity:0.6;}/*!sc*/
data-styled.g6[id="ButtonBase-sc-181ps9o-0"]{content:"cjGjQg,"}/*!sc*/
.fafffn{margin-right:8px;}/*!sc*/
data-styled.g8[id="StyledOcticon-uhnt7w-0"]{content:"bhRGQB,fafffn,"}/*!sc*/
.fTkTnC{font-weight:600;font-size:32px;margin:0;font-size:12px;font-weight:500;color:#959da5;margin-bottom:4px;text-transform:uppercase;font-family:Content-font,Roboto,sans-serif;}/*!sc*/
.glhHOU{font-weight:600;font-size:32px;margin:0;margin-right:8px;}/*!sc*/
.ffNRvO{font-weight:600;font-size:32px;margin:0;}/*!sc*/
data-styled.g12[id="Heading-sc-1cjoo9h-0"]{content:"fTkTnC,glhHOU,ffNRvO,"}/*!sc*/
.ifFLoZ{color:#0366d6;border:1px solid rgba(27,31,35,0.15);background-color:#fafbfc;box-shadow:0 1px 0 rgba(27,31,35,0.04);margin-left:16px;}/*!sc*/
.ifFLoZ:hover{color:#ffffff;background-color:#0366d6;border-color:rgba(27,31,35,0.15);box-shadow:0 1px 0 rgba(27,31,35,0.1);}/*!sc*/
.ifFLoZ:focus{border-color:rgba(27,31,35,0.15);box-shadow:0 0 0 3px rgba(0,92,197,0.4);}/*!sc*/
.ifFLoZ:active{color:#ffffff;background-color:hsla(212,97%,40%,1);box-shadow:inset 0 1px 0 rgba(5,38,76,0.2);border-color:rgba(27,31,35,0.15);}/*!sc*/
.ifFLoZ:disabled{color:rgba(3,102,214,0.5);background-color:#fafbfc;border-color:rgba(27,31,35,0.15);}/*!sc*/
.fKTxJr{color:#0366d6;border:1px solid rgba(27,31,35,0.15);background-color:#fafbfc;box-shadow:0 1px 0 rgba(27,31,35,0.04);}/*!sc*/
.fKTxJr:hover{color:#ffffff;background-color:#0366d6;border-color:rgba(27,31,35,0.15);box-shadow:0 1px 0 rgba(27,31,35,0.1);}/*!sc*/
.fKTxJr:focus{border-color:rgba(27,31,35,0.15);box-shadow:0 0 0 3px rgba(0,92,197,0.4);}/*!sc*/
.fKTxJr:active{color:#ffffff;background-color:hsla(212,97%,40%,1);box-shadow:inset 0 1px 0 rgba(5,38,76,0.2);border-color:rgba(27,31,35,0.15);}/*!sc*/
.fKTxJr:disabled{color:rgba(3,102,214,0.5);background-color:#fafbfc;border-color:rgba(27,31,35,0.15);}/*!sc*/
.cXFtEt{color:#0366d6;border:1px solid rgba(27,31,35,0.15);background-color:#fafbfc;box-shadow:0 1px 0 rgba(27,31,35,0.04);margin-left:16px;}/*!sc*/
.cXFtEt:hover{color:#ffffff;background-color:#0366d6;border-color:rgba(27,31,35,0.15);box-shadow:0 1px 0 rgba(27,31,35,0.1);}/*!sc*/
.cXFtEt:focus{border-color:rgba(27,31,35,0.15);box-shadow:0 0 0 3px rgba(0,92,197,0.4);}/*!sc*/
.cXFtEt:active{color:#ffffff;background-color:hsla(212,97%,40%,1);box-shadow:inset 0 1px 0 rgba(5,38,76,0.2);border-color:rgba(27,31,35,0.15);}/*!sc*/
.cXFtEt:disabled{color:rgba(3,102,214,0.5);background-color:#fafbfc;border-color:rgba(27,31,35,0.15);}/*!sc*/
data-styled.g13[id="ButtonOutline-sc-15gta9l-0"]{content:"ifFLoZ,fKTxJr,cXFtEt,"}/*!sc*/
.iEGqHu{color:rgba(255,255,255,0.7);background-color:transparent;border:1px solid #444d56;box-shadow:none;}/*!sc*/
data-styled.g14[id="dark-button__DarkButton-sc-bvvmfe-0"]{content:"iEGqHu,"}/*!sc*/
.ljCWQd{border:0;font-size:inherit;font-family:inherit;background-color:transparent;-webkit-appearance:none;color:inherit;width:100%;}/*!sc*/
.ljCWQd:focus{outline:0;}/*!sc*/
data-styled.g15[id="TextInput__Input-sc-1apmpmt-0"]{content:"ljCWQd,"}/*!sc*/
.dHfzvf{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;min-height:34px;font-size:14px;line-height:20px;color:#24292e;vertical-align:middle;background-repeat:no-repeat;background-position:right 8px center;border:1px solid #e1e4e8;border-radius:6px;outline:none;box-shadow:inset 0 1px 0 rgba(225,228,232,0.2);padding:6px 12px;width:240px;}/*!sc*/
.dHfzvf .TextInput-icon{-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;color:#959da5;margin:0 8px;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;}/*!sc*/
.dHfzvf:focus-within{border-color:#0366d6;box-shadow:0 0 0 3px rgba(3,102,214,0.3);}/*!sc*/
@media (min-width:768px){.dHfzvf{font-size:14px;}}/*!sc*/
data-styled.g16[id="TextInput__Wrapper-sc-1apmpmt-1"]{content:"dHfzvf,"}/*!sc*/
.khRwtY{font-size:16px !important;color:rgba(255,255,255,0.7);background-color:rgba(255,255,255,0.07);border:1px solid transparent;box-shadow:none;}/*!sc*/
.khRwtY:focus{border:1px solid #444d56 outline:none;box-shadow:none;}/*!sc*/
data-styled.g17[id="dark-text-input__DarkTextInput-sc-1s2iwzn-0"]{content:"khRwtY,"}/*!sc*/
.bqVpte.active{font-weight:600;color:#2f363d;}/*!sc*/
data-styled.g19[id="nav-items__NavLink-sc-tqz5wl-0"]{content:"bqVpte,"}/*!sc*/
.kEKZhO.active{font-weight:600;color:#2f363d;}/*!sc*/
data-styled.g20[id="nav-items__NavBox-sc-tqz5wl-1"]{content:"kEKZhO,"}/*!sc*/
.gCPbFb{margin-top:24px;margin-bottom:16px;-webkit-scroll-margin-top:90px;-moz-scroll-margin-top:90px;-ms-scroll-margin-top:90px;scroll-margin-top:90px;}/*!sc*/
.gCPbFb .octicon-link{visibility:hidden;}/*!sc*/
.gCPbFb:hover .octicon-link,.gCPbFb:focus-within .octicon-link{visibility:visible;}/*!sc*/
data-styled.g22[id="heading__StyledHeading-sc-1fu06k9-0"]{content:"gCPbFb,"}/*!sc*/
.fGjcEF{margin-top:0;padding-bottom:4px;font-size:32px;border-bottom:1px solid #e1e4e8;}/*!sc*/
data-styled.g23[id="heading__StyledH1-sc-1fu06k9-1"]{content:"fGjcEF,"}/*!sc*/
.fvbkiW{padding-bottom:4px;font-size:24px;border-bottom:1px solid #e1e4e8;}/*!sc*/
data-styled.g24[id="heading__StyledH2-sc-1fu06k9-2"]{content:"fvbkiW,"}/*!sc*/
.cxpRJj{font-size:20px;}/*!sc*/
data-styled.g25[id="heading__StyledH3-sc-1fu06k9-3"]{content:"cxpRJj,"}/*!sc*/
.elBfYx{max-width:100%;box-sizing:content-box;background-color:#ffffff;}/*!sc*/
data-styled.g30[id="image__Image-sc-1r30dtv-0"]{content:"elBfYx,"}/*!sc*/
.dFVIUa{padding-left:2em;margin-bottom:4px;}/*!sc*/
.dFVIUa ul,.dFVIUa ol{margin-top:0;margin-bottom:0;}/*!sc*/
.dFVIUa li{line-height:1.6;}/*!sc*/
.dFVIUa li > p{margin-top:16px;}/*!sc*/
.dFVIUa li + li{margin-top:8px;}/*!sc*/
data-styled.g32[id="list__List-sc-s5kxp2-0"]{content:"dFVIUa,"}/*!sc*/
.iNQqSl{margin:0 0 16px;}/*!sc*/
data-styled.g34[id="paragraph__Paragraph-sc-17pab92-0"]{content:"iNQqSl,"}/*!sc*/
.drDDht{z-index:0;}/*!sc*/
data-styled.g37[id="layout___StyledBox-sc-7a5ttt-0"]{content:"drDDht,"}/*!sc*/
.flyUPp{list-style:none;}/*!sc*/
data-styled.g39[id="table-of-contents___StyledBox-sc-1jtv948-0"]{content:"flyUPp,"}/*!sc*/
.bPkrfP{grid-area:table-of-contents;overflow:auto;}/*!sc*/
data-styled.g40[id="post-page___StyledBox-sc-17hbw1s-0"]{content:"bPkrfP,"}/*!sc*/
</style><title data-react-helmet="true">Training Deep Neural Networks - Webizen Development Related Documentation.</title><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper picture.object-fit-polyfill{position:static!important}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){if(void 0===e.target.dataset.mainImage)return;if(void 0===e.target.dataset.gatsbyImageSsr)return;const t=e.target;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="icon" href="/favicon-32x32.png?v=202c3b6fa23c481f8badd00dc2119591" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=202c3b6fa23c481f8badd00dc2119591"/><link rel="sitemap" type="application/xml" href="/sitemap/sitemap-index.xml"/><link rel="preconnect" href="https://www.googletagmanager.com"/><link rel="dns-prefetch" href="https://www.googletagmanager.com"/><link as="script" rel="preload" href="/webpack-runtime-1fe3daf7582b39746d36.js"/><link as="script" rel="preload" href="/framework-6c63f85700e5678d2c2a.js"/><link as="script" rel="preload" href="/f0e45107-3309acb69b4ccd30ce0c.js"/><link as="script" rel="preload" href="/0e226fb0-1cb0709e5ed968a9c435.js"/><link as="script" rel="preload" href="/dc6a8720040df98778fe970bf6c000a41750d3ae-8fdfd959b24cacbf7cee.js"/><link as="script" rel="preload" href="/app-f28009dab402ccf9360c.js"/><link as="script" rel="preload" href="/commons-c89ede6cb9a530ac5a37.js"/><link as="script" rel="preload" href="/component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js-46274f1a3983fff8a36b.js"/><link as="fetch" rel="preload" href="/page-data/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-training-dnn/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/2230547434.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/2320115945.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/3495835395.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/451533639.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><a class="Link-sc-1brdqhf-0 fnAJEh skip-link__SkipLink-sc-1z0kjxc-0 EuMgV" color="auto.white" href="#skip-nav" font-size="1">Skip to content</a><div display="flex" color="text.primary" class="Box-nv15kw-0 ifkhtm"><div class="Box-nv15kw-0 gSrgIV"><div display="flex" height="66" color="header.text" class="Box-nv15kw-0 iTlzRc"><div display="flex" class="Box-nv15kw-0 kCrfOd"><a color="header.logo" mr="3" class="Link-sc-1brdqhf-0 czsBQU" href="/"><svg aria-hidden="true" role="img" class="StyledOcticon-uhnt7w-0 bhRGQB" viewBox="0 0 16 16" width="32" height="32" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path></svg></a><a color="header.logo" font-family="mono" class="Link-sc-1brdqhf-0 kLOWMo" href="/">Wiki</a><div display="none,,,block" class="Box-nv15kw-0 gELiHA"><div role="combobox" aria-expanded="false" aria-haspopup="listbox" aria-labelledby="downshift-search-label" class="Box-nv15kw-0 gYHnkh"><span class="TextInput__Wrapper-sc-1apmpmt-1 dHfzvf dark-text-input__DarkTextInput-sc-1s2iwzn-0 khRwtY TextInput-wrapper" width="240"><input type="text" aria-autocomplete="list" aria-labelledby="downshift-search-label" autoComplete="off" value="" id="downshift-search-input" placeholder="Search Wiki" class="TextInput__Input-sc-1apmpmt-0 ljCWQd"/></span></div></div></div><div display="flex" class="Box-nv15kw-0 dMFMzl"><div display="none,,,flex" class="Box-nv15kw-0 jhCmHN"><div display="flex" color="header.text" class="Box-nv15kw-0 elXfHl"><a display="block" color="inherit" target="_blank" rel="noopener noreferrer" href="https://github.com/webizenai/devdocs/" class="Link-sc-1brdqhf-0 kEUvCO">Github</a><a display="block" color="inherit" target="_blank" rel="noopener noreferrer" href="https://twitter.com/webcivics" class="Link-sc-1brdqhf-0 kEUvCO">Twitter</a></div><button aria-label="Theme" aria-expanded="false" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 cjGjQg ifFLoZ iEGqHu"><svg aria-hidden="true" role="img" class="octicon octicon-sun" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z"></path></svg></button></div><div display="flex,,,none" class="Box-nv15kw-0 gjFLbZ"><button aria-label="Search" aria-expanded="false" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 cjGjQg fKTxJr iEGqHu"><svg aria-hidden="true" role="img" class="octicon octicon-search" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M11.5 7a4.499 4.499 0 11-8.998 0A4.499 4.499 0 0111.5 7zm-.82 4.74a6 6 0 111.06-1.06l3.04 3.04a.75.75 0 11-1.06 1.06l-3.04-3.04z"></path></svg></button></div><button aria-label="Show Graph Visualisation" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 cjGjQg cXFtEt iEGqHu"><div title="Show Graph Visualisation" aria-label="Show Graph Visualisation" color="header.text" display="flex" class="Box-nv15kw-0 gucKKf"><svg t="1607341341241" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" width="20" height="20"><path d="M512 512m-125.866667 0a125.866667 125.866667 0 1 0 251.733334 0 125.866667 125.866667 0 1 0-251.733334 0Z"></path><path d="M512 251.733333m-72.533333 0a72.533333 72.533333 0 1 0 145.066666 0 72.533333 72.533333 0 1 0-145.066666 0Z"></path><path d="M614.4 238.933333c0 4.266667 2.133333 8.533333 2.133333 12.8 0 19.2-4.266667 36.266667-12.8 51.2 81.066667 36.266667 138.666667 117.333333 138.666667 211.2C742.4 640 640 744.533333 512 744.533333s-230.4-106.666667-230.4-232.533333c0-93.866667 57.6-174.933333 138.666667-211.2-8.533333-14.933333-12.8-32-12.8-51.2 0-4.266667 0-8.533333 2.133333-12.8-110.933333 42.666667-189.866667 147.2-189.866667 273.066667 0 160 130.133333 292.266667 292.266667 292.266666S804.266667 672 804.266667 512c0-123.733333-78.933333-230.4-189.866667-273.066667z"></path><path d="M168.533333 785.066667m-72.533333 0a72.533333 72.533333 0 1 0 145.066667 0 72.533333 72.533333 0 1 0-145.066667 0Z"></path><path d="M896 712.533333m-61.866667 0a61.866667 61.866667 0 1 0 123.733334 0 61.866667 61.866667 0 1 0-123.733334 0Z"></path><path d="M825.6 772.266667c-74.666667 89.6-187.733333 147.2-313.6 147.2-93.866667 0-181.333333-32-249.6-87.466667-10.666667 19.2-25.6 34.133333-44.8 44.8C298.666667 942.933333 401.066667 981.333333 512 981.333333c149.333333 0 281.6-70.4 366.933333-177.066666-21.333333-4.266667-40.533333-17.066667-53.333333-32zM142.933333 684.8c-25.6-53.333333-38.4-110.933333-38.4-172.8C104.533333 288 288 104.533333 512 104.533333S919.466667 288 919.466667 512c0 36.266667-6.4 72.533333-14.933334 106.666667 23.466667 2.133333 42.666667 10.666667 57.6 25.6 12.8-42.666667 19.2-87.466667 19.2-132.266667 0-258.133333-211.2-469.333333-469.333333-469.333333S42.666667 253.866667 42.666667 512c0 74.666667 17.066667 142.933333 46.933333 204.8 14.933333-14.933333 32-27.733333 53.333333-32z"></path></svg><span display="none,,,inline" class="Text-sc-1s3uzov-0 fbaWCe">Show Graph Visualisation</span></div></button><div display="flex,,,none" class="Box-nv15kw-0 gjFLbZ"><button aria-label="Menu" aria-expanded="false" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 cjGjQg ifFLoZ iEGqHu"><svg aria-hidden="true" role="img" class="octicon octicon-three-bars" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M1 2.75A.75.75 0 011.75 2h12.5a.75.75 0 110 1.5H1.75A.75.75 0 011 2.75zm0 5A.75.75 0 011.75 7h12.5a.75.75 0 110 1.5H1.75A.75.75 0 011 7.75zM1.75 12a.75.75 0 100 1.5h12.5a.75.75 0 100-1.5H1.75z"></path></svg></button></div></div></div></div><div display="flex" class="Box-nv15kw-0 layout___StyledBox-sc-7a5ttt-0 fBMuRw drDDht"><div display="none,,,block" height="calc(100vh - 66px)" color="auto.gray.8" class="Box-nv15kw-0 bQaVuO"><div height="100%" style="overflow:auto" class="Box-nv15kw-0 eeDmz"><div display="flex" class="Box-nv15kw-0 kSoTbZ"><div class="Box-nv15kw-0 nElVQ"><div display="flex" class="Box-nv15kw-0 kSoTbZ"><h2 color="text.disabled" font-size="12px" font-weight="500" class="Heading-sc-1cjoo9h-0 fTkTnC">Categories</h2><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Commercial</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Core Services</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Core Technologies</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Database Requirements</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Host Service Requirements</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 fdzjHV bqVpte" display="block" sx="[object Object]" href="/HyperMedia Library/">HyperMedia Library</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">ICT Stack</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Implementation V1</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Non-HTTP(s) Protocols</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Old-Work-Archives</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">2018-Webizen-Net-Au</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">_Link_library_links</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">_Posts</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/about/">about</a><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/the-human-centric-infosphere/">An Overview</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/">Resource Library</a><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">awesomeLists</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/">Handong1587</a><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">_Posts</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Computer_science</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Computer_vision</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Deep_learning</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2021-07-28-3d/">3D</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-cnn-compression-acceleration/">Acceleration and Model Compression</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-knowledge-distillation/">Acceleration and Model Compression</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-adversarial-attacks-and-defences/">Adversarial Attacks and Defences</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-audio-image-video-generation/">Audio / Image / Video Generation</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2022-06-27-bev/">BEV</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recognition/">Classification / Recognition</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-autonomous-driving/">Deep Learning and Autonomous Driving</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-pose-estimation/">Deep Learning Applications</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-applications/">Deep Learning Applications</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-courses/">Deep learning Courses</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-frameworks/">Deep Learning Frameworks</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-resources/">Deep Learning Resources</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-software-hardware/">Deep Learning Software and Hardware</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tricks/">Deep Learning Tricks</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-tutorials/">Deep Learning Tutorials</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-dl-with-ml/">Deep Learning with Machine Learning</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-face-recognition/">Face Recognition</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-fun-with-deep-learning/">Fun With Deep Learning</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gan/">Generative Adversarial Networks</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-gcn/">Graph Convolutional Networks</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-captioning/">Image / Video Captioning</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-retrieval/">Image Retrieval</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2018-09-03-keep-up-with-new-trends/">Keep Up With New Trends</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-lidar-3d-detection/">LiDAR 3D Object Detection</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nlp/">Natural Language Processing</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-nas/">Neural Architecture Search</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-counting/">Object Counting</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-object-detection/">Object Detection</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-ocr/">OCR</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-optical-flow/">Optical Flow</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-re-id/">Re-ID</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-recommendation-system/">Recommendation System</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rl/">Reinforcement Learning</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-rnn-and-lstm/">RNN and LSTM</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-segmentation/">Segmentation</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-style-transfer/">Style Transfer</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-super-resolution/">Super-Resolution</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-tracking/">Tracking</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a aria-current="page" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte active" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-training-dnn/">Training Deep Neural Networks</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-transfer-learning/">Transfer Learning</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-unsupervised-learning/">Unsupervised Learning</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-video-applications/">Video Applications</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-vqa/">Visual Question Answering</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-visulizing-interpreting-cnn/">Visualizing and Interpreting Convolutional Neural Network</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Leisure</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Machine_learning</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Mathematics</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Programming_study</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Reading_and_thoughts</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Study</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Working_on_linux</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Working_on_mac</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Working_on_windows</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Drafts</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div></div></div></div><div display="flex" class="Box-nv15kw-0 jLseWZ"><div display="flex" font-size="1" class="Box-nv15kw-0 kRSqJi"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 HGjBQ bqVpte" display="block" sx="[object Object]" href="/old-work-archives/2018 - Web Civics BizPlan/">EXECUTIVE SUMMARY</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 hIjKHD kEKZhO" display="block">Webizen 2.0</div><div display="flex" class="Box-nv15kw-0 icYakO"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 iXtyim"><div display="flex" font-size="1" class="Box-nv15kw-0 vaHQm"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 fdzjHV bqVpte" display="block" sx="[object Object]" href="/">Webizen V1 Project Documentation</a><div display="flex" class="Box-nv15kw-0 icYakO"></div></div></div></div></div></div></div></div><main class="Box-nv15kw-0 klfmeZ"><div id="skip-nav" display="flex" width="100%" class="Box-nv15kw-0 TZbDV"><div display="none,,block" class="Box-nv15kw-0 post-page___StyledBox-sc-17hbw1s-0 DPDMP bPkrfP"><span display="inline-block" font-weight="bold" class="Text-sc-1s3uzov-0 bLwTGz">On this page</span><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#tutorials" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Tutorials</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#papers" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Papers</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#activation-functions" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Activation functions</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#relu" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">ReLU</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#lrelu" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">LReLU</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#prelu" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">PReLU</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#srelu" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">SReLU</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#mba" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">MBA</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#concatenated-relu-crelu" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Concatenated ReLU (CRelu)</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#gelu" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">GELU</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#selu" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">SELU</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#eraserelu" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">EraseReLU</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#swish" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Swish</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#series-on-initialization-of-weights-for-dnn" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Series on Initialization of Weights for DNN</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#weights-initialization" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Weights Initialization</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#batch-normalization" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Batch Normalization</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#layer-normalization" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Layer Normalization</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#group-normalization" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Group Normalization</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#batch-instance-normalization" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Batch-Instance Normalization</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#dynamic-normalization" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Dynamic Normalization</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#loss-function" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Loss Function</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#learning-rates" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Learning Rates</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#convolution-filters" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Convolution Filters</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#pooling" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Pooling</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#mini-batch" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Mini-Batch</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#optimization-methods" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Optimization Methods</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#adam" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Adam</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#tensor-methods" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Tensor Methods</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#regularization" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Regularization</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#dropout" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Dropout</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#dropconnect" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">DropConnect</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#dropneuron" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">DropNeuron</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#dropblock" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">DropBlock</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#maxout" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Maxout</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#swapout" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Swapout</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#whiteout" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Whiteout</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#gradient-descent" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Gradient Descent</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#adagrad" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">AdaGrad</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#momentum" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Momentum</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#backpropagation" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Backpropagation</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#accelerate-training" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Accelerate Training</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#parallelism" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Parallelism</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#handling-datasets" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Handling Datasets</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#data-augmentation" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Data Augmentation</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#imbalanced-datasets" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Imbalanced Datasets</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#noisy--unlabelled-data" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Noisy / Unlabelled Data</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#low-numerical-precision" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Low Numerical Precision</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#distributed-training" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Distributed Training</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#projects" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Projects</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#videos" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Videos</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#blogs" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Blogs</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#adversarial-training" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Adversarial Training</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#low-precision-training" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Low-Precision Training</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#incremental-training" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Incremental Training</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#papers-1" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Papers</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#tools" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Tools</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#blogs-1" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Blogs</a></li></ul></div><div width="100%" class="Box-nv15kw-0 meQBK"><div class="Box-nv15kw-0 fkoaiG"><div display="flex" class="Box-nv15kw-0 biGwYR"><h1 class="Heading-sc-1cjoo9h-0 glhHOU">Training Deep Neural Networks</h1></div></div><div display="block,,none" class="Box-nv15kw-0 jYYExC"><div class="Box-nv15kw-0 hgiZBa"><div display="flex" class="Box-nv15kw-0 hnQOQh"><span font-weight="bold" class="Text-sc-1s3uzov-0 cQAYyE">On this page</span></div></div><div class="Box-nv15kw-0 gEqaxf"><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#tutorials" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Tutorials</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#papers" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Papers</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#activation-functions" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Activation functions</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#relu" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">ReLU</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#lrelu" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">LReLU</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#prelu" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">PReLU</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#srelu" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">SReLU</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#mba" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">MBA</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#concatenated-relu-crelu" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Concatenated ReLU (CRelu)</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#gelu" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">GELU</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#selu" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">SELU</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#eraserelu" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">EraseReLU</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#swish" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Swish</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#series-on-initialization-of-weights-for-dnn" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Series on Initialization of Weights for DNN</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#weights-initialization" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Weights Initialization</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#batch-normalization" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Batch Normalization</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#layer-normalization" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Layer Normalization</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#group-normalization" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Group Normalization</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#batch-instance-normalization" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Batch-Instance Normalization</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#dynamic-normalization" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Dynamic Normalization</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#loss-function" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Loss Function</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#learning-rates" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Learning Rates</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#convolution-filters" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Convolution Filters</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#pooling" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Pooling</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#mini-batch" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Mini-Batch</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#optimization-methods" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Optimization Methods</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#adam" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Adam</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#tensor-methods" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Tensor Methods</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#regularization" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Regularization</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#dropout" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Dropout</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#dropconnect" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">DropConnect</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#dropneuron" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">DropNeuron</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#dropblock" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">DropBlock</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#maxout" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Maxout</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#swapout" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Swapout</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#whiteout" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Whiteout</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#gradient-descent" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Gradient Descent</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#adagrad" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">AdaGrad</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#momentum" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Momentum</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#backpropagation" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Backpropagation</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#accelerate-training" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Accelerate Training</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#parallelism" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Parallelism</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#handling-datasets" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Handling Datasets</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#data-augmentation" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Data Augmentation</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#imbalanced-datasets" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Imbalanced Datasets</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#noisy--unlabelled-data" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Noisy / Unlabelled Data</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#low-numerical-precision" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Low Numerical Precision</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#distributed-training" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Distributed Training</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 gUNLMu flyUPp"><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#projects" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Projects</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#videos" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Videos</a></li><li class="Box-nv15kw-0 bnaGYs"><a display="inline-block" href="#blogs" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Blogs</a></li></ul></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#adversarial-training" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Adversarial Training</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#low-precision-training" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Low-Precision Training</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#incremental-training" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Incremental Training</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#papers-1" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Papers</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#tools" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Tools</a></li><li class="Box-nv15kw-0 bzTeHX"><a display="inline-block" href="#blogs-1" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 bQLMRL">Blogs</a></li></ul></div></div><h1 id="tutorials" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#tutorials" color="auto.gray.8" aria-label="Tutorials permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Tutorials</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Popular Training Approaches of DNNs — A Quick Overview</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://medium.com/@asjad/popular-training-approaches-of-dnns-a-quick-overview-26ee37ad7e96#.pqyo039bb" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@asjad/popular-training-approaches-of-dnns-a-quick-overview-26ee37ad7e96#.pqyo039bb</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Optimisation and training techniques for deep learning</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://blog.acolyer.org/2017/03/01/optimisation-and-training-techniques-for-deep-learning/" class="Link-sc-1brdqhf-0 cKRjba">https://blog.acolyer.org/2017/03/01/optimisation-and-training-techniques-for-deep-learning/</a></p><h1 id="papers" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#papers" color="auto.gray.8" aria-label="Papers permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Papers</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>SNIPER: Efficient Multi-Scale Training</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1805.09300" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1805.09300</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>RePr: Improved Training of Convolutional Filters</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1811.07275" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1811.07275</a></p><h1 id="activation-functions" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#activation-functions" color="auto.gray.8" aria-label="Activation functions permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Activation functions</h1><h2 id="relu" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#relu" color="auto.gray.8" aria-label="ReLU permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>ReLU</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Rectified linear units improve restricted boltzmann machines</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ReLU</li><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://machinelearning.wustl.edu/mlpapers/paper_files/icml2010_NairH10.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://machinelearning.wustl.edu/mlpapers/paper_files/icml2010_NairH10.pdf</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Expressiveness of Rectifier Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICML 2016</li><li>intro: This paper studies the expressiveness of ReLU Networks</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1511.05678" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1511.05678</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>How can a deep neural network with ReLU activations in its hidden layers approximate any function?</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>quora: <a target="_blank" rel="noopener noreferrer" href="https://www.quora.com/How-can-a-deep-neural-network-with-ReLU-activations-in-its-hidden-layers-approximate-any-function" class="Link-sc-1brdqhf-0 cKRjba">https://www.quora.com/How-can-a-deep-neural-network-with-ReLU-activations-in-its-hidden-layers-approximate-any-function</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Understanding Deep Neural Networks with Rectified Linear Units</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Johns Hopkins University</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1611.01491" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1611.01491</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Learning ReLUs via Gradient Descent</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1705.04591" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1705.04591</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Training Better CNNs Requires to Rethink ReLU</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1709.06247" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1709.06247</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Learning using Rectified Linear Units (ReLU)</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Adamson University</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1803.08375" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1803.08375</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/AFAgarap/relu-classifier" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/AFAgarap/relu-classifier</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Stochastic Gradient Descent Optimizes Over-parameterized Deep ReLU Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: University of California, Los Angeles</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1811.08888" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1811.08888</a></li></ul><h2 id="lrelu" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#lrelu" color="auto.gray.8" aria-label="LReLU permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>LReLU</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Rectifier Nonlinearities Improve Neural Network Acoustic Models</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: leaky-ReLU, aka LReLU</li><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Sparse Rectifier Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf</a></li></ul><h2 id="prelu" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#prelu" color="auto.gray.8" aria-label="PReLU permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>PReLU</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>keywords: PReLU, Caffe &quot;msra&quot; weights initilization</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1502.01852" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1502.01852</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Empirical Evaluation of Rectified Activations in Convolutional Network</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ReLU / LReLU / PReLU / RReLU</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1505.00853" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1505.00853</a></li></ul><h2 id="srelu" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#srelu" color="auto.gray.8" aria-label="SReLU permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>SReLU</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Learning with S-shaped Rectified Linear Activation Units</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro:  SReLU</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1512.07030" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1512.07030</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Parametric Activation Pools greatly increase performance and consistency in ConvNets</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://blog.claymcleod.io/2016/02/06/Parametric-Activation-Pools-greatly-increase-performance-and-consistency-in-ConvNets/" class="Link-sc-1brdqhf-0 cKRjba">http://blog.claymcleod.io/2016/02/06/Parametric-Activation-Pools-greatly-increase-performance-and-consistency-in-ConvNets/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICML 2016</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1602.02068" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1602.02068</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/gokceneraslan/SparseMax.torch" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/gokceneraslan/SparseMax.torch</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/Unbabel/sparsemax" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Unbabel/sparsemax</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Revise Saturated Activation Functions</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1602.05980" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1602.05980</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Noisy Activation Functions</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1603.00391" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1603.00391</a></li></ul><h2 id="mba" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#mba" color="auto.gray.8" aria-label="MBA permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>MBA</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Multi-Bias Non-linear Activation in Deep Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: MBA</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1604.00676" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1604.00676</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Learning activation functions from data using cubic spline interpolation</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1605.05509" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1605.05509</a></li><li>bitbucket: <a target="_blank" rel="noopener noreferrer" href="https://bitbucket.org/ispamm/spline-nn" class="Link-sc-1brdqhf-0 cKRjba">https://bitbucket.org/ispamm/spline-nn</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>What is the role of the activation function in a neural network?</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>quora: <a target="_blank" rel="noopener noreferrer" href="https://www.quora.com/What-is-the-role-of-the-activation-function-in-a-neural-network" class="Link-sc-1brdqhf-0 cKRjba">https://www.quora.com/What-is-the-role-of-the-activation-function-in-a-neural-network</a></li></ul><h2 id="concatenated-relu-crelu" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#concatenated-relu-crelu" color="auto.gray.8" aria-label="Concatenated ReLU (CRelu) permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Concatenated ReLU (CRelu)</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICML 2016</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1603.05201" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1603.05201</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Implement CReLU (Concatenated ReLU)</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/pfnet/chainer/pull/1142" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/pfnet/chainer/pull/1142</a></li></ul><h2 id="gelu" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#gelu" color="auto.gray.8" aria-label="GELU permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>GELU</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1606.08415" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1606.08415</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Formulating The ReLU</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://www.jefkine.com/general/2016/08/24/formulating-the-relu/" class="Link-sc-1brdqhf-0 cKRjba">http://www.jefkine.com/general/2016/08/24/formulating-the-relu/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Activation Ensembles for Deep Neural Networks</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1702.07790" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1702.07790</a></p><h2 id="selu" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#selu" color="auto.gray.8" aria-label="SELU permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>SELU</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Self-Normalizing Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: SELU</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1706.02515" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1706.02515</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/bioinf-jku/SNNs" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/bioinf-jku/SNNs</a></li><li>notes: <a target="_blank" rel="noopener noreferrer" href="https://github.com/kevinzakka/research-paper-notes/blob/master/snn.md" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/kevinzakka/research-paper-notes/blob/master/snn.md</a></li><li>github(Chainer): <a target="_blank" rel="noopener noreferrer" href="https://github.com/musyoku/self-normalizing-networks" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/musyoku/self-normalizing-networks</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>SELUs (scaled exponential linear units) - Visualized and Histogramed Comparisons among ReLU and Leaky ReLU</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://github.com/shaohua0116/Activation-Visualization-Histogram" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/shaohua0116/Activation-Visualization-Histogram</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Difference Between Softmax Function and Sigmoid Function</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://dataaspirant.com/2017/03/07/difference-between-softmax-function-and-sigmoid-function/" class="Link-sc-1brdqhf-0 cKRjba">http://dataaspirant.com/2017/03/07/difference-between-softmax-function-and-sigmoid-function/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Flexible Rectified Linear Units for Improving Convolutional Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>keywords: flexible rectified linear unit (FReLU)</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1706.08098" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1706.08098</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Be Careful What You Backpropagate: A Case For Linear Output Activations &amp; Gradient Boosting</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: CMU</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1707.04199" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1707.04199</a></li></ul><h2 id="eraserelu" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#eraserelu" color="auto.gray.8" aria-label="EraseReLU permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>EraseReLU</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>EraseReLU: A Simple Way to Ease the Training of Deep Convolution Neural Networks</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1709.07634" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1709.07634</a></p><h2 id="swish" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#swish" color="auto.gray.8" aria-label="Swish permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Swish</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Swish: a Self-Gated Activation Function</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Searching for Activation Functions</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Google Brain</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1710.05941" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1710.05941</a></li><li>reddit: <a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/MachineLearning/comments/77gcrv/d_swish_is_not_performing_very_well/" class="Link-sc-1brdqhf-0 cKRjba">https://www.reddit.com/r/MachineLearning/comments/77gcrv/d_swish_is_not_performing_very_well/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Learning with Data Dependent Implicit Activation Function</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1802.00168" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1802.00168</a></p><h2 id="series-on-initialization-of-weights-for-dnn" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#series-on-initialization-of-weights-for-dnn" color="auto.gray.8" aria-label="Series on Initialization of Weights for DNN permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Series on Initialization of Weights for DNN</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Initialization Of Feedfoward Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://www.jefkine.com/deep/2016/07/27/initialization-of-feedfoward-networks/" class="Link-sc-1brdqhf-0 cKRjba">http://www.jefkine.com/deep/2016/07/27/initialization-of-feedfoward-networks/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Initialization Of Deep Feedfoward Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://www.jefkine.com/deep/2016/08/01/initialization-of-deep-feedfoward-networks/" class="Link-sc-1brdqhf-0 cKRjba">http://www.jefkine.com/deep/2016/08/01/initialization-of-deep-feedfoward-networks/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Initialization Of Deep Networks Case of Rectifiers</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://www.jefkine.com/deep/2016/08/08/initialization-of-deep-networks-case-of-rectifiers/" class="Link-sc-1brdqhf-0 cKRjba">http://www.jefkine.com/deep/2016/08/08/initialization-of-deep-networks-case-of-rectifiers/</a></li></ul><h1 id="weights-initialization" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#weights-initialization" color="auto.gray.8" aria-label="Weights Initialization permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Weights Initialization</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>An Explanation of Xavier Initialization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization" class="Link-sc-1brdqhf-0 cKRjba">http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Random Walk Initialization for Training Very Deep Feedforward Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1412.6558" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1412.6558</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Neural Networks with Random Gaussian Weights: A Universal Classification Strategy?</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1504.08291" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1504.08291</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>All you need is a good init</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICLR 2016</li><li>intro: Layer-sequential unit-variance (LSUV) initialization</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1511.06422" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1511.06422</a></li><li>github(Caffe): <a target="_blank" rel="noopener noreferrer" href="https://github.com/ducha-aiki/LSUVinit" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/ducha-aiki/LSUVinit</a></li><li>github(Torch): <a target="_blank" rel="noopener noreferrer" href="https://github.com/yobibyte/torch-lsuv" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/yobibyte/torch-lsuv</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/yobibyte/yobiblog/blob/master/posts/all-you-need-is-a-good-init.md" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/yobibyte/yobiblog/blob/master/posts/all-you-need-is-a-good-init.md</a></li><li>github(Keras): <a target="_blank" rel="noopener noreferrer" href="https://github.com/ducha-aiki/LSUV-keras" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/ducha-aiki/LSUV-keras</a></li><li>review: <a target="_blank" rel="noopener noreferrer" href="http://www.erogol.com/need-good-init/" class="Link-sc-1brdqhf-0 cKRjba">http://www.erogol.com/need-good-init/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>All You Need is Beyond a Good Init: Exploring Better Solution for Training Extremely Deep Convolutional Neural Networks with Orthonormality and Modulation</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: CVPR 2017. HIKVision</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1703.01827" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1703.01827</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Data-dependent Initializations of Convolutional Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1511.06856" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1511.06856</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/philkr/magic_init" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/philkr/magic_init</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>What are good initial weights in a neural network?</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>stackexchange: <a target="_blank" rel="noopener noreferrer" href="http://stats.stackexchange.com/questions/47590/what-are-good-initial-weights-in-a-neural-network" class="Link-sc-1brdqhf-0 cKRjba">http://stats.stackexchange.com/questions/47590/what-are-good-initial-weights-in-a-neural-network</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>RandomOut: Using a convolutional gradient norm to win The Filter Lottery</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1602.05931" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1602.05931</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Categorical Reparameterization with Gumbel-Softmax</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Google Brain &amp; University of Cambridge &amp; Stanford University</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1611.01144" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1611.01144</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/ericjang/gumbel-softmax" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/ericjang/gumbel-softmax</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>On weight initialization in deep neural networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1704.08863" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1704.08863</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/sidkk86/weight_initialization" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/sidkk86/weight_initialization</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10,000-Layer Vanilla Convolutional Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICML 2018. Google Brain</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1806.05393" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1806.05393</a></li></ul><h2 id="batch-normalization" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#batch-normalization" color="auto.gray.8" aria-label="Batch Normalization permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Batch Normalization</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ImageNet top-5 error: 4.82%</li><li>keywords: internal covariate shift problem</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1502.03167" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1502.03167</a></li><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://standardfrancis.wordpress.com/2015/04/16/batch-normalization/" class="Link-sc-1brdqhf-0 cKRjba">https://standardfrancis.wordpress.com/2015/04/16/batch-normalization/</a></li><li>notes: <a target="_blank" rel="noopener noreferrer" href="http://blog.csdn.net/happynear/article/details/44238541" class="Link-sc-1brdqhf-0 cKRjba">http://blog.csdn.net/happynear/article/details/44238541</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1602.07868" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1602.07868</a></li><li>github(Lasagne): <a target="_blank" rel="noopener noreferrer" href="https://github.com/TimSalimans/weight_norm" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/TimSalimans/weight_norm</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/openai/weightnorm" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/openai/weightnorm</a></li><li>notes: <a target="_blank" rel="noopener noreferrer" href="http://www.erogol.com/my-notes-weight-normalization/" class="Link-sc-1brdqhf-0 cKRjba">http://www.erogol.com/my-notes-weight-normalization/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Normalization Propagation: A Parametric Technique for Removing Internal Covariate Shift in Deep Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1603.01431" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1603.01431</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Revisiting Batch Normalization For Practical Domain Adaptation</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Peking University &amp; TuSimple &amp; SenseTime</li><li>intro: Pattern Recognition</li><li>keywords: Adaptive Batch Normalization (AdaBN)</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1603.04779" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1603.04779</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Implementing Batch Normalization in Tensorflow</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://r2rt.com/implementing-batch-normalization-in-tensorflow.html" class="Link-sc-1brdqhf-0 cKRjba">http://r2rt.com/implementing-batch-normalization-in-tensorflow.html</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deriving the Gradient for the Backward Pass of Batch Normalization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://kevinzakka.github.io/2016/09/14/batch_normalization/" class="Link-sc-1brdqhf-0 cKRjba">https://kevinzakka.github.io/2016/09/14/batch_normalization/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Exploring Normalization in Deep Residual Networks with Concatenated Rectified Linear Units</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Oculus VR &amp; Facebook &amp; NEC Labs America</li><li>paper: <a target="_blank" rel="noopener noreferrer" href="https://research.fb.com/publications/exploring-normalization-in-deep-residual-networks-with-concatenated-rectified-linear-units/" class="Link-sc-1brdqhf-0 cKRjba">https://research.fb.com/publications/exploring-normalization-in-deep-residual-networks-with-concatenated-rectified-linear-units/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Sergey Ioffe, Google</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1702.03275" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1702.03275</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Comparison of Batch Normalization and Weight Normalization Algorithms for the Large-scale Image Classification</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1709.08145" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1709.08145</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>In-Place Activated BatchNorm for Memory-Optimized Training of DNNs</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Mapillary Research</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.02616" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.02616</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/mapillary/inplace_abn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/mapillary/inplace_abn</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Batch Kalman Normalization: Towards Training Deep Neural Networks with Micro-Batches</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1802.03133" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1802.03133</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Decorrelated Batch Normalization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: CVPR 2018</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1804.08450" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1804.08450</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/umich-vl/DecorrelatedBN" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/umich-vl/DecorrelatedBN</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Understanding Batch Normalization</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1806.02375" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1806.02375</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Implementing Synchronized Multi-GPU Batch Normalization</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://hangzh.com/PyTorch-Encoding/notes/syncbn.html" class="Link-sc-1brdqhf-0 cKRjba">http://hangzh.com/PyTorch-Encoding/notes/syncbn.html</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Restructuring Batch Normalization to Accelerate CNN Training</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1807.01702" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1807.01702</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Intro to optimization in deep learning: Busting the myth about batch normalization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://blog.paperspace.com/busting-the-myths-about-batch-normalization/" class="Link-sc-1brdqhf-0 cKRjba">https://blog.paperspace.com/busting-the-myths-about-batch-normalization/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Understanding Regularization in Batch Normalization</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1809.00846" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1809.00846</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>How Does Batch Normalization Help Optimization?</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: NeurIPS 2018. MIT</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1805.11604" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1805.11604</a></li><li>video: <a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=ZOabsYbmBRM" class="Link-sc-1brdqhf-0 cKRjba">https://www.youtube.com/watch?v=ZOabsYbmBRM</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Cross-Iteration Batch Normalization</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2002.05712" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/2002.05712</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Extended Batch Normalization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Chinese Academy of Sciences</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2003.05569" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/2003.05569</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Towards Stabilizing Batch Statistics in Backward Propagation of Batch Normalization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICLR 2020 Poster</li><li>keywords: Moving Average Batch Normalization</li><li>openreview: <a target="_blank" rel="noopener noreferrer" href="https://openreview.net/forum?id=SkgGjRVKDS" class="Link-sc-1brdqhf-0 cKRjba">https://openreview.net/forum?id=SkgGjRVKDS</a></li><li>github(official, Pytorch): <a target="_blank" rel="noopener noreferrer" href="https://github.com/megvii-model/MABN" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/megvii-model/MABN</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Rethinking “Batch” in BatchNorm</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Facebook AI Research</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2105.07576" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/2105.07576</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Delving into the Estimation Shift of Batch Normalization in a Network</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: CVPR 2022</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2203.10778" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/2203.10778</a></li><li>gtihub: <a target="_blank" rel="noopener noreferrer" href="https://github.com/huangleiBuaa/XBNBlock" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/huangleiBuaa/XBNBlock</a></li></ul><h3 id="backward-pass-of-bn" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH3-sc-1fu06k9-3 ffNRvO gCPbFb cxpRJj Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#backward-pass-of-bn" color="auto.gray.8" aria-label="Backward pass of BN permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Backward pass of BN</h3><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Understanding the backward pass through Batch Normalization Layer</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html" class="Link-sc-1brdqhf-0 cKRjba">https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deriving the Gradient for the Backward Pass of Batch Normalization</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://kevinzakka.github.io/2016/09/14/batch_normalization/" class="Link-sc-1brdqhf-0 cKRjba">https://kevinzakka.github.io/2016/09/14/batch_normalization/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>What does the gradient flowing through batch normalization looks like ?</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://cthorey.github.io./backpropagation/" class="Link-sc-1brdqhf-0 cKRjba">http://cthorey.github.io./backpropagation/</a></p><h2 id="layer-normalization" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#layer-normalization" color="auto.gray.8" aria-label="Layer Normalization permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Layer Normalization</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Layer Normalization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1607.06450" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1607.06450</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/ryankiros/layer-norm" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/ryankiros/layer-norm</a></li><li>github(TensorFlow): <a target="_blank" rel="noopener noreferrer" href="https://github.com/pbhatia243/tf-layer-norm" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/pbhatia243/tf-layer-norm</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/MycChiu/fast-LayerNorm-TF" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/MycChiu/fast-LayerNorm-TF</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Keras GRU with Layer Normalization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>gist: <a target="_blank" rel="noopener noreferrer" href="https://gist.github.com/udibr/7f46e790c9e342d75dcbd9b1deb9d940" class="Link-sc-1brdqhf-0 cKRjba">https://gist.github.com/udibr/7f46e790c9e342d75dcbd9b1deb9d940</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Cosine Normalization: Using Cosine Similarity Instead of Dot Product in Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1702.05870" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1702.05870</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Differentiable Learning-to-Normalize via Switchable Normalization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1806.10779" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1806.10779</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/switchablenorms/Switchable-Normalization" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/switchablenorms/Switchable-Normalization</a></li></ul><h2 id="group-normalization" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#group-normalization" color="auto.gray.8" aria-label="Group Normalization permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Group Normalization</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Group Normalization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ECCV 2018 Best Paper Award Honorable Mention</li><li>intro: Facebook AI Research (FAIR)</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1803.08494" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1803.08494</a></li></ul><h2 id="batch-instance-normalization" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#batch-instance-normalization" color="auto.gray.8" aria-label="Batch-Instance Normalization permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Batch-Instance Normalization</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Batch-Instance Normalization for Adaptively Style-Invariant Neural Networks</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1805.07925" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1805.07925</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Two at Once: Enhancing Learning and Generalization Capacities via IBN-Net</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ECCV 2018</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1807.09441" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1807.09441</a></li><li>github(official, Pytorch): <a target="_blank" rel="noopener noreferrer" href="https://github.com/XingangPan/IBN-Net" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/XingangPan/IBN-Net</a></li></ul><h2 id="dynamic-normalization" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#dynamic-normalization" color="auto.gray.8" aria-label="Dynamic Normalization permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Dynamic Normalization</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Dynamic Normalization</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2101.06073" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/2101.06073</a></p><h1 id="loss-function" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#loss-function" color="auto.gray.8" aria-label="Loss Function permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Loss Function</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>The Loss Surfaces of Multilayer Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1412.0233" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1412.0233</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Direct Loss Minimization for Training Deep Neural Nets</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1511.06411" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1511.06411</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Nonconvex Loss Functions for Classifiers and Deep Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://casmls.github.io/general/2016/10/27/NonconvexLosses.html" class="Link-sc-1brdqhf-0 cKRjba">https://casmls.github.io/general/2016/10/27/NonconvexLosses.html</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Learning Deep Embeddings with Histogram Loss</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1611.00822" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1611.00822</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Large-Margin Softmax Loss for Convolutional Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICML 2016</li><li>intro: Peking University &amp; South China University of Technology &amp; CMU &amp; Shenzhen University</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1612.02295" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1612.02295</a></li><li>github(Official. Caffe): <a target="_blank" rel="noopener noreferrer" href="https://github.com/wy1iu/LargeMargin_Softmax_Loss" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/wy1iu/LargeMargin_Softmax_Loss</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/luoyetx/mx-lsoftmax" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/luoyetx/mx-lsoftmax</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/tpys/face-recognition-caffe2" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/tpys/face-recognition-caffe2</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/jihunchoi/lsoftmax-pytorch" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/jihunchoi/lsoftmax-pytorch</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>An empirical analysis of the optimization of deep network loss surfaces</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1612.04010" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1612.04010</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Towards Understanding Generalization of Deep Learning: Perspective of Loss Landscapes</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Peking University</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1706.10239" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1706.10239</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Hierarchical Softmax</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://building-babylon.net/2017/08/01/hierarchical-softmax/" class="Link-sc-1brdqhf-0 cKRjba">http://building-babylon.net/2017/08/01/hierarchical-softmax/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Noisy Softmax: Improving the Generalization Ability of DCNN via Postponing the Early Softmax Saturation</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: CVPR 2017</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1708.03769" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1708.03769</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DropMax: Adaptive Stochastic Softmax</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: UNIST &amp; Postech &amp; KAIST</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.07834" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.07834</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Rethinking Feature Distribution for Loss Functions in Image Classification</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: CVPR 2018 spotlight</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1803.02988" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1803.02988</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Ensemble Soft-Margin Softmax Loss for Image Classification</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: IJCAI 2018</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1805.03922" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1805.03922</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Cornell University</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1805.07836" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1805.07836</a></li></ul><h1 id="learning-rates" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#learning-rates" color="auto.gray.8" aria-label="Learning Rates permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Learning Rates</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>No More Pesky Learning Rates</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Tom Schaul, Sixin Zhang, Yann LeCun</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1206.1106" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1206.1106</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Coupling Adaptive Batch Sizes with Learning Rates</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Max Planck Institute for Intelligent Systems</li><li>intro: Tensorflow implementation of SGD with Coupled Adaptive Batch Size (CABS)</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1612.05086" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1612.05086</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/ProbabilisticNumerics/cabs" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/ProbabilisticNumerics/cabs</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Super-Convergence: Very Fast Training of Residual Networks Using Large Learning Rates</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1708.07120" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1708.07120</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Improving the way we work with learning rate.</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://medium.com/@bushaev/improving-the-way-we-work-with-learning-rate-5e99554f163b" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@bushaev/improving-the-way-we-work-with-learning-rate-5e99554f163b</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>WNGrad: Learn the Learning Rate in Gradient Descent</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: University of Texas at Austin &amp; Facebook AI Research</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1803.02865" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1803.02865</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Learning with Random Learning Rates</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Facebook AI Research &amp; Universite Paris Sud</li><li>keywords: All Learning Rates At Once (Alrao)</li><li>project page: <a target="_blank" rel="noopener noreferrer" href="https://leonardblier.github.io/alrao/" class="Link-sc-1brdqhf-0 cKRjba">https://leonardblier.github.io/alrao/</a></li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1810.01322" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1810.01322</a></li><li>github(PyTorch, official): <a target="_blank" rel="noopener noreferrer" href="https://github.com/leonardblier/alrao" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/leonardblier/alrao</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Learning Rate Dropout</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: 1Xiamen University &amp; Columbia University</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1912.00144" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1912.00144</a></li></ul><h1 id="convolution-filters" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#convolution-filters" color="auto.gray.8" aria-label="Convolution Filters permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Convolution Filters</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Non-linear Convolution Filters for CNN-based Learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICCV 2017</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1708.07038" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1708.07038</a></li></ul><h1 id="pooling" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#pooling" color="auto.gray.8" aria-label="Pooling permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Pooling</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Stochastic Pooling for Regularization of Deep Convolutional Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICLR 2013. Matthew D. Zeiler, Rob Fergus</li><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://www.matthewzeiler.com/pubs/iclr2013/iclr2013.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://www.matthewzeiler.com/pubs/iclr2013/iclr2013.pdf</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Multi-scale Orderless Pooling of Deep Convolutional Activation Features</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ECCV 2014</li><li>intro: MOP-CNN, orderless VLAD pooling, image classification / instance-level retrieval</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1403.1840" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1403.1840</a></li><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://web.engr.illinois.edu/~slazebni/publications/yunchao_eccv14_mopcnn.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://web.engr.illinois.edu/~slazebni/publications/yunchao_eccv14_mopcnn.pdf</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Fractional Max-Pooling</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1412.6071" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1412.6071</a></li><li>notes: <a target="_blank" rel="noopener noreferrer" href="https://gist.github.com/shagunsodhani/ccfe3134f46fd3738aa0" class="Link-sc-1brdqhf-0 cKRjba">https://gist.github.com/shagunsodhani/ccfe3134f46fd3738aa0</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/torch/nn/issues/371" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/torch/nn/issues/371</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>TI-POOLING: transformation-invariant pooling for feature learning in Convolutional Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: CVPR 2016</li><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://dlaptev.org/papers/Laptev16_CVPR.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://dlaptev.org/papers/Laptev16_CVPR.pdf</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/dlaptev/TI-pooling" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/dlaptev/TI-pooling</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>S3Pool: Pooling with Stochastic Spatial Sampling</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1611.05138" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1611.05138</a></li><li>github(Lasagne): <a target="_blank" rel="noopener noreferrer" href="https://github.com/Shuangfei/s3pool" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Shuangfei/s3pool</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Inductive Bias of Deep Convolutional Networks through Pooling Geometry</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1605.06743" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1605.06743</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/HUJI-Deep/inductive-pooling" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/HUJI-Deep/inductive-pooling</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Improved Bilinear Pooling with CNNs</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1707.06772" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1707.06772</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl">**Learning Bag-of-Features Pooling for Deep Convolutional Neural Networks</p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICCV 2017</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1707.08105" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1707.08105</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/passalis/cbof" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/passalis/cbof</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A new kind of pooling layer for faster and sharper convergence</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://medium.com/@singlasahil14/a-new-kind-of-pooling-layer-for-faster-and-sharper-convergence-1043c756a221" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@singlasahil14/a-new-kind-of-pooling-layer-for-faster-and-sharper-convergence-1043c756a221</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/singlasahil14/sortpool2d" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/singlasahil14/sortpool2d</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Statistically Motivated Second Order Pooling</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1801.07492" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1801.07492</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Detail-Preserving Pooling in Deep Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: CVPR 2018</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1804.04076" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1804.04076</a></li></ul><h1 id="mini-batch" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#mini-batch" color="auto.gray.8" aria-label="Mini-Batch permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Mini-Batch</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Online Batch Selection for Faster Training of Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Workshop paper at ICLR 2016</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1511.06343" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1511.06343</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICLR 2017</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1609.04836" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1609.04836</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Facebook</li><li>keywords: Training with 256 GPUs, minibatches of 8192</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1706.02677" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1706.02677</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Scaling SGD Batch Size to 32K for ImageNet Training</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Large Batch Training of Convolutional Networks</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1708.03888" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1708.03888</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>ImageNet Training in 24 Minutes</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1709.05011" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1709.05011</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Don&#x27;t Decay the Learning Rate, Increase the Batch Size</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Google Brain</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1711.00489" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1711.00489</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Extremely Large Minibatch SGD: Training ResNet-50 on ImageNet in 15 Minutes</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: NIPS 2017 Workshop: Deep Learning at Supercomputer Scale</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1711.04325" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1711.04325</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>AdaBatch: Adaptive Batch Sizes for Training Deep Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: UC Berkeley &amp; NVIDIA</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.02029" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.02029</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Hessian-based Analysis of Large Batch Training and Robustness to Adversaries</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: UC Berkeley &amp; University of Texas</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1802.08241" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1802.08241</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Large Batch Training of Convolutional Networks with Layer-wise Adaptive Rate Scaling</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>keywords: large batch, LARS, adaptive rate scaling</li><li>openreview: <a target="_blank" rel="noopener noreferrer" href="https://openreview.net/forum?id=rJ4uaX2aW" class="Link-sc-1brdqhf-0 cKRjba">https://openreview.net/forum?id=rJ4uaX2aW</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Revisiting Small Batch Training for Deep Neural Networks</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1804.07612" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1804.07612</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Second-order Optimization Method for Large Mini-batch: Training ResNet-50 on ImageNet in 35 Epochs</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1811.12019" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1811.12019</a></p><h1 id="optimization-methods" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#optimization-methods" color="auto.gray.8" aria-label="Optimization Methods permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Optimization Methods</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>On Optimization Methods for Deep Learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://www.icml-2011.org/papers/210_icmlpaper.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://www.icml-2011.org/papers/210_icmlpaper.pdf</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Invariant backpropagation: how to train a transformation-invariant neural network</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1502.04434" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1502.04434</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/sdemyanov/ConvNet" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/sdemyanov/ConvNet</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A practical theory for designing very deep convolutional neural network</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>kaggle: <a target="_blank" rel="noopener noreferrer" href="https://www.kaggle.com/c/datasciencebowl/forums/t/13166/happy-lantern-festival-report-and-code/69284" class="Link-sc-1brdqhf-0 cKRjba">https://www.kaggle.com/c/datasciencebowl/forums/t/13166/happy-lantern-festival-report-and-code/69284</a></li><li>paper: <a target="_blank" rel="noopener noreferrer" href="https://kaggle2.blob.core.windows.net/forum-message-attachments/69182/2287/A%20practical%20theory%20for%20designing%20very%20deep%20convolutional%20neural%20networks.pdf?sv=2012-02-12&amp;se=2015-12-05T15%3A40%3A02Z&amp;sr=b&amp;sp=r&amp;sig=kfBQKduA1pDtu837Y9Iqyrp2VYItTV0HCgOeOok9E3E%3D" class="Link-sc-1brdqhf-0 cKRjba">https://kaggle2.blob.core.windows.net/forum-message-attachments/69182/2287/A%20practical%20theory%20for%20designing%20very%20deep%20convolutional%20neural%20networks.pdf?sv=2012-02-12&amp;se=2015-12-05T15%3A40%3A02Z&amp;sr=b&amp;sp=r&amp;sig=kfBQKduA1pDtu837Y9Iqyrp2VYItTV0HCgOeOok9E3E%3D</a></li><li>slides: <a target="_blank" rel="noopener noreferrer" href="http://vdisk.weibo.com/s/3nFsznjLKn" class="Link-sc-1brdqhf-0 cKRjba">http://vdisk.weibo.com/s/3nFsznjLKn</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Stochastic Optimization Techniques</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: SGD/Momentum/NAG/Adagrad/RMSProp/Adadelta/Adam/ESGD/Adasecant/vSGD/Rprop</li><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://colinraffel.com/wiki/stochastic_optimization_techniques" class="Link-sc-1brdqhf-0 cKRjba">http://colinraffel.com/wiki/stochastic_optimization_techniques</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Alec Radford&#x27;s animations for optimization algorithms</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://www.denizyuret.com/2015/03/alec-radfords-animations-for.html" class="Link-sc-1brdqhf-0 cKRjba">http://www.denizyuret.com/2015/03/alec-radfords-animations-for.html</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Faster Asynchronous SGD (FASGD)</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1601.04033" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1601.04033</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/DoctorTeeth/fred" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/DoctorTeeth/fred</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>An overview of gradient descent optimization algorithms (★★★★★)</strong></p><img src="http://sebastianruder.com/content/images/2016/01/contours_evaluation_optimizers.gif" class="image__Image-sc-1r30dtv-0 elBfYx"/><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1609.04747" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1609.04747</a></li><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://sebastianruder.com/optimizing-gradient-descent/" class="Link-sc-1brdqhf-0 cKRjba">http://sebastianruder.com/optimizing-gradient-descent/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Exploiting the Structure: Stochastic Gradient Methods Using Raw Clusters</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1602.02151" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1602.02151</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Writing fast asynchronous SGD/AdaGrad with RcppParallel</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://gallery.rcpp.org/articles/rcpp-sgd/" class="Link-sc-1brdqhf-0 cKRjba">http://gallery.rcpp.org/articles/rcpp-sgd/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Quick Explanations Of Optimization Methods</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://jxieeducation.com/2016-07-02/Quick-Explanations-of-Optimization-Methods/" class="Link-sc-1brdqhf-0 cKRjba">http://jxieeducation.com/2016-07-02/Quick-Explanations-of-Optimization-Methods/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Learning to learn by gradient descent by gradient descent</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Google DeepMind</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1606.04474" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1606.04474</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/deepmind/learning-to-learn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/deepmind/learning-to-learn</a></li><li>github(TensorFlow): <a target="_blank" rel="noopener noreferrer" href="https://github.com/runopti/Learning-To-Learn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/runopti/Learning-To-Learn</a></li><li>github(PyTorch): <a target="_blank" rel="noopener noreferrer" href="https://github.com/ikostrikov/pytorch-meta-optimizer" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/ikostrikov/pytorch-meta-optimizer</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>SGDR: Stochastic Gradient Descent with Restarts</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICLR 2017</li><li>keywords: cosine annealing strategy</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1608.03983" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1608.03983</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/loshchil/SGDR" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/loshchil/SGDR</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>The zen of gradient descent</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://blog.mrtz.org/2013/09/07/the-zen-of-gradient-descent.html" class="Link-sc-1brdqhf-0 cKRjba">http://blog.mrtz.org/2013/09/07/the-zen-of-gradient-descent.html</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Big Batch SGD: Automated Inference using Adaptive Batch Sizes</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1610.05792" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1610.05792</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Improving Stochastic Gradient Descent with Feedback</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1611.01505" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1611.01505</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/jayanthkoushik/sgd-feedback" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/jayanthkoushik/sgd-feedback</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/Eve" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/Eve</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Learning Gradient Descent: Better Generalization and Longer Horizons</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Tsinghua University</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1703.03633" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1703.03633</a></li><li>github(TensorFlow): <a target="_blank" rel="noopener noreferrer" href="https://github.com/vfleaking/rnnprop" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/vfleaking/rnnprop</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Optimization Algorithms</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://3dbabove.com/2017/11/14/optimizationalgorithms/" class="Link-sc-1brdqhf-0 cKRjba">https://3dbabove.com/2017/11/14/optimizationalgorithms/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com//ManuelGonzalezRivero/3dbabove" class="Link-sc-1brdqhf-0 cKRjba">https://github.com//ManuelGonzalezRivero/3dbabove</a></li><li>reddit: <a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/MachineLearning/comments/7ehxky/d_optimization_algorithms_math_and_code/" class="Link-sc-1brdqhf-0 cKRjba">https://www.reddit.com/r/MachineLearning/comments/7ehxky/d_optimization_algorithms_math_and_code/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Gradient Normalization &amp; Depth Based Decay For Deep Learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Columbia University</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.03607" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.03607</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Neumann Optimizer: A Practical Optimization Algorithm for Deep Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Google Research</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.03298" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.03298</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Optimization for Deep Learning Highlights in 2017</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://ruder.io/deep-learning-optimization-2017/index.html" class="Link-sc-1brdqhf-0 cKRjba">http://ruder.io/deep-learning-optimization-2017/index.html</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Gradients explode - Deep Networks are shallow - ResNet explained</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: CMU &amp; UC Berkeley</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.05577" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.05577</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A Sufficient Condition for Convergences of Adam and RMSProp</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1811.09358" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1811.09358</a></p><h2 id="adam" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#adam" color="auto.gray.8" aria-label="Adam permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Adam</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Adam: A Method for Stochastic Optimization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICLR 2015</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1412.6980" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1412.6980</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Fixing Weight Decay Regularization in Adam</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: University of Freiburg</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1711.05101" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1711.05101</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/loshchil/AdamW-and-SGDW" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/loshchil/AdamW-and-SGDW</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/fastai/fastai/pull/46/files" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/fastai/fastai/pull/46/files</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>On the Convergence of Adam and Beyond</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICLR 2018 best paper award. CMU &amp; IBM Research</li><li>paper: <a target="_blank" rel="noopener noreferrer" href="https://openreview.net/pdf?id=ryQu7f-RZ" class="Link-sc-1brdqhf-0 cKRjba">https://openreview.net/pdf?id=ryQu7f-RZ</a></li><li>openreview: <a target="_blank" rel="noopener noreferrer" href="https://openreview.net/forum?id=ryQu7f-RZ" class="Link-sc-1brdqhf-0 cKRjba">https://openreview.net/forum?id=ryQu7f-RZ</a></li></ul><h1 id="tensor-methods" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#tensor-methods" color="auto.gray.8" aria-label="Tensor Methods permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Tensor Methods</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Tensorizing Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: TensorNet</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1509.06569" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1509.06569</a></li><li>github(Matlab+Theano+Lasagne): <a target="_blank" rel="noopener noreferrer" href="https://github.com/Bihaqo/TensorNet" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Bihaqo/TensorNet</a></li><li>github(TensorFlow): <a target="_blank" rel="noopener noreferrer" href="https://github.com/timgaripov/TensorNet-TF" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/timgaripov/TensorNet-TF</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Tensor methods for training neural networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://newport.eecs.uci.edu/anandkumar/#home" class="Link-sc-1brdqhf-0 cKRjba">http://newport.eecs.uci.edu/anandkumar/#home</a></li><li>youtube: <a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=B4YvhcGaafw" class="Link-sc-1brdqhf-0 cKRjba">https://www.youtube.com/watch?v=B4YvhcGaafw</a></li><li>slides: <a target="_blank" rel="noopener noreferrer" href="http://newport.eecs.uci.edu/anandkumar/slides/Strata-NY.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://newport.eecs.uci.edu/anandkumar/slides/Strata-NY.pdf</a></li><li>talks: <a target="_blank" rel="noopener noreferrer" href="http://newport.eecs.uci.edu/anandkumar/#talks" class="Link-sc-1brdqhf-0 cKRjba">http://newport.eecs.uci.edu/anandkumar/#talks</a></li></ul><h1 id="regularization" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#regularization" color="auto.gray.8" aria-label="Regularization permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Regularization</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DisturbLabel: Regularizing CNN on the Loss Layer</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro:  University of California &amp; MSR 2016</li><li>intro: &quot;an extremely simple algorithm which randomly replaces a part of labels as incorrect values in each iteration&quot;</li><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://research.microsoft.com/en-us/um/people/jingdw/pubs/cvpr16-disturblabel.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://research.microsoft.com/en-us/um/people/jingdw/pubs/cvpr16-disturblabel.pdf</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Robust Convolutional Neural Networks under Adversarial Noise</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro:  ICLR 2016</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1511.06306" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1511.06306</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Adding Gradient Noise Improves Learning for Very Deep Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro:  ICLR 2016</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1511.06807" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1511.06807</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Stochastic Function Norm Regularization of Deep Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1605.09085" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1605.09085</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/AmalRT/DNN_Reg" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/AmalRT/DNN_Reg</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>SoftTarget Regularization: An Effective Technique to Reduce Over-Fitting in Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1609.06693" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1609.06693</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Regularizing neural networks by penalizing confident predictions</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Gabriel Pereyra, George Tucker, Lukasz Kaiser, Geoffrey Hinton [Google Brain</li><li>dropbox: <a target="_blank" rel="noopener noreferrer" href="https://www.dropbox.com/s/8kqf4v2c9lbnvar/BayLearn%202016%20(gjt).pdf?dl=0" class="Link-sc-1brdqhf-0 cKRjba">https://www.dropbox.com/s/8kqf4v2c9lbnvar/BayLearn%202016%20(gjt).pdf?dl=0</a></li><li>mirror: <a target="_blank" rel="noopener noreferrer" href="https://pan.baidu.com/s/1kUUtxdl" class="Link-sc-1brdqhf-0 cKRjba">https://pan.baidu.com/s/1kUUtxdl</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Automatic Node Selection for Deep Neural Networks using Group Lasso Regularization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1611.05527" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1611.05527</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Regularization in deep learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://medium.com/@cristina_scheau/regularization-in-deep-learning-f649a45d6e0#.py327hkuv" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@cristina_scheau/regularization-in-deep-learning-f649a45d6e0#.py327hkuv</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/cscheau/Examples/blob/master/iris_l1_l2.py" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/cscheau/Examples/blob/master/iris_l1_l2.py</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>LDMNet: Low Dimensional Manifold Regularized Neural Networks</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1711.06246" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1711.06246</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Learning Sparse Neural Networks through L0 Regularization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: University of Amsterdam &amp; OpenAI</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.01312" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.01312</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Regularization and Optimization strategies in Deep Convolutional Neural Network</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.04711" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.04711</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Regularizing Deep Networks by Modeling and Predicting Label Structure</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: CVPR 2018</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1804.02009" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1804.02009</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Adversarial Noise Layer: Regularize Neural Network By Adding Noise</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Peking University &amp; ‡University of Electronic Science and Technology of China &amp; Australian National University</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1805.08000" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1805.08000</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/youzhonghui/ANL" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/youzhonghui/ANL</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Bilevel Learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ECCV 2018</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1809.01465" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1809.01465</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Can We Gain More from Orthogonality Regularizations in Training Deep CNNs?</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: NIPS 2018</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1810.09102" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1810.09102</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Gradient-Coherent Strong Regularization for Deep Neural Networks</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1811.08056" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1811.08056</a></p><h2 id="dropout" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#dropout" color="auto.gray.8" aria-label="Dropout permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Dropout</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Improving neural networks by preventing co-adaptation of feature detectors</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Dropout</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1207.0580" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1207.0580</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Dropout: A Simple Way to Prevent Neural Networks from Overfitting</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>paper: <a target="_blank" rel="noopener noreferrer" href="https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf" class="Link-sc-1brdqhf-0 cKRjba">https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Fast dropout training</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://jmlr.org/proceedings/papers/v28/wang13a.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://jmlr.org/proceedings/papers/v28/wang13a.pdf</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/sidaw/fastdropout" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/sidaw/fastdropout</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Dropout as data augmentation</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1506.08700" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1506.08700</a></li><li>notes: <a target="_blank" rel="noopener noreferrer" href="https://www.evernote.com/shard/s189/sh/ef0c3302-21a4-40d7-b8b4-1c65b8ebb1c9/24ff553fcfb70a27d61ff003df75b5a9" class="Link-sc-1brdqhf-0 cKRjba">https://www.evernote.com/shard/s189/sh/ef0c3302-21a4-40d7-b8b4-1c65b8ebb1c9/24ff553fcfb70a27d61ff003df75b5a9</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1512.05287" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1512.05287</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/yaringal/BayesianRNN" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/yaringal/BayesianRNN</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Improved Dropout for Shallow and Deep Learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1602.02220" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1602.02220</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Dropout Regularization in Deep Learning Models With Keras</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/" class="Link-sc-1brdqhf-0 cKRjba">http://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Dropout with Expectation-linear Regularization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1609.08017" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1609.08017</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Dropout with Theano</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://rishy.github.io/ml/2016/10/12/dropout-with-theano/" class="Link-sc-1brdqhf-0 cKRjba">http://rishy.github.io/ml/2016/10/12/dropout-with-theano/</a></li><li>ipn: <a target="_blank" rel="noopener noreferrer" href="http://nbviewer.jupyter.org/github/rishy/rishy.github.io/blob/master/ipy_notebooks/Dropout-Theano.ipynb" class="Link-sc-1brdqhf-0 cKRjba">http://nbviewer.jupyter.org/github/rishy/rishy.github.io/blob/master/ipy_notebooks/Dropout-Theano.ipynb</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Information Dropout: learning optimal representations through noise</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1611.01353" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1611.01353</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Recent Developments in Dropout</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://casmls.github.io/general/2016/11/11/dropout.html" class="Link-sc-1brdqhf-0 cKRjba">https://casmls.github.io/general/2016/11/11/dropout.html</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Generalized Dropout</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1611.06791" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1611.06791</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Analysis of Dropout</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://pgaleone.eu/deep-learning/regularization/2017/01/10/anaysis-of-dropout/" class="Link-sc-1brdqhf-0 cKRjba">https://pgaleone.eu/deep-learning/regularization/2017/01/10/anaysis-of-dropout/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Variational Dropout Sparsifies Deep Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1701.05369" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1701.05369</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Learning Deep Networks from Noisy Labels with Dropout Regularization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: 2016 IEEE 16th International Conference on Data Mining</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1705.03419" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1705.03419</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Concrete Dropout</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: University of Cambridge</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1705.07832" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1705.07832</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/yaringal/ConcreteDropout" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/yaringal/ConcreteDropout</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Analysis of dropout learning regarded as ensemble learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Nihon University</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1706.06859" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1706.06859</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>An Analysis of Dropout for Matrix Factorization</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1710.03487" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1710.03487</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Analysis of Dropout in Online Learning</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1711.03343" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1711.03343</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Regularization of Deep Neural Networks with Spectral Dropout</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1711.08591" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1711.08591</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Data Dropout in Arbitrary Basis for Deep Network Regularization</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.00891" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.00891</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A New Angle on L2 Regularization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: An explorable explanation on the phenomenon of adversarial examples in linear classification and its relation to L2 regularization</li><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://thomas-tanay.github.io/post--L2-regularization/" class="Link-sc-1brdqhf-0 cKRjba">https://thomas-tanay.github.io/post--L2-regularization/</a></li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1806.11186" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1806.11186</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Dropout is a special case of the stochastic delta rule: faster and more accurate deep learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Rutgers University</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1808.03578" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1808.03578</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/noahfl/densenet-sdr/" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/noahfl/densenet-sdr/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Data Dropout: Optimizing Training Data for Convolutional Neural Networks</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1809.00193" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1809.00193</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DropFilter: Dropout for Convolutions</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1810.09849" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1810.09849</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DropFilter: A Novel Regularization Method for Learning Convolutional Neural Networks</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1811.06783" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1811.06783</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Targeted Dropout</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Google Brain &amp; FOR.ai &amp; University of Oxford</li><li>paper: <a target="_blank" rel="noopener noreferrer" href="https://openreview.net/pdf?id=HkghWScuoQ" class="Link-sc-1brdqhf-0 cKRjba">https://openreview.net/pdf?id=HkghWScuoQ</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/for-ai/TD" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/for-ai/TD</a></li></ul><h2 id="dropconnect" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#dropconnect" color="auto.gray.8" aria-label="DropConnect permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>DropConnect</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Regularization of Neural Networks using DropConnect</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>homepage: <a target="_blank" rel="noopener noreferrer" href="http://cs.nyu.edu/~wanli/dropc/" class="Link-sc-1brdqhf-0 cKRjba">http://cs.nyu.edu/~wanli/dropc/</a></li><li>gitxiv: <a target="_blank" rel="noopener noreferrer" href="http://gitxiv.com/posts/rJucpiQiDhQ7HkZoX/regularization-of-neural-networks-using-dropconnect" class="Link-sc-1brdqhf-0 cKRjba">http://gitxiv.com/posts/rJucpiQiDhQ7HkZoX/regularization-of-neural-networks-using-dropconnect</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/iassael/torch-dropconnect" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/iassael/torch-dropconnect</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Regularizing neural networks with dropout and with DropConnect</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://fastml.com/regularizing-neural-networks-with-dropout-and-with-dropconnect/" class="Link-sc-1brdqhf-0 cKRjba">http://fastml.com/regularizing-neural-networks-with-dropout-and-with-dropconnect/</a></li></ul><h2 id="dropneuron" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#dropneuron" color="auto.gray.8" aria-label="DropNeuron permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>DropNeuron</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DropNeuron: Simplifying the Structure of Deep Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1606.07326" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1606.07326</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/panweihit/DropNeuron" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/panweihit/DropNeuron</a></li></ul><h2 id="dropblock" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#dropblock" color="auto.gray.8" aria-label="DropBlock permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>DropBlock</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DropBlock: A regularization method for convolutional networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: NIPS 2018</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1810.12890" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1810.12890</a></li></ul><h2 id="maxout" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#maxout" color="auto.gray.8" aria-label="Maxout permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Maxout</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Maxout Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICML 2013</li><li>intro: &quot;its output is the max of a set of inputs, a natural companion to dropout&quot;</li><li>project page: <a target="_blank" rel="noopener noreferrer" href="http://www-etud.iro.umontreal.ca/~goodfeli/maxout.html" class="Link-sc-1brdqhf-0 cKRjba">http://www-etud.iro.umontreal.ca/~goodfeli/maxout.html</a></li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1302.4389" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1302.4389</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/lisa-lab/pylearn2/blob/master/pylearn2/models/maxout.py" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/lisa-lab/pylearn2/blob/master/pylearn2/models/maxout.py</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Improving Deep Neural Networks with Probabilistic Maxout Units</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1312.6116" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1312.6116</a></li></ul><h2 id="swapout" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#swapout" color="auto.gray.8" aria-label="Swapout permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Swapout</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Swapout: Learning an ensemble of deep architectures</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1605.06465" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1605.06465</a></li><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://gab41.lab41.org/lab41-reading-group-swapout-learning-an-ensemble-of-deep-architectures-e67d2b822f8a#.9r2s4c58n" class="Link-sc-1brdqhf-0 cKRjba">https://gab41.lab41.org/lab41-reading-group-swapout-learning-an-ensemble-of-deep-architectures-e67d2b822f8a#.9r2s4c58n</a></li></ul><h2 id="whiteout" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#whiteout" color="auto.gray.8" aria-label="Whiteout permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Whiteout</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Whiteout: Gaussian Adaptive Regularization Noise in Deep Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: University of Notre Dame &amp; University of Science and Technology of China</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1612.01490" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1612.01490</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>ShakeDrop regularization</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1802.02375" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1802.02375</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Shakeout: A New Approach to Regularized Deep Neural Network Training</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: T-PAMI 2018</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1904.06593" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1904.06593</a></li></ul><h1 id="gradient-descent" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#gradient-descent" color="auto.gray.8" aria-label="Gradient Descent permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Gradient Descent</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>RMSProp: Divide the gradient by a running average of its recent magnitude</strong></p><img src="/assets/train-dnn/rmsprop.jpg" class="image__Image-sc-1r30dtv-0 elBfYx"/><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: it was not proposed in a paper, in fact it was just introduced in a slide in Geoffrey Hinton&#x27;s Coursera class </li><li>slides: <a target="_blank" rel="noopener noreferrer" href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Fitting a model via closed-form equations vs. Gradient Descent vs Stochastic Gradient Descent vs Mini-Batch Learning. What is the difference?(Normal Equations vs. GD vs. SGD vs. MB-GD)</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://sebastianraschka.com/faq/docs/closed-form-vs-gd.html" class="Link-sc-1brdqhf-0 cKRjba">http://sebastianraschka.com/faq/docs/closed-form-vs-gd.html</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>An Introduction to Gradient Descent in Python</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://tillbergmann.com/blog/articles/python-gradient-descent.html" class="Link-sc-1brdqhf-0 cKRjba">http://tillbergmann.com/blog/articles/python-gradient-descent.html</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Train faster, generalize better: Stability of stochastic gradient descent</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1509.01240" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1509.01240</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A Variational Analysis of Stochastic Gradient Algorithms</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1602.02666" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1602.02666</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>The vanishing gradient problem: Oh no — an obstacle to deep learning!</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://medium.com/a-year-of-artificial-intelligence/rohan-4-the-vanishing-gradient-problem-ec68f76ffb9b#.50hu5vwa8" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/a-year-of-artificial-intelligence/rohan-4-the-vanishing-gradient-problem-ec68f76ffb9b#.50hu5vwa8</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Gradient Descent For Machine Learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://machinelearningmastery.com/gradient-descent-for-machine-learning/" class="Link-sc-1brdqhf-0 cKRjba">http://machinelearningmastery.com/gradient-descent-for-machine-learning/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Revisiting Distributed Synchronous SGD</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1604.00981" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1604.00981</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Convergence rate of gradient descent</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://building-babylon.net/2016/06/23/convergence-rate-of-gradient-descent/" class="Link-sc-1brdqhf-0 cKRjba">https://building-babylon.net/2016/06/23/convergence-rate-of-gradient-descent/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A Robust Adaptive Stochastic Gradient Method for Deep Learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: IJCNN 2017 Accepted Paper, An extension of paper, &quot;ADASECANT: Robust Adaptive Secant Method for Stochastic Gradient&quot;</li><li>intro: Universite de Montreal &amp; University of Oxford</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1703.00788" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1703.00788</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Accelerating Stochastic Gradient Descent</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1704.08227" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1704.08227</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Gentle Introduction to the Adam Optimization Algorithm for Deep Learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/" class="Link-sc-1brdqhf-0 cKRjba">http://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Understanding Generalization and Stochastic Gradient Descent</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A Bayesian Perspective on Generalization and Stochastic Gradient Descent</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Google Brain</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1710.06451" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1710.06451</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Accelerated Gradient Descent Escapes Saddle Points Faster than Gradient Descent</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: UC Berkeley &amp; Microsoft Research, India</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1711.10456" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1711.10456</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Improving Generalization Performance by Switching from Adam to SGD</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.07628" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.07628</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Laplacian Smoothing Gradient Descent</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: UCLA</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1806.06317" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1806.06317</a></li></ul><h2 id="adagrad" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#adagrad" color="auto.gray.8" aria-label="AdaGrad permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>AdaGrad</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>ADADELTA: An Adaptive Learning Rate Method</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1212.5701" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1212.5701</a></li></ul><h2 id="momentum" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#momentum" color="auto.gray.8" aria-label="Momentum permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Momentum</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>On the importance of initialization and momentum in deep learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro:  NAG: Nesterov</li><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://www.cs.toronto.edu/~fritz/absps/momentum.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://www.cs.toronto.edu/~fritz/absps/momentum.pdf</a></li><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://jmlr.org/proceedings/papers/v28/sutskever13.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://jmlr.org/proceedings/papers/v28/sutskever13.pdf</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>YellowFin and the Art of Momentum Tuning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Stanford University</li><li>intro: auto-tuning momentum SGD optimizer</li><li>project page: <a target="_blank" rel="noopener noreferrer" href="http://cs.stanford.edu/~zjian/project/YellowFin/" class="Link-sc-1brdqhf-0 cKRjba">http://cs.stanford.edu/~zjian/project/YellowFin/</a></li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1706.03471" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1706.03471</a></li><li>github(TensorFlow): <a target="_blank" rel="noopener noreferrer" href="https://github.com/JianGoForIt/YellowFin" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/JianGoForIt/YellowFin</a><a target="_blank" rel="noopener noreferrer" href="https://github.com/JianGoForIt/YellowFin_Pytorch" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/JianGoForIt/YellowFin_Pytorch</a></li></ul><h1 id="backpropagation" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#backpropagation" color="auto.gray.8" aria-label="Backpropagation permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Backpropagation</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Relay Backpropagation for Effective Learning of Deep Convolutional Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ECCV 2016. first place of ILSVRC 2015 Scene Classification Challenge</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1512.05830" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1512.05830</a></li><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://www.cis.pku.edu.cn/faculty/vision/zlin/Publications/2016-ECCV-RelayBP.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://www.cis.pku.edu.cn/faculty/vision/zlin/Publications/2016-ECCV-RelayBP.pdf</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Top-down Neural Attention by Excitation Backprop</strong></p><img src="http://cs-people.bu.edu/jmzhang/images/screen%20shot%202016-08-19%20at%2035847%20pm.jpg?crc=3911895888" class="image__Image-sc-1r30dtv-0 elBfYx"/><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ECCV, 2016 (oral)</li><li>projpage: <a target="_blank" rel="noopener noreferrer" href="http://cs-people.bu.edu/jmzhang/excitationbp.html" class="Link-sc-1brdqhf-0 cKRjba">http://cs-people.bu.edu/jmzhang/excitationbp.html</a></li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1608.00507" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1608.00507</a></li><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://cs-people.bu.edu/jmzhang/EB/ExcitationBackprop.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://cs-people.bu.edu/jmzhang/EB/ExcitationBackprop.pdf</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/jimmie33/Caffe-ExcitationBP" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/jimmie33/Caffe-ExcitationBP</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Towards a Biologically Plausible Backprop</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1602.05179" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1602.05179</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/bscellier/Towards-a-Biologically-Plausible-Backprop" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/bscellier/Towards-a-Biologically-Plausible-Backprop</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Sampled Backpropagation: Training Deep and Wide Neural Networks on Large Scale, User Generated Content Using Label Sampling</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://medium.com/@karl1980.lab41/sampled-backpropagation-27ac58d5c51c#.xnbhyxtou" class="Link-sc-1brdqhf-0 cKRjba">https://medium.com/@karl1980.lab41/sampled-backpropagation-27ac58d5c51c#.xnbhyxtou</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>The Reversible Residual Network: Backpropagation Without Storing Activations</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: CoRR 2017. University of Toronto</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1707.04585" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1707.04585</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/renmengye/revnet-public" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/renmengye/revnet-public</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>meProp: Sparsified Back Propagation for Accelerated Deep Learning with Reduced Overfitting</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICML 2017</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1706.06197" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1706.06197</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com//jklj077/meProp" class="Link-sc-1brdqhf-0 cKRjba">https://github.com//jklj077/meProp</a></li></ul><h1 id="accelerate-training" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#accelerate-training" color="auto.gray.8" aria-label="Accelerate Training permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Accelerate Training</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Neural Networks with Few Multiplications</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro:  ICLR 2016</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1510.03009" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1510.03009</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Acceleration of Deep Neural Network Training with Resistive Cross-Point Devices</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1603.07341" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1603.07341</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Q-Networks for Accelerating the Training of Deep Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1606.01467" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1606.01467</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/bigaidream-projects/qan" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/bigaidream-projects/qan</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Omnivore: An Optimizer for Multi-device Deep Learning on CPUs and GPUs</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1606.04487" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1606.04487</a></li></ul><h2 id="parallelism" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#parallelism" color="auto.gray.8" aria-label="Parallelism permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Parallelism</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>One weird trick for parallelizing convolutional neural networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>author: Alex Krizhevsky</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1404.5997" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1404.5997</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>8-Bit Approximations for Parallelism in Deep Learning (ICLR 2016)</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1511.04561" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1511.04561</a></li></ul><h1 id="handling-datasets" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#handling-datasets" color="auto.gray.8" aria-label="Handling Datasets permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Handling Datasets</h1><h2 id="data-augmentation" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#data-augmentation" color="auto.gray.8" aria-label="Data Augmentation permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Data Augmentation</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DataAugmentation ver1.0: Image data augmentation tool for training of image recognition algorithm</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/takmin/DataAugmentation" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/takmin/DataAugmentation</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Caffe-Data-Augmentation: a branc caffe with feature of Data Augmentation using a configurable stochastic combination of 7 data augmentation techniques</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/ShaharKatz/Caffe-Data-Augmentation" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/ShaharKatz/Caffe-Data-Augmentation</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Image Augmentation for Deep Learning With Keras</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://machinelearningmastery.com/image-augmentation-deep-learning-keras/" class="Link-sc-1brdqhf-0 cKRjba">http://machinelearningmastery.com/image-augmentation-deep-learning-keras/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>What you need to know about data augmentation for machine learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: keras Imagegenerator</li><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://cartesianfaith.com/2016/10/06/what-you-need-to-know-about-data-augmentation-for-machine-learning/" class="Link-sc-1brdqhf-0 cKRjba">https://cartesianfaith.com/2016/10/06/what-you-need-to-know-about-data-augmentation-for-machine-learning/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>HZPROC: torch data augmentation toolbox (supports affine transform)</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhanghang1989/hzproc" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/zhanghang1989/hzproc</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>AGA: Attribute Guided Augmentation</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: one-shot recognition</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1612.02559" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1612.02559</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Accelerating Deep Learning with Multiprocess Image Augmentation in Keras</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://blog.stratospark.com/multiprocess-image-augmentation-keras.html" class="Link-sc-1brdqhf-0 cKRjba">http://blog.stratospark.com/multiprocess-image-augmentation-keras.html</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/stratospark/keras-multiprocess-image-data-generator" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/stratospark/keras-multiprocess-image-data-generator</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Comprehensive Data Augmentation and Sampling for Pytorch</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/ncullen93/torchsample" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/ncullen93/torchsample</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Image augmentation for machine learning experiments.</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://github.com/aleju/imgaug" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/aleju/imgaug</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Google/inception&#x27;s data augmentation: scale and aspect ratio augmentation</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebook/fb.resnet.torch/blob/master/datasets/transforms.lua#L130" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/facebook/fb.resnet.torch/blob/master/datasets/transforms.lua#L130</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Caffe Augmentation Extension</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Data Augmentation for Caffe</li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/twtygqyy/caffe-augmentation" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/twtygqyy/caffe-augmentation</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Improving Deep Learning using Generic Data Augmentation</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: University of Cape Town</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1708.06020" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1708.06020</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/webstorms/AugmentedDatasets" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/webstorms/AugmentedDatasets</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Augmentor: An Image Augmentation Library for Machine Learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1708.04680" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1708.04680</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/mdbloice/Augmentor" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/mdbloice/Augmentor</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Automatic Dataset Augmentation</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>project page: <a target="_blank" rel="noopener noreferrer" href="https://auto-da.github.io/" class="Link-sc-1brdqhf-0 cKRjba">https://auto-da.github.io/</a></li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1708.08201" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1708.08201</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Learning to Compose Domain-Specific Transformations for Data Augmentation</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1709.01643" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1709.01643</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Data Augmentation in Classification using GAN</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1711.00648" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1711.00648</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Data Augmentation Generative Adversarial Networks</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1711.04340" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1711.04340</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Random Erasing Data Augmentation</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1708.04896" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1708.04896</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhunzhong07/Random-Erasing" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/zhunzhong07/Random-Erasing</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Context Augmentation for Convolutional Neural Networks</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.01653" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.01653</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>The Effectiveness of Data Augmentation in Image Classification using Deep Learning</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.04621" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.04621</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>MentorNet: Regularizing Very Deep Neural Networks on Corrupted Labels</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Google Inc &amp; Stanford University</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.05055" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.05055</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>mixup: Beyond Empirical Risk Minimization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: MIT &amp; FAIR</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1710.09412" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1710.09412</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com//leehomyc/mixup_pytorch" class="Link-sc-1brdqhf-0 cKRjba">https://github.com//leehomyc/mixup_pytorch</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com//unsky/mixup" class="Link-sc-1brdqhf-0 cKRjba">https://github.com//unsky/mixup</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>mixup: Data-Dependent Data Augmentation</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://www.inference.vc/mixup-data-dependent-data-augmentation/" class="Link-sc-1brdqhf-0 cKRjba">http://www.inference.vc/mixup-data-dependent-data-augmentation/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Data Augmentation by Pairing Samples for Images Classification</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: IBM Research - Tokyo</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1801.02929" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1801.02929</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Feature Space Transfer for Data Augmentation</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>keywords: eATure TransfEr Network (FATTEN)</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1801.04356" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1801.04356</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Visual Data Augmentation through Learning</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1801.06665" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1801.06665</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Data Augmentation Generative Adversarial Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1711.04340" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1711.04340</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/AntreasAntoniou/DAGAN" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/AntreasAntoniou/DAGAN</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>BAGAN: Data Augmentation with Balancing GAN</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1803.09655" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1803.09655</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Parallel Grid Pooling for Data Augmentation</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: The University of Tokyo &amp; NTT Communications Science Laboratories</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1803.11370" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1803.11370</a></li><li>github(Chainer): <a target="_blank" rel="noopener noreferrer" href="https://github.com/akitotakeki/pgp-chainer" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/akitotakeki/pgp-chainer</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>AutoAugment: Learning Augmentation Policies from Data</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: CVPR 2019</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1805.09501" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1805.09501</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/DeepVoltaire/AutoAugment" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/DeepVoltaire/AutoAugment</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Improved Mixed-Example Data Augmentation</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1805.11272" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1805.11272</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Data augmentation instead of explicit regularization</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1806.03852" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1806.03852</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Data Augmentation using Random Image Cropping and Patching for Deep CNNs</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: An extended version of a proceeding of ACML2018</li><li>keywords: random image cropping and patching (RICAP)</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1811.09030" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1811.09030</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>GANsfer Learning: Combining labelled and unlabelled data for GAN based data augmentat</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1811.10669" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1811.10669</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Adversarial Learning of General Transformations for Data Augmentation</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Ecole de Technologie Sup ´ erieure &amp; Element AI</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1909.09801" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1909.09801</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Implicit Semantic Data Augmentation for Deep Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: NeurIPS 2019</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1909.12220" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1909.12220</a></li><li>github(official): <a target="_blank" rel="noopener noreferrer" href="https://github.com/blackfeather-wang/ISDA-for-Deep-Networks" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/blackfeather-wang/ISDA-for-Deep-Networks</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Data Augmentation Revisited: Rethinking the Distribution Gap between Clean and Augmented Data</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1909.09148" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1909.09148</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICLR 2020</li><li>intro: Google &amp; Deepmind</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1912.02781" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1912.02781</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/google-research/augmix" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/google-research/augmix</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>GridMask Data Augmentation</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2001.04086" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/2001.04086</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>On Feature Normalization and Data Augmentation</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Cornell University &amp; Cornell Tech &amp; ASAPP Inc. &amp; Facebook AI</li><li>keywords: MoEx (Moment Exchange)</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2002.11102" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/2002.11102</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/Boyiliee/MoEx" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Boyiliee/MoEx</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DADA: Differentiable Automatic Data Augmentation</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2003.03780" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/2003.03780</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Negative Data Augmentation</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICLR 2021</li><li>intro: Stanford University &amp; Samsung Research America</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2102.05113" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/2102.05113</a></li></ul><h2 id="imbalanced-datasets" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#imbalanced-datasets" color="auto.gray.8" aria-label="Imbalanced Datasets permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Imbalanced Datasets</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Investigation on handling Structured &amp; Imbalanced Datasets with Deep Learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: smote resampling, cost sensitive learning</li><li>blog: <a target="_blank" rel="noopener noreferrer" href="https://www.analyticsvidhya.com/blog/2016/10/investigation-on-handling-structured-imbalanced-datasets-with-deep-learning/" class="Link-sc-1brdqhf-0 cKRjba">https://www.analyticsvidhya.com/blog/2016/10/investigation-on-handling-structured-imbalanced-datasets-with-deep-learning/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A systematic study of the class imbalance problem in convolutional neural networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Duke University &amp; Royal Institute of Technology (KTH)</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1710.05381" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1710.05381</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Class Rectification Hard Mining for Imbalanced Deep Learning</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.03162" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.03162</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Bridging the Gap: Simultaneous Fine Tuning for Data Re-Balancing</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1801.02548" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1801.02548</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/JohnMcKay/dataImbalance" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/JohnMcKay/dataImbalance</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Imbalanced Deep Learning by Minority Class Incremental Rectification</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: TPAMI</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1804.10851" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1804.10851</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Pseudo-Feature Generation for Imbalanced Data Analysis in Deep Learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: National Institute of Information and Communications Technology, Tokyo Japan</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1807.06538" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1807.06538</a></li><li>slides: <a target="_blank" rel="noopener noreferrer" href="https://www.slideshare.net/TomohikoKonno/pseudofeature-generation-for-imbalanced-data-analysis-in-deep-learning-tomohiko-105318569" class="Link-sc-1brdqhf-0 cKRjba">https://www.slideshare.net/TomohikoKonno/pseudofeature-generation-for-imbalanced-data-analysis-in-deep-learning-tomohiko-105318569</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Max-margin Class Imbalanced Learning with Gaussian Affinity</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1901.07711" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1901.07711</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Dynamic Curriculum Learning for Imbalanced Data Classification</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICCV 2019</li><li>intro: SenseTime</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1901.06783" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1901.06783</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Class Rectification Hard Mining for Imbalanced Deep Learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICCV 2017</li><li>paper: <a target="_blank" rel="noopener noreferrer" href="https://www.eecs.qmul.ac.uk/~sgg/papers/DongEtAl_ICCV2017.pdf" class="Link-sc-1brdqhf-0 cKRjba">https://www.eecs.qmul.ac.uk/~sgg/papers/DongEtAl_ICCV2017.pdf</a></li></ul><h2 id="noisy--unlabelled-data" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#noisy--unlabelled-data" color="auto.gray.8" aria-label="Noisy / Unlabelled Data permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Noisy / Unlabelled Data</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Data Distillation: Towards Omni-Supervised Learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Facebook AI Research (FAIR)</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.04440" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.04440</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Learning From Noisy Singly-labeled Data</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: University of Illinois Urbana Champaign &amp; CMU &amp; Caltech &amp; Amazon AI</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.04577" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.04577</a></li></ul><h1 id="low-numerical-precision" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#low-numerical-precision" color="auto.gray.8" aria-label="Low Numerical Precision permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Low Numerical Precision</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Training deep neural networks with low precision multiplications</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICLR 2015</li><li>intro: Maxout networks, 10-bit activations, 12-bit parameter updates</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1412.7024" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1412.7024</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/MatthieuCourbariaux/deep-learning-multipliers" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/MatthieuCourbariaux/deep-learning-multipliers</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Learning with Limited Numerical Precision</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICML 2015</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1502.02551" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1502.02551</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>BinaryConnect: Training Deep Neural Networks with binary weights during propagations</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://papers.nips.cc/paper/5647-shape-and-illumination-from-shading-using-the-generic-viewpoint-assumption" class="Link-sc-1brdqhf-0 cKRjba">http://papers.nips.cc/paper/5647-shape-and-illumination-from-shading-using-the-generic-viewpoint-assumption</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/MatthieuCourbariaux/BinaryConnect" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/MatthieuCourbariaux/BinaryConnect</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Binarized Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1602.02505" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1602.02505</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1602.02830" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1602.02830</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/MatthieuCourbariaux/BinaryNet" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/MatthieuCourbariaux/BinaryNet</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/codekansas/tinier-nn" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/codekansas/tinier-nn</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1609.07061" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1609.07061</a></li></ul><h1 id="distributed-training" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#distributed-training" color="auto.gray.8" aria-label="Distributed Training permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Distributed Training</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Large Scale Distributed Systems for Training Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: By Jeff Dean &amp; Oriol Vinyals, Google. NIPS 2015.</li><li>slides: <a target="_blank" rel="noopener noreferrer" href="https://media.nips.cc/Conferences/2015/tutorialslides/Jeff-Oriol-NIPS-Tutorial-2015.pdf" class="Link-sc-1brdqhf-0 cKRjba">https://media.nips.cc/Conferences/2015/tutorialslides/Jeff-Oriol-NIPS-Tutorial-2015.pdf</a></li><li>video: <a target="_blank" rel="noopener noreferrer" href="http://research.microsoft.com/apps/video/default.aspx?id=259564&amp;l=i" class="Link-sc-1brdqhf-0 cKRjba">http://research.microsoft.com/apps/video/default.aspx?id=259564&amp;l=i</a></li><li>mirror: <a target="_blank" rel="noopener noreferrer" href="http://pan.baidu.com/s/1mgXV0hU" class="Link-sc-1brdqhf-0 cKRjba">http://pan.baidu.com/s/1mgXV0hU</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Large Scale Distributed Deep Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: distributed CPU training, data parallelism, model parallelism</li><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://www.cs.toronto.edu/~ranzato/publications/DistBeliefNIPS2012_withAppendix.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://www.cs.toronto.edu/~ranzato/publications/DistBeliefNIPS2012_withAppendix.pdf</a></li><li>slides: <a target="_blank" rel="noopener noreferrer" href="http://admis.fudan.edu.cn/~yfhuang/files/LSDDN_slide.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://admis.fudan.edu.cn/~yfhuang/files/LSDDN_slide.pdf</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Implementation of a Practical Distributed Calculation System with Browsers and JavaScript, and Application to Distributed Deep Learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>project page: <a target="_blank" rel="noopener noreferrer" href="http://mil-tokyo.github.io/" class="Link-sc-1brdqhf-0 cKRjba">http://mil-tokyo.github.io/</a></li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1503.05743" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1503.05743</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>SparkNet: Training Deep Networks in Spark</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1511.06051" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1511.06051</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/amplab/SparkNet" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/amplab/SparkNet</a></li><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://www.kdnuggets.com/2015/12/spark-deep-learning-training-with-sparknet.html" class="Link-sc-1brdqhf-0 cKRjba">http://www.kdnuggets.com/2015/12/spark-deep-learning-training-with-sparknet.html</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A Scalable Implementation of Deep Learning on Spark</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Alexander Ulanov</li><li>slides: <a target="_blank" rel="noopener noreferrer" href="http://www.slideshare.net/AlexanderUlanov1/a-scalable-implementation-of-deep-learning-on-spark-alexander-ulanov" class="Link-sc-1brdqhf-0 cKRjba">http://www.slideshare.net/AlexanderUlanov1/a-scalable-implementation-of-deep-learning-on-spark-alexander-ulanov</a></li><li>mirror: <a target="_blank" rel="noopener noreferrer" href="http://pan.baidu.com/s/1jHiNW5C" class="Link-sc-1brdqhf-0 cKRjba">http://pan.baidu.com/s/1jHiNW5C</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1603.04467" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1603.04467</a></li><li>gitxiv: <a target="_blank" rel="noopener noreferrer" href="http://gitxiv.com/posts/57kjddp3AWt4y5K4h/tensorflow-large-scale-machine-learning-on-heterogeneous" class="Link-sc-1brdqhf-0 cKRjba">http://gitxiv.com/posts/57kjddp3AWt4y5K4h/tensorflow-large-scale-machine-learning-on-heterogeneous</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Distributed Supervised Learning using Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Ph.D. thesis</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1607.06364" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1607.06364</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Distributed Training of Deep Neuronal Networks: Theoretical and Practical Limits of Parallel Scalability</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1609.06870" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1609.06870</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>How to scale distributed deep learning?</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Extended version of paper accepted at ML Sys 2016 (at NIPS 2016)</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1611.04581" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1611.04581</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Tsinghua University &amp; Stanford University</li><li>comments: we find 99.9% of the gradient exchange in distributed SGD is redundant; we reduce the communication bandwidth by two orders of magnitude without losing accuracy</li><li>keywords: momentum correction, local gradient clipping, momentum factor masking, and warm-up training</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.01887" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.01887</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Distributed learning of CNNs on heterogeneous CPU/GPU architectures</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.02546" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.02546</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Integrated Model and Data Parallelism in Training Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: UC Berkeley &amp; Lawrence Berkeley National Laboratory</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.04432" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.04432</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICLR 2018</li><li>intro: we find 99.9% of the gradient exchange in distributed SGD is redundant; we reduce the communication bandwidth by two orders of magnitude without losing accuracy</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.01887" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.01887</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>RedSync : Reducing Synchronization Traffic for Distributed Deep Learning</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1808.04357" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1808.04357</a></p><h2 id="projects" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#projects" color="auto.gray.8" aria-label="Projects permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Projects</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Theano-MPI: a Theano-based Distributed Training Framework</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1605.08325" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1605.08325</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/uoguelph-mlrg/Theano-MPI" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/uoguelph-mlrg/Theano-MPI</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>CaffeOnSpark: Open Sourced for Distributed Deep Learning on Big Data Clusters</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Yahoo Big ML Team</li><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://yahoohadoop.tumblr.com/post/139916563586/caffeonspark-open-sourced-for-distributed-deep" class="Link-sc-1brdqhf-0 cKRjba">http://yahoohadoop.tumblr.com/post/139916563586/caffeonspark-open-sourced-for-distributed-deep</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/yahoo/CaffeOnSpark" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/yahoo/CaffeOnSpark</a></li><li>youtube: <a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=bqj7nML-aHk" class="Link-sc-1brdqhf-0 cKRjba">https://www.youtube.com/watch?v=bqj7nML-aHk</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Tunnel: Data Driven Framework for Distributed Computing in Torch 7</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhangxiangxiao/tunnel" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/zhangxiangxiao/tunnel</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Distributed deep learning with Keras and Apache Spark</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>project page: <a target="_blank" rel="noopener noreferrer" href="http://joerihermans.com/work/distributed-keras/" class="Link-sc-1brdqhf-0 cKRjba">http://joerihermans.com/work/distributed-keras/</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/JoeriHermans/dist-keras" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/JoeriHermans/dist-keras</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>BigDL: Distributed Deep learning Library for Apache Spark</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/intel-analytics/BigDL" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/intel-analytics/BigDL</a></li></ul><h2 id="videos" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#videos" color="auto.gray.8" aria-label="Videos permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Videos</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>A Scalable Implementation of Deep Learning on Spark</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>youtube: <a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=pNYBBhuK8yU" class="Link-sc-1brdqhf-0 cKRjba">https://www.youtube.com/watch?v=pNYBBhuK8yU</a></li><li>mirror: <a target="_blank" rel="noopener noreferrer" href="http://pan.baidu.com/s/1mhzF1uK" class="Link-sc-1brdqhf-0 cKRjba">http://pan.baidu.com/s/1mhzF1uK</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Distributed TensorFlow on Spark: Scaling Google&#x27;s Deep Learning Library (Spark Summit)</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>youtube: <a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=-QtcP3yRqyM" class="Link-sc-1brdqhf-0 cKRjba">https://www.youtube.com/watch?v=-QtcP3yRqyM</a></li><li>mirror: <a target="_blank" rel="noopener noreferrer" href="http://pan.baidu.com/s/1mgOR1GG" class="Link-sc-1brdqhf-0 cKRjba">http://pan.baidu.com/s/1mgOR1GG</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Recurrent Neural Networks for Sequence Learning in Spark (Spark Summit)</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>youtube: <a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=mUuqLcl8Jog" class="Link-sc-1brdqhf-0 cKRjba">https://www.youtube.com/watch?v=mUuqLcl8Jog</a></li><li>mirror: <a target="_blank" rel="noopener noreferrer" href="http://pan.baidu.com/s/1sklHTPr" class="Link-sc-1brdqhf-0 cKRjba">http://pan.baidu.com/s/1sklHTPr</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Distributed deep learning on Spark</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>author: Alexander Ulanov July 12, 2016</li><li>intro: Alexander Ulanov offers an overview of tools and frameworks that have been proposed for performing deep learning on Spark.</li><li>video: <a target="_blank" rel="noopener noreferrer" href="https://www.oreilly.com/learning/distributed-deep-learning-on-spark" class="Link-sc-1brdqhf-0 cKRjba">https://www.oreilly.com/learning/distributed-deep-learning-on-spark</a></li></ul><h2 id="blogs" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 ffNRvO gCPbFb fvbkiW Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#blogs" color="auto.gray.8" aria-label="Blogs permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Blogs</h2><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Distributed Deep Learning Reads</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://github.com//tmulc18/DistributedDeepLearningReads" class="Link-sc-1brdqhf-0 cKRjba">https://github.com//tmulc18/DistributedDeepLearningReads</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Hadoop, Spark, Deep Learning Mesh on Single GPU Cluster</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://www.nextplatform.com/2016/02/24/hadoop-spark-deep-learning-mesh-on-single-gpu-cluster/" class="Link-sc-1brdqhf-0 cKRjba">http://www.nextplatform.com/2016/02/24/hadoop-spark-deep-learning-mesh-on-single-gpu-cluster/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>The Unreasonable Effectiveness of Deep Learning on Spark</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://databricks.com/blog/2016/04/01/unreasonable-effectiveness-of-deep-learning-on-spark.html" class="Link-sc-1brdqhf-0 cKRjba">https://databricks.com/blog/2016/04/01/unreasonable-effectiveness-of-deep-learning-on-spark.html</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Distributed Deep Learning with Caffe Using a MapR Cluster</strong></p><img src="https://www.mapr.com/sites/default/files/spark-driver.jpg" class="image__Image-sc-1r30dtv-0 elBfYx"/><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://www.mapr.com/blog/distributed-deep-learning-caffe-using-mapr-cluster" class="Link-sc-1brdqhf-0 cKRjba">https://www.mapr.com/blog/distributed-deep-learning-caffe-using-mapr-cluster</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deep Learning with Apache Spark and TensorFlow</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://databricks.com/blog/2016/01/25/deep-learning-with-apache-spark-and-tensorflow.html" class="Link-sc-1brdqhf-0 cKRjba">https://databricks.com/blog/2016/01/25/deep-learning-with-apache-spark-and-tensorflow.html</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Deeplearning4j on Spark</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://deeplearning4j.org/spark" class="Link-sc-1brdqhf-0 cKRjba">http://deeplearning4j.org/spark</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Distributed Deep Learning, Part 1: An Introduction to Distributed Training of Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>blog: <a target="_blank" rel="noopener noreferrer" href="http://engineering.skymind.io/distributed-deep-learning-part-1-an-introduction-to-distributed-training-of-neural-networks" class="Link-sc-1brdqhf-0 cKRjba">http://engineering.skymind.io/distributed-deep-learning-part-1-an-introduction-to-distributed-training-of-neural-networks</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>GPU Acceleration in Databricks: Speeding Up Deep Learning on Apache Spark</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://databricks.com/blog/2016/10/27/gpu-acceleration-in-databricks.html" class="Link-sc-1brdqhf-0 cKRjba">https://databricks.com/blog/2016/10/27/gpu-acceleration-in-databricks.html</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Distributed Deep Learning with Apache Spark and Keras</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://db-blog.web.cern.ch/blog/joeri-hermans/2017-01-distributed-deep-learning-apache-spark-and-keras" class="Link-sc-1brdqhf-0 cKRjba">https://db-blog.web.cern.ch/blog/joeri-hermans/2017-01-distributed-deep-learning-apache-spark-and-keras</a></p><h1 id="adversarial-training" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#adversarial-training" color="auto.gray.8" aria-label="Adversarial Training permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Adversarial Training</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Learning from Simulated and Unsupervised Images through Adversarial Training</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: CVPR 2017 oral, best paper award. Apple Inc.</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1612.07828" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1612.07828</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>The Robust Manifold Defense: Adversarial Training using Generative Models</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.09196" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.09196</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>DeepDefense: Training Deep Neural Networks with Improved Robustness</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1803.00404" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1803.00404</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Gradient Adversarial Training of Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Magic Leap</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1806.08028" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1806.08028</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Gray-box Adversarial Training</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ECCV 2018</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1808.01753" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1808.01753</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Universal Adversarial Training</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1811.11304" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1811.11304</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>MEAL: Multi-Model Ensemble via Adversarial Learning</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: AAAI 2019</li><li>intro: Fudan University &amp; University of Illinois at Urbana-Champaign</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1812.02425" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1812.02425</a></li><li>github(official): <a target="_blank" rel="noopener noreferrer" href="https://github.com/AaronHeee/MEAL" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/AaronHeee/MEAL</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Regularized Ensembles and Transferability in Adversarial Learning</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1812.01821" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1812.01821</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Feature denoising for improving adversarial robustness</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Johns Hopkins University &amp; Facebook AI Research</li><li>intro: ranked first in Competition on Adversarial Attacks and Defenses (CAAD) 2018</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1812.03411" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1812.03411</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/ImageNet-Adversarial-Training" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/facebookresearch/ImageNet-Adversarial-Training</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Second Rethinking of Network Pruning in the Adversarial Setting</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1903.12561" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1903.12561</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Interpreting Adversarially Trained Convolutional Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICML 2019</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1905.09797" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1905.09797</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>On Stabilizing Generative Adversarial Training with Noise</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: CVPR 2019</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1906.04612" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1906.04612</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Adversarial Learning with Margin-based Triplet Embedding Regularization</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICCV 2019</li><li>intro: BUPT</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1909.09481" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1909.09481</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhongyy/Adversarial_MTER" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/zhongyy/Adversarial_MTER</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Bag of Tricks for Adversarial Training</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Tsinghua University</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2010.00467" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/2010.00467</a></li></ul><h1 id="low-precision-training" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#low-precision-training" color="auto.gray.8" aria-label="Low-Precision Training permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Low-Precision Training</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Mixed Precision Training</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: ICLR 2018</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1710.03740" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1710.03740</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>High-Accuracy Low-Precision Training</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Cornell University &amp; Stanford University</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1803.03383" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1803.03383</a></li></ul><h1 id="incremental-training" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#incremental-training" color="auto.gray.8" aria-label="Incremental Training permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Incremental Training</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>ClickBAIT: Click-based Accelerated Incremental Training of Convolutional Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1709.05021" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1709.05021</a></li><li>dataset: <a target="_blank" rel="noopener noreferrer" href="http://clickbait.crossmobile.info/" class="Link-sc-1brdqhf-0 cKRjba">http://clickbait.crossmobile.info/</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>ClickBAIT-v2: Training an Object Detector in Real-Time</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1803.10358" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1803.10358</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Class-incremental Learning via Deep Model Consolidation</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: University of Southern California &amp; Arizona State University &amp; Samsung Research America</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1903.07864" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1903.07864</a></li></ul><h1 id="papers-1" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#papers" color="auto.gray.8" aria-label="Papers permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Papers</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Understanding the difficulty of training deep feed forward neural networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Xavier initialization</li><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf" class="Link-sc-1brdqhf-0 cKRjba">http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Domain-Adversarial Training of Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1505.07818" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1505.07818</a></li><li>paper: <a target="_blank" rel="noopener noreferrer" href="http://jmlr.org/papers/v17/15-239.html" class="Link-sc-1brdqhf-0 cKRjba">http://jmlr.org/papers/v17/15-239.html</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/pumpikano/tf-dann" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/pumpikano/tf-dann</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Scalable and Sustainable Deep Learning via Randomized Hashing</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1602.08194" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1602.08194</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Training Deep Nets with Sublinear Memory Cost</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1604.06174" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1604.06174</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/dmlc/mxnet-memonger" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/dmlc/mxnet-memonger</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/Bihaqo/tf-memonger" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Bihaqo/tf-memonger</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Improving the Robustness of Deep Neural Networks via Stability Training</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1604.04326" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1604.04326</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Faster Training of Very Deep Networks Via p-Norm Gates</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1608.03639" class="Link-sc-1brdqhf-0 cKRjba">http://arxiv.org/abs/1608.03639</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Fast Training of Convolutional Neural Networks via Kernel Rescaling</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1610.03623" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1610.03623</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>FreezeOut: Accelerate Training by Progressively Freezing Layers</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1706.04983" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1706.04983</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/ajbrock/FreezeOut" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/ajbrock/FreezeOut</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Normalized Gradient with Adaptive Stepsize Method for Deep Neural Network Training</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: CMU &amp; The University of Iowa</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1707.04822" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1707.04822</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Image Quality Assessment Guided Deep Neural Networks Training</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1708.03880" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1708.03880</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>An Effective Training Method For Deep Convolutional Neural Network</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Beijing Institute of Technology &amp; Tsinghua University</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1708.01666" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1708.01666</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>On the Importance of Consistency in Training Deep Neural Networks</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: University of Maryland &amp; Arizona State University</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1708.00631" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1708.00631</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Solving internal covariate shift in deep learning with linked neurons</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>intro: Universitat de Barcelona</li><li>arxiv: <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.02609" class="Link-sc-1brdqhf-0 cKRjba">https://arxiv.org/abs/1712.02609</a></li><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/blauigris/linked_neurons" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/blauigris/linked_neurons</a></li></ul><h1 id="tools" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#tools" color="auto.gray.8" aria-label="Tools permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Tools</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>pastalog: Simple, realtime visualization of neural network training performance</strong></p><img src="/assets/train-dnn/pastalog-main-big.gif" class="image__Image-sc-1r30dtv-0 elBfYx"/><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/rewonc/pastalog" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/rewonc/pastalog</a></li></ul><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>torch-pastalog: A Torch interface for pastalog - simple, realtime visualization of neural network training performance</strong></p><ul class="list__List-sc-s5kxp2-0 dFVIUa"><li>github: <a target="_blank" rel="noopener noreferrer" href="https://github.com/Kaixhin/torch-pastalog" class="Link-sc-1brdqhf-0 cKRjba">https://github.com/Kaixhin/torch-pastalog</a></li></ul><h1 id="blogs-1" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 ffNRvO gCPbFb fGjcEF Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 ffNRvO gCPbFb"><a href="#blogs" color="auto.gray.8" aria-label="Blogs permalink" class="Link-sc-1brdqhf-0 ekSqTm"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Blogs</h1><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Important nuances to train deep learning models</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="http://www.erogol.com/important-nuances-train-deep-learning-models/" class="Link-sc-1brdqhf-0 cKRjba">http://www.erogol.com/important-nuances-train-deep-learning-models/</a></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><strong>Train your deep model faster and sharper — two novel techniques</strong></p><p class="paragraph__Paragraph-sc-17pab92-0 iNQqSl"><a target="_blank" rel="noopener noreferrer" href="https://hackernoon.com/training-your-deep-model-faster-and-sharper-e85076c3b047" class="Link-sc-1brdqhf-0 cKRjba">https://hackernoon.com/training-your-deep-model-faster-and-sharper-e85076c3b047</a></p><div class="Box-nv15kw-0 ksEcN"><div display="flex" class="Box-nv15kw-0 jsSpbO"><a href="https://github.com/webizenai/devdocs/tree/main/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-training-dnn.md" class="Link-sc-1brdqhf-0 iLYDsn"><svg aria-hidden="true" role="img" class="StyledOcticon-uhnt7w-0 fafffn" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M11.013 1.427a1.75 1.75 0 012.474 0l1.086 1.086a1.75 1.75 0 010 2.474l-8.61 8.61c-.21.21-.47.364-.756.445l-3.251.93a.75.75 0 01-.927-.928l.929-3.25a1.75 1.75 0 01.445-.758l8.61-8.61zm1.414 1.06a.25.25 0 00-.354 0L10.811 3.75l1.439 1.44 1.263-1.263a.25.25 0 000-.354l-1.086-1.086zM11.189 6.25L9.75 4.81l-6.286 6.287a.25.25 0 00-.064.108l-.558 1.953 1.953-.558a.249.249 0 00.108-.064l6.286-6.286z"></path></svg>Edit this page</a><div><span font-size="1" color="auto.gray.7" class="Text-sc-1s3uzov-0 gHwtLv">Last updated on<!-- --> <b>12/30/2022</b></span></div></div></div></div></div></main></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script async="" src="https://www.googletagmanager.com/gtag/js?id="></script><script>
      
      
      if(true) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){window.dataLayer && window.dataLayer.push(arguments);}
        gtag('js', new Date());

        
      }
      </script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/old-work-archives/2018-webizen-net-au/resource-library/handong1587/_posts/deep_learning/2015-10-09-training-dnn/";window.___webpackCompilationHash="10c8b9c1f9dde870e591";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-2526e2a471eef3b9c3b2.js"],"app":["/app-f28009dab402ccf9360c.js"],"component---node-modules-gatsby-theme-primer-wiki-src-pages-404-js":["/component---node-modules-gatsby-theme-primer-wiki-src-pages-404-js-bd1c4b7f67a97d4f99af.js"],"component---node-modules-gatsby-theme-primer-wiki-src-templates-latest-query-js":["/component---node-modules-gatsby-theme-primer-wiki-src-templates-latest-query-js-6ed623c5d829c1a69525.js"],"component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js":["/component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js-46274f1a3983fff8a36b.js"]};/*]]>*/</script><script src="/polyfill-2526e2a471eef3b9c3b2.js" nomodule=""></script><script src="/component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js-46274f1a3983fff8a36b.js" async=""></script><script src="/commons-c89ede6cb9a530ac5a37.js" async=""></script><script src="/app-f28009dab402ccf9360c.js" async=""></script><script src="/dc6a8720040df98778fe970bf6c000a41750d3ae-8fdfd959b24cacbf7cee.js" async=""></script><script src="/0e226fb0-1cb0709e5ed968a9c435.js" async=""></script><script src="/f0e45107-3309acb69b4ccd30ce0c.js" async=""></script><script src="/framework-6c63f85700e5678d2c2a.js" async=""></script><script src="/webpack-runtime-1fe3daf7582b39746d36.js" async=""></script></body></html>